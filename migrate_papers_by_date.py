#!/usr/bin/env python3
"""
ê¸°ì¡´ individual_papers í´ë”ì˜ ë…¼ë¬¸ë“¤ì„ ë‚ ì§œë³„ í´ë”ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""

import os
import re
import shutil
from pathlib import Path
from datetime import datetime
from typing import Optional


def extract_date_from_filename(filename: str) -> Optional[str]:
    """
    íŒŒì¼ëª…ì—ì„œ ë‚ ì§œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    íŒŒì¼ëª… í˜•íƒœ: ë…¼ë¬¸ì œëª©_YYYYMMDD.md
    """
    # íŒŒì¼ëª… ëì—ì„œ _YYYYMMDD íŒ¨í„´ ì°¾ê¸°
    pattern = r'_(\d{8})\.md$'
    match = re.search(pattern, filename)

    if match:
        date_str = match.group(1)  # YYYYMMDD
        try:
            # ë‚ ì§œ í˜•ì‹ ê²€ì¦
            date_obj = datetime.strptime(date_str, '%Y%m%d')
            return date_obj.strftime('%Y-%m-%d')  # YYYY-MM-DD í˜•íƒœë¡œ ë³€í™˜
        except ValueError:
            print(f"âš ï¸ ì˜ëª»ëœ ë‚ ì§œ í˜•ì‹: {filename}")
            return None

    # ëŒ€ì²´ íŒ¨í„´ ì‹œë„: _YYYYMMDD_ì¶”ê°€í…ìŠ¤íŠ¸.md
    pattern_alt = r'_(\d{8})_.*\.md$'
    match_alt = re.search(pattern_alt, filename)

    if match_alt:
        date_str = match_alt.group(1)
        try:
            date_obj = datetime.strptime(date_str, '%Y%m%d')
            return date_obj.strftime('%Y-%m-%d')
        except ValueError:
            print(f"âš ï¸ ì˜ëª»ëœ ë‚ ì§œ í˜•ì‹ (ëŒ€ì²´ íŒ¨í„´): {filename}")
            return None

    print(f"âš ï¸ ë‚ ì§œë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ëŠ” íŒŒì¼ëª…: {filename}")
    return None


def extract_date_from_content(file_path: Path) -> Optional[str]:
    """
    íŒŒì¼ ë‚´ìš©ì—ì„œ ë°œí–‰ì¼ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # ë°œí–‰ì¼ íŒ¨í„´ ì°¾ê¸°
        patterns = [
            r'ë°œí–‰ì¼:\s*(\d{4}-\d{2}-\d{2})',
            r'Published:\s*(\d{4}-\d{2}-\d{2})',
            r'ë‚ ì§œ:\s*(\d{4}-\d{2}-\d{2})',
            r'Date:\s*(\d{4}-\d{2}-\d{2})',
        ]

        for pattern in patterns:
            match = re.search(pattern, content)
            if match:
                return match.group(1)

        return None
    except Exception as e:
        print(f"âš ï¸ íŒŒì¼ ë‚´ìš© ì½ê¸° ì‹¤íŒ¨ {file_path}: {e}")
        return None


def update_obsidian_links_in_file(file_path: Path, old_path: str, new_path: str):
    """
    íŒŒì¼ ë‚´ì˜ ì˜µì‹œë””ì–¸ ë§í¬ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # ìƒëŒ€ ê²½ë¡œ ë§í¬ íŒ¨í„´ ì°¾ê¸° ë° ìˆ˜ì •
        # [[ë…¼ë¬¸ì œëª©_ë‚ ì§œ]] -> [[ë‚ ì§œ/ë…¼ë¬¸ì œëª©_ë‚ ì§œ]]
        pattern = r'\[\[([^|\]]+)\]\]'

        def replace_link(match):
            link_text = match.group(1)
            # ë§Œì•½ ë§í¬ê°€ ë…¼ë¬¸ íŒŒì¼ì„ ê°€ë¦¬í‚¤ëŠ” ê²½ìš° ë‚ ì§œ í´ë” ê²½ë¡œë¥¼ ì¶”ê°€
            if re.search(r'_\d{8}$', link_text):  # _YYYYMMDDë¡œ ëë‚˜ëŠ” ê²½ìš°
                date_from_link = extract_date_from_filename(link_text + '.md')
                if date_from_link:
                    return f'[[{date_from_link}/{link_text}]]'
            return match.group(0)  # ë³€ê²½í•˜ì§€ ì•ŠìŒ

        updated_content = re.sub(pattern, replace_link, content)

        if content != updated_content:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(updated_content)
            print(f"âœ… ì˜µì‹œë””ì–¸ ë§í¬ ì—…ë°ì´íŠ¸: {file_path}")

    except Exception as e:
        print(f"âš ï¸ ì˜µì‹œë””ì–¸ ë§í¬ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ {file_path}: {e}")


def migrate_papers():
    """
    ê¸°ì¡´ ë…¼ë¬¸ë“¤ì„ ë‚ ì§œë³„ í´ë”ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•©ë‹ˆë‹¤.
    """
    # ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
    base_dir = Path("reports/individual_papers")

    if not base_dir.exists():
        print(f"âŒ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {base_dir}")
        return

    print(f"ğŸ“ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘: {base_dir}")

    # ë°±ì—… ë””ë ‰í† ë¦¬ ìƒì„±
    backup_dir = base_dir.parent / "individual_papers_backup"
    if not backup_dir.exists():
        print(f"ğŸ“‚ ë°±ì—… ë””ë ‰í† ë¦¬ ìƒì„±: {backup_dir}")
        shutil.copytree(base_dir, backup_dir)

    moved_files = []
    failed_files = []

    # .md íŒŒì¼ë“¤ë§Œ ì²˜ë¦¬
    for file_path in base_dir.glob("*.md"):
        filename = file_path.name
        print(f"\nğŸ” ì²˜ë¦¬ ì¤‘: {filename}")

        # 1. íŒŒì¼ëª…ì—ì„œ ë‚ ì§œ ì¶”ì¶œ ì‹œë„
        target_date = extract_date_from_filename(filename)

        # 2. íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ, íŒŒì¼ ë‚´ìš©ì—ì„œ ì¶”ì¶œ ì‹œë„
        if not target_date:
            target_date = extract_date_from_content(file_path)

        # 3. ë‚ ì§œ ì¶”ì¶œ ì‹¤íŒ¨
        if not target_date:
            print(f"âŒ ë‚ ì§œ ì¶”ì¶œ ì‹¤íŒ¨: {filename}")
            failed_files.append(filename)
            continue

        # ë‚ ì§œë³„ í´ë” ìƒì„±
        date_dir = base_dir / target_date
        date_dir.mkdir(exist_ok=True)

        # íŒŒì¼ ì´ë™
        new_file_path = date_dir / filename

        try:
            shutil.move(str(file_path), str(new_file_path))
            print(f"âœ… ì´ë™ ì™„ë£Œ: {filename} -> {target_date}/")
            moved_files.append((filename, target_date))

            # ì˜µì‹œë””ì–¸ ë§í¬ ì—…ë°ì´íŠ¸
            update_obsidian_links_in_file(new_file_path, filename, f"{target_date}/{filename}")

        except Exception as e:
            print(f"âŒ íŒŒì¼ ì´ë™ ì‹¤íŒ¨ {filename}: {e}")
            failed_files.append(filename)

    # ëª¨ë“  ë‚ ì§œ í´ë”ì˜ íŒŒì¼ë“¤ì— ëŒ€í•´ ì˜µì‹œë””ì–¸ ë§í¬ ì—…ë°ì´íŠ¸
    print(f"\nğŸ”— ëª¨ë“  íŒŒì¼ì˜ ì˜µì‹œë””ì–¸ ë§í¬ ì—…ë°ì´íŠ¸ ì¤‘...")
    for date_dir in base_dir.iterdir():
        if date_dir.is_dir():
            for file_path in date_dir.glob("*.md"):
                update_obsidian_links_in_file(file_path, "", "")

    # ê²°ê³¼ ìš”ì•½
    print(f"\nğŸ“Š ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")
    print(f"âœ… ì„±ê³µ: {len(moved_files)}ê°œ íŒŒì¼")
    print(f"âŒ ì‹¤íŒ¨: {len(failed_files)}ê°œ íŒŒì¼")

    if moved_files:
        print(f"\nğŸ“ ë‚ ì§œë³„ ë¶„ë¥˜ ê²°ê³¼:")
        date_counts = {}
        for filename, date in moved_files:
            date_counts[date] = date_counts.get(date, 0) + 1

        for date, count in sorted(date_counts.items()):
            print(f"  ğŸ“… {date}: {count}ê°œ íŒŒì¼")

    if failed_files:
        print(f"\nâš ï¸ ì²˜ë¦¬ ì‹¤íŒ¨í•œ íŒŒì¼ë“¤:")
        for filename in failed_files:
            print(f"  - {filename}")

    print(f"\nğŸ’¾ ë°±ì—… ìœ„ì¹˜: {backup_dir}")


if __name__ == "__main__":
    print("ğŸ“„ AI Frontier ë…¼ë¬¸ íŒŒì¼ ë‚ ì§œë³„ ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸")
    print("=" * 60)

    # ìë™ ì‹¤í–‰ (í™•ì¸ ë©”ì‹œì§€ ìŠ¤í‚µ)
    migrate_papers()