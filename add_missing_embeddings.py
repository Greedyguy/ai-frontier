#!/usr/bin/env python3
"""ëˆ„ë½ëœ ë…¼ë¬¸ë“¤ì˜ ì„ë² ë”© ìƒì„± ë° ë²¡í„° DB ì¶”ê°€"""

import os
import sys
import re
from pathlib import Path
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Add src to path
sys.path.insert(0, '/Users/luke/work/SKT/edu/ai_frontier/src')

from ai_frontier.embeddings.similarity_manager import SimilarityManager
from ai_frontier.embeddings.service import get_embeddings_service
from ai_frontier.arxiv.client import ArxivPaper
from datetime import datetime

def extract_paper_info_from_file(filepath):
    """ë…¼ë¬¸ íŒŒì¼ì—ì„œ í•„ìš”í•œ ì •ë³´ ì¶”ì¶œ"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()

        # ì œëª© ì¶”ì¶œ (ì²« ë²ˆì§¸ # í—¤ë”)
        title_match = re.search(r'^# (.+)$', content, re.MULTILINE)
        title = title_match.group(1) if title_match else ""

        # ArXiv ID ì¶”ì¶œ
        arxiv_match = re.search(r'\*\*ArXiv ID\*\*:\s*\[([^\]]+)\]', content)
        arxiv_id = arxiv_match.group(1) if arxiv_match else ""
        # v1, v2 ë“± ë²„ì „ ì œê±°
        if 'v' in arxiv_id:
            arxiv_id = arxiv_id.split('v')[0]

        # Published ë‚ ì§œ ì¶”ì¶œ
        published_match = re.search(r'\*\*Published\*\*:\s*([^\n]+)', content)
        published_str = published_match.group(1) if published_match else "2025-09-17"

        # Category ì¶”ì¶œ
        category_match = re.search(r'\*\*Category\*\*:\s*([^\n]+)', content)
        category = category_match.group(1) if category_match else "cs.AI"

        # Abstract ì¶”ì¶œ (ì›ë¬¸)
        abstract_match = re.search(r'## ğŸ“„ Abstract \(ì›ë¬¸\)\n\n(.*?)\n\n## ', content, re.DOTALL)
        abstract = abstract_match.group(1).strip() if abstract_match else ""

        # ìš”ì•½ ì¶”ì¶œ
        summary_match = re.search(r'## ğŸ“ ìš”ì•½\n\n(.*?)\n\n## ', content, re.DOTALL)
        summary = summary_match.group(1).strip() if summary_match else ""

        # í•µì‹¬ í¬ì¸íŠ¸ ì¶”ì¶œ
        key_points_match = re.search(r'## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸\n\n(.*?)(?:\n\n---|$)', content, re.DOTALL)
        key_points_text = key_points_match.group(1).strip() if key_points_match else ""

        # í•µì‹¬ í¬ì¸íŠ¸ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        key_points = []
        if key_points_text:
            lines = key_points_text.split('\n')
            for line in lines:
                line = line.strip()
                if line and line.startswith('- '):
                    key_points.append(line[2:].strip())

        return {
            'arxiv_id': arxiv_id,
            'title': title,
            'abstract': abstract,
            'summary': summary,
            'key_points': key_points,
            'published': published_str,
            'category': category
        }

    except Exception as e:
        print(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ {filepath}: {e}")
        return None

def create_arxiv_paper_object(paper_info):
    """ArxivPaper ê°ì²´ ìƒì„±"""
    from datetime import datetime

    # ë‚ ì§œ íŒŒì‹±
    try:
        if paper_info['published']:
            published_date = datetime.strptime(paper_info['published'], '%Y-%m-%d')
        else:
            published_date = datetime.now()
    except:
        published_date = datetime.now()

    return ArxivPaper(
        arxiv_id=paper_info['arxiv_id'],
        title=paper_info['title'],
        authors=[],  # ê¸°ë³¸ê°’
        abstract=paper_info['abstract'],
        published=published_date,  # published í•„ë“œ
        updated=None,  # ê¸°ë³¸ê°’
        pdf_url=f"http://arxiv.org/pdf/{paper_info['arxiv_id']}.pdf",  # PDF URL ìƒì„±
        category=paper_info['category']  # category í•„ë“œ
    )

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ ëˆ„ë½ëœ ë…¼ë¬¸ ì„ë² ë”© ìƒì„± ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘")

    try:
        # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        print("ğŸ“Š ì„ë² ë”© ë° ìœ ì‚¬ë„ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”...")
        embeddings_service = get_embeddings_service()
        similarity_manager = SimilarityManager(embeddings_service=embeddings_service)

        # í˜„ì¬ ë²¡í„° DB ìƒíƒœ í™•ì¸
        current_count = len(similarity_manager.vector_db.arxiv_id_to_index)
        print(f"âœ… í˜„ì¬ ë²¡í„° DB ì„ë² ë”© ìˆ˜: {current_count}")

        # ëˆ„ë½ëœ ë…¼ë¬¸ íŒŒì¼ë“¤
        missing_files = [
            "/Users/luke/work/SKT/edu/ai_frontier/reports/individual_papers/Exploring Major Transitions in the Evolution of Bi_20250917.md",
            "/Users/luke/work/SKT/edu/ai_frontier/reports/individual_papers/HLSMAC_ A New StarCraft Multi-Agent Challenge for_20250916.md"
        ]

        print(f"ğŸ“„ ì²˜ë¦¬í•  ëˆ„ë½ëœ ë…¼ë¬¸: {len(missing_files)}ê°œ")

        for i, filepath in enumerate(missing_files, 1):
            filename = Path(filepath).name
            print(f"[{i}/{len(missing_files)}] ì²˜ë¦¬ ì¤‘: {filename[:50]}...")

            # ë…¼ë¬¸ ì •ë³´ ì¶”ì¶œ
            paper_info = extract_paper_info_from_file(filepath)
            if not paper_info:
                print(f"âŒ ë…¼ë¬¸ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {filename}")
                continue

            arxiv_id = paper_info['arxiv_id']
            print(f"  ğŸ“„ ArXiv ID: {arxiv_id}")
            print(f"  ğŸ“ ì œëª©: {paper_info['title'][:60]}...")

            # ì´ë¯¸ ë²¡í„° DBì— ìˆëŠ”ì§€ í™•ì¸
            if arxiv_id in similarity_manager.vector_db.arxiv_id_to_index:
                print(f"  â­ï¸  ì´ë¯¸ ë²¡í„° DBì— ì¡´ì¬í•¨")
                continue

            # ArxivPaper ê°ì²´ ìƒì„±
            paper = create_arxiv_paper_object(paper_info)

            # ì„ë² ë”© ìƒì„± ë° ì €ì¥
            try:
                print(f"  ğŸ”„ ì„ë² ë”© ìƒì„± ì¤‘...")
                paper_embedding = similarity_manager.process_paper(
                    paper,
                    paper_info['summary'],
                    paper_info['key_points']
                )
                print(f"  âœ… ì„ë² ë”© ìƒì„± ë° ì €ì¥ ì™„ë£Œ")

            except Exception as e:
                print(f"  âŒ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
                continue

        # ìµœì¢… ìƒíƒœ í™•ì¸
        final_count = len(similarity_manager.vector_db.arxiv_id_to_index)
        added_count = final_count - current_count

        print(f"\nğŸ‰ ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"  ğŸ“Š ì´ì „ ì„ë² ë”© ìˆ˜: {current_count}")
        print(f"  ğŸ“Š í˜„ì¬ ì„ë² ë”© ìˆ˜: {final_count}")
        print(f"  âœ… ì¶”ê°€ëœ ì„ë² ë”©: {added_count}ê°œ")

    except Exception as e:
        print(f"âŒ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        return 1

    return 0

if __name__ == "__main__":
    exit(main())