---
keywords:
  - Large Language Models
  - Malware Behavior Auditing
  - Static Reachability Analysis
category: cs.AI
publish_date: 2025-09-17
arxiv_id:
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 23:00:15.441454",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Models",
    "Malware Behavior Auditing",
    "Static Reachability Analysis"
  ],
  "rejected_keywords": [
    "Function-Level Structural Representations"
  ],
  "similarity_scores": {
    "Large Language Models": 0.8,
    "Malware Behavior Auditing": 0.78,
    "Static Reachability Analysis": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->

# Beyond Classification: Evaluating LLMs for Fine-Grained Automatic Malware Behavior Auditing

**Korean Title:** ë¶„ë¥˜ë¥¼ ë„˜ì–´ì„œ: ì„¸ë¶„í™”ëœ ìë™ ì•…ì„±ì½”ë“œ í–‰ë™ ê°ì‚¬ì— ëŒ€í•œ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ í‰ê°€

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[digests/daily_digest_20250917|2025-09-17]]        [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Large Language Models|Large Language Models]], [[keywords/Static Reachability Analysis|Static Reachability Analysis]]
**âš¡ Unique Technical**: [[keywords/Malware Behavior Auditing|Malware Behavior Auditing]]

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[MedVAL_ Toward Expert-Level Medical Text Validation with Language Models_20250919|MedVAL Toward Expert-Level Medical Text Validation with Language Models]] (83.7% similar)
- [[BEACON_ Behavioral Malware Classification with Large Language Model Embeddings and Deep Learning_20250919|BEACON Behavioral Malware Classification with Large Language Model Embeddings and Deep Learning]] (83.7% similar)
- [[MADAR_ Efficient Continual Learning for Malware Analysis with Distribution-Aware Replay_20250919|MADAR Efficient Continual Learning for Malware Analysis with Distribution-Aware Replay]] (83.6% similar)
- [[LNE-Blocking_ An Efficient Framework for Contamination Mitigation Evaluation on Large Language Models_20250918|LNE-Blocking An Efficient Framework for Contamination Mitigation Evaluation on Large Language Models]] (83.3% similar)
- [[Simulating a Bias Mitigation Scenario in Large Language Models_20250917|Simulating a Bias Mitigation Scenario in Large Language Models]] (83.0% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** Xinran Zheng, Xingzhi Qian, Yiling He, Shuo Yang, Lorenzo Cavallaro

## ğŸ“„ Abstract (ì›ë¬¸)

Automated malware classification has achieved strong detection performance.
Yet, malware behavior auditing seeks causal and verifiable explanations of
malicious activities -- essential not only to reveal what malware does but also
to substantiate such claims with evidence. This task is challenging, as
adversarial intent is often hidden within complex, framework-heavy
applications, making manual auditing slow and costly. Large Language Models
(LLMs) could help address this gap, but their auditing potential remains
largely unexplored due to three limitations: (1) scarce fine-grained
annotations for fair assessment; (2) abundant benign code obscuring malicious
signals; and (3) unverifiable, hallucination-prone outputs undermining
attribution credibility. To close this gap, we introduce MalEval, a
comprehensive framework for fine-grained Android malware auditing, designed to
evaluate how effectively LLMs support auditing under real-world constraints.
MalEval provides expert-verified reports and an updated sensitive API list to
mitigate ground truth scarcity and reduce noise via static reachability
analysis. Function-level structural representations serve as intermediate
attribution units for verifiable evaluation. Building on this, we define four
analyst-aligned tasks -- function prioritization, evidence attribution,
behavior synthesis, and sample discrimination -- together with domain-specific
metrics and a unified workload-oriented score. We evaluate seven widely used
LLMs on a curated dataset of recent malware and misclassified benign apps,
offering the first systematic assessment of their auditing capabilities.
MalEval reveals both promising potential and critical limitations across audit
stages, providing a reproducible benchmark and foundation for future research
on LLM-enhanced malware behavior auditing. MalEval is publicly available at
https://github.com/ZhengXR930/MalEval.git

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

ìë™í™”ëœ ì•…ì„±ì½”ë“œ ë¶„ë¥˜ëŠ” ê°•ë ¥í•œ íƒì§€ ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì•…ì„±ì½”ë“œ í–‰ë™ ê°ì‚¬ëŠ” ì•…ì˜ì ì¸ í™œë™ì— ëŒ€í•œ ì¸ê³¼ì ì´ê³  ê²€ì¦ ê°€ëŠ¥í•œ ì„¤ëª…ì„ ì¶”êµ¬í•©ë‹ˆë‹¤. ì´ëŠ” ì•…ì„±ì½”ë“œê°€ ë¬´ì—‡ì„ í•˜ëŠ”ì§€ë¥¼ ë°íˆëŠ” ê²ƒë¿ë§Œ ì•„ë‹ˆë¼ ê·¸ëŸ¬í•œ ì£¼ì¥ì„ ì¦ê±°ë¡œ ë’·ë°›ì¹¨í•˜ëŠ” ë° í•„ìˆ˜ì ì…ë‹ˆë‹¤. ì´ ì‘ì—…ì€ ë„ì „ì ì…ë‹ˆë‹¤. ì™œëƒí•˜ë©´ ì ëŒ€ì ì¸ ì˜ë„ê°€ ì¢…ì¢… ë³µì¡í•˜ê³  í”„ë ˆì„ì›Œí¬ê°€ ë¬´ê±°ìš´ ì• í”Œë¦¬ì¼€ì´ì…˜ ë‚´ì— ìˆ¨ê²¨ì ¸ ìˆì–´ ìˆ˜ë™ ê°ì‚¬ê°€ ëŠë¦¬ê³  ë¹„ìš©ì´ ë§ì´ ë“¤ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ ì´ ê²©ì°¨ë¥¼ í•´ì†Œí•˜ëŠ” ë° ë„ì›€ì„ ì¤„ ìˆ˜ ìˆì§€ë§Œ, ì„¸ ê°€ì§€ ì œí•œ ì‚¬í•­ìœ¼ë¡œ ì¸í•´ ê°ì‚¬ ì ì¬ë ¥ì€ ëŒ€ë¶€ë¶„ íƒêµ¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: (1) ê³µì •í•œ í‰ê°€ë¥¼ ìœ„í•œ ì„¸ë°€í•œ ì£¼ì„ì˜ ë¶€ì¡±; (2) ì•…ì„± ì‹ í˜¸ë¥¼ ê°€ë¦¬ëŠ” í’ë¶€í•œ ì •ìƒ ì½”ë“œ; (3) ê²€ì¦í•  ìˆ˜ ì—†ê³  í™˜ê°ì— ì·¨ì•½í•œ ì¶œë ¥ì´ ì†ì„±ì˜ ì‹ ë¢°ì„±ì„ ì €í•´í•¨. ì´ ê²©ì°¨ë¥¼ í•´ì†Œí•˜ê¸° ìœ„í•´ ìš°ë¦¬ëŠ” MalEvalì„ ì†Œê°œí•©ë‹ˆë‹¤. ì´ëŠ” ì„¸ë°€í•œ ì•ˆë“œë¡œì´ë“œ ì•…ì„±ì½”ë“œ ê°ì‚¬ë¥¼ ìœ„í•œ í¬ê´„ì ì¸ í”„ë ˆì„ì›Œí¬ë¡œ, ì‹¤ì œ ì œì•½ ì¡°ê±´ í•˜ì—ì„œ LLMì´ ê°ì‚¬ë¥¼ ì–¼ë§ˆë‚˜ íš¨ê³¼ì ìœ¼ë¡œ ì§€ì›í•˜ëŠ”ì§€ë¥¼ í‰ê°€í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. MalEvalì€ ì „ë¬¸ê°€ê°€ ê²€ì¦í•œ ë³´ê³ ì„œì™€ ì—…ë°ì´íŠ¸ëœ ë¯¼ê°í•œ API ëª©ë¡ì„ ì œê³µí•˜ì—¬ ì§„ì‹¤ì˜ ë¶€ì¡±ì„ ì™„í™”í•˜ê³  ì •ì  ë„ë‹¬ ê°€ëŠ¥ì„± ë¶„ì„ì„ í†µí•´ ì¡ìŒì„ ì¤„ì…ë‹ˆë‹¤. í•¨ìˆ˜ ìˆ˜ì¤€ì˜ êµ¬ì¡°ì  í‘œí˜„ì€ ê²€ì¦ ê°€ëŠ¥í•œ í‰ê°€ë¥¼ ìœ„í•œ ì¤‘ê°„ ì†ì„± ë‹¨ìœ„ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤. ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìš°ë¦¬ëŠ” ë„¤ ê°€ì§€ ë¶„ì„ê°€ ì •ë ¬ ì‘ì—… -- í•¨ìˆ˜ ìš°ì„ ìˆœìœ„ ì§€ì •, ì¦ê±° ì†ì„±, í–‰ë™ í•©ì„±, ìƒ˜í”Œ êµ¬ë³„ -- ì„ ë„ë©”ì¸ë³„ ë©”íŠ¸ë¦­ ë° í†µí•©ëœ ì‘ì—…ëŸ‰ ì§€í–¥ ì ìˆ˜ì™€ í•¨ê»˜ ì •ì˜í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ìµœê·¼ ì•…ì„±ì½”ë“œì™€ ì˜¤ë¶„ë¥˜ëœ ì •ìƒ ì•±ì˜ íë ˆì´ì…˜ëœ ë°ì´í„°ì…‹ì—ì„œ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” 7ê°œì˜ LLMì„ í‰ê°€í•˜ì—¬ ê·¸ë“¤ì˜ ê°ì‚¬ ëŠ¥ë ¥ì— ëŒ€í•œ ìµœì´ˆì˜ ì²´ê³„ì ì¸ í‰ê°€ë¥¼ ì œê³µí•©ë‹ˆë‹¤. MalEvalì€ ê°ì‚¬ ë‹¨ê³„ ì „ë°˜ì— ê±¸ì³ ìœ ë§í•œ ì ì¬ë ¥ê³¼ ì¤‘ìš”í•œ í•œê³„ë¥¼ ëª¨ë‘ ë“œëŸ¬ë‚´ë©°, LLM ê°•í™” ì•…ì„±ì½”ë“œ í–‰ë™ ê°ì‚¬ì— ëŒ€í•œ ë¯¸ë˜ ì—°êµ¬ì˜ ì¬í˜„ ê°€ëŠ¥í•œ ë²¤ì¹˜ë§ˆí¬ì™€ ê¸°ì´ˆë¥¼ ì œê³µí•©ë‹ˆë‹¤. MalEvalì€ https://github.com/ZhengXR930/MalEval.gitì—ì„œ ê³µê°œì ìœ¼ë¡œ ì´ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ìë™í™”ëœ ì•…ì„±ì½”ë“œ ë¶„ë¥˜ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ MalEvalì´ë¼ëŠ” í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. MalEvalì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ í™œìš©í•˜ì—¬ ì•ˆë“œë¡œì´ë“œ ì•…ì„±ì½”ë“œì˜ ì„¸ë°€í•œ ê°ì‚¬ ì‘ì—…ì„ ì§€ì›í•˜ë©°, ì‹¤ì œ í™˜ê²½ì—ì„œì˜ íš¨ê³¼ì„±ì„ í‰ê°€í•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ì „ë¬¸ê°€ ê²€ì¦ ë³´ê³ ì„œì™€ ìµœì‹  ë¯¼ê° API ëª©ë¡ì„ ì œê³µí•˜ê³ , ì •ì  ë„ë‹¬ ê°€ëŠ¥ì„± ë¶„ì„ì„ í†µí•´ ë…¸ì´ì¦ˆë¥¼ ì¤„ì…ë‹ˆë‹¤. ê¸°ëŠ¥ ìš°ì„ ìˆœìœ„ ê²°ì •, ì¦ê±° ê·€ì†, í–‰ë™ í•©ì„±, ìƒ˜í”Œ êµ¬ë¶„ì˜ ë„¤ ê°€ì§€ ì‘ì—…ì„ ì •ì˜í•˜ê³ , ë„ë©”ì¸ë³„ ì§€í‘œì™€ í†µí•© ì ìˆ˜ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. 7ê°œì˜ LLMì„ í‰ê°€í•œ ê²°ê³¼, MalEvalì€ LLMì˜ ê°ì‚¬ ëŠ¥ë ¥ì˜ ì ì¬ë ¥ê³¼ í•œê³„ë¥¼ ë“œëŸ¬ë‚´ë©°, í–¥í›„ ì—°êµ¬ì˜ ê¸°ì´ˆë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ìë™í™”ëœ ì•…ì„±ì½”ë“œ ë¶„ë¥˜ëŠ” ê°•ë ¥í•œ íƒì§€ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë‚˜, ì•…ì„±ì½”ë“œ í–‰ë™ ê°ì‚¬ëŠ” ì¸ê³¼ì ì´ê³  ê²€ì¦ ê°€ëŠ¥í•œ ì„¤ëª…ì„ ìš”êµ¬í•˜ì—¬ ìˆ˜ì‘ì—… ê°ì‚¬ê°€ ëŠë¦¬ê³  ë¹„ìš©ì´ ë§ì´ ë“ ë‹¤.

- 2. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ ì•…ì„±ì½”ë“œ ê°ì‚¬ì˜ ì ì¬ë ¥ì„ ê°€ì§€ê³  ìˆì§€ë§Œ, ì„¸ ê°€ì§€ ì œí•œ ì‚¬í•­ìœ¼ë¡œ ì¸í•´ ê·¸ ê°€ëŠ¥ì„±ì´ ì¶©ë¶„íˆ íƒêµ¬ë˜ì§€ ì•Šì•˜ë‹¤.

- 3. MalEvalì€ LLMì´ ì‹¤ì œ í™˜ê²½ì—ì„œ ì•…ì„±ì½”ë“œ ê°ì‚¬ë¥¼ ì–¼ë§ˆë‚˜ íš¨ê³¼ì ìœ¼ë¡œ ì§€ì›í•˜ëŠ”ì§€ë¥¼ í‰ê°€í•˜ê¸° ìœ„í•œ ì¢…í•©ì ì¸ í”„ë ˆì„ì›Œí¬ë¡œ, ì „ë¬¸ê°€ ê²€ì¦ ë³´ê³ ì„œì™€ ì—…ë°ì´íŠ¸ëœ ë¯¼ê° API ëª©ë¡ì„ ì œê³µí•œë‹¤.

- 4. MalEvalì€ ê¸°ëŠ¥ ìš°ì„ ìˆœìœ„í™”, ì¦ê±° ê·€ì†, í–‰ë™ í•©ì„±, ìƒ˜í”Œ êµ¬ë¶„ì˜ ë„¤ ê°€ì§€ ë¶„ì„ê°€ ì •ë ¬ ì‘ì—…ê³¼ ë„ë©”ì¸ë³„ ë©”íŠ¸ë¦­ ë° í†µí•©ëœ ì‘ì—…ëŸ‰ ì§€í–¥ ì ìˆ˜ë¥¼ ì •ì˜í•œë‹¤.

- 5. MalEvalì€ LLMì˜ ê°ì‚¬ ëŠ¥ë ¥ì„ ì²´ê³„ì ìœ¼ë¡œ í‰ê°€í•˜ì—¬ ê°ì‚¬ ë‹¨ê³„ ì „ë°˜ì— ê±¸ì³ ìœ ë§í•œ ì ì¬ë ¥ê³¼ ì¤‘ìš”í•œ í•œê³„ë¥¼ ë“œëŸ¬ë‚´ë©°, LLM ê¸°ë°˜ ì•…ì„±ì½”ë“œ í–‰ë™ ê°ì‚¬ ì—°êµ¬ì˜ ê¸°ì´ˆë¥¼ ì œê³µí•œë‹¤.

---

*Generated on 2025-09-20 07:38:39*