---
keywords:
  - Neural PDE Solvers
  - Operator Learning
  - Optimization
category: cs.AI
publish_date: 2025-09-17
arxiv_id:
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 23:02:31.772916",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Neural PDE Solvers",
    "Operator Learning",
    "Optimization"
  ],
  "rejected_keywords": [
    "Residual-Based Adaptivity",
    "Adaptive Weighting"
  ],
  "similarity_scores": {
    "Neural PDE Solvers": 0.78,
    "Operator Learning": 0.75,
    "Optimization": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->

# A Variational Framework for Residual-Based Adaptivity in Neural PDE Solvers and Operator Learning

**Korean Title:** ì‹ ê²½ í¸ë¯¸ë¶„ ë°©ì •ì‹(PDE) í•´ì„ê¸°ì™€ ì—°ì‚°ì í•™ìŠµì—ì„œ ì”ì°¨ ê¸°ë°˜ ì ì‘ì„±ì„ ìœ„í•œ ë³€ë¶„ì  í”„ë ˆì„ì›Œí¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[digests/daily_digest_20250917|2025-09-17]]       [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸŒ Broad Technical**: [[keywords/Optimization|Optimization]]
**âš¡ Unique Technical**: [[keywords/Neural PDE Solvers|Neural PDE Solvers]], [[keywords/Operator Learning|Operator Learning]]

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[Data coarse graining can improve model performance_20250918|Data coarse graining can improve model performance]] (80.3% similar)
- [[Data-Driven Distributed Optimization via Aggregative Tracking and Deep-Learning_20250918|Data-Driven Distributed Optimization via Aggregative Tracking and Deep-Learning]] (80.2% similar)
- [[ActivePusher_ Active Learning and Planning with Residual Physics for Nonprehensile Manipulation_20250919|ActivePusher Active Learning and Planning with Residual Physics for Nonprehensile Manipulation]] (79.8% similar)
- [[Decentralized Optimization with Topology-Independent Communication_20250917|Decentralized Optimization with Topology-Independent Communication]] (79.6% similar)
- [[A Universal Banach--Bregman Framework for Stochastic Iterations_ Unifying Stochastic Mirror Descent, Learning and LLM Training_20250917|A Universal Banach--Bregman Framework for Stochastic Iterations Unifying Stochastic Mirror Descent, Learning and LLM Training]] (79.6% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** Juan Diego Toscano, Daniel T. Chen, Vivek Oommen, George Em Karniadakis

## ğŸ“„ Abstract (ì›ë¬¸)

Residual-based adaptive strategies are widely used in scientific machine
learning but remain largely heuristic. We introduce a unifying variational
framework that formalizes these methods by integrating convex transformations
of the residual. Different transformations correspond to distinct objective
functionals: exponential weights target the minimization of uniform error,
while linear weights recover the minimization of quadratic error. Within this
perspective, adaptive weighting is equivalent to selecting sampling
distributions that optimize the primal objective, thereby linking
discretization choices directly to error metrics. This principled approach
yields three benefits: (1) it enables systematic design of adaptive schemes
across norms, (2) reduces discretization error through variance reduction of
the loss estimator, and (3) enhances learning dynamics by improving the
gradient signal-to-noise ratio. Extending the framework to operator learning,
we demonstrate substantial performance gains across optimizers and
architectures. Our results provide a theoretical justification of
residual-based adaptivity and establish a foundation for principled
discretization and training strategies.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

ì”ì°¨ ê¸°ë°˜ ì ì‘ ì „ëµì€ ê³¼í•™ì  ê¸°ê³„ í•™ìŠµì—ì„œ ë„ë¦¬ ì‚¬ìš©ë˜ì§€ë§Œ, ì—¬ì „íˆ ëŒ€ë¶€ë¶„ì€ ê²½í—˜ì ì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì´ëŸ¬í•œ ë°©ë²•ì„ ì”ì°¨ì˜ ë³¼ë¡ ë³€í™˜ì„ í†µí•©í•˜ì—¬ í˜•ì‹í™”í•˜ëŠ” í†µí•© ë³€ë¶„ í”„ë ˆì„ì›Œí¬ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ì„œë¡œ ë‹¤ë¥¸ ë³€í™˜ì€ ì„œë¡œ ë‹¤ë¥¸ ëª©ì  í•¨ìˆ˜ì— í•´ë‹¹í•©ë‹ˆë‹¤: ì§€ìˆ˜ ê°€ì¤‘ì¹˜ëŠ” ê· ì¼í•œ ì˜¤ë¥˜ ìµœì†Œí™”ë¥¼ ëª©í‘œë¡œ í•˜ê³ , ì„ í˜• ê°€ì¤‘ì¹˜ëŠ” ì´ì°¨ ì˜¤ë¥˜ ìµœì†Œí™”ë¥¼ íšŒë³µí•©ë‹ˆë‹¤. ì´ ê´€ì ì—ì„œ ì ì‘ ê°€ì¤‘í™”ëŠ” ê¸°ë³¸ ëª©ì ì„ ìµœì í™”í•˜ëŠ” ìƒ˜í”Œë§ ë¶„í¬ë¥¼ ì„ íƒí•˜ëŠ” ê²ƒê³¼ ë™ë“±í•˜ë©°, ì´ë¥¼ í†µí•´ ì´ì‚°í™” ì„ íƒì„ ì˜¤ë¥˜ ë©”íŠ¸ë¦­ì— ì§ì ‘ ì—°ê²°í•©ë‹ˆë‹¤. ì´ ì›ì¹™ì ì¸ ì ‘ê·¼ë²•ì€ ì„¸ ê°€ì§€ ì´ì ì„ ì œê³µí•©ë‹ˆë‹¤: (1) ë‹¤ì–‘í•œ ë…¸ë¦„ì— ê±¸ì³ ì ì‘í˜• ìŠ¤í‚´ì˜ ì²´ê³„ì ì¸ ì„¤ê³„ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ê³ , (2) ì†ì‹¤ ì¶”ì •ì¹˜ì˜ ë¶„ì‚° ê°ì†Œë¥¼ í†µí•´ ì´ì‚°í™” ì˜¤ë¥˜ë¥¼ ì¤„ì´ë©°, (3) ê·¸ë˜ë””ì–¸íŠ¸ ì‹ í˜¸ ëŒ€ ì¡ìŒë¹„ë¥¼ ê°œì„ í•˜ì—¬ í•™ìŠµ ì—­í•™ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì—°ì‚°ì í•™ìŠµìœ¼ë¡œ í”„ë ˆì„ì›Œí¬ë¥¼ í™•ì¥í•˜ì—¬, ìš°ë¦¬ëŠ” ìµœì í™”ê¸°ì™€ ì•„í‚¤í…ì²˜ ì „ë°˜ì— ê±¸ì³ ìƒë‹¹í•œ ì„±ëŠ¥ í–¥ìƒì„ ì…ì¦í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ê²°ê³¼ëŠ” ì”ì°¨ ê¸°ë°˜ ì ì‘ì„±ì˜ ì´ë¡ ì  ì •ë‹¹ì„±ì„ ì œê³µí•˜ê³ , ì›ì¹™ì ì¸ ì´ì‚°í™” ë° í›ˆë ¨ ì „ëµì˜ ê¸°ì´ˆë¥¼ í™•ë¦½í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì”ì°¨ ê¸°ë°˜ ì ì‘ ì „ëµì„ í˜•ì‹í™”í•˜ê¸° ìœ„í•´ ë³€ë¶„ í”„ë ˆì„ì›Œí¬ë¥¼ ë„ì…í•˜ì—¬ ê¸°ì¡´ì˜ íœ´ë¦¬ìŠ¤í‹± ë°©ë²•ì„ ì²´ê³„í™”í•©ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ì”ì°¨ì˜ ë³¼ë¡ ë³€í™˜ì„ í†µí•©í•˜ì—¬ ë‹¤ì–‘í•œ ëª©ì  í•¨ìˆ˜ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì ì‘ ê°€ì¤‘ì¹˜ê°€ ê¸°ë³¸ ëª©í‘œë¥¼ ìµœì í™”í•˜ëŠ” ìƒ˜í”Œë§ ë¶„í¬ ì„ íƒê³¼ ë™ë“±í•˜ê²Œ ë˜ì–´, ì´ì‚°í™” ì„ íƒì„ ì˜¤ë¥˜ ë©”íŠ¸ë¦­ê³¼ ì§ì ‘ ì—°ê²°í•©ë‹ˆë‹¤. ì´ ì ‘ê·¼ë²•ì€ (1) ë‹¤ì–‘í•œ ë…¸ë¦„ì—ì„œì˜ ì²´ê³„ì ì¸ ì ì‘ ì„¤ê³„, (2) ì†ì‹¤ ì¶”ì •ì¹˜ì˜ ë¶„ì‚° ê°ì†Œë¥¼ í†µí•œ ì´ì‚°í™” ì˜¤ë¥˜ ê°ì†Œ, (3) ê¸°ìš¸ê¸° ì‹ í˜¸ ëŒ€ ì¡ìŒë¹„ ê°œì„ ì„ í†µí•œ í•™ìŠµ ë™ì—­í•™ í–¥ìƒì„ ì œê³µí•©ë‹ˆë‹¤. ë˜í•œ, ì—°ì‚°ì í•™ìŠµìœ¼ë¡œ í™•ì¥í•˜ì—¬ ìµœì í™”ê¸°ì™€ ì•„í‚¤í…ì²˜ ì „ë°˜ì— ê±¸ì³ ì„±ëŠ¥ í–¥ìƒì„ ì…ì¦í•©ë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ì”ì°¨ ê¸°ë°˜ ì ì‘ì˜ ì´ë¡ ì  ì •ë‹¹ì„±ì„ ì œê³µí•˜ê³ , ì›ì¹™ì ì¸ ì´ì‚°í™” ë° í›ˆë ¨ ì „ëµì˜ ê¸°ì´ˆë¥¼ ë§ˆë ¨í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì”ì°¨ ê¸°ë°˜ ì ì‘ ì „ëµì„ í†µí•©í•˜ëŠ” ë³€ë¶„ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•˜ì—¬ ê¸°ì¡´ì˜ íœ´ë¦¬ìŠ¤í‹± ë°©ë²•ì„ ì²´ê³„í™”í•©ë‹ˆë‹¤.

- 2. ë‹¤ì–‘í•œ ë³€í™˜ì„ í†µí•´ ì„œë¡œ ë‹¤ë¥¸ ëª©í‘œ í•¨ìˆ˜ê°€ ì •ì˜ë˜ë©°, ì´ëŠ” ê· ì¼ ì˜¤ì°¨ì™€ ì´ì°¨ ì˜¤ì°¨ ìµœì†Œí™”ë¥¼ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

- 3. ì ì‘ ê°€ì¤‘ì¹˜ëŠ” ìƒ˜í”Œë§ ë¶„í¬ ì„ íƒê³¼ ë™ì¼ì‹œë˜ë©°, ì´ëŠ” ì´ì‚°í™” ì„ íƒì„ ì˜¤ë¥˜ ë©”íŠ¸ë¦­ê³¼ ì§ì ‘ ì—°ê²°í•©ë‹ˆë‹¤.

- 4. ì œì•ˆëœ ì ‘ê·¼ë²•ì€ ë‹¤ì–‘í•œ ë…¸ë¦„ì— ê±¸ì¹œ ì²´ê³„ì ì¸ ì ì‘ ìŠ¤í‚´ ì„¤ê³„ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ê³ , ì†ì‹¤ ì¶”ì •ê¸°ì˜ ë¶„ì‚° ê°ì†Œë¥¼ í†µí•´ ì´ì‚°í™” ì˜¤ë¥˜ë¥¼ ì¤„ì…ë‹ˆë‹¤.

- 5. í”„ë ˆì„ì›Œí¬ë¥¼ ì—°ì‚°ì í•™ìŠµìœ¼ë¡œ í™•ì¥í•˜ì—¬ ìµœì í™”ê¸°ì™€ ì•„í‚¤í…ì²˜ ì „ë°˜ì— ê±¸ì³ ì„±ëŠ¥ í–¥ìƒì„ ì…ì¦í•©ë‹ˆë‹¤.

---

*Generated on 2025-09-20 07:43:31*