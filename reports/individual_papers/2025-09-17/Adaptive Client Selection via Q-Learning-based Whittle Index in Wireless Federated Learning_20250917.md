# Adaptive Client Selection via Q-Learning-based Whittle Index in Wireless Federated Learning

**Korean Title:** λ¬΄μ„  μ—°ν•© ν•™μµμ—μ„ Q-λ¬λ‹ κΈ°λ° Whittle μ§€μλ¥Ό ν†µν• μ μ‘ν• ν΄λΌμ΄μ–ΈνΈ μ„ νƒ

## π“‹ λ©”νƒ€λ°μ΄ν„°

**Links**: [[daily/2025-09-17|2025-09-17]] [[authors/Qiyue Li|Qiyue Li]] [[authors/Yingxin Liu|Yingxin Liu]] [[authors/Hang Qi|Hang Qi]] [[authors/Jieping Luo|Jieping Luo]] [[authors/Zhizhang Liu|Zhizhang Liu]] [[categories/cs.AI|cs.AI]]

## π·οΈ μΉ΄ν…κ³ λ¦¬ν™”λ ν‚¤μ›λ“
**π”— Specific Connectable**: Restless Multi-armed Bandit

## π”— μ μ‚¬ν• λ…Όλ¬Έ
- [[Who to Trust Aggregating Client Knowledge in Logit-Based Federated Learning_20250919|Who to Trust Aggregating Client Knowledge in Logit-Based Federated Learning]] (80.8% similar)
- [[FedAVOT_ Exact Distribution Alignment in Federated Learning via Masked Optimal Transport_20250919|FedAVOT Exact Distribution Alignment in Federated Learning via Masked Optimal Transport]] (78.7% similar)
- [[Adaptive LoRA Experts Allocation and Selection for Federated Fine-Tuning_20250918|Adaptive LoRA Experts Allocation and Selection for Federated Fine-Tuning]] (77.7% similar)
- [[Multi-Fidelity Hybrid Reinforcement Learning via Information Gain Maximization_20250919|Multi-Fidelity Hybrid Reinforcement Learning via Information Gain Maximization]] (77.5% similar)
- [[Hierarchical Federated Learning for Social Network with Mobility_20250919|Hierarchical Federated Learning for Social Network with Mobility]] (77.4% similar)

## π“‹ μ €μ μ •λ³΄

**Authors:** Qiyue Li, Yingxin Liu, Hang Qi, Jieping Luo, Zhizhang Liu, Jingjin Wu

## π“„ Abstract (μ›λ¬Έ)

We consider the client selection problem in wireless Federated Learning (FL),
with the objective of reducing the total required time to achieve a certain
level of learning accuracy. Since the server cannot observe the clients'
dynamic states that can change their computation and communication efficiency,
we formulate client selection as a restless multi-armed bandit problem. We
propose a scalable and efficient approach called the Whittle Index Learning in
Federated Q-learning (WILF-Q), which uses Q-learning to adaptively learn and
update an approximated Whittle index associated with each client, and then
selects the clients with the highest indices. Compared to existing approaches,
WILF-Q does not require explicit knowledge of client state transitions or data
distributions, making it well-suited for deployment in practical FL settings.
Experiment results demonstrate that WILF-Q significantly outperforms existing
baseline policies in terms of learning efficiency, providing a robust and
efficient approach to client selection in wireless FL.

## π” Abstract (ν•κΈ€ λ²μ—­)

λ¬΄μ„  μ—°ν•© ν•™μµ(FL)μ—μ„ ν΄λΌμ΄μ–ΈνΈ μ„ νƒ λ¬Έμ λ¥Ό κ³ λ ¤ν•λ©°, νΉμ • ν•™μµ μ •ν™•λ„ μμ¤€μ„ λ‹¬μ„±ν•κΈ° μ„ν• μ΄ μ†μ” μ‹κ°„μ„ μ¤„μ΄λ” κ²ƒμ„ λ©ν‘λ΅ ν•©λ‹λ‹¤. μ„λ²„λ” ν΄λΌμ΄μ–ΈνΈμ κ³„μ‚° λ° ν†µμ‹  ν¨μ¨μ„±μ„ λ³€ν™”μ‹ν‚¬ μ μλ” λ™μ  μƒνƒλ¥Ό κ΄€μ°°ν•  μ μ—†κΈ° λ•λ¬Έμ—, μ°λ¦¬λ” ν΄λΌμ΄μ–ΈνΈ μ„ νƒμ„ ν΄μ‹ μ—†λ” λ‹¤μ¤‘ μ¬λ΅― λ°΄λ””νΈ λ¬Έμ λ΅ κ³µμ‹ν™”ν•©λ‹λ‹¤. μ°λ¦¬λ” μ—°ν•© Q-ν•™μµμ—μ„ νν‹€ μ§€μ ν•™μµ(WILF-Q)μ΄λΌλ” ν™•μ¥ κ°€λ¥ν•κ³  ν¨μ¨μ μΈ μ ‘κ·Ό λ°©μ‹μ„ μ μ•ν•©λ‹λ‹¤. μ΄ λ°©λ²•μ€ Q-ν•™μµμ„ μ‚¬μ©ν•μ—¬ κ° ν΄λΌμ΄μ–ΈνΈμ™€ κ΄€λ ¨λ κ·Όμ‚¬ νν‹€ μ§€μλ¥Ό μ μ‘μ μΌλ΅ ν•™μµν•κ³  μ—…λ°μ΄νΈν•λ©°, κ°€μ¥ λ†’μ€ μ§€μλ¥Ό κ°€μ§„ ν΄λΌμ΄μ–ΈνΈλ¥Ό μ„ νƒν•©λ‹λ‹¤. κΈ°μ΅΄ μ ‘κ·Ό λ°©μ‹κ³Ό λΉ„κµν•μ—¬, WILF-Qλ” ν΄λΌμ΄μ–ΈνΈ μƒνƒ μ „μ΄ λλ” λ°μ΄ν„° λ¶„ν¬μ— λ€ν• λ…μ‹μ  μ§€μ‹μ΄ ν•„μ”ν•μ§€ μ•μ•„ μ‹¤μ  FL ν™κ²½μ— λ°°ν¬ν•κΈ°μ— μ ν•©ν•©λ‹λ‹¤. μ‹¤ν— κ²°κ³Όλ” WILF-Qκ°€ ν•™μµ ν¨μ¨μ„± μΈ΅λ©΄μ—μ„ κΈ°μ΅΄μ κΈ°μ¤€ μ •μ±…μ„ ν¬κ² λ¥κ°€ν•λ©°, λ¬΄μ„  FLμ—μ„ ν΄λΌμ΄μ–ΈνΈ μ„ νƒμ— μμ–΄ κ°•λ ¥ν•κ³  ν¨μ¨μ μΈ μ ‘κ·Ό λ°©μ‹μ„ μ κ³µν•¨μ„ λ³΄μ—¬μ¤λ‹λ‹¤.

## π“ μ”μ•½

μ΄ λ…Όλ¬Έμ€ λ¬΄μ„  μ—°ν•© ν•™μµ(FL)μ—μ„ ν΄λΌμ΄μ–ΈνΈ μ„ νƒ λ¬Έμ λ¥Ό λ‹¤λ£¨λ©°, λ©ν‘λ” νΉμ • ν•™μµ μ •ν™•λ„μ— λ„λ‹¬ν•λ” λ° ν•„μ”ν• μ΄ μ‹κ°„μ„ μ¤„μ΄λ” κ²ƒμ…λ‹λ‹¤. μ„λ²„κ°€ ν΄λΌμ΄μ–ΈνΈμ λ™μ  μƒνƒλ¥Ό κ΄€μ°°ν•  μ μ—†κΈ° λ•λ¬Έμ—, ν΄λΌμ΄μ–ΈνΈ μ„ νƒ λ¬Έμ λ¥Ό μ§€μ†μ  λ©€ν‹°μ•”λ“ λ°΄λ”§ λ¬Έμ λ΅ κ³µμ‹ν™”ν–μµλ‹λ‹¤. μ΄λ¥Ό ν•΄κ²°ν•κΈ° μ„ν•΄ μ μ•λ WILF-Q(Whittle Index Learning in Federated Q-learning)λ” Q-λ¬λ‹μ„ μ‚¬μ©ν•μ—¬ κ° ν΄λΌμ΄μ–ΈνΈμ™€ κ΄€λ ¨λ Whittle μ§€μλ¥Ό μ μ‘μ μΌλ΅ ν•™μµν•κ³  μ—…λ°μ΄νΈν•λ©°, κ°€μ¥ λ†’μ€ μ§€μλ¥Ό κ°€μ§„ ν΄λΌμ΄μ–ΈνΈλ¥Ό μ„ νƒν•©λ‹λ‹¤. WILF-Qλ” ν΄λΌμ΄μ–ΈνΈ μƒνƒ μ „μ΄λ‚ λ°μ΄ν„° λ¶„ν¬μ— λ€ν• λ…μ‹μ  μ§€μ‹μ΄ ν•„μ”ν•μ§€ μ•μ•„ μ‹¤μ  FL ν™κ²½μ— μ ν•©ν•©λ‹λ‹¤. μ‹¤ν— κ²°κ³Ό, WILF-Qλ” κΈ°μ΅΄μ κΈ°μ¤€ μ •μ±…λ“¤λ³΄λ‹¤ ν•™μµ ν¨μ¨μ„± λ©΄μ—μ„ λ›°μ–΄λ‚ μ„±λ¥μ„ λ³΄μ€μµλ‹λ‹¤.

## π― μ£Όμ” ν¬μΈνΈ

- 1. λ¬΄μ„  μ—°ν•© ν•™μµ(FL)μ—μ„ ν΄λΌμ΄μ–ΈνΈ μ„ νƒ λ¬Έμ λ¥Ό ν•™μµ μ •ν™•λ„λ¥Ό μΌμ • μμ¤€μΌλ΅ λ‹¬μ„±ν•λ” λ° ν•„μ”ν• μ΄ μ‹κ°„μ„ μ¤„μ΄λ” λ©ν‘λ΅ κ³ λ ¤ν•©λ‹λ‹¤.

- 2. ν΄λΌμ΄μ–ΈνΈμ λ™μ  μƒνƒλ¥Ό μ„λ²„κ°€ κ΄€μ°°ν•  μ μ—†κΈ° λ•λ¬Έμ— ν΄λΌμ΄μ–ΈνΈ μ„ νƒ λ¬Έμ λ¥Ό λ¬΄μ •μ§€ λ‹¤μ¤‘ μ¬λ΅― λ°΄λ”§ λ¬Έμ λ΅ κ³µμ‹ν™”ν•©λ‹λ‹¤.

- 3. WILF-Qλ” Q-λ¬λ‹μ„ μ‚¬μ©ν•μ—¬ κ° ν΄λΌμ΄μ–ΈνΈμ™€ κ΄€λ ¨λ κ·Όμ‚¬ Whittle μ§€μλ¥Ό μ μ‘μ μΌλ΅ ν•™μµν•κ³  μ—…λ°μ΄νΈν•μ—¬ κ°€μ¥ λ†’μ€ μ§€μλ¥Ό κ°€μ§„ ν΄λΌμ΄μ–ΈνΈλ¥Ό μ„ νƒν•©λ‹λ‹¤.

- 4. WILF-Qλ” ν΄λΌμ΄μ–ΈνΈ μƒνƒ μ „μ΄ λλ” λ°μ΄ν„° λ¶„ν¬μ— λ€ν• λ…μ‹μ  μ§€μ‹μ΄ ν•„μ”ν•μ§€ μ•μ•„ μ‹¤μ  FL ν™κ²½μ— μ ν•©ν•©λ‹λ‹¤.

- 5. μ‹¤ν— κ²°κ³Ό WILF-Qλ” ν•™μµ ν¨μ¨μ„± μΈ΅λ©΄μ—μ„ κΈ°μ΅΄μ κΈ°μ¤€ μ •μ±…μ„ ν¬κ² λ¥κ°€ν•μ—¬ λ¬΄μ„  FLμ—μ„ ν΄λΌμ΄μ–ΈνΈ μ„ νƒμ— λ€ν• κ²¬κ³ ν•κ³  ν¨μ¨μ μΈ μ ‘κ·Ό λ°©μ‹μ„ μ κ³µν•©λ‹λ‹¤.

---

*Generated on 2025-09-20 09:23:12*