# Reasoning Efficiently Through Adaptive Chain-of-Thought Compression: A Self-Optimizing Framework

**Korean Title:** ì ì‘í˜• ì‚¬ê³  ê³¼ì • ì••ì¶•ì„ í†µí•œ íš¨ìœ¨ì ì¸ ì¶”ë¡ : ìê¸° ìµœì í™” í”„ë ˆì„ì›Œí¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-17|2025-09-17]] [[authors/Kerui Huang|Kerui Huang]] [[authors/Shuhan Liu|Shuhan Liu]] [[authors/Xing Hu|Xing Hu]] [[authors/Tongtong Xu|Tongtong Xu]] [[authors/Lingfeng Bao|Lingfeng Bao]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Adaptive Chain-of-Thought Compression

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[Early Stopping Chain-of-thoughts in Large Language Models_20250918|Early Stopping Chain-of-thoughts in Large Language Models]] (89.4% similar)
- [[ASCoT_ An Adaptive Self-Correction Chain-of-Thought Method for Late-Stage Fragility in LLMs_20250919|ASCoT An Adaptive Self-Correction Chain-of-Thought Method for Late-Stage Fragility in LLMs]] (86.0% similar)
- [[Uni-cot_ Towards Unified Chain-of-Thought Reasoning Across Text and Vision_20250918|Uni-cot Towards Unified Chain-of-Thought Reasoning Across Text and Vision]] (84.2% similar)
- [[Do Code Semantics Help A Comprehensive Study on Execution Trace-Based Information for Code Large Language Models_20250919|Do Code Semantics Help A Comprehensive Study on Execution Trace-Based Information for Code Large Language Models]] (81.7% similar)
- [[WebCoT_ Enhancing Web Agent Reasoning by Reconstructing Chain-of-Thought in Reflection, Branching, and Rollback_20250919|WebCoT Enhancing Web Agent Reasoning by Reconstructing Chain-of-Thought in Reflection, Branching, and Rollback]] (81.5% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** Kerui Huang, Shuhan Liu, Xing Hu, Tongtong Xu, Lingfeng Bao, Xin Xia

## ğŸ“„ Abstract (ì›ë¬¸)

Chain-of-Thought (CoT) reasoning enhances Large Language Models (LLMs) by
prompting intermediate steps, improving accuracy and robustness in arithmetic,
logic, and commonsense tasks. However, this benefit comes with high
computational costs: longer outputs increase latency, memory usage, and
KV-cache demands. These issues are especially critical in software engineering
tasks where concise and deterministic outputs are required. To investigate
these trade-offs, we conduct an empirical study based on code generation
benchmarks. The results reveal that longer CoT does not always help. Excessive
reasoning often causes truncation, accuracy drops, and latency up to five times
higher, with failed outputs consistently longer than successful ones. These
findings challenge the assumption that longer reasoning is inherently better
and highlight the need for adaptive CoT control. Motivated by this, we propose
SEER (Self-Enhancing Efficient Reasoning), an adaptive framework that
compresses CoT while preserving accuracy. SEER combines Best-of-N sampling with
task-aware adaptive filtering, dynamically adjusting thresholds based on
pre-inference outputs to reduce verbosity and computational overhead. We then
evaluate SEER on three software engineering tasks and one math task. On
average, SEER shortens CoT by 42.1%, improves accuracy by reducing truncation,
and eliminates most infinite loops. These results demonstrate SEER as a
practical method to make CoT-enhanced LLMs more efficient and robust, even
under resource constraints.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

ì—°ì‡„ ì‚¬ê³ (Chain-of-Thought, CoT) ì¶”ë¡ ì€ ì¤‘ê°„ ë‹¨ê³„ë¥¼ ìœ ë„í•˜ì—¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì‚°ìˆ , ë…¼ë¦¬, ìƒì‹ ì‘ì—…ì—ì„œ ì •í™•ì„±ê³¼ ê²¬ê³ ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ëŸ¬í•œ ì´ì ì€ ë†’ì€ ê³„ì‚° ë¹„ìš©ì„ ìˆ˜ë°˜í•©ë‹ˆë‹¤. ì¶œë ¥ì´ ê¸¸ì–´ì§€ë©´ ì§€ì—° ì‹œê°„, ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰, KV-ìºì‹œ ìš”êµ¬ëŸ‰ì´ ì¦ê°€í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ë¬¸ì œëŠ” ê°„ê²°í•˜ê³  ê²°ì •ë¡ ì ì¸ ì¶œë ¥ì´ í•„ìš”í•œ ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´ë§ ì‘ì—…ì—ì„œ íŠ¹íˆ ì¤‘ìš”í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ìƒì¶© ê´€ê³„ë¥¼ ì¡°ì‚¬í•˜ê¸° ìœ„í•´ ì½”ë“œ ìƒì„± ë²¤ì¹˜ë§ˆí¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹¤ì¦ ì—°êµ¬ë¥¼ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. ê²°ê³¼ëŠ” ë” ê¸´ CoTê°€ í•­ìƒ ë„ì›€ì´ ë˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ê³¼ë„í•œ ì¶”ë¡ ì€ ì¢…ì¢… ì˜ë¦¼, ì •í™•ë„ ì €í•˜, ìµœëŒ€ 5ë°° ë†’ì€ ì§€ì—° ì‹œê°„ì„ ì´ˆë˜í•˜ë©°, ì‹¤íŒ¨í•œ ì¶œë ¥ì€ ì„±ê³µí•œ ì¶œë ¥ë³´ë‹¤ ì¼ê´€ë˜ê²Œ ë” ê¹ë‹ˆë‹¤. ì´ëŸ¬í•œ ë°œê²¬ì€ ë” ê¸´ ì¶”ë¡ ì´ ë³¸ì§ˆì ìœ¼ë¡œ ë” ë‚«ë‹¤ëŠ” ê°€ì •ì„ ë„ì „í•˜ë©° ì ì‘í˜• CoT ì œì–´ì˜ í•„ìš”ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤. ì´ì— ì˜ê°ì„ ë°›ì•„, ìš°ë¦¬ëŠ” ì •í™•ì„±ì„ ìœ ì§€í•˜ë©´ì„œ CoTë¥¼ ì••ì¶•í•˜ëŠ” ì ì‘í˜• í”„ë ˆì„ì›Œí¬ì¸ SEER(Self-Enhancing Efficient Reasoning)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. SEERëŠ” Best-of-N ìƒ˜í”Œë§ê³¼ ì‘ì—… ì¸ì‹ ì ì‘í˜• í•„í„°ë§ì„ ê²°í•©í•˜ì—¬ ì‚¬ì „ ì¶”ë¡  ì¶œë ¥ì— ê¸°ë°˜í•œ ì„ê³„ê°’ì„ ë™ì ìœ¼ë¡œ ì¡°ì •í•˜ì—¬ ì¥í™©í•¨ê³¼ ê³„ì‚° ì˜¤ë²„í—¤ë“œë¥¼ ì¤„ì…ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ SEERë¥¼ ì„¸ ê°€ì§€ ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´ë§ ì‘ì—…ê³¼ í•˜ë‚˜ì˜ ìˆ˜í•™ ì‘ì—…ì— ëŒ€í•´ í‰ê°€í•©ë‹ˆë‹¤. í‰ê· ì ìœ¼ë¡œ SEERëŠ” CoTë¥¼ 42.1% ë‹¨ì¶•í•˜ê³ , ì˜ë¦¼ì„ ì¤„ì—¬ ì •í™•ì„±ì„ ê°œì„ í•˜ë©°, ëŒ€ë¶€ë¶„ì˜ ë¬´í•œ ë£¨í”„ë¥¼ ì œê±°í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ê²°ê³¼ëŠ” SEERê°€ ìì› ì œì•½ í•˜ì—ì„œë„ CoTë¡œ ê°•í™”ëœ LLMì„ ë³´ë‹¤ íš¨ìœ¨ì ì´ê³  ê²¬ê³ í•˜ê²Œ ë§Œë“œëŠ” ì‹¤ìš©ì ì¸ ë°©ë²•ì„ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

Chain-of-Thought (CoT) ì¶”ë¡ ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì˜ ì¤‘ê°„ ë‹¨ê³„ ìœ ë„ë¥¼ í†µí•´ ì‚°ìˆ , ë…¼ë¦¬, ìƒì‹ ì‘ì—…ì˜ ì •í™•ì„±ê³¼ ê²¬ê³ ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ëŠ” ì¶œë ¥ ê¸¸ì´ ì¦ê°€ë¡œ ì¸í•œ ë†’ì€ ê³„ì‚° ë¹„ìš©ì„ ìˆ˜ë°˜í•©ë‹ˆë‹¤. ë³¸ ì—°êµ¬ëŠ” ì½”ë“œ ìƒì„± ë²¤ì¹˜ë§ˆí¬ë¥¼ í†µí•´ ì´ëŸ¬í•œ ë¹„ìš©ê³¼ ì´ì ì˜ ê· í˜•ì„ ì¡°ì‚¬í•˜ì˜€ìœ¼ë©°, ê¸´ CoTê°€ í•­ìƒ ìœ ë¦¬í•˜ì§€ ì•ŠìŒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ê³¼ë„í•œ ì¶”ë¡ ì€ ì¶œë ¥ì´ ì˜ë¦¬ê±°ë‚˜ ì •í™•ë„ê°€ ë–¨ì–´ì§€ë©°, ì§€ì—° ì‹œê°„ì´ ìµœëŒ€ 5ë°° ì¦ê°€í•˜ëŠ” ë¬¸ì œë¥¼ ì´ˆë˜í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ SEER(Self-Enhancing Efficient Reasoning)ë¼ëŠ” ì ì‘í˜• í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•˜ì˜€ìœ¼ë©°, ì´ëŠ” CoTë¥¼ ì••ì¶•í•˜ë©´ì„œë„ ì •í™•ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤. SEERëŠ” Best-of-N ìƒ˜í”Œë§ê³¼ ì‘ì—… ì¸ì‹ ì ì‘í˜• í•„í„°ë§ì„ ê²°í•©í•˜ì—¬ ë¶ˆí•„ìš”í•œ ì¥í™©í•¨ê³¼ ê³„ì‚° ë¶€ë‹´ì„ ì¤„ì…ë‹ˆë‹¤. ì„¸ ê°€ì§€ ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´ë§ ì‘ì—…ê³¼ í•˜ë‚˜ì˜ ìˆ˜í•™ ì‘ì—…ì— ëŒ€í•œ í‰ê°€ ê²°ê³¼, SEERëŠ” CoT ê¸¸ì´ë¥¼ í‰ê·  42.1% ë‹¨ì¶•í•˜ê³  ì •í™•ì„±ì„ í–¥ìƒì‹œì¼œ ë¬´í•œ ë£¨í”„ë¥¼ ëŒ€ë¶€ë¶„ ì œê±°í–ˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ SEERëŠ” ìì› ì œì•½ í•˜ì—ì„œë„ CoT ê°•í™” LLMì„ ë” íš¨ìœ¨ì ì´ê³  ê²¬ê³ í•˜ê²Œ ë§Œë“œëŠ” ì‹¤ìš©ì ì¸ ë°©ë²•ì„ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Chain-of-Thought (CoT) ì¶”ë¡ ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì •í™•ì„±ê³¼ ê²¬ê³ ì„±ì„ í–¥ìƒì‹œí‚¤ì§€ë§Œ, ë†’ì€ ê³„ì‚° ë¹„ìš©ì„ ì´ˆë˜í•©ë‹ˆë‹¤.

- 2. CoTì˜ ì¥í™©í•œ ì¶œë ¥ì€ ì§€ì—°, ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€, KV-ìºì‹œ ìš”êµ¬ ì¦ê°€ë¥¼ ì•¼ê¸°í•˜ë©°, íŠ¹íˆ ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´ë§ ì‘ì—…ì—ì„œ ë¬¸ì œê°€ ë©ë‹ˆë‹¤.

- 3. ì—°êµ¬ ê²°ê³¼, CoTì˜ ê¸¸ì´ê°€ í•­ìƒ ë„ì›€ì´ ë˜ëŠ” ê²ƒì€ ì•„ë‹ˆë©°, ê³¼ë„í•œ ì¶”ë¡ ì€ ì •í™•ë„ ì €í•˜ì™€ ì§€ì—°ì„ ì´ˆë˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- 4. SEER(Self-Enhancing Efficient Reasoning)ëŠ” CoTë¥¼ ì••ì¶•í•˜ì—¬ ì •í™•ì„±ì„ ìœ ì§€í•˜ë©´ì„œ ê³„ì‚° ë¹„ìš©ì„ ì¤„ì´ëŠ” ì ì‘í˜• í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.

- 5. SEERëŠ” CoT ê¸¸ì´ë¥¼ í‰ê·  42.1% ë‹¨ì¶•í•˜ê³ , ì •í™•ì„±ì„ ê°œì„ í•˜ë©°, ëŒ€ë¶€ë¶„ì˜ ë¬´í•œ ë£¨í”„ë¥¼ ì œê±°í•˜ì—¬ CoT-ê°•í™” LLMì˜ íš¨ìœ¨ì„±ê³¼ ê²¬ê³ ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

---

*Generated on 2025-09-20 07:48:04*