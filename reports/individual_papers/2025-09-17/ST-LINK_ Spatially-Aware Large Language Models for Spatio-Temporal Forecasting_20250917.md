---
keywords:
  - Large Language Models
  - Attention Mechanism
  - Graph Neural Networks
category: cs.AI
publish_date: 2025-09-17
arxiv_id:
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 22:46:12.638844",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Models",
    "Attention Mechanism",
    "Graph Neural Networks"
  ],
  "rejected_keywords": [
    "Spatially-Enhanced Attention",
    "Spatio-Temporal Forecasting"
  ],
  "similarity_scores": {
    "Large Language Models": 0.78,
    "Attention Mechanism": 0.77,
    "Graph Neural Networks": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->

# ST-LINK: Spatially-Aware Large Language Models for Spatio-Temporal Forecasting

**Korean Title:** ST-LINK: ì‹œê³µê°„ ì˜ˆì¸¡ì„ ìœ„í•œ ê³µê°„ ì¸ì‹ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[digests/daily_digest_20250917|2025-09-17]]       [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Attention Mechanism|Attention Mechanism]], [[keywords/Graph Neural Networks|Graph-Structured Spatial Data]]
**ğŸš€ Evolved Concepts**: [[keywords/Large Language Models|Large Language Models]]

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[Improving Internet Traffic Matrix Prediction via Time Series Clustering_20250919|Improving Internet Traffic Matrix Prediction via Time Series Clustering]] (82.3% similar)
- [[Unleashing the Potential of Multimodal LLMs for Zero-Shot Spatio-Temporal Video Grounding_20250919|Unleashing the Potential of Multimodal LLMs for Zero-Shot Spatio-Temporal Video Grounding]] (82.1% similar)
- [[Traffic Co-Simulation Framework Empowered by Infrastructure Camera Sensing and Reinforcement Learning_20250919|Traffic Co-Simulation Framework Empowered by Infrastructure Camera Sensing and Reinforcement Learning]] (82.0% similar)
- [[LLM-I_ LLMs are Naturally Interleaved Multimodal Creators_20250918|LLM-I LLMs are Naturally Interleaved Multimodal Creators]] (80.2% similar)
- [[CARGO_ A Framework for Confidence-Aware Routing of Large Language Models_20250918|CARGO A Framework for Confidence-Aware Routing of Large Language Models]] (80.1% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** Hyotaek Jeon, Hyunwook Lee, Juwon Kim, Sungahn Ko

## ğŸ“„ Abstract (ì›ë¬¸)

Traffic forecasting represents a crucial problem within intelligent
transportation systems. In recent research, Large Language Models (LLMs) have
emerged as a promising method, but their intrinsic design, tailored primarily
for sequential token processing, introduces notable challenges in effectively
capturing spatial dependencies. Specifically, the inherent limitations of LLMs
in modeling spatial relationships and their architectural incompatibility with
graph-structured spatial data remain largely unaddressed. To overcome these
limitations, we introduce ST-LINK, a novel framework that enhances the
capability of Large Language Models to capture spatio-temporal dependencies.
Its key components are Spatially-Enhanced Attention (SE-Attention) and the
Memory Retrieval Feed-Forward Network (MRFFN). SE-Attention extends rotary
position embeddings to integrate spatial correlations as direct rotational
transformations within the attention mechanism. This approach maximizes spatial
learning while preserving the LLM's inherent sequential processing structure.
Meanwhile, MRFFN dynamically retrieves and utilizes key historical patterns to
capture complex temporal dependencies and improve the stability of long-term
forecasting. Comprehensive experiments on benchmark datasets demonstrate that
ST-LINK surpasses conventional deep learning and LLM approaches, and
effectively captures both regular traffic patterns and abrupt changes.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

êµí†µ ì˜ˆì¸¡ì€ ì§€ëŠ¥í˜• êµí†µ ì‹œìŠ¤í…œì—ì„œ ì¤‘ìš”í•œ ë¬¸ì œë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ìµœê·¼ ì—°êµ¬ì—ì„œëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì´ ìœ ë§í•œ ë°©ë²•ìœ¼ë¡œ ë¶€ìƒí–ˆì§€ë§Œ, ì£¼ë¡œ ìˆœì°¨ì ì¸ í† í° ì²˜ë¦¬ì— ë§ì¶°ì§„ ì´ë“¤ì˜ ë³¸ì§ˆì ì¸ ì„¤ê³„ëŠ” ê³µê°„ì  ì¢…ì†ì„±ì„ íš¨ê³¼ì ìœ¼ë¡œ í¬ì°©í•˜ëŠ” ë° ìˆì–´ ìƒë‹¹í•œ ë„ì „ì„ ì œê¸°í•©ë‹ˆë‹¤. êµ¬ì²´ì ìœ¼ë¡œ, LLMì˜ ê³µê°„ì  ê´€ê³„ë¥¼ ëª¨ë¸ë§í•˜ëŠ” ë° ìˆì–´ì„œì˜ ë‚´ì¬ì  í•œê³„ì™€ ê·¸ë˜í”„ êµ¬ì¡°ì˜ ê³µê°„ ë°ì´í„°ë¥¼ ë‹¤ë£¨ëŠ” ë° ìˆì–´ì„œì˜ êµ¬ì¡°ì  ë¹„í˜¸í™˜ì„±ì€ ëŒ€ë¶€ë¶„ í•´ê²°ë˜ì§€ ì•Šì€ ìƒíƒœë¡œ ë‚¨ì•„ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ ì‹œê³µê°„ì  ì¢…ì†ì„± í¬ì°© ëŠ¥ë ¥ì„ ê°•í™”í•˜ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ì¸ ST-LINKë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ST-LINKì˜ ì£¼ìš” êµ¬ì„± ìš”ì†ŒëŠ” ê³µê°„ ê°•í™” ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜(SE-Attention)ê³¼ ë©”ëª¨ë¦¬ ê²€ìƒ‰ í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬(MRFFN)ì…ë‹ˆë‹¤. SE-Attentionì€ íšŒì „ ìœ„ì¹˜ ì„ë² ë”©ì„ í™•ì¥í•˜ì—¬ ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ ë‚´ì—ì„œ ê³µê°„ ìƒê´€ê´€ê³„ë¥¼ ì§ì ‘ì ì¸ íšŒì „ ë³€í™˜ìœ¼ë¡œ í†µí•©í•©ë‹ˆë‹¤. ì´ ì ‘ê·¼ ë°©ì‹ì€ LLMì˜ ê³ ìœ í•œ ìˆœì°¨ ì²˜ë¦¬ êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ë©´ì„œ ê³µê°„ í•™ìŠµì„ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤. í•œí¸, MRFFNì€ ì£¼ìš” ì—­ì‚¬ì  íŒ¨í„´ì„ ë™ì ìœ¼ë¡œ ê²€ìƒ‰í•˜ê³  í™œìš©í•˜ì—¬ ë³µì¡í•œ ì‹œê°„ì  ì¢…ì†ì„±ì„ í¬ì°©í•˜ê³  ì¥ê¸° ì˜ˆì¸¡ì˜ ì•ˆì •ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì— ëŒ€í•œ ì¢…í•©ì ì¸ ì‹¤í—˜ ê²°ê³¼, ST-LINKëŠ” ê¸°ì¡´ì˜ ë”¥ëŸ¬ë‹ ë° LLM ì ‘ê·¼ ë°©ì‹ì„ ëŠ¥ê°€í•˜ë©°, ê·œì¹™ì ì¸ êµí†µ íŒ¨í„´ê³¼ ê¸‰ê²©í•œ ë³€í™”ë¥¼ ëª¨ë‘ íš¨ê³¼ì ìœ¼ë¡œ í¬ì°©í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

êµí†µ ì˜ˆì¸¡ì€ ì§€ëŠ¥í˜• êµí†µ ì‹œìŠ¤í…œì—ì„œ ì¤‘ìš”í•œ ë¬¸ì œì…ë‹ˆë‹¤. ìµœê·¼ ì—°êµ¬ì—ì„œëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì´ ìœ ë§í•œ ë°©ë²•ìœ¼ë¡œ ë– ì˜¬ëì§€ë§Œ, ì£¼ë¡œ ìˆœì°¨ì  í† í° ì²˜ë¦¬ì— ë§ì¶°ì§„ ì„¤ê³„ë¡œ ì¸í•´ ê³µê°„ì  ì˜ì¡´ì„±ì„ íš¨ê³¼ì ìœ¼ë¡œ í¬ì°©í•˜ëŠ” ë° ì–´ë ¤ì›€ì´ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ST-LINKë¼ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ST-LINKëŠ” ê³µê°„-ì‹œê°„ ì˜ì¡´ì„±ì„ í¬ì°©í•˜ê¸° ìœ„í•´ ê³µê°„ ê°•í™” ì£¼ì˜(SE-Attention)ì™€ ë©”ëª¨ë¦¬ ê²€ìƒ‰ í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬(MRFFN)ë¥¼ ë„ì…í•©ë‹ˆë‹¤. SE-Attentionì€ íšŒì „ ìœ„ì¹˜ ì„ë² ë”©ì„ í™•ì¥í•˜ì—¬ ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ ë‚´ì—ì„œ ê³µê°„ ìƒê´€ê´€ê³„ë¥¼ ì§ì ‘ íšŒì „ ë³€í™˜ìœ¼ë¡œ í†µí•©í•©ë‹ˆë‹¤. MRFFNì€ ì£¼ìš” ì—­ì‚¬ì  íŒ¨í„´ì„ ë™ì ìœ¼ë¡œ ê²€ìƒ‰í•˜ì—¬ ë³µì¡í•œ ì‹œê°„ì  ì˜ì¡´ì„±ì„ í¬ì°©í•˜ê³  ì¥ê¸° ì˜ˆì¸¡ì˜ ì•ˆì •ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì— ëŒ€í•œ ì‹¤í—˜ ê²°ê³¼, ST-LINKëŠ” ê¸°ì¡´ì˜ ì‹¬ì¸µ í•™ìŠµ ë° LLM ì ‘ê·¼ ë°©ì‹ì„ ëŠ¥ê°€í•˜ë©°, ê·œì¹™ì ì¸ êµí†µ íŒ¨í„´ê³¼ ê¸‰ê²©í•œ ë³€í™”ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í¬ì°©í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. LLMsëŠ” ìˆœì°¨ì  í† í° ì²˜ë¦¬ì— ìµœì í™”ë˜ì–´ ìˆì–´ ê³µê°„ì  ì˜ì¡´ì„±ì„ íš¨ê³¼ì ìœ¼ë¡œ í¬ì°©í•˜ëŠ” ë° ì–´ë ¤ì›€ì´ ìˆë‹¤.

- 2. ST-LINKëŠ” LLMì˜ ì‹œê³µê°„ ì˜ì¡´ì„± í¬ì°© ëŠ¥ë ¥ì„ ê°•í™”í•˜ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¡œ, SE-Attentionê³¼ MRFFNì„ í•µì‹¬ êµ¬ì„± ìš”ì†Œë¡œ í•œë‹¤.

- 3. SE-Attentionì€ íšŒì „ ìœ„ì¹˜ ì„ë² ë”©ì„ í™•ì¥í•˜ì—¬ ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ ë‚´ì—ì„œ ê³µê°„ ìƒê´€ê´€ê³„ë¥¼ ì§ì ‘ íšŒì „ ë³€í™˜ìœ¼ë¡œ í†µí•©í•œë‹¤.

- 4. MRFFNì€ ì£¼ìš” ì—­ì‚¬ì  íŒ¨í„´ì„ ë™ì ìœ¼ë¡œ ê²€ìƒ‰ ë° í™œìš©í•˜ì—¬ ë³µì¡í•œ ì‹œê°„ì  ì˜ì¡´ì„±ì„ í¬ì°©í•˜ê³  ì¥ê¸° ì˜ˆì¸¡ì˜ ì•ˆì •ì„±ì„ í–¥ìƒì‹œí‚¨ë‹¤.

- 5. ST-LINKëŠ” ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì—ì„œ ê¸°ì¡´ì˜ ë”¥ëŸ¬ë‹ ë° LLM ì ‘ê·¼ ë°©ì‹ì„ ëŠ¥ê°€í•˜ë©°, ê·œì¹™ì ì¸ êµí†µ íŒ¨í„´ê³¼ ê¸‰ê²©í•œ ë³€í™”ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í¬ì°©í•œë‹¤.

---

*Generated on 2025-09-20 09:36:24*