---
keywords:
  - Diffusion Models
  - Text-guided Audio Editing
  - Rectified Flow Matching
category: cs.AI
publish_date: 2025-09-17
arxiv_id:
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 22:46:43.212995",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Diffusion Models",
    "Text-guided Audio Editing",
    "Rectified Flow Matching"
  ],
  "rejected_keywords": [
    "Generative Models"
  ],
  "similarity_scores": {
    "Diffusion Models": 0.8,
    "Text-guided Audio Editing": 0.78,
    "Rectified Flow Matching": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->

# RFM-Editing: Rectified Flow Matching for Text-guided Audio Editing

**Korean Title:** RFM-í¸ì§‘: í…ìŠ¤íŠ¸ ê¸°ë°˜ ì˜¤ë””ì˜¤ í¸ì§‘ì„ ìœ„í•œ ìˆ˜ì •ëœ íë¦„ ë§¤ì¹­

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[digests/daily_digest_20250917|2025-09-17]]        [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Diffusion Models|Diffusion models]]
**âš¡ Unique Technical**: [[keywords/Text-guided Audio Editing|Text-guided audio editing]], [[keywords/Rectified Flow Matching|Rectified flow matching]]

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[Mitigating data replication in text-to-audio generative diffusion models through anti-memorization guidance_20250919|Mitigating data replication in text-to-audio generative diffusion models through anti-memorization guidance]] (82.4% similar)
- [[Fast and Fluent Diffusion Language Models via Convolutional Decoding and Rejective Fine-tuning_20250918|Fast and Fluent Diffusion Language Models via Convolutional Decoding and Rejective Fine-tuning]] (80.9% similar)
- [[Spatial Audio Motion Understanding and Reasoning_20250918|Spatial Audio Motion Understanding and Reasoning]] (80.5% similar)
- [[DPDEdit_ Detail-Preserved Diffusion Models for Multimodal Fashion Image Editing_20250918|DPDEdit Detail-Preserved Diffusion Models for Multimodal Fashion Image Editing]] (80.1% similar)
- [[Diffusion-Based Unsupervised Audio-Visual Speech Separation in Noisy Environments with Noise Prior_20250919|Diffusion-Based Unsupervised Audio-Visual Speech Separation in Noisy Environments with Noise Prior]] (79.9% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** Liting Gao, Yi Yuan, Yaru Chen, Yuelan Cheng, Zhenbo Li, Juan Wen, Shubin Zhang, Wenwu Wang

## ğŸ“„ Abstract (ì›ë¬¸)

Diffusion models have shown remarkable progress in text-to-audio generation.
However, text-guided audio editing remains in its early stages. This task
focuses on modifying the target content within an audio signal while preserving
the rest, thus demanding precise localization and faithful editing according to
the text prompt. Existing training-based and zero-shot methods that rely on
full-caption or costly optimization often struggle with complex editing or lack
practicality. In this work, we propose a novel end-to-end efficient rectified
flow matching-based diffusion framework for audio editing, and construct a
dataset featuring overlapping multi-event audio to support training and
benchmarking in complex scenarios. Experiments show that our model achieves
faithful semantic alignment without requiring auxiliary captions or masks,
while maintaining competitive editing quality across metrics.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

í™•ì‚° ëª¨ë¸ì€ í…ìŠ¤íŠ¸-ì˜¤ë””ì˜¤ ìƒì„±ì—ì„œ ë†€ë¼ìš´ ë°œì „ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ í…ìŠ¤íŠ¸ ê¸°ë°˜ ì˜¤ë””ì˜¤ í¸ì§‘ì€ ì•„ì§ ì´ˆê¸° ë‹¨ê³„ì— ë¨¸ë¬¼ëŸ¬ ìˆìŠµë‹ˆë‹¤. ì´ ì‘ì—…ì€ ì˜¤ë””ì˜¤ ì‹ í˜¸ ë‚´ì˜ ëª©í‘œ ì½˜í…ì¸ ë¥¼ ìˆ˜ì •í•˜ë©´ì„œ ë‚˜ë¨¸ì§€ëŠ” ë³´ì¡´í•˜ëŠ” ë° ì¤‘ì ì„ ë‘ë©°, ë”°ë¼ì„œ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ì— ë”°ë¼ ì •í™•í•œ ìœ„ì¹˜ ì§€ì •ê³¼ ì¶©ì‹¤í•œ í¸ì§‘ì„ ìš”êµ¬í•©ë‹ˆë‹¤. ì „ì²´ ìº¡ì…˜ì´ë‚˜ ë¹„ìš©ì´ ë§ì´ ë“œëŠ” ìµœì í™”ì— ì˜ì¡´í•˜ëŠ” ê¸°ì¡´ì˜ í•™ìŠµ ê¸°ë°˜ ë° ì œë¡œìƒ· ë°©ë²•ì€ ë³µì¡í•œ í¸ì§‘ì—ì„œ ì¢…ì¢… ì–´ë ¤ì›€ì„ ê²ªê±°ë‚˜ ì‹¤ìš©ì„±ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” ì˜¤ë””ì˜¤ í¸ì§‘ì„ ìœ„í•œ ìƒˆë¡œìš´ ì—”ë“œ íˆ¬ ì—”ë“œ íš¨ìœ¨ì ì¸ ìˆ˜ì •ëœ íë¦„ ë§¤ì¹­ ê¸°ë°˜ í™•ì‚° í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•˜ê³ , ë³µì¡í•œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œì˜ í•™ìŠµ ë° ë²¤ì¹˜ë§ˆí‚¹ì„ ì§€ì›í•˜ê¸° ìœ„í•´ ì¤‘ì²©ëœ ë‹¤ì¤‘ ì´ë²¤íŠ¸ ì˜¤ë””ì˜¤ë¥¼ íŠ¹ì§•ìœ¼ë¡œ í•˜ëŠ” ë°ì´í„°ì…‹ì„ êµ¬ì¶•í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ìš°ë¦¬ì˜ ëª¨ë¸ì€ ë³´ì¡° ìº¡ì…˜ì´ë‚˜ ë§ˆìŠ¤í¬ ì—†ì´ë„ ì¶©ì‹¤í•œ ì˜ë¯¸ì  ì •ë ¬ì„ ë‹¬ì„±í•˜ë©°, ë‹¤ì–‘í•œ ì§€í‘œì—ì„œ ê²½ìŸë ¥ ìˆëŠ” í¸ì§‘ í’ˆì§ˆì„ ìœ ì§€í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ í…ìŠ¤íŠ¸ ê¸°ë°˜ ì˜¤ë””ì˜¤ í¸ì§‘ì„ ìœ„í•œ ìƒˆë¡œìš´ í™•ì‚° ëª¨ë¸ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ ë°©ë²•ë“¤ì´ ë³µì¡í•œ í¸ì§‘ì— ì–´ë ¤ì›€ì„ ê²ªëŠ” ë°˜ë©´, ì œì•ˆëœ ëª¨ë¸ì€ íš¨ìœ¨ì ì¸ ì •ë¥˜ íë¦„ ë§¤ì¹­ ê¸°ë°˜ì˜ í™•ì‚° í”„ë ˆì„ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ ì‹ í˜¸ ë‚´ì—ì„œ ëª©í‘œ ì½˜í…ì¸ ë¥¼ ì •í™•íˆ ìˆ˜ì •í•˜ë©´ì„œ ë‚˜ë¨¸ì§€ë¥¼ ë³´ì¡´í•©ë‹ˆë‹¤. ë˜í•œ, ì¤‘ì²©ëœ ë‹¤ì¤‘ ì´ë²¤íŠ¸ ì˜¤ë””ì˜¤ ë°ì´í„°ì…‹ì„ êµ¬ì¶•í•˜ì—¬ ë³µì¡í•œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œì˜ í›ˆë ¨ê³¼ ë²¤ì¹˜ë§ˆí‚¹ì„ ì§€ì›í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ë³´ì¡° ìº¡ì…˜ì´ë‚˜ ë§ˆìŠ¤í¬ ì—†ì´ë„ ì˜ë¯¸ ì •ë ¬ì„ ì¶©ì‹¤íˆ ìˆ˜í–‰í•˜ë©°, ë‹¤ì–‘í•œ ì§€í‘œì—ì„œ ê²½ìŸë ¥ ìˆëŠ” í¸ì§‘ í’ˆì§ˆì„ ìœ ì§€í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. í…ìŠ¤íŠ¸ ê¸°ë°˜ ì˜¤ë””ì˜¤ í¸ì§‘ì€ ì´ˆê¸° ë‹¨ê³„ì— ìˆìœ¼ë©°, ì •í™•í•œ ìœ„ì¹˜ ì§€ì •ê³¼ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ì— ë”°ë¥¸ ì¶©ì‹¤í•œ í¸ì§‘ì´ ìš”êµ¬ëœë‹¤.

- 2. ê¸°ì¡´ ë°©ë²•ë“¤ì€ ë³µì¡í•œ í¸ì§‘ì—ì„œ ì–´ë ¤ì›€ì„ ê²ªê±°ë‚˜ ì‹¤ìš©ì„±ì´ ë¶€ì¡±í•˜ë‹¤.

- 3. ë³¸ ì—°êµ¬ëŠ” ì˜¤ë””ì˜¤ í¸ì§‘ì„ ìœ„í•œ ìƒˆë¡œìš´ íš¨ìœ¨ì ì¸ ì •ë¥˜ íë¦„ ë§¤ì¹­ ê¸°ë°˜ í™•ì‚° í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•œë‹¤.

- 4. ì¤‘ì²©ëœ ë‹¤ì¤‘ ì´ë²¤íŠ¸ ì˜¤ë””ì˜¤ë¥¼ í¬í•¨í•˜ëŠ” ë°ì´í„°ì…‹ì„ êµ¬ì¶•í•˜ì—¬ ë³µì¡í•œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œì˜ í›ˆë ¨ ë° ë²¤ì¹˜ë§ˆí‚¹ì„ ì§€ì›í•œë‹¤.

- 5. ì œì•ˆëœ ëª¨ë¸ì€ ë³´ì¡° ìº¡ì…˜ì´ë‚˜ ë§ˆìŠ¤í¬ ì—†ì´ë„ ì¶©ì‹¤í•œ ì˜ë¯¸ ì •ë ¬ì„ ë‹¬ì„±í•˜ë©´ì„œ ê²½ìŸë ¥ ìˆëŠ” í¸ì§‘ í’ˆì§ˆì„ ìœ ì§€í•œë‹¤.

---

*Generated on 2025-09-20 09:19:39*