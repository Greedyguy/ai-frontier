---
keywords:
  - Compute as Teacher
  - Self-Proposed Rubrics
  - Large Language Models
category: cs.AI
publish_date: 2025-09-17
arxiv_id:
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 22:58:36.427081",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Compute as Teacher",
    "Self-Proposed Rubrics",
    "Large Language Models"
  ],
  "rejected_keywords": [
    "Reinforcement Learning"
  ],
  "similarity_scores": {
    "Compute as Teacher": 0.8,
    "Self-Proposed Rubrics": 0.77,
    "Large Language Models": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->

# Compute as Teacher: Turning Inference Compute Into Reference-Free Supervision

**Korean Title:** êµì‚¬ë¡œì„œì˜ ê³„ì‚°: ì¶”ë¡  ê³„ì‚°ì„ ì°¸ì¡° ì—†ëŠ” ê°ë…ìœ¼ë¡œ ì „í™˜í•˜ê¸°

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[digests/daily_digest_20250917|2025-09-17]]        [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**âš¡ Unique Technical**: [[keywords/Compute as Teacher|Compute as Teacher]], [[keywords/Self-Proposed Rubrics|Self-Proposed Rubrics]]
**ğŸš€ Evolved Concepts**: [[keywords/Large Language Models|Large Language Models]]

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[Teaching According to Talents! Instruction Tuning LLMs with Competence-Aware Curriculum Learning_20250917|Teaching According to Talents! Instruction Tuning LLMs with Competence-Aware Curriculum Learning]] (80.9% similar)
- [[TDRM_ Smooth Reward Models with Temporal Difference for LLM RL and Inference_20250918|TDRM Smooth Reward Models with Temporal Difference for LLM RL and Inference]] (80.4% similar)
- [[From Correction to Mastery_ Reinforced Distillation of Large Language Model Agents_20250919|From Correction to Mastery Reinforced Distillation of Large Language Model Agents]] (79.9% similar)
- [[Enhancing Logical Reasoning in Language Models via Symbolically-Guided Monte Carlo Process Supervision_20250919|Enhancing Logical Reasoning in Language Models via Symbolically-Guided Monte Carlo Process Supervision]] (79.7% similar)
- [[Process-Supervised Reinforcement Learning for Interactive Multimodal Tool-Use Agents_20250919|Process-Supervised Reinforcement Learning for Interactive Multimodal Tool-Use Agents]] (79.6% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** Dulhan Jayalath, Shashwat Goel, Thomas Foster, Parag Jain, Suchin Gururangan, Cheng Zhang, Anirudh Goyal, Alan Schelten

## ğŸ“„ Abstract (ì›ë¬¸)

Where do learning signals come from when there is no ground truth in
post-training? We propose turning exploration into supervision through Compute
as Teacher (CaT), which converts the model's own exploration at inference-time
into reference-free supervision by synthesizing a single reference from a group
of parallel rollouts and then optimizing toward it. Concretely, the current
policy produces a group of rollouts; a frozen anchor (the initial policy)
reconciles omissions and contradictions to estimate a reference, turning extra
inference-time compute into a teacher signal. We turn this into rewards in two
regimes: (i) verifiable tasks use programmatic equivalence on final answers;
(ii) non-verifiable tasks use self-proposed rubrics-binary, auditable criteria
scored by an independent LLM judge, with reward given by the fraction
satisfied. Unlike selection methods (best-of-N, majority, perplexity, or judge
scores), synthesis may disagree with the majority and be correct even when all
rollouts are wrong; performance scales with the number of rollouts. As a
test-time procedure, CaT improves Gemma 3 4B, Qwen 3 4B, and Llama 3.1 8B (up
to +27% on MATH-500; +12% on HealthBench). With reinforcement learning
(CaT-RL), we obtain further gains (up to +33% and +30%), with the trained
policy surpassing the initial teacher signal.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

í•™ìŠµ ì‹ í˜¸ëŠ” í›ˆë ¨ í›„ì— ì •ë‹µì´ ì—†ì„ ë•Œ ì–´ë””ì—ì„œ ì˜¤ëŠ”ê°€? ìš°ë¦¬ëŠ” Compute as Teacher (CaT)ë¥¼ í†µí•´ íƒìƒ‰ì„ ê°ë…ìœ¼ë¡œ ì „í™˜í•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí•œë‹¤. ì´ëŠ” ëª¨ë¸ì˜ ì¶”ë¡  ì‹œê°„ íƒìƒ‰ì„ ë³‘ë ¬ ë¡¤ì•„ì›ƒ ê·¸ë£¹ì—ì„œ ë‹¨ì¼ ì°¸ì¡°ë¥¼ í•©ì„±í•˜ì—¬ ì°¸ì¡° ì—†ëŠ” ê°ë…ìœ¼ë¡œ ë³€í™˜í•œ í›„ ì´ë¥¼ ìµœì í™”í•˜ëŠ” ë°©ì‹ì´ë‹¤. êµ¬ì²´ì ìœ¼ë¡œ, í˜„ì¬ ì •ì±…ì€ ë¡¤ì•„ì›ƒ ê·¸ë£¹ì„ ìƒì„±í•˜ê³ , ê³ ì •ëœ ì•µì»¤(ì´ˆê¸° ì •ì±…)ëŠ” ëˆ„ë½ ë° ëª¨ìˆœì„ ì¡°ì •í•˜ì—¬ ì°¸ì¡°ë¥¼ ì¶”ì •í•˜ë©°, ì¶”ê°€ì ì¸ ì¶”ë¡  ì‹œê°„ ê³„ì‚°ì„ êµì‚¬ ì‹ í˜¸ë¡œ ì „í™˜í•œë‹¤. ìš°ë¦¬ëŠ” ì´ë¥¼ ë‘ ê°€ì§€ ì²´ì œì—ì„œ ë³´ìƒìœ¼ë¡œ ì „í™˜í•œë‹¤: (i) ê²€ì¦ ê°€ëŠ¥í•œ ì‘ì—…ì€ ìµœì¢… ë‹µë³€ì˜ í”„ë¡œê·¸ë¨ì  ë™ë“±ì„±ì„ ì‚¬ìš©í•œë‹¤; (ii) ê²€ì¦ ë¶ˆê°€ëŠ¥í•œ ì‘ì—…ì€ ë…ë¦½ì ì¸ LLM ì‹¬íŒì— ì˜í•´ ì ìˆ˜í™”ëœ ì´ì§„, ê°ì‚¬ ê°€ëŠ¥í•œ ê¸°ì¤€ì¸ ìì²´ ì œì•ˆ ë£¨ë¸Œë¦­ì„ ì‚¬ìš©í•˜ë©°, ë§Œì¡±ëœ ë¹„ìœ¨ì— ë”°ë¼ ë³´ìƒì´ ì£¼ì–´ì§„ë‹¤. ì„ íƒ ë°©ë²•(ìµœìƒì˜ N, ë‹¤ìˆ˜ê²°, ë‹¹í˜¹ë„, ë˜ëŠ” ì‹¬íŒ ì ìˆ˜)ê³¼ ë‹¬ë¦¬, í•©ì„±ì€ ë‹¤ìˆ˜ì™€ ì˜ê²¬ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë©° ëª¨ë“  ë¡¤ì•„ì›ƒì´ í‹€ë ¸ì„ ë•Œë„ ì˜¬ë°”ë¥¼ ìˆ˜ ìˆë‹¤; ì„±ëŠ¥ì€ ë¡¤ì•„ì›ƒ ìˆ˜ì— ë”°ë¼ í™•ì¥ëœë‹¤. í…ŒìŠ¤íŠ¸ ì‹œê°„ ì ˆì°¨ë¡œì„œ, CaTëŠ” Gemma 3 4B, Qwen 3 4B, ê·¸ë¦¬ê³  Llama 3.1 8Bì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¨ë‹¤ (MATH-500ì—ì„œ ìµœëŒ€ +27%; HealthBenchì—ì„œ +12%). ê°•í™” í•™ìŠµ(CaT-RL)ê³¼ í•¨ê»˜, ìš°ë¦¬ëŠ” ì¶”ê°€ì ì¸ í–¥ìƒì„ ì–»ìœ¼ë©° (ìµœëŒ€ +33% ë° +30%), í›ˆë ¨ëœ ì •ì±…ì´ ì´ˆê¸° êµì‚¬ ì‹ í˜¸ë¥¼ ëŠ¥ê°€í•œë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ í•™ìŠµ ì‹ í˜¸ê°€ ì—†ëŠ” ìƒí™©ì—ì„œ ëª¨ë¸ì˜ íƒìƒ‰ì„ ê°ë… ì‹ í˜¸ë¡œ ì „í™˜í•˜ëŠ” ë°©ë²•ì¸ Compute as Teacher (CaT)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. CaTëŠ” ëª¨ë¸ì˜ ì¶”ë¡  ì‹œ íƒìƒ‰ì„ í†µí•´ ìƒì„±ëœ ì—¬ëŸ¬ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ì°¸ì¡°ë¡œ í•©ì„±í•˜ê³ , ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìµœì í™”í•©ë‹ˆë‹¤. ë‘ ê°€ì§€ ë°©ì‹ìœ¼ë¡œ ë³´ìƒì„ ì œê³µí•©ë‹ˆë‹¤: ê²€ì¦ ê°€ëŠ¥í•œ ì‘ì—…ì—ì„œëŠ” í”„ë¡œê·¸ë¨ì  ë™ë“±ì„±ì„ ì‚¬ìš©í•˜ê³ , ë¹„ê²€ì¦ ì‘ì—…ì—ì„œëŠ” ë…ë¦½ì ì¸ LLM ì‹¬íŒì´ í‰ê°€í•˜ëŠ” ê¸°ì¤€ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. CaTëŠ” ë‹¤ìˆ˜ì˜ ê²°ê³¼ì™€ ë‹¤ë¥¼ ìˆ˜ ìˆì§€ë§Œ, ì˜¤íˆë ¤ ì •í™•í•  ìˆ˜ ìˆìœ¼ë©°, ë¡¤ì•„ì›ƒ ìˆ˜ì— ë”°ë¼ ì„±ëŠ¥ì´ í–¥ìƒë©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, CaTëŠ” ì—¬ëŸ¬ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œì¼°ìœ¼ë©°, ê°•í™” í•™ìŠµì„ í†µí•´ ì¶”ê°€ì ì¸ ì„±ëŠ¥ í–¥ìƒì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Compute as Teacher (CaT)ëŠ” ëª¨ë¸ì˜ íƒìƒ‰ ê³¼ì •ì„ ê°ë… ì‹ í˜¸ë¡œ ì „í™˜í•˜ì—¬ ì°¸ì¡° ì—†ì´ ìµœì í™”í•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤.

- 2. CaTëŠ” ë³‘ë ¬ ë¡¤ì•„ì›ƒ ê·¸ë£¹ì—ì„œ ë‹¨ì¼ ì°¸ì¡°ë¥¼ í•©ì„±í•˜ì—¬ ì¶”ê°€ ì¶”ë¡  ì‹œê°„ ê³„ì‚°ì„ êµì‚¬ ì‹ í˜¸ë¡œ ì „í™˜í•©ë‹ˆë‹¤.

- 3. ê²€ì¦ ê°€ëŠ¥í•œ ì‘ì—…ì—ì„œëŠ” ìµœì¢… ë‹µë³€ì˜ í”„ë¡œê·¸ë¨ì  ë™ë“±ì„±ì„ ì‚¬ìš©í•˜ê³ , ê²€ì¦ ë¶ˆê°€ëŠ¥í•œ ì‘ì—…ì—ì„œëŠ” ë…ë¦½ì ì¸ LLM íŒì‚¬ê°€ ì±„ì í•˜ëŠ” ê¸°ì¤€ì„ ì‚¬ìš©í•˜ì—¬ ë³´ìƒì„ ì œê³µí•©ë‹ˆë‹¤.

- 4. CaTëŠ” ë¡¤ì•„ì›ƒ ìˆ˜ì— ë”°ë¼ ì„±ëŠ¥ì´ í™•ì¥ë˜ë©°, ëª¨ë“  ë¡¤ì•„ì›ƒì´ í‹€ë¦° ê²½ìš°ì—ë„ ë‹¤ìˆ˜ê²°ê³¼ ë‹¤ë¥´ê²Œ ì •ë‹µì„ ì œì‹œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- 5. ê°•í™” í•™ìŠµ(CaT-RL)ì„ í†µí•´ ì¶”ê°€ì ì¸ ì„±ëŠ¥ í–¥ìƒì„ ì´ë£¨ë©°, í›ˆë ¨ëœ ì •ì±…ì´ ì´ˆê¸° êµì‚¬ ì‹ í˜¸ë¥¼ ëŠ¥ê°€í•©ë‹ˆë‹¤.

---

*Generated on 2025-09-20 07:39:42*