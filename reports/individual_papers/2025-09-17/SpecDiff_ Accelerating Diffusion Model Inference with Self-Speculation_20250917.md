---
keywords:
  - Diffusion Models
  - Self-Speculation
  - Efficient Diffusion Model Inference
category: cs.AI
publish_date: 2025-09-17
arxiv_id:
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 22:45:27.336531",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Diffusion Models",
    "Self-Speculation",
    "Efficient Diffusion Model Inference"
  ],
  "rejected_keywords": [
    "Feature Caching"
  ],
  "similarity_scores": {
    "Diffusion Models": 0.9,
    "Self-Speculation": 0.85,
    "Efficient Diffusion Model Inference": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->

# SpecDiff: Accelerating Diffusion Model Inference with Self-Speculation

**Korean Title:** SpecDiff: ìê¸° ì¶”ì¸¡ì„ í†µí•œ í™•ì‚° ëª¨ë¸ ì¶”ë¡  ê°€ì†í™”

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[digests/daily_digest_20250917|2025-09-17]]       [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Diffusion Models|Diffusion Model]]
**âš¡ Unique Technical**: [[keywords/Self-Speculation|Self-Speculation]]
**ğŸš€ Evolved Concepts**: [[keywords/Efficient Diffusion Model Inference|Efficient Diffusion Model Inference]]

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[Fast and Fluent Diffusion Language Models via Convolutional Decoding and Rejective Fine-tuning_20250918|Fast and Fluent Diffusion Language Models via Convolutional Decoding and Rejective Fine-tuning]] (82.0% similar)
- [[Lightweight and Accurate Multi-View Stereo with Confidence-Aware Diffusion Model_20250918|Lightweight and Accurate Multi-View Stereo with Confidence-Aware Diffusion Model]] (81.7% similar)
- [[AnoF-Diff_ One-Step Diffusion-Based Anomaly Detection for Forceful Tool Use_20250918|AnoF-Diff One-Step Diffusion-Based Anomaly Detection for Forceful Tool Use]] (81.0% similar)
- [[FlightDiffusion_ Revolutionising Autonomous Drone Training with Diffusion Models Generating FPV Video_20250918|FlightDiffusion Revolutionising Autonomous Drone Training with Diffusion Models Generating FPV Video]] (80.7% similar)
- [[Data coarse graining can improve model performance_20250918|Data coarse graining can improve model performance]] (80.5% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** Jiayi Pan, Jiaming Xu, Yongkang Zhou, Guohao Dai

## ğŸ“„ Abstract (ì›ë¬¸)

Feature caching has recently emerged as a promising method for diffusion
model acceleration. It effectively alleviates the inefficiency problem caused
by high computational requirements by caching similar features in the inference
process of the diffusion model. In this paper, we analyze existing feature
caching methods from the perspective of information utilization, and point out
that relying solely on historical information will lead to constrained accuracy
and speed performance. And we propose a novel paradigm that introduces future
information via self-speculation based on the information similarity at the
same time step across different iteration times. Based on this paradigm, we
present \textit{SpecDiff}, a training-free multi-level feature caching strategy
including a cached feature selection algorithm and a multi-level feature
classification algorithm. (1) Feature selection algorithm based on
self-speculative information. \textit{SpecDiff} determines a dynamic importance
score for each token based on self-speculative information and historical
information, and performs cached feature selection through the importance
score. (2) Multi-level feature classification algorithm based on feature
importance scores. \textit{SpecDiff} classifies tokens by leveraging the
differences in feature importance scores and introduces a multi-level feature
calculation strategy. Extensive experiments show that \textit{SpecDiff}
achieves average 2.80 \times, 2.74 \times , and 3.17\times speedup with
negligible quality loss in Stable Diffusion 3, 3.5, and FLUX compared to RFlow
on NVIDIA A800-80GB GPU. By merging speculative and historical information,
\textit{SpecDiff} overcomes the speedup-accuracy trade-off bottleneck, pushing
the Pareto frontier of speedup and accuracy in the efficient diffusion model
inference.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

íŠ¹ì§• ìºì‹±ì€ ìµœê·¼ í™•ì‚° ëª¨ë¸ ê°€ì†í™”ë¥¼ ìœ„í•œ ìœ ë§í•œ ë°©ë²•ìœ¼ë¡œ ë¶€ìƒí•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŠ” í™•ì‚° ëª¨ë¸ì˜ ì¶”ë¡  ê³¼ì •ì—ì„œ ìœ ì‚¬í•œ íŠ¹ì§•ì„ ìºì‹±í•¨ìœ¼ë¡œì¨ ë†’ì€ ê³„ì‚° ìš”êµ¬ ì‚¬í•­ìœ¼ë¡œ ì¸í•œ ë¹„íš¨ìœ¨ì„± ë¬¸ì œë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì™„í™”í•©ë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì •ë³´ í™œìš©ì˜ ê´€ì ì—ì„œ ê¸°ì¡´ì˜ íŠ¹ì§• ìºì‹± ë°©ë²•ì„ ë¶„ì„í•˜ê³ , ê³¼ê±° ì •ë³´ì—ë§Œ ì˜ì¡´í•  ê²½ìš° ì •í™•ì„±ê³¼ ì†ë„ ì„±ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŒì„ ì§€ì í•©ë‹ˆë‹¤. ê·¸ë¦¬ê³  ìš°ë¦¬ëŠ” ì„œë¡œ ë‹¤ë¥¸ ë°˜ë³µ ì‹œê°„ì— ë™ì¼í•œ ì‹œê°„ ë‹¨ê³„ì—ì„œ ì •ë³´ ìœ ì‚¬ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ ìê¸° ì¶”ì¸¡ì„ í†µí•´ ë¯¸ë˜ ì •ë³´ë¥¼ ë„ì…í•˜ëŠ” ìƒˆë¡œìš´ íŒ¨ëŸ¬ë‹¤ì„ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ íŒ¨ëŸ¬ë‹¤ì„ì„ ë°”íƒ•ìœ¼ë¡œ, ìš°ë¦¬ëŠ” \textit{SpecDiff}ë¼ëŠ” í›ˆë ¨ì´ í•„ìš” ì—†ëŠ” ë‹¤ì¤‘ ìˆ˜ì¤€ íŠ¹ì§• ìºì‹± ì „ëµì„ ì œì‹œí•©ë‹ˆë‹¤. ì—¬ê¸°ì—ëŠ” ìºì‹œëœ íŠ¹ì§• ì„ íƒ ì•Œê³ ë¦¬ì¦˜ê³¼ ë‹¤ì¤‘ ìˆ˜ì¤€ íŠ¹ì§• ë¶„ë¥˜ ì•Œê³ ë¦¬ì¦˜ì´ í¬í•¨ë©ë‹ˆë‹¤. (1) ìê¸° ì¶”ì¸¡ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ íŠ¹ì§• ì„ íƒ ì•Œê³ ë¦¬ì¦˜. \textit{SpecDiff}ëŠ” ìê¸° ì¶”ì¸¡ ì •ë³´ì™€ ê³¼ê±° ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê° í† í°ì— ëŒ€í•œ ë™ì  ì¤‘ìš”ë„ ì ìˆ˜ë¥¼ ê²°ì •í•˜ê³ , ì´ ì¤‘ìš”ë„ ì ìˆ˜ë¥¼ í†µí•´ ìºì‹œëœ íŠ¹ì§• ì„ íƒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. (2) íŠ¹ì§• ì¤‘ìš”ë„ ì ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ë‹¤ì¤‘ ìˆ˜ì¤€ íŠ¹ì§• ë¶„ë¥˜ ì•Œê³ ë¦¬ì¦˜. \textit{SpecDiff}ëŠ” íŠ¹ì§• ì¤‘ìš”ë„ ì ìˆ˜ì˜ ì°¨ì´ë¥¼ í™œìš©í•˜ì—¬ í† í°ì„ ë¶„ë¥˜í•˜ê³ , ë‹¤ì¤‘ ìˆ˜ì¤€ íŠ¹ì§• ê³„ì‚° ì „ëµì„ ë„ì…í•©ë‹ˆë‹¤. ê´‘ë²”ìœ„í•œ ì‹¤í—˜ ê²°ê³¼, \textit{SpecDiff}ëŠ” NVIDIA A800-80GB GPUì—ì„œ RFlowì™€ ë¹„êµí•˜ì—¬ Stable Diffusion 3, 3.5 ë° FLUXì—ì„œ í‰ê·  2.80ë°°, 2.74ë°°, 3.17ë°°ì˜ ì†ë„ í–¥ìƒì„ ë‹¬ì„±í•˜ë©° í’ˆì§ˆ ì†ì‹¤ì€ ë¯¸ë¯¸í•œ ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤. ì¶”ì¸¡ ì •ë³´ì™€ ê³¼ê±° ì •ë³´ë¥¼ ê²°í•©í•¨ìœ¼ë¡œì¨, \textit{SpecDiff}ëŠ” ì†ë„ í–¥ìƒê³¼ ì •í™•ì„± ê°„ì˜ ê· í˜•ì„ ê·¹ë³µí•˜ì—¬ íš¨ìœ¨ì ì¸ í™•ì‚° ëª¨ë¸ ì¶”ë¡ ì—ì„œ ì†ë„ í–¥ìƒê³¼ ì •í™•ì„±ì˜ íŒŒë ˆí†  ì „ì„ ì„ í™•ì¥í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ìµœê·¼ í™•ì‚° ëª¨ë¸ ê°€ì†í™” ë°©ë²•ìœ¼ë¡œ ì£¼ëª©ë°›ê³  ìˆëŠ” íŠ¹ì§• ìºì‹±ì€ ê³„ì‚° ìš”êµ¬ëŸ‰ì´ ë†’ì€ í™•ì‚° ëª¨ë¸ì˜ ë¹„íš¨ìœ¨ì„±ì„ ì™„í™”í•©ë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ê¸°ì¡´ íŠ¹ì§• ìºì‹± ë°©ë²•ì„ ì •ë³´ í™œìš© ê´€ì ì—ì„œ ë¶„ì„í•˜ê³ , ê³¼ê±° ì •ë³´ì—ë§Œ ì˜ì¡´í•  ê²½ìš° ì •í™•ë„ì™€ ì†ë„ê°€ ì œí•œëœë‹¤ëŠ” ì ì„ ì§€ì í•©ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ë™ì¼í•œ ì‹œê°„ ë‹¨ê³„ì—ì„œì˜ ì •ë³´ ìœ ì‚¬ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ ë¯¸ë˜ ì •ë³´ë¥¼ ë„ì…í•˜ëŠ” ìƒˆë¡œìš´ íŒ¨ëŸ¬ë‹¤ì„ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ íŒ¨ëŸ¬ë‹¤ì„ì— ê¸°ë°˜í•œ \textit{SpecDiff}ëŠ” í›ˆë ¨ì´ í•„ìš” ì—†ëŠ” ë‹¤ì¤‘ ìˆ˜ì¤€ íŠ¹ì§• ìºì‹± ì „ëµìœ¼ë¡œ, ìºì‹±ëœ íŠ¹ì§• ì„ íƒ ì•Œê³ ë¦¬ì¦˜ê³¼ ë‹¤ì¤‘ ìˆ˜ì¤€ íŠ¹ì§• ë¶„ë¥˜ ì•Œê³ ë¦¬ì¦˜ì„ í¬í•¨í•©ë‹ˆë‹¤. \textit{SpecDiff}ëŠ” ìê¸° ì¶”ì¸¡ ì •ë³´ë¥¼ í™œìš©í•´ ê° í† í°ì˜ ì¤‘ìš”ë„ë¥¼ ë™ì ìœ¼ë¡œ í‰ê°€í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìºì‹±ëœ íŠ¹ì§•ì„ ì„ íƒí•©ë‹ˆë‹¤. ë˜í•œ, íŠ¹ì§• ì¤‘ìš”ë„ ì ìˆ˜ ì°¨ì´ë¥¼ í™œìš©í•´ í† í°ì„ ë¶„ë¥˜í•˜ê³  ë‹¤ì¤‘ ìˆ˜ì¤€ íŠ¹ì§• ê³„ì‚° ì „ëµì„ ë„ì…í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, \textit{SpecDiff}ëŠ” RFlow ëŒ€ë¹„ NVIDIA A800-80GB GPUì—ì„œ Stable Diffusion 3, 3.5, FLUX ëª¨ë¸ì—ì„œ ê°ê° í‰ê·  2.80ë°°, 2.74ë°°, 3.17ë°°ì˜ ì†ë„ í–¥ìƒì„ ì´ë£¨ë©´ì„œ í’ˆì§ˆ ì†ì‹¤ì€ ë¯¸ë¯¸í–ˆìŠµë‹ˆë‹¤. \textit{SpecDiff}ëŠ” ì¶”ì¸¡ ì •ë³´ì™€ ê³¼ê±° ì •ë³´ë¥¼ ê²°í•©í•˜ì—¬ ì†ë„ì™€ ì •í™•ë„ì˜ ê· í˜• ë¬¸ì œë¥¼ ê·¹ë³µí•˜ê³ , íš¨ìœ¨ì ì¸ í™•ì‚° ëª¨ë¸ ì¶”ë¡ ì—ì„œ ì†ë„ì™€ ì •í™•ë„ì˜ íŒŒë ˆí†  ê²½ê³„ë¥¼ í™•ì¥í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Feature cachingì€ í™•ì‚° ëª¨ë¸ì˜ ë¹„íš¨ìœ¨ì„±ì„ ì™„í™”í•˜ëŠ” ìœ ë§í•œ ê°€ì†í™” ë°©ë²•ìœ¼ë¡œ ì£¼ëª©ë°›ê³  ìˆìŠµë‹ˆë‹¤.

- 2. ê¸°ì¡´ì˜ feature caching ë°©ë²•ì€ ê³¼ê±° ì •ë³´ì—ë§Œ ì˜ì¡´í•˜ì—¬ ì •í™•ì„±ê³¼ ì†ë„ ì„±ëŠ¥ì— ì œì•½ì´ ìˆìŠµë‹ˆë‹¤.

- 3. \textit{SpecDiff}ëŠ” ë¯¸ë˜ ì •ë³´ë¥¼ ë„ì…í•˜ì—¬ ë™ì  ì¤‘ìš”ë„ ì ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìºì‹œëœ íŠ¹ì§• ì„ íƒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

- 4. \textit{SpecDiff}ëŠ” íŠ¹ì§• ì¤‘ìš”ë„ ì ìˆ˜ ì°¨ì´ë¥¼ í™œìš©í•˜ì—¬ ë‹¤ì¤‘ ìˆ˜ì¤€ì˜ íŠ¹ì§• ë¶„ë¥˜ ì•Œê³ ë¦¬ì¦˜ì„ ì œì•ˆí•©ë‹ˆë‹¤.

- 5. \textit{SpecDiff}ëŠ” ì†ë„ì™€ ì •í™•ì„±ì˜ ê· í˜•ì„ ê·¹ë³µí•˜ì—¬ íš¨ìœ¨ì ì¸ í™•ì‚° ëª¨ë¸ ì¶”ë¡ ì—ì„œ Pareto ìµœì ì„ ì„ í™•ì¥í•©ë‹ˆë‹¤.

---

*Generated on 2025-09-20 09:29:19*