# Dense Video Understanding with Gated Residual Tokenization

**Korean Title:** ì¡°ë°€í•œ ë¹„ë””ì˜¤ ì´í•´ë¥¼ ìœ„í•œ ê²Œì´íŠ¸ ì”ì—¬ í† í°í™”

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-17|2025-09-17]] [[authors/Haichao Zhang|Haichao Zhang]] [[authors/Wenhao Chai|Wenhao Chai]] [[authors/Shwai He|Shwai He]] [[authors/Ang Li|Ang Li]] [[authors/Yun Fu|Yun Fu]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Dense Temporal Information

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[WorldForge_ Unlocking Emergent 3D4D Generation in Video Diffusion Model via Training-Free Guidance_20250919|WorldForge Unlocking Emergent 3D4D Generation in Video Diffusion Model via Training-Free Guidance]] (80.4% similar)
- [[AToken_ A Unified Tokenizer for Vision_20250919|AToken A Unified Tokenizer for Vision]] (80.1% similar)
- [[Unleashing the Potential of Multimodal LLMs for Zero-Shot Spatio-Temporal Video Grounding_20250919|Unleashing the Potential of Multimodal LLMs for Zero-Shot Spatio-Temporal Video Grounding]] (80.1% similar)
- [[UnifiedVisual_ A Framework for Constructing Unified Vision-Language Datasets_20250919|UnifiedVisual A Framework for Constructing Unified Vision-Language Datasets]] (79.5% similar)
- [[MovieCORE_ COgnitive REasoning in Movies_20250919|MovieCORE COgnitive REasoning in Movies]] (79.2% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** Haichao Zhang, Wenhao Chai, Shwai He, Ang Li, Yun Fu

## ğŸ“„ Abstract (ì›ë¬¸)

High temporal resolution is essential for capturing fine-grained details in
video understanding. However, current video large language models (VLLMs) and
benchmarks mostly rely on low-frame-rate sampling, such as uniform sampling or
keyframe selection, discarding dense temporal information. This compromise
avoids the high cost of tokenizing every frame, which otherwise leads to
redundant computation and linear token growth as video length increases. While
this trade-off works for slowly changing content, it fails for tasks like
lecture comprehension, where information appears in nearly every frame and
requires precise temporal alignment. To address this gap, we introduce Dense
Video Understanding (DVU), which enables high-FPS video comprehension by
reducing both tokenization time and token overhead. Existing benchmarks are
also limited, as their QA pairs focus on coarse content changes. We therefore
propose DIVE (Dense Information Video Evaluation), the first benchmark designed
for dense temporal reasoning. To make DVU practical, we present Gated Residual
Tokenization (GRT), a two-stage framework: (1) Motion-Compensated Inter-Gated
Tokenization uses pixel-level motion estimation to skip static regions during
tokenization, achieving sub-linear growth in token count and compute. (2)
Semantic-Scene Intra-Tokenization Merging fuses tokens across static regions
within a scene, further reducing redundancy while preserving dynamic semantics.
Experiments on DIVE show that GRT outperforms larger VLLM baselines and scales
positively with FPS. These results highlight the importance of dense temporal
information and demonstrate that GRT enables efficient, scalable high-FPS video
understanding.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

ê³ í•´ìƒë„ì˜ ì‹œê°„ì  í•´ìƒë„ëŠ” ë¹„ë””ì˜¤ ì´í•´ì—ì„œ ì„¸ë°€í•œ ë””í…Œì¼ì„ í¬ì°©í•˜ëŠ” ë° í•„ìˆ˜ì ì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ í˜„ì¬ì˜ ë¹„ë””ì˜¤ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(VLLM)ê³¼ ë²¤ì¹˜ë§ˆí¬ëŠ” ëŒ€ë¶€ë¶„ ê· ì¼ ìƒ˜í”Œë§ì´ë‚˜ í‚¤í”„ë ˆì„ ì„ íƒê³¼ ê°™ì€ ì €í”„ë ˆì„ë¥  ìƒ˜í”Œë§ì— ì˜ì¡´í•˜ì—¬ ë°€ì§‘í•œ ì‹œê°„ ì •ë³´ë¥¼ ë²„ë¦½ë‹ˆë‹¤. ì´ëŸ¬í•œ íƒ€í˜‘ì€ ëª¨ë“  í”„ë ˆì„ì„ í† í°í™”í•˜ëŠ” ë†’ì€ ë¹„ìš©ì„ í”¼í•˜ëŠ”ë°, ì´ëŠ” ë¹„ë””ì˜¤ ê¸¸ì´ê°€ ì¦ê°€í•¨ì— ë”°ë¼ ë¶ˆí•„ìš”í•œ ê³„ì‚°ê³¼ ì„ í˜•ì ì¸ í† í° ì¦ê°€ë¡œ ì´ì–´ì§€ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ì´ ì ˆì¶©ì•ˆì€ ì²œì²œíˆ ë³€í™”í•˜ëŠ” ì½˜í…ì¸ ì—ëŠ” íš¨ê³¼ì ì´ì§€ë§Œ, ì •ë³´ê°€ ê±°ì˜ ëª¨ë“  í”„ë ˆì„ì— ë‚˜íƒ€ë‚˜ê³  ì •í™•í•œ ì‹œê°„ ì •ë ¬ì´ í•„ìš”í•œ ê°•ì˜ ì´í•´ì™€ ê°™ì€ ì‘ì—…ì—ëŠ” ì‹¤íŒ¨í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ê²©ì°¨ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” í† í°í™” ì‹œê°„ê³¼ í† í° ì˜¤ë²„í—¤ë“œë¥¼ ì¤„ì—¬ ê³ FPS ë¹„ë””ì˜¤ ì´í•´ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” Dense Video Understanding (DVU)ì„ ì†Œê°œí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë²¤ì¹˜ë§ˆí¬ëŠ” QA ìŒì´ ëŒ€ëµì ì¸ ì½˜í…ì¸  ë³€í™”ì— ì´ˆì ì„ ë§ì¶”ê³  ìˆì–´ ì œí•œì ì…ë‹ˆë‹¤. ë”°ë¼ì„œ ìš°ë¦¬ëŠ” ë°€ì§‘í•œ ì‹œê°„ì  ì¶”ë¡ ì„ ìœ„í•´ ì„¤ê³„ëœ ì²« ë²ˆì§¸ ë²¤ì¹˜ë§ˆí¬ì¸ DIVE (Dense Information Video Evaluation)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. DVUë¥¼ ì‹¤ìš©ì ìœ¼ë¡œ ë§Œë“¤ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” Gated Residual Tokenization (GRT)ì„ ì œì‹œí•©ë‹ˆë‹¤. ì´ëŠ” ë‘ ë‹¨ê³„ì˜ í”„ë ˆì„ì›Œí¬ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤: (1) Motion-Compensated Inter-Gated Tokenizationì€ í”½ì…€ ìˆ˜ì¤€ì˜ ëª¨ì…˜ ì¶”ì •ì„ ì‚¬ìš©í•˜ì—¬ í† í°í™” ì¤‘ ì •ì  ì˜ì—­ì„ ê±´ë„ˆë›°ì–´ í† í° ìˆ˜ì™€ ê³„ì‚°ì˜ ì„œë¸Œ-ì„ í˜• ì„±ì¥ì„ ë‹¬ì„±í•©ë‹ˆë‹¤. (2) Semantic-Scene Intra-Tokenization Mergingì€ ì¥ë©´ ë‚´ ì •ì  ì˜ì—­ ê°„ì˜ í† í°ì„ ìœµí•©í•˜ì—¬ ë™ì  ì˜ë¯¸ë¥¼ ìœ ì§€í•˜ë©´ì„œ ì¤‘ë³µì„ ë”ìš± ì¤„ì…ë‹ˆë‹¤. DIVEì— ëŒ€í•œ ì‹¤í—˜ì€ GRTê°€ ë” í° VLLM ê¸°ì¤€ì„ ì„ ëŠ¥ê°€í•˜ë©° FPSì™€ ê¸ì •ì ìœ¼ë¡œ í™•ì¥ë¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŸ¬í•œ ê²°ê³¼ëŠ” ë°€ì§‘í•œ ì‹œê°„ ì •ë³´ì˜ ì¤‘ìš”ì„±ì„ ê°•ì¡°í•˜ë©°, GRTê°€ íš¨ìœ¨ì ì´ê³  í™•ì¥ ê°€ëŠ¥í•œ ê³ FPS ë¹„ë””ì˜¤ ì´í•´ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•¨ì„ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ê³ í•´ìƒë„ ì˜ìƒ ì´í•´ë¥¼ ìœ„í•´ Dense Video Understanding (DVU)ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ì˜ìƒ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(VLLMs)ì€ ë‚®ì€ í”„ë ˆì„ ì†ë„ë¡œ ì¸í•´ ì„¸ë°€í•œ ì‹œê°„ ì •ë³´ë¥¼ ë†“ì¹˜ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, Gated Residual Tokenization (GRT)ì´ë¼ëŠ” ë‘ ë‹¨ê³„ì˜ í”„ë ˆì„ì›Œí¬ë¥¼ ë„ì…í•©ë‹ˆë‹¤. ì²« ë²ˆì§¸ ë‹¨ê³„ëŠ” Motion-Compensated Inter-Gated Tokenizationìœ¼ë¡œ, í”½ì…€ ìˆ˜ì¤€ì˜ ì›€ì§ì„ ì¶”ì •ì„ í†µí•´ ì •ì ì¸ ì˜ì—­ì„ ê±´ë„ˆë›°ì–´ í† í° ìˆ˜ì™€ ê³„ì‚°ëŸ‰ì„ ì¤„ì…ë‹ˆë‹¤. ë‘ ë²ˆì§¸ ë‹¨ê³„ëŠ” Semantic-Scene Intra-Tokenization Mergingìœ¼ë¡œ, ì¥ë©´ ë‚´ ì •ì  ì˜ì—­ì˜ í† í°ì„ ë³‘í•©í•˜ì—¬ ì¤‘ë³µì„ ì¤„ì´ë©´ì„œ ë™ì  ì˜ë¯¸ë¥¼ ë³´ì¡´í•©ë‹ˆë‹¤. DIVEë¼ëŠ” ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ë¥¼ í†µí•´ ì‹¤í—˜í•œ ê²°ê³¼, GRTëŠ” ê¸°ì¡´ VLLMë³´ë‹¤ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì´ë©°, ë†’ì€ FPSì—ì„œë„ íš¨ìœ¨ì ì´ê³  í™•ì¥ ê°€ëŠ¥í•œ ì˜ìƒ ì´í•´ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. í˜„ì¬ì˜ ë¹„ë””ì˜¤ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(VLLMs)ì€ ë‚®ì€ í”„ë ˆì„ ì†ë„ ìƒ˜í”Œë§ì— ì˜ì¡´í•˜ì—¬ ì„¸ë°€í•œ ì‹œê°„ ì •ë³´ë¥¼ ë†“ì¹˜ê³  ìˆë‹¤.

- 2. ê°•ì˜ ì´í•´ì™€ ê°™ì€ ì‘ì—…ì—ì„œëŠ” ê±°ì˜ ëª¨ë“  í”„ë ˆì„ì— ì •ë³´ê°€ ë‚˜íƒ€ë‚˜ë¯€ë¡œ ì •í™•í•œ ì‹œê°„ ì •ë ¬ì´ í•„ìš”í•˜ë‹¤.

- 3. Dense Video Understanding(DVU)ëŠ” ë†’ì€ FPS ë¹„ë””ì˜¤ ì´í•´ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ë©°, í† í°í™” ì‹œê°„ê³¼ í† í° ì˜¤ë²„í—¤ë“œë¥¼ ì¤„ì¸ë‹¤.

- 4. DIVEëŠ” ë°€ë„ ë†’ì€ ì‹œê°„ì  ì¶”ë¡ ì„ ìœ„í•œ ìµœì´ˆì˜ ë²¤ì¹˜ë§ˆí¬ë¡œ, ê¸°ì¡´ ë²¤ì¹˜ë§ˆí¬ì˜ í•œê³„ë¥¼ ê·¹ë³µí•œë‹¤.

- 5. Gated Residual Tokenization(GRT)ëŠ” ì •ì  ì˜ì—­ì„ ê±´ë„ˆë›°ê³ , ì¥ë©´ ë‚´ ì •ì  ì˜ì—­ì˜ í† í°ì„ ìœµí•©í•˜ì—¬ íš¨ìœ¨ì ì¸ ê³ FPS ë¹„ë””ì˜¤ ì´í•´ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤.

---

*Generated on 2025-09-20 07:43:04*