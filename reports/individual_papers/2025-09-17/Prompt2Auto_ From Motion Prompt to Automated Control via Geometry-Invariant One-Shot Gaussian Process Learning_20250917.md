---
keywords:
  - Multi-Modal Learning
  - Reinforcement Learning
  - Few-Shot Learning
category: cs.AI
publish_date: 2025-09-17
arxiv_id:
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 22:47:46.187193",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multi-Modal Learning",
    "Reinforcement Learning",
    "Few-Shot Learning"
  ],
  "rejected_keywords": [
    "Optimization"
  ],
  "similarity_scores": {
    "Multi-Modal Learning": 0.79,
    "Reinforcement Learning": 0.78,
    "Few-Shot Learning": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->


# Prompt2Auto: From Motion Prompt to Automated Control via Geometry-Invariant One-Shot Gaussian Process Learning

**Korean Title:** í”„ë¡¬í”„íŠ¸2ì˜¤í† : ìš´ë™ í”„ë¡¬í”„íŠ¸ë¡œë¶€í„° ê¸°í•˜í•™ ë¶ˆë³€ ì›ìƒ· ê°€ìš°ì‹œì•ˆ í”„ë¡œì„¸ìŠ¤ í•™ìŠµì„ í†µí•œ ìë™í™”ëœ ì œì–´Maintain the academic tone and technical terminology appropriately.

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[digests/daily_digest_20250917|2025-09-17]]        [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Reinforcement Learning|learning from demonstration]], [[keywords/Few-Shot Learning|geometry-invariant one-shot Gaussian process]]
**ğŸš€ Evolved Concepts**: [[keywords/Multi-Modal Learning|multi-skill autonomy]]

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[GWM Towards Scalable Gaussian World Models for Robotic Manipulation]] (80.4% similar)
- [[Learning Multimodal Attention for Manipulating Deformable Objects with Changing States]] (79.5% similar)
- [[Humanoid_Agent_via_Embodied_Chain-of-Action_Reasoning_with_Multimodal_Foundation_Models_for_Zero-Shot_Loco-Manipulation_20250918|Humanoid Agent via Embodied Chain-of-Action Reasoning with Multimodal Foundation Models for Zero-Shot Loco-Manipulation]] (79.4% similar)
- [[$Agent^2$ An Agent-Generates-Agent Framework for Reinforcement Learning Automation]] (79.0% similar)
- [[MAP End-to-End Autonomous Driving with Map-Assisted Planning]] (78.8% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** Zewen Yang, Xiaobing Dai, Dongfa Zhang, Yu Li, Ziyang Meng, Bingkun Huang, Hamid Sadeghian, Sami Haddadin

## ğŸ“„ Abstract (ì›ë¬¸)

Learning from demonstration allows robots to acquire complex skills from
human demonstrations, but conventional approaches often require large datasets
and fail to generalize across coordinate transformations. In this paper, we
propose Prompt2Auto, a geometry-invariant one-shot Gaussian process (GeoGP)
learning framework that enables robots to perform human-guided automated
control from a single motion prompt. A dataset-construction strategy based on
coordinate transformations is introduced that enforces invariance to
translation, rotation, and scaling, while supporting multi-step predictions.
Moreover, GeoGP is robust to variations in the user's motion prompt and
supports multi-skill autonomy. We validate the proposed approach through
numerical simulations with the designed user graphical interface and two
real-world robotic experiments, which demonstrate that the proposed method is
effective, generalizes across tasks, and significantly reduces the
demonstration burden. Project page is available at:
https://prompt2auto.github.io

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

ì‹œë²” í•™ìŠµì„ í†µí•´ ë¡œë´‡ì€ ì¸ê°„ì˜ ì‹œë²”ì„ í†µí•´ ë³µì¡í•œ ê¸°ìˆ ì„ ìŠµë“í•  ìˆ˜ ìˆì§€ë§Œ, ê¸°ì¡´ì˜ ë°©ë²•ë¡ ì€ ì¢…ì¢… í° ë°ì´í„°ì…‹ì„ í•„ìš”ë¡œ í•˜ë©° ì¢Œí‘œ ë³€í™˜ì„ í†µí•´ ì¼ë°˜í™”í•˜ëŠ” ë° ì‹¤íŒ¨í•©ë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ë¡œë´‡ì´ ë‹¨ì¼ ë™ì‘ í”„ë¡¬í”„íŠ¸ë¡œë¶€í„° ì¸ê°„ ì§€ë„ ìë™ ì œì–´ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” geometry-invariant one-shot Gaussian process (GeoGP) í•™ìŠµ í”„ë ˆì„ì›Œí¬ì¸ Prompt2Autoë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì¢Œí‘œ ë³€í™˜ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ë°ì´í„°ì…‹ êµ¬ì¶• ì „ëµì´ ì†Œê°œë˜ì–´ ì´ë™, íšŒì „ ë° ìŠ¤ì¼€ì¼ë§ì— ëŒ€í•œ ë¶ˆë³€ì„±ì„ ê°•ì œí•˜ë©´ì„œ ë‹¤ë‹¨ê³„ ì˜ˆì¸¡ì„ ì§€ì›í•©ë‹ˆë‹¤. ë˜í•œ, GeoGPëŠ” ì‚¬ìš©ìì˜ ë™ì‘ í”„ë¡¬í”„íŠ¸ ë³€í™”ì— ê°•í•˜ë©° ë‹¤ì¤‘ ê¸°ìˆ  ììœ¨ì„±ì„ ì§€ì›í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì œì•ˆëœ ë°©ë²•ë¡ ì„ ì„¤ê³„ëœ ì‚¬ìš©ì ê·¸ë˜í”½ ì¸í„°í˜ì´ìŠ¤ì™€ ë‘ ê°€ì§€ ì‹¤ì œ ë¡œë´‡ ì‹¤í—˜ì„ í†µí•´ ìˆ˜ì¹˜ ì‹œë®¬ë ˆì´ì…˜ì„ í†µí•´ ê²€ì¦í•˜ì˜€ìœ¼ë©°, ì œì•ˆëœ ë°©ë²•ì´ íš¨ê³¼ì ì´ê³  ì‘ì—… ê°„ì— ì¼ë°˜í™”ë˜ë©° ì‹œë²” ë¶€ë‹´ì„ í¬ê²Œ ì¤„ì¸ë‹¤ëŠ” ê²ƒì„ ì…ì¦í•˜ì˜€ìŠµë‹ˆë‹¤. í”„ë¡œì íŠ¸ í˜ì´ì§€ëŠ” ë‹¤ìŒì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤: https://prompt2auto.github.io

## ğŸ“ ìš”ì•½

ë¡œë´‡ì´ ì¸ê°„ì˜ ë°ëª¨ë¡œë¶€í„° ë³µì¡í•œ ê¸°ìˆ ì„ ìŠµë“í•˜ëŠ” í•™ìŠµì€ ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì„ í•„ìš”ë¡œ í•˜ê³  ì¢Œí‘œ ë³€í™˜ì— ëŒ€í•´ ì¼ë°˜í™”í•˜ì§€ ëª»í•˜ëŠ” ë¬¸ì œê°€ ìˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” Prompt2Autoë¼ëŠ” geometry-invariant one-shot Gaussian process (GeoGP) í•™ìŠµ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•œë‹¤. ì´ëŠ” ë¡œë´‡ì´ ë‹¨ì¼ ë™ì‘ í”„ë¡¬í”„íŠ¸ë¡œë¶€í„° ì¸ê°„ ì§€ë„ ì•„ë˜ ìë™ ì œì–´ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆê²Œ í•œë‹¤. ì¢Œí‘œ ë³€í™˜ì— ê¸°ë°˜í•œ ë°ì´í„°ì…‹ êµ¬ì¶• ì „ëµì„ ì†Œê°œí•˜ì—¬ ë²ˆì—­, íšŒì „, ìŠ¤ì¼€ì¼ë§ì— ëŒ€í•œ ë¶ˆë³€ì„±ì„ ê°•í™”í•˜ê³  ë‹¤ë‹¨ê³„ ì˜ˆì¸¡ì„ ì§€ì›í•œë‹¤. ë˜í•œ, GeoGPëŠ” ì‚¬ìš©ìì˜ ë™ì‘ í”„ë¡¬í”„íŠ¸ ë³€í™”ì— ê°•ê±´í•˜ë©° ë‹¤ì¤‘ ê¸°ìˆ  ììœ¨ì„±ì„ ì§€ì›í•œë‹¤. ì œì•ˆëœ ë°©ë²•ì„ ìˆ˜ì¹˜ ì‹œë®¬ë ˆì´ì…˜ê³¼ ë‘ ê°€ì§€ ì‹¤ì œ ë¡œë´‡ ì‹¤í—˜ì„ í†µí•´ ê²€ì¦í•˜ì—¬ íš¨ê³¼ì ì´ë©° ì‘ì—… ê°„ì— ì¼ë°˜í™”ë˜ë©° ë°ëª¨ ë¶€ë‹´ì„ í¬ê²Œ ì¤„ì¸ë‹¤ëŠ” ê²ƒì„ ì…ì¦í•˜ì˜€ë‹¤. í”„ë¡œì íŠ¸ í˜ì´ì§€: https://prompt2auto.github.io

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- ë¡œë´‡ì´ í•œêµ­ì˜ ì§€ë„ì—ì„œ ë³µì¡í•œ ê¸°ìˆ ì„ ìŠµë“í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” í•™ìŠµ ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤.

- í•œ ë²ˆì˜ ë™ì‘ í”„ë¡¬í”„íŠ¸ë¡œ ë¡œë´‡ì´ ì¸ê°„ ì§€ë„ì— ë”°ë¼ ìë™ ì œì–´í•  ìˆ˜ ìˆëŠ” í•™ìŠµ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.

- GeoGPëŠ” ë³€í™˜ì— ë¶ˆë³€í•œ ë°ì´í„° ì§‘í•© êµ¬ì¶• ì „ëµì„ ë„ì…í•˜ì—¬ ë‹¤ì–‘í•œ ì˜ˆì¸¡ì„ ì§€ì›í•©ë‹ˆë‹¤.

- GeoGPëŠ” ì‚¬ìš©ìì˜ ë™ì‘ í”„ë¡¬í”„íŠ¸ ë³€í™”ì— ê°•í•˜ë©° ë‹¤ì¤‘ ê¸°ìˆ  ììœ¨ì„±ì„ ì§€ì›í•©ë‹ˆë‹¤.

- ì œì•ˆëœ ë°©ë²•ì€ íš¨ê³¼ì ì´ë©° ì‘ì—… ê°„ì— ì¼ë°˜í™”ë˜ë©°, ì‹œì—° ë¶€ë‹´ì„ í¬ê²Œ ì¤„ì…ë‹ˆë‹¤.

---

*Generated on 2025-09-18 17:04:42*