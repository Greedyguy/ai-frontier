# Scrub It Out! Erasing Sensitive Memorization in Code Language Models via Machine Unlearning

**Korean Title:** ë¯¼ê°í•œ ì•”ê¸°ë¥¼ ì œê±°í•˜ë¼! ê¸°ê³„ì  ë¹„í•™ìŠµì„ í†µí•œ ì½”ë“œ ì–¸ì–´ ëª¨ë¸ì—ì„œì˜ ë¯¼ê°í•œ ì•”ê¸° ì‚­ì œ

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-17|2025-09-17]] [[authors/Zhaoyang Chu|Zhaoyang Chu]] [[authors/Yao Wan|Yao Wan]] [[authors/Zhikun Zhang|Zhikun Zhang]] [[authors/Di Wang|Di Wang]] [[authors/Zhou Yang|Zhou Yang]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Sensitive Memorization Erasure

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[Reveal and Release_ Iterative LLM Unlearning with Self-generated Data_20250918|Reveal and Release Iterative LLM Unlearning with Self-generated Data]] (84.8% similar)
- [[CUFG_ Curriculum Unlearning Guided by the Forgetting Gradient_20250918|CUFG Curriculum Unlearning Guided by the Forgetting Gradient]] (84.0% similar)
- [[LNE-Blocking_ An Efficient Framework for Contamination Mitigation Evaluation on Large Language Models_20250918|LNE-Blocking An Efficient Framework for Contamination Mitigation Evaluation on Large Language Models]] (82.7% similar)
- [[Enterprise AI Must Enforce Participant-Aware Access Control_20250919|Enterprise AI Must Enforce Participant-Aware Access Control]] (80.6% similar)
- [[Towards a Real-World Aligned Benchmark for Unlearning in Recommender Systems_20250919|Towards a Real-World Aligned Benchmark for Unlearning in Recommender Systems]] (79.6% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** Zhaoyang Chu, Yao Wan, Zhikun Zhang, Di Wang, Zhou Yang, Hongyu Zhang, Pan Zhou, Xuanhua Shi, Hai Jin, David Lo

## ğŸ“„ Abstract (ì›ë¬¸)

While Code Language Models (CLMs) have demonstrated superior performance in
software engineering tasks such as code generation and summarization, recent
empirical studies reveal a critical privacy vulnerability: these models exhibit
unintended memorization of sensitive training data, enabling verbatim
reproduction of confidential information when specifically prompted. To address
this issue, several approaches, including training data de-duplication and
differential privacy augmentation, have been proposed. However, these methods
require full-model retraining for deployed CLMs, which incurs substantial
computational costs. In this paper, we aim to answer the following research
question: Can sensitive information memorized by CLMs be erased effectively and
efficiently?
  We conduct a pioneering investigation into erasing sensitive memorization in
CLMs through machine unlearning - a post-hoc modification method that removes
specific information from trained models without requiring full retraining.
Specifically, we first quantify the memorization risks of sensitive data within
CLM training datasets and curate a high-risk dataset of 50,000 sensitive
memorized samples as unlearning targets. We study two widely used gradient
ascent-based unlearning approaches: the vanilla and constraint-based methods,
and introduce CodeEraser, an advanced variant that selectively unlearns
sensitive memorized segments in code while preserving the structural integrity
and functional correctness of the surrounding code. Extensive experiments on
three families of CLMs, i.e., CodeParrot, CodeGen-Mono, and Qwen2.5-Coder,
validate the effectiveness and efficiency of CodeEraser in erasing targeted
sensitive memorization while maintaining model utility.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

ì½”ë“œ ì–¸ì–´ ëª¨ë¸(CLM)ì€ ì½”ë“œ ìƒì„± ë° ìš”ì•½ê³¼ ê°™ì€ ì†Œí”„íŠ¸ì›¨ì–´ ê³µí•™ ì‘ì—…ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì—ˆì§€ë§Œ, ìµœê·¼ì˜ ì‹¤ì¦ ì—°êµ¬ë“¤ì€ ì¤‘ìš”í•œ ê°œì¸ì •ë³´ ì·¨ì•½ì„±ì„ ë“œëŸ¬ëƒˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ëª¨ë¸ì€ ë¯¼ê°í•œ í›ˆë ¨ ë°ì´í„°ë¥¼ ì˜ë„ì¹˜ ì•Šê²Œ ì•”ê¸°í•˜ì—¬ íŠ¹ì •í•œ ìš”ì²­ ì‹œ ê¸°ë°€ ì •ë³´ë¥¼ ë¬¸ì ê·¸ëŒ€ë¡œ ì¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ í›ˆë ¨ ë°ì´í„° ì¤‘ë³µ ì œê±° ë° ì°¨ë“± ê°œì¸ì •ë³´ ë³´í˜¸ ê°•í™”ì™€ ê°™ì€ ì—¬ëŸ¬ ì ‘ê·¼ë²•ì´ ì œì•ˆë˜ì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ëŸ¬í•œ ë°©ë²•ë“¤ì€ ë°°í¬ëœ CLMì— ëŒ€í•´ ì „ì²´ ëª¨ë¸ ì¬í›ˆë ¨ì„ í•„ìš”ë¡œ í•˜ë©°, ì´ëŠ” ìƒë‹¹í•œ ê³„ì‚° ë¹„ìš©ì„ ì´ˆë˜í•©ë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ë‹¤ìŒì˜ ì—°êµ¬ ì§ˆë¬¸ì— ë‹µí•˜ê³ ì í•©ë‹ˆë‹¤: CLMì´ ì•”ê¸°í•œ ë¯¼ê°í•œ ì •ë³´ë¥¼ íš¨ê³¼ì ì´ê³  íš¨ìœ¨ì ìœ¼ë¡œ ì œê±°í•  ìˆ˜ ìˆëŠ”ê°€? ìš°ë¦¬ëŠ” ê¸°ê³„ í•™ìŠµ ì œê±°ë¥¼ í†µí•´ CLMì˜ ë¯¼ê°í•œ ì•”ê¸°ë¥¼ ì œê±°í•˜ëŠ” ì„ êµ¬ì ì¸ ì—°êµ¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì´ëŠ” í›ˆë ¨ëœ ëª¨ë¸ì—ì„œ íŠ¹ì • ì •ë³´ë¥¼ ì œê±°í•˜ëŠ” ì‚¬í›„ ìˆ˜ì • ë°©ë²•ìœ¼ë¡œ, ì „ì²´ ì¬í›ˆë ¨ì„ ìš”êµ¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. êµ¬ì²´ì ìœ¼ë¡œ, ìš°ë¦¬ëŠ” CLM í›ˆë ¨ ë°ì´í„°ì…‹ ë‚´ ë¯¼ê°í•œ ë°ì´í„°ì˜ ì•”ê¸° ìœ„í—˜ì„ ì •ëŸ‰í™”í•˜ê³ , í•™ìŠµ ì œê±° ëŒ€ìƒìœ¼ë¡œ 50,000ê°œì˜ ë¯¼ê°í•œ ì•”ê¸° ìƒ˜í”Œë¡œ êµ¬ì„±ëœ ê³ ìœ„í—˜ ë°ì´í„°ì…‹ì„ íë ˆì´ì…˜í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ë‘ ê°€ì§€ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ê·¸ë˜ë””ì–¸íŠ¸ ìƒìŠ¹ ê¸°ë°˜ í•™ìŠµ ì œê±° ì ‘ê·¼ë²•ì¸ ê¸°ë³¸ ë°©ë²•ê³¼ ì œì•½ ê¸°ë°˜ ë°©ë²•ì„ ì—°êµ¬í•˜ê³ , ì£¼ë³€ ì½”ë“œì˜ êµ¬ì¡°ì  ë¬´ê²°ì„±ê³¼ ê¸°ëŠ¥ì  ì •í™•ì„±ì„ ìœ ì§€í•˜ë©´ì„œ ì½”ë“œ ë‚´ ë¯¼ê°í•œ ì•”ê¸° ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì„ íƒì ìœ¼ë¡œ ì œê±°í•˜ëŠ” ê³ ê¸‰ ë³€í˜•ì¸ CodeEraserë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. CodeParrot, CodeGen-Mono, Qwen2.5-Coderë¼ëŠ” ì„¸ ê°€ì§€ CLM ê³„ì—´ì— ëŒ€í•œ ê´‘ë²”ìœ„í•œ ì‹¤í—˜ì„ í†µí•´ CodeEraserê°€ ëª¨ë¸ì˜ ìœ ìš©ì„±ì„ ìœ ì§€í•˜ë©´ì„œ ëª©í‘œë¡œ í•œ ë¯¼ê°í•œ ì•”ê¸°ë¥¼ ì œê±°í•˜ëŠ” ë° ìˆì–´ íš¨ê³¼ì ì´ê³  íš¨ìœ¨ì ì„ì„ ê²€ì¦í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì½”ë“œ ì–¸ì–´ ëª¨ë¸(CLM)ì´ ë¯¼ê°í•œ í›ˆë ¨ ë°ì´í„°ë¥¼ ì˜ë„ì¹˜ ì•Šê²Œ ê¸°ì–µí•˜ì—¬ ê¸°ë°€ ì •ë³´ë¥¼ ì¬ìƒì‚°í•  ìˆ˜ ìˆëŠ” í”„ë¼ì´ë²„ì‹œ ì·¨ì•½ì„±ì„ ì§€ì í•©ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ì „ì²´ ëª¨ë¸ ì¬í›ˆë ¨ ì—†ì´ íŠ¹ì • ì •ë³´ë¥¼ ì œê±°í•˜ëŠ” ì‚¬í›„ ìˆ˜ì • ë°©ë²•ì¸ ë¨¸ì‹  ì–¸ëŸ¬ë‹ì„ í™œìš©í•˜ì—¬ ë¯¼ê°í•œ ì •ë³´ì˜ ê¸°ì–µì„ ì§€ìš°ëŠ” ë°©ë²•ì„ ì—°êµ¬í–ˆìŠµë‹ˆë‹¤. ì—°êµ¬ì—ì„œëŠ” 50,000ê°œì˜ ë¯¼ê°í•œ ë°ì´í„°ë¥¼ ëŒ€ìƒìœ¼ë¡œ ë‘ ê°€ì§€ ê·¸ë¼ë””ì–¸íŠ¸ ìƒìŠ¹ ê¸°ë°˜ ì–¸ëŸ¬ë‹ ë°©ë²•ê³¼ CodeEraserë¼ëŠ” ê³ ê¸‰ ë³€í˜• ê¸°ë²•ì„ ì œì•ˆí–ˆìŠµë‹ˆë‹¤. CodeEraserëŠ” ì½”ë“œì˜ êµ¬ì¡°ì  ë¬´ê²°ì„±ê³¼ ê¸°ëŠ¥ì  ì •í™•ì„±ì„ ìœ ì§€í•˜ë©´ì„œ ë¯¼ê°í•œ ê¸°ì–µ ë¶€ë¶„ë§Œ ì„ íƒì ìœ¼ë¡œ ì œê±°í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, CodeEraserëŠ” ëª¨ë¸ì˜ ìœ ìš©ì„±ì„ ìœ ì§€í•˜ë©´ì„œë„ ë¯¼ê°í•œ ê¸°ì–µì„ íš¨ê³¼ì ì´ê³  íš¨ìœ¨ì ìœ¼ë¡œ ì§€ìš¸ ìˆ˜ ìˆìŒì„ ê²€ì¦í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì½”ë“œ ì–¸ì–´ ëª¨ë¸(CLMs)ì€ ë¯¼ê°í•œ í›ˆë ¨ ë°ì´í„°ë¥¼ ì˜ë„ì¹˜ ì•Šê²Œ ê¸°ì–µí•˜ì—¬ íŠ¹ì • í”„ë¡¬í”„íŠ¸ì— ë”°ë¼ ê¸°ë°€ ì •ë³´ë¥¼ ê·¸ëŒ€ë¡œ ì¬ìƒì‚°í•  ìˆ˜ ìˆëŠ” í”„ë¼ì´ë²„ì‹œ ì·¨ì•½ì ì„ ê°€ì§€ê³  ìˆë‹¤.

- 2. ë¯¼ê°í•œ ì •ë³´ì˜ ê¸°ì–µì„ íš¨ê³¼ì ì´ê³  íš¨ìœ¨ì ìœ¼ë¡œ ì§€ìš¸ ìˆ˜ ìˆëŠ”ì§€ë¥¼ ì—°êµ¬í•˜ê¸° ìœ„í•´ ê¸°ê³„ í•™ìŠµ í›„ íŠ¹ì • ì •ë³´ë¥¼ ì œê±°í•˜ëŠ” ë°©ë²•ì¸ 'ê¸°ê³„ ì–¸ëŸ¬ë‹'ì„ ì¡°ì‚¬í•˜ì˜€ë‹¤.

- 3. CodeEraserëŠ” ì½”ë“œì˜ êµ¬ì¡°ì  ì™„ì „ì„±ê³¼ ê¸°ëŠ¥ì  ì •í™•ì„±ì„ ìœ ì§€í•˜ë©´ì„œ ë¯¼ê°í•œ ê¸°ì–µ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì„ íƒì ìœ¼ë¡œ ì œê±°í•˜ëŠ” ê³ ê¸‰ ê¸°ë²•ì´ë‹¤.

- 4. CodeEraserëŠ” CodeParrot, CodeGen-Mono, Qwen2.5-Coder ë“± ì„¸ ê°€ì§€ CLM ê³„ì—´ì—ì„œ ê´‘ë²”ìœ„í•œ ì‹¤í—˜ì„ í†µí•´ ëª©í‘œë¡œ í•œ ë¯¼ê°í•œ ê¸°ì–µì„ ì§€ìš°ë©´ì„œë„ ëª¨ë¸ì˜ ìœ ìš©ì„±ì„ ìœ ì§€í•˜ëŠ” ë° íš¨ê³¼ì ì´ê³  íš¨ìœ¨ì ì„ì„ ì…ì¦í•˜ì˜€ë‹¤.

---

*Generated on 2025-09-20 09:36:00*