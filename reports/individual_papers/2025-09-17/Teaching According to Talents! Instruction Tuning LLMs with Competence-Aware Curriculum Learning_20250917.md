---
keywords:
  - Large Language Models
  - Instruction Tuning
  - Curriculum Learning
category: cs.AI
publish_date: 2025-09-17
arxiv_id:
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 22:44:26.751544",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Models",
    "Instruction Tuning",
    "Curriculum Learning"
  ],
  "rejected_keywords": [
    "Competence-Aware Curriculum"
  ],
  "similarity_scores": {
    "Large Language Models": 0.8,
    "Instruction Tuning": 0.79,
    "Curriculum Learning": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->


# Teaching According to Talents! Instruction Tuning LLMs with Competence-Aware Curriculum Learning

**Korean Title:** 재능에 따른 가르침! 능력 인식 교육과정 학습을 통한 LLMs의 지도 조정

## 📋 메타데이터

**Links**: [[digests/daily_digest_20250917|2025-09-17]]        [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Large Language Models|Large Language Models]]
**⚡ Unique Technical**: [[keywords/Curriculum Learning|Curriculum Learning]]
**🚀 Evolved Concepts**: [[keywords/Instruction Tuning|Instruction Tuning]]

## 🔗 유사한 논문
- [[Forget What You Know about LLMs Evaluations -- LLMs are Like a Chameleon]] (82.6% similar)
- [[CyberLLMInstruct A Pseudo-malicious Dataset Revealing Safety-performance Trade-offs in Cyber Security LLM Fine-tuning]] (80.8% similar)
- [[MAgICoRe Multi-Agent, Iterative, Coarse-to-Fine Refinement for Reasoning]] (79.9% similar)
- [[LLM Chatbot-Creation Approaches]] (79.8% similar)
- [[Omni-CLST Error-aware Curriculum Learning with guided Selective chain-of-Thought for audio question answering]] (79.6% similar)

## 📋 저자 정보

**Authors:** Yangning Li, Tingwei Lu, Yinghui Li, Yankai Chen, Wei-Chieh Huang, Wenhao Jiang, Hui Wang, Hai-Tao Zheng, Philip S. Yu

## 📄 Abstract (원문)

Efficient instruction tuning aims to enhance the ultimate performance of
large language models (LLMs) trained on a given instruction dataset. Curriculum
learning as a typical data organization strategy has shown preliminary
effectiveness in instruction tuning. However, current curriculum tuning methods
suffer from the curriculum rigidity, since they rely solely on static heuristic
difficulty metrics. These methods fail to adapt to the evolving capabilities of
models during training, resulting in a fixed and potentially sub-optimal
learning trajectory. To address the issue, Competence-Aware Multi-Perspective
cUrriculum inStruction tuning framework termed CAMPUS is proposed. CAMPUS
offers several advantages: (1) Dynamic selection for sub-curriculum. (2)
Competency-aware adjustment to the curriculum schedule. (3) Multiple
difficulty-based scheduling. Extensive experiments prove the superior
performance of CAMPUS, compared to other state-of-the-art baselines for
efficient instruction tuning.

## 🔍 Abstract (한글 번역)

효율적인 교육 튜닝은 주어진 교육 데이터셋에서 훈련된 대규모 언어 모델 (LLMs)의 최종 성능을 향상시키는 것을 목표로 합니다. 전형적인 데이터 구성 전략으로서의 커리큘럼 학습은 교육 튜닝에서 초기 효과를 보여주었습니다. 그러나 현재의 커리큘럼 튜닝 방법은 정적 휴리스틱 난이도 지표에만 의존하기 때문에 커리큘럼의 엄격함에 문제가 있습니다. 이러한 방법들은 훈련 중 모델의 진화하는 능력에 적응하지 못하며, 고정된 그리고 잠재적으로 최적이 아닌 학습 궤적을 낳습니다. 이 문제를 해결하기 위해, CAMPUS라고 불리는 Competence-Aware Multi-Perspective cUrriculum inStruction tuning 프레임워크가 제안되었습니다. CAMPUS는 여러 가지 장점을 제공합니다: (1) 하위 커리큘럼에 대한 동적 선택. (2) 역량 인식을 통한 커리큘럼 일정 조정. (3) 다양한 난이도 기반 일정 설정. 포괄적인 실험은 효율적인 교육 튜닝을 위한 CAMPUS의 우수한 성능을 입증하였습니다.

## 📝 요약

대규모 언어 모델의 최종 성능을 향상시키기 위한 효율적인 지도 튜닝은 중요하다. 현재의 커리큘럼 튜닝 방법은 정적 휴리스틱 난이도 지표에만 의존하여 모델의 진화하는 능력에 적응하지 못하고 고정된 학습 궤적을 유발한다. 이 문제를 해결하기 위해 CAMPUS 프레임워크가 제안되었다. CAMPUS는 하위 커리큘럼의 동적 선택, 역량 인식적인 커리큘럼 일정 조정, 다양한 난이도 기반 일정을 제공하여 탁월한 성능을 보여준다. 다양한 실험 결과, CAMPUS가 효율적인 지도 튜닝을 위한 다른 최첨단 기준선에 비해 우수한 성능을 보여준다.

## 🎯 주요 포인트

- 대규모 언어 모델의 성능 향상을 위해 효율적인 지시 튜닝이 중요하다.

- 기존의 커리큘럼 튜닝 방법은 고정된 어려움 지표에 의존하여 유연성이 부족하다.

- CAMPUS 프레임워크는 동적 선택과 능력 인식을 통해 우수한 성능을 보여준다.

---

*Generated on 2025-09-18 17:05:28*