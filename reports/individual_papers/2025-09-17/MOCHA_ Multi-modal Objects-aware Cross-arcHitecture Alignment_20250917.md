---
keywords:
  - MOCHA
  - Vision-Language Models
  - Few-Shot Learning
category: cs.AI
publish_date: 2025-09-17
arxiv_id:
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 22:51:35.121509",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "MOCHA",
    "Vision-Language Models",
    "Few-Shot Learning"
  ],
  "rejected_keywords": [
    "Knowledge Distillation",
    "Object Detection"
  ],
  "similarity_scores": {
    "MOCHA": 0.85,
    "Vision-Language Models": 0.78,
    "Few-Shot Learning": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->

# MOCHA: Multi-modal Objects-aware Cross-arcHitecture Alignment

**Korean Title:** MOCHA: ë‹¤ì¤‘ ëª¨ë‹¬ ê°ì²´ ì¸ì‹ êµì°¨ ì•„í‚¤í…ì²˜ ì •ë ¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[digests/daily_digest_20250917|2025-09-17]]        [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Few-Shot Learning|few-shot regimes]]
**âš¡ Unique Technical**: [[keywords/MOCHA|MOCHA]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Models|vision-language teacher]]

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[Multimodal Knowledge Distillation for Egocentric Action Recognition Robust to Missing Modalities_20250919|Multimodal Knowledge Distillation for Egocentric Action Recognition Robust to Missing Modalities]] (84.0% similar)
- [[Lost in Translation Vocabulary Alignment for Source-Free Domain Adaptation in Open-Vocabulary Semantic Segmentation_20250918|Lost in Translation Vocabulary Alignment for Source-Free Domain Adaptation in Open-Vocabulary Semantic Segmentation]] (82.8% similar)
- [[VSE-MOT_ Multi-Object Tracking in Low-Quality Video Scenes Guided by Visual Semantic Enhancement_20250918|VSE-MOT Multi-Object Tracking in Low-Quality Video Scenes Guided by Visual Semantic Enhancement]] (81.2% similar)
- [[Internalizing Self-Consistency in Language Models_ Multi-Agent Consensus Alignment_20250919|Internalizing Self-Consistency in Language Models Multi-Agent Consensus Alignment]] (81.0% similar)
- [[Reconstruction Alignment Improves Unified Multimodal Models_20250919|Reconstruction Alignment Improves Unified Multimodal Models]] (80.7% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** Elena Camuffo, Francesco Barbato, Mete Ozay, Simone Milani, Umberto Michieli

## ğŸ“„ Abstract (ì›ë¬¸)

We introduce MOCHA (Multi-modal Objects-aware Cross-arcHitecture Alignment),
a knowledge distillation approach that transfers region-level multimodal
semantics from a large vision-language teacher (e.g., LLaVa) into a lightweight
vision-only object detector student (e.g., YOLO). A translation module maps
student features into a joint space, where the training of the student and
translator is guided by a dual-objective loss that enforces both local
alignment and global relational consistency. Unlike prior approaches focused on
dense or global alignment, MOCHA operates at the object level, enabling
efficient transfer of semantics without modifying the teacher or requiring
textual input at inference. We validate our method across four personalized
detection benchmarks under few-shot regimes. Results show consistent gains over
baselines, with a +10.1 average score improvement. Despite its compact
architecture, MOCHA reaches performance on par with larger multimodal models,
proving its suitability for real-world deployment.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

MOCHA(Multi-modal Objects-aware Cross-arcHitecture Alignment)ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ì´ëŠ” ëŒ€í˜• ë¹„ì „-ì–¸ì–´ êµì‚¬ ëª¨ë¸(ì˜ˆ: LLaVa)ë¡œë¶€í„° ì§€ì—­ ìˆ˜ì¤€ì˜ ë‹¤ì¤‘ ëª¨ë‹¬ ì˜ë¯¸ë¥¼ ê²½ëŸ‰ ë¹„ì „ ì „ìš© ê°ì²´ íƒì§€ í•™ìƒ ëª¨ë¸(ì˜ˆ: YOLO)ë¡œ ì „ì´í•˜ëŠ” ì§€ì‹ ì¦ë¥˜ ì ‘ê·¼ë²•ì…ë‹ˆë‹¤. ë²ˆì—­ ëª¨ë“ˆì€ í•™ìƒ ëª¨ë¸ì˜ íŠ¹ì§•ì„ ê³µë™ ê³µê°„ìœ¼ë¡œ ë§¤í•‘í•˜ë©°, í•™ìƒ ëª¨ë¸ê³¼ ë²ˆì—­ê¸°ì˜ í•™ìŠµì€ ì§€ì—­ ì •ë ¬ê³¼ ì „ì—­ ê´€ê³„ ì¼ê´€ì„±ì„ ëª¨ë‘ ê°•í™”í•˜ëŠ” ì´ì¤‘ ëª©í‘œ ì†ì‹¤ì— ì˜í•´ ì•ˆë‚´ë©ë‹ˆë‹¤. ì´ì „ì˜ ë°€ì§‘ ë˜ëŠ” ì „ì—­ ì •ë ¬ì— ì¤‘ì ì„ ë‘” ì ‘ê·¼ë²•ê³¼ ë‹¬ë¦¬, MOCHAëŠ” ê°ì²´ ìˆ˜ì¤€ì—ì„œ ì‘ë™í•˜ì—¬ êµì‚¬ë¥¼ ìˆ˜ì •í•˜ê±°ë‚˜ ì¶”ë¡  ì‹œ í…ìŠ¤íŠ¸ ì…ë ¥ì„ ìš”êµ¬í•˜ì§€ ì•Šê³ ë„ íš¨ìœ¨ì ì¸ ì˜ë¯¸ ì „ì´ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì†Œìˆ˜ ìƒ· ì²´ì œ í•˜ì—ì„œ ë„¤ ê°€ì§€ ê°œì¸í™”ëœ íƒì§€ ë²¤ì¹˜ë§ˆí¬ë¥¼ í†µí•´ ìš°ë¦¬ì˜ ë°©ë²•ì„ ê²€ì¦í–ˆìŠµë‹ˆë‹¤. ê²°ê³¼ëŠ” ê¸°ì¤€ì„  ëŒ€ë¹„ ì¼ê´€ëœ í–¥ìƒì„ ë³´ì—¬ì£¼ë©°, í‰ê·  ì ìˆ˜ê°€ +10.1 ì¦ê°€í–ˆìŠµë‹ˆë‹¤. MOCHAëŠ” ì»´íŒ©íŠ¸í•œ ì•„í‚¤í…ì²˜ì—ë„ ë¶ˆêµ¬í•˜ê³ , ë” í° ë‹¤ì¤‘ ëª¨ë‹¬ ëª¨ë¸ê³¼ ë™ë“±í•œ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ì—¬ ì‹¤ì œ í™˜ê²½ì—ì„œì˜ ë°°í¬ì— ì í•©í•¨ì„ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

MOCHAëŠ” ëŒ€í˜• ë¹„ì „-ì–¸ì–´ ëª¨ë¸ì˜ ì§€ì—­ ìˆ˜ì¤€ ë©€í‹°ëª¨ë‹¬ ì˜ë¯¸ë¥¼ ê²½ëŸ‰ ë¹„ì „ ì „ìš© ê°ì²´ íƒì§€ ëª¨ë¸ë¡œ ì „ì´í•˜ëŠ” ì§€ì‹ ì¦ë¥˜ ê¸°ë²•ì…ë‹ˆë‹¤. í•™ìƒ ëª¨ë¸ì˜ íŠ¹ì§•ì„ ê³µë™ ê³µê°„ìœ¼ë¡œ ë§¤í•‘í•˜ì—¬ ì§€ì—­ ì •ë ¬ê³¼ ì „ì—­ ê´€ê³„ ì¼ê´€ì„±ì„ ë™ì‹œì— ìœ ì§€í•˜ëŠ” ì´ì¤‘ ëª©í‘œ ì†ì‹¤ì„ í†µí•´ í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤. ê¸°ì¡´ ë°©ë²•ê³¼ ë‹¬ë¦¬ ê°ì²´ ìˆ˜ì¤€ì—ì„œ ì˜ë¯¸ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì „ì´í•˜ë©°, êµì‚¬ ëª¨ë¸ ìˆ˜ì •ì´ë‚˜ ì¶”ë¡  ì‹œ í…ìŠ¤íŠ¸ ì…ë ¥ì´ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë„¤ ê°€ì§€ ê°œì¸í™”ëœ íƒì§€ ë²¤ì¹˜ë§ˆí¬ì—ì„œ MOCHAëŠ” ê¸°ì¡´ ë°©ë²• ëŒ€ë¹„ í‰ê·  10.1ì  í–¥ìƒëœ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë©°, ì»´íŒ©íŠ¸í•œ êµ¬ì¡°ì„ì—ë„ ëŒ€í˜• ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ê³¼ ìœ ì‚¬í•œ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ì—¬ ì‹¤ì œ ì ìš©ì— ì í•©í•¨ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. MOCHAëŠ” ëŒ€í˜• ë¹„ì „-ì–¸ì–´ ëª¨ë¸ì˜ ì§€ì—­ ìˆ˜ì¤€ ë©€í‹°ëª¨ë‹¬ ì˜ë¯¸ë¥¼ ê²½ëŸ‰ ë¹„ì „ ì „ìš© ê°ì²´ íƒì§€ ëª¨ë¸ë¡œ ì „ì´í•˜ëŠ” ì§€ì‹ ì¦ë¥˜ ì ‘ê·¼ë²•ì…ë‹ˆë‹¤.

- 2. í•™ìƒ ëª¨ë¸ê³¼ ë²ˆì—­ ëª¨ë“ˆì€ ì§€ì—­ ì •ë ¬ê³¼ ì „ì—­ ê´€ê³„ ì¼ê´€ì„±ì„ ë™ì‹œì— ê°•í™”í•˜ëŠ” ì´ì¤‘ ëª©í‘œ ì†ì‹¤ì„ í†µí•´ í›ˆë ¨ë©ë‹ˆë‹¤.

- 3. MOCHAëŠ” ê°ì²´ ìˆ˜ì¤€ì—ì„œ ì‘ë™í•˜ì—¬ êµì‚¬ ëª¨ë¸ì„ ìˆ˜ì •í•˜ê±°ë‚˜ ì¶”ë¡  ì‹œ í…ìŠ¤íŠ¸ ì…ë ¥ì´ í•„ìš”í•˜ì§€ ì•Šìœ¼ë©´ì„œë„ íš¨ìœ¨ì ì¸ ì˜ë¯¸ ì „ì´ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.

- 4. ë„¤ ê°€ì§€ ë§ì¶¤í˜• íƒì§€ ë²¤ì¹˜ë§ˆí¬ì—ì„œ MOCHAëŠ” ê¸°ì¡´ ëª¨ë¸ ëŒ€ë¹„ í‰ê·  10.1ì  í–¥ìƒëœ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤.

- 5. MOCHAëŠ” ì»´íŒ©íŠ¸í•œ êµ¬ì¡°ì—ë„ ë¶ˆêµ¬í•˜ê³  ëŒ€í˜• ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ê³¼ ë™ë“±í•œ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ì—¬ ì‹¤ì œ í™˜ê²½ì—ì„œì˜ ì í•©ì„±ì„ ì…ì¦í•©ë‹ˆë‹¤.

---

*Generated on 2025-09-20 09:20:01*