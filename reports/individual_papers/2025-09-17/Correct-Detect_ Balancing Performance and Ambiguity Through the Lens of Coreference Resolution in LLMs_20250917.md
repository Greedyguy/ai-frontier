---
keywords:
  - Large Language Models
  - Coreference Resolution
  - Natural Language Processing
category: cs.AI
publish_date: 2025-09-17
arxiv_id:
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 22:58:09.495164",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Models",
    "Coreference Resolution",
    "Natural Language Processing"
  ],
  "rejected_keywords": [
    "Semantic Ambiguity"
  ],
  "similarity_scores": {
    "Large Language Models": 0.8,
    "Coreference Resolution": 0.78,
    "Natural Language Processing": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->

# Correct-Detect: Balancing Performance and Ambiguity Through the Lens of Coreference Resolution in LLMs

**Korean Title:** Correct-Detect: ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì—ì„œì˜ ìƒí˜¸ ì°¸ì¡° í•´ê²°ì„ í†µí•œ ì„±ëŠ¥ê³¼ ëª¨í˜¸ì„±ì˜ ê· í˜• ì¡°ì •

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[digests/daily_digest_20250917|2025-09-17]]       [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸŒ Broad Technical**: [[keywords/Natural Language Processing|Natural Language Processing]]
**âš¡ Unique Technical**: [[keywords/Coreference Resolution|Coreference Resolution]]
**ğŸš€ Evolved Concepts**: [[keywords/Large Language Models|Large Language Models]]

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[DetectAnyLLM_ Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models_20250919|DetectAnyLLM Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models]] (85.1% similar)
- [[Decoupled Proxy Alignment_ Mitigating Language Prior Conflict for Multimodal Alignment in MLLM_20250919|Decoupled Proxy Alignment Mitigating Language Prior Conflict for Multimodal Alignment in MLLM]] (82.8% similar)
- [[Adding LLMs to the psycholinguistic norming toolbox_ A practical guide to getting the most out of human ratings_20250919|Adding LLMs to the psycholinguistic norming toolbox A practical guide to getting the most out of human ratings]] (82.8% similar)
- [[Zero-Shot LLMs in Human-in-the-Loop RL_ Replacing Human Feedback for Reward Shaping_20250919|Zero-Shot LLMs in Human-in-the-Loop RL Replacing Human Feedback for Reward Shaping]] (82.4% similar)
- [[Large Language Model probabilities cannot distinguish between possible and impossible language_20250919|Large Language Model probabilities cannot distinguish between possible and impossible language]] (82.4% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** Amber Shore, Russell Scheinberg, Ameeta Agrawal, So Young Lee

## ğŸ“„ Abstract (ì›ë¬¸)

Large Language Models (LLMs) are intended to reflect human linguistic
competencies. But humans have access to a broad and embodied context, which is
key in detecting and resolving linguistic ambiguities, even in isolated text
spans. A foundational case of semantic ambiguity is found in the task of
coreference resolution: how is a pronoun related to an earlier person mention?
This capability is implicit in nearly every downstream task, and the presence
of ambiguity at this level can alter performance significantly. We show that
LLMs can achieve good performance with minimal prompting in both coreference
disambiguation and the detection of ambiguity in coreference, however, they
cannot do both at the same time. We present the CORRECT-DETECT trade-off:
though models have both capabilities and deploy them implicitly, successful
performance balancing these two abilities remains elusive.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ ì¸ê°„ì˜ ì–¸ì–´ ëŠ¥ë ¥ì„ ë°˜ì˜í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì¸ê°„ì€ ë„“ê³  êµ¬ì²´í™”ëœ ë§¥ë½ì— ì ‘ê·¼í•  ìˆ˜ ìˆìœ¼ë©°, ì´ëŠ” ê³ ë¦½ëœ í…ìŠ¤íŠ¸ ë²”ìœ„ì—ì„œë„ ì–¸ì–´ì  ëª¨í˜¸ì„±ì„ ê°ì§€í•˜ê³  í•´ê²°í•˜ëŠ” ë° í•µì‹¬ì ì…ë‹ˆë‹¤. ì˜ë¯¸ì  ëª¨í˜¸ì„±ì˜ ê·¼ë³¸ì ì¸ ì‚¬ë¡€ëŠ” ëŒ€ëª…ì‚¬ í•´ì†Œ ì‘ì—…ì—ì„œ ë°œê²¬ë©ë‹ˆë‹¤: ëŒ€ëª…ì‚¬ê°€ ì´ì „ì— ì–¸ê¸‰ëœ ì‚¬ëŒê³¼ ì–´ë–»ê²Œ ê´€ë ¨ë˜ëŠ”ê°€? ì´ ëŠ¥ë ¥ì€ ê±°ì˜ ëª¨ë“  í•˜ìœ„ ì‘ì—…ì— ì•”ë¬µì ìœ¼ë¡œ í¬í•¨ë˜ì–´ ìˆìœ¼ë©°, ì´ ìˆ˜ì¤€ì—ì„œì˜ ëª¨í˜¸ì„±ì€ ì„±ëŠ¥ì— ìƒë‹¹í•œ ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” LLMì´ ëŒ€ëª…ì‚¬ ëª¨í˜¸ì„± í•´ì†Œì™€ ëŒ€ëª…ì‚¬ ëª¨í˜¸ì„± ê°ì§€ ëª¨ë‘ì—ì„œ ìµœì†Œí•œì˜ í”„ë¡¬í”„íŠ¸ë¡œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë‹¬ì„±í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì£¼ì§€ë§Œ, ë‘ ì‘ì—…ì„ ë™ì‹œì— ìˆ˜í–‰í•  ìˆ˜ëŠ” ì—†ìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ìš°ë¦¬ëŠ” CORRECT-DETECT ìƒì¶© ê´€ê³„ë¥¼ ì œì‹œí•©ë‹ˆë‹¤: ëª¨ë¸ì´ ë‘ ê°€ì§€ ëŠ¥ë ¥ì„ ëª¨ë‘ ê°€ì§€ê³  ì´ë¥¼ ì•”ë¬µì ìœ¼ë¡œ ì‚¬ìš©í•˜ì§€ë§Œ, ì´ ë‘ ëŠ¥ë ¥ì„ ê· í˜• ìˆê²Œ ì„±ê³µì ìœ¼ë¡œ ìˆ˜í–‰í•˜ëŠ” ê²ƒì€ ì—¬ì „íˆ ì–´ë ¤ìš´ ê³¼ì œì…ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ ì¸ê°„ì˜ ì–¸ì–´ ëŠ¥ë ¥ì„ ë°˜ì˜í•˜ë ¤ í•˜ì§€ë§Œ, ì¸ê°„ì€ ì–¸ì–´ì  ëª¨í˜¸ì„±ì„ í•´ê²°í•˜ëŠ” ë° ì¤‘ìš”í•œ ê´‘ë²”ìœ„í•˜ê³  êµ¬ì²´ì ì¸ ë§¥ë½ì— ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ëª¨í˜¸ì„±ì˜ ëŒ€í‘œì ì¸ ì‚¬ë¡€ëŠ” ëŒ€ëª…ì‚¬ì™€ ì´ì „ ì¸ë¬¼ ì–¸ê¸‰ ê°„ì˜ ê´€ê³„ë¥¼ íŒŒì•…í•˜ëŠ” 'ê³µì§€ í•´ê²°' ì‘ì—…ì—ì„œ ë‚˜íƒ€ë‚©ë‹ˆë‹¤. ì—°êµ¬ ê²°ê³¼, LLMì€ ìµœì†Œí•œì˜ í”„ë¡¬í”„íŠ¸ë¡œ ê³µì§€ ëª¨í˜¸ì„± í•´ì†Œì™€ ëª¨í˜¸ì„± íƒì§€ì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ì§€ë§Œ, ë‘ ì‘ì—…ì„ ë™ì‹œì— ìˆ˜í–‰í•˜ëŠ” ë°ëŠ” í•œê³„ê°€ ìˆìŒì„ ë°í˜”ìŠµë‹ˆë‹¤. ì´ë¥¼ 'CORRECT-DETECT' íŠ¸ë ˆì´ë“œì˜¤í”„ë¡œ ì •ì˜í•˜ë©°, ë‘ ëŠ¥ë ¥ì„ ê· í˜• ìˆê²Œ ë°œíœ˜í•˜ëŠ” ê²ƒì€ ì—¬ì „íˆ ì–´ë ¤ìš´ ê³¼ì œì„ì„ ì œì‹œí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì€ ì¸ê°„ì˜ ì–¸ì–´ ëŠ¥ë ¥ì„ ë°˜ì˜í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆì§€ë§Œ, ì¸ê°„ì€ ë„“ê³  ì²´í™”ëœ ë§¥ë½ì— ì ‘ê·¼í•  ìˆ˜ ìˆì–´ ì–¸ì–´ì  ëª¨í˜¸ì„±ì„ ê°ì§€í•˜ê³  í•´ê²°í•˜ëŠ” ë° ìœ ë¦¬í•˜ë‹¤.

- 2. ì˜ë¯¸ì  ëª¨í˜¸ì„±ì˜ ê¸°ë³¸ ì‚¬ë¡€ëŠ” ëŒ€ëª…ì‚¬ì™€ ì´ì „ ì¸ë¬¼ ì–¸ê¸‰ ê°„ì˜ ê´€ê³„ë¥¼ íŒŒì•…í•˜ëŠ” 'ê³µì§€ í•´ê²°' ì‘ì—…ì—ì„œ ë°œê²¬ëœë‹¤.

- 3. ê³µì§€ í•´ê²°ì˜ ëª¨í˜¸ì„±ì€ ê±°ì˜ ëª¨ë“  í•˜ìœ„ ì‘ì—…ì— ì•”ë¬µì ìœ¼ë¡œ í¬í•¨ë˜ì–´ ìˆìœ¼ë©°, ì´ ìˆ˜ì¤€ì—ì„œì˜ ëª¨í˜¸ì„±ì€ ì„±ëŠ¥ì— í° ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆë‹¤.

- 4. LLMsëŠ” ìµœì†Œí•œì˜ í”„ë¡¬í”„íŠ¸ë¡œ ê³µì§€ ëª¨í˜¸ì„± í•´ì†Œì™€ ëª¨í˜¸ì„± ê°ì§€ì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë°œíœ˜í•  ìˆ˜ ìˆì§€ë§Œ, ë‘ ì‘ì—…ì„ ë™ì‹œì— ìˆ˜í–‰í•  ìˆ˜ëŠ” ì—†ë‹¤.

- 5. CORRECT-DETECT ìƒì¶© ê´€ê³„ë¥¼ ì œì‹œí•˜ë©°, ë‘ ëŠ¥ë ¥ì„ ê· í˜• ìˆê²Œ ë°œíœ˜í•˜ëŠ” ì„±ê³µì ì¸ ì„±ëŠ¥ì€ ì—¬ì „íˆ ì–´ë ¤ìš´ ê³¼ì œë¡œ ë‚¨ì•„ ìˆë‹¤.

---

*Generated on 2025-09-20 05:56:00*