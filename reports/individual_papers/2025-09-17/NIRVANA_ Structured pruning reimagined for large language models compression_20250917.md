---
keywords:
  - Large Language Models
  - Attention Mechanism
  - Structured Pruning
category: cs.AI
publish_date: 2025-09-17
arxiv_id:
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 22:49:59.100943",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Models",
    "Attention Mechanism",
    "Structured Pruning"
  ],
  "rejected_keywords": [
    "Neural Tangent Kernel",
    "Optimization"
  ],
  "similarity_scores": {
    "Large Language Models": 0.9,
    "Attention Mechanism": 0.78,
    "Structured Pruning": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->

# NIRVANA: Structured pruning reimagined for large language models compression

**Korean Title:** NIRVANA: ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ì••ì¶•ì„ ìœ„í•œ êµ¬ì¡°ì  í”„ë£¨ë‹ì˜ ì¬êµ¬ì„±

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[digests/daily_digest_20250917|2025-09-17]]       [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Attention Mechanism|Attention Mechanism]]
**âš¡ Unique Technical**: [[keywords/Structured Pruning|Structured Pruning]]
**ğŸš€ Evolved Concepts**: [[keywords/Large Language Models|Large Language Models]]

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[Value-Guided KV Compression for LLMs via Approximated CUR Decomposition_20250919|Value-Guided KV Compression for LLMs via Approximated CUR Decomposition]] (81.0% similar)
- [[LNE-Blocking_ An Efficient Framework for Contamination Mitigation Evaluation on Large Language Models_20250918|LNE-Blocking An Efficient Framework for Contamination Mitigation Evaluation on Large Language Models]] (79.9% similar)
- [[LLM-I_ LLMs are Naturally Interleaved Multimodal Creators_20250918|LLM-I LLMs are Naturally Interleaved Multimodal Creators]] (79.8% similar)
- [[A Novel Compression Framework for YOLOv8_ Achieving Real-Time Aerial Object Detection on Edge Devices via Structured Pruning and Channel-Wise Distillation_20250918|A Novel Compression Framework for YOLOv8 Achieving Real-Time Aerial Object Detection on Edge Devices via Structured Pruning and Channel-Wise Distillation]] (79.8% similar)
- [[TDRM_ Smooth Reward Models with Temporal Difference for LLM RL and Inference_20250918|TDRM Smooth Reward Models with Temporal Difference for LLM RL and Inference]] (79.6% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** Mengting Ai, Tianxin Wei, Sirui Chen, Jingrui He

## ğŸ“„ Abstract (ì›ë¬¸)

Structured pruning of large language models (LLMs) offers substantial
efficiency improvements by removing entire hidden units, yet current approaches
often suffer from significant performance degradation, particularly in
zero-shot settings, and necessitate costly recovery techniques such as
supervised fine-tuning (SFT) or adapter insertion. To address these critical
shortcomings, we introduce NIRVANA, a novel pruning method explicitly designed
to balance immediate zero-shot accuracy preservation with robust fine-tuning
capability. Leveraging a first-order saliency criterion derived from the Neural
Tangent Kernel under Adam optimization dynamics, NIRVANA provides a
theoretically grounded pruning strategy that respects essential model training
behaviors. To further address the unique challenges posed by structured
pruning, NIRVANA incorporates an adaptive sparsity allocation mechanism across
layers and modules (attention vs. MLP), which adjusts pruning intensity between
modules in a globally balanced manner. Additionally, to mitigate the high
sensitivity of pruning decisions to calibration data quality, we propose a
simple yet effective KL divergence-based calibration data selection strategy,
ensuring more reliable and task-agnostic pruning outcomes. Comprehensive
experiments conducted on Llama3, Qwen, and T5 models demonstrate that NIRVANA
outperforms existing structured pruning methods under equivalent sparsity
constraints, providing a theoretically sound and practical approach to LLM
compression. The code is available at
https://github.com/iDEA-iSAIL-Lab-UIUC/NIRVANA.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ êµ¬ì¡°ì  ê°€ì§€ì¹˜ê¸°ëŠ” ì „ì²´ ì€ë‹‰ ìœ ë‹›ì„ ì œê±°í•¨ìœ¼ë¡œì¨ ìƒë‹¹í•œ íš¨ìœ¨ì„± í–¥ìƒì„ ì œê³µí•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ í˜„ì¬ì˜ ì ‘ê·¼ ë°©ì‹ì€ íŠ¹íˆ ì œë¡œìƒ· ì„¤ì •ì—ì„œ ì„±ëŠ¥ ì €í•˜ë¥¼ ê²ªëŠ” ê²½ìš°ê°€ ë§ìœ¼ë©°, ê°ë…ëœ ë¯¸ì„¸ ì¡°ì •(SFT) ë˜ëŠ” ì–´ëŒ‘í„° ì‚½ì…ê³¼ ê°™ì€ ë¹„ìš©ì´ ë§ì´ ë“œëŠ” ë³µêµ¬ ê¸°ìˆ ì„ í•„ìš”ë¡œ í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì¤‘ìš”í•œ ë‹¨ì ì„ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ì¦‰ê°ì ì¸ ì œë¡œìƒ· ì •í™•ë„ ë³´ì¡´ê³¼ ê°•ë ¥í•œ ë¯¸ì„¸ ì¡°ì • ëŠ¥ë ¥ì„ ê· í˜• ìˆê²Œ ì„¤ê³„í•œ ìƒˆë¡œìš´ ê°€ì§€ì¹˜ê¸° ë°©ë²•ì¸ NIRVANAë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. Adam ìµœì í™” ë™ì—­í•™ í•˜ì—ì„œ ì‹ ê²½ ì ‘ì„  ì»¤ë„ì—ì„œ íŒŒìƒëœ ì¼ì°¨ ì¤‘ìš”ë„ ê¸°ì¤€ì„ í™œìš©í•˜ì—¬, NIRVANAëŠ” í•„ìˆ˜ì ì¸ ëª¨ë¸ í›ˆë ¨ í–‰ë™ì„ ì¡´ì¤‘í•˜ëŠ” ì´ë¡ ì ìœ¼ë¡œ ê·¼ê±° ìˆëŠ” ê°€ì§€ì¹˜ê¸° ì „ëµì„ ì œê³µí•©ë‹ˆë‹¤. êµ¬ì¡°ì  ê°€ì§€ì¹˜ê¸°ê°€ ì œê¸°í•˜ëŠ” ë…íŠ¹í•œ ê³¼ì œë¥¼ ì¶”ê°€ë¡œ í•´ê²°í•˜ê¸° ìœ„í•´, NIRVANAëŠ” ê³„ì¸µ ë° ëª¨ë“ˆ(ì£¼ì˜ vs. MLP) ê°„ì˜ ì ì‘í˜• í¬ì†Œì„± í• ë‹¹ ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•©í•˜ì—¬ ëª¨ë“ˆ ê°„ ê°€ì§€ì¹˜ê¸° ê°•ë„ë¥¼ ì „ì—­ì ìœ¼ë¡œ ê· í˜• ìˆê²Œ ì¡°ì •í•©ë‹ˆë‹¤. ë˜í•œ, ê°€ì§€ì¹˜ê¸° ê²°ì •ì´ ë³´ì • ë°ì´í„° í’ˆì§ˆì— ë§¤ìš° ë¯¼ê°í•œ ë¬¸ì œë¥¼ ì™„í™”í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ë‹¨ìˆœí•˜ì§€ë§Œ íš¨ê³¼ì ì¸ KL ë°œì‚° ê¸°ë°˜ ë³´ì • ë°ì´í„° ì„ íƒ ì „ëµì„ ì œì•ˆí•˜ì—¬ ë³´ë‹¤ ì‹ ë¢°í•  ìˆ˜ ìˆê³  ì‘ì—…ì— êµ¬ì• ë°›ì§€ ì•ŠëŠ” ê°€ì§€ì¹˜ê¸° ê²°ê³¼ë¥¼ ë³´ì¥í•©ë‹ˆë‹¤. Llama3, Qwen, T5 ëª¨ë¸ì—ì„œ ìˆ˜í–‰ëœ ì¢…í•©ì ì¸ ì‹¤í—˜ì€ NIRVANAê°€ ë™ì¼í•œ í¬ì†Œì„± ì œì•½ í•˜ì—ì„œ ê¸°ì¡´ì˜ êµ¬ì¡°ì  ê°€ì§€ì¹˜ê¸° ë°©ë²•ì„ ëŠ¥ê°€í•˜ë©°, LLM ì••ì¶•ì— ëŒ€í•œ ì´ë¡ ì ìœ¼ë¡œ íƒ€ë‹¹í•˜ê³  ì‹¤ìš©ì ì¸ ì ‘ê·¼ ë°©ì‹ì„ ì œê³µí•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì½”ë“œëŠ” https://github.com/iDEA-iSAIL-Lab-UIUC/NIRVANAì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ êµ¬ì¡°ì  í”„ë£¨ë‹ì€ íš¨ìœ¨ì„±ì„ ë†’ì´ì§€ë§Œ, ì„±ëŠ¥ ì €í•˜ì™€ ë³µêµ¬ ë¹„ìš© ë¬¸ì œë¥¼ ë™ë°˜í•©ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” NIRVANAë¼ëŠ” ìƒˆë¡œìš´ í”„ë£¨ë‹ ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ Neural Tangent Kernelì„ í™œìš©í•œ saliency ê¸°ì¤€ì„ í†µí•´ ì´ë¡ ì ìœ¼ë¡œ íƒ€ë‹¹í•œ í”„ë£¨ë‹ ì „ëµì„ ì œê³µí•©ë‹ˆë‹¤. ë˜í•œ, ê³„ì¸µê³¼ ëª¨ë“ˆ ê°„ì˜ ì ì‘ì  í¬ì†Œì„± í• ë‹¹ ë©”ì»¤ë‹ˆì¦˜ì„ ë„ì…í•˜ì—¬ ê· í˜• ì¡íŒ í”„ë£¨ë‹ì„ êµ¬í˜„í•©ë‹ˆë‹¤. KL ë°œì‚° ê¸°ë°˜ì˜ êµì • ë°ì´í„° ì„ íƒ ì „ëµì„ í†µí•´ í”„ë£¨ë‹ ê²°ì •ì˜ ë¯¼ê°ì„±ì„ ì™„í™”í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, NIRVANAëŠ” ê¸°ì¡´ ë°©ë²•ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. NIRVANAëŠ” ì¦‰ê°ì ì¸ zero-shot ì •í™•ë„ ìœ ì§€ì™€ ê°•ë ¥í•œ ë¯¸ì„¸ ì¡°ì • ëŠ¥ë ¥ì„ ê· í˜• ìˆê²Œ ì œê³µí•˜ëŠ” ìƒˆë¡œìš´ ê°€ì§€ì¹˜ê¸° ë°©ë²•ì…ë‹ˆë‹¤.

- 2. NIRVANAëŠ” Adam ìµœì í™” ë™ë ¥í•™ í•˜ì˜ Neural Tangent Kernelì—ì„œ ìœ ë„ëœ 1ì°¨ ì¤‘ìš”ë„ ê¸°ì¤€ì„ í™œìš©í•˜ì—¬ ì´ë¡ ì ìœ¼ë¡œ ê·¼ê±° ìˆëŠ” ê°€ì§€ì¹˜ê¸° ì „ëµì„ ì œê³µí•©ë‹ˆë‹¤.

- 3. ì ì‘í˜• í¬ì†Œì„± í• ë‹¹ ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´ NIRVANAëŠ” ë ˆì´ì–´ì™€ ëª¨ë“ˆ(ì˜ˆ: ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ vs. MLP) ê°„ì˜ ê°€ì§€ì¹˜ê¸° ê°•ë„ë¥¼ ì „ì—­ì ìœ¼ë¡œ ê· í˜• ìˆê²Œ ì¡°ì •í•©ë‹ˆë‹¤.

- 4. KL ë°œì‚° ê¸°ë°˜ì˜ êµì • ë°ì´í„° ì„ íƒ ì „ëµì„ ì œì•ˆí•˜ì—¬ ê°€ì§€ì¹˜ê¸° ê²°ì •ì˜ ë¯¼ê°ì„±ì„ ì¤„ì´ê³ , ë³´ë‹¤ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì‘ì—… ë¬´ê´€í•œ ê°€ì§€ì¹˜ê¸° ê²°ê³¼ë¥¼ ë³´ì¥í•©ë‹ˆë‹¤.

- 5. Llama3, Qwen, T5 ëª¨ë¸ì— ëŒ€í•œ ì‹¤í—˜ì—ì„œ NIRVANAëŠ” ê¸°ì¡´ì˜ êµ¬ì¡°ì  ê°€ì§€ì¹˜ê¸° ë°©ë²•ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì´ë©°, LLM ì••ì¶•ì— ëŒ€í•œ ì´ë¡ ì ì´ê³  ì‹¤ìš©ì ì¸ ì ‘ê·¼ë²•ì„ ì œê³µí•©ë‹ˆë‹¤.

---

*Generated on 2025-09-20 07:40:33*