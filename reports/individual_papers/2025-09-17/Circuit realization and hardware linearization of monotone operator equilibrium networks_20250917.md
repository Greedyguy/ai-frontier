# Circuit realization and hardware linearization of monotone operator equilibrium networks

**Korean Title:** ë‹¨ì¡° ì—°ì‚°ì í‰í˜• ë„¤íŠ¸ì›Œí¬ì˜ íšŒë¡œ êµ¬í˜„ ë° í•˜ë“œì›¨ì–´ ì„ í˜•í™”

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-17|2025-09-17]] [[authors/Thomas Chaffey|Thomas Chaffey]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Hardware Linearization

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[A Neural Network for the Identical Kuramoto Equation_ Architectural Considerations and Performance Evaluation_20250917|A Neural Network for the Identical Kuramoto Equation Architectural Considerations and Performance Evaluation]] (80.6% similar)
- [[Low-rank surrogate modeling and stochastic zero-order optimization for training of neural networks with black-box layers_20250918|Low-rank surrogate modeling and stochastic zero-order optimization for training of neural networks with black-box layers]] (78.5% similar)
- [[MaRVIn_ A Cross-Layer Mixed-Precision RISC-V Framework for DNN Inference, from ISA Extension to Hardware Acceleration_20250919|MaRVIn A Cross-Layer Mixed-Precision RISC-V Framework for DNN Inference, from ISA Extension to Hardware Acceleration]] (77.4% similar)
- [[Learning Graph from Smooth Signals under Partial Observation_ A Robustness Analysis_20250918|Learning Graph from Smooth Signals under Partial Observation A Robustness Analysis]] (76.8% similar)
- [[GraphTorque_ Torque-Driven Rewiring Graph Neural Network_20250918|GraphTorque Torque-Driven Rewiring Graph Neural Network]] (76.7% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** Thomas Chaffey

## ğŸ“„ Abstract (ì›ë¬¸)

It is shown that the port behavior of a resistor-diode network corresponds to
the solution of a ReLU monotone operator equilibrium network (a neural network
in the limit of infinite depth), giving a parsimonious construction of a neural
network in analog hardware. We furthermore show that the gradient of such a
circuit can be computed directly in hardware, using a procedure we call
hardware linearization. This allows the network to be trained in hardware,
which we demonstrate with a device-level circuit simulation. We extend the
results to cascades of resistor-diode networks, which can be used to implement
feedforward and other asymmetric networks. We finally show that different
nonlinear elements give rise to different activation functions, and introduce
the novel diode ReLU which is induced by a non-ideal diode model.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

ì €í•­-ë‹¤ì´ì˜¤ë“œ ë„¤íŠ¸ì›Œí¬ì˜ í¬íŠ¸ ë™ì‘ì´ ReLU ë‹¨ì¡° ì—°ì‚°ì í‰í˜• ë„¤íŠ¸ì›Œí¬(ë¬´í•œ ê¹Šì´ì˜ í•œê³„ì—ì„œì˜ ì‹ ê²½ë§)ì˜ í•´ì™€ ì¼ì¹˜í•¨ì„ ë³´ì—¬ì£¼ë©°, ì´ëŠ” ì•„ë‚ ë¡œê·¸ í•˜ë“œì›¨ì–´ì—ì„œ ì‹ ê²½ë§ì˜ ê°„ê²°í•œ êµ¬ì„±ì„ ì œê³µí•©ë‹ˆë‹¤. ë˜í•œ, ì´ëŸ¬í•œ íšŒë¡œì˜ ê¸°ìš¸ê¸°ë¥¼ í•˜ë“œì›¨ì–´ì—ì„œ ì§ì ‘ ê³„ì‚°í•  ìˆ˜ ìˆëŠ” ì ˆì°¨ì¸ í•˜ë“œì›¨ì–´ ì„ í˜•í™”ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë„¤íŠ¸ì›Œí¬ë¥¼ í•˜ë“œì›¨ì–´ì—ì„œ í•™ìŠµí•  ìˆ˜ ìˆìœ¼ë©°, ìš°ë¦¬ëŠ” ì´ë¥¼ ì†Œì ìˆ˜ì¤€ì˜ íšŒë¡œ ì‹œë®¬ë ˆì´ì…˜ì„ í†µí•´ ì…ì¦í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ê²°ê³¼ë¥¼ ì €í•­-ë‹¤ì´ì˜¤ë“œ ë„¤íŠ¸ì›Œí¬ì˜ ê³„ë‹¨ì‹ êµ¬ì¡°ë¡œ í™•ì¥í•˜ì—¬ í”¼ë“œí¬ì›Œë“œ ë° ê¸°íƒ€ ë¹„ëŒ€ì¹­ ë„¤íŠ¸ì›Œí¬ë¥¼ êµ¬í˜„í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ, ì„œë¡œ ë‹¤ë¥¸ ë¹„ì„ í˜• ìš”ì†Œê°€ ì„œë¡œ ë‹¤ë¥¸ í™œì„±í™” í•¨ìˆ˜ë¥¼ ìœ ë„í•¨ì„ ë³´ì—¬ì£¼ê³ , ë¹„ì´ìƒì ì¸ ë‹¤ì´ì˜¤ë“œ ëª¨ë¸ì— ì˜í•´ ìœ ë„ë˜ëŠ” ìƒˆë¡œìš´ ë‹¤ì´ì˜¤ë“œ ReLUë¥¼ ì†Œê°œí•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì €í•­-ë‹¤ì´ì˜¤ë“œ ë„¤íŠ¸ì›Œí¬ì˜ í¬íŠ¸ ë™ì‘ì´ ReLU ë‹¨ì¡° ì—°ì‚°ì í‰í˜• ë„¤íŠ¸ì›Œí¬(ë¬´í•œ ê¹Šì´ì˜ ì‹ ê²½ë§)ì˜ í•´ì™€ ëŒ€ì‘í•¨ì„ ë³´ì—¬ì£¼ë©°, ì´ë¥¼ í†µí•´ ì•„ë‚ ë¡œê·¸ í•˜ë“œì›¨ì–´ì—ì„œ ì‹ ê²½ë§ì„ ê°„ê²°í•˜ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆìŒì„ ì œì‹œí•©ë‹ˆë‹¤. ë˜í•œ, í•˜ë“œì›¨ì–´ ì„ í˜•í™”ë¼ëŠ” ì ˆì°¨ë¥¼ í†µí•´ ì´ëŸ¬í•œ íšŒë¡œì˜ ê¸°ìš¸ê¸°ë¥¼ í•˜ë“œì›¨ì–´ì—ì„œ ì§ì ‘ ê³„ì‚°í•  ìˆ˜ ìˆì–´, í•˜ë“œì›¨ì–´ì—ì„œ ë„¤íŠ¸ì›Œí¬ë¥¼ í›ˆë ¨í•  ìˆ˜ ìˆìŒì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤. ì´ ê²°ê³¼ë¥¼ ì €í•­-ë‹¤ì´ì˜¤ë“œ ë„¤íŠ¸ì›Œí¬ì˜ ì—°ì‡„ë¡œ í™•ì¥í•˜ì—¬ í”¼ë“œí¬ì›Œë“œ ë° ë¹„ëŒ€ì¹­ ë„¤íŠ¸ì›Œí¬ êµ¬í˜„ì— í™œìš©í•  ìˆ˜ ìˆìŒì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ, ë‹¤ì–‘í•œ ë¹„ì„ í˜• ìš”ì†Œê°€ ì„œë¡œ ë‹¤ë¥¸ í™œì„±í™” í•¨ìˆ˜ë¥¼ ìœ ë„í•˜ë©°, ë¹„ì´ìƒì ì¸ ë‹¤ì´ì˜¤ë“œ ëª¨ë¸ì— ì˜í•´ ìœ ë„ë˜ëŠ” ìƒˆë¡œìš´ ë‹¤ì´ì˜¤ë“œ ReLUë¥¼ ì†Œê°œí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì €í•­-ë‹¤ì´ì˜¤ë“œ ë„¤íŠ¸ì›Œí¬ì˜ í¬íŠ¸ ë™ì‘ì´ ReLU ë‹¨ì¡° ì—°ì‚°ì í‰í˜• ë„¤íŠ¸ì›Œí¬ì˜ í•´ì™€ ì¼ì¹˜í•¨ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

- 2. í•˜ë“œì›¨ì–´ ì„ í˜•í™” ì ˆì°¨ë¥¼ í†µí•´ ì´ëŸ¬í•œ íšŒë¡œì˜ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ í•˜ë“œì›¨ì–´ì—ì„œ ì§ì ‘ ê³„ì‚°í•  ìˆ˜ ìˆìŒì„ ì¦ëª…í–ˆìŠµë‹ˆë‹¤.

- 3. í•˜ë“œì›¨ì–´ì—ì„œ ë„¤íŠ¸ì›Œí¬ë¥¼ í•™ìŠµì‹œí‚¬ ìˆ˜ ìˆìœ¼ë©°, ì´ë¥¼ ì¥ì¹˜ ìˆ˜ì¤€ì˜ íšŒë¡œ ì‹œë®¬ë ˆì´ì…˜ìœ¼ë¡œ ì…ì¦í–ˆìŠµë‹ˆë‹¤.

- 4. ì €í•­-ë‹¤ì´ì˜¤ë“œ ë„¤íŠ¸ì›Œí¬ì˜ ì—°ì‡„ë¥¼ í™•ì¥í•˜ì—¬ í”¼ë“œí¬ì›Œë“œ ë° ë¹„ëŒ€ì¹­ ë„¤íŠ¸ì›Œí¬ë¥¼ êµ¬í˜„í•  ìˆ˜ ìˆìŒì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

- 5. ë‹¤ì–‘í•œ ë¹„ì„ í˜• ìš”ì†Œê°€ ì„œë¡œ ë‹¤ë¥¸ í™œì„±í™” í•¨ìˆ˜ë¥¼ ìœ ë„í•˜ë©°, ë¹„ì´ìƒì ì¸ ë‹¤ì´ì˜¤ë“œ ëª¨ë¸ì— ì˜í•´ ìœ ë„ëœ ìƒˆë¡œìš´ ë‹¤ì´ì˜¤ë“œ ReLUë¥¼ ì†Œê°œí–ˆìŠµë‹ˆë‹¤.

---

*Generated on 2025-09-20 09:31:51*