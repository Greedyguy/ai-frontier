# Exploring Fine-Tuning of Large Audio Language Models for Spoken Language Understanding under Limited Speech data

**Korean Title:** ì œí•œëœ ìŒì„± ë°ì´í„°ë¥¼ í†µí•œ êµ¬ì–´ ì´í•´ë¥¼ ìœ„í•œ ëŒ€í˜• ì˜¤ë””ì˜¤ ì–¸ì–´ ëª¨ë¸ì˜ ë¯¸ì„¸ ì¡°ì • íƒêµ¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.LG|cs.LG]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Cross-lingual Spoken Language Understanding

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Middo_ Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning_20250919|Middo Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning]] (85.2% similar)
- [[2025-09-22/SightSound-R1_ Cross-Modal Reasoning Distillation from Vision to Audio Language Models_20250922|SightSound-R1 Cross-Modal Reasoning Distillation from Vision to Audio Language Models]] (84.6% similar)
- [[2025-09-19/Controlling Language Difficulty in Dialogues with Linguistic Features_20250919|Controlling Language Difficulty in Dialogues with Linguistic Features]] (84.6% similar)
- [[2025-09-22/Session-Level Spoken Language Assessment with a Multimodal Foundation Model via Multi-Target Learning_20250922|Session-Level Spoken Language Assessment with a Multimodal Foundation Model via Multi-Target Learning]] (84.5% similar)
- [[2025-09-22/Exploring Polyglot Harmony_ On Multilingual Data Allocation for Large Language Models Pretraining_20250922|Exploring Polyglot Harmony On Multilingual Data Allocation for Large Language Models Pretraining]] (83.7% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15389v1 Announce Type: cross 
Abstract: Large Audio Language Models (LALMs) have emerged as powerful tools for speech-related tasks but remain underexplored for fine-tuning, especially with limited speech data. To bridge this gap, we systematically examine how different fine-tuning schemes including text-only, direct mixing, and curriculum learning affect spoken language understanding (SLU), focusing on scenarios where text-label pairs are abundant while paired speech-label data are limited. Results show that LALMs already achieve competitive performance with text-only fine-tuning, highlighting their strong generalization ability. Adding even small amounts of speech data (2-5%) yields substantial further gains, with curriculum learning particularly effective under scarce data. In cross-lingual SLU, combining source-language speech data with target-language text and minimal target-language speech data enables effective adaptation. Overall, this study provides practical insights into the LALM fine-tuning under realistic data constraints.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15389v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ëŒ€í˜• ì˜¤ë””ì˜¤ ì–¸ì–´ ëª¨ë¸(LALM)ì€ ìŒì„± ê´€ë ¨ ì‘ì—…ì—ì„œ ê°•ë ¥í•œ ë„êµ¬ë¡œ ë¶€ìƒí–ˆì§€ë§Œ, íŠ¹íˆ ì œí•œëœ ìŒì„± ë°ì´í„°ë¡œ ì„¸ë¶€ ì¡°ì •í•˜ëŠ” ë° ìˆì–´ì„œëŠ” ì¶©ë¶„íˆ íƒêµ¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ê²©ì°¨ë¥¼ í•´ì†Œí•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” í…ìŠ¤íŠ¸ ì „ìš©, ì§ì ‘ í˜¼í•©, ì»¤ë¦¬í˜ëŸ¼ í•™ìŠµì„ í¬í•¨í•œ ë‹¤ì–‘í•œ ì„¸ë¶€ ì¡°ì • ë°©ì‹ì´ ìŒì„± ì–¸ì–´ ì´í•´(SLU)ì— ì–´ë–»ê²Œ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ ì²´ê³„ì ìœ¼ë¡œ ì¡°ì‚¬í•©ë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” í…ìŠ¤íŠ¸-ë ˆì´ë¸” ìŒì´ í’ë¶€í•˜ì§€ë§Œ ìŒì„±-ë ˆì´ë¸” ìŒ ë°ì´í„°ê°€ ì œí•œëœ ì‹œë‚˜ë¦¬ì˜¤ì— ì¤‘ì ì„ ë‘¡ë‹ˆë‹¤. ê²°ê³¼ëŠ” LALMì´ ì´ë¯¸ í…ìŠ¤íŠ¸ ì „ìš© ì„¸ë¶€ ì¡°ì •ìœ¼ë¡œ ê²½ìŸë ¥ ìˆëŠ” ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ì—¬ ê°•ë ¥í•œ ì¼ë°˜í™” ëŠ¥ë ¥ì„ ê°•ì¡°í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì†ŒëŸ‰ì˜ ìŒì„± ë°ì´í„°(2-5%)ë¥¼ ì¶”ê°€í•˜ë©´ ìƒë‹¹í•œ ì¶”ê°€ ì´ë“ì´ ìˆìœ¼ë©°, íŠ¹íˆ ë°ì´í„°ê°€ ë¶€ì¡±í•œ ê²½ìš° ì»¤ë¦¬í˜ëŸ¼ í•™ìŠµì´ íš¨ê³¼ì ì…ë‹ˆë‹¤. êµì°¨ ì–¸ì–´ SLUì—ì„œëŠ” ì†ŒìŠ¤ ì–¸ì–´ ìŒì„± ë°ì´í„°ë¥¼ íƒ€ê²Ÿ ì–¸ì–´ í…ìŠ¤íŠ¸ ë° ìµœì†Œí•œì˜ íƒ€ê²Ÿ ì–¸ì–´ ìŒì„± ë°ì´í„°ì™€ ê²°í•©í•˜ì—¬ íš¨ê³¼ì ì¸ ì ì‘ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ì „ë°˜ì ìœ¼ë¡œ, ì´ ì—°êµ¬ëŠ” í˜„ì‹¤ì ì¸ ë°ì´í„° ì œì•½ í•˜ì—ì„œ LALM ì„¸ë¶€ ì¡°ì •ì— ëŒ€í•œ ì‹¤ì§ˆì ì¸ í†µì°°ë ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€ê·œëª¨ ì˜¤ë””ì˜¤ ì–¸ì–´ ëª¨ë¸(LALMs)ì˜ ë¯¸ì„¸ ì¡°ì • ë°©ë²•ë¡ ì„ ì—°êµ¬í•˜ì—¬, íŠ¹íˆ ì œí•œëœ ìŒì„± ë°ì´í„° ìƒí™©ì—ì„œì˜ ì„±ëŠ¥ í–¥ìƒì„ íƒêµ¬í•©ë‹ˆë‹¤. í…ìŠ¤íŠ¸ë§Œì„ ì‚¬ìš©í•œ ë¯¸ì„¸ ì¡°ì •ì—ì„œë„ ê²½ìŸë ¥ ìˆëŠ” ì„±ëŠ¥ì„ ë³´ì´ë©°, ì†ŒëŸ‰ì˜ ìŒì„± ë°ì´í„°ë¥¼ ì¶”ê°€í•˜ë©´ ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤. ì»¤ë¦¬í˜ëŸ¼ í•™ìŠµì€ ë°ì´í„°ê°€ ë¶€ì¡±í•œ ìƒí™©ì—ì„œ íŠ¹íˆ íš¨ê³¼ì ì…ë‹ˆë‹¤. ë˜í•œ, êµì°¨ ì–¸ì–´ SLUì—ì„œëŠ” ì†ŒìŠ¤ ì–¸ì–´ì˜ ìŒì„± ë°ì´í„°ì™€ íƒ€ê²Ÿ ì–¸ì–´ì˜ í…ìŠ¤íŠ¸ ë° ìµœì†Œí•œì˜ íƒ€ê²Ÿ ì–¸ì–´ ìŒì„± ë°ì´í„°ë¥¼ ê²°í•©í•˜ì—¬ íš¨ê³¼ì ì¸ ì ì‘ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” í˜„ì‹¤ì ì¸ ë°ì´í„° ì œì•½ í•˜ì—ì„œ LALMì˜ ë¯¸ì„¸ ì¡°ì •ì— ëŒ€í•œ ì‹¤ì§ˆì ì¸ í†µì°°ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì˜¤ë””ì˜¤ ì–¸ì–´ ëª¨ë¸(LALMs)ì€ í…ìŠ¤íŠ¸ë§Œì„ ì‚¬ìš©í•œ ë¯¸ì„¸ ì¡°ì •ìœ¼ë¡œë„ ê²½ìŸë ¥ ìˆëŠ” ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ë©°, ê°•ë ¥í•œ ì¼ë°˜í™” ëŠ¥ë ¥ì„ ì…ì¦í•œë‹¤.

- 2. ì†ŒëŸ‰ì˜ ìŒì„± ë°ì´í„°(2-5%)ë¥¼ ì¶”ê°€í•˜ë©´ ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë˜ë©°, ì»¤ë¦¬í˜ëŸ¼ í•™ìŠµì´ íŠ¹íˆ ë°ì´í„°ê°€ ë¶€ì¡±í•œ ìƒí™©ì—ì„œ íš¨ê³¼ì ì´ë‹¤.

- 3. êµì°¨ ì–¸ì–´ SLUì—ì„œ ì†ŒìŠ¤ ì–¸ì–´ì˜ ìŒì„± ë°ì´í„°ì™€ íƒ€ê²Ÿ ì–¸ì–´ì˜ í…ìŠ¤íŠ¸ ë° ìµœì†Œí•œì˜ íƒ€ê²Ÿ ì–¸ì–´ ìŒì„± ë°ì´í„°ë¥¼ ê²°í•©í•˜ë©´ íš¨ê³¼ì ì¸ ì ì‘ì´ ê°€ëŠ¥í•˜ë‹¤.

- 4. ë³¸ ì—°êµ¬ëŠ” í˜„ì‹¤ì ì¸ ë°ì´í„° ì œì•½ ì¡°ê±´ í•˜ì—ì„œ LALMì˜ ë¯¸ì„¸ ì¡°ì •ì— ëŒ€í•œ ì‹¤ì§ˆì ì¸ í†µì°°ì„ ì œê³µí•œë‹¤.

---

*Generated on 2025-09-22 15:37:45*