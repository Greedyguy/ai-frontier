# Exploring Fine-Tuning of Large Audio Language Models for Spoken Language Understanding under Limited Speech data

**Korean Title:** 제한된 음성 데이터를 통한 구어 이해를 위한 대형 오디오 언어 모델의 미세 조정 탐구

## 📋 메타데이터

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.LG|cs.LG]]

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Cross-lingual Spoken Language Understanding

## 🔗 유사한 논문
- [[2025-09-19/Middo_ Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning_20250919|Middo Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning]] (85.2% similar)
- [[2025-09-22/SightSound-R1_ Cross-Modal Reasoning Distillation from Vision to Audio Language Models_20250922|SightSound-R1 Cross-Modal Reasoning Distillation from Vision to Audio Language Models]] (84.6% similar)
- [[2025-09-19/Controlling Language Difficulty in Dialogues with Linguistic Features_20250919|Controlling Language Difficulty in Dialogues with Linguistic Features]] (84.6% similar)
- [[2025-09-22/Session-Level Spoken Language Assessment with a Multimodal Foundation Model via Multi-Target Learning_20250922|Session-Level Spoken Language Assessment with a Multimodal Foundation Model via Multi-Target Learning]] (84.5% similar)
- [[2025-09-22/Exploring Polyglot Harmony_ On Multilingual Data Allocation for Large Language Models Pretraining_20250922|Exploring Polyglot Harmony On Multilingual Data Allocation for Large Language Models Pretraining]] (83.7% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.15389v1 Announce Type: cross 
Abstract: Large Audio Language Models (LALMs) have emerged as powerful tools for speech-related tasks but remain underexplored for fine-tuning, especially with limited speech data. To bridge this gap, we systematically examine how different fine-tuning schemes including text-only, direct mixing, and curriculum learning affect spoken language understanding (SLU), focusing on scenarios where text-label pairs are abundant while paired speech-label data are limited. Results show that LALMs already achieve competitive performance with text-only fine-tuning, highlighting their strong generalization ability. Adding even small amounts of speech data (2-5%) yields substantial further gains, with curriculum learning particularly effective under scarce data. In cross-lingual SLU, combining source-language speech data with target-language text and minimal target-language speech data enables effective adaptation. Overall, this study provides practical insights into the LALM fine-tuning under realistic data constraints.

## 🔍 Abstract (한글 번역)

arXiv:2509.15389v1 발표 유형: 교차  
초록: 대형 오디오 언어 모델(LALM)은 음성 관련 작업에서 강력한 도구로 부상했지만, 특히 제한된 음성 데이터로 세부 조정하는 데 있어서는 충분히 탐구되지 않았습니다. 이러한 격차를 해소하기 위해, 우리는 텍스트 전용, 직접 혼합, 커리큘럼 학습을 포함한 다양한 세부 조정 방식이 음성 언어 이해(SLU)에 어떻게 영향을 미치는지 체계적으로 조사합니다. 이 연구는 텍스트-레이블 쌍이 풍부하지만 음성-레이블 쌍 데이터가 제한된 시나리오에 중점을 둡니다. 결과는 LALM이 이미 텍스트 전용 세부 조정으로 경쟁력 있는 성능을 달성하여 강력한 일반화 능력을 강조함을 보여줍니다. 소량의 음성 데이터(2-5%)를 추가하면 상당한 추가 이득이 있으며, 특히 데이터가 부족한 경우 커리큘럼 학습이 효과적입니다. 교차 언어 SLU에서는 소스 언어 음성 데이터를 타겟 언어 텍스트 및 최소한의 타겟 언어 음성 데이터와 결합하여 효과적인 적응을 가능하게 합니다. 전반적으로, 이 연구는 현실적인 데이터 제약 하에서 LALM 세부 조정에 대한 실질적인 통찰력을 제공합니다.

## 📝 요약

이 논문은 대규모 오디오 언어 모델(LALMs)의 미세 조정 방법론을 연구하여, 특히 제한된 음성 데이터 상황에서의 성능 향상을 탐구합니다. 텍스트만을 사용한 미세 조정에서도 경쟁력 있는 성능을 보이며, 소량의 음성 데이터를 추가하면 성능이 크게 향상됩니다. 커리큘럼 학습은 데이터가 부족한 상황에서 특히 효과적입니다. 또한, 교차 언어 SLU에서는 소스 언어의 음성 데이터와 타겟 언어의 텍스트 및 최소한의 타겟 언어 음성 데이터를 결합하여 효과적인 적응이 가능합니다. 이 연구는 현실적인 데이터 제약 하에서 LALM의 미세 조정에 대한 실질적인 통찰을 제공합니다.

## 🎯 주요 포인트

- 1. 대형 오디오 언어 모델(LALMs)은 텍스트만을 사용한 미세 조정으로도 경쟁력 있는 성능을 보여주며, 강력한 일반화 능력을 입증한다.

- 2. 소량의 음성 데이터(2-5%)를 추가하면 성능이 크게 향상되며, 커리큘럼 학습이 특히 데이터가 부족한 상황에서 효과적이다.

- 3. 교차 언어 SLU에서 소스 언어의 음성 데이터와 타겟 언어의 텍스트 및 최소한의 타겟 언어 음성 데이터를 결합하면 효과적인 적응이 가능하다.

- 4. 본 연구는 현실적인 데이터 제약 조건 하에서 LALM의 미세 조정에 대한 실질적인 통찰을 제공한다.

---

*Generated on 2025-09-22 15:37:45*