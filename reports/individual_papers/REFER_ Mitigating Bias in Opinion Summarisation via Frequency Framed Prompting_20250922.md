# REFER: Mitigating Bias in Opinion Summarisation via Frequency Framed Prompting

**Korean Title:** 의견 요약에서의 편향 완화를 위한 빈도 기반 프롬프트: REFER

## 📋 메타데이터

## 📋 메타데이터

**Links**: [[reports/digests/daily_digest_20250922|2025-09-22]] [[keywords/evolved/Fairness in Opinion Summarisation|Fairness in Opinion Summarisation]] [[keywords/specific/Frequency Based Representations|Frequency Based Representations]] [[keywords/broad/Large Language Models|Large Language Models]] [[keywords/broad/Natural Language Processing|Natural Language Processing]] [[keywords/unique/Frequency Framed Prompting|Frequency Framed Prompting]] [[categories/cs.CL|cs.CL]] [[2025-09-22/DivLogicEval_ A Framework for Benchmarking Logical Reasoning Evaluation in Large Language Models_20250922|DivLogicEval: A Framework for Benchmarking Logical Reasoning Evaluation in Large Language Models]] (85.5% similar) [[2025-09-17/Simulating a Bias Mitigation Scenario in Large Language Models_20250917|Simulating a Bias Mitigation Scenario in Large Language Models]] (85.3% similar) [[2025-09-22/Re-FRAME the Meeting Summarization SCOPE_ Fact-Based Summarization and Personalization via Questions_20250922|Re-FRAME the Meeting Summarization SCOPE: Fact-Based Summarization and Personalization via Questions]] (84.5% similar)

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Fairness in Opinion Summarisation
**🔗 Specific Connectable**: Frequency Framed Prompting
**🔬 Broad Technical**: Large Language Models, Natural Language Processing
**⭐ Unique Technical**: REFER
## 🔗 유사한 논문
- [[2025-09-22/DivLogicEval_ A Framework for Benchmarking Logical Reasoning Evaluation in Large Language Models_20250922|DivLogicEval A Framework for Benchmarking Logical Reasoning Evaluation in Large Language Models]] (85.5% similar)
- [[2025-09-17/Simulating a Bias Mitigation Scenario in Large Language Models_20250917|Simulating a Bias Mitigation Scenario in Large Language Models]] (85.3% similar)
- [[2025-09-22/Re-FRAME the Meeting Summarization SCOPE_ Fact-Based Summarization and Personalization via Questions_20250922|Re-FRAME the Meeting Summarization SCOPE Fact-Based Summarization and Personalization via Questions]] (84.5% similar)
- [[2025-09-22/Entropy-Regularized Process Reward Model_20250922|Entropy-Regularized Process Reward Model]] (84.3% similar)
- [[2025-09-22/Think, Verbalize, then Speak_ Bridging Complex Thoughts and Comprehensible Speech_20250922|Think, Verbalize, then Speak Bridging Complex Thoughts and Comprehensible Speech]] (84.3% similar)


**ArXiv ID**: [2509.15723](https://arxiv.org/abs/2509.15723)
**Published**: 2025-09-22
**Category**: cs.CL
**PDF**: [Download](https://arxiv.org/pdf/2509.15723.pdf)


**ArXiv ID**: [2509.15723](https://arxiv.org/abs/2509.15723)
**Published**: 2025-09-22
**Category**: cs.CL
**PDF**: [Download](https://arxiv.org/pdf/2509.15723.pdf)

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Fairness in Opinion Summarisation
**🔗 Specific Connectable**: Frequency Framed Prompting
**⭐ Unique Technical**: REFER
**🔬 Broad Technical**: Large Language Models, Natural Language Processing

## 🏷️ 추출된 키워드



`Large Language Models` • 

`Natural Language Processing` • 

`Frequency Framed Prompting` • 

`REFER` • 

`Fairness in Opinion Summarisation`



## 🔗 유사한 논문

Similar papers will be displayed here based on embedding similarity.

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.15723v1 Announce Type: new 
Abstract: Individuals express diverse opinions, a fair summary should represent these viewpoints comprehensively. Previous research on fairness in opinion summarisation using large language models (LLMs) relied on hyperparameter tuning or providing ground truth distributional information in prompts. However, these methods face practical limitations: end-users rarely modify default model parameters, and accurate distributional information is often unavailable. Building upon cognitive science research demonstrating that frequency-based representations reduce systematic biases in human statistical reasoning by making reference classes explicit and reducing cognitive load, this study investigates whether frequency framed prompting (REFER) can similarly enhance fairness in LLM opinion summarisation. Through systematic experimentation with different prompting frameworks, we adapted techniques known to improve human reasoning to elicit more effective information processing in language models compared to abstract probabilistic representations.Our results demonstrate that REFER enhances fairness in language models when summarising opinions. This effect is particularly pronounced in larger language models and using stronger reasoning instructions.

## 🔍 Abstract (한글 번역)

arXiv:2509.15723v1 발표 유형: 신규  
초록: 개인들은 다양한 의견을 표현하며, 공정한 요약은 이러한 관점을 포괄적으로 대표해야 합니다. 대형 언어 모델(LLM)을 사용한 의견 요약의 공정성에 대한 이전 연구는 하이퍼파라미터 튜닝이나 프롬프트에 대한 실제 분포 정보 제공에 의존했습니다. 그러나 이러한 방법은 실질적인 한계를 가지고 있습니다. 최종 사용자는 기본 모델 매개변수를 거의 수정하지 않으며, 정확한 분포 정보는 종종 사용할 수 없습니다. 인지 과학 연구에 따르면 빈도 기반 표현은 참조 클래스를 명확히 하고 인지 부하를 줄임으로써 인간의 통계적 추론에서 체계적인 편향을 줄인다는 점을 바탕으로, 이 연구는 빈도 기반 프레이밍 프롬프팅(REFER)이 LLM 의견 요약에서 공정성을 유사하게 향상시킬 수 있는지 조사합니다. 다양한 프롬프팅 프레임워크를 통한 체계적인 실험을 통해, 우리는 인간의 추론을 개선하는 것으로 알려진 기법을 추상적인 확률적 표현보다 언어 모델에서 더 효과적인 정보 처리를 이끌어내기 위해 적응시켰습니다. 우리의 결과는 REFER가 의견을 요약할 때 언어 모델의 공정성을 향상시킨다는 것을 보여줍니다. 이 효과는 특히 더 큰 언어 모델과 강력한 추론 지침을 사용할 때 두드러집니다.

## 📝 요약

이 연구는 다양한 의견을 공정하게 요약하기 위해 대형 언어 모델(LLM)에서의 공정성을 개선하는 방법을 제안합니다. 기존 방법은 하이퍼파라미터 조정이나 정확한 분포 정보를 제공하는 방식에 의존했지만, 이는 실용적인 한계가 있습니다. 본 연구는 인지과학에서의 빈도 기반 표현이 인간의 통계적 추론 편향을 줄인다는 점에 착안하여, 빈도 기반 프롬프트(REPER)가 LLM의 의견 요약 공정성을 향상시킬 수 있는지를 조사했습니다. 실험 결과, REPER는 특히 더 큰 언어 모델과 강력한 추론 지침을 사용할 때 공정성을 증진시켰습니다.

## 🎯 주요 포인트


- 1. 다양한 의견을 공정하게 요약하기 위해서는 각 관점을 포괄적으로 대표해야 한다.

- 2. 기존 연구는 대형 언어 모델(LLM)의 하이퍼파라미터 조정이나 프롬프트에 정확한 분포 정보를 제공하는 방식에 의존했으나, 이는 실용적 한계가 있다.

- 3. 빈도 기반 표현이 인간의 통계적 추론에서 체계적 편향을 줄인다는 인지과학 연구에 기반하여, 본 연구는 빈도 프레임 프롬프트(REFER)가 LLM의 의견 요약 공정성을 향상시킬 수 있는지를 조사했다.

- 4. 연구 결과, REFER는 특히 더 큰 언어 모델과 강력한 추론 지침을 사용할 때 의견 요약의 공정성을 향상시킨다.

- 5. 빈도 기반 프롬프트는 추상적 확률 표현보다 언어 모델의 정보 처리 능력을 더 효과적으로 유도한다.


---

*Generated on 2025-09-22 16:26:31*