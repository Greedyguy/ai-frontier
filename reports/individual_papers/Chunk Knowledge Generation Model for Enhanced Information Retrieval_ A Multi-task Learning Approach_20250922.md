# Chunk Knowledge Generation Model for Enhanced Information Retrieval: A Multi-task Learning Approach

**Korean Title:** í–¥ìƒëœ ì •ë³´ ê²€ìƒ‰ì„ ìœ„í•œ ì²­í¬ ì§€ì‹ ìƒì„± ëª¨ë¸: ë‹¤ì¤‘ ê³¼ì œ í•™ìŠµ ì ‘ê·¼ë²•

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: Multi-task Learning, Query Expansion

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/ImpRAG_ Retrieval-Augmented Generation with Implicit Queries_20250919|ImpRAG Retrieval-Augmented Generation with Implicit Queries]] (84.2% similar)
- [[2025-09-22/Relevance to Utility_ Process-Supervised Rewrite for RAG_20250922|Relevance to Utility Process-Supervised Rewrite for RAG]] (84.0% similar)
- [[2025-09-19/Select to Know_ An Internal-External Knowledge Self-Selection Framework for Domain-Specific Question Answering_20250919|Select to Know An Internal-External Knowledge Self-Selection Framework for Domain-Specific Question Answering]] (83.6% similar)
- [[2025-09-18/KBM_ Delineating Knowledge Boundary for Adaptive Retrieval in Large Language Models_20250918|KBM Delineating Knowledge Boundary for Adaptive Retrieval in Large Language Models]] (82.7% similar)
- [[2025-09-19/Graph-Enhanced Retrieval-Augmented Question Answering for E-Commerce Customer Support_20250919|Graph-Enhanced Retrieval-Augmented Question Answering for E-Commerce Customer Support]] (82.0% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15658v1 Announce Type: cross 
Abstract: Traditional query expansion techniques for addressing vocabulary mismatch problems in information retrieval are context-sensitive and may lead to performance degradation. As an alternative, document expansion research has gained attention, but existing methods such as Doc2Query have limitations including excessive preprocessing costs, increased index size, and reliability issues with generated content. To mitigate these problems and seek more structured and efficient alternatives, this study proposes a method that divides documents into chunk units and generates textual data for each chunk to simultaneously improve retrieval efficiency and accuracy. The proposed "Chunk Knowledge Generation Model" adopts a T5-based multi-task learning structure that simultaneously generates titles and candidate questions from each document chunk while extracting keywords from user queries. This approach maximizes computational efficiency by generating and extracting three types of semantic information in parallel through a single encoding and two decoding processes. The generated data is utilized as additional information in the retrieval system. GPT-based evaluation on 305 query-document pairs showed that retrieval using the proposed model achieved 95.41% accuracy at Top@10, demonstrating superior performance compared to document chunk-level retrieval. This study contributes by proposing an approach that simultaneously generates titles and candidate questions from document chunks for application in retrieval pipelines, and provides empirical evidence applicable to large-scale information retrieval systems by demonstrating improved retrieval accuracy through qualitative evaluation.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15658v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ì •ë³´ ê²€ìƒ‰ì—ì„œ ì–´íœ˜ ë¶ˆì¼ì¹˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ì „í†µì ì¸ ì¿¼ë¦¬ í™•ì¥ ê¸°ë²•ì€ ë¬¸ë§¥ì— ë¯¼ê°í•˜ì—¬ ì„±ëŠ¥ ì €í•˜ë¥¼ ì´ˆë˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ì— ëŒ€í•œ ëŒ€ì•ˆìœ¼ë¡œ ë¬¸ì„œ í™•ì¥ ì—°êµ¬ê°€ ì£¼ëª©ë°›ê³  ìˆì§€ë§Œ, Doc2Queryì™€ ê°™ì€ ê¸°ì¡´ ë°©ë²•ì€ ê³¼ë„í•œ ì „ì²˜ë¦¬ ë¹„ìš©, ì¦ê°€ëœ ì¸ë±ìŠ¤ í¬ê¸°, ìƒì„±ëœ ì½˜í…ì¸ ì˜ ì‹ ë¢°ì„± ë¬¸ì œ ë“±ì˜ í•œê³„ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë¬¸ì œë¥¼ ì™„í™”í•˜ê³  ë³´ë‹¤ êµ¬ì¡°ì ì´ê³  íš¨ìœ¨ì ì¸ ëŒ€ì•ˆì„ ëª¨ìƒ‰í•˜ê¸° ìœ„í•´, ë³¸ ì—°êµ¬ëŠ” ë¬¸ì„œë¥¼ ì²­í¬ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê³  ê° ì²­í¬ì— ëŒ€í•œ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ìƒì„±í•˜ì—¬ ê²€ìƒ‰ íš¨ìœ¨ì„±ê³¼ ì •í™•ì„±ì„ ë™ì‹œì— í–¥ìƒì‹œí‚¤ëŠ” ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì œì•ˆëœ "ì²­í¬ ì§€ì‹ ìƒì„± ëª¨ë¸"ì€ T5 ê¸°ë°˜ì˜ ë©€í‹°íƒœìŠ¤í¬ í•™ìŠµ êµ¬ì¡°ë¥¼ ì±„íƒí•˜ì—¬ ê° ë¬¸ì„œ ì²­í¬ì—ì„œ ì œëª©ê³¼ í›„ë³´ ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” ë™ì‹œì— ì‚¬ìš©ì ì¿¼ë¦¬ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. ì´ ì ‘ê·¼ ë°©ì‹ì€ ë‹¨ì¼ ì¸ì½”ë”©ê³¼ ë‘ ê°œì˜ ë””ì½”ë”© í”„ë¡œì„¸ìŠ¤ë¥¼ í†µí•´ ì„¸ ê°€ì§€ ìœ í˜•ì˜ ì˜ë¯¸ ì •ë³´ë¥¼ ë³‘ë ¬ë¡œ ìƒì„±í•˜ê³  ì¶”ì¶œí•˜ì—¬ ê³„ì‚° íš¨ìœ¨ì„±ì„ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤. ìƒì„±ëœ ë°ì´í„°ëŠ” ê²€ìƒ‰ ì‹œìŠ¤í…œì—ì„œ ì¶”ê°€ ì •ë³´ë¡œ í™œìš©ë©ë‹ˆë‹¤. 305ê°œì˜ ì¿¼ë¦¬-ë¬¸ì„œ ìŒì— ëŒ€í•œ GPT ê¸°ë°˜ í‰ê°€ì—ì„œ ì œì•ˆëœ ëª¨ë¸ì„ ì‚¬ìš©í•œ ê²€ìƒ‰ì´ Top@10ì—ì„œ 95.41%ì˜ ì •í™•ë„ë¥¼ ë‹¬ì„±í•˜ì—¬ ë¬¸ì„œ ì²­í¬ ìˆ˜ì¤€ì˜ ê²€ìƒ‰ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ëŠ” ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸ì— ì ìš©í•˜ê¸° ìœ„í•´ ë¬¸ì„œ ì²­í¬ì—ì„œ ì œëª©ê³¼ í›„ë³´ ì§ˆë¬¸ì„ ë™ì‹œì— ìƒì„±í•˜ëŠ” ì ‘ê·¼ ë°©ì‹ì„ ì œì•ˆí•˜ê³ , ì§ˆì  í‰ê°€ë¥¼ í†µí•´ ê²€ìƒ‰ ì •í™•ë„ê°€ í–¥ìƒë¨ì„ ì…ì¦í•˜ì—¬ ëŒ€ê·œëª¨ ì •ë³´ ê²€ìƒ‰ ì‹œìŠ¤í…œì— ì ìš© ê°€ëŠ¥í•œ ì‹¤ì¦ì  ì¦ê±°ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” ì •ë³´ ê²€ìƒ‰ì—ì„œ ì–´íœ˜ ë¶ˆì¼ì¹˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì „í†µì ì¸ ì§ˆì˜ í™•ì¥ ê¸°ë²• ëŒ€ì‹  ë¬¸ì„œ í™•ì¥ ì ‘ê·¼ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ ë°©ë²•ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ë¬¸ì„œë¥¼ ì²­í¬ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê³ , ê° ì²­í¬ì—ì„œ ì œëª©ê³¼ í›„ë³´ ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” "ì²­í¬ ì§€ì‹ ìƒì„± ëª¨ë¸"ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ T5 ê¸°ë°˜ì˜ ë©€í‹°íƒœìŠ¤í¬ í•™ìŠµ êµ¬ì¡°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì§ˆì˜ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ê³ , ë‹¨ì¼ ì¸ì½”ë”©ê³¼ ë‘ ê°œì˜ ë””ì½”ë”© ê³¼ì •ì„ í†µí•´ íš¨ìœ¨ì ìœ¼ë¡œ ì„¸ ê°€ì§€ ì˜ë¯¸ ì •ë³´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ìƒì„±ëœ ë°ì´í„°ëŠ” ê²€ìƒ‰ ì‹œìŠ¤í…œì—ì„œ ì¶”ê°€ ì •ë³´ë¡œ í™œìš©ë˜ë©°, GPT ê¸°ë°˜ í‰ê°€ì—ì„œ Top@10ì—ì„œ 95.41%ì˜ ì •í™•ë„ë¥¼ ê¸°ë¡í•˜ì—¬ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ëŒ€ê·œëª¨ ì •ë³´ ê²€ìƒ‰ ì‹œìŠ¤í…œì—ì„œ ê²€ìƒ‰ ì •í™•ë„ë¥¼ í–¥ìƒì‹œí‚¤ëŠ” ë°©ë²•ë¡ ì„ ì œì‹œí•˜ê³ , ì§ˆì  í‰ê°€ë¥¼ í†µí•´ ê·¸ íš¨ê³¼ë¥¼ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ê¸°ì¡´ì˜ ì¿¼ë¦¬ í™•ì¥ ê¸°ë²•ì€ ë¬¸ë§¥ì— ë¯¼ê°í•˜ì—¬ ì„±ëŠ¥ ì €í•˜ë¥¼ ì´ˆë˜í•  ìˆ˜ ìˆìœ¼ë©°, ì´ë¥¼ ëŒ€ì²´í•˜ê¸° ìœ„í•´ ë¬¸ì„œ í™•ì¥ ì—°êµ¬ê°€ ì£¼ëª©ë°›ê³  ìˆìŠµë‹ˆë‹¤.

- 2. ì œì•ˆëœ "ì²­í¬ ì§€ì‹ ìƒì„± ëª¨ë¸"ì€ T5 ê¸°ë°˜ì˜ ë©€í‹°íƒœìŠ¤í¬ í•™ìŠµ êµ¬ì¡°ë¥¼ ì±„íƒí•˜ì—¬ ë¬¸ì„œ ì²­í¬ì—ì„œ ì œëª©ê³¼ í›„ë³´ ì§ˆë¬¸ì„ ìƒì„±í•˜ê³  ì‚¬ìš©ì ì¿¼ë¦¬ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

- 3. ì´ ëª¨ë¸ì€ ë‹¨ì¼ ì¸ì½”ë”©ê³¼ ë‘ ê°œì˜ ë””ì½”ë”© ê³¼ì •ì„ í†µí•´ ì„¸ ê°€ì§€ ìœ í˜•ì˜ ì˜ë¯¸ ì •ë³´ë¥¼ ë³‘ë ¬ë¡œ ìƒì„± ë° ì¶”ì¶œí•˜ì—¬ ê³„ì‚° íš¨ìœ¨ì„±ì„ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤.

- 4. ì œì•ˆëœ ëª¨ë¸ì„ ì‚¬ìš©í•œ ê²€ìƒ‰ì€ 305ê°œì˜ ì¿¼ë¦¬-ë¬¸ì„œ ìŒì—ì„œ Top@10 ê¸°ì¤€ 95.41%ì˜ ì •í™•ë„ë¥¼ ë‹¬ì„±í•˜ì—¬ ë¬¸ì„œ ì²­í¬ ìˆ˜ì¤€ ê²€ìƒ‰ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

- 5. ë³¸ ì—°êµ¬ëŠ” ë¬¸ì„œ ì²­í¬ì—ì„œ ì œëª©ê³¼ í›„ë³´ ì§ˆë¬¸ì„ ë™ì‹œì— ìƒì„±í•˜ëŠ” ì ‘ê·¼ ë°©ì‹ì„ ì œì•ˆí•˜ê³ , ëŒ€ê·œëª¨ ì •ë³´ ê²€ìƒ‰ ì‹œìŠ¤í…œì— ì ìš© ê°€ëŠ¥í•œ ê²½í—˜ì  ì¦ê±°ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

---

*Generated on 2025-09-22 14:06:46*