
# Tabular Data Generation Models: An In-Depth Survey and Performance Benchmarks with Extensive Tuning

**Korean Title:** í‘œ í˜•ì‹ ë°ì´í„° ìƒì„± ëª¨ë¸: ì² ì €í•œ ì¡°ì‚¬ ë° ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹ê³¼ í¬ê´„ì ì¸ íŠœë‹

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-18|2025-09-18]] [[keywords/evolved/Dataset-specific Tuning|Dataset-specific Tuning]] [[keywords/broad/Generative Models|Generative Models]] [[keywords/broad/Tabular Data|Tabular Data]] [[keywords/specific/Diffusion-based Models|Diffusion-based Models]] [[keywords/unique/Feature Encodings|Feature Encodings]] [[categories/cs.LG|cs.LG]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Dataset-specific Tuning
**ğŸ”¬ Broad Technical**: Generative Models, Tabular Data
**ğŸ”— Specific Connectable**: Diffusion-based Models
**â­ Unique Technical**: Feature Encodings

**ArXiv ID**: [2406.12945](https://arxiv.org/abs/2406.12945)
**Published**: 2025-09-18
**Category**: cs.LG
**PDF**: [Download](https://arxiv.org/pdf/2406.12945.pdf)


## ğŸ·ï¸ ì¶”ì¶œëœ í‚¤ì›Œë“œ



`Generative Models` â€¢ 

`Tabular Data` â€¢ 

`Diffusion-based Models` â€¢ 

`Feature Encodings` â€¢ 

`Dataset-specific Tuning`



## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2406.12945v4 Announce Type: replace 
Abstract: The ability to train generative models that produce realistic, safe and useful tabular data is essential for data privacy, imputation, oversampling, explainability or simulation. However, generating tabular data is not straightforward due to its heterogeneity, non-smooth distributions, complex dependencies and imbalanced categorical features. Although diverse methods have been proposed in the literature, there is a need for a unified evaluation, under the same conditions, on a variety of datasets. This study addresses this need by fully considering the optimization of: hyperparameters, feature encodings, and architectures. We investigate the impact of dataset-specific tuning on five recent model families for tabular data generation through an extensive benchmark on 16 datasets. These datasets vary in terms of size (an average of 80,000 rows), data types, and domains. We also propose a reduced search space for each model that allows for quick optimization, achieving nearly equivalent performance at a significantly lower cost. Our benchmark demonstrates that, for most models, large-scale dataset-specific tuning substantially improves performance compared to the original configurations. Furthermore, we confirm that diffusion-based models generally outperform other models on tabular data. However, this advantage is not significant when the entire tuning and training process is restricted to the same GPU budget.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2406.12945v4 ë°œí‘œ ìœ í˜•: ëŒ€ì²´
ìš”ì•½: í˜„ì‹¤ì ì´ê³  ì•ˆì „í•˜ë©° ìœ ìš©í•œ í…Œì´ë¸” ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ìƒì„± ëª¨ë¸ì„ í›ˆë ¨í•˜ëŠ” ëŠ¥ë ¥ì€ ë°ì´í„° í”„ë¼ì´ë²„ì‹œ, ëŒ€ì²´, ì˜¤ë²„ìƒ˜í”Œë§, ì„¤ëª… ê°€ëŠ¥ì„± ë˜ëŠ” ì‹œë®¬ë ˆì´ì…˜ì— ì¤‘ìš”í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ í…Œì´ë¸” ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì€ ê·¸ì˜ ì´ì§ˆì„±, ë¹„ë¶€ë“œëŸ¬ìš´ ë¶„í¬, ë³µì¡í•œ ì˜ì¡´ì„± ë° ë¶ˆê· í˜•í•œ ë²”ì£¼í˜• íŠ¹ì§•ìœ¼ë¡œ ì¸í•´ ê°„ë‹¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë¬¸í—Œì—ì„œ ë‹¤ì–‘í•œ ë°©ë²•ì´ ì œì•ˆë˜ì—ˆì§€ë§Œ, ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ì— ëŒ€í•´ ë™ì¼í•œ ì¡°ê±´ì—ì„œ í†µí•© í‰ê°€ê°€ í•„ìš”í•©ë‹ˆë‹¤. ë³¸ ì—°êµ¬ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„°, íŠ¹ì§• ì¸ì½”ë”© ë° ì•„í‚¤í…ì²˜ì˜ ìµœì í™”ë¥¼ ì™„ì „íˆ ê³ ë ¤í•˜ì—¬ ì´ëŸ¬í•œ í•„ìš”ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. ìš°ë¦¬ëŠ” 16ê°œì˜ ë°ì´í„°ì…‹ì— ëŒ€í•œ ê´‘ë²”ìœ„í•œ ë²¤ì¹˜ë§ˆí‚¹ì„ í†µí•´ í…Œì´ë¸” ë°ì´í„° ìƒì„±ì„ ìœ„í•œ ë‹¤ì„¯ ê°€ì§€ ìµœê·¼ ëª¨ë¸ íŒ¨ë°€ë¦¬ì— ëŒ€í•œ ë°ì´í„°ì…‹ë³„ íŠœë‹ì˜ ì˜í–¥ì„ ì¡°ì‚¬í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ë°ì´í„°ì…‹ì€ í¬ê¸°(í‰ê·  80,000í–‰), ë°ì´í„° ìœ í˜• ë° ë„ë©”ì¸ ì¸¡ë©´ì—ì„œ ë‹¤ì–‘í•©ë‹ˆë‹¤. ë˜í•œ ê° ëª¨ë¸ì— ëŒ€í•œ ì¶•ì†Œëœ íƒìƒ‰ ê³µê°„ì„ ì œì•ˆí•˜ì—¬ ë¹ ë¥¸ ìµœì í™”ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ë©°, ìƒë‹¹íˆ ë‚®ì€ ë¹„ìš©ìœ¼ë¡œ ê±°ì˜ ë™ë“±í•œ ì„±ëŠ¥ì„ ë‹¬ì„±í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ë²¤ì¹˜ë§ˆí¬ëŠ” ëŒ€ë¶€ë¶„ì˜ ëª¨ë¸ì— ëŒ€í•´ ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ë³„ íŠœë‹ì´ ì›ë˜ êµ¬ì„±ë³´ë‹¤ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚¨ë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë˜í•œ í™•ì‚° ê¸°ë°˜ ëª¨ë¸ì´ ì¼ë°˜ì ìœ¼ë¡œ ë‹¤ë¥¸ ëª¨ë¸ë³´ë‹¤ í…Œì´ë¸” ë°ì´í„°ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤€ë‹¤ëŠ” ê²ƒì„ í™•ì¸í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì „ì²´ íŠœë‹ ë° í›ˆë ¨ í”„ë¡œì„¸ìŠ¤ë¥¼ ë™ì¼í•œ GPU ì˜ˆì‚°ìœ¼ë¡œ ì œí•œí•  ë•Œ ì´ ì´ì ì€ ì¤‘ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ë³¸ ì—°êµ¬ëŠ” ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ì— ëŒ€í•´ í•˜ì´í¼íŒŒë¼ë¯¸í„°, íŠ¹ì„± ì¸ì½”ë”©, ì•„í‚¤í…ì²˜ ìµœì í™”ë¥¼ ê³ ë ¤í•˜ì—¬ íƒ­ëŸ¬ ë°ì´í„° ìƒì„±ì„ í‰ê°€í•˜ì˜€ë‹¤. 16ê°€ì§€ ë°ì´í„°ì…‹ì„ ëŒ€ìƒìœ¼ë¡œ ìµœê·¼ ëª¨ë¸ íŒ¨ë°€ë¦¬ 5ê°€ì§€ì˜ ì˜í–¥ì„ ì¡°ì‚¬í•˜ì˜€ê³ , ëŒ€ë¶€ë¶„ì˜ ëª¨ë¸ì—ì„œ ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ íŠ¹ì • íŠœë‹ì´ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚¨ë‹¤ëŠ” ê²ƒì„ í™•ì¸í•˜ì˜€ë‹¤. í™•ì‚° ê¸°ë°˜ ëª¨ë¸ì´ ë‹¤ë¥¸ ëª¨ë¸ë³´ë‹¤ ì¼ë°˜ì ìœ¼ë¡œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì´ì§€ë§Œ, ë™ì¼í•œ GPU ì˜ˆì‚° ë‚´ì—ì„œ íŠœë‹ ë° í›ˆë ¨ ê³¼ì •ì„ ì œí•œí•  ê²½ìš° ì´ ìš°ìœ„ëŠ” í¬ì§€ ì•ŠìŒì„ í™•ì¸í•˜ì˜€ë‹¤. ì´ë¥¼ í†µí•´ ë¹ ë¥¸ ìµœì í™”ë¥¼ í—ˆìš©í•˜ëŠ” ê° ëª¨ë¸ì˜ ì¶•ì†Œëœ íƒìƒ‰ ê³µê°„ì„ ì œì•ˆí•˜ì˜€ë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸


- ì‹¤ì œì ì´ê³  ì•ˆì „í•˜ë©° ìœ ìš©í•œ íƒ€ë¸”ëŸ¬ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ìƒì„± ëª¨ë¸ í›ˆë ¨ì´ ì¤‘ìš”í•˜ë‹¤.

- ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ì— ëŒ€í•´ ë™ì¼í•œ ì¡°ê±´ í•˜ì— í†µí•©ëœ í‰ê°€ê°€ í•„ìš”í•˜ë‹¤.

- ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì— ëŒ€í•œ íŠœë‹ì€ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆë‹¤.


---

*Generated on 2025-09-18 16:46:06*