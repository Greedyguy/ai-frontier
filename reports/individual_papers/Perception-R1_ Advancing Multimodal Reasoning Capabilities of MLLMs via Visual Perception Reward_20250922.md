# Perception-R1: Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward

**Korean Title:** Perception-R1: 시각적 인식 보상을 통한 MLLM의 다중 모드 추론 능력 향상

## 📋 메타데이터

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Multimodal Reasoning

## 🔗 유사한 논문
- [[2025-09-22/Beyond Spurious Signals_ Debiasing Multimodal Large Language Models via Counterfactual Inference and Adaptive Expert Routing_20250922|Beyond Spurious Signals Debiasing Multimodal Large Language Models via Counterfactual Inference and Adaptive Expert Routing]] (86.6% similar)
- [[2025-09-18/TDRM_ Smooth Reward Models with Temporal Difference for LLM RL and Inference_20250918|TDRM Smooth Reward Models with Temporal Difference for LLM RL and Inference]] (86.2% similar)
- [[2025-09-19/Decoupled Proxy Alignment_ Mitigating Language Prior Conflict for Multimodal Alignment in MLLM_20250919|Decoupled Proxy Alignment Mitigating Language Prior Conflict for Multimodal Alignment in MLLM]] (85.4% similar)
- [[2025-09-22/Reward Hacking Mitigation using Verifiable Composite Rewards_20250922|Reward Hacking Mitigation using Verifiable Composite Rewards]] (85.2% similar)
- [[2025-09-19/Modular Machine Learning_ An Indispensable Path towards New-Generation Large Language Models_20250919|Modular Machine Learning An Indispensable Path towards New-Generation Large Language Models]] (85.1% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2506.07218v2 Announce Type: replace-cross 
Abstract: Enhancing the multimodal reasoning capabilities of Multimodal Large Language Models (MLLMs) is a challenging task that has attracted increasing attention in the community. Recently, several studies have applied Reinforcement Learning with Verifiable Rewards (RLVR) to the multimodal domain in order to enhance the reasoning abilities of MLLMs. However, these works largely overlook the enhancement of multimodal perception capabilities in MLLMs, which serve as a core prerequisite and foundational component of complex multimodal reasoning. Through McNemar's test, we find that existing RLVR method fails to effectively enhance the multimodal perception capabilities of MLLMs, thereby limiting their further improvement in multimodal reasoning. To address this limitation, we propose Perception-R1, which introduces a novel visual perception reward that explicitly encourages MLLMs to perceive the visual content accurately, thereby can effectively incentivizing both their multimodal perception and reasoning capabilities. Specifically, we first collect textual visual annotations from the CoT trajectories of multimodal problems, which will serve as visual references for reward assignment. During RLVR training, we employ a judging LLM to assess the consistency between the visual annotations and the responses generated by MLLM, and assign the visual perception reward based on these consistency judgments. Extensive experiments on several multimodal reasoning benchmarks demonstrate the effectiveness of our Perception-R1, which achieves state-of-the-art performance on most benchmarks using only 1,442 training data.

## 🔍 Abstract (한글 번역)

arXiv:2506.07218v2 발표 유형: 교차 교체  
초록: 다중모드 대형 언어 모델(Multimodal Large Language Models, MLLMs)의 다중모드 추론 능력을 향상시키는 것은 점점 더 많은 관심을 받고 있는 어려운 과제입니다. 최근 여러 연구에서는 강화 학습과 검증 가능한 보상(Reinforcement Learning with Verifiable Rewards, RLVR)을 다중모드 도메인에 적용하여 MLLMs의 추론 능력을 향상시키고자 했습니다. 그러나 이러한 연구들은 MLLMs의 다중모드 인식 능력 향상을 대체로 간과하고 있으며, 이는 복잡한 다중모드 추론의 핵심 전제 조건이자 기초 구성 요소로 작용합니다. McNemar 검정을 통해, 기존의 RLVR 방법이 MLLMs의 다중모드 인식 능력을 효과적으로 향상시키지 못하여 다중모드 추론의 추가적인 발전을 제한하고 있음을 발견했습니다. 이러한 한계를 해결하기 위해, 우리는 Perception-R1을 제안합니다. 이는 MLLMs가 시각적 콘텐츠를 정확하게 인식하도록 명시적으로 장려하는 새로운 시각 인식 보상을 도입하여, 다중모드 인식 및 추론 능력을 효과적으로 강화할 수 있습니다. 구체적으로, 우리는 다중모드 문제의 CoT 궤적에서 텍스트 시각 주석을 수집하여 보상 할당의 시각적 참조로 활용합니다. RLVR 훈련 동안, 우리는 판단 LLM을 사용하여 시각 주석과 MLLM이 생성한 응답 간의 일관성을 평가하고, 이러한 일관성 판단에 기반하여 시각 인식 보상을 할당합니다. 여러 다중모드 추론 벤치마크에 대한 광범위한 실험은 Perception-R1의 효과를 입증하며, 1,442개의 훈련 데이터만으로 대부분의 벤치마크에서 최첨단 성능을 달성합니다.

## 📝 요약

이 논문은 다중 모드 대형 언어 모델(MLLM)의 다중 모드 추론 능력을 향상시키기 위한 연구로, 기존의 강화 학습 방법이 다중 모드 인식 능력을 충분히 개선하지 못한다는 문제를 지적합니다. 이를 해결하기 위해, 저자들은 새로운 시각 인식 보상 시스템인 Perception-R1을 제안합니다. 이 시스템은 MLLM이 시각적 콘텐츠를 정확하게 인식하도록 유도하여 다중 모드 인식과 추론 능력을 동시에 개선합니다. 실험 결과, Perception-R1은 1,442개의 훈련 데이터만으로도 여러 다중 모드 추론 벤치마크에서 최첨단 성능을 달성했습니다.

## 🎯 주요 포인트

- 1. 다중모달 대형 언어 모델(MLLM)의 다중모달 추론 능력을 강화하는 것은 도전적인 과제이며, 최근 커뮤니티에서 많은 관심을 받고 있다.

- 2. 기존의 강화학습 방법은 MLLM의 다중모달 인식 능력을 효과적으로 강화하지 못하여, 다중모달 추론의 추가적인 발전을 제한한다.

- 3. Perception-R1은 시각적 인식을 명확히 장려하는 새로운 시각적 인식 보상을 도입하여, MLLM의 다중모달 인식 및 추론 능력을 효과적으로 향상시킨다.

- 4. Perception-R1은 다중모달 문제의 CoT 경로에서 수집한 텍스트 시각 주석을 보상 할당을 위한 시각적 참조로 사용한다.

- 5. 여러 다중모달 추론 벤치마크에서 Perception-R1의 효과가 입증되었으며, 1,442개의 훈련 데이터만으로 대부분의 벤치마크에서 최첨단 성능을 달성한다.

---

*Generated on 2025-09-22 14:54:26*