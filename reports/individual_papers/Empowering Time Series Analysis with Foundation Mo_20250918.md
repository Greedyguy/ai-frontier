
# Empowering Time Series Analysis with Foundation Models: A Comprehensive Survey

**Korean Title:** 기초 모델을 활용한 시계열 분석 강화: 포괄적인 조사

## 📋 메타데이터

**Links**: [[daily/2025-09-18|2025-09-18]] [[keywords/evolved/Multimodal Integration|Multimodal Integration]] [[keywords/broad/Foundation Models|Foundation Models]] [[keywords/broad/Time Series Analysis|Time Series Analysis]] [[keywords/specific/Zero-shot Learning|Zero-shot Learning]] [[keywords/unique/Modality-aware Perspective|Modality-aware Perspective]] [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Domain-specific Advancements
**🔬 Broad Technical**: Foundation Models, Time Series Analysis
**🔗 Specific Connectable**: Multimodal Integration
**⭐ Unique Technical**: Modality-aware Perspective

**ArXiv ID**: [2405.02358](https://arxiv.org/abs/2405.02358)
**Published**: 2025-09-18
**Category**: cs.AI
**PDF**: [Download](https://arxiv.org/pdf/2405.02358.pdf)


## 🏷️ 추출된 키워드



`Foundation Models` • 

`Time Series Analysis` • 

`Zero-shot Learning` • 

`Modality-aware Perspective` • 

`Multimodal Integration`



## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2405.02358v4 Announce Type: replace-cross 
Abstract: Time series data are ubiquitous across diverse real-world applications, making time series analysis critically important. Traditional approaches are largely task-specific, offering limited functionality and poor transferability. In recent years, foundation models have revolutionized NLP and CV with their remarkable cross-task transferability, zero-/few-shot learning capabilities, and multimodal integration capacity. This success has motivated increasing efforts to explore foundation models for addressing time series modeling challenges. Although some tutorials and surveys were published in the early stages of this field, the rapid pace of recent developments necessitates a more comprehensive and in-depth synthesis to cover the latest advances. Our survey aims to fill this gap by introducing a modality-aware, challenge-oriented perspective, which reveals how foundation models pre-trained on different modalities face distinct hurdles when adapted to time series tasks. Building on this perspective, we propose a taxonomy of existing works organized by pre-training modality (time series, language, and vision), analyze modality-specific challenges and categorize corresponding solutions, discussing their advantages and limitations. Beyond this, we review real-world applications to illustrate domain-specific advancements, provide open-source codes, and conclude with potential future research directions in this rapidly evolving field.

## 🔍 Abstract (한글 번역)

arXiv:2405.02358v4 발표 유형: 대체-교차
요약: 시계열 데이터는 다양한 실제 응용 프로그램에서 널리 사용되며, 시계열 분석은 중요한 역할을 합니다. 전통적인 접근 방식은 주로 작업별로 제한된 기능과 낮은 이식성을 제공합니다. 최근 몇 년간, 기초 모델은 놀라운 교차 작업 이식성, 제로-/퓨-샷 학습 능력 및 다중 모달 통합 능력으로 NLP 및 CV를 혁신시켰습니다. 이 성공은 시계열 모델링 과제를 해결하기 위해 기초 모델을 탐색하는 노력을 증가시켰습니다. 이 분야 초기에 일부 튜토리얼과 설문 조사가 발표되었지만, 최근 발전의 신속한 속도는 최신 발전을 다루기 위해 보다 포괄적이고 심층적인 종합을 필요로 합니다. 저희 설문은 이 간극을 메우기 위해 모달리티 인식, 과제 중심적 관점을 소개하여, 다양한 모달리티에서 사전 훈련된 기초 모델이 시계열 작업에 적응할 때 어떤 도전에 직면하는지 보여줍니다. 이 관점을 기반으로, 우리는 사전 훈련 모달리티(시계열, 언어, 시각)에 따라 구성된 기존 작업의 분류법을 제안하고, 모달리티별 도전 과제를 분석하고 해당 솔루션을 분류하여 이점과 한계를 논의합니다. 이외에도, 도메인별 진보를 설명하기 위해 실제 응용 사례를 검토하고, 오픈 소스 코드를 제공하며, 이 빠르게 발전하는 분야에서의 잠재적인 미래 연구 방향을 결론 짓습니다.

## 📝 요약

최근 몇 년간 NLP 및 CV 분야에서의 성공을 통해 기초 모델이 과업 간 전이성, 제로-/퓨-샷 학습 능력 및 다중 모달 통합 능력을 갖춘 것으로 입증되었으며, 이는 시계열 데이터 분석에도 적용될 수 있다는 가능성을 제시하고 있다. 본 조사는 시계열 모델링 과제에 대한 기초 모델의 적용 가능성을 탐구하고, 다양한 모달리티에 대한 도전적인 관점을 소개함으로써 최신 발전 사항을 다루는 종합적이고 심층적인 종합을 제공한다. 이를 통해 기존 작업을 시계열, 언어 및 비전의 사전 훈련 모달리티에 따라 분류하고, 각각의 도전과 그에 대응하는 해결책을 분석하여 이점과 한계를 논의한다. 또한 도메인별 발전 사항을 설명하고, 오픈 소스 코드를 제공하며, 이 분야의 잠재적인 미래 연구 방향을 제시한다.

## 🎯 주요 포인트


- 시계열 데이터는 다양한 실세계 응용 프로그램에서 널리 사용되어 시계열 분석이 중요하다.

- 기존 방법론은 주로 과제별이며 기능이 제한되고 이전성이 낮다.

- 최근 몇 년간의 발전으로 기초 모델이 NLP 및 CV를 혁신시키고 있다.


---

*Generated on 2025-09-18 16:28:08*