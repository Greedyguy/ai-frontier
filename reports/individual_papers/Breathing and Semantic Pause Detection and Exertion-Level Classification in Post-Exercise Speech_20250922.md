# Breathing and Semantic Pause Detection and Exertion-Level Classification in Post-Exercise Speech

**Korean Title:** ìš´ë™ í›„ ë°œí™”ì—ì„œ í˜¸í¡ ë° ì˜ë¯¸ì  íœ´ì§€ íƒì§€ì™€ ìš´ë™ ê°•ë„ ìˆ˜ì¤€ ë¶„ë¥˜

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.LG|cs.LG]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: Multimodal Analysis, Feature Fusion

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/Multimodal signal fusion for stress detection using deep neural networks_ a novel approach for converting 1D signals to unified 2D images_20250918|Multimodal signal fusion for stress detection using deep neural networks a novel approach for converting 1D signals to unified 2D images]] (78.9% similar)
- [[2025-09-18/Estimating Respiratory Effort from Nocturnal Breathing Sounds for Obstructive Sleep Apnoea Screening_20250918|Estimating Respiratory Effort from Nocturnal Breathing Sounds for Obstructive Sleep Apnoea Screening]] (78.2% similar)
- [[2025-09-22/mucAI at BAREC Shared Task 2025_ Towards Uncertainty Aware Arabic Readability Assessment_20250922|mucAI at BAREC Shared Task 2025 Towards Uncertainty Aware Arabic Readability Assessment]] (77.8% similar)
- [[2025-09-17/Personalization on a Budget_ Minimally-Labeled Continual Learning for Resource-Efficient Seizure Detection_20250917|Personalization on a Budget Minimally-Labeled Continual Learning for Resource-Efficient Seizure Detection]] (77.2% similar)
- [[2025-09-18/HD3C_ Efficient Medical Data Classification for Embedded Devices_20250918|HD3C Efficient Medical Data Classification for Embedded Devices]] (77.2% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15473v1 Announce Type: cross 
Abstract: Post-exercise speech contains rich physiological and linguistic cues, often marked by semantic pauses, breathing pauses, and combined breathing-semantic pauses. Detecting these events enables assessment of recovery rate, lung function, and exertion-related abnormalities. However, existing works on identifying and distinguishing different types of pauses in this context are limited. In this work, building on a recently released dataset with synchronized audio and respiration signals, we provide systematic annotations of pause types. Using these annotations, we systematically conduct exploratory breathing and semantic pause detection and exertion-level classification across deep learning models (GRU, 1D CNN-LSTM, AlexNet, VGG16), acoustic features (MFCC, MFB), and layer-stratified Wav2Vec2 representations. We evaluate three setups-single feature, feature fusion, and a two-stage detection-classification cascade-under both classification and regression formulations. Results show per-type detection accuracy up to 89$\%$ for semantic, 55$\%$ for breathing, 86$\%$ for combined pauses, and 73$\%$overall, while exertion-level classification achieves 90.5$\%$ accuracy, outperformin prior work.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15473v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ìš´ë™ í›„ ë°œí™”ëŠ” í’ë¶€í•œ ìƒë¦¬ì  ë° ì–¸ì–´ì  ë‹¨ì„œë¥¼ í¬í•¨í•˜ê³  ìˆìœ¼ë©°, ì¢…ì¢… ì˜ë¯¸ì  ë©ˆì¶¤, í˜¸í¡ ë©ˆì¶¤, ê·¸ë¦¬ê³  í˜¸í¡-ì˜ë¯¸ ê²°í•© ë©ˆì¶¤ìœ¼ë¡œ íŠ¹ì§•ì§€ì–´ì§‘ë‹ˆë‹¤. ì´ëŸ¬í•œ ì‚¬ê±´ì„ ê°ì§€í•˜ë©´ íšŒë³µ ì†ë„, í ê¸°ëŠ¥ ë° ìš´ë™ ê´€ë ¨ ì´ìƒì„ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ ë§¥ë½ì—ì„œ ë‹¤ì–‘í•œ ìœ í˜•ì˜ ë©ˆì¶¤ì„ ì‹ë³„í•˜ê³  êµ¬ë³„í•˜ëŠ” ê¸°ì¡´ ì—°êµ¬ëŠ” ì œí•œì ì…ë‹ˆë‹¤. ì´ ì—°êµ¬ì—ì„œëŠ” ìµœê·¼ì— ê³µê°œëœ ì˜¤ë””ì˜¤ì™€ í˜¸í¡ ì‹ í˜¸ê°€ ë™ê¸°í™”ëœ ë°ì´í„°ì…‹ì„ ê¸°ë°˜ìœ¼ë¡œ ë©ˆì¶¤ ìœ í˜•ì— ëŒ€í•œ ì²´ê³„ì ì¸ ì£¼ì„ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì£¼ì„ì„ ì‚¬ìš©í•˜ì—¬ ì‹¬ì¸µ í•™ìŠµ ëª¨ë¸(GRU, 1D CNN-LSTM, AlexNet, VGG16), ìŒí–¥ íŠ¹ì§•(MFCC, MFB), ë° ê³„ì¸µë³„ Wav2Vec2 í‘œí˜„ì„ í†µí•´ íƒìƒ‰ì  í˜¸í¡ ë° ì˜ë¯¸ì  ë©ˆì¶¤ ê°ì§€ì™€ ìš´ë™ ìˆ˜ì¤€ ë¶„ë¥˜ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ìˆ˜í–‰í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ë‹¨ì¼ íŠ¹ì§•, íŠ¹ì§• ìœµí•©, ê·¸ë¦¬ê³  ë‘ ë‹¨ê³„ ê°ì§€-ë¶„ë¥˜ ì—°ì‡„ë¼ëŠ” ì„¸ ê°€ì§€ ì„¤ì •ì„ ë¶„ë¥˜ ë° íšŒê·€ ê³µì‹í™” í•˜ì— í‰ê°€í•©ë‹ˆë‹¤. ê²°ê³¼ëŠ” ì˜ë¯¸ì  ë©ˆì¶¤ì— ëŒ€í•´ ìµœëŒ€ 89%, í˜¸í¡ ë©ˆì¶¤ì— ëŒ€í•´ 55%, ê²°í•© ë©ˆì¶¤ì— ëŒ€í•´ 86%, ì „ì²´ì ìœ¼ë¡œ 73%ì˜ ìœ í˜•ë³„ ê°ì§€ ì •í™•ë„ë¥¼ ë³´ì—¬ì£¼ë©°, ìš´ë™ ìˆ˜ì¤€ ë¶„ë¥˜ëŠ” 90.5%ì˜ ì •í™•ë„ë¥¼ ë‹¬ì„±í•˜ì—¬ ì´ì „ ì—°êµ¬ë¥¼ ëŠ¥ê°€í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ìš´ë™ í›„ ë°œí™”ì—ì„œ ë‚˜íƒ€ë‚˜ëŠ” ë‹¤ì–‘í•œ ìœ í˜•ì˜ ë©ˆì¶¤(ì˜ë¯¸ì , í˜¸í¡ì , ê²°í•©ì )ì„ íƒì§€í•˜ì—¬ íšŒë³µ ì†ë„, í ê¸°ëŠ¥ ë° ìš´ë™ ê´€ë ¨ ì´ìƒì„ í‰ê°€í•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ìµœê·¼ ê³µê°œëœ ë™ê¸°í™”ëœ ì˜¤ë””ì˜¤ ë° í˜¸í¡ ì‹ í˜¸ ë°ì´í„°ì…‹ì„ ê¸°ë°˜ìœ¼ë¡œ ì²´ê³„ì ì¸ ë©ˆì¶¤ ìœ í˜• ì£¼ì„ì„ ì œê³µí•˜ê³ , ì´ë¥¼ í†µí•´ GRU, 1D CNN-LSTM, AlexNet, VGG16 ë“±ì˜ ë”¥ëŸ¬ë‹ ëª¨ë¸ê³¼ MFCC, MFB, Wav2Vec2 ë“±ì˜ ìŒí–¥ íŠ¹ì§•ì„ í™œìš©í•˜ì—¬ ë©ˆì¶¤ íƒì§€ ë° ìš´ë™ ê°•ë„ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. ë‹¨ì¼ íŠ¹ì§•, íŠ¹ì§• ìœµí•©, 2ë‹¨ê³„ íƒì§€-ë¶„ë¥˜ ì ‘ê·¼ë²•ì„ í‰ê°€í•œ ê²°ê³¼, ì˜ë¯¸ì  ë©ˆì¶¤ 89%, í˜¸í¡ì  ë©ˆì¶¤ 55%, ê²°í•©ì  ë©ˆì¶¤ 86%, ì „ì²´ì ìœ¼ë¡œ 73%ì˜ íƒì§€ ì •í™•ë„ë¥¼ ë³´ì˜€ìœ¼ë©°, ìš´ë™ ê°•ë„ ë¶„ë¥˜ ì •í™•ë„ëŠ” 90.5%ë¡œ ì´ì „ ì—°êµ¬ë¥¼ ëŠ¥ê°€í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ìš´ë™ í›„ ë°œí™”ì—ëŠ” ì˜ë¯¸ì  íœ´ì§€, í˜¸í¡ íœ´ì§€, ê²°í•©ëœ í˜¸í¡-ì˜ë¯¸ íœ´ì§€ì™€ ê°™ì€ ë‹¤ì–‘í•œ ìƒë¦¬ì  ë° ì–¸ì–´ì  ë‹¨ì„œê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

- 2. ì´ ì—°êµ¬ì—ì„œëŠ” ìµœê·¼ ê³µê°œëœ ì˜¤ë””ì˜¤ ë° í˜¸í¡ ì‹ í˜¸ê°€ ë™ê¸°í™”ëœ ë°ì´í„°ì…‹ì„ ê¸°ë°˜ìœ¼ë¡œ íœ´ì§€ ìœ í˜•ì— ëŒ€í•œ ì²´ê³„ì ì¸ ì£¼ì„ì„ ì œê³µí•©ë‹ˆë‹¤.

- 3. GRU, 1D CNN-LSTM, AlexNet, VGG16ê³¼ ê°™ì€ ë”¥ëŸ¬ë‹ ëª¨ë¸ê³¼ MFCC, MFB ë“±ì˜ ìŒí–¥ íŠ¹ì§•ì„ ì‚¬ìš©í•˜ì—¬ íœ´ì§€ íƒì§€ ë° ë…¸ë ¥ ìˆ˜ì¤€ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.

- 4. ë‹¨ì¼ íŠ¹ì§•, íŠ¹ì§• ìœµí•©, ì´ë‹¨ê³„ íƒì§€-ë¶„ë¥˜ ì—°ì‡„ì˜ ì„¸ ê°€ì§€ ì„¤ì •ì„ í‰ê°€í•˜ë©°, ì˜ë¯¸ì  íœ´ì§€ íƒì§€ ì •í™•ë„ëŠ” ìµœëŒ€ 89%, í˜¸í¡ íœ´ì§€ëŠ” 55%, ê²°í•©ëœ íœ´ì§€ëŠ” 86%, ì „ì²´ì ìœ¼ë¡œëŠ” 73%ì˜ ì •í™•ë„ë¥¼ ë³´ì…ë‹ˆë‹¤.

- 5. ë…¸ë ¥ ìˆ˜ì¤€ ë¶„ë¥˜ì—ì„œëŠ” 90.5%ì˜ ì •í™•ë„ë¥¼ ë‹¬ì„±í•˜ì—¬ ì´ì „ ì—°êµ¬ë¥¼ ëŠ¥ê°€í•©ë‹ˆë‹¤.

---

*Generated on 2025-09-22 15:38:47*