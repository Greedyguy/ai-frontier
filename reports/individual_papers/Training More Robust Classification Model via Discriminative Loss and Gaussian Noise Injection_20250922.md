# Training More Robust Classification Model via Discriminative Loss and Gaussian Noise Injection

**Korean Title:** ë”ìš± ê²¬ê³ í•œ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ: íŒë³„ ì†ì‹¤ ë° ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ ì£¼ì…ì„ í†µí•œ ì ‘ê·¼

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[reports/digests/daily_digest_20250922|2025-09-22]] [[keywords/specific/Gaussian Noise Injection|Gaussian Noise Injection]] [[keywords/specific/Feature Alignment|Feature Alignment]] [[keywords/broad/Deep Learning|Deep Learning]] [[keywords/broad/Neural Networks|Neural Networks]] [[keywords/unique/Discriminative Loss|Discriminative Loss]] [[categories/cs.LG|cs.LG]] [[2025-09-22/Noise-Robustness Through Noise_ Asymmetric LoRA Adaption with Poisoning Expert_20250922|Noise-Robustness Through Noise: Asymmetric LoRA Adaption with Poisoning Expert]] (85.2% similar) [[2025-09-22/A noise-corrected Langevin algorithm and sampling by half-denoising_20250922|A noise-corrected Langevin algorithm and sampling by half-denoising]] (83.7% similar) [[2025-09-18/Not All Degradations Are Equal_ A Targeted Feature Denoising Framework for Generalizable Image Super-Resolution_20250918|Not All Degradations Are Equal: A Targeted Feature Denoising Framework for Generalizable Image Super-Resolution]] (83.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: Gaussian Noise Injection, Feature Alignment
**ğŸ”¬ Broad Technical**: Deep Learning, Neural Networks
**â­ Unique Technical**: Discriminative Loss
## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Noise-Robustness Through Noise_ Asymmetric LoRA Adaption with Poisoning Expert_20250922|Noise-Robustness Through Noise Asymmetric LoRA Adaption with Poisoning Expert]] (85.2% similar)
- [[2025-09-22/A noise-corrected Langevin algorithm and sampling by half-denoising_20250922|A noise-corrected Langevin algorithm and sampling by half-denoising]] (83.7% similar)
- [[2025-09-18/Not All Degradations Are Equal_ A Targeted Feature Denoising Framework for Generalizable Image Super-Resolution_20250918|Not All Degradations Are Equal A Targeted Feature Denoising Framework for Generalizable Image Super-Resolution]] (83.3% similar)
- [[2025-09-22/Nonconvex Decentralized Stochastic Bilevel Optimization under Heavy-Tailed Noises_20250922|Nonconvex Decentralized Stochastic Bilevel Optimization under Heavy-Tailed Noises]] (81.6% similar)
- [[2025-09-18/Efficient Conformal Prediction for Regression Models under Label Noise_20250918|Efficient Conformal Prediction for Regression Models under Label Noise]] (81.3% similar)


**ArXiv ID**: [2405.18499](https://arxiv.org/abs/2405.18499)
**Published**: 2025-09-22
**Category**: cs.LG
**PDF**: [Download](https://arxiv.org/pdf/2405.18499.pdf)


**ArXiv ID**: [2405.18499](https://arxiv.org/abs/2405.18499)
**Published**: 2025-09-22
**Category**: cs.LG
**PDF**: [Download](https://arxiv.org/pdf/2405.18499.pdf)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Noise Robust Deep Learning
**ğŸ”— Specific Connectable**: Gaussian Noise Injection, Feature Alignment
**â­ Unique Technical**: Discriminative Loss
**ğŸ”¬ Broad Technical**: Deep Neural Networks

## ğŸ·ï¸ ì¶”ì¶œëœ í‚¤ì›Œë“œ



`Deep Learning` â€¢ 

`Neural Networks` â€¢ 

`Gaussian Noise Injection` â€¢ 

`Feature Alignment` â€¢ 

`Discriminative Loss`



## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸

Similar papers will be displayed here based on embedding similarity.

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2405.18499v3 Announce Type: replace-cross 
Abstract: Robustness of deep neural networks to input noise remains a critical challenge, as naive noise injection often degrades accuracy on clean (uncorrupted) data. We propose a novel training framework that addresses this trade-off through two complementary objectives. First, we introduce a loss function applied at the penultimate layer that explicitly enforces intra-class compactness and increases the margin to analytically defined decision boundaries. This enhances feature discriminativeness and class separability for clean data. Second, we propose a class-wise feature alignment mechanism that brings noisy data clusters closer to their clean counterparts. Furthermore, we provide a theoretical analysis demonstrating that improving feature stability under additive Gaussian noise implicitly reduces the curvature of the softmax loss landscape in input space, as measured by Hessian eigenvalues.This thus naturally enhances robustness without explicit curvature penalties. Conversely, we also theoretically show that lower curvatures lead to more robust models. We validate the effectiveness of our method on standard benchmarks and our custom dataset. Our approach significantly reinforces model robustness to various perturbations while maintaining high accuracy on clean data, advancing the understanding and practice of noise-robust deep learning.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2405.18499v3 ë°œí‘œ ìœ í˜•: êµì°¨ êµì²´  
ì´ˆë¡: ì…ë ¥ ë…¸ì´ì¦ˆì— ëŒ€í•œ ì‹¬ì¸µ ì‹ ê²½ë§ì˜ ê²¬ê³ ì„±ì€ ì—¬ì „íˆ ì¤‘ìš”í•œ ê³¼ì œë¡œ ë‚¨ì•„ ìˆìœ¼ë©°, ë‹¨ìˆœí•œ ë…¸ì´ì¦ˆ ì£¼ì…ì€ ì¢…ì¢… ê¹¨ë—í•œ(ì†ìƒë˜ì§€ ì•Šì€) ë°ì´í„°ì˜ ì •í™•ë„ë¥¼ ì €í•˜ì‹œí‚µë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì´ ê· í˜• ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë‘ ê°€ì§€ ìƒí˜¸ ë³´ì™„ì ì¸ ëª©í‘œë¥¼ í†µí•´ ìƒˆë¡œìš´ í›ˆë ¨ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì²«ì§¸, ìš°ë¦¬ëŠ” í´ë˜ìŠ¤ ë‚´ ì‘ì§‘ì„±ì„ ëª…ì‹œì ìœ¼ë¡œ ê°•í™”í•˜ê³  ë¶„ì„ì ìœ¼ë¡œ ì •ì˜ëœ ê²°ì • ê²½ê³„ì— ëŒ€í•œ ì—¬ìœ ë¥¼ ì¦ê°€ì‹œí‚¤ëŠ” ì†ì‹¤ í•¨ìˆ˜ë¥¼ ë§ˆì§€ë§‰ì—ì„œ ë‘ ë²ˆì§¸ ì¸µì— ì ìš©í•©ë‹ˆë‹¤. ì´ëŠ” ê¹¨ë—í•œ ë°ì´í„°ì— ëŒ€í•œ íŠ¹ì§•ì˜ ë³€ë³„ë ¥ê³¼ í´ë˜ìŠ¤ ë¶„ë¦¬ë¥¼ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ë‘˜ì§¸, ìš°ë¦¬ëŠ” ë…¸ì´ì¦ˆê°€ ìˆëŠ” ë°ì´í„° í´ëŸ¬ìŠ¤í„°ë¥¼ ê·¸ë“¤ì˜ ê¹¨ë—í•œ ëŒ€ì‘ë¬¼ì— ë” ê°€ê¹ê²Œ ê°€ì ¸ì˜¤ëŠ” í´ë˜ìŠ¤ë³„ íŠ¹ì§• ì •ë ¬ ë©”ì»¤ë‹ˆì¦˜ì„ ì œì•ˆí•©ë‹ˆë‹¤. ë˜í•œ, ìš°ë¦¬ëŠ” ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆê°€ ì¶”ê°€ëœ í™˜ê²½ì—ì„œ íŠ¹ì§• ì•ˆì •ì„±ì„ í–¥ìƒì‹œí‚¤ëŠ” ê²ƒì´ ì…ë ¥ ê³µê°„ì—ì„œ ì†Œí”„íŠ¸ë§¥ìŠ¤ ì†ì‹¤ ì§€í˜•ì˜ ê³¡ë¥ ì„ ì•”ì‹œì ìœ¼ë¡œ ê°ì†Œì‹œí‚¨ë‹¤ëŠ” ì´ë¡ ì  ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ëŠ” í—¤ì„¸ í–‰ë ¬ì˜ ê³ ìœ ê°’ìœ¼ë¡œ ì¸¡ì •ë˜ë©°, ë”°ë¼ì„œ ëª…ì‹œì ì¸ ê³¡ë¥  íŒ¨ë„í‹° ì—†ì´ë„ ìì—°ìŠ¤ëŸ½ê²Œ ê²¬ê³ ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ë°˜ëŒ€ë¡œ, ìš°ë¦¬ëŠ” ë‚®ì€ ê³¡ë¥ ì´ ë” ê²¬ê³ í•œ ëª¨ë¸ë¡œ ì´ì–´ì§„ë‹¤ëŠ” ê²ƒì„ ì´ë¡ ì ìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤. ìš°ë¦¬ëŠ” í‘œì¤€ ë²¤ì¹˜ë§ˆí¬ì™€ ìš°ë¦¬ì˜ ë§ì¶¤í˜• ë°ì´í„°ì…‹ì—ì„œ ìš°ë¦¬ì˜ ë°©ë²•ì˜ íš¨ê³¼ë¥¼ ê²€ì¦í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì ‘ê·¼ ë°©ì‹ì€ ë‹¤ì–‘í•œ êµë€ì— ëŒ€í•œ ëª¨ë¸ì˜ ê²¬ê³ ì„±ì„ í¬ê²Œ ê°•í™”í•˜ë©´ì„œë„ ê¹¨ë—í•œ ë°ì´í„°ì— ëŒ€í•œ ë†’ì€ ì •í™•ë„ë¥¼ ìœ ì§€í•˜ì—¬ ë…¸ì´ì¦ˆ ê²¬ê³ í•œ ì‹¬ì¸µ í•™ìŠµì˜ ì´í•´ì™€ ì‹¤ì²œì„ ë°œì „ì‹œí‚µë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì…ë ¥ ë…¸ì´ì¦ˆì— ëŒ€í•œ ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ ê°•ê±´ì„±ì„ ê°œì„ í•˜ëŠ” ìƒˆë¡œìš´ í•™ìŠµ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì²«ì§¸, ì¤‘ê°„ì¸µì— ì ìš©ë˜ëŠ” ì†ì‹¤ í•¨ìˆ˜ë¥¼ ë„ì…í•˜ì—¬ í´ë˜ìŠ¤ ë‚´ ë°ì´í„°ì˜ ì‘ì§‘ì„±ì„ ë†’ì´ê³  ê²°ì • ê²½ê³„ì˜ ì—¬ìœ ë¥¼ ì¦ê°€ì‹œí‚µë‹ˆë‹¤. ë‘˜ì§¸, ë…¸ì´ì¦ˆ ë°ì´í„° í´ëŸ¬ìŠ¤í„°ë¥¼ ê¹¨ë—í•œ ë°ì´í„°ì™€ ì •ë ¬ì‹œí‚¤ëŠ” í´ë˜ìŠ¤ë³„ íŠ¹ì§• ì •ë ¬ ë©”ì»¤ë‹ˆì¦˜ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ í•˜ì—ì„œ íŠ¹ì§•ì˜ ì•ˆì •ì„±ì„ ê°œì„ í•˜ì—¬ ì†Œí”„íŠ¸ë§¥ìŠ¤ ì†ì‹¤ì˜ ê³¡ë¥ ì„ ìì—°ìŠ¤ëŸ½ê²Œ ê°ì†Œì‹œí‚µë‹ˆë‹¤. ì´ë¡ ì ìœ¼ë¡œ ë‚®ì€ ê³¡ë¥ ì´ ë” ê°•ê±´í•œ ëª¨ë¸ì„ ë§Œë“ ë‹¤ëŠ” ê²ƒì„ ì¦ëª…í•©ë‹ˆë‹¤. ì œì•ˆëœ ë°©ë²•ì€ í‘œì¤€ ë²¤ì¹˜ë§ˆí¬ì™€ ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ì—ì„œ ê²€ì¦ë˜ì—ˆìœ¼ë©°, ë‹¤ì–‘í•œ ë…¸ì´ì¦ˆì— ëŒ€í•œ ëª¨ë¸ì˜ ê°•ê±´ì„±ì„ í¬ê²Œ ê°•í™”í•˜ë©´ì„œë„ ê¹¨ë—í•œ ë°ì´í„°ì— ëŒ€í•œ ë†’ì€ ì •í™•ë„ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸


- 1. ì…ë ¥ ë…¸ì´ì¦ˆì— ëŒ€í•œ ì‹¬ì¸µ ì‹ ê²½ë§ì˜ ê°•ê±´ì„±ì„ ê°œì„ í•˜ê¸° ìœ„í•´ ë‘ ê°€ì§€ ìƒí˜¸ ë³´ì™„ì ì¸ ëª©í‘œë¥¼ ì œì•ˆí•˜ëŠ” ìƒˆë¡œìš´ í›ˆë ¨ í”„ë ˆì„ì›Œí¬ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤.

- 2. ì „ì¸µ ì†ì‹¤ í•¨ìˆ˜ë¥¼ ë„ì…í•˜ì—¬ í´ë˜ìŠ¤ ë‚´ ì••ì¶•ì„±ì„ ëª…ì‹œì ìœ¼ë¡œ ê°•í™”í•˜ê³ , ê²°ì • ê²½ê³„ì— ëŒ€í•œ ë§ˆì§„ì„ ì¦ê°€ì‹œì¼œ ê¹¨ë—í•œ ë°ì´í„°ì˜ íŠ¹ì§• êµ¬ë³„ì„±ê³¼ í´ë˜ìŠ¤ ë¶„ë¦¬ë¥¼ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

- 3. í´ë˜ìŠ¤ë³„ íŠ¹ì§• ì •ë ¬ ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´ ë…¸ì´ì¦ˆê°€ ìˆëŠ” ë°ì´í„° í´ëŸ¬ìŠ¤í„°ë¥¼ ê¹¨ë—í•œ ë°ì´í„° í´ëŸ¬ìŠ¤í„°ì— ë” ê°€ê¹ê²Œ ë§Œë“­ë‹ˆë‹¤.

- 4. ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ í•˜ì—ì„œ íŠ¹ì§• ì•ˆì •ì„±ì„ ê°œì„ í•˜ë©´ ì…ë ¥ ê³µê°„ì˜ ì†Œí”„íŠ¸ë§¥ìŠ¤ ì†ì‹¤ ê³¡ë¥ ì´ ìì—°ìŠ¤ëŸ½ê²Œ ê°ì†Œí•˜ì—¬ ê°•ê±´ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

- 5. ì œì•ˆëœ ë°©ë²•ì€ ë‹¤ì–‘í•œ êµë€ì— ëŒ€í•œ ëª¨ë¸ì˜ ê°•ê±´ì„±ì„ í¬ê²Œ ê°•í™”í•˜ë©´ì„œë„ ê¹¨ë—í•œ ë°ì´í„°ì— ëŒ€í•œ ë†’ì€ ì •í™•ë„ë¥¼ ìœ ì§€í•¨ì„ í‘œì¤€ ë²¤ì¹˜ë§ˆí¬ì™€ ì‚¬ìš©ì ì •ì˜ ë°ì´í„°ì…‹ì„ í†µí•´ ê²€ì¦í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-22 16:06:20*