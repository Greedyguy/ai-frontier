
# Hybrid Quantum-Classical Neural Networks for Few-Shot Credit Risk Assessment

**Korean Title:** 퓨-샷 신용 위험 평가를 위한 하이브리드 양자-고전적 신경망

## 📋 메타데이터

**Links**: [[daily/2025-09-18|2025-09-18]] [[keywords/evolved/Ensemble Learning|Ensemble Learning]] [[keywords/broad/Quantum Machine Learning|Quantum Machine Learning]] [[keywords/broad/Hybrid Quantum-Classical Neural Networks|Hybrid Quantum-Classical Neural Networks]] [[keywords/specific/Few-shot Learning|Few-shot Learning]] [[keywords/unique/QNN|QNN]] [[categories/cs.LG|cs.LG]]

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Ensemble Learning
**🔬 Broad Technical**: Quantum Machine Learning, Hybrid Quantum-Classical Neural Networks
**🔗 Specific Connectable**: Few-shot Learning
**⭐ Unique Technical**: QNN

**ArXiv ID**: [2509.13818](https://arxiv.org/abs/2509.13818)
**Published**: 2025-09-18
**Category**: cs.LG
**PDF**: [Download](https://arxiv.org/pdf/2509.13818.pdf)


## 🏷️ 추출된 키워드



`Quantum Machine Learning` • 

`Hybrid Quantum-Classical Neural Networks` • 

`Few-shot Learning` • 

`QNN` • 

`Ensemble Learning`



## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.13818v1 Announce Type: new 
Abstract: Quantum Machine Learning (QML) offers a new paradigm for addressing complex financial problems intractable for classical methods. This work specifically tackles the challenge of few-shot credit risk assessment, a critical issue in inclusive finance where data scarcity and imbalance limit the effectiveness of conventional models. To address this, we design and implement a novel hybrid quantum-classical workflow. The methodology first employs an ensemble of classical machine learning models (Logistic Regression, Random Forest, XGBoost) for intelligent feature engineering and dimensionality reduction. Subsequently, a Quantum Neural Network (QNN), trained via the parameter-shift rule, serves as the core classifier. This framework was evaluated through numerical simulations and deployed on the Quafu Quantum Cloud Platform's ScQ-P21 superconducting processor. On a real-world credit dataset of 279 samples, our QNN achieved a robust average AUC of 0.852 +/- 0.027 in simulations and yielded an impressive AUC of 0.88 in the hardware experiment. This performance surpasses a suite of classical benchmarks, with a particularly strong result on the recall metric. This study provides a pragmatic blueprint for applying quantum computing to data-constrained financial scenarios in the NISQ era and offers valuable empirical evidence supporting its potential in high-stakes applications like inclusive finance.

## 🔍 Abstract (한글 번역)

arXiv:2509.13818v1 발표 유형: 새로운
요약: 양자 기계 학습(QML)은 고전적 방법으로는 해결하기 어려운 복잡한 금융 문제를 다루는 새로운 패러다임을 제공합니다. 본 연구는 특히 데이터 부족과 불균형으로 인해 전통적 모델의 효과성이 제한되는 포괄적 금융에서의 소수 샷 신용 위험 평가의 과제에 대응합니다. 이를 해결하기 위해 우리는 새로운 하이브리드 양자-고전적 워크플로우를 설계하고 구현했습니다. 이 방법론은 먼저 지능적인 특성 공학과 차원 축소를 위해 고전적 기계 학습 모델 (로지스틱 회귀, 랜덤 포레스트, XGBoost)의 앙상블을 사용합니다. 이후에는 파라미터-시프트 규칙을 통해 훈련된 양자 신경망(QNN)이 핵심 분류기로 작용합니다. 이 프레임워크는 수치 시뮬레이션을 통해 평가되었으며 Quafu 양자 클라우드 플랫폼의 ScQ-P21 초전도 프로세서에 배포되었습니다. 279개의 실제 신용 데이터 세트에서, 우리의 QNN은 시뮬레이션에서 안정적인 평균 AUC 0.852 +/- 0.027을 달성하였으며 하드웨어 실험에서 0.88의 인상적인 AUC를 얻었습니다. 이 성능은 특히 회수 메트릭에서 강력한 결과를 보이며 고전적 벤치마크를 능가합니다. 본 연구는 NISQ 시대의 데이터 제약 금융 시나리오에 양자 컴퓨팅을 적용하는 실용적인 청사진을 제공하며 포괄적 금융과 같은 고위험 응용 분야에서의 잠재력을 지원하는 가치 있는 경험적 증거를 제시합니다.

## 📝 요약

본 연구는 양자 기계 학습(QML)을 활용하여 전통적인 방법으로는 해결하기 어려운 복잡한 금융 문제에 대한 새로운 패러다임을 제시한다. 특히, 소수의 데이터로 신용 위험을 평가하는 것을 목표로 하며, 이를 위해 혼합 양자-고전적 워크플로우를 설계하고 구현한다. 이 방법론은 먼저 로지스틱 회귀, 랜덤 포레스트, XGBoost와 같은 고전적 기계 학습 모델 앙상블을 활용하여 지능적인 특성 공학과 차원 축소를 수행한다. 그 후, 파라미터-시프트 규칙을 통해 훈련된 양자 신경망(QNN)이 핵심 분류기로 작용한다. 이 프레임워크는 수치 시뮬레이션을 통해 평가되었으며, 실제 하드웨어 실험에서 0.88의 높은 AUC를 달성하였다. 이 연구는 NISQ 시대의 데이터 제약적 금융 시나리오에 양자 컴퓨팅을 적용하는 실용적인 청사진을 제시하고, 포괄적인 금융과 같은 고위험 응용 분야에서의 잠재력을 지지하는 소중한 경험적 증거를 제공한다.

## 🎯 주요 포인트


- 1. 양자 기계 학습(QML)은 고전적 방법으로는 해결하기 어려운 복잡한 금융 문제를 다루는 새로운 패러다임을 제공한다.

- 2. 이 연구는 소수의 데이터로는 효과적인 모델의 성능을 제한하는 데이터 부족과 불균형이라는 문제에 대처하기 위해 혼합 양자-고전적 워크플로우를 설계하고 구현했다.

- 3. 양자 신경망(QNN)을 핵심 분류기로 사용하여 실제 신용 데이터셋에서 뛰어난 성과를 보여주었으며, 고전적 벤치마크를 능가하는 결과를 얻었다.


---

*Generated on 2025-09-18 16:39:10*