# Toxicity Red-Teaming: Benchmarking LLM Safety in Singapore's Low-Resource Languages

**Korean Title:** ë…ì„± ë ˆë“œíŒ€: ì‹±ê°€í¬ë¥´ì˜ ì €ìì› ì–¸ì–´ì—ì„œ LLM ì•ˆì „ì„± ë²¤ì¹˜ë§ˆí‚¹

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[reports/digests/daily_digest_20250922|2025-09-22]] [[keywords/evolved/Red-Teaming Approach|Red-Teaming Approach]] [[keywords/specific/Multilingual LLMs|Multilingual LLMs]] [[keywords/broad/Large Language Models|Large Language Models]] [[keywords/broad/Natural Language Processing|Natural Language Processing]] [[keywords/unique/SGToxicGuard|SGToxicGuard]] [[categories/cs.CL|cs.CL]] [[2025-09-22/SABER_ Uncovering Vulnerabilities in Safety Alignment via Cross-Layer Residual Connection_20250922|SABER: Uncovering Vulnerabilities in Safety Alignment via Cross-Layer Residual Connection]] (85.2% similar) [[2025-09-22/Exploring the Impact of Personality Traits on LLM Bias and Toxicity_20250922|Exploring the Impact of Personality Traits on LLM Bias and Toxicity]] (84.7% similar) [[2025-09-19/Enterprise AI Must Enforce Participant-Aware Access Control_20250919|Enterprise AI Must Enforce Participant-Aware Access Control]] (84.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Red-Teaming Approach
**ğŸ”— Specific Connectable**: Multilingual LLMs
**ğŸ”¬ Broad Technical**: Large Language Models, Natural Language Processing
**â­ Unique Technical**: SGToxicGuard
## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/SABER_ Uncovering Vulnerabilities in Safety Alignment via Cross-Layer Residual Connection_20250922|SABER Uncovering Vulnerabilities in Safety Alignment via Cross-Layer Residual Connection]] (85.2% similar)
- [[2025-09-22/Exploring the Impact of Personality Traits on LLM Bias and Toxicity_20250922|Exploring the Impact of Personality Traits on LLM Bias and Toxicity]] (84.7% similar)
- [[2025-09-19/Enterprise AI Must Enforce Participant-Aware Access Control_20250919|Enterprise AI Must Enforce Participant-Aware Access Control]] (84.5% similar)
- [[2025-09-18/Evaluating and Improving the Robustness of Security Attack Detectors Generated by LLMs_20250918|Evaluating and Improving the Robustness of Security Attack Detectors Generated by LLMs]] (84.5% similar)
- [[2025-09-17/Simulating a Bias Mitigation Scenario in Large Language Models_20250917|Simulating a Bias Mitigation Scenario in Large Language Models]] (84.0% similar)


**ArXiv ID**: [2509.15260](https://arxiv.org/abs/2509.15260)
**Published**: 2025-09-22
**Category**: cs.CL
**PDF**: [Download](https://arxiv.org/pdf/2509.15260.pdf)


**ArXiv ID**: [2509.15260](https://arxiv.org/abs/2509.15260)
**Published**: 2025-09-22
**Category**: cs.CL
**PDF**: [Download](https://arxiv.org/pdf/2509.15260.pdf)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Red-Teaming Approach
**ğŸ”— Specific Connectable**: Multilingual LLMs
**â­ Unique Technical**: SGToxicGuard
**ğŸ”¬ Broad Technical**: Large Language Models, Natural Language Processing

## ğŸ·ï¸ ì¶”ì¶œëœ í‚¤ì›Œë“œ



`Large Language Models` â€¢ 

`Natural Language Processing` â€¢ 

`Multilingual LLMs` â€¢ 

`SGToxicGuard` â€¢ 

`Red-teaming Approach`



## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸

Similar papers will be displayed here based on embedding similarity.

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15260v1 Announce Type: new 
Abstract: The advancement of Large Language Models (LLMs) has transformed natural language processing; however, their safety mechanisms remain under-explored in low-resource, multilingual settings. Here, we aim to bridge this gap. In particular, we introduce \textsf{SGToxicGuard}, a novel dataset and evaluation framework for benchmarking LLM safety in Singapore's diverse linguistic context, including Singlish, Chinese, Malay, and Tamil. SGToxicGuard adopts a red-teaming approach to systematically probe LLM vulnerabilities in three real-world scenarios: \textit{conversation}, \textit{question-answering}, and \textit{content composition}. We conduct extensive experiments with state-of-the-art multilingual LLMs, and the results uncover critical gaps in their safety guardrails. By offering actionable insights into cultural sensitivity and toxicity mitigation, we lay the foundation for safer and more inclusive AI systems in linguistically diverse environments.\footnote{Link to the dataset: https://github.com/Social-AI-Studio/SGToxicGuard.} \textcolor{red}{Disclaimer: This paper contains sensitive content that may be disturbing to some readers.}

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15260v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì˜ ë°œì „ì€ ìì—°ì–´ ì²˜ë¦¬ ë¶„ì•¼ì— í˜ì‹ ì„ ê°€ì ¸ì™”ì§€ë§Œ, ì €ìì› ë‹¤êµ­ì–´ í™˜ê²½ì—ì„œì˜ ì•ˆì „ ë©”ì»¤ë‹ˆì¦˜ì€ ì—¬ì „íˆ ì¶©ë¶„íˆ íƒêµ¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” ì´ ê²©ì°¨ë¥¼ í•´ì†Œí•˜ê³ ì í•©ë‹ˆë‹¤. íŠ¹íˆ, ì‹±ê°€í¬ë¥´ì˜ ë‹¤ì–‘í•œ ì–¸ì–´ì  ë§¥ë½(ì‹±ê¸€ë¦¬ì‹œ, ì¤‘êµ­ì–´, ë§ë ˆì´ì–´, íƒ€ë°€ì–´ í¬í•¨)ì—ì„œ LLMì˜ ì•ˆì „ì„±ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ë°ì´í„°ì…‹ ë° í‰ê°€ í”„ë ˆì„ì›Œí¬ì¸ \textsf{SGToxicGuard}ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. SGToxicGuardëŠ” ë ˆë“œíŒ€ ì ‘ê·¼ë²•ì„ ì±„íƒí•˜ì—¬ \textit{ëŒ€í™”}, \textit{ì§ˆë¬¸-ì‘ë‹µ}, \textit{ì½˜í…ì¸  ì‘ì„±}ì˜ ì„¸ ê°€ì§€ ì‹¤ì œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ LLMì˜ ì·¨ì•½ì ì„ ì²´ê³„ì ìœ¼ë¡œ íƒìƒ‰í•©ë‹ˆë‹¤. ìµœì²¨ë‹¨ ë‹¤êµ­ì–´ LLMì„ ì‚¬ìš©í•˜ì—¬ ê´‘ë²”ìœ„í•œ ì‹¤í—˜ì„ ìˆ˜í–‰í•œ ê²°ê³¼, ì´ë“¤ì˜ ì•ˆì „ ì¥ì¹˜ì— ì¤‘ìš”í•œ ê²©ì°¨ê°€ ìˆìŒì„ ë°í˜€ëƒˆìŠµë‹ˆë‹¤. ë¬¸í™”ì  ë¯¼ê°ì„±ê³¼ ë…ì„± ì™„í™”ì— ëŒ€í•œ ì‹¤í–‰ ê°€ëŠ¥í•œ í†µì°°ë ¥ì„ ì œê³µí•¨ìœ¼ë¡œì¨, ì–¸ì–´ì ìœ¼ë¡œ ë‹¤ì–‘í•œ í™˜ê²½ì—ì„œ ë” ì•ˆì „í•˜ê³  í¬ìš©ì ì¸ AI ì‹œìŠ¤í…œì„ ìœ„í•œ ê¸°ì´ˆë¥¼ ë§ˆë ¨í•©ë‹ˆë‹¤.\footnote{ë°ì´í„°ì…‹ ë§í¬: https://github.com/Social-AI-Studio/SGToxicGuard.} \textcolor{red}{ë©´ì±… ì¡°í•­: ì´ ë…¼ë¬¸ì—ëŠ” ì¼ë¶€ ë…ìì—ê²Œ ë¶ˆì¾Œê°ì„ ì¤„ ìˆ˜ ìˆëŠ” ë¯¼ê°í•œ ë‚´ìš©ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.}

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì•ˆì „ ë©”ì»¤ë‹ˆì¦˜ì´ ì €ìì›, ë‹¤ì–¸ì–´ í™˜ê²½ì—ì„œ ì¶©ë¶„íˆ íƒêµ¬ë˜ì§€ ì•Šì•˜ìŒì„ ì§€ì í•˜ë©°, ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ \textsf{SGToxicGuard}ë¼ëŠ” ìƒˆë¡œìš´ ë°ì´í„°ì…‹ê³¼ í‰ê°€ í”„ë ˆì„ì›Œí¬ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ì‹±ê°€í¬ë¥´ì˜ ë‹¤ì–‘í•œ ì–¸ì–´ì  ë§¥ë½ì„ ë°˜ì˜í•œ ì´ í”„ë ˆì„ì›Œí¬ëŠ” Singlish, ì¤‘êµ­ì–´, ë§ë ˆì´ì–´, íƒ€ë°€ì–´ë¥¼ í¬í•¨í•˜ì—¬ LLMì˜ ì•ˆì „ì„±ì„ í‰ê°€í•©ë‹ˆë‹¤. \textsf{SGToxicGuard}ëŠ” ëŒ€í™”, ì§ˆë¬¸-ì‘ë‹µ, ì½˜í…ì¸  ì‘ì„±ì˜ ì„¸ ê°€ì§€ ì‹¤ì œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ LLMì˜ ì·¨ì•½ì ì„ ì²´ê³„ì ìœ¼ë¡œ íƒìƒ‰í•˜ëŠ” ë ˆë“œíŒ€ ì ‘ê·¼ ë°©ì‹ì„ ì±„íƒí•©ë‹ˆë‹¤. ìµœì‹  ë‹¤ì–¸ì–´ LLMì„ ëŒ€ìƒìœ¼ë¡œ í•œ ì‹¤í—˜ ê²°ê³¼, ì•ˆì „ì„±ì— ì¤‘ìš”í•œ ê²©ì°¨ê°€ ìˆìŒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ë¬¸í™”ì  ë¯¼ê°ì„±ê³¼ ë…ì„± ì™„í™”ì— ëŒ€í•œ ì‹¤ì§ˆì ì¸ í†µì°°ì„ ì œê³µí•˜ì—¬ ì–¸ì–´ì ìœ¼ë¡œ ë‹¤ì–‘í•œ í™˜ê²½ì—ì„œ ë” ì•ˆì „í•˜ê³  í¬ìš©ì ì¸ AI ì‹œìŠ¤í…œì˜ ê¸°ì´ˆë¥¼ ë§ˆë ¨í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸


- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì•ˆì „ ë©”ì»¤ë‹ˆì¦˜ì€ ì €ìì›, ë‹¤ì–¸ì–´ í™˜ê²½ì—ì„œ ì¶©ë¶„íˆ íƒêµ¬ë˜ì§€ ì•Šì•˜ë‹¤.

- 2. SGToxicGuardëŠ” ì‹±ê°€í¬ë¥´ì˜ ë‹¤ì–‘í•œ ì–¸ì–´ì  ë§¥ë½ì—ì„œ LLMì˜ ì•ˆì „ì„±ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ë°ì´í„°ì…‹ ë° í‰ê°€ í”„ë ˆì„ì›Œí¬ì´ë‹¤.

- 3. SGToxicGuardëŠ” ëŒ€í™”, ì§ˆë¬¸-ì‘ë‹µ, ì½˜í…ì¸  êµ¬ì„±ì˜ ì„¸ ê°€ì§€ ì‹¤ì œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ LLMì˜ ì·¨ì•½ì„±ì„ ì²´ê³„ì ìœ¼ë¡œ íƒìƒ‰í•œë‹¤.

- 4. ìµœì²¨ë‹¨ ë‹¤ì–¸ì–´ LLMì„ ëŒ€ìƒìœ¼ë¡œ í•œ ì‹¤í—˜ ê²°ê³¼, ì•ˆì „ì„±ì˜ ì¤‘ìš”í•œ ê²©ì°¨ê°€ ë“œëŸ¬ë‚¬ë‹¤.

- 5. ë¬¸í™”ì  ë¯¼ê°ì„±ê³¼ ë…ì„± ì™„í™”ì— ëŒ€í•œ ì‹¤í–‰ ê°€ëŠ¥í•œ í†µì°°ì„ ì œê³µí•˜ì—¬, ì–¸ì–´ì ìœ¼ë¡œ ë‹¤ì–‘í•œ í™˜ê²½ì—ì„œ ë” ì•ˆì „í•˜ê³  í¬ìš©ì ì¸ AI ì‹œìŠ¤í…œì˜ ê¸°ì´ˆë¥¼ ë§ˆë ¨í•œë‹¤.


---

*Generated on 2025-09-22 16:19:04*