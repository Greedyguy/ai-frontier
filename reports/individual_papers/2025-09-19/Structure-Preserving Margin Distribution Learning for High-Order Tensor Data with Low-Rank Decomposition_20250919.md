---
keywords:
  - Optimization
  - Large Margin Distribution Machine
  - Low-Rank Decomposition
category: cs.AI
publish_date: 2025-09-19
arxiv_id: 2509.14577
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 21:23:11.707325",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Optimization",
    "Large Margin Distribution Machine",
    "Low-Rank Decomposition"
  ],
  "rejected_keywords": [
    "High-Order Tensor Data",
    "Tucker Decomposition"
  ],
  "similarity_scores": {
    "Optimization": 0.79,
    "Large Margin Distribution Machine": 0.78,
    "Low-Rank Decomposition": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->


# Structure-Preserving Margin Distribution Learning for High-Order Tensor Data with Low-Rank Decomposition

**Korean Title:** ê³ ì°¨ì› í…ì„œ ë°ì´í„°ì˜ ì €ìˆœìœ„ ë¶„í•´ë¥¼ í†µí•œ êµ¬ì¡° ë³´ì¡´ ë§ˆì§„ ë¶„í¬ í•™ìŠµ

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[digests/daily_digest_20250919|2025-09-19]]   [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸŒ Broad Technical**: [[keywords/Optimization|Alternating Optimization]]
**ğŸ”— Specific Connectable**: [[keywords/Low-Rank Decomposition|Low-Rank Decomposition]]
**âš¡ Unique Technical**: [[keywords/Large Margin Distribution Machine|Large Margin Distribution Machine]]

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[Middo Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning]] (77.3% similar)
- [[SMARTER A Data-efficient Framework to Improve Toxicity Detection with Explanation via Self-augmenting Large Language Models]] (76.9% similar)
- [[Taylor-Series_Expanded_Kolmogorov-Arnold_Network_for_Medical_Imaging_Classification_20250918|Taylor-Series Expanded Kolmogorov-Arnold Network for Medical Imaging Classification]] (76.5% similar)
- [[Superpose_Task-specific_Features_for_Model_Merging_20250919|Superpose Task-specific Features for Model Merging]] (76.5% similar)
- [[Data-Driven_Distributed_Optimization_via_Aggregative_Tracking_and_Deep-Learning_20250918|Data-Driven Distributed Optimization via Aggregative Tracking and Deep-Learning]] (76.4% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.14577v1 Announce Type: new 
Abstract: The Large Margin Distribution Machine (LMDM) is a recent advancement in classifier design that optimizes not just the minimum margin (as in SVM) but the entire margin distribution, thereby improving generalization. However, existing LMDM formulations are limited to vectorized inputs and struggle with high-dimensional tensor data due to the need for flattening, which destroys the data's inherent multi-mode structure and increases computational burden. In this paper, we propose a Structure-Preserving Margin Distribution Learning for High-Order Tensor Data with Low-Rank Decomposition (SPMD-LRT) that operates directly on tensor representations without vectorization. The SPMD-LRT preserves multi-dimensional spatial structure by incorporating first-order and second-order tensor statistics (margin mean and variance) into the objective, and it leverages low-rank tensor decomposition techniques including rank-1(CP), higher-rank CP, and Tucker decomposition to parameterize the weight tensor. An alternating optimization (double-gradient descent) algorithm is developed to efficiently solve the SPMD-LRT, iteratively updating factor matrices and core tensor. This approach enables SPMD-LRT to maintain the structural information of high-order data while optimizing margin distribution for improved classification. Extensive experiments on diverse datasets (including MNIST, images and fMRI neuroimaging) demonstrate that SPMD-LRT achieves superior classification accuracy compared to conventional SVM, vector-based LMDM, and prior tensor-based SVM extensions (Support Tensor Machines and Support Tucker Machines). Notably, SPMD-LRT with Tucker decomposition attains the highest accuracy, highlighting the benefit of structure preservation. These results confirm the effectiveness and robustness of SPMD-LRT in handling high-dimensional tensor data for classification.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.14577v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: ëŒ€í˜• ë§ˆì§„ ë¶„í¬ ê¸°ê³„(LMDM)ëŠ” ìµœê·¼ ë¶„ë¥˜ê¸° ì„¤ê³„ì—ì„œì˜ ë°œì „ìœ¼ë¡œ, ìµœì†Œ ë§ˆì§„(SVMì—ì„œì²˜ëŸ¼)ë¿ë§Œ ì•„ë‹ˆë¼ ì „ì²´ ë§ˆì§„ ë¶„í¬ë¥¼ ìµœì í™”í•˜ì—¬ ì¼ë°˜í™”ë¥¼ ê°œì„ í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê¸°ì¡´ì˜ LMDM ê³µì‹ì€ ë²¡í„°í™”ëœ ì…ë ¥ì—ë§Œ ì œí•œë˜ë©°, ê³ ì°¨ì› í…ì„œ ë°ì´í„°ì— ëŒ€í•´ì„œëŠ” í‰íƒ„í™”ê°€ í•„ìš”í•˜ì—¬ ë°ì´í„°ì˜ ê³ ìœ í•œ ë‹¤ì¤‘ ëª¨ë“œ êµ¬ì¡°ë¥¼ íŒŒê´´í•˜ê³  ê³„ì‚° ë¶€ë‹´ì„ ì¦ê°€ì‹œí‚µë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ë²¡í„°í™” ì—†ì´ í…ì„œ í‘œí˜„ì—ì„œ ì§ì ‘ ì‘ë™í•˜ëŠ” ê³ ì°¨ì› í…ì„œ ë°ì´í„°ë¥¼ ìœ„í•œ êµ¬ì¡° ë³´ì¡´ ë§ˆì§„ ë¶„í¬ í•™ìŠµ(SPMD-LRT)ì„ ì œì•ˆí•©ë‹ˆë‹¤. SPMD-LRTëŠ” ëª©ì  í•¨ìˆ˜ì— 1ì°¨ ë° 2ì°¨ í…ì„œ í†µê³„(ë§ˆì§„ í‰ê·  ë° ë¶„ì‚°)ë¥¼ í¬í•¨í•˜ì—¬ ë‹¤ì°¨ì› ê³µê°„ êµ¬ì¡°ë¥¼ ë³´ì¡´í•˜ë©°, ë­í¬-1(CP), ê³ ì°¨ì› CP, í„°ì»¤ ë¶„í•´ë¥¼ í¬í•¨í•œ ì €ë­í¬ í…ì„œ ë¶„í•´ ê¸°ë²•ì„ í™œìš©í•˜ì—¬ ê°€ì¤‘ì¹˜ í…ì„œë¥¼ ë§¤ê°œë³€ìˆ˜í™”í•©ë‹ˆë‹¤. êµëŒ€ ìµœì í™”(ì´ì¤‘ ê²½ì‚¬ í•˜ê°•) ì•Œê³ ë¦¬ì¦˜ì´ ê°œë°œë˜ì–´ SPMD-LRTë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ í•´ê²°í•˜ë©°, ìš”ì†Œ í–‰ë ¬ê³¼ ì½”ì–´ í…ì„œë¥¼ ë°˜ë³µì ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤. ì´ ì ‘ê·¼ ë°©ì‹ì€ SPMD-LRTê°€ ê³ ì°¨ì› ë°ì´í„°ì˜ êµ¬ì¡°ì  ì •ë³´ë¥¼ ìœ ì§€í•˜ë©´ì„œ ë§ˆì§„ ë¶„í¬ë¥¼ ìµœì í™”í•˜ì—¬ ë¶„ë¥˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤. ë‹¤ì–‘í•œ ë°ì´í„°ì…‹(MNIST, ì´ë¯¸ì§€ ë° fMRI ì‹ ê²½ì˜ìƒ í¬í•¨)ì— ëŒ€í•œ ê´‘ë²”ìœ„í•œ ì‹¤í—˜ ê²°ê³¼, SPMD-LRTëŠ” ê¸°ì¡´ SVM, ë²¡í„° ê¸°ë°˜ LMDM ë° ì´ì „ì˜ í…ì„œ ê¸°ë°˜ SVM í™•ì¥(ì„œí¬íŠ¸ í…ì„œ ë¨¸ì‹  ë° ì„œí¬íŠ¸ í„°ì»¤ ë¨¸ì‹ )ê³¼ ë¹„êµí•˜ì—¬ ìš°ìˆ˜í•œ ë¶„ë¥˜ ì •í™•ë„ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. íŠ¹íˆ, í„°ì»¤ ë¶„í•´ë¥¼ ì‚¬ìš©í•œ SPMD-LRTëŠ” ê°€ì¥ ë†’ì€ ì •í™•ë„ë¥¼ ë‹¬ì„±í•˜ì—¬ êµ¬ì¡° ë³´ì¡´ì˜ ì´ì ì„ ê°•ì¡°í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ê²°ê³¼ëŠ” SPMD-LRTê°€ ê³ ì°¨ì› í…ì„œ ë°ì´í„°ë¥¼ ë¶„ë¥˜í•˜ëŠ” ë° ìˆì–´ íš¨ê³¼ì ì´ê³  ê²¬ê³ í•¨ì„ í™•ì¸ì‹œì¼œ ì¤ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ê³ ì°¨ì› í…ì„œ ë°ì´í„°ë¥¼ ë‹¤ë£¨ëŠ” ìƒˆë¡œìš´ ë¶„ë¥˜ê¸° ì„¤ê³„ë²•ì¸ êµ¬ì¡° ë³´ì¡´ ë§ˆì§„ ë¶„í¬ í•™ìŠµ(SPMD-LRT)ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ëŒ€í˜• ë§ˆì§„ ë¶„í¬ ê¸°ê³„(LMDM)ëŠ” ë²¡í„°í™”ëœ ì…ë ¥ì— í•œì •ë˜ì–´ ê³ ì°¨ì› í…ì„œ ë°ì´í„° ì²˜ë¦¬ì— í•œê³„ê°€ ìˆì—ˆìœ¼ë‚˜, SPMD-LRTëŠ” ë²¡í„°í™” ì—†ì´ í…ì„œ í‘œí˜„ì„ ì§ì ‘ í™œìš©í•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ í…ì„œì˜ ë‹¤ì°¨ì› êµ¬ì¡°ë¥¼ ë³´ì¡´í•˜ë©°, ì €ë­í¬ í…ì„œ ë¶„í•´ ê¸°ë²•ì„ ì‚¬ìš©í•˜ì—¬ ë§ˆì§„ ë¶„í¬ë¥¼ ìµœì í™”í•©ë‹ˆë‹¤. ì œì•ˆëœ ì•Œê³ ë¦¬ì¦˜ì€ ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ì—ì„œ ê¸°ì¡´ ë°©ë²•ë“¤ë³´ë‹¤ ìš°ìˆ˜í•œ ë¶„ë¥˜ ì •í™•ë„ë¥¼ ë³´ì˜€ìœ¼ë©°, íŠ¹íˆ Tucker ë¶„í•´ë¥¼ ì‚¬ìš©í•œ ê²½ìš° ê°€ì¥ ë†’ì€ ì •í™•ë„ë¥¼ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” êµ¬ì¡° ë³´ì¡´ì˜ ì´ì ì„ ê°•ì¡°í•˜ë©°, SPMD-LRTì˜ íš¨ê³¼ì„±ê³¼ ê°•ê±´í•¨ì„ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Large Margin Distribution Machine (LMDM)ì€ ìµœì†Œ ë§ˆì§„ë¿ë§Œ ì•„ë‹ˆë¼ ì „ì²´ ë§ˆì§„ ë¶„í¬ë¥¼ ìµœì í™”í•˜ì—¬ ì¼ë°˜í™”ë¥¼ ê°œì„ í•©ë‹ˆë‹¤.

- 2. ê¸°ì¡´ LMDMì€ ë²¡í„°í™”ëœ ì…ë ¥ì— êµ­í•œë˜ì–´ ê³ ì°¨ì› í…ì„œ ë°ì´í„° ì²˜ë¦¬ì— ì–´ë ¤ì›€ì„ ê²ªìŠµë‹ˆë‹¤.

- 3. ì œì•ˆëœ SPMD-LRTëŠ” ë²¡í„°í™”ë¥¼ í”¼í•˜ê³  í…ì„œ í‘œí˜„ì„ ì§ì ‘ ë‹¤ë£¨ì–´ ë‹¤ì°¨ì› ê³µê°„ êµ¬ì¡°ë¥¼ ë³´ì¡´í•©ë‹ˆë‹¤.

- 4. SPMD-LRTëŠ” ì €ë­í¬ í…ì„œ ë¶„í•´ ê¸°ë²•ì„ í™œìš©í•˜ì—¬ ê³ ì°¨ì› ë°ì´í„°ì˜ êµ¬ì¡° ì •ë³´ë¥¼ ìœ ì§€í•˜ë©´ì„œ ë§ˆì§„ ë¶„í¬ë¥¼ ìµœì í™”í•©ë‹ˆë‹¤.

- 5. ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ ì‹¤í—˜ ê²°ê³¼, SPMD-LRTëŠ” ê¸°ì¡´ SVM ë° í…ì„œ ê¸°ë°˜ SVM í™•ì¥ë³´ë‹¤ ìš°ìˆ˜í•œ ë¶„ë¥˜ ì •í™•ë„ë¥¼ ë‹¬ì„±í•©ë‹ˆë‹¤.

---

*Generated on 2025-09-19 15:25:12*