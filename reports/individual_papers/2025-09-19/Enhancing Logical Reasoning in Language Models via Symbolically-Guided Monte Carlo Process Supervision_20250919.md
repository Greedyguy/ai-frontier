
# Enhancing Logical Reasoning in Language Models via Symbolically-Guided Monte Carlo Process Supervision

**Korean Title:** ì–¸ì–´ ëª¨ë¸ì—ì„œ ë…¼ë¦¬ì  ì¶”ë¡ ì„ ê°•í™”í•˜ê¸° ìœ„í•œ ìƒì§•ì ìœ¼ë¡œ ìœ ë„ëœ ëª¬í…Œì¹´ë¥¼ë¡œ í”„ë¡œì„¸ìŠ¤ ê°ë…

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-19|2025-09-19]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: Monte Carlo Estimation, Supervised Fine-Tuning

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[THOR Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning]] (85.4% similar)
- [[Explicit Reasoning Makes Better Judges A Systematic Study on Accuracy, Efficiency, and Robustness]] (85.2% similar)
- [[Modular Machine Learning An Indispensable Path towards New-Generation Large Language Models]] (85.1% similar)
- [[Opening the Black Box Interpretable LLMs via Semantic Resonance Architecture]] (85.0% similar)
- [[Internalizing Self-Consistency in Language Models Multi-Agent Consensus Alignment]] (84.6% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2505.20415v2 Announce Type: replace 
Abstract: Large language models (LLMs) have shown strong performance in many reasoning benchmarks. However, recent studies have pointed to memorization, rather than generalization, as one of the leading causes for such performance. LLMs, in fact, are susceptible to content variations, demonstrating a lack of robust planning or symbolic abstractions supporting their reasoning process. To improve reliability, many attempts have been made to combine LLMs with symbolic methods. Nevertheless, existing approaches fail to effectively leverage symbolic representations due to the challenges involved in developing reliable and scalable verification mechanisms. In this paper, we propose to overcome such limitations by synthesizing high-quality symbolic reasoning trajectories with stepwise pseudo-labels at scale via Monte Carlo estimation. A Process Reward Model (PRM) can be efficiently trained based on the synthesized data and then used to select more symbolic trajectories. The trajectories are then employed with Direct Preference Optimization (DPO) and Supervised Fine-Tuning (SFT) to improve logical reasoning and generalization. Our results on benchmarks (i.e., FOLIO and LogicAsker) show the effectiveness of the proposed method with gains on frontier and open-weight models. Moreover, additional experiments on claim verification data reveal that fine-tuning on the generated symbolic reasoning trajectories enhances out-of-domain generalizability, suggesting the potential impact of the proposed method in enhancing planning and logical reasoning.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2505.20415v2 ë°œí‘œ ìœ í˜•: êµì²´  
ì´ˆë¡: ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ ë§ì€ ì¶”ë¡  ë²¤ì¹˜ë§ˆí¬ì—ì„œ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ìµœê·¼ ì—°êµ¬ë“¤ì€ ì´ëŸ¬í•œ ì„±ëŠ¥ì˜ ì£¼ìš” ì›ì¸ ì¤‘ í•˜ë‚˜ë¡œ ì¼ë°˜í™”ë³´ë‹¤ëŠ” ì•”ê¸°ë¥¼ ì§€ì í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì‹¤ì œë¡œ LLMì€ ì½˜í…ì¸  ë³€í˜•ì— ì·¨ì•½í•˜ë©°, ê·¸ë“¤ì˜ ì¶”ë¡  ê³¼ì •ì„ ë’·ë°›ì¹¨í•˜ëŠ” ê²¬ê³ í•œ ê³„íšì´ë‚˜ ìƒì§•ì  ì¶”ìƒí™”ê°€ ë¶€ì¡±í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì‹ ë¢°ì„±ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´, ë§ì€ ì‹œë„ê°€ LLMì„ ìƒì§•ì  ë°©ë²•ê³¼ ê²°í•©í•˜ë ¤ê³  í–ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³ , ê¸°ì¡´ ì ‘ê·¼ë²•ì€ ì‹ ë¢°í•  ìˆ˜ ìˆê³  í™•ì¥ ê°€ëŠ¥í•œ ê²€ì¦ ë©”ì»¤ë‹ˆì¦˜ì„ ê°œë°œí•˜ëŠ” ë° ê´€ë ¨ëœ ì–´ë ¤ì›€ ë•Œë¬¸ì— ìƒì§•ì  í‘œí˜„ì„ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•˜ì§€ ëª»í•©ë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ëª¬í…Œì¹´ë¥¼ë¡œ ì¶”ì •ì„ í†µí•´ ë‹¨ê³„ë³„ ì˜ì‚¬ ë¼ë²¨ì„ ì‚¬ìš©í•˜ì—¬ ëŒ€ê·œëª¨ë¡œ ê³ í’ˆì§ˆì˜ ìƒì§•ì  ì¶”ë¡  ê²½ë¡œë¥¼ í•©ì„±í•¨ìœ¼ë¡œì¨ ì´ëŸ¬í•œ ì œí•œì„ ê·¹ë³µí•  ê²ƒì„ ì œì•ˆí•©ë‹ˆë‹¤. í”„ë¡œì„¸ìŠ¤ ë³´ìƒ ëª¨ë¸(PRM)ì€ í•©ì„±ëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ íš¨ìœ¨ì ìœ¼ë¡œ í›ˆë ¨ë  ìˆ˜ ìˆìœ¼ë©°, ì´í›„ ë” ë§ì€ ìƒì§•ì  ê²½ë¡œë¥¼ ì„ íƒí•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ ì´ ê²½ë¡œë“¤ì€ ë…¼ë¦¬ì  ì¶”ë¡ ê³¼ ì¼ë°˜í™”ë¥¼ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ì§ì ‘ ì„ í˜¸ ìµœì í™”(DPO)ì™€ ì§€ë„ í•™ìŠµ(SFT)ê³¼ í•¨ê»˜ ì‚¬ìš©ë©ë‹ˆë‹¤. ë²¤ì¹˜ë§ˆí¬(ì¦‰, FOLIO ë° LogicAsker)ì—ì„œì˜ ìš°ë¦¬ì˜ ê²°ê³¼ëŠ” í”„ë¡ í‹°ì–´ ë° ì˜¤í”ˆ ì›¨ì´íŠ¸ ëª¨ë¸ì—ì„œì˜ ì´ë“ê³¼ í•¨ê»˜ ì œì•ˆëœ ë°©ë²•ì˜ íš¨ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ê²Œë‹¤ê°€, ì£¼ì¥ ê²€ì¦ ë°ì´í„°ì— ëŒ€í•œ ì¶”ê°€ ì‹¤í—˜ì€ ìƒì„±ëœ ìƒì§•ì  ì¶”ë¡  ê²½ë¡œì— ëŒ€í•œ ë¯¸ì„¸ ì¡°ì •ì´ ë„ë©”ì¸ ì™¸ ì¼ë°˜í™”ë¥¼ í–¥ìƒì‹œí‚¨ë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì£¼ë©°, ì œì•ˆëœ ë°©ë²•ì´ ê³„íš ë° ë…¼ë¦¬ì  ì¶”ë¡ ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° ë¯¸ì¹˜ëŠ” ì ì¬ì  ì˜í–¥ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì„±ëŠ¥ì´ ê¸°ì–µì— ì˜ì¡´í•˜ëŠ” ê²½í–¥ì´ ìˆìœ¼ë©°, ì¼ë°˜í™” ëŠ¥ë ¥ì´ ë¶€ì¡±í•˜ë‹¤ëŠ” ë¬¸ì œë¥¼ ì§€ì í•©ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì €ìë“¤ì€ ëª¬í…Œì¹´ë¥¼ë¡œ ì¶”ì •ì„ í†µí•´ ë‹¨ê³„ë³„ ê°€ì§œ ë ˆì´ë¸”ì„ ì‚¬ìš©í•˜ì—¬ ê³ í’ˆì§ˆì˜ ìƒì§•ì  ì¶”ë¡  ê²½ë¡œë¥¼ ëŒ€ëŸ‰ìœ¼ë¡œ ìƒì„±í•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ë°ì´í„°ë¡œ í›ˆë ¨ëœ í”„ë¡œì„¸ìŠ¤ ë³´ìƒ ëª¨ë¸(PRM)ì€ ë” ë‚˜ì€ ìƒì§•ì  ê²½ë¡œë¥¼ ì„ íƒí•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. ì´ëŸ¬í•œ ê²½ë¡œëŠ” ì§ì ‘ ì„ í˜¸ ìµœì í™”(DPO)ì™€ ì§€ë„ í•™ìŠµ(SFT)ê³¼ ê²°í•©ë˜ì–´ ë…¼ë¦¬ì  ì¶”ë¡ ê³¼ ì¼ë°˜í™”ë¥¼ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì´ FOLIOì™€ LogicAsker ë²¤ì¹˜ë§ˆí¬ì—ì„œ ì„±ëŠ¥ì„ í–¥ìƒì‹œì¼°ìœ¼ë©°, ì£¼ì¥ ê²€ì¦ ë°ì´í„°ì—ì„œì˜ ì¶”ê°€ ì‹¤í—˜ì€ ìƒì„±ëœ ìƒì§•ì  ì¶”ë¡  ê²½ë¡œë¡œ ë¯¸ì„¸ ì¡°ì • ì‹œ ë„ë©”ì¸ ì™¸ ì¼ë°˜í™” ëŠ¥ë ¥ì´ ê°œì„ ë¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŠ” ê³„íš ë° ë…¼ë¦¬ì  ì¶”ë¡  í–¥ìƒì— ê¸°ì—¬í•  ê°€ëŠ¥ì„±ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì„±ëŠ¥ì€ ê¸°ì–µë³´ë‹¤ëŠ” ì¼ë°˜í™” ë¶€ì¡±ìœ¼ë¡œ ì¸í•´ ì½˜í…ì¸  ë³€í˜•ì— ì·¨ì•½í•˜ë‹¤.

- 2. ì‹ ë¢°ì„±ì„ ë†’ì´ê¸° ìœ„í•´ LLMê³¼ ìƒì§•ì  ë°©ë²•ì„ ê²°í•©í•˜ë ¤ëŠ” ì‹œë„ê°€ ìˆì—ˆìœ¼ë‚˜, ê¸°ì¡´ ì ‘ê·¼ë²•ì€ ê²€ì¦ ë©”ì»¤ë‹ˆì¦˜ì˜ í•œê³„ë¡œ ì¸í•´ íš¨ê³¼ì ì´ì§€ ì•Šë‹¤.

- 3. ë³¸ ë…¼ë¬¸ì€ ëª¬í…Œì¹´ë¥¼ë¡œ ì¶”ì •ì„ í†µí•´ ê³ í’ˆì§ˆì˜ ìƒì§•ì  ì¶”ë¡  ê²½ë¡œë¥¼ ëŒ€ê·œëª¨ë¡œ ìƒì„±í•˜ì—¬ ì´ëŸ¬í•œ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³ ì í•œë‹¤.

- 4. ìƒì„±ëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ íš¨ìœ¨ì ìœ¼ë¡œ í›ˆë ¨ëœ í”„ë¡œì„¸ìŠ¤ ë³´ìƒ ëª¨ë¸(PRM)ì€ ë” ë‚˜ì€ ìƒì§•ì  ê²½ë¡œ ì„ íƒì— ì‚¬ìš©ëœë‹¤.

- 5. ì œì•ˆëœ ë°©ë²•ì€ ë…¼ë¦¬ì  ì¶”ë¡ ê³¼ ì¼ë°˜í™”ë¥¼ ê°œì„ í•˜ë©°, ìƒì„±ëœ ìƒì§•ì  ì¶”ë¡  ê²½ë¡œë¡œì˜ ë¯¸ì„¸ ì¡°ì •ì´ ë„ë©”ì¸ ì™¸ ì¼ë°˜í™” ê°€ëŠ¥ì„±ì„ ë†’ì¸ë‹¤.

---

*Generated on 2025-09-19 15:59:59*