
# GAF: Gaussian Action Field as a Dynamic World Model for Robotic Manipulation

**Korean Title:** GAF: 로봇 조작을 위한 동적 세계 모델로서의 가우시안 액션 필드

## 📋 메타데이터

**Links**: [[daily/2025-09-19|2025-09-19]] [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Motion Aware 4D Representations

## 🔗 유사한 논문
- [[GWM Towards Scalable Gaussian World Models for Robotic Manipulation]] (84.6% similar)
- [[ForceVLA Enhancing VLA Models with a Force-aware MoE for Contact-rich Manipulation]] (82.7% similar)
- [[GeoAware-VLA Implicit Geometry Aware Vision-Language-Action Model]] (82.5% similar)
- [[PhysicalAgent Towards General Cognitive Robotics with Foundation World Models]] (82.0% similar)
- [[textsc{Gen2Real} Towards Demo-Free Dexterous Manipulation by Harnessing Generated Video]] (81.6% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2506.14135v3 Announce Type: replace-cross 
Abstract: Accurate scene perception is critical for vision-based robotic manipulation. Existing approaches typically follow either a Vision-to-Action (V-A) paradigm, predicting actions directly from visual inputs, or a Vision-to-3D-to-Action (V-3D-A) paradigm, leveraging intermediate 3D representations. However, these methods often struggle with action inaccuracies due to the complexity and dynamic nature of manipulation scenes. In this paper, we adopt a V-4D-A framework that enables direct action reasoning from motion-aware 4D representations via a Gaussian Action Field (GAF). GAF extends 3D Gaussian Splatting (3DGS) by incorporating learnable motion attributes, allowing 4D modeling of dynamic scenes and manipulation actions. To learn time-varying scene geometry and action-aware robot motion, GAF provides three interrelated outputs: reconstruction of the current scene, prediction of future frames, and estimation of init action via Gaussian motion. Furthermore, we employ an action-vision-aligned denoising framework, conditioned on a unified representation that combines the init action and the Gaussian perception, both generated by the GAF, to further obtain more precise actions. Extensive experiments demonstrate significant improvements, with GAF achieving +11.5385 dB PSNR, +0.3864 SSIM and -0.5574 LPIPS improvements in reconstruction quality, while boosting the average +7.3% success rate in robotic manipulation tasks over state-of-the-art methods.

## 🔍 Abstract (한글 번역)

arXiv:2506.14135v3 발표 유형: 교체-교차  
초록: 정확한 장면 인식은 비전 기반 로봇 조작에 있어 매우 중요합니다. 기존 접근 방식은 일반적으로 비전-액션(V-A) 패러다임, 즉 시각 입력에서 직접 행동을 예측하거나, 비전-3D-액션(V-3D-A) 패러다임, 즉 중간 3D 표현을 활용하는 방식을 따릅니다. 그러나 이러한 방법들은 조작 장면의 복잡성과 동적 특성 때문에 행동의 부정확성 문제를 자주 겪습니다. 본 논문에서는 모션 인식 4D 표현을 통해 직접적인 행동 추론을 가능하게 하는 V-4D-A 프레임워크를 채택하였습니다. Gaussian Action Field (GAF)는 학습 가능한 모션 속성을 포함하여 3D Gaussian Splatting (3DGS)을 확장함으로써 동적 장면 및 조작 행동의 4D 모델링을 가능하게 합니다. 시간에 따라 변화하는 장면 기하학과 행동 인식 로봇 모션을 학습하기 위해, GAF는 현재 장면의 재구성, 미래 프레임 예측, Gaussian 모션을 통한 초기 행동 추정을 포함한 세 가지 상호 관련된 출력을 제공합니다. 또한, GAF에 의해 생성된 초기 행동과 Gaussian 인식을 결합한 통합 표현을 조건으로 하는 행동-비전 정렬 노이즈 제거 프레임워크를 사용하여 보다 정밀한 행동을 얻습니다. 광범위한 실험 결과, GAF는 재구성 품질에서 +11.5385 dB PSNR, +0.3864 SSIM 및 -0.5574 LPIPS의 개선을 달성하였으며, 최첨단 방법들에 비해 로봇 조작 작업의 평균 성공률을 +7.3% 향상시켰습니다.

## 📝 요약

이 논문은 로봇 조작을 위한 장면 인식의 정확성을 높이기 위해 V-4D-A 프레임워크를 제안합니다. 기존의 V-A 및 V-3D-A 접근법은 조작 장면의 복잡성과 동적 특성 때문에 정확한 행동 예측에 어려움을 겪습니다. 제안된 V-4D-A 프레임워크는 Gaussian Action Field (GAF)를 사용하여 모션 인식 4D 표현에서 직접적으로 행동을 추론합니다. GAF는 3D Gaussian Splatting을 확장하여 학습 가능한 모션 속성을 포함함으로써 동적 장면과 조작 행동의 4D 모델링을 가능하게 합니다. GAF는 현재 장면의 재구성, 미래 프레임 예측, 초기 행동 추정을 통해 시간에 따라 변화하는 장면 기하학과 행동 인식 로봇 모션을 학습합니다. 또한, GAF가 생성한 초기 행동과 Gaussian 인식을 결합한 통합 표현을 조건으로 하는 행동-비전 정렬 잡음 제거 프레임워크를 사용하여 더 정확한 행동을 얻습니다. 실험 결과, GAF는 최첨단 방법들에 비해 로봇 조작 작업의 평균 성공률을 7.3% 향상시키며, 재구성 품질에서도 PSNR, SSIM, LPIPS에서 각각 +11.5385 dB, +0.3864, -0.5574의 개선을 보였습니다.

## 🎯 주요 포인트

- 1. 본 논문은 동작 인식이 가능한 4D 표현을 통해 직접적인 행동 추론을 가능하게 하는 V-4D-A 프레임워크를 제안합니다.

- 2. Gaussian Action Field (GAF)는 학습 가능한 동작 속성을 포함하여 3D Gaussian Splatting을 확장하여 동적 장면과 조작 동작의 4D 모델링을 지원합니다.

- 3. GAF는 현재 장면의 재구성, 미래 프레임 예측, Gaussian motion을 통한 초기 행동 추정의 세 가지 상호 관련된 출력을 제공합니다.

- 4. 행동-비전 정렬 잡음 제거 프레임워크를 사용하여 GAF가 생성한 초기 행동과 Gaussian 인식을 결합한 통합 표현을 조건으로 더 정확한 행동을 도출합니다.

- 5. 실험 결과, GAF는 최첨단 방법 대비 로봇 조작 작업의 평균 성공률을 +7.3% 향상시키며, 재구성 품질에서 +11.5385 dB PSNR, +0.3864 SSIM, -0.5574 LPIPS의 개선을 보였습니다.

---

*Generated on 2025-09-19 16:21:40*