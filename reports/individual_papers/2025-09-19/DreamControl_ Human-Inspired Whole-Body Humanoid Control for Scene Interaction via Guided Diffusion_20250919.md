---
keywords:
  - Reinforcement Learning
  - Diffusion Models
  - Sim-to-Real Transfer
category: cs.AI
publish_date: 2025-09-19
arxiv_id: 2509.14353
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 21:47:14.910943",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Reinforcement Learning",
    "Diffusion Models",
    "Sim-to-Real Transfer"
  ],
  "rejected_keywords": [
    "Human Motion Data"
  ],
  "similarity_scores": {
    "Reinforcement Learning": 0.9,
    "Diffusion Models": 0.88,
    "Sim-to-Real Transfer": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->


# DreamControl: Human-Inspired Whole-Body Humanoid Control for Scene Interaction via Guided Diffusion

**Korean Title:** DreamControl: 장면 상호작용을 위한 유도 확산을 통한 인간 영감의 전신 휴머노이드 제어

## 📋 메타데이터

**Links**: [[digests/daily_digest_20250919|2025-09-19]]   [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Reinforcement Learning|Reinforcement Learning]], [[keywords/Diffusion Models|Diffusion Models]]
**🚀 Evolved Concepts**: [[keywords/Sim-to-Real Transfer|Sim-to-Real Transfer]]

## 🔗 유사한 논문
- [[Embracing Bulky Objects with Humanoid Robots Whole-Body Manipulation with Reinforcement Learning]] (84.1% similar)
- [[TrajBooster Boosting Humanoid Whole-Body Manipulation via Trajectory-Centric Learning]] (82.4% similar)
- [[DREAM Domain-aware Reasoning for Efficient Autonomous Underwater Monitoring]] (81.7% similar)
- [[FlightDiffusion Revolutionising Autonomous Drone Training with Diffusion Models Generating FPV Video]] (81.1% similar)
- [[textsc{Gen2Real} Towards Demo-Free Dexterous Manipulation by Harnessing Generated Video]] (80.9% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.14353v1 Announce Type: cross 
Abstract: We introduce DreamControl, a novel methodology for learning autonomous whole-body humanoid skills. DreamControl leverages the strengths of diffusion models and Reinforcement Learning (RL): our core innovation is the use of a diffusion prior trained on human motion data, which subsequently guides an RL policy in simulation to complete specific tasks of interest (e.g., opening a drawer or picking up an object). We demonstrate that this human motion-informed prior allows RL to discover solutions unattainable by direct RL, and that diffusion models inherently promote natural looking motions, aiding in sim-to-real transfer. We validate DreamControl's effectiveness on a Unitree G1 robot across a diverse set of challenging tasks involving simultaneous lower and upper body control and object interaction.

## 🔍 Abstract (한글 번역)

arXiv:2509.14353v1 발표 유형: 교차  
초록: 우리는 자율적인 전신 휴머노이드 기술 학습을 위한 새로운 방법론인 DreamControl을 소개합니다. DreamControl은 확산 모델과 강화 학습(RL)의 강점을 활용합니다. 우리의 핵심 혁신은 인간의 동작 데이터를 기반으로 훈련된 확산 사전(prior)을 사용하여, 이후 시뮬레이션에서 RL 정책을 안내하여 관심 있는 특정 작업(예: 서랍 열기 또는 물건 집기)을 완료하는 것입니다. 우리는 이 인간 동작 정보 기반 사전이 RL이 직접적으로는 도달할 수 없는 솔루션을 발견할 수 있게 하며, 확산 모델이 본질적으로 자연스러운 동작을 촉진하여 시뮬레이션에서 실제로의 전환을 돕는다는 것을 입증합니다. 우리는 DreamControl의 효과를 Unitree G1 로봇에서 하체와 상체의 동시 제어 및 물체 상호작용을 포함한 다양한 어려운 작업 세트에서 검증합니다.

## 📝 요약

DreamControl은 인간의 전신 움직임 데이터를 학습한 확산 모델과 강화 학습(RL)을 결합하여 자율적인 휴머노이드 스킬을 학습하는 새로운 방법론입니다. 이 방법론은 인간의 움직임을 반영한 확산 모델을 통해 RL 정책을 시뮬레이션에서 특정 작업(예: 서랍 열기, 물건 집기)을 수행하도록 안내합니다. 이를 통해 직접적인 RL로는 찾기 어려운 솔루션을 발견할 수 있으며, 자연스러운 움직임을 촉진하여 시뮬레이션에서 현실로의 전환을 돕습니다. DreamControl의 효과는 Unitree G1 로봇을 통해 다양한 복잡한 작업에서 검증되었습니다.

## 🎯 주요 포인트

- 1. DreamControl은 인간의 움직임 데이터를 기반으로 훈련된 확산 모델을 활용하여 강화 학습(RL) 정책을 안내하는 새로운 방법론입니다.

- 2. DreamControl은 서랍 열기, 물건 집기 등 특정 작업을 완료하기 위해 시뮬레이션에서 RL 정책을 안내합니다.

- 3. 인간 움직임 정보를 반영한 사전 모델은 직접적인 RL로는 발견할 수 없는 솔루션을 찾도록 도와줍니다.

- 4. 확산 모델은 자연스러운 움직임을 촉진하여 시뮬레이션에서 현실로의 전환을 돕습니다.

- 5. DreamControl의 효과는 Unitree G1 로봇을 통해 다양한 도전 과제에서 검증되었습니다.

---

*Generated on 2025-09-19 14:54:20*