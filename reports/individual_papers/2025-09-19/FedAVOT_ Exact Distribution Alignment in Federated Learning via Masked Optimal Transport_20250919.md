---
keywords:
  - Federated Learning
  - Optimal Transport
  - Distribution Alignment
category: cs.AI
publish_date: 2025-09-19
arxiv_id: 2509.14444
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 21:44:04.091028",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Federated Learning",
    "Optimal Transport",
    "Distribution Alignment"
  ],
  "rejected_keywords": [
    "Sinkhorn Scaling"
  ],
  "similarity_scores": {
    "Federated Learning": 0.95,
    "Optimal Transport": 0.85,
    "Distribution Alignment": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->


# FedAVOT: Exact Distribution Alignment in Federated Learning via Masked Optimal Transport

**Korean Title:** FedAVOT: ì—°í•© í•™ìŠµì—ì„œ ë§ˆìŠ¤í‚¹ëœ ìµœì  ìˆ˜ì†¡ì„ í†µí•œ ì •í™•í•œ ë¶„í¬ ì •ë ¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[digests/daily_digest_20250919|2025-09-19]]   [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Federated Learning|Federated Learning]]
**âš¡ Unique Technical**: [[keywords/Optimal Transport|Optimal Transport]]
**ğŸš€ Evolved Concepts**: [[keywords/Distribution Alignment|Distribution Alignment]]

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[FedDiverse Tackling Data Heterogeneity in Federated Learning with Diversity-Driven Client Selection]] (83.9% similar)
- [[FedSSG Expectation-Gated and History-Aware Drift Alignment for Federated Learning]] (83.3% similar)
- [[Federated Learning for Deforestation Detection A Distributed Approach with Satellite Imagery]] (80.0% similar)
- [[Data-Driven_Distributed_Optimization_via_Aggregative_Tracking_and_Deep-Learning_20250918|Data-Driven Distributed Optimization via Aggregative Tracking and Deep-Learning]] (79.4% similar)
- [[Performance_Optimization_of_YOLO-FEDER_FusionNet_for_Robust_Drone_Detection_in_Visually_Complex_Environments_20250918|Performance Optimization of YOLO-FEDER FusionNet for Robust Drone Detection in Visually Complex Environments]] (78.0% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.14444v1 Announce Type: new 
Abstract: Federated Learning (FL) allows distributed model training without sharing raw data, but suffers when client participation is partial. In practice, the distribution of available users (\emph{availability distribution} $q$) rarely aligns with the distribution defining the optimization objective (\emph{importance distribution} $p$), leading to biased and unstable updates under classical FedAvg. We propose \textbf{Fereated AVerage with Optimal Transport (\textbf{FedAVOT})}, which formulates aggregation as a masked optimal transport problem aligning $q$ and $p$. Using Sinkhorn scaling, \textbf{FedAVOT} computes transport-based aggregation weights with provable convergence guarantees. \textbf{FedAVOT} achieves a standard $\mathcal{O}(1/\sqrt{T})$ rate under a nonsmooth convex FL setting, independent of the number of participating users per round. Our experiments confirm drastically improved performance compared to FedAvg across heterogeneous, fairness-sensitive, and low-availability regimes, even when only two clients participate per round.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.14444v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: ì—°í•© í•™ìŠµ(Federated Learning, FL)ì€ ì›ì‹œ ë°ì´í„°ë¥¼ ê³µìœ í•˜ì§€ ì•Šê³  ë¶„ì‚°ëœ ëª¨ë¸ í•™ìŠµì„ ê°€ëŠ¥í•˜ê²Œ í•˜ì§€ë§Œ, í´ë¼ì´ì–¸íŠ¸ ì°¸ì—¬ê°€ ë¶€ë¶„ì ì¼ ë•Œ ì„±ëŠ¥ì´ ì €í•˜ë©ë‹ˆë‹¤. ì‹¤ì œë¡œ, ì‚¬ìš© ê°€ëŠ¥í•œ ì‚¬ìš©ìë“¤ì˜ ë¶„í¬(ê°€ìš©ì„± ë¶„í¬ $q$)ëŠ” ìµœì í™” ëª©í‘œë¥¼ ì •ì˜í•˜ëŠ” ë¶„í¬(ì¤‘ìš”ë„ ë¶„í¬ $p$)ì™€ ê±°ì˜ ì¼ì¹˜í•˜ì§€ ì•Šìœ¼ë©°, ì´ëŠ” ì „í†µì ì¸ FedAvgì—ì„œ í¸í–¥ë˜ê³  ë¶ˆì•ˆì •í•œ ì—…ë°ì´íŠ¸ë¡œ ì´ì–´ì§‘ë‹ˆë‹¤. ìš°ë¦¬ëŠ” \textbf{ìµœì  ìˆ˜ì†¡ì„ ì´ìš©í•œ ì—°í•© í‰ê·  (\textbf{FedAVOT})}ì„ ì œì•ˆí•˜ë©°, ì´ëŠ” $q$ì™€ $p$ë¥¼ ì •ë ¬í•˜ëŠ” ë§ˆìŠ¤í‚¹ëœ ìµœì  ìˆ˜ì†¡ ë¬¸ì œë¡œ ì§‘ê³„ë¥¼ ê³µì‹í™”í•©ë‹ˆë‹¤. Sinkhorn ìŠ¤ì¼€ì¼ë§ì„ ì‚¬ìš©í•˜ì—¬, \textbf{FedAVOT}ëŠ” ìˆ˜ì†¡ ê¸°ë°˜ ì§‘ê³„ ê°€ì¤‘ì¹˜ë¥¼ ê³„ì‚°í•˜ë©° ìˆ˜ë ´ ë³´ì¥ì„ ì œê³µí•©ë‹ˆë‹¤. \textbf{FedAVOT}ëŠ” ë¹„ë§¤ë„ëŸ¬ìš´ ë³¼ë¡ FL ì„¤ì •ì—ì„œ ë¼ìš´ë“œë‹¹ ì°¸ì—¬ ì‚¬ìš©ì ìˆ˜ì™€ ë¬´ê´€í•˜ê²Œ í‘œì¤€ $\mathcal{O}(1/\sqrt{T})$ ì†ë„ë¥¼ ë‹¬ì„±í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì‹¤í—˜ì€ ì´ì§ˆì ì´ê³  ê³µì •ì„±ì— ë¯¼ê°í•˜ë©° ê°€ìš©ì„±ì´ ë‚®ì€ í™˜ê²½ì—ì„œ FedAvgì— ë¹„í•´ ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë¨ì„ í™•ì¸í•˜ì˜€ìœ¼ë©°, ë¼ìš´ë“œë‹¹ ë‘ ê°œì˜ í´ë¼ì´ì–¸íŠ¸ë§Œ ì°¸ì—¬í•˜ë”ë¼ë„ ì„±ëŠ¥ì´ ê°œì„ ë¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì—°í•© í•™ìŠµ(FL)ì€ ì›ì‹œ ë°ì´í„°ë¥¼ ê³µìœ í•˜ì§€ ì•Šê³  ë¶„ì‚°ëœ ëª¨ë¸ í•™ìŠµì„ ê°€ëŠ¥í•˜ê²Œ í•˜ì§€ë§Œ, í´ë¼ì´ì–¸íŠ¸ ì°¸ì—¬ê°€ ë¶€ë¶„ì ì¼ ë•Œ ë¬¸ì œê°€ ë°œìƒí•©ë‹ˆë‹¤. ê¸°ì¡´ FedAvgëŠ” ì‚¬ìš©ìì˜ ê°€ìš©ì„± ë¶„í¬ì™€ ìµœì í™” ëª©í‘œ ë¶„í¬ê°€ ì¼ì¹˜í•˜ì§€ ì•Šì„ ê²½ìš° í¸í–¥ë˜ê³  ë¶ˆì•ˆì •í•œ ì—…ë°ì´íŠ¸ë¥¼ ì´ˆë˜í•©ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ìš°ë¦¬ëŠ” ìµœì  ìˆ˜ì†¡ ë¬¸ì œë¥¼ í™œìš©í•œ \textbf{FedAVOT}ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ Sinkhorn ìŠ¤ì¼€ì¼ë§ì„ ì‚¬ìš©í•˜ì—¬ ìˆ˜ì†¡ ê¸°ë°˜ì˜ ì§‘ê³„ ê°€ì¤‘ì¹˜ë¥¼ ê³„ì‚°í•˜ë©°, ìˆ˜ë ´ ë³´ì¥ì„ ì œê³µí•©ë‹ˆë‹¤. \textbf{FedAVOT}ëŠ” ë¹„ë§¤ë„ëŸ¬ìš´ ë³¼ë¡ FL ì„¤ì •ì—ì„œ í‘œì¤€ ìˆ˜ë ´ ì†ë„ë¥¼ ë‹¬ì„±í•˜ë©°, ì°¸ì—¬ ì‚¬ìš©ì ìˆ˜ì— ë…ë¦½ì ì…ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, FedAvgë³´ë‹¤ ì´ì§ˆì ì´ê³  ê³µì •ì„±ì— ë¯¼ê°í•˜ë©° ë‚®ì€ ê°€ìš©ì„± í™˜ê²½ì—ì„œ ì„±ëŠ¥ì´ í¬ê²Œ ê°œì„ ë¨ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì—°í•© í•™ìŠµ(Federated Learning)ì€ ì›ì‹œ ë°ì´í„°ë¥¼ ê³µìœ í•˜ì§€ ì•Šê³  ë¶„ì‚° ëª¨ë¸ í•™ìŠµì„ ê°€ëŠ¥í•˜ê²Œ í•˜ì§€ë§Œ, í´ë¼ì´ì–¸íŠ¸ ì°¸ì—¬ê°€ ë¶€ë¶„ì ì¼ ë•Œ ì„±ëŠ¥ì´ ì €í•˜ë©ë‹ˆë‹¤.

- 2. FedAVOTëŠ” ê°€ìš© ì‚¬ìš©ì ë¶„í¬ì™€ ìµœì í™” ëª©í‘œ ë¶„í¬ë¥¼ ì •ë ¬í•˜ëŠ” ë§ˆìŠ¤í‚¹ëœ ìµœì  ìˆ˜ì†¡ ë¬¸ì œë¡œ ì§‘ê³„ë¥¼ ê³µì‹í™”í•˜ì—¬ í¸í–¥ë˜ê³  ë¶ˆì•ˆì •í•œ ì—…ë°ì´íŠ¸ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤.

- 3. Sinkhorn ìŠ¤ì¼€ì¼ë§ì„ ì‚¬ìš©í•˜ì—¬ FedAVOTëŠ” ìˆ˜ì†¡ ê¸°ë°˜ ì§‘ê³„ ê°€ì¤‘ì¹˜ë¥¼ ê³„ì‚°í•˜ë©°, ìˆ˜ë ´ ë³´ì¥ì„ ì œê³µí•©ë‹ˆë‹¤.

- 4. FedAVOTëŠ” ë¹„ë§¤ë„ëŸ¬ìš´ ë³¼ë¡ FL ì„¤ì •ì—ì„œ ì°¸ì—¬ ì‚¬ìš©ì ìˆ˜ì™€ ë¬´ê´€í•˜ê²Œ í‘œì¤€ ìˆ˜ë ´ ì†ë„ë¥¼ ë‹¬ì„±í•©ë‹ˆë‹¤.

- 5. ì‹¤í—˜ ê²°ê³¼, FedAVOTëŠ” ì´ì§ˆì ì´ê³  ê³µì •ì„±ì— ë¯¼ê°í•˜ë©° ë‚®ì€ ê°€ìš©ì„± í™˜ê²½ì—ì„œë„ FedAvgë³´ë‹¤ ì„±ëŠ¥ì´ í¬ê²Œ ê°œì„ ë¨ì„ í™•ì¸í•˜ì˜€ìŠµë‹ˆë‹¤.

---

*Generated on 2025-09-19 15:24:29*