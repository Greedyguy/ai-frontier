
# Manipulation Facing Threats: Evaluating Physical Vulnerabilities in End-to-End Vision Language Action Models

**Korean Title:** 위협에 직면한 조작: 종단 간 비전 언어 행동 모델의 물리적 취약성 평가

## 📋 메타데이터

**Links**: [[daily/2025-09-19|2025-09-19]] [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Vision Language Action Models

## 🔗 유사한 논문
- [[The Sum Leaks More Than Its Parts Compositional Privacy Risks and Mitigations in Multi-Agent Collaboration]] (84.1% similar)
- [[V-SEAM Visual Semantic Editing and Attention Modulating for Causal Interpretability of Vision-Language Models]] (83.6% similar)
- [[A Multi-Agent LLM Defense Pipeline Against Prompt Injection Attacks_20250919|A Multi-Agent LLM Defense Pipeline Against Prompt Injection Attacks]] (82.8% similar)
- [[CyberLLMInstruct A Pseudo-malicious Dataset Revealing Safety-performance Trade-offs in Cyber Security LLM Fine-tuning]] (82.6% similar)
- [[CLAW A Vision-Language-Action Framework for Weight-Aware Robotic Grasping]] (82.6% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2409.13174v3 Announce Type: replace 
Abstract: Recently, driven by advancements in Multimodal Large Language Models (MLLMs), Vision Language Action Models (VLAMs) are being proposed to achieve better performance in open-vocabulary scenarios for robotic manipulation tasks. Since manipulation tasks involve direct interaction with the physical world, ensuring robustness and safety during the execution of this task is always a very critical issue. In this paper, by synthesizing current safety research on MLLMs and the specific application scenarios of the manipulation task in the physical world, we comprehensively evaluate VLAMs in the face of potential physical threats. Specifically, we propose the Physical Vulnerability Evaluating Pipeline (PVEP) that can incorporate as many visual modal physical threats as possible for evaluating the physical robustness of VLAMs. The physical threats in PVEP specifically include Out-of-Distribution, Typography-based Visual Prompt, and Adversarial Patch Attacks. By comparing the performance fluctuations of VLAMs before and after being attacked, we provide generalizable \textbf{\textit{Analyses}} of how VLAMs respond to different physical threats.

## 🔍 Abstract (한글 번역)

arXiv:2409.13174v3 발표 유형: 교체  
초록: 최근 다중 모달 대형 언어 모델(Multimodal Large Language Models, MLLMs)의 발전에 힘입어, 비전 언어 행동 모델(Vision Language Action Models, VLAMs)이 로봇 조작 작업의 개방형 어휘 시나리오에서 더 나은 성능을 달성하기 위해 제안되고 있습니다. 조작 작업은 물리적 세계와의 직접적인 상호작용을 포함하기 때문에, 이 작업을 수행하는 동안의 견고성과 안전성을 보장하는 것은 항상 매우 중요한 문제입니다. 본 논문에서는 MLLMs에 대한 현재의 안전 연구와 물리적 세계에서의 조작 작업의 특정 응용 시나리오를 종합하여, 잠재적인 물리적 위협에 직면한 VLAMs를 포괄적으로 평가합니다. 구체적으로, 우리는 VLAMs의 물리적 견고성을 평가하기 위해 가능한 한 많은 시각적 모달 물리적 위협을 포함할 수 있는 물리적 취약성 평가 파이프라인(Physical Vulnerability Evaluating Pipeline, PVEP)을 제안합니다. PVEP의 물리적 위협에는 Out-of-Distribution, 타이포그래피 기반 시각적 프롬프트, 그리고 적대적 패치 공격이 포함됩니다. 공격 전후의 VLAMs의 성능 변동을 비교함으로써, 우리는 VLAMs가 다양한 물리적 위협에 어떻게 반응하는지에 대한 일반화 가능한 \textbf{\textit{분석}}을 제공합니다.

## 📝 요약

이 논문은 멀티모달 대형 언어 모델(MLLM)의 발전에 힘입어 로봇 조작 작업에서 개방형 어휘 시나리오의 성능을 향상시키기 위해 제안된 Vision Language Action Models(VLAMs)의 물리적 위협에 대한 평가를 다룹니다. 물리적 세계와의 직접적인 상호작용이 필요한 조작 작업에서의 안전성과 견고성을 보장하는 것이 중요합니다. 저자들은 MLLM의 안전성 연구와 물리적 세계에서의 조작 작업의 특정 응용 시나리오를 종합하여 VLAMs의 물리적 위협에 대한 평가를 수행했습니다. 이를 위해 물리적 취약성 평가 파이프라인(PVEP)을 제안하여 VLAMs의 물리적 견고성을 평가하고, Out-of-Distribution, Typography 기반의 시각적 프롬프트, 적대적 패치 공격 등을 포함한 다양한 물리적 위협을 분석합니다. 연구 결과, VLAMs가 다양한 물리적 위협에 어떻게 반응하는지를 일반화된 분석을 통해 제시합니다.

## 🎯 주요 포인트

- 1. 최근 멀티모달 대형 언어 모델(MLLM)의 발전으로 인해, 로봇 조작 작업에서 개방형 어휘 시나리오의 성능을 향상시키기 위해 비전 언어 행동 모델(VLAM)이 제안되고 있습니다.

- 2. 물리적 세계와의 직접적인 상호작용이 포함된 조작 작업에서의 안전성과 견고성 확보는 매우 중요한 문제입니다.

- 3. 본 논문에서는 MLLM의 현재 안전성 연구와 물리적 세계에서의 조작 작업의 특정 응용 시나리오를 종합하여 VLAM의 잠재적 물리적 위협에 대한 평가를 수행합니다.

- 4. 우리는 VLAM의 물리적 견고성을 평가하기 위해 가능한 많은 시각적 모달 물리적 위협을 포함할 수 있는 물리적 취약성 평가 파이프라인(PVEP)을 제안합니다.

- 5. PVEP에서 다루는 물리적 위협은 분포 외 데이터, 타이포그래피 기반 시각적 프롬프트, 그리고 적대적 패치 공격을 포함합니다.

---

*Generated on 2025-09-19 16:15:07*