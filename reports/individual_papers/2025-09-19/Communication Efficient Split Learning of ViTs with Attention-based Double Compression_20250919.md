---
keywords:
  - Vision Transformers
  - Attention-based Double Compression
  - Split Learning
category: cs.AI
publish_date: 2025-09-19
arxiv_id: 2509.15058
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 21:52:21.463954",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Vision Transformers",
    "Attention-based Double Compression",
    "Split Learning"
  ],
  "rejected_keywords": [
    "Attention Mechanism"
  ],
  "similarity_scores": {
    "Vision Transformers": 0.88,
    "Attention-based Double Compression": 0.92,
    "Split Learning": 0.85
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->


# Communication Efficient Split Learning of ViTs with Attention-based Double Compression

**Korean Title:** ë¹„ì „ íŠ¸ëœìŠ¤í¬ë¨¸(ViTs)ì˜ í†µì‹  íš¨ìœ¨ì ì¸ ë¶„í•  í•™ìŠµ: ì£¼ì˜ ê¸°ë°˜ ì´ì¤‘ ì••ì¶•ì„ í™œìš©í•˜ì—¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[digests/daily_digest_20250919|2025-09-19]]   [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Vision Transformers|Vision Transformers]]
**âš¡ Unique Technical**: [[keywords/Attention-based Double Compression|Attention-based Double Compression]], [[keywords/Split Learning|Split Learning]]

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[Singular_Value_Few-shot_Adaptation_of_Vision-Language_Models_20250918|Singular Value Few-shot Adaptation of Vision-Language Models]] (80.8% similar)
- [[A Novel Compression Framework for YOLOv8 Achieving Real-Time Aerial Object Detection on Edge Devices via Structured Pruning and Channel-Wise Distillation]] (78.3% similar)
- [[Re-purposing SAM into Efficient Visual Projectors for MLLM-Based Referring Image Segmentation]] (77.3% similar)
- [[Search-TTA A Multimodal Test-Time Adaptation Framework for Visual Search in the Wild]] (77.0% similar)
- [[MCGS-SLAM A Multi-Camera SLAM Framework Using Gaussian Splatting for High-Fidelity Mapping]] (76.8% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15058v1 Announce Type: cross 
Abstract: This paper proposes a novel communication-efficient Split Learning (SL) framework, named Attention-based Double Compression (ADC), which reduces the communication overhead required for transmitting intermediate Vision Transformers activations during the SL training process. ADC incorporates two parallel compression strategies. The first one merges samples' activations that are similar, based on the average attention score calculated in the last client layer; this strategy is class-agnostic, meaning that it can also merge samples having different classes, without losing generalization ability nor decreasing final results. The second strategy follows the first and discards the least meaningful tokens, further reducing the communication cost. Combining these strategies not only allows for sending less during the forward pass, but also the gradients are naturally compressed, allowing the whole model to be trained without additional tuning or approximations of the gradients. Simulation results demonstrate that Attention-based Double Compression outperforms state-of-the-art SL frameworks by significantly reducing communication overheads while maintaining high accuracy.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15058v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ì´ ë…¼ë¬¸ì€ ì£¼ì˜ ê¸°ë°˜ ì´ì¤‘ ì••ì¶•(ADC)ì´ë¼ëŠ” ìƒˆë¡œìš´ í†µì‹  íš¨ìœ¨ì ì¸ ë¶„í•  í•™ìŠµ(SL) í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•˜ë©°, ì´ëŠ” SL í›ˆë ¨ ê³¼ì •ì—ì„œ ì¤‘ê°„ ë¹„ì „ íŠ¸ëœìŠ¤í¬ë¨¸ í™œì„±í™”ë¥¼ ì „ì†¡í•˜ëŠ” ë° í•„ìš”í•œ í†µì‹  ì˜¤ë²„í—¤ë“œë¥¼ ì¤„ì…ë‹ˆë‹¤. ADCëŠ” ë‘ ê°€ì§€ ë³‘ë ¬ ì••ì¶• ì „ëµì„ í†µí•©í•©ë‹ˆë‹¤. ì²« ë²ˆì§¸ ì „ëµì€ ë§ˆì§€ë§‰ í´ë¼ì´ì–¸íŠ¸ ê³„ì¸µì—ì„œ ê³„ì‚°ëœ í‰ê·  ì£¼ì˜ ì ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìœ ì‚¬í•œ ìƒ˜í”Œì˜ í™œì„±í™”ë¥¼ ë³‘í•©í•©ë‹ˆë‹¤. ì´ ì „ëµì€ í´ë˜ìŠ¤ì— êµ¬ì• ë°›ì§€ ì•Šìœ¼ë©°, ì¼ë°˜í™” ëŠ¥ë ¥ì„ ìƒì§€ ì•Šìœ¼ë©´ì„œë„ ì„œë¡œ ë‹¤ë¥¸ í´ë˜ìŠ¤ë¥¼ ê°€ì§„ ìƒ˜í”Œë„ ë³‘í•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‘ ë²ˆì§¸ ì „ëµì€ ì²« ë²ˆì§¸ ì „ëµì„ ë”°ë¥´ë©° ê°€ì¥ ì˜ë¯¸ ì—†ëŠ” í† í°ì„ ë²„ë ¤ í†µì‹  ë¹„ìš©ì„ ë”ìš± ì¤„ì…ë‹ˆë‹¤. ì´ëŸ¬í•œ ì „ëµì„ ê²°í•©í•˜ë©´ ìˆœë°©í–¥ íŒ¨ìŠ¤ì—ì„œ ì „ì†¡í•˜ëŠ” ì–‘ì„ ì¤„ì¼ ìˆ˜ ìˆì„ ë¿ë§Œ ì•„ë‹ˆë¼, ê·¸ë˜ë””ì–¸íŠ¸ë„ ìì—°ìŠ¤ëŸ½ê²Œ ì••ì¶•ë˜ì–´ ì¶”ê°€ ì¡°ì •ì´ë‚˜ ê·¸ë˜ë””ì–¸íŠ¸ ê·¼ì‚¬ ì—†ì´ ì „ì²´ ëª¨ë¸ì„ í›ˆë ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ì— ë”°ë¥´ë©´ ì£¼ì˜ ê¸°ë°˜ ì´ì¤‘ ì••ì¶•ì€ í†µì‹  ì˜¤ë²„í—¤ë“œë¥¼ í¬ê²Œ ì¤„ì´ë©´ì„œ ë†’ì€ ì •í™•ë„ë¥¼ ìœ ì§€í•˜ì—¬ ìµœì²¨ë‹¨ SL í”„ë ˆì„ì›Œí¬ë¥¼ ëŠ¥ê°€í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì£¼ì˜ ê¸°ë°˜ ì´ì¤‘ ì••ì¶•(ADC)ì´ë¼ëŠ” ìƒˆë¡œìš´ í†µì‹  íš¨ìœ¨ì ì¸ ë¶„í•  í•™ìŠµ(SL) í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ADCëŠ” ì¤‘ê°„ ë¹„ì „ íŠ¸ëœìŠ¤í¬ë¨¸ í™œì„±í™” ì „ì†¡ ì‹œì˜ í†µì‹  ì˜¤ë²„í—¤ë“œë¥¼ ì¤„ì…ë‹ˆë‹¤. ì²« ë²ˆì§¸ ì••ì¶• ì „ëµì€ ë§ˆì§€ë§‰ í´ë¼ì´ì–¸íŠ¸ ë ˆì´ì–´ì—ì„œ ê³„ì‚°ëœ í‰ê·  ì£¼ì˜ ì ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìœ ì‚¬í•œ ìƒ˜í”Œì˜ í™œì„±í™”ë¥¼ ë³‘í•©í•˜ë©°, ì´ëŠ” í´ë˜ìŠ¤ì— êµ¬ì• ë°›ì§€ ì•Šê³  ì¼ë°˜í™” ëŠ¥ë ¥ì„ ìœ ì§€í•©ë‹ˆë‹¤. ë‘ ë²ˆì§¸ ì „ëµì€ ëœ ì¤‘ìš”í•œ í† í°ì„ ë²„ë ¤ í†µì‹  ë¹„ìš©ì„ ì¶”ê°€ë¡œ ê°ì†Œì‹œí‚µë‹ˆë‹¤. ì´ ë‘ ì „ëµì„ ê²°í•©í•˜ë©´ ìˆœë°©í–¥ íŒ¨ìŠ¤ì—ì„œ ì „ì†¡ëŸ‰ì„ ì¤„ì´ê³ , ìì—°ìŠ¤ëŸ½ê²Œ ê·¸ë˜ë””ì–¸íŠ¸ë„ ì••ì¶•ë˜ì–´ ì¶”ê°€ ì¡°ì • ì—†ì´ ëª¨ë¸ì„ í›ˆë ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼, ADCëŠ” í†µì‹  ì˜¤ë²„í—¤ë“œë¥¼ í¬ê²Œ ì¤„ì´ë©´ì„œ ë†’ì€ ì •í™•ë„ë¥¼ ìœ ì§€í•˜ì—¬ ê¸°ì¡´ SL í”„ë ˆì„ì›Œí¬ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Attention-based Double Compression(ADC)ëŠ” ì¤‘ê°„ Vision Transformers í™œì„±í™” ì „ì†¡ ì‹œ í†µì‹  ì˜¤ë²„í—¤ë“œë¥¼ ì¤„ì´ëŠ” ìƒˆë¡œìš´ Split Learning(SL) í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.

- 2. ADCëŠ” ë‘ ê°€ì§€ ë³‘ë ¬ ì••ì¶• ì „ëµì„ í¬í•¨í•˜ë©°, ì²« ë²ˆì§¸ ì „ëµì€ í´ë˜ìŠ¤ì— ê´€ê³„ì—†ì´ ìœ ì‚¬í•œ ìƒ˜í”Œì˜ í™œì„±í™”ë¥¼ ë³‘í•©í•˜ì—¬ ì¼ë°˜í™” ëŠ¥ë ¥ì„ ìœ ì§€í•©ë‹ˆë‹¤.

- 3. ë‘ ë²ˆì§¸ ì „ëµì€ ì²« ë²ˆì§¸ ì „ëµì„ ë”°ë¥´ë©°, ì˜ë¯¸ê°€ ì ì€ í† í°ì„ ë²„ë ¤ í†µì‹  ë¹„ìš©ì„ ì¶”ê°€ë¡œ ì¤„ì…ë‹ˆë‹¤.

- 4. ì´ëŸ¬í•œ ì „ëµì„ ê²°í•©í•˜ë©´ ìˆœë°©í–¥ íŒ¨ìŠ¤ì—ì„œ ì „ì†¡ëŸ‰ì´ ì¤„ì–´ë“¤ ë¿ë§Œ ì•„ë‹ˆë¼, ê¸°ìš¸ê¸°ë„ ìì—°ìŠ¤ëŸ½ê²Œ ì••ì¶•ë˜ì–´ ì¶”ê°€ì ì¸ íŠœë‹ ì—†ì´ ëª¨ë¸ì„ í›ˆë ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- 5. ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼, ADCëŠ” ë†’ì€ ì •í™•ë„ë¥¼ ìœ ì§€í•˜ë©´ì„œ í†µì‹  ì˜¤ë²„í—¤ë“œë¥¼ í¬ê²Œ ì¤„ì—¬ ê¸°ì¡´ì˜ SL í”„ë ˆì„ì›Œí¬ë¥¼ ëŠ¥ê°€í•©ë‹ˆë‹¤.

---

*Generated on 2025-09-19 15:05:04*