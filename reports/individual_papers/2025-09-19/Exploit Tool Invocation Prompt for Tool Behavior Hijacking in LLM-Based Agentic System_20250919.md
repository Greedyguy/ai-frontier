---
keywords:
  - Large Language Models
  - Tool Invocation Prompt
  - Remote Code Execution
category: cs.AI
publish_date: 2025-09-19
arxiv_id: 2509.05755
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 21:44:44.570807",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Models",
    "Tool Invocation Prompt",
    "Remote Code Execution"
  ],
  "rejected_keywords": [
    "Denial of Service"
  ],
  "similarity_scores": {
    "Large Language Models": 0.78,
    "Tool Invocation Prompt": 0.8,
    "Remote Code Execution": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->


# Exploit Tool Invocation Prompt for Tool Behavior Hijacking in LLM-Based Agentic System

**Korean Title:** 도구 동작 하이재킹을 위한 LLM 기반 에이전트 시스템에서의 익스플로잇 도구 호출 프롬프트

## 📋 메타데이터

**Links**: [[digests/daily_digest_20250919|2025-09-19]]   [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🌐 Broad Technical**: [[keywords/Large Language Models|Large Language Models]]
**🔗 Specific Connectable**: [[keywords/Remote Code Execution|Remote Code Execution]]
**⚡ Unique Technical**: [[keywords/Tool Invocation Prompt|Tool Invocation Prompt]]

## 🔗 유사한 논문
- [[Enterprise_AI_Must_Enforce_Participant-Aware_Access_Control_20250919|Enterprise AI Must Enforce Participant-Aware Access Control]] (84.7% similar)
- [[The Sum Leaks More Than Its Parts Compositional Privacy Risks and Mitigations in Multi-Agent Collaboration]] (83.2% similar)
- [[From Capabilities to Performance Evaluating Key Functional Properties of LLM Architectures in Penetration Testing]] (82.9% similar)
- [[CyberLLMInstruct A Pseudo-malicious Dataset Revealing Safety-performance Trade-offs in Cyber Security LLM Fine-tuning]] (82.5% similar)
- [[An LLM Agentic Approach for Legal-Critical Software A Case Study for Tax Prep Software]] (82.5% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.05755v3 Announce Type: replace-cross 
Abstract: LLM-based agentic systems leverage large language models to handle user queries, make decisions, and execute external tools for complex tasks across domains like chatbots, customer service, and software engineering. A critical component of these systems is the Tool Invocation Prompt (TIP), which defines tool interaction protocols and guides LLMs to ensure the security and correctness of tool usage. Despite its importance, TIP security has been largely overlooked. This work investigates TIP-related security risks, revealing that major LLM-based systems like Cursor, Claude Code, and others are vulnerable to attacks such as remote code execution (RCE) and denial of service (DoS). Through a systematic TIP exploitation workflow (TEW), we demonstrate external tool behavior hijacking via manipulated tool invocations. We also propose defense mechanisms to enhance TIP security in LLM-based agentic systems.

## 🔍 Abstract (한글 번역)

arXiv:2509.05755v3 발표 유형: 교차 교체  
초록: LLM 기반 에이전트 시스템은 대형 언어 모델을 활용하여 사용자 질의에 응답하고, 의사 결정을 내리며, 챗봇, 고객 서비스, 소프트웨어 엔지니어링과 같은 다양한 분야에서 복잡한 작업을 수행하기 위해 외부 도구를 실행합니다. 이러한 시스템의 중요한 구성 요소는 도구 호출 프롬프트(TIP)로, 도구 상호작용 프로토콜을 정의하고 LLM이 도구 사용의 보안성과 정확성을 보장하도록 안내합니다. 그 중요성에도 불구하고, TIP 보안은 크게 간과되어 왔습니다. 본 연구는 TIP 관련 보안 위험을 조사하여 Cursor, Claude Code 등 주요 LLM 기반 시스템이 원격 코드 실행(RCE) 및 서비스 거부(DoS)와 같은 공격에 취약하다는 사실을 밝혀냅니다. 체계적인 TIP 악용 워크플로우(TEW)를 통해 조작된 도구 호출을 통한 외부 도구 동작 하이재킹을 시연합니다. 또한, LLM 기반 에이전트 시스템에서 TIP 보안을 강화하기 위한 방어 메커니즘을 제안합니다.

## 📝 요약

이 논문은 대형 언어 모델(LLM)을 활용한 에이전트 시스템에서의 도구 호출 프롬프트(TIP)의 보안 문제를 다룹니다. TIP는 도구 상호작용 프로토콜을 정의하여 LLM의 도구 사용의 안전성과 정확성을 보장하는 중요한 요소입니다. 그러나 TIP 보안은 그동안 간과되어 왔습니다. 연구 결과, Cursor, Claude Code 등 주요 LLM 기반 시스템이 원격 코드 실행(RCE) 및 서비스 거부(DoS) 공격에 취약하다는 사실을 밝혀냈습니다. 저자들은 체계적인 TIP 악용 워크플로우(TEW)를 통해 외부 도구의 행동을 조작할 수 있음을 시연하고, 이러한 보안 문제를 개선하기 위한 방어 메커니즘을 제안합니다.

## 🎯 주요 포인트

- 1. LLM 기반 에이전트 시스템은 사용자 질의 처리, 의사 결정, 외부 도구 실행을 통해 다양한 분야의 복잡한 작업을 수행합니다.

- 2. 도구 호출 프롬프트(TIP)는 도구 상호작용 프로토콜을 정의하고 LLM의 도구 사용의 보안성과 정확성을 보장하는 중요한 요소입니다.

- 3. 주요 LLM 기반 시스템들이 원격 코드 실행(RCE) 및 서비스 거부(DoS) 공격에 취약하다는 점을 밝혀냈습니다.

- 4. 체계적인 TIP 악용 워크플로우(TEW)를 통해 조작된 도구 호출을 통한 외부 도구 행동 하이재킹을 시연했습니다.

- 5. LLM 기반 에이전트 시스템의 TIP 보안을 강화하기 위한 방어 메커니즘을 제안했습니다.

---

*Generated on 2025-09-19 15:21:38*