
# Out-of-Sight Trajectories: Tracking, Fusion, and Prediction

**Korean Title:** ë³´ì´ì§€ ì•ŠëŠ” ê¶¤ì : ì¶”ì , ìœµí•© ë° ì˜ˆì¸¡

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-19|2025-09-19]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: Trajectory Prediction, Sensor Data Denoising

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[VSE-MOT Multi-Object Tracking in Low-Quality Video Scenes Guided by Visual Semantic Enhancement]] (80.6% similar)
- [[Ensemble of Pre-Trained Models for Long-Tailed Trajectory Prediction]] (80.0% similar)
- [[DECAMP Towards Scene-Consistent Multi-Agent Motion Prediction with Disentangled Context-Aware Pre-Training]] (79.6% similar)
- [[MAP End-to-End Autonomous Driving with Map-Assisted Planning]] (79.1% similar)
- [[Occupancy-aware_Trajectory_Planning_for_Autonomous_Valet_Parking_in_Uncertain_Dynamic_Environments_20250918|Occupancy-aware Trajectory Planning for Autonomous Valet Parking in Uncertain Dynamic Environments]] (78.7% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15219v1 Announce Type: cross 
Abstract: Trajectory prediction is a critical task in computer vision and autonomous systems, playing a key role in autonomous driving, robotics, surveillance, and virtual reality. Existing methods often rely on complete and noise-free observational data, overlooking the challenges associated with out-of-sight objects and the inherent noise in sensor data caused by limited camera coverage, obstructions, and the absence of ground truth for denoised trajectories. These limitations pose safety risks and hinder reliable prediction in real-world scenarios. In this extended work, we present advancements in Out-of-Sight Trajectory (OST), a novel task that predicts the noise-free visual trajectories of out-of-sight objects using noisy sensor data. Building on our previous research, we broaden the scope of Out-of-Sight Trajectory Prediction (OOSTraj) to include pedestrians and vehicles, extending its applicability to autonomous driving, robotics, surveillance, and virtual reality. Our enhanced Vision-Positioning Denoising Module leverages camera calibration to establish a vision-positioning mapping, addressing the lack of visual references, while effectively denoising noisy sensor data in an unsupervised manner. Through extensive evaluations on the Vi-Fi and JRDB datasets, our approach achieves state-of-the-art performance in both trajectory denoising and prediction, significantly surpassing previous baselines. Additionally, we introduce comparisons with traditional denoising methods, such as Kalman filtering, and adapt recent trajectory prediction models to our task, providing a comprehensive benchmark. This work represents the first initiative to integrate vision-positioning projection for denoising noisy sensor trajectories of out-of-sight agents, paving the way for future advances. The code and preprocessed datasets are available at github.com/Hai-chao-Zhang/OST

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15219v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ê¶¤ì  ì˜ˆì¸¡ì€ ì»´í“¨í„° ë¹„ì „ê³¼ ììœ¨ ì‹œìŠ¤í…œì—ì„œ ì¤‘ìš”í•œ ê³¼ì œë¡œ, ììœ¨ ì£¼í–‰, ë¡œë´‡ ê³µí•™, ê°ì‹œ, ê°€ìƒ í˜„ì‹¤ì—ì„œ í•µì‹¬ì ì¸ ì—­í• ì„ í•©ë‹ˆë‹¤. ê¸°ì¡´ ë°©ë²•ë“¤ì€ ì¢…ì¢… ì™„ì „í•˜ê³  ì¡ìŒì´ ì—†ëŠ” ê´€ì°° ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ë©°, ì‹œì•¼ ë°– ë¬¼ì²´ì™€ ì œí•œëœ ì¹´ë©”ë¼ ë²”ìœ„, ì¥ì• ë¬¼, ì¡ìŒì´ ì œê±°ëœ ê¶¤ì ì— ëŒ€í•œ ì‹¤ì œ ë°ì´í„°ì˜ ë¶€ì¬ë¡œ ì¸í•´ ë°œìƒí•˜ëŠ” ì„¼ì„œ ë°ì´í„°ì˜ ê³ ìœ í•œ ì¡ìŒê³¼ ê´€ë ¨ëœ ë¬¸ì œë¥¼ ê°„ê³¼í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì œí•œì€ ì•ˆì „ ìœ„í—˜ì„ ì´ˆë˜í•˜ê³  ì‹¤ì œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì˜ˆì¸¡ì„ ë°©í•´í•©ë‹ˆë‹¤. ì´ í™•ì¥ëœ ì—°êµ¬ì—ì„œëŠ” ì‹œì•¼ ë°– ê¶¤ì (OST)ì—ì„œì˜ ë°œì „ì„ ì œì‹œí•˜ë©°, ì¡ìŒì´ ìˆëŠ” ì„¼ì„œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œì•¼ ë°– ë¬¼ì²´ì˜ ì¡ìŒ ì—†ëŠ” ì‹œê°ì  ê¶¤ì ì„ ì˜ˆì¸¡í•˜ëŠ” ìƒˆë¡œìš´ ê³¼ì œë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ì´ì „ ì—°êµ¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ìš°ë¦¬ëŠ” ì‹œì•¼ ë°– ê¶¤ì  ì˜ˆì¸¡(OOSTraj)ì˜ ë²”ìœ„ë¥¼ ë³´í–‰ìì™€ ì°¨ëŸ‰ì„ í¬í•¨í•˜ë„ë¡ í™•ì¥í•˜ì—¬ ììœ¨ ì£¼í–‰, ë¡œë´‡ ê³µí•™, ê°ì‹œ, ê°€ìƒ í˜„ì‹¤ì—ì˜ ì ìš© ê°€ëŠ¥ì„±ì„ ë„“í˜”ìŠµë‹ˆë‹¤. í–¥ìƒëœ ë¹„ì „-í¬ì§€ì…”ë‹ ì¡ìŒ ì œê±° ëª¨ë“ˆì€ ì¹´ë©”ë¼ ë³´ì •ì„ í™œìš©í•˜ì—¬ ë¹„ì „-í¬ì§€ì…”ë‹ ë§¤í•‘ì„ ì„¤ì •í•˜ê³ , ì‹œê°ì  ì°¸ì¡°ì˜ ë¶€ì¡± ë¬¸ì œë¥¼ í•´ê²°í•˜ë©°, ë¹„ì§€ë„ ë°©ì‹ìœ¼ë¡œ ì¡ìŒì´ ìˆëŠ” ì„¼ì„œ ë°ì´í„°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì¡ìŒ ì œê±°í•©ë‹ˆë‹¤. Vi-Fi ë° JRDB ë°ì´í„°ì…‹ì— ëŒ€í•œ ê´‘ë²”ìœ„í•œ í‰ê°€ë¥¼ í†µí•´, ìš°ë¦¬ì˜ ì ‘ê·¼ ë°©ì‹ì€ ê¶¤ì  ì¡ìŒ ì œê±° ë° ì˜ˆì¸¡ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ë©°, ì´ì „ ê¸°ì¤€ì„ í¬ê²Œ ëŠ¥ê°€í•©ë‹ˆë‹¤. ë˜í•œ, ì¹¼ë§Œ í•„í„°ë§ê³¼ ê°™ì€ ì „í†µì ì¸ ì¡ìŒ ì œê±° ë°©ë²•ê³¼ì˜ ë¹„êµë¥¼ ì†Œê°œí•˜ê³ , ìµœê·¼ ê¶¤ì  ì˜ˆì¸¡ ëª¨ë¸ì„ ìš°ë¦¬ì˜ ê³¼ì œì— ë§ê²Œ ì¡°ì •í•˜ì—¬ í¬ê´„ì ì¸ ë²¤ì¹˜ë§ˆí¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ì‹œì•¼ ë°– ì—ì´ì „íŠ¸ì˜ ì¡ìŒ ìˆëŠ” ì„¼ì„œ ê¶¤ì ì„ ì¡ìŒ ì œê±°í•˜ê¸° ìœ„í•´ ë¹„ì „-í¬ì§€ì…”ë‹ íˆ¬ì˜ì„ í†µí•©í•˜ëŠ” ì²« ë²ˆì§¸ ì‹œë„ë¡œ, í–¥í›„ ë°œì „ì˜ ê¸¸ì„ ì—´ì–´ì¤ë‹ˆë‹¤. ì½”ë“œì™€ ì „ì²˜ë¦¬ëœ ë°ì´í„°ì…‹ì€ github.com/Hai-chao-Zhang/OSTì—ì„œ ì´ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ììœ¨ ì£¼í–‰, ë¡œë´‡ ê³µí•™, ê°ì‹œ, ê°€ìƒ í˜„ì‹¤ ë“±ì—ì„œ ì¤‘ìš”í•œ ì—­í• ì„ í•˜ëŠ” ê²½ë¡œ ì˜ˆì¸¡ ë¬¸ì œë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. ê¸°ì¡´ ë°©ë²•ë“¤ì€ ì™„ì „í•˜ê³  ì¡ìŒì´ ì—†ëŠ” ë°ì´í„°ë¥¼ ê°€ì •í•˜ì§€ë§Œ, ì´ ì—°êµ¬ëŠ” ì‹œì•¼ ë°– ê°ì²´ì˜ ì¡ìŒ ìˆëŠ” ì„¼ì„œ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ì¡ìŒ ì—†ëŠ” ê²½ë¡œë¥¼ ì˜ˆì¸¡í•˜ëŠ” ìƒˆë¡œìš´ ê³¼ì œì¸ Out-of-Sight Trajectory (OST)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. íŠ¹íˆ, ì¹´ë©”ë¼ ë³´ì •ì„ í™œìš©í•œ Vision-Positioning Denoising Moduleì„ í†µí•´ ì‹œê°ì  ì°¸ì¡°ê°€ ë¶€ì¡±í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³ , ë¹„ì§€ë„ í•™ìŠµ ë°©ì‹ìœ¼ë¡œ ì„¼ì„œ ë°ì´í„°ì˜ ì¡ìŒì„ ì œê±°í•©ë‹ˆë‹¤. Vi-Fiì™€ JRDB ë°ì´í„°ì…‹ì„ í†µí•œ í‰ê°€ì—ì„œ ê¸°ì¡´ ë°©ë²•ë“¤ì„ ëŠ¥ê°€í•˜ëŠ” ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë©°, Kalman í•„í„°ë§ ë“± ì „í†µì ì¸ ë°©ë²•ê³¼ì˜ ë¹„êµë„ í¬í•¨í•˜ì—¬ í¬ê´„ì ì¸ ë²¤ì¹˜ë§ˆí¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ì‹œì•¼ ë°– ê°ì²´ì˜ ì¡ìŒ ìˆëŠ” ê²½ë¡œë¥¼ ì‹œê°-ìœ„ì¹˜ íˆ¬ì˜ì„ í†µí•´ ì œê±°í•˜ëŠ” ìµœì´ˆì˜ ì‹œë„ë¡œ, í–¥í›„ ë°œì „ ê°€ëŠ¥ì„±ì„ ì œì‹œí•©ë‹ˆë‹¤. ê´€ë ¨ ì½”ë“œëŠ” GitHubì—ì„œ ì œê³µë©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë³¸ ì—°êµ¬ëŠ” ì‹œì•¼ ë°– ê°ì²´ì˜ ë…¸ì´ì¦ˆ ì—†ëŠ” ì‹œê°ì  ê¶¤ì ì„ ì˜ˆì¸¡í•˜ëŠ” ìƒˆë¡œìš´ ê³¼ì œì¸ Out-of-Sight Trajectory (OST)ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.

- 2. Vision-Positioning Denoising Moduleì„ í†µí•´ ì¹´ë©”ë¼ ë³´ì •ì„ í™œìš©í•˜ì—¬ ì‹œê°-ìœ„ì¹˜ ë§¤í•‘ì„ êµ¬ì¶•í•˜ê³ , ë¹„ì§€ë„ ë°©ì‹ìœ¼ë¡œ ì„¼ì„œ ë°ì´í„°ì˜ ë…¸ì´ì¦ˆë¥¼ ì œê±°í•©ë‹ˆë‹¤.

- 3. Vi-Fi ë° JRDB ë°ì´í„°ì…‹ì„ í†µí•œ í‰ê°€ì—ì„œ, ì œì•ˆëœ ë°©ë²•ì€ ê¶¤ì  ë…¸ì´ì¦ˆ ì œê±° ë° ì˜ˆì¸¡ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ë©° ê¸°ì¡´ ê¸°ì¤€ì„ ì„ í¬ê²Œ ì´ˆê³¼í•©ë‹ˆë‹¤.

- 4. Kalman í•„í„°ë§ê³¼ ê°™ì€ ì „í†µì ì¸ ë…¸ì´ì¦ˆ ì œê±° ë°©ë²•ê³¼ì˜ ë¹„êµë¥¼ í†µí•´ í¬ê´„ì ì¸ ë²¤ì¹˜ë§ˆí¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

- 5. ì´ ì—°êµ¬ëŠ” ì‹œì•¼ ë°– ì—ì´ì „íŠ¸ì˜ ë…¸ì´ì¦ˆ ì„¼ì„œ ê¶¤ì ì„ ì œê±°í•˜ê¸° ìœ„í•´ ì‹œê°-ìœ„ì¹˜ íˆ¬ì˜ì„ í†µí•©í•œ ìµœì´ˆì˜ ì‹œë„ë¡œ, í–¥í›„ ë°œì „ì˜ ê¸¸ì„ ì—´ì—ˆìŠµë‹ˆë‹¤.

---

*Generated on 2025-09-19 15:37:26*