---
keywords:
  - Tilted Empirical Risk Minimization
  - Outlier Detection
  - Robust Regression
category: cs.AI
publish_date: 2025-09-19
arxiv_id: 2509.15141
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 21:54:59.889942",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Tilted Empirical Risk Minimization",
    "Outlier Detection",
    "Robust Regression"
  ],
  "rejected_keywords": [
    "Empirical Risk Minimization"
  ],
  "similarity_scores": {
    "Tilted Empirical Risk Minimization": 0.78,
    "Outlier Detection": 0.77,
    "Robust Regression": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->


# Benefits of Online Tilted Empirical Risk Minimization: A Case Study of Outlier Detection and Robust Regression

**Korean Title:** ì˜¨ë¼ì¸ ê¸°ìš¸ì–´ì§„ ê²½í—˜ì  ìœ„í—˜ ìµœì†Œí™”ì˜ ì´ì : ì´ìƒì¹˜ íƒì§€ ë° ê°•ê±´ íšŒê·€ì˜ ì‚¬ë¡€ ì—°êµ¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[digests/daily_digest_20250919|2025-09-19]]   [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Outlier Detection|Outlier Detection]], [[keywords/Robust Regression|Robust Regression]]
**âš¡ Unique Technical**: [[keywords/Tilted Empirical Risk Minimization|Tilted Empirical Risk Minimization]]

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[Multi-Fidelity_Hybrid_Reinforcement_Learning_via_Information_Gain_Maximization_20250919|Multi-Fidelity Hybrid Reinforcement Learning via Information Gain Maximization]] (79.8% similar)
- [[Sample_Efficient_Experience_Replay_in_Non-stationary_Environments_20250919|Sample Efficient Experience Replay in Non-stationary Environments]] (79.1% similar)
- [[Optimal_Learning_from_Label_Proportions_with_General_Loss_Functions_20250919|Optimal Learning from Label Proportions with General Loss Functions]] (78.5% similar)
- [[Accelerated Gradient Methods with Biased Gradient Estimates Risk Sensitivity, High-Probability Guarantees, and Large Deviation Bounds]] (77.5% similar)
- [[Efficient Last-Iterate Convergence in Regret Minimization via Adaptive Reward Transformation]] (77.4% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15141v1 Announce Type: cross 
Abstract: Empirical Risk Minimization (ERM) is a foundational framework for supervised learning but primarily optimizes average-case performance, often neglecting fairness and robustness considerations. Tilted Empirical Risk Minimization (TERM) extends ERM by introducing an exponential tilt hyperparameter $t$ to balance average-case accuracy with worst-case fairness and robustness. However, in online or streaming settings where data arrive one sample at a time, the classical TERM objective degenerates to standard ERM, losing tilt sensitivity. We address this limitation by proposing an online TERM formulation that removes the logarithm from the classical objective, preserving tilt effects without additional computational or memory overhead. This formulation enables a continuous trade-off controlled by $t$, smoothly interpolating between ERM ($t \to 0$), fairness emphasis ($t > 0$), and robustness to outliers ($t < 0$). We empirically validate online TERM on two representative streaming tasks: robust linear regression with adversarial outliers and minority-class detection in binary classification. Our results demonstrate that negative tilting effectively suppresses outlier influence, while positive tilting improves recall with minimal impact on precision, all at per-sample computational cost equivalent to ERM. Online TERM thus recovers the full robustness-fairness spectrum of classical TERM in an efficient single-sample learning regime.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15141v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ê²½í—˜ì  ìœ„í—˜ ìµœì†Œí™”(ERM)ëŠ” ì§€ë„ í•™ìŠµì„ ìœ„í•œ ê¸°ì´ˆì ì¸ í”„ë ˆì„ì›Œí¬ì´ì§€ë§Œ, ì£¼ë¡œ í‰ê· ì ì¸ ì„±ëŠ¥ì„ ìµœì í™”í•˜ì—¬ ê³µì •ì„±ê³¼ ê²¬ê³ ì„± ê³ ë ¤ë¥¼ ì¢…ì¢… ê°„ê³¼í•©ë‹ˆë‹¤. ê¸°ìš¸ì–´ì§„ ê²½í—˜ì  ìœ„í—˜ ìµœì†Œí™”(TERM)ëŠ” í‰ê· ì ì¸ ì •í™•ë„ì™€ ìµœì•…ì˜ ê²½ìš°ì˜ ê³µì •ì„±ê³¼ ê²¬ê³ ì„±ì„ ê· í˜• ìˆê²Œ ì¡°ì ˆí•˜ê¸° ìœ„í•´ ì§€ìˆ˜ ê¸°ìš¸ê¸° í•˜ì´í¼íŒŒë¼ë¯¸í„° $t$ë¥¼ ë„ì…í•˜ì—¬ ERMì„ í™•ì¥í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë°ì´í„°ê°€ í•œ ë²ˆì— í•˜ë‚˜ì”© ë„ì°©í•˜ëŠ” ì˜¨ë¼ì¸ ë˜ëŠ” ìŠ¤íŠ¸ë¦¬ë° í™˜ê²½ì—ì„œëŠ”, ê³ ì „ì ì¸ TERM ëª©í‘œê°€ í‘œì¤€ ERMìœ¼ë¡œ í‡´í™”í•˜ì—¬ ê¸°ìš¸ê¸° ë¯¼ê°ì„±ì„ ìƒìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” ê³ ì „ì ì¸ ëª©í‘œì—ì„œ ë¡œê·¸ë¥¼ ì œê±°í•˜ì—¬ ì¶”ê°€ì ì¸ ê³„ì‚°ì´ë‚˜ ë©”ëª¨ë¦¬ ë¶€ë‹´ ì—†ì´ ê¸°ìš¸ê¸° íš¨ê³¼ë¥¼ ìœ ì§€í•˜ëŠ” ì˜¨ë¼ì¸ TERM ê³µì‹ì„ ì œì•ˆí•˜ì—¬ ì´ í•œê³„ë¥¼ í•´ê²°í•©ë‹ˆë‹¤. ì´ ê³µì‹ì€ $t$ì— ì˜í•´ ì œì–´ë˜ëŠ” ì—°ì†ì ì¸ ì ˆì¶©ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ì—¬, ERM ($t \to 0$), ê³µì •ì„± ê°•ì¡° ($t > 0$), ì´ìƒì¹˜ì— ëŒ€í•œ ê²¬ê³ ì„± ($t < 0$) ì‚¬ì´ë¥¼ ë¶€ë“œëŸ½ê²Œ ë³´ê°„í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ë‘ ê°€ì§€ ëŒ€í‘œì ì¸ ìŠ¤íŠ¸ë¦¬ë° ì‘ì—…ì¸ ì ëŒ€ì  ì´ìƒì¹˜ê°€ ìˆëŠ” ê²¬ê³ í•œ ì„ í˜• íšŒê·€ì™€ ì´ì§„ ë¶„ë¥˜ì—ì„œì˜ ì†Œìˆ˜ í´ë˜ìŠ¤ íƒì§€ì— ëŒ€í•´ ì˜¨ë¼ì¸ TERMì„ ê²½í—˜ì ìœ¼ë¡œ ê²€ì¦í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ê²°ê³¼ëŠ” ë¶€ì •ì ì¸ ê¸°ìš¸ê¸°ê°€ íš¨ê³¼ì ìœ¼ë¡œ ì´ìƒì¹˜ì˜ ì˜í–¥ì„ ì–µì œí•˜ê³ , ê¸ì •ì ì¸ ê¸°ìš¸ê¸°ê°€ ì •ë°€ë„ì— ìµœì†Œí•œì˜ ì˜í–¥ì„ ë¯¸ì¹˜ë©´ì„œ ì¬í˜„ìœ¨ì„ í–¥ìƒì‹œí‚¨ë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ëª¨ë“  ê²ƒì´ ERMê³¼ ë™ë“±í•œ ìƒ˜í”Œë‹¹ ê³„ì‚° ë¹„ìš©ìœ¼ë¡œ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤. ë”°ë¼ì„œ ì˜¨ë¼ì¸ TERMì€ íš¨ìœ¨ì ì¸ ë‹¨ì¼ ìƒ˜í”Œ í•™ìŠµ ì²´ê³„ì—ì„œ ê³ ì „ì ì¸ TERMì˜ ì „ì²´ ê²¬ê³ ì„±-ê³µì •ì„± ìŠ¤í™íŠ¸ëŸ¼ì„ íšŒë³µí•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

Empirical Risk Minimization(ERM)ì€ í‰ê·  ì„±ëŠ¥ ìµœì í™”ì— ì¤‘ì ì„ ë‘ì§€ë§Œ ê³µì •ì„±ê³¼ ê°•ê±´ì„±ì„ ê°„ê³¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ ê°œì„ í•˜ê¸° ìœ„í•´ Tilted Empirical Risk Minimization(TERM)ì€ ì§€ìˆ˜ ê¸°ìš¸ê¸° ë§¤ê°œë³€ìˆ˜ $t$ë¥¼ ë„ì…í•˜ì—¬ í‰ê·  ì„±ëŠ¥ê³¼ ìµœì•…ì˜ ê²½ìš°ì˜ ê³µì •ì„± ë° ê°•ê±´ì„±ì„ ê· í˜• ìˆê²Œ ì¡°ì ˆí•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì˜¨ë¼ì¸ í™˜ê²½ì—ì„œëŠ” ê¸°ì¡´ TERM ëª©í‘œê°€ ERMìœ¼ë¡œ í‡´í™”í•˜ëŠ” ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ìš°ë¦¬ëŠ” ë¡œê·¸ë¥¼ ì œê±°í•œ ì˜¨ë¼ì¸ TERM ê³µì‹ì„ ì œì•ˆí•˜ì—¬ ê¸°ìš¸ê¸° íš¨ê³¼ë¥¼ ìœ ì§€í•˜ë©´ì„œ ì¶”ê°€ì ì¸ ê³„ì‚°ì´ë‚˜ ë©”ëª¨ë¦¬ ë¶€ë‹´ ì—†ì´ ì¡°ì ˆí•  ìˆ˜ ìˆë„ë¡ í–ˆìŠµë‹ˆë‹¤. ì´ ê³µì‹ì€ $t$ì— ë”°ë¼ ERM($t \to 0$), ê³µì •ì„± ê°•ì¡°($t > 0$), ì´ìƒì¹˜ì— ëŒ€í•œ ê°•ê±´ì„±($t < 0$)ì„ ë§¤ë„ëŸ½ê²Œ ì¡°ì ˆí•©ë‹ˆë‹¤. ë‘ ê°€ì§€ ìŠ¤íŠ¸ë¦¬ë° ì‘ì—…ì—ì„œ ì˜¨ë¼ì¸ TERMì„ ì‹¤í—˜í•œ ê²°ê³¼, ìŒì˜ ê¸°ìš¸ê¸°ëŠ” ì´ìƒì¹˜ ì˜í–¥ì„ ì–µì œí•˜ê³  ì–‘ì˜ ê¸°ìš¸ê¸°ëŠ” ì¬í˜„ìœ¨ì„ í–¥ìƒì‹œí‚¤ë©´ì„œ ì •ë°€ë„ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ìµœì†Œí™”í•¨ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ì˜¨ë¼ì¸ TERMì€ ë‹¨ì¼ ìƒ˜í”Œ í•™ìŠµ í™˜ê²½ì—ì„œ íš¨ìœ¨ì ìœ¼ë¡œ ê°•ê±´ì„±ê³¼ ê³µì •ì„±ì˜ ì „ì²´ ìŠ¤í™íŠ¸ëŸ¼ì„ íšŒë³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ê¸°ìš¸ì–´ì§„ ê²½í—˜ì  ìœ„í—˜ ìµœì†Œí™”(TERM)ëŠ” í‰ê·  ì„±ëŠ¥ê³¼ ìµœì•…ì˜ ê²½ìš°ì˜ ê³µì •ì„±ê³¼ ê°•ê±´ì„±ì„ ê· í˜• ìˆê²Œ ì¡°ì •í•©ë‹ˆë‹¤.

- 2. ì˜¨ë¼ì¸ í™˜ê²½ì—ì„œ ê¸°ì¡´ TERM ëª©ì ì€ í‘œì¤€ ERMìœ¼ë¡œ í‡´í™”í•˜ì—¬ ê¸°ìš¸ê¸° ë¯¼ê°ì„±ì„ ìƒìŠµë‹ˆë‹¤.

- 3. ì œì•ˆëœ ì˜¨ë¼ì¸ TERM ê³µì‹ì€ ë¡œê·¸ë¥¼ ì œê±°í•˜ì—¬ ì¶”ê°€ì ì¸ ê³„ì‚° ë˜ëŠ” ë©”ëª¨ë¦¬ ë¶€ë‹´ ì—†ì´ ê¸°ìš¸ê¸° íš¨ê³¼ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.

- 4. ì˜¨ë¼ì¸ TERMì€ ê¸°ìš¸ê¸° ë§¤ê°œë³€ìˆ˜ $t$ë¥¼ í†µí•´ ERM, ê³µì •ì„± ê°•ì¡°, ì´ìƒì¹˜ì— ëŒ€í•œ ê°•ê±´ì„± ê°„ì˜ ì—°ì†ì ì¸ ì ˆì¶©ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.

- 5. ì‹¤í—˜ ê²°ê³¼, ì˜¨ë¼ì¸ TERMì€ ì´ìƒì¹˜ì˜ ì˜í–¥ì„ ì–µì œí•˜ê³  ì†Œìˆ˜ í´ë˜ìŠ¤ ê²€ì¶œì—ì„œ ì¬í˜„ìœ¨ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

---

*Generated on 2025-09-19 15:37:00*