
# TableDART: Dynamic Adaptive Multi-Modal Routing for Table Understanding

**Korean Title:** TableDART: í‘œ ì´í•´ë¥¼ ìœ„í•œ ë™ì  ì ì‘í˜• ë‹¤ì¤‘ ëª¨ë‹¬ ë¼ìš°íŒ…

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-19|2025-09-19]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Dynamic Adaptive Routing

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[DetectAnyLLM Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models]] (81.4% similar)
- [[(P)rior(D)yna(F)low A Priori Dynamic Workflow Construction via Multi-Agent Collaboration]] (80.8% similar)
- [[LLM-I LLMs are Naturally Interleaved Multimodal Creators]] (80.8% similar)
- [[Process-Supervised_Reinforcement_Learning_for_Interactive_Multimodal_Tool-Use_Agents_20250919|Process-Supervised Reinforcement Learning for Interactive Multimodal Tool-Use Agents]] (80.5% similar)
- [[DRDT3 Diffusion-Refined Decision Test-Time Training Model]] (80.2% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.14671v1 Announce Type: cross 
Abstract: Modeling semantic and structural information from tabular data remains a core challenge for effective table understanding. Existing Table-as-Text approaches flatten tables for large language models (LLMs), but lose crucial structural cues, while Table-as-Image methods preserve structure yet struggle with fine-grained semantics. Recent Table-as-Multimodality strategies attempt to combine textual and visual views, but they (1) statically process both modalities for every query-table pair within a large multimodal LLMs (MLLMs), inevitably introducing redundancy and even conflicts, and (2) depend on costly fine-tuning of MLLMs. In light of this, we propose TableDART, a training-efficient framework that integrates multimodal views by reusing pretrained single-modality models. TableDART introduces a lightweight 2.59M-parameter MLP gating network that dynamically selects the optimal path (either Text-only, Image-only, or Fusion) for each table-query pair, effectively reducing redundancy and conflicts from both modalities. In addition, we propose a novel agent to mediate cross-modal knowledge integration by analyzing outputs from text- and image-based models, either selecting the best result or synthesizing a new answer through reasoning. This design avoids the prohibitive costs of full MLLM fine-tuning. Extensive experiments on seven benchmarks show that TableDART establishes new state-of-the-art performance among open-source models, surpassing the strongest baseline by an average of 4.02%. The code is available at: https://anonymous.4open.science/r/TableDART-C52B

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.14671v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: í‘œ ë°ì´í„°ë¥¼ ì´í•´í•˜ëŠ” ë° ìˆì–´ ì˜ë¯¸ì  ë° êµ¬ì¡°ì  ì •ë³´ë¥¼ ëª¨ë¸ë§í•˜ëŠ” ê²ƒì€ ì—¬ì „íˆ í•µì‹¬ ê³¼ì œì…ë‹ˆë‹¤. ê¸°ì¡´ì˜ í…ìŠ¤íŠ¸ë¡œì„œì˜ í‘œ ì ‘ê·¼ ë°©ì‹ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ ìœ„í•´ í‘œë¥¼ í‰íƒ„í™”í•˜ì§€ë§Œ ì¤‘ìš”í•œ êµ¬ì¡°ì  ë‹¨ì„œë¥¼ ìƒì–´ë²„ë¦¬ë©°, ì´ë¯¸ì§€ë¡œì„œì˜ í‘œ ë°©ë²•ì€ êµ¬ì¡°ë¥¼ ë³´ì¡´í•˜ì§€ë§Œ ì„¸ë°€í•œ ì˜ë¯¸ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªìŠµë‹ˆë‹¤. ìµœê·¼ì˜ ë©€í‹°ëª¨ë‹¬ë¦¬í‹°ë¡œì„œì˜ í‘œ ì „ëµì€ í…ìŠ¤íŠ¸ ë° ì‹œê°ì  ê´€ì ì„ ê²°í•©í•˜ë ¤ê³  ì‹œë„í•˜ì§€ë§Œ, (1) ëŒ€í˜• ë©€í‹°ëª¨ë‹¬ LLM(MLLM) ë‚´ì—ì„œ ëª¨ë“  ì¿¼ë¦¬-í‘œ ìŒì— ëŒ€í•´ ë‘ ê°€ì§€ ëª¨ë‹¬ë¦¬í‹°ë¥¼ ì •ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ë¶ˆê°€í”¼í•˜ê²Œ ì¤‘ë³µ ë° ì¶©ëŒì„ ì´ˆë˜í•˜ê³ , (2) MLLMì˜ ë¹„ìš©ì´ ë§ì´ ë“œëŠ” ë¯¸ì„¸ ì¡°ì •ì— ì˜ì¡´í•©ë‹ˆë‹¤. ì´ë¥¼ ê³ ë ¤í•˜ì—¬, ìš°ë¦¬ëŠ” ì‚¬ì „ í›ˆë ¨ëœ ë‹¨ì¼ ëª¨ë‹¬ë¦¬í‹° ëª¨ë¸ì„ ì¬ì‚¬ìš©í•˜ì—¬ ë©€í‹°ëª¨ë‹¬ ê´€ì ì„ í†µí•©í•˜ëŠ” í›ˆë ¨ íš¨ìœ¨ì ì¸ í”„ë ˆì„ì›Œí¬ì¸ TableDARTë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. TableDARTëŠ” ê° í‘œ-ì¿¼ë¦¬ ìŒì— ëŒ€í•´ ìµœì ì˜ ê²½ë¡œ(í…ìŠ¤íŠ¸ ì „ìš©, ì´ë¯¸ì§€ ì „ìš© ë˜ëŠ” ìœµí•©)ë¥¼ ë™ì ìœ¼ë¡œ ì„ íƒí•˜ëŠ” ê²½ëŸ‰ì˜ 2.59M-íŒŒë¼ë¯¸í„° MLP ê²Œì´íŒ… ë„¤íŠ¸ì›Œí¬ë¥¼ ë„ì…í•˜ì—¬ ë‘ ëª¨ë‹¬ë¦¬í‹°ì˜ ì¤‘ë³µ ë° ì¶©ëŒì„ íš¨ê³¼ì ìœ¼ë¡œ ì¤„ì…ë‹ˆë‹¤. ë˜í•œ, ìš°ë¦¬ëŠ” í…ìŠ¤íŠ¸ ë° ì´ë¯¸ì§€ ê¸°ë°˜ ëª¨ë¸ì˜ ì¶œë ¥ì„ ë¶„ì„í•˜ì—¬ ìµœìƒì˜ ê²°ê³¼ë¥¼ ì„ íƒí•˜ê±°ë‚˜ ì¶”ë¡ ì„ í†µí•´ ìƒˆë¡œìš´ ë‹µë³€ì„ í•©ì„±í•¨ìœ¼ë¡œì¨ êµì°¨ ëª¨ë‹¬ ì§€ì‹ í†µí•©ì„ ì¤‘ì¬í•˜ëŠ” ìƒˆë¡œìš´ ì—ì´ì „íŠ¸ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ì„¤ê³„ëŠ” ì „ì²´ MLLM ë¯¸ì„¸ ì¡°ì •ì˜ ê³¼ë„í•œ ë¹„ìš©ì„ í”¼í•©ë‹ˆë‹¤. ì¼ê³± ê°€ì§€ ë²¤ì¹˜ë§ˆí¬ì— ëŒ€í•œ ê´‘ë²”ìœ„í•œ ì‹¤í—˜ì€ TableDARTê°€ ì˜¤í”ˆ ì†ŒìŠ¤ ëª¨ë¸ ì¤‘ ìƒˆë¡œìš´ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ í™•ë¦½í•˜ë©°, ê°€ì¥ ê°•ë ¥í•œ ê¸°ì¤€ì„ ì„ í‰ê·  4.02% ì´ˆê³¼í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì½”ë“œëŠ” ë‹¤ìŒì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤: https://anonymous.4open.science/r/TableDART-C52B

## ğŸ“ ìš”ì•½

TableDARTëŠ” í…Œì´ë¸” ë°ì´í„°ì˜ ì˜ë¯¸ì™€ êµ¬ì¡° ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ëª¨ë¸ë§í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¡œ, ê¸°ì¡´ì˜ Table-as-Textì™€ Table-as-Image ì ‘ê·¼ë²•ì˜ í•œê³„ë¥¼ ê·¹ë³µí•©ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ì‚¬ì „ í•™ìŠµëœ ë‹¨ì¼ ëª¨ë‹¬ë¦¬í‹° ëª¨ë¸ì„ ì¬ì‚¬ìš©í•˜ì—¬ ë©€í‹°ëª¨ë‹¬ ë·°ë¥¼ í†µí•©í•˜ë©°, 2.59M íŒŒë¼ë¯¸í„°ì˜ MLP ê²Œì´íŒ… ë„¤íŠ¸ì›Œí¬ë¥¼ í†µí•´ ê° í…Œì´ë¸”-ì¿¼ë¦¬ ìŒì— ëŒ€í•´ ìµœì ì˜ ê²½ë¡œë¥¼ ë™ì ìœ¼ë¡œ ì„ íƒí•©ë‹ˆë‹¤. ë˜í•œ, í…ìŠ¤íŠ¸ ë° ì´ë¯¸ì§€ ê¸°ë°˜ ëª¨ë¸ì˜ ì¶œë ¥ì„ ë¶„ì„í•˜ì—¬ ìµœì ì˜ ê²°ê³¼ë¥¼ ì„ íƒí•˜ê±°ë‚˜ ìƒˆë¡œìš´ ë‹µë³€ì„ í•©ì„±í•˜ëŠ” ì—ì´ì „íŠ¸ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ì ‘ê·¼ë²•ì€ MLLMì˜ ë¹„ìš©ì´ ë§ì´ ë“œëŠ” ë¯¸ì„¸ ì¡°ì •ì„ í”¼í•˜ë©´ì„œë„, 7ê°œì˜ ë²¤ì¹˜ë§ˆí¬ ì‹¤í—˜ì—ì„œ í‰ê·  4.02%ì˜ ì„±ëŠ¥ í–¥ìƒì„ ë‹¬ì„±í•˜ë©° ìƒˆë¡œìš´ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. TableDARTëŠ” ì‚¬ì „ í•™ìŠµëœ ë‹¨ì¼ ëª¨ë‹¬ë¦¬í‹° ëª¨ë¸ì„ ì¬ì‚¬ìš©í•˜ì—¬ ë©€í‹°ëª¨ë‹¬ ë·°ë¥¼ í†µí•©í•˜ëŠ” íš¨ìœ¨ì ì¸ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.

- 2. 2.59M íŒŒë¼ë¯¸í„°ì˜ ê²½ëŸ‰ MLP ê²Œì´íŒ… ë„¤íŠ¸ì›Œí¬ë¥¼ ë„ì…í•˜ì—¬ ê° í…Œì´ë¸”-ì¿¼ë¦¬ ìŒì— ëŒ€í•´ ìµœì ì˜ ê²½ë¡œë¥¼ ë™ì ìœ¼ë¡œ ì„ íƒí•©ë‹ˆë‹¤.

- 3. í…ìŠ¤íŠ¸ ë° ì´ë¯¸ì§€ ê¸°ë°˜ ëª¨ë¸ì˜ ì¶œë ¥ì„ ë¶„ì„í•˜ì—¬ ìµœìƒì˜ ê²°ê³¼ë¥¼ ì„ íƒí•˜ê±°ë‚˜ ìƒˆë¡œìš´ ë‹µë³€ì„ í•©ì„±í•˜ëŠ” êµì°¨ ëª¨ë‹¬ ì§€ì‹ í†µí•© ì—ì´ì „íŠ¸ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.

- 4. TableDARTëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ ëª¨ë¸ ì¤‘ ìƒˆë¡œìš´ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ë©°, ê°€ì¥ ê°•ë ¥í•œ ê¸°ì¤€ì„ ë³´ë‹¤ í‰ê·  4.02% ë” ë†’ì€ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.

---

*Generated on 2025-09-19 14:59:43*