---
keywords:
  - Large Language Models
  - Optimization
  - agentic framework
category: cs.AI
publish_date: 2025-09-19
arxiv_id: 2509.14279
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 21:20:49.250738",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Models",
    "Optimization",
    "agentic framework"
  ],
  "rejected_keywords": [
    "robust-kbench",
    "evolutionary meta-generation"
  ],
  "similarity_scores": {
    "Large Language Models": 0.85,
    "Optimization": 0.78,
    "agentic framework": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->


# Towards Robust Agentic CUDA Kernel Benchmarking, Verification, and Optimization

**Korean Title:** ê²¬ê³ í•œ ì—ì´ì „íŠ¸ CUDA ì»¤ë„ ë²¤ì¹˜ë§ˆí‚¹, ê²€ì¦ ë° ìµœì í™”ë¥¼ í–¥í•˜ì—¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[digests/daily_digest_20250919|2025-09-19]]   [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸŒ Broad Technical**: [[keywords/Optimization|CUDA kernel optimization]]
**âš¡ Unique Technical**: [[keywords/agentic framework|agentic framework]]
**ğŸš€ Evolved Concepts**: [[keywords/Large Language Models|Large Language Models]]

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[Evolution of Kernels Automated RISC-V Kernel Optimization with Large Language Models]] (84.0% similar)
- [[AgentCompass Towards Reliable Evaluation of Agentic Workflows in Production]] (82.8% similar)
- [[From Capabilities to Performance Evaluating Key Functional Properties of LLM Architectures in Penetration Testing]] (81.9% similar)
- [[LLM-I LLMs are Naturally Interleaved Multimodal Creators]] (81.4% similar)
- [[From Legacy Fortran to Portable Kokkos An Autonomous Agentic AI Workflow]] (81.4% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.14279v1 Announce Type: cross 
Abstract: Recent advances in large language models (LLMs) demonstrate their effectiveness in scaling test-time compute for software engineering tasks. However, these approaches often focus on high-level solutions, with limited attention to optimizing low-level CUDA kernel implementations. Additionally, existing kernel generation benchmarks suffer from exploitable loopholes and insufficient diversity in testing conditions, hindering true generalization assessment. To address these limitations, we introduce robust-kbench, a new benchmark for rigorous evaluation of kernel performance and correctness across varied scenarios. Furthermore, we present a comprehensive agentic framework that automates CUDA kernel discovery, verification, and optimization. This pipeline enables frontier LLMs to translate torch code to CUDA kernels and iteratively improve their runtime within our robust evaluation setting. Our sequential workflow first translates PyTorch code into equivalent CUDA kernels. It then optimizes their runtime using a novel evolutionary meta-generation procedure tailored to the CUDA ecosystem, guided by LLM-based verifiers for correctness and efficient filtering. Evaluated on robust-kbench, our approach produces CUDA kernels outperforming torch implementations for practical applications, including forward and backward passes. It can fuse operations and deploy various runtime optimization strategies. The verifier workflow accurately classifies incorrect kernels, enhancing hardware verification efficiency.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.14279v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ìµœê·¼ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì˜ ë°œì „ì€ ì†Œí”„íŠ¸ì›¨ì–´ ê³µí•™ ì‘ì—…ì—ì„œ í…ŒìŠ¤íŠ¸ ì‹œì ì˜ ê³„ì‚°ì„ í™•ì¥í•˜ëŠ” ë° ìˆì–´ ê·¸ íš¨ê³¼ì„±ì„ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ëŸ¬í•œ ì ‘ê·¼ ë°©ì‹ì€ ì¢…ì¢… ê³ ìˆ˜ì¤€ ì†”ë£¨ì…˜ì— ì¤‘ì ì„ ë‘ë©°, ì €ìˆ˜ì¤€ CUDA ì»¤ë„ êµ¬í˜„ ìµœì í™”ì—ëŠ” ì œí•œì ì¸ ê´€ì‹¬ì„ ê¸°ìš¸ì…ë‹ˆë‹¤. ë˜í•œ, ê¸°ì¡´ì˜ ì»¤ë„ ìƒì„± ë²¤ì¹˜ë§ˆí¬ëŠ” ì•…ìš© ê°€ëŠ¥í•œ í—ˆì ê³¼ í…ŒìŠ¤íŠ¸ ì¡°ê±´ì˜ ë‹¤ì–‘ì„± ë¶€ì¡±ìœ¼ë¡œ ì¸í•´ ì§„ì •í•œ ì¼ë°˜í™” í‰ê°€ë¥¼ ë°©í•´í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ í•œê³„ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì»¤ë„ ì„±ëŠ¥ê³¼ ì •í™•ì„±ì„ ì—„ê²©í•˜ê²Œ í‰ê°€í•  ìˆ˜ ìˆëŠ” ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ì¸ robust-kbenchë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ë” ë‚˜ì•„ê°€, CUDA ì»¤ë„ íƒìƒ‰, ê²€ì¦ ë° ìµœì í™”ë¥¼ ìë™í™”í•˜ëŠ” í¬ê´„ì ì¸ ì—ì´ì „í‹± í”„ë ˆì„ì›Œí¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ì´ íŒŒì´í”„ë¼ì¸ì€ ìµœì²¨ë‹¨ LLMì´ torch ì½”ë“œë¥¼ CUDA ì»¤ë„ë¡œ ë³€í™˜í•˜ê³ , ìš°ë¦¬ì˜ ê°•ë ¥í•œ í‰ê°€ í™˜ê²½ ë‚´ì—ì„œ ì‹¤í–‰ ì‹œê°„ì„ ë°˜ë³µì ìœ¼ë¡œ ê°œì„ í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ìˆœì°¨ì  ì›Œí¬í”Œë¡œìš°ëŠ” ë¨¼ì € PyTorch ì½”ë“œë¥¼ ë™ë“±í•œ CUDA ì»¤ë„ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ, CUDA ìƒíƒœê³„ì— ë§ì¶˜ ìƒˆë¡œìš´ ì§„í™”ì  ë©”íƒ€ ìƒì„± ì ˆì°¨ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤í–‰ ì‹œê°„ì„ ìµœì í™”í•˜ë©°, LLM ê¸°ë°˜ ê²€ì¦ìë¥¼ í†µí•´ ì •í™•ì„±ê³¼ íš¨ìœ¨ì ì¸ í•„í„°ë§ì„ ì•ˆë‚´í•©ë‹ˆë‹¤. robust-kbenchì—ì„œ í‰ê°€í•œ ê²°ê³¼, ìš°ë¦¬ì˜ ì ‘ê·¼ ë°©ì‹ì€ torch êµ¬í˜„ì„ ëŠ¥ê°€í•˜ëŠ” CUDA ì»¤ë„ì„ ìƒì„±í•˜ì—¬, ìˆœë°©í–¥ ë° ì—­ë°©í–¥ íŒ¨ìŠ¤ë¥¼ í¬í•¨í•œ ì‹¤ì œ ì‘ìš© í”„ë¡œê·¸ë¨ì— ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ì—°ì‚°ì„ ìœµí•©í•˜ê³  ë‹¤ì–‘í•œ ì‹¤í–‰ ì‹œê°„ ìµœì í™” ì „ëµì„ ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê²€ì¦ì ì›Œí¬í”Œë¡œìš°ëŠ” ì˜ëª»ëœ ì»¤ë„ì„ ì •í™•í•˜ê²Œ ë¶„ë¥˜í•˜ì—¬ í•˜ë“œì›¨ì–´ ê²€ì¦ íš¨ìœ¨ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ìµœê·¼ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ë°œì „ì€ ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´ë§ ì‘ì—…ì—ì„œì˜ ì„±ëŠ¥ì„ ì…ì¦í–ˆì§€ë§Œ, ì €ìˆ˜ì¤€ì˜ CUDA ì»¤ë„ êµ¬í˜„ ìµœì í™”ì—ëŠ” í•œê³„ê°€ ìˆì—ˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì»¤ë„ ì„±ëŠ¥ê³¼ ì •í™•ì„±ì„ í‰ê°€í•  ìˆ˜ ìˆëŠ” ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ì¸ robust-kbenchë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ë˜í•œ, CUDA ì»¤ë„ì˜ ë°œê²¬, ê²€ì¦ ë° ìµœì í™”ë¥¼ ìë™í™”í•˜ëŠ” í¬ê´„ì ì¸ ì—ì´ì „íŠ¸ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” PyTorch ì½”ë“œë¥¼ CUDA ì»¤ë„ë¡œ ë³€í™˜í•˜ê³ , LLM ê¸°ë°˜ ê²€ì¦ê¸°ë¥¼ í†µí•´ ì •í™•ì„±ê³¼ íš¨ìœ¨ì„±ì„ ë†’ì´ë©°, ìƒˆë¡œìš´ ì§„í™”ì  ë©”íƒ€ ìƒì„± ì ˆì°¨ë¥¼ í†µí•´ ëŸ°íƒ€ì„ì„ ìµœì í™”í•©ë‹ˆë‹¤. robust-kbench í‰ê°€ ê²°ê³¼, ìš°ë¦¬ì˜ ì ‘ê·¼ ë°©ì‹ì€ ì‹¤ì œ ì‘ìš© í”„ë¡œê·¸ë¨ì—ì„œ torch êµ¬í˜„ë³´ë‹¤ ìš°ìˆ˜í•œ CUDA ì»¤ë„ì„ ìƒì„±í•˜ë©°, ë‹¤ì–‘í•œ ëŸ°íƒ€ì„ ìµœì í™” ì „ëµì„ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê²€ì¦ ì›Œí¬í”Œë¡œëŠ” ì˜ëª»ëœ ì»¤ë„ì„ ì •í™•íˆ ë¶„ë¥˜í•˜ì—¬ í•˜ë“œì›¨ì–´ ê²€ì¦ íš¨ìœ¨ì„±ì„ ë†’ì…ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì€ ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´ë§ ì‘ì—…ì—ì„œ í…ŒìŠ¤íŠ¸ ì‹œê°„ ê³„ì‚°ì„ í™•ì¥í•˜ëŠ” ë° íš¨ê³¼ì ì„ì„ ë³´ì—¬ì£¼ì—ˆì§€ë§Œ, ì €ìˆ˜ì¤€ CUDA ì»¤ë„ êµ¬í˜„ ìµœì í™”ì—ëŠ” ì œí•œì ì¸ ê´€ì‹¬ì„ ë‘ê³  ìˆìŠµë‹ˆë‹¤.

- 2. ê¸°ì¡´ ì»¤ë„ ìƒì„± ë²¤ì¹˜ë§ˆí¬ëŠ” ì·¨ì•½ì ì´ ìˆìœ¼ë©°, í…ŒìŠ¤íŠ¸ ì¡°ê±´ì˜ ë‹¤ì–‘ì„±ì´ ë¶€ì¡±í•˜ì—¬ ì¼ë°˜í™” í‰ê°€ì— í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤.

- 3. robust-kbenchë¼ëŠ” ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ë¥¼ ë„ì…í•˜ì—¬ ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì»¤ë„ ì„±ëŠ¥ê³¼ ì •í™•ì„±ì„ ì—„ê²©í•˜ê²Œ í‰ê°€í•©ë‹ˆë‹¤.

- 4. CUDA ì»¤ë„ ë°œê²¬, ê²€ì¦ ë° ìµœì í™”ë¥¼ ìë™í™”í•˜ëŠ” í¬ê´„ì ì¸ ì—ì´ì „í‹± í”„ë ˆì„ì›Œí¬ë¥¼ ì œì‹œí•˜ì—¬, PyTorch ì½”ë“œë¥¼ CUDA ì»¤ë„ë¡œ ë³€í™˜í•˜ê³  ëŸ°íƒ€ì„ì„ ê°œì„ í•©ë‹ˆë‹¤.

- 5. ì œì•ˆëœ ë°©ë²•ì€ robust-kbenchì—ì„œ í‰ê°€ëœ ê²°ê³¼, ì‹¤ì œ ì‘ìš© í”„ë¡œê·¸ë¨ì—ì„œ torch êµ¬í˜„ë³´ë‹¤ ë›°ì–´ë‚œ CUDA ì»¤ë„ì„ ìƒì„±í•˜ë©°, ë‹¤ì–‘í•œ ëŸ°íƒ€ì„ ìµœì í™” ì „ëµì„ í™œìš©í•©ë‹ˆë‹¤.

---

*Generated on 2025-09-19 14:53:13*