---
keywords:
  - Large Language Models
  - Rule-Guided Prompting
  - Oppression Measurement
category: cs.AI
publish_date: 2025-09-19
arxiv_id: 2509.15216
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 21:55:59.156336",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Models",
    "Rule-Guided Prompting",
    "Oppression Measurement"
  ],
  "rejected_keywords": [
    "Systemic Exclusion"
  ],
  "similarity_scores": {
    "Large Language Models": 0.8,
    "Rule-Guided Prompting": 0.72,
    "Oppression Measurement": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->


# Assessing Historical Structural Oppression Worldwide via Rule-Guided Prompting of Large Language Models

**Korean Title:** 전 세계의 역사적 구조적 억압 평가: 대규모 언어 모델의 규칙 기반 프롬프트 사용

## 📋 메타데이터

**Links**: [[digests/daily_digest_20250919|2025-09-19]]   [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Large Language Models|Large Language Models]]
**⚡ Unique Technical**: [[keywords/Rule-Guided Prompting|rule-guided prompting]], [[keywords/Oppression Measurement|oppression measurement]]

## 🔗 유사한 논문
- [[Adding LLMs to the psycholinguistic norming toolbox A practical guide to getting the most out of human ratings]] (85.4% similar)
- [[Forget What You Know about LLMs Evaluations -- LLMs are Like a Chameleon]] (83.9% similar)
- [[Controlling Language Difficulty in Dialogues with Linguistic Features_20250919|Controlling Language Difficulty in Dialogues with Linguistic Features]] (82.7% similar)
- [[Do LLMs Align Human Values Regarding Social Biases_ Judging and Explaining Social Biases with LLMs_20250918|Do LLMs Align Human Values Regarding Social Biases Judging and Explaining Social Biases with LLMs]] (82.5% similar)
- [[A Comprehensive Survey on the Trustworthiness of Large Language Models in Healthcare]] (82.3% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.15216v1 Announce Type: new 
Abstract: Traditional efforts to measure historical structural oppression struggle with cross-national validity due to the unique, locally specified histories of exclusion, colonization, and social status in each country, and often have relied on structured indices that privilege material resources while overlooking lived, identity-based exclusion. We introduce a novel framework for oppression measurement that leverages Large Language Models (LLMs) to generate context-sensitive scores of lived historical disadvantage across diverse geopolitical settings. Using unstructured self-identified ethnicity utterances from a multilingual COVID-19 global study, we design rule-guided prompting strategies that encourage models to produce interpretable, theoretically grounded estimations of oppression. We systematically evaluate these strategies across multiple state-of-the-art LLMs. Our results demonstrate that LLMs, when guided by explicit rules, can capture nuanced forms of identity-based historical oppression within nations. This approach provides a complementary measurement tool that highlights dimensions of systemic exclusion, offering a scalable, cross-cultural lens for understanding how oppression manifests in data-driven research and public health contexts. To support reproducible evaluation, we release an open-sourced benchmark dataset for assessing LLMs on oppression measurement (https://github.com/chattergpt/llm-oppression-benchmark).

## 🔍 Abstract (한글 번역)

arXiv:2509.15216v1 발표 유형: 신규  
초록: 역사적 구조적 억압을 측정하려는 전통적인 노력은 각 국가의 배제, 식민화, 사회적 지위에 대한 고유하고 지역적으로 특정된 역사 때문에 국가 간 타당성을 확보하는 데 어려움을 겪으며, 종종 물질적 자원을 우선시하면서 경험적이고 정체성 기반의 배제를 간과하는 구조화된 지수에 의존해 왔습니다. 우리는 다양한 지정학적 환경에서 경험된 역사적 불이익의 맥락에 민감한 점수를 생성하기 위해 대형 언어 모델(LLM)을 활용하는 새로운 억압 측정 프레임워크를 소개합니다. 다국어 COVID-19 글로벌 연구에서 비구조화된 자가 식별 민족 발화를 사용하여, 모델이 해석 가능하고 이론적으로 근거 있는 억압 추정을 생성하도록 유도하는 규칙 기반 프롬프트 전략을 설계합니다. 우리는 이러한 전략을 여러 최첨단 LLM에 걸쳐 체계적으로 평가합니다. 우리의 결과는 명시적인 규칙에 의해 안내될 때 LLM이 국가 내 정체성 기반의 역사적 억압의 미묘한 형태를 포착할 수 있음을 보여줍니다. 이 접근 방식은 체계적 배제의 차원을 강조하는 보완적인 측정 도구를 제공하여 데이터 기반 연구 및 공중 보건 맥락에서 억압이 어떻게 나타나는지를 이해하기 위한 확장 가능하고 문화 간의 관점을 제공합니다. 재현 가능한 평가를 지원하기 위해, 우리는 억압 측정에 대한 LLM 평가를 위한 오픈 소스 벤치마크 데이터셋을 공개합니다 (https://github.com/chattergpt/llm-oppression-benchmark).

## 📝 요약

이 논문은 전통적인 역사적 억압 측정 방식의 한계를 극복하기 위해 대형 언어 모델(LLMs)을 활용한 새로운 프레임워크를 제안합니다. 각국의 고유한 배제와 식민지화 역사를 반영하기 어려운 기존 방법론 대신, LLMs를 통해 다양한 지정학적 환경에서 맥락에 민감한 억압 점수를 생성합니다. 다국어 COVID-19 연구에서 수집된 비구조화된 자기 식별 민족 발언을 사용하여, 모델이 해석 가능하고 이론적으로 기반을 둔 억압 추정을 생성하도록 유도하는 규칙 기반 프롬프트 전략을 설계했습니다. 여러 최신 LLMs를 통해 이러한 전략을 체계적으로 평가한 결과, 명시적인 규칙에 의해 안내된 LLMs가 국가 내 정체성 기반의 역사적 억압을 세밀하게 포착할 수 있음을 보여주었습니다. 이 접근법은 체계적 배제의 차원을 강조하는 보완적 측정 도구를 제공하며, 데이터 기반 연구와 공중 보건 맥락에서 억압이 어떻게 나타나는지를 이해하는 데 유용한 도구가 될 수 있습니다. 재현 가능한 평가를 지원하기 위해 억압 측정에 대한 LLMs 평가를 위한 오픈 소스 벤치마크 데이터셋도 공개했습니다.

## 🎯 주요 포인트

- 1. 전통적인 역사적 구조적 억압 측정은 각국의 고유한 배제, 식민지화, 사회적 지위의 역사로 인해 국가 간 유효성에 어려움을 겪습니다.

- 2. 우리는 대형 언어 모델(LLMs)을 활용하여 다양한 지정학적 환경에서 경험된 역사적 불이익의 맥락에 민감한 점수를 생성하는 새로운 억압 측정 프레임워크를 소개합니다.

- 3. 다국어 COVID-19 글로벌 연구에서 비구조화된 자가 식별 민족성을 사용하여, 모델이 해석 가능하고 이론적으로 근거 있는 억압 추정을 생성하도록 유도하는 규칙 기반 프롬프트 전략을 설계했습니다.

- 4. 명시적인 규칙에 의해 안내될 때 LLMs가 국가 내에서 정체성 기반의 역사적 억압의 미묘한 형태를 포착할 수 있음을 입증했습니다.

- 5. 우리는 LLMs의 억압 측정을 평가하기 위한 오픈 소스 벤치마크 데이터셋을 공개하여 재현 가능한 평가를 지원합니다.

---

*Generated on 2025-09-19 15:56:13*