
# From Capabilities to Performance: Evaluating Key Functional Properties of LLM Architectures in Penetration Testing

**Korean Title:** 능력에서 성능으로: 침투 테스트에서 LLM 아키텍처의 주요 기능적 속성 평가

## 📋 메타데이터

**Links**: [[daily/2025-09-19|2025-09-19]] [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🔬 Broad Technical**: Large Language Models, Penetration Testing

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.14289v1 Announce Type: new 
Abstract: Large language models (LLMs) are increasingly used to automate or augment penetration testing, but their effectiveness and reliability across attack phases remain unclear. We present a comprehensive evaluation of multiple LLM-based agents, from single-agent to modular designs, across realistic penetration testing scenarios, measuring empirical performance and recurring failure patterns. We also isolate the impact of five core functional capabilities via targeted augmentations: Global Context Memory (GCM), Inter-Agent Messaging (IAM), Context-Conditioned Invocation (CCI), Adaptive Planning (AP), and Real-Time Monitoring (RTM). These interventions support, respectively: (i) context coherence and retention, (ii) inter-component coordination and state management, (iii) tool use accuracy and selective execution, (iv) multi-step strategic planning, error detection, and recovery, and (v) real-time dynamic responsiveness. Our results show that while some architectures natively exhibit subsets of these properties, targeted augmentations substantially improve modular agent performance, especially in complex, multi-step, and real-time penetration testing tasks.

## 🔍 Abstract (한글 번역)

arXiv:2509.14289v1 발표 유형: 신규  
초록: 대형 언어 모델(LLM)은 점점 더 침투 테스트를 자동화하거나 보강하는 데 사용되고 있지만, 공격 단계 전반에 걸친 그들의 효과성과 신뢰성은 여전히 명확하지 않습니다. 우리는 단일 에이전트에서 모듈식 설계에 이르기까지 다양한 LLM 기반 에이전트를 현실적인 침투 테스트 시나리오에서 평가하여 경험적 성능과 반복되는 실패 패턴을 측정합니다. 또한, 다섯 가지 핵심 기능적 역량의 영향을 목표 지향적 보강을 통해 분리합니다: 글로벌 컨텍스트 메모리(GCM), 에이전트 간 메시징(IAM), 컨텍스트 조건 호출(CCI), 적응형 계획(AP), 실시간 모니터링(RTM). 이러한 개입은 각각 다음을 지원합니다: (i) 컨텍스트 일관성과 유지, (ii) 구성 요소 간 조정 및 상태 관리, (iii) 도구 사용 정확성과 선택적 실행, (iv) 다단계 전략 계획, 오류 탐지 및 복구, (v) 실시간 동적 반응성. 우리의 결과는 일부 아키텍처가 본래 이러한 속성의 하위 집합을 보여주지만, 목표 지향적 보강이 특히 복잡하고 다단계 및 실시간 침투 테스트 작업에서 모듈식 에이전트 성능을 상당히 향상시킨다는 것을 보여줍니다.

## 📝 요약

이 논문은 대형 언어 모델(LLM)을 활용한 침투 테스트의 효과와 신뢰성을 평가합니다. 다양한 LLM 기반 에이전트를 단일 및 모듈형 설계로 나누어 현실적인 침투 테스트 시나리오에서 성능을 측정하고 반복적인 실패 패턴을 분석했습니다. 또한, 다섯 가지 핵심 기능인 글로벌 컨텍스트 메모리(GCM), 에이전트 간 메시징(IAM), 컨텍스트 조건 호출(CCI), 적응형 계획(AP), 실시간 모니터링(RTM)의 영향을 분석했습니다. 이러한 기능들은 각각 문맥 일관성, 구성 요소 간 조정, 도구 사용 정확성, 다단계 전략 계획, 실시간 반응성을 지원합니다. 연구 결과, 일부 아키텍처는 이러한 기능을 자연적으로 갖추고 있지만, 목표 지향적 보강을 통해 모듈형 에이전트의 성능이 특히 복잡하고 다단계인 실시간 침투 테스트 작업에서 크게 향상됨을 발견했습니다.

## 🎯 주요 포인트

- 1. 대형 언어 모델(LLM)은 침투 테스트 자동화 및 보조에 점점 더 많이 사용되고 있지만, 공격 단계 전반에 걸친 효과성과 신뢰성은 명확하지 않다.

- 2. 다양한 LLM 기반 에이전트를 현실적인 침투 테스트 시나리오에서 평가하여 성능과 반복적인 실패 패턴을 측정했다.

- 3. 다섯 가지 핵심 기능(GCM, IAM, CCI, AP, RTM)의 영향을 분리하여 각 기능이 성능에 미치는 영향을 분석했다.

- 4. 특정 기능 강화는 모듈형 에이전트의 성능을 크게 향상시켰으며, 특히 복잡하고 다단계 및 실시간 침투 테스트 작업에서 효과적이었다.

- 5. 일부 아키텍처는 본래 이러한 기능의 일부를 가지고 있지만, 기능 강화를 통해 성능이 크게 개선되었다.

---

*Generated on 2025-09-19 18:00:11*