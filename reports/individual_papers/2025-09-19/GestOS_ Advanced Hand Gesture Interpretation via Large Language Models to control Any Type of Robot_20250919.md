
# GestOS: Advanced Hand Gesture Interpretation via Large Language Models to control Any Type of Robot

**Korean Title:** GestOS: 대형 언어 모델을 통한 고급 손동작 해석을 통한 모든 유형의 로봇 제어

## 📋 메타데이터

**Links**: [[daily/2025-09-19|2025-09-19]] [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Adaptive Robot Control

## 🔗 유사한 논문
- [[PhysicalAgent Towards General Cognitive Robotics with Foundation World Models]] (79.9% similar)
- [[VeriOS Query-Driven Proactive Human-Agent-GUI Interaction for Trustworthy OS Agents]] (78.3% similar)
- [[Flexible and Foldable Workspace Analysis and Object Manipulation Using a Soft, Interconnected, Origami-Inspired Actuator Array]] (78.1% similar)
- [[GAF Gaussian Action Field as a Dynamic World Model for Robotic Manipulation]] (78.1% similar)
- [[Humanoid Agent via Embodied Chain-of-Action Reasoning with Multimodal Foundation Models for Zero-Shot Loco-Manipulation_20250918|Humanoid Agent via Embodied Chain-of-Action Reasoning with Multimodal Foundation Models for Zero-Shot Loco-Manipulation]] (78.1% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.14412v1 Announce Type: new 
Abstract: We present GestOS, a gesture-based operating system for high-level control of heterogeneous robot teams. Unlike prior systems that map gestures to fixed commands or single-agent actions, GestOS interprets hand gestures semantically and dynamically distributes tasks across multiple robots based on their capabilities, current state, and supported instruction sets. The system combines lightweight visual perception with large language model (LLM) reasoning: hand poses are converted into structured textual descriptions, which the LLM uses to infer intent and generate robot-specific commands. A robot selection module ensures that each gesture-triggered task is matched to the most suitable agent in real time. This architecture enables context-aware, adaptive control without requiring explicit user specification of targets or commands. By advancing gesture interaction from recognition to intelligent orchestration, GestOS supports scalable, flexible, and user-friendly collaboration with robotic systems in dynamic environments.

## 🔍 Abstract (한글 번역)

arXiv:2509.14412v1 발표 유형: 신규  
초록: 우리는 이질적인 로봇 팀의 고급 제어를 위한 제스처 기반 운영 체제인 GestOS를 소개합니다. 이전 시스템이 제스처를 고정된 명령이나 단일 에이전트 동작에 매핑하는 것과 달리, GestOS는 손 제스처를 의미적으로 해석하고 로봇의 능력, 현재 상태 및 지원되는 명령 세트에 따라 여러 로봇에 작업을 동적으로 분배합니다. 이 시스템은 경량의 시각적 인식과 대형 언어 모델(LLM) 추론을 결합합니다: 손 자세는 구조화된 텍스트 설명으로 변환되며, LLM은 이를 사용하여 의도를 추론하고 로봇별 명령을 생성합니다. 로봇 선택 모듈은 각 제스처로 촉발된 작업이 실시간으로 가장 적합한 에이전트에 매칭되도록 보장합니다. 이 아키텍처는 사용자가 명시적으로 목표나 명령을 지정할 필요 없이 상황 인식적이고 적응적인 제어를 가능하게 합니다. 제스처 상호작용을 인식에서 지능적 조정으로 발전시킴으로써, GestOS는 동적 환경에서 로봇 시스템과의 확장 가능하고 유연하며 사용자 친화적인 협업을 지원합니다.

## 📝 요약

GestOS는 이기종 로봇 팀의 고급 제어를 위한 제스처 기반 운영 체제로, 기존 시스템과 달리 제스처를 고정 명령이나 단일 에이전트 작업에 매핑하지 않고, 로봇의 능력, 현재 상태, 지원되는 명령 세트를 기반으로 작업을 동적으로 분배합니다. 경량 시각 인식과 대형 언어 모델(LLM) 추론을 결합하여 손 제스처를 구조화된 텍스트로 변환하고, LLM이 이를 해석해 로봇별 명령을 생성합니다. 로봇 선택 모듈은 각 제스처로 촉발된 작업을 실시간으로 가장 적합한 에이전트와 매칭합니다. 이 아키텍처는 명시적인 사용자 지정 없이도 상황 인식과 적응형 제어를 가능하게 하여, 동적 환경에서 로봇 시스템과의 확장 가능하고 유연하며 사용자 친화적인 협업을 지원합니다.

## 🎯 주요 포인트

- 1. GestOS는 이기종 로봇 팀의 고급 제어를 위한 제스처 기반 운영 체제입니다.

- 2. GestOS는 손 제스처를 의미적으로 해석하고 여러 로봇에 작업을 동적으로 분배합니다.

- 3. 시스템은 경량의 시각적 인식과 대형 언어 모델(LLM) 추론을 결합하여 제스처를 로봇 명령으로 변환합니다.

- 4. 로봇 선택 모듈은 각 제스처로 유발된 작업이 실시간으로 가장 적합한 에이전트에 매칭되도록 보장합니다.

- 5. GestOS는 인식에서 지능적 조율로 제스처 상호작용을 발전시켜, 동적 환경에서 로봇 시스템과의 유연하고 사용자 친화적인 협업을 지원합니다.

---

*Generated on 2025-09-19 16:29:47*