---
keywords:
  - Large Language Models
  - Few-Shot Learning
  - Toxicity Detection
category: cs.AI
publish_date: 2025-09-19
arxiv_id: 2509.15174
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 21:26:25.139031",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Models",
    "Few-Shot Learning",
    "Toxicity Detection"
  ],
  "rejected_keywords": [
    "Explainable Content Moderation"
  ],
  "similarity_scores": {
    "Large Language Models": 0.8,
    "Few-Shot Learning": 0.78,
    "Toxicity Detection": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->


# SMARTER: A Data-efficient Framework to Improve Toxicity Detection with Explanation via Self-augmenting Large Language Models

**Korean Title:** SMARTER: ìê¸° ì¦ê°• ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì„ í†µí•œ ì„¤ëª…ê³¼ í•¨ê»˜ ë…ì„± íƒì§€ë¥¼ ê°œì„ í•˜ê¸° ìœ„í•œ ë°ì´í„° íš¨ìœ¨ì  í”„ë ˆì„ì›Œí¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[digests/daily_digest_20250919|2025-09-19]]   [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Large Language Models|Large Language Models]], [[keywords/Few-Shot Learning|Few-Shot Learning]]
**âš¡ Unique Technical**: [[keywords/Toxicity Detection|Toxicity Detection]]

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[Forget What You Know about LLMs Evaluations -- LLMs are Like a Chameleon]] (82.8% similar)
- [[Internalizing Self-Consistency in Language Models Multi-Agent Consensus Alignment]] (82.7% similar)
- [[LLM-I LLMs are Naturally Interleaved Multimodal Creators]] (82.4% similar)
- [[DetectAnyLLM Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models]] (82.2% similar)
- [[Opening the Black Box Interpretable LLMs via Semantic Resonance Architecture]] (82.2% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15174v1 Announce Type: cross 
Abstract: WARNING: This paper contains examples of offensive materials. Toxic content has become pervasive on social media platforms. We introduce SMARTER, a data-efficient two-stage framework for explainable content moderation using Large Language Models (LLMs). In Stage 1, we leverage LLMs' own outputs to generate synthetic explanations for both correct and incorrect labels, enabling alignment via preference optimization with minimal human supervision. In Stage 2, we refine explanation quality through cross-model training, allowing weaker models to align stylistically and semantically with stronger ones. Experiments on three benchmark tasks -- HateXplain, Latent Hate, and Implicit Hate -- demonstrate that SMARTER enables LLMs to achieve up to a 13.5% macro-F1 improvement over standard few-shot baselines while using only a fraction of the full training data. Our framework offers a scalable strategy for low-resource settings by harnessing LLMs' self-improving capabilities for both classification and explanation.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15174v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ê²½ê³ : ì´ ë…¼ë¬¸ì€ ê³µê²©ì ì¸ ìë£Œì˜ ì˜ˆì‹œë¥¼ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì†Œì…œ ë¯¸ë””ì–´ í”Œë«í¼ì—ì„œ ìœ í•´í•œ ì½˜í…ì¸ ê°€ ë§Œì—°í•´ì§€ê³  ìˆìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì„ ì‚¬ìš©í•˜ì—¬ ì„¤ëª… ê°€ëŠ¥í•œ ì½˜í…ì¸  ê´€ë¦¬ë¥¼ ìœ„í•œ ë°ì´í„° íš¨ìœ¨ì ì¸ 2ë‹¨ê³„ í”„ë ˆì„ì›Œí¬ì¸ SMARTERë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. 1ë‹¨ê³„ì—ì„œëŠ” LLMì˜ ìì²´ ì¶œë ¥ì„ í™œìš©í•˜ì—¬ ì˜¬ë°”ë¥¸ ë ˆì´ë¸”ê³¼ ì˜ëª»ëœ ë ˆì´ë¸” ëª¨ë‘ì— ëŒ€í•œ í•©ì„± ì„¤ëª…ì„ ìƒì„±í•˜ê³ , ìµœì†Œí•œì˜ ì¸ê°„ ê°ë…ìœ¼ë¡œ ì„ í˜¸ ìµœì í™”ë¥¼ í†µí•´ ì •ë ¬ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. 2ë‹¨ê³„ì—ì„œëŠ” êµì°¨ ëª¨ë¸ í›ˆë ¨ì„ í†µí•´ ì„¤ëª…ì˜ í’ˆì§ˆì„ ê°œì„ í•˜ì—¬ ì•½í•œ ëª¨ë¸ë“¤ì´ ê°•í•œ ëª¨ë¸ë“¤ê³¼ ìŠ¤íƒ€ì¼ ë° ì˜ë¯¸ì ìœ¼ë¡œ ì •ë ¬ë  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. HateXplain, Latent Hate, Implicit Hateë¼ëŠ” ì„¸ ê°€ì§€ ë²¤ì¹˜ë§ˆí¬ ì‘ì—…ì— ëŒ€í•œ ì‹¤í—˜ì€ SMARTERê°€ ì „ì²´ í›ˆë ¨ ë°ì´í„°ì˜ ì¼ë¶€ë§Œ ì‚¬ìš©í•˜ë©´ì„œë„ í‘œì¤€ ì†Œìˆ˜ ìƒ· ê¸°ì¤€ì„ ì— ë¹„í•´ ìµœëŒ€ 13.5%ì˜ ë§¤í¬ë¡œ-F1 í–¥ìƒì„ LLMì´ ë‹¬ì„±í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ìš°ë¦¬ì˜ í”„ë ˆì„ì›Œí¬ëŠ” LLMì˜ ìì²´ ê°œì„  ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ ë¶„ë¥˜ì™€ ì„¤ëª… ëª¨ë‘ì— ëŒ€í•´ ì €ìì› í™˜ê²½ì—ì„œ í™•ì¥ ê°€ëŠ¥í•œ ì „ëµì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì†Œì…œ ë¯¸ë””ì–´ì˜ ìœ í•´ ì½˜í…ì¸  ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ SMARTERë¼ëŠ” ë°ì´í„° íš¨ìœ¨ì ì¸ ë‘ ë‹¨ê³„ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì²« ë²ˆì§¸ ë‹¨ê³„ì—ì„œëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì¶œë ¥ì„ í™œìš©í•´ ì˜¬ë°”ë¥¸ ë° ì˜ëª»ëœ ë ˆì´ë¸”ì— ëŒ€í•œ ì„¤ëª…ì„ ìƒì„±í•˜ê³ , ìµœì†Œí•œì˜ ì¸ê°„ ê°ë…ìœ¼ë¡œ ì„ í˜¸ ìµœì í™”ë¥¼ í†µí•´ ì •ë ¬í•©ë‹ˆë‹¤. ë‘ ë²ˆì§¸ ë‹¨ê³„ì—ì„œëŠ” êµì°¨ ëª¨ë¸ í•™ìŠµì„ í†µí•´ ì„¤ëª…ì˜ ì§ˆì„ ê°œì„ í•˜ì—¬ ì•½í•œ ëª¨ë¸ì´ ê°•í•œ ëª¨ë¸ê³¼ ìŠ¤íƒ€ì¼ ë° ì˜ë¯¸ì ìœ¼ë¡œ ì •ë ¬ë˜ë„ë¡ í•©ë‹ˆë‹¤. HateXplain, Latent Hate, Implicit Hate ë“± ì„¸ ê°€ì§€ ë²¤ì¹˜ë§ˆí¬ ê³¼ì œì—ì„œ ì‹¤í—˜í•œ ê²°ê³¼, SMARTERëŠ” ì „ì²´ í›ˆë ¨ ë°ì´í„°ì˜ ì¼ë¶€ë§Œ ì‚¬ìš©í•˜ë©´ì„œë„ í‘œì¤€ ëª‡ ìƒ· ê¸°ì¤€ë³´ë‹¤ ìµœëŒ€ 13.5% ë†’ì€ ë§¤í¬ë¡œ F1 ì ìˆ˜ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” LLMì˜ ìê¸° ê°œì„  ëŠ¥ë ¥ì„ í™œìš©í•˜ì—¬ ì €ìì› í™˜ê²½ì—ì„œ ë¶„ë¥˜ì™€ ì„¤ëª…ì„ ìœ„í•œ í™•ì¥ ê°€ëŠ¥í•œ ì „ëµì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. SMARTERëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì„ í™œìš©í•œ ì„¤ëª… ê°€ëŠ¥í•œ ì½˜í…ì¸  ì¡°ì ˆì„ ìœ„í•œ ë°ì´í„° íš¨ìœ¨ì ì¸ ë‘ ë‹¨ê³„ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.

- 2. 1ë‹¨ê³„ì—ì„œëŠ” LLMsì˜ ì¶œë ¥ì„ í™œìš©í•˜ì—¬ ì˜¬ë°”ë¥¸ ë° ì˜ëª»ëœ ë ˆì´ë¸”ì— ëŒ€í•œ í•©ì„± ì„¤ëª…ì„ ìƒì„±í•˜ê³ , ìµœì†Œí•œì˜ ì¸ê°„ ê°ë…ìœ¼ë¡œ ì„ í˜¸ ìµœì í™”ë¥¼ í†µí•´ ì •ë ¬ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.

- 3. 2ë‹¨ê³„ì—ì„œëŠ” êµì°¨ ëª¨ë¸ í›ˆë ¨ì„ í†µí•´ ì„¤ëª…ì˜ ì§ˆì„ í–¥ìƒì‹œì¼œ, ì•½í•œ ëª¨ë¸ì´ ê°•í•œ ëª¨ë¸ê³¼ ìŠ¤íƒ€ì¼ ë° ì˜ë¯¸ì ìœ¼ë¡œ ì •ë ¬ë˜ë„ë¡ í•©ë‹ˆë‹¤.

- 4. SMARTERëŠ” HateXplain, Latent Hate, Implicit Hate ë“±ì˜ ì„¸ ê°€ì§€ ë²¤ì¹˜ë§ˆí¬ ì‘ì—…ì—ì„œ í‘œì¤€ ëª‡ ìƒ· ê¸°ì¤€ë³´ë‹¤ ìµœëŒ€ 13.5%ì˜ ë§¤í¬ë¡œ-F1 í–¥ìƒì„ ë‹¬ì„±í•˜ë©°, ì „ì²´ í›ˆë ¨ ë°ì´í„°ì˜ ì¼ë¶€ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.

- 5. ì´ í”„ë ˆì„ì›Œí¬ëŠ” LLMsì˜ ìê¸° ê°œì„  ëŠ¥ë ¥ì„ í™œìš©í•˜ì—¬ ë¶„ë¥˜ ë° ì„¤ëª… ëª¨ë‘ì—ì„œ ì €ìì› í™˜ê²½ì— ëŒ€í•œ í™•ì¥ ê°€ëŠ¥í•œ ì „ëµì„ ì œê³µí•©ë‹ˆë‹¤.

---

*Generated on 2025-09-19 15:07:54*