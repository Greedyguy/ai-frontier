---
keywords:
  - Gene Regulatory Networks
  - Large Language Models
  - Foundation Models
category: cs.AI
publish_date: 2025-09-19
arxiv_id: 2509.14723
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 21:20:17.479155",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Gene Regulatory Networks",
    "Large Language Models",
    "Foundation Models"
  ],
  "rejected_keywords": [
    "Transcoders"
  ],
  "similarity_scores": {
    "Gene Regulatory Networks": 0.78,
    "Large Language Models": 0.82,
    "Foundation Models": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->


# Transcoder-based Circuit Analysis for Interpretable Single-Cell Foundation Models

**Korean Title:** íŠ¸ëœìŠ¤ì½”ë” ê¸°ë°˜ íšŒë¡œ ë¶„ì„ì„ í†µí•œ í•´ì„ ê°€ëŠ¥í•œ ë‹¨ì¼ ì„¸í¬ ê¸°ì´ˆ ëª¨ë¸ ì—°êµ¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[digests/daily_digest_20250919|2025-09-19]]   [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Large Language Models|Large Language Models]]
**âš¡ Unique Technical**: [[keywords/Gene Regulatory Networks|gene regulatory networks]]
**ğŸš€ Evolved Concepts**: [[keywords/Foundation Models|Single-cell foundation models]]

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[From Correction to Mastery Reinforced Distillation of Large Language Model Agents]] (77.8% similar)
- [[TICL Text-Embedding KNN For Speech In-Context Learning Unlocks Speech Recognition Abilities of Large Multimodal Models]] (77.3% similar)
- [[Opening the Black Box Interpretable LLMs via Semantic Resonance Architecture]] (76.9% similar)
- [[Modular Machine Learning An Indispensable Path towards New-Generation Large Language Models]] (76.7% similar)
- [[(P)rior(D)yna(F)low A Priori Dynamic Workflow Construction via Multi-Agent Collaboration]] (76.6% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.14723v1 Announce Type: new 
Abstract: Single-cell foundation models (scFMs) have demonstrated state-of-the-art performance on various tasks, such as cell-type annotation and perturbation response prediction, by learning gene regulatory networks from large-scale transcriptome data. However, a significant challenge remains: the decision-making processes of these models are less interpretable compared to traditional methods like differential gene expression analysis. Recently, transcoders have emerged as a promising approach for extracting interpretable decision circuits from large language models (LLMs). In this work, we train a transcoder on the cell2sentence (C2S) model, a state-of-the-art scFM. By leveraging the trained transcoder, we extract internal decision-making circuits from the C2S model. We demonstrate that the discovered circuits correspond to real-world biological mechanisms, confirming the potential of transcoders to uncover biologically plausible pathways within complex single-cell models.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.14723v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: ë‹¨ì¼ ì„¸í¬ ê¸°ì´ˆ ëª¨ë¸(scfM)ì€ ëŒ€ê·œëª¨ ì „ì‚¬ì²´ ë°ì´í„°ë¥¼ í†µí•´ ìœ ì „ì ì¡°ì ˆ ë„¤íŠ¸ì›Œí¬ë¥¼ í•™ìŠµí•¨ìœ¼ë¡œì¨ ì„¸í¬ ìœ í˜• ì£¼ì„ ë° êµë€ ë°˜ì‘ ì˜ˆì¸¡ê³¼ ê°™ì€ ë‹¤ì–‘í•œ ì‘ì—…ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ëŸ¬í•œ ëª¨ë¸ì˜ ì˜ì‚¬ ê²°ì • ê³¼ì •ì€ ì°¨ë“± ìœ ì „ì ë°œí˜„ ë¶„ì„ê³¼ ê°™ì€ ì „í†µì ì¸ ë°©ë²•ì— ë¹„í•´ í•´ì„ ê°€ëŠ¥ì„±ì´ ë‚®ë‹¤ëŠ” ì¤‘ìš”í•œ ê³¼ì œê°€ ë‚¨ì•„ ìˆìŠµë‹ˆë‹¤. ìµœê·¼ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì—ì„œ í•´ì„ ê°€ëŠ¥í•œ ì˜ì‚¬ ê²°ì • íšŒë¡œë¥¼ ì¶”ì¶œí•˜ê¸° ìœ„í•œ ìœ ë§í•œ ì ‘ê·¼ë²•ìœ¼ë¡œ íŠ¸ëœìŠ¤ì½”ë”ê°€ ë“±ì¥í–ˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ì—ì„œëŠ” ìµœì²¨ë‹¨ scFMì¸ cell2sentence(C2S) ëª¨ë¸ì—ì„œ íŠ¸ëœìŠ¤ì½”ë”ë¥¼ í›ˆë ¨í•©ë‹ˆë‹¤. í›ˆë ¨ëœ íŠ¸ëœìŠ¤ì½”ë”ë¥¼ í™œìš©í•˜ì—¬ C2S ëª¨ë¸ì˜ ë‚´ë¶€ ì˜ì‚¬ ê²°ì • íšŒë¡œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. ë°œê²¬ëœ íšŒë¡œê°€ ì‹¤ì œ ìƒë¬¼í•™ì  ë©”ì»¤ë‹ˆì¦˜ì— í•´ë‹¹í•œë‹¤ëŠ” ê²ƒì„ ì…ì¦í•¨ìœ¼ë¡œì¨, íŠ¸ëœìŠ¤ì½”ë”ê°€ ë³µì¡í•œ ë‹¨ì¼ ì„¸í¬ ëª¨ë¸ ë‚´ì—ì„œ ìƒë¬¼í•™ì ìœ¼ë¡œ íƒ€ë‹¹í•œ ê²½ë¡œë¥¼ ë°œê²¬í•  ìˆ˜ ìˆëŠ” ì ì¬ë ¥ì„ í™•ì¸í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë‹¨ì¼ ì„¸í¬ ê¸°ì´ˆ ëª¨ë¸(scFMs)ì˜ í•´ì„ ê°€ëŠ¥ì„±ì„ ë†’ì´ê¸° ìœ„í•´ íŠ¸ëœìŠ¤ì½”ë”ë¥¼ í™œìš©í•œ ì—°êµ¬ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. scFMsëŠ” ëŒ€ê·œëª¨ ì „ì‚¬ì²´ ë°ì´í„°ë¥¼ í†µí•´ ì„¸í¬ ìœ í˜• ì£¼ì„ ë° ë³€í˜• ë°˜ì‘ ì˜ˆì¸¡ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì´ë‚˜, ê¸°ì¡´ ë°©ë²•ì— ë¹„í•´ ì˜ì‚¬ê²°ì • ê³¼ì •ì˜ í•´ì„ì´ ì–´ë ¤ìš´ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ì €ìë“¤ì€ ìµœì‹  scFMì¸ cell2sentence(C2S) ëª¨ë¸ì— íŠ¸ëœìŠ¤ì½”ë”ë¥¼ í›ˆë ¨ì‹œì¼œ, ëª¨ë¸ì˜ ë‚´ë¶€ ì˜ì‚¬ê²°ì • íšŒë¡œë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤. ì´ íšŒë¡œê°€ ì‹¤ì œ ìƒë¬¼í•™ì  ë©”ì»¤ë‹ˆì¦˜ê³¼ ì¼ì¹˜í•¨ì„ ë³´ì—¬ì£¼ì–´, ë³µì¡í•œ ë‹¨ì¼ ì„¸í¬ ëª¨ë¸ ë‚´ì—ì„œ ìƒë¬¼í•™ì ìœ¼ë¡œ íƒ€ë‹¹í•œ ê²½ë¡œë¥¼ ë°œê²¬í•  ìˆ˜ ìˆëŠ” íŠ¸ëœìŠ¤ì½”ë”ì˜ ì ì¬ë ¥ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë‹¨ì¼ ì„¸í¬ ê¸°ë°˜ ëª¨ë¸(scFMs)ì€ ëŒ€ê·œëª¨ ì „ì‚¬ì²´ ë°ì´í„°ë¥¼ í†µí•´ ìœ ì „ì ì¡°ì ˆ ë„¤íŠ¸ì›Œí¬ë¥¼ í•™ìŠµí•˜ì—¬ ì„¸í¬ ìœ í˜• ì£¼ì„ ë° ë³€ì´ ë°˜ì‘ ì˜ˆì¸¡ ë“±ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤.

- 2. ì´ëŸ¬í•œ ëª¨ë¸ì˜ ê²°ì • ê³¼ì •ì€ ì „í†µì ì¸ ë°©ë²•ì— ë¹„í•´ í•´ì„ ê°€ëŠ¥ì„±ì´ ë‚®ë‹¤ëŠ” ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.

- 3. íŠ¸ëœìŠ¤ì½”ë”ëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì—ì„œ í•´ì„ ê°€ëŠ¥í•œ ê²°ì • íšŒë¡œë¥¼ ì¶”ì¶œí•˜ëŠ” ìœ ë§í•œ ì ‘ê·¼ë²•ìœ¼ë¡œ ë“±ì¥í–ˆìŠµë‹ˆë‹¤.

- 4. ë³¸ ì—°êµ¬ì—ì„œëŠ” C2S ëª¨ë¸ì´ë¼ëŠ” ìµœì²¨ë‹¨ scFMì— íŠ¸ëœìŠ¤ì½”ë”ë¥¼ í›ˆë ¨ì‹œì¼œ ë‚´ë¶€ ê²°ì • íšŒë¡œë¥¼ ì¶”ì¶œí•˜ì˜€ìŠµë‹ˆë‹¤.

- 5. ë°œê²¬ëœ íšŒë¡œê°€ ì‹¤ì œ ìƒë¬¼í•™ì  ë©”ì»¤ë‹ˆì¦˜ê³¼ ì¼ì¹˜í•¨ì„ ë³´ì—¬ì£¼ì–´, íŠ¸ëœìŠ¤ì½”ë”ê°€ ë³µì¡í•œ ë‹¨ì¼ ì„¸í¬ ëª¨ë¸ ë‚´ ìƒë¬¼í•™ì ìœ¼ë¡œ íƒ€ë‹¹í•œ ê²½ë¡œë¥¼ ë°œê²¬í•  ê°€ëŠ¥ì„±ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.

---

*Generated on 2025-09-19 15:26:47*