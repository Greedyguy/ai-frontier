---
keywords:
  - Gene Regulatory Networks
  - Large Language Models
  - Foundation Models
category: cs.AI
publish_date: 2025-09-19
arxiv_id: 2509.14723
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 21:20:17.479155",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Gene Regulatory Networks",
    "Large Language Models",
    "Foundation Models"
  ],
  "rejected_keywords": [
    "Transcoders"
  ],
  "similarity_scores": {
    "Gene Regulatory Networks": 0.78,
    "Large Language Models": 0.82,
    "Foundation Models": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->


# Transcoder-based Circuit Analysis for Interpretable Single-Cell Foundation Models

**Korean Title:** 트랜스코더 기반 회로 분석을 통한 해석 가능한 단일 세포 기초 모델 연구

## 📋 메타데이터

**Links**: [[digests/daily_digest_20250919|2025-09-19]]   [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Large Language Models|Large Language Models]]
**⚡ Unique Technical**: [[keywords/Gene Regulatory Networks|gene regulatory networks]]
**🚀 Evolved Concepts**: [[keywords/Foundation Models|Single-cell foundation models]]

## 🔗 유사한 논문
- [[From Correction to Mastery Reinforced Distillation of Large Language Model Agents]] (77.8% similar)
- [[TICL Text-Embedding KNN For Speech In-Context Learning Unlocks Speech Recognition Abilities of Large Multimodal Models]] (77.3% similar)
- [[Opening the Black Box Interpretable LLMs via Semantic Resonance Architecture]] (76.9% similar)
- [[Modular Machine Learning An Indispensable Path towards New-Generation Large Language Models]] (76.7% similar)
- [[(P)rior(D)yna(F)low A Priori Dynamic Workflow Construction via Multi-Agent Collaboration]] (76.6% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.14723v1 Announce Type: new 
Abstract: Single-cell foundation models (scFMs) have demonstrated state-of-the-art performance on various tasks, such as cell-type annotation and perturbation response prediction, by learning gene regulatory networks from large-scale transcriptome data. However, a significant challenge remains: the decision-making processes of these models are less interpretable compared to traditional methods like differential gene expression analysis. Recently, transcoders have emerged as a promising approach for extracting interpretable decision circuits from large language models (LLMs). In this work, we train a transcoder on the cell2sentence (C2S) model, a state-of-the-art scFM. By leveraging the trained transcoder, we extract internal decision-making circuits from the C2S model. We demonstrate that the discovered circuits correspond to real-world biological mechanisms, confirming the potential of transcoders to uncover biologically plausible pathways within complex single-cell models.

## 🔍 Abstract (한글 번역)

arXiv:2509.14723v1 발표 유형: 신규  
초록: 단일 세포 기초 모델(scfM)은 대규모 전사체 데이터를 통해 유전자 조절 네트워크를 학습함으로써 세포 유형 주석 및 교란 반응 예측과 같은 다양한 작업에서 최첨단 성능을 보여주었습니다. 그러나 이러한 모델의 의사 결정 과정은 차등 유전자 발현 분석과 같은 전통적인 방법에 비해 해석 가능성이 낮다는 중요한 과제가 남아 있습니다. 최근 대규모 언어 모델(LLM)에서 해석 가능한 의사 결정 회로를 추출하기 위한 유망한 접근법으로 트랜스코더가 등장했습니다. 이 연구에서는 최첨단 scFM인 cell2sentence(C2S) 모델에서 트랜스코더를 훈련합니다. 훈련된 트랜스코더를 활용하여 C2S 모델의 내부 의사 결정 회로를 추출합니다. 발견된 회로가 실제 생물학적 메커니즘에 해당한다는 것을 입증함으로써, 트랜스코더가 복잡한 단일 세포 모델 내에서 생물학적으로 타당한 경로를 발견할 수 있는 잠재력을 확인합니다.

## 📝 요약

이 논문은 단일 세포 기초 모델(scFMs)의 해석 가능성을 높이기 위해 트랜스코더를 활용한 연구를 다룹니다. scFMs는 대규모 전사체 데이터를 통해 세포 유형 주석 및 변형 반응 예측에서 뛰어난 성능을 보이나, 기존 방법에 비해 의사결정 과정의 해석이 어려운 문제가 있습니다. 저자들은 최신 scFM인 cell2sentence(C2S) 모델에 트랜스코더를 훈련시켜, 모델의 내부 의사결정 회로를 추출했습니다. 이 회로가 실제 생물학적 메커니즘과 일치함을 보여주어, 복잡한 단일 세포 모델 내에서 생물학적으로 타당한 경로를 발견할 수 있는 트랜스코더의 잠재력을 입증했습니다.

## 🎯 주요 포인트

- 1. 단일 세포 기반 모델(scFMs)은 대규모 전사체 데이터를 통해 유전자 조절 네트워크를 학습하여 세포 유형 주석 및 변이 반응 예측 등에서 최첨단 성능을 보여주고 있습니다.

- 2. 이러한 모델의 결정 과정은 전통적인 방법에 비해 해석 가능성이 낮다는 문제가 있습니다.

- 3. 트랜스코더는 대형 언어 모델(LLMs)에서 해석 가능한 결정 회로를 추출하는 유망한 접근법으로 등장했습니다.

- 4. 본 연구에서는 C2S 모델이라는 최첨단 scFM에 트랜스코더를 훈련시켜 내부 결정 회로를 추출하였습니다.

- 5. 발견된 회로가 실제 생물학적 메커니즘과 일치함을 보여주어, 트랜스코더가 복잡한 단일 세포 모델 내 생물학적으로 타당한 경로를 발견할 가능성을 확인했습니다.

---

*Generated on 2025-09-19 15:26:47*