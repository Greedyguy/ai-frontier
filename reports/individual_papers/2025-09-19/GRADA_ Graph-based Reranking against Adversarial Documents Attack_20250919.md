
# GRADA: Graph-based Reranking against Adversarial Documents Attack

**Korean Title:** GRADA: 적대적 문서 공격에 대한 그래프 기반 재정렬

## 📋 메타데이터

**Links**: [[daily/2025-09-19|2025-09-19]] [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Adversarial Document Attacks

## 🔗 유사한 논문
- [[Enhancing_Retrieval_Augmentation_via_Adversarial_Collaboration_20250919|Enhancing Retrieval Augmentation via Adversarial Collaboration]] (87.9% similar)
- [[Adversarial_Distilled_Retrieval-Augmented_Guarding_Model_for_Online_Malicious_Intent_Detection_20250919|Adversarial Distilled Retrieval-Augmented Guarding Model for Online Malicious Intent Detection]] (85.6% similar)
- [[Evaluating_and_Improving_the_Robustness_of_Security_Attack_Detectors_Generated_by_LLMs_20250918|Evaluating and Improving the Robustness of Security Attack Detectors Generated by LLMs]] (84.2% similar)
- [[KBM Delineating Knowledge Boundary for Adaptive Retrieval in Large Language Models]] (83.1% similar)
- [[Who Taught the Lie Responsibility Attribution for Poisoned Knowledge in Retrieval-Augmented Generation]] (82.6% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2505.07546v3 Announce Type: replace-cross 
Abstract: Retrieval Augmented Generation (RAG) frameworks improve the accuracy of large language models (LLMs) by integrating external knowledge from retrieved documents, thereby overcoming the limitations of models' static intrinsic knowledge. However, these systems are susceptible to adversarial attacks that manipulate the retrieval process by introducing documents that are adversarial yet semantically similar to the query. Notably, while these adversarial documents resemble the query, they exhibit weak similarity to benign documents in the retrieval set. Thus, we propose a simple yet effective Graph-based Reranking against Adversarial Document Attacks (GRADA) framework aiming at preserving retrieval quality while significantly reducing the success of adversaries. Our study evaluates the effectiveness of our approach through experiments conducted on five LLMs: GPT-3.5-Turbo, GPT-4o, Llama3.1-8b, Llama3.1-70b, and Qwen2.5-7b. We use three datasets to assess performance, with results from the Natural Questions dataset demonstrating up to an 80% reduction in attack success rates while maintaining minimal loss in accuracy.

## 🔍 Abstract (한글 번역)

arXiv:2505.07546v3 발표 유형: 교체-교차  
초록: 검색 증강 생성(Retrieval Augmented Generation, RAG) 프레임워크는 검색된 문서로부터 외부 지식을 통합하여 대형 언어 모델(LLM)의 정확성을 향상시킴으로써 모델의 고정된 내재적 지식의 한계를 극복합니다. 그러나 이러한 시스템은 쿼리와 의미적으로 유사하지만 적대적인 문서를 도입하여 검색 과정을 조작하는 적대적 공격에 취약합니다. 특히, 이러한 적대적 문서는 쿼리와 유사하지만, 검색 집합 내의 정상 문서와는 약한 유사성을 보입니다. 따라서 우리는 검색 품질을 유지하면서 적대자의 성공을 크게 줄이기 위한 간단하지만 효과적인 적대적 문서 공격에 대한 그래프 기반 재정렬(GRADA) 프레임워크를 제안합니다. 본 연구는 GPT-3.5-Turbo, GPT-4o, Llama3.1-8b, Llama3.1-70b, Qwen2.5-7b의 다섯 가지 LLM을 대상으로 실험을 통해 접근 방식의 효과를 평가합니다. 성능 평가를 위해 세 가지 데이터셋을 사용하며, Natural Questions 데이터셋의 결과는 정확도의 최소 손실을 유지하면서 공격 성공률이 최대 80% 감소함을 보여줍니다.

## 📝 요약

이 논문은 검색 기반 생성(RAG) 프레임워크의 취약점을 개선하기 위해 GRADA라는 그래프 기반 재정렬 방법을 제안합니다. RAG는 외부 문서의 정보를 활용하여 대형 언어 모델(LLM)의 정확성을 높이지만, 적대적 공격에 취약합니다. GRADA는 적대적 문서 공격을 효과적으로 방어하면서 검색 품질을 유지합니다. 실험 결과, Natural Questions 데이터셋에서 공격 성공률을 최대 80%까지 줄이면서도 정확도 손실을 최소화하는 성과를 보였습니다. 이 연구는 GPT-3.5-Turbo, GPT-4o, Llama3.1-8b 등 5개의 LLM을 대상으로 수행되었습니다.

## 🎯 주요 포인트

- 1. Retrieval Augmented Generation (RAG) 프레임워크는 외부 지식을 통합하여 대형 언어 모델의 정확성을 향상시킵니다.

- 2. RAG 시스템은 쿼리와 유사하지만 악의적인 문서를 도입하여 검색 과정을 조작하는 적대적 공격에 취약합니다.

- 3. GRADA(그래프 기반 재랭킹) 프레임워크는 검색 품질을 유지하면서 적대적 공격의 성공률을 크게 줄입니다.

- 4. GRADA의 효과는 GPT-3.5-Turbo, GPT-4o, Llama3.1-8b, Llama3.1-70b, Qwen2.5-7b 등 5개의 LLM을 통해 평가되었습니다.

- 5. Natural Questions 데이터셋 실험 결과, 공격 성공률이 최대 80% 감소하면서도 정확성 손실은 최소화되었습니다.

---

*Generated on 2025-09-19 15:14:35*