
# Hierarchical Federated Learning for Social Network with Mobility

**Korean Title:** ëª¨ë¹Œë¦¬í‹°ë¥¼ ê³ ë ¤í•œ ì†Œì…œ ë„¤íŠ¸ì›Œí¬ì˜ ê³„ì¸µì  ì—°í•© í•™ìŠµ

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-19|2025-09-19]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Dynamic Optimization in Social Network with Mobility

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[FedDiverse Tackling Data Heterogeneity in Federated Learning with Diversity-Driven Client Selection]] (81.8% similar)
- [[FedAVOT Exact Distribution Alignment in Federated Learning via Masked Optimal Transport]] (81.5% similar)
- [[Data-Driven_Distributed_Optimization_via_Aggregative_Tracking_and_Deep-Learning_20250918|Data-Driven Distributed Optimization via Aggregative Tracking and Deep-Learning]] (81.1% similar)
- [[RF-LSCM Pushing Radiance Fields to Multi-Domain Localized Statistical Channel Modeling for Cellular Network Optimization]] (80.8% similar)
- [[Federated Learning for Deforestation Detection A Distributed Approach with Satellite Imagery]] (79.5% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.14938v1 Announce Type: new 
Abstract: Federated Learning (FL) offers a decentralized solution that allows collaborative local model training and global aggregation, thereby protecting data privacy. In conventional FL frameworks, data privacy is typically preserved under the assumption that local data remains absolutely private, whereas the mobility of clients is frequently neglected in explicit modeling. In this paper, we propose a hierarchical federated learning framework based on the social network with mobility namely HFL-SNM that considers both data sharing among clients and their mobility patterns. Under the constraints of limited resources, we formulate a joint optimization problem of resource allocation and client scheduling, which objective is to minimize the energy consumption of clients during the FL process. In social network, we introduce the concepts of Effective Data Coverage Rate and Redundant Data Coverage Rate. We analyze the impact of effective data and redundant data on the model performance through preliminary experiments. We decouple the optimization problem into multiple sub-problems, analyze them based on preliminary experimental results, and propose Dynamic Optimization in Social Network with Mobility (DO-SNM) algorithm. Experimental results demonstrate that our algorithm achieves superior model performance while significantly reducing energy consumption, compared to traditional baseline algorithms.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.14938v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: ì—°í•© í•™ìŠµ(FL)ì€ í˜‘ë ¥ì ì¸ ë¡œì»¬ ëª¨ë¸ í•™ìŠµê³¼ ê¸€ë¡œë²Œ ì§‘ê³„ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ì—¬ ë°ì´í„° í”„ë¼ì´ë²„ì‹œë¥¼ ë³´í˜¸í•˜ëŠ” ë¶„ì‚° ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ FL í”„ë ˆì„ì›Œí¬ì—ì„œëŠ” ë¡œì»¬ ë°ì´í„°ê°€ ì ˆëŒ€ì ìœ¼ë¡œ ë¹„ê³µê°œë¡œ ìœ ì§€ëœë‹¤ëŠ” ê°€ì • í•˜ì— ë°ì´í„° í”„ë¼ì´ë²„ì‹œê°€ ì¼ë°˜ì ìœ¼ë¡œ ë³´ì¥ë˜ë©°, í´ë¼ì´ì–¸íŠ¸ì˜ ì´ë™ì„±ì€ ëª…ì‹œì ì¸ ëª¨ë¸ë§ì—ì„œ ìì£¼ ê°„ê³¼ë©ë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” í´ë¼ì´ì–¸íŠ¸ ê°„ì˜ ë°ì´í„° ê³µìœ ì™€ ì´ë™ íŒ¨í„´ì„ ëª¨ë‘ ê³ ë ¤í•œ ì´ë™ì„±ì„ ê°–ì¶˜ ì†Œì…œ ë„¤íŠ¸ì›Œí¬ ê¸°ë°˜ì˜ ê³„ì¸µì  ì—°í•© í•™ìŠµ í”„ë ˆì„ì›Œí¬ì¸ HFL-SNMì„ ì œì•ˆí•©ë‹ˆë‹¤. ì œí•œëœ ìì› í•˜ì—ì„œ, ìš°ë¦¬ëŠ” FL ê³¼ì • ë™ì•ˆ í´ë¼ì´ì–¸íŠ¸ì˜ ì—ë„ˆì§€ ì†Œë¹„ë¥¼ ìµœì†Œí™”í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ ìì› í• ë‹¹ê³¼ í´ë¼ì´ì–¸íŠ¸ ìŠ¤ì¼€ì¤„ë§ì˜ ê³µë™ ìµœì í™” ë¬¸ì œë¥¼ ìˆ˜ë¦½í•©ë‹ˆë‹¤. ì†Œì…œ ë„¤íŠ¸ì›Œí¬ì—ì„œ, ìš°ë¦¬ëŠ” ìœ íš¨ ë°ì´í„° ì»¤ë²„ë¦¬ì§€ ë¹„ìœ¨ê³¼ ì¤‘ë³µ ë°ì´í„° ì»¤ë²„ë¦¬ì§€ ë¹„ìœ¨ì˜ ê°œë…ì„ ë„ì…í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì˜ˆë¹„ ì‹¤í—˜ì„ í†µí•´ ìœ íš¨ ë°ì´í„°ì™€ ì¤‘ë³µ ë°ì´í„°ê°€ ëª¨ë¸ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•©ë‹ˆë‹¤. ìµœì í™” ë¬¸ì œë¥¼ ì—¬ëŸ¬ í•˜ìœ„ ë¬¸ì œë¡œ ë¶„ë¦¬í•˜ê³ , ì˜ˆë¹„ ì‹¤í—˜ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ì´ë™ì„±ì„ ê°–ì¶˜ ì†Œì…œ ë„¤íŠ¸ì›Œí¬ì—ì„œì˜ ë™ì  ìµœì í™”(DO-SNM) ì•Œê³ ë¦¬ì¦˜ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ìš°ë¦¬ì˜ ì•Œê³ ë¦¬ì¦˜ì€ ì „í†µì ì¸ ê¸°ì¤€ ì•Œê³ ë¦¬ì¦˜ì— ë¹„í•´ ì—ë„ˆì§€ ì†Œë¹„ë¥¼ í¬ê²Œ ì¤„ì´ë©´ì„œ ìš°ìˆ˜í•œ ëª¨ë¸ ì„±ëŠ¥ì„ ë‹¬ì„±í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì´ë™ì„±ì„ ê³ ë ¤í•œ ì‚¬íšŒ ë„¤íŠ¸ì›Œí¬ ê¸°ë°˜ì˜ ê³„ì¸µì  ì—°í•© í•™ìŠµ(HFL-SNM) í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ëŠ” í´ë¼ì´ì–¸íŠ¸ ê°„ ë°ì´í„° ê³µìœ ì™€ ì´ë™ íŒ¨í„´ì„ ê³ ë ¤í•˜ì—¬, ì œí•œëœ ìì› í•˜ì—ì„œ ì—ë„ˆì§€ ì†Œë¹„ë¥¼ ìµœì†Œí™”í•˜ëŠ” ìì› í• ë‹¹ ë° í´ë¼ì´ì–¸íŠ¸ ìŠ¤ì¼€ì¤„ë§ ë¬¸ì œë¥¼ ìµœì í™”í•©ë‹ˆë‹¤. íš¨ê³¼ì  ë°ì´í„° ì»¤ë²„ë¦¬ì§€ìœ¨ê³¼ ì¤‘ë³µ ë°ì´í„° ì»¤ë²„ë¦¬ì§€ìœ¨ ê°œë…ì„ ë„ì…í•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¬¸ì œë¥¼ ì—¬ëŸ¬ í•˜ìœ„ ë¬¸ì œë¡œ ë¶„ë¦¬í•˜ì—¬ ë¶„ì„í•œ í›„, DO-SNM ì•Œê³ ë¦¬ì¦˜ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ì•Œê³ ë¦¬ì¦˜ì€ ê¸°ì¡´ ì•Œê³ ë¦¬ì¦˜ë³´ë‹¤ ì—ë„ˆì§€ ì†Œë¹„ë¥¼ í¬ê²Œ ì¤„ì´ë©´ì„œ ìš°ìˆ˜í•œ ëª¨ë¸ ì„±ëŠ¥ì„ ë‹¬ì„±í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë³¸ ë…¼ë¬¸ì€ ì´ë™ì„±ì„ ê³ ë ¤í•œ ì‚¬íšŒ ë„¤íŠ¸ì›Œí¬ ê¸°ë°˜ì˜ ê³„ì¸µì  ì—°í•© í•™ìŠµ í”„ë ˆì„ì›Œí¬ HFL-SNMì„ ì œì•ˆí•©ë‹ˆë‹¤.

- 2. ì œí•œëœ ìì› í•˜ì—ì„œ ìì› í• ë‹¹ê³¼ í´ë¼ì´ì–¸íŠ¸ ìŠ¤ì¼€ì¤„ë§ì˜ ê³µë™ ìµœì í™” ë¬¸ì œë¥¼ í†µí•´ ì—ë„ˆì§€ ì†Œë¹„ë¥¼ ìµœì†Œí™”í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

- 3. íš¨ê³¼ì ì¸ ë°ì´í„° ì»¤ë²„ë¦¬ì§€ìœ¨ê³¼ ì¤‘ë³µ ë°ì´í„° ì»¤ë²„ë¦¬ì§€ìœ¨ì˜ ê°œë…ì„ ë„ì…í•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•©ë‹ˆë‹¤.

- 4. ì œì•ˆëœ DO-SNM ì•Œê³ ë¦¬ì¦˜ì€ ì „í†µì ì¸ ê¸°ì¤€ ì•Œê³ ë¦¬ì¦˜ì— ë¹„í•´ ì—ë„ˆì§€ ì†Œë¹„ë¥¼ í¬ê²Œ ì¤„ì´ë©´ì„œ ìš°ìˆ˜í•œ ëª¨ë¸ ì„±ëŠ¥ì„ ë‹¬ì„±í•©ë‹ˆë‹¤.

---

*Generated on 2025-09-19 15:28:38*