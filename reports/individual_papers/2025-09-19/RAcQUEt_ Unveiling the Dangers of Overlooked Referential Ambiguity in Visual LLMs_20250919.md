---
keywords:
  - Large Language Models
  - Referential Ambiguity
  - RACQUET-BIAS
category: cs.AI
publish_date: 2025-09-19
arxiv_id: 2412.13835
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 21:28:11.371947",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Models",
    "Referential Ambiguity",
    "RACQUET-BIAS"
  ],
  "rejected_keywords": [
    "Uncertainty Quantification"
  ],
  "similarity_scores": {
    "Large Language Models": 0.8,
    "Referential Ambiguity": 0.78,
    "RACQUET-BIAS": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->


# RAcQUEt: Unveiling the Dangers of Overlooked Referential Ambiguity in Visual LLMs

**Korean Title:** RAcQUEt: 시각적 대형 언어 모델에서 간과된 참조적 모호성의 위험성 공개

## 📋 메타데이터

**Links**: [[digests/daily_digest_20250919|2025-09-19]]   [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Large Language Models|Large Multimodal Language Models]]
**⚡ Unique Technical**: [[keywords/Referential Ambiguity|Referential Ambiguity]], [[keywords/RACQUET-BIAS|RACQUET-BIAS]]

## 🔗 유사한 논문
- [[Understanding and Mitigating Overrefusal in LLMs from an Unveiling Perspective of Safety Decision Boundary]] (85.4% similar)
- [[Language Models Identify Ambiguities and Exploit Loopholes]] (82.7% similar)
- [[AssoCiAm A Benchmark for Evaluating Association Thinking while Circumventing Ambiguity]] (82.1% similar)
- [[BiasMap Leveraging Cross-Attentions to Discover and Mitigate Hidden Social Biases in Text-to-Image Generation]] (81.6% similar)
- [[Causal-Counterfactual RAG The Integration of Causal-Counterfactual Reasoning into RAG]] (81.1% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2412.13835v2 Announce Type: replace 
Abstract: Ambiguity resolution is key to effective communication. While humans effortlessly address ambiguity through conversational grounding strategies, the extent to which current language models can emulate these strategies remains unclear. In this work, we examine referential ambiguity in image-based question answering by introducing RACQUET, a carefully curated dataset targeting distinct aspects of ambiguity. Through a series of evaluations, we reveal significant limitations and problems of overconfidence of state-of-the-art large multimodal language models in addressing ambiguity in their responses. The overconfidence issue becomes particularly relevant for RACQUET-BIAS, a subset designed to analyze a critical yet underexplored problem: failing to address ambiguity leads to stereotypical, socially biased responses. Our results underscore the urgency of equipping models with robust strategies to deal with uncertainty without resorting to undesirable stereotypes.

## 🔍 Abstract (한글 번역)

arXiv:2412.13835v2 발표 유형: 교체  
초록: 모호성 해결은 효과적인 의사소통의 핵심입니다. 인간은 대화적 기초 전략을 통해 모호성을 쉽게 해결하지만, 현재의 언어 모델이 이러한 전략을 모방할 수 있는 정도는 불분명합니다. 본 연구에서는 이미지 기반 질문 응답에서 참조적 모호성을 조사하기 위해 모호성의 다양한 측면을 겨냥한 신중하게 구성된 데이터셋인 RACQUET을 소개합니다. 일련의 평가를 통해, 최첨단 대형 다중모달 언어 모델이 응답에서 모호성을 해결하는 데 있어 상당한 한계와 과도한 자신감의 문제를 드러냅니다. 과도한 자신감 문제는 RACQUET-BIAS에 특히 관련이 있으며, 이는 모호성을 해결하지 못하면 고정관념적이고 사회적으로 편향된 응답을 초래하는 중요한 문제를 분석하기 위해 설계된 하위 집합입니다. 우리의 결과는 모델이 바람직하지 않은 고정관념에 의존하지 않고 불확실성을 처리할 수 있는 강력한 전략을 갖추는 것이 시급하다는 점을 강조합니다.

## 📝 요약

이 논문은 이미지 기반 질문 응답에서의 참조적 모호성을 다루며, 이를 위해 RACQUET라는 데이터셋을 소개합니다. 연구는 최신 대규모 멀티모달 언어 모델들이 모호성을 처리하는 데 있어 과신하는 문제와 한계를 드러냅니다. 특히 RACQUET-BIAS라는 하위 집합을 통해 모호성을 해결하지 못할 경우 사회적 편견이 반영된 답변이 생성되는 문제를 분석합니다. 결과적으로, 모델이 불확실성을 효과적으로 처리할 수 있는 전략을 갖추는 것이 중요하다는 점을 강조합니다.

## 🎯 주요 포인트

- 1. 모호성 해결은 효과적인 의사소통의 핵심 요소이다.

- 2. RACQUET라는 데이터셋을 통해 이미지 기반 질문 응답에서의 참조적 모호성을 분석하였다.

- 3. 최신 대규모 멀티모달 언어 모델들이 모호성을 다루는 데 있어 과신하는 경향이 있음을 발견하였다.

- 4. RACQUET-BIAS 하위 집합은 모호성을 해결하지 못할 경우 고정관념적이고 사회적으로 편향된 응답을 초래할 수 있음을 보여준다.

- 5. 모델들이 불확실성을 다루기 위해 바람직하지 않은 고정관념에 의존하지 않도록 강력한 전략을 갖추는 것이 시급하다.

---

*Generated on 2025-09-19 15:57:44*