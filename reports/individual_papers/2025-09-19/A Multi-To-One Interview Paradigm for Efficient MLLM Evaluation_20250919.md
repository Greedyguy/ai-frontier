---
keywords:
  - Large Language Models
  - Natural Language Processing
  - Adaptive Mechanisms
category: cs.AI
publish_date: 2025-09-19
arxiv_id: 2509.14886
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 22:00:06.618502",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Models",
    "Natural Language Processing",
    "Adaptive Mechanisms"
  ],
  "rejected_keywords": [
    "Adaptive Interview Paradigm"
  ],
  "similarity_scores": {
    "Large Language Models": 0.88,
    "Natural Language Processing": 0.8,
    "Adaptive Mechanisms": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->


# A Multi-To-One Interview Paradigm for Efficient MLLM Evaluation

**Korean Title:** 효율적인 MLLM 평가를 위한 다대일 인터뷰 패러다임

## 📋 메타데이터

**Links**: [[digests/daily_digest_20250919|2025-09-19]]   [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🌐 Broad Technical**: [[keywords/Natural Language Processing|Question-Answering evaluations]]
**🚀 Evolved Concepts**: [[keywords/Adaptive Mechanisms|dynamic adjustment of interviewer weights]]

## 🔗 유사한 논문
- [[Forget What You Know about LLMs Evaluations -- LLMs are Like a Chameleon]] (83.9% similar)
- [[LLM-I LLMs are Naturally Interleaved Multimodal Creators]] (82.9% similar)
- [[(P)rior(D)yna(F)low A Priori Dynamic Workflow Construction via Multi-Agent Collaboration]] (82.9% similar)
- [[From Capabilities to Performance Evaluating Key Functional Properties of LLM Architectures in Penetration Testing]] (82.3% similar)
- [[Internalizing Self-Consistency in Language Models Multi-Agent Consensus Alignment]] (82.1% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.14886v1 Announce Type: cross 
Abstract: The rapid progress of Multi-Modal Large Language Models (MLLMs) has spurred the creation of numerous benchmarks. However, conventional full-coverage Question-Answering evaluations suffer from high redundancy and low efficiency. Inspired by human interview processes, we propose a multi-to-one interview paradigm for efficient MLLM evaluation. Our framework consists of (i) a two-stage interview strategy with pre-interview and formal interview phases, (ii) dynamic adjustment of interviewer weights to ensure fairness, and (iii) an adaptive mechanism for question difficulty-level chosen. Experiments on different benchmarks show that the proposed paradigm achieves significantly higher correlation with full-coverage results than random sampling, with improvements of up to 17.6% in PLCC and 16.7% in SRCC, while reducing the number of required questions. These findings demonstrate that the proposed paradigm provides a reliable and efficient alternative for large-scale MLLM benchmarking.

## 🔍 Abstract (한글 번역)

arXiv:2509.14886v1 발표 유형: 교차  
초록: 다중 모드 대형 언어 모델(Multi-Modal Large Language Models, MLLMs)의 급속한 발전은 수많은 벤치마크의 생성을 촉진했습니다. 그러나 기존의 전면적 질문-응답 평가 방식은 높은 중복성과 낮은 효율성을 겪고 있습니다. 인간의 인터뷰 과정을 본떠, 우리는 효율적인 MLLM 평가를 위한 다대일 인터뷰 패러다임을 제안합니다. 우리의 프레임워크는 (i) 사전 인터뷰와 공식 인터뷰 단계로 구성된 두 단계 인터뷰 전략, (ii) 공정성을 보장하기 위한 인터뷰어 가중치의 동적 조정, (iii) 선택된 질문 난이도 수준에 대한 적응적 메커니즘으로 구성됩니다. 다양한 벤치마크에 대한 실험 결과, 제안된 패러다임은 무작위 샘플링보다 전면적 결과와의 상관관계가 최대 17.6%의 PLCC와 16.7%의 SRCC 향상을 보이며, 필요한 질문 수를 줄이는 데 성공했습니다. 이러한 결과는 제안된 패러다임이 대규모 MLLM 벤치마킹에 신뢰할 수 있고 효율적인 대안을 제공함을 입증합니다.

## 📝 요약

이 논문은 다중 모달 대형 언어 모델(MLLM)의 평가 효율성을 높이기 위해 새로운 인터뷰 패러다임을 제안합니다. 기존의 전면적 질문-응답 방식은 중복성과 비효율성이 문제였는데, 이를 해결하기 위해 인간의 인터뷰 과정을 모방한 다중 대 일 인터뷰 방식을 도입했습니다. 제안된 프레임워크는 사전 인터뷰와 공식 인터뷰로 구성된 두 단계 전략, 공정성을 보장하는 인터뷰어 가중치의 동적 조정, 질문 난이도 선택을 위한 적응적 메커니즘을 포함합니다. 다양한 벤치마크 실험 결과, 이 패러다임은 기존의 무작위 샘플링보다 최대 17.6% 높은 PLCC와 16.7% 높은 SRCC 상관성을 보이며, 필요한 질문 수를 줄이면서도 신뢰성과 효율성을 입증했습니다.

## 🎯 주요 포인트

- 1. 다중 모달 대형 언어 모델(MLLM)의 효율적인 평가를 위해 다대일 인터뷰 패러다임을 제안합니다.

- 2. 제안된 프레임워크는 사전 인터뷰와 공식 인터뷰 단계로 구성된 두 단계 인터뷰 전략을 포함합니다.

- 3. 인터뷰어 가중치의 동적 조정을 통해 공정성을 보장합니다.

- 4. 질문 난이도를 선택하는 적응 메커니즘을 도입하여 평가 효율성을 높였습니다.

- 5. 제안된 패러다임은 기존의 무작위 샘플링보다 최대 17.6%의 PLCC와 16.7%의 SRCC 개선을 통해 높은 상관성을 달성합니다.

---

*Generated on 2025-09-19 15:02:21*