---
keywords:
  - Machine Translation
  - Large Language Models
  - Transfer Learning
category: cs.AI
publish_date: 2025-09-19
arxiv_id: 2509.14493
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 21:20:09.511428",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Machine Translation",
    "Large Language Models",
    "Transfer Learning"
  ],
  "rejected_keywords": [
    "Multilingual Toxicity Detection"
  ],
  "similarity_scores": {
    "Machine Translation": 0.85,
    "Large Language Models": 0.8,
    "Transfer Learning": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->


# Translate, then Detect: Leveraging Machine Translation for Cross-Lingual Toxicity Classification

**Korean Title:** ë²ˆì—­ í›„ íƒì§€: ê¸°ê³„ ë²ˆì—­ì„ í™œìš©í•œ ë‹¤êµ­ì–´ ë…ì„± ë¶„ë¥˜

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[digests/daily_digest_20250919|2025-09-19]]   [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Machine Translation|Machine Translation]], [[keywords/Transfer Learning|Cross-Lingual Transfer]]

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[DetectAnyLLM Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models]] (81.5% similar)
- [[SMARTER A Data-efficient Framework to Improve Toxicity Detection with Explanation via Self-augmenting Large Language Models]] (80.7% similar)
- [[You Are What You Train Effects of Data Composition on Training Context-aware Machine Translation Models]] (80.4% similar)
- [[Semantic Alignment-Enhanced Code Translation via an LLM-Based Multi-Agent System_20250918|Semantic Alignment-Enhanced Code Translation via an LLM-Based Multi-Agent System]] (80.3% similar)
- [[Audio-Based Crowd-Sourced Evaluation of Machine Translation Quality_20250918|Audio-Based Crowd-Sourced Evaluation of Machine Translation Quality]] (79.7% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.14493v1 Announce Type: new 
Abstract: Multilingual toxicity detection remains a significant challenge due to the scarcity of training data and resources for many languages. While prior work has leveraged the translate-test paradigm to support cross-lingual transfer across a range of classification tasks, the utility of translation in supporting toxicity detection at scale remains unclear. In this work, we conduct a comprehensive comparison of translation-based and language-specific/multilingual classification pipelines. We find that translation-based pipelines consistently outperform out-of-distribution classifiers in 81.3% of cases (13 of 16 languages), with translation benefits strongly correlated with both the resource level of the target language and the quality of the machine translation (MT) system. Our analysis reveals that traditional classifiers outperform large language model (LLM) judges, with this advantage being particularly pronounced for low-resource languages, where translate-classify methods dominate translate-judge approaches in 6 out of 7 cases. We additionally show that MT-specific fine-tuning on LLMs yields lower refusal rates compared to standard instruction-tuned models, but it can negatively impact toxicity detection accuracy for low-resource languages. These findings offer actionable guidance for practitioners developing scalable multilingual content moderation systems.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.14493v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: ë‹¤êµ­ì–´ ë…ì„± ê°ì§€ ë¶„ì•¼ëŠ” ë§ì€ ì–¸ì–´ì— ëŒ€í•œ í•™ìŠµ ë°ì´í„°ì™€ ìì›ì˜ ë¶€ì¡±ìœ¼ë¡œ ì¸í•´ ì—¬ì „íˆ í° ë„ì „ ê³¼ì œë¡œ ë‚¨ì•„ ìˆìŠµë‹ˆë‹¤. ì´ì „ ì—°êµ¬ì—ì„œëŠ” ë‹¤ì–‘í•œ ë¶„ë¥˜ ì‘ì—…ì—ì„œ ì–¸ì–´ ê°„ ì „ì´ë¥¼ ì§€ì›í•˜ê¸° ìœ„í•´ ë²ˆì—­-í…ŒìŠ¤íŠ¸ íŒ¨ëŸ¬ë‹¤ì„ì„ í™œìš©í–ˆì§€ë§Œ, ëŒ€ê·œëª¨ ë…ì„± ê°ì§€ë¥¼ ì§€ì›í•˜ëŠ” ë²ˆì—­ì˜ ìœ ìš©ì„±ì€ ì—¬ì „íˆ ë¶ˆë¶„ëª…í•©ë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” ë²ˆì—­ ê¸°ë°˜ ë° ì–¸ì–´ë³„/ë‹¤êµ­ì–´ ë¶„ë¥˜ íŒŒì´í”„ë¼ì¸ì„ ì¢…í•©ì ìœ¼ë¡œ ë¹„êµí•©ë‹ˆë‹¤. ë²ˆì—­ ê¸°ë°˜ íŒŒì´í”„ë¼ì¸ì´ 81.3%ì˜ ê²½ìš°(16ê°œ ì–¸ì–´ ì¤‘ 13ê°œ)ì—ì„œ ë¶„í¬ ì™¸ ë¶„ë¥˜ê¸°ë³´ë‹¤ ì¼ê´€ë˜ê²Œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë©°, ë²ˆì—­ì˜ ì´ì ì€ ëŒ€ìƒ ì–¸ì–´ì˜ ìì› ìˆ˜ì¤€ê³¼ ê¸°ê³„ ë²ˆì—­(MT) ì‹œìŠ¤í…œì˜ í’ˆì§ˆê³¼ ê°•í•œ ìƒê´€ ê´€ê³„ê°€ ìˆìŒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ìš°ë¦¬ì˜ ë¶„ì„ì€ ì „í†µì ì¸ ë¶„ë¥˜ê¸°ê°€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM) ì‹¬íŒë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì´ë©°, íŠ¹íˆ ìì›ì´ ë¶€ì¡±í•œ ì–¸ì–´ì—ì„œ ì´ ì ì´ ë‘ë“œëŸ¬ì§€ë©°, ë²ˆì—­-ë¶„ë¥˜ ë°©ë²•ì´ ë²ˆì—­-ì‹¬íŒ ì ‘ê·¼ ë°©ì‹ì„ 7ê°œ ì‚¬ë¡€ ì¤‘ 6ê°œì—ì„œ ì§€ë°°í•œë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë˜í•œ, LLMì— ëŒ€í•œ MT íŠ¹ì • ë¯¸ì„¸ ì¡°ì •ì´ í‘œì¤€ ì§€ì¹¨ ì¡°ì • ëª¨ë¸ì— ë¹„í•´ ê±°ë¶€ìœ¨ì„ ë‚®ì¶”ì§€ë§Œ, ìì›ì´ ë¶€ì¡±í•œ ì–¸ì–´ì˜ ë…ì„± ê°ì§€ ì •í™•ì„±ì—ëŠ” ë¶€ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŸ¬í•œ ë°œê²¬ì€ í™•ì¥ ê°€ëŠ¥í•œ ë‹¤êµ­ì–´ ì½˜í…ì¸  ëª¨ë”ë ˆì´ì…˜ ì‹œìŠ¤í…œì„ ê°œë°œí•˜ëŠ” ì‹¤ë¬´ìì—ê²Œ ì‹¤ì§ˆì ì¸ ì§€ì¹¨ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ë‹¤ì–¸ì–´ ë…ì„± íƒì§€ëŠ” ë§ì€ ì–¸ì–´ì— ëŒ€í•œ í›ˆë ¨ ë°ì´í„°ì™€ ìì›ì˜ ë¶€ì¡±ìœ¼ë¡œ ì—¬ì „íˆ ì–´ë ¤ìš´ ê³¼ì œì…ë‹ˆë‹¤. ë³¸ ì—°êµ¬ëŠ” ë²ˆì—­ ê¸°ë°˜ ë° ì–¸ì–´ë³„/ë‹¤ì–¸ì–´ ë¶„ë¥˜ íŒŒì´í”„ë¼ì¸ì„ ë¹„êµí•˜ì—¬, ë²ˆì—­ ê¸°ë°˜ ì ‘ê·¼ë²•ì´ 81.3%ì˜ ê²½ìš°ì—ì„œ ë” ìš°ìˆ˜í•¨ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. íŠ¹íˆ ë²ˆì—­ì˜ ì´ì ì€ ëŒ€ìƒ ì–¸ì–´ì˜ ìì› ìˆ˜ì¤€ê³¼ ê¸°ê³„ ë²ˆì—­ ì‹œìŠ¤í…œì˜ í’ˆì§ˆê³¼ ê°•í•˜ê²Œ ì—°ê´€ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì „í†µì ì¸ ë¶„ë¥˜ê¸°ê°€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ë³´ë‹¤ ì„±ëŠ¥ì´ ë›°ì–´ë‚¬ìœ¼ë©°, íŠ¹íˆ ìì›ì´ ë¶€ì¡±í•œ ì–¸ì–´ì—ì„œ ë²ˆì—­-ë¶„ë¥˜ ë°©ë²•ì´ ë²ˆì—­-íŒë‹¨ ë°©ë²•ë³´ë‹¤ ìš°ì„¸í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, LLMì— ëŒ€í•œ ê¸°ê³„ ë²ˆì—­(MT) íŠ¹í™” ë¯¸ì„¸ ì¡°ì •ì´ ê±°ë¶€ìœ¨ì„ ë‚®ì¶”ì§€ë§Œ, ìì›ì´ ë¶€ì¡±í•œ ì–¸ì–´ì—ì„œëŠ” ë…ì„± íƒì§€ ì •í™•ë„ë¥¼ ì €í•˜ì‹œí‚¬ ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŸ¬í•œ ê²°ê³¼ëŠ” í™•ì¥ ê°€ëŠ¥í•œ ë‹¤ì–¸ì–´ ì½˜í…ì¸  ëª¨ë”ë ˆì´ì…˜ ì‹œìŠ¤í…œ ê°œë°œì— ìœ ìš©í•œ ì§€ì¹¨ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë‹¤êµ­ì–´ ìœ í•´ì„± íƒì§€ëŠ” ë§ì€ ì–¸ì–´ì— ëŒ€í•œ í›ˆë ¨ ë°ì´í„°ì™€ ìì›ì˜ ë¶€ì¡±ìœ¼ë¡œ ì¸í•´ ì—¬ì „íˆ í° ë„ì „ ê³¼ì œì…ë‹ˆë‹¤.

- 2. ë²ˆì—­ ê¸°ë°˜ íŒŒì´í”„ë¼ì¸ì€ 81.3%ì˜ ê²½ìš°ì—ì„œ ë²ˆì—­í•˜ì§€ ì•Šì€ ë¶„ë¥˜ê¸°ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

- 3. ë²ˆì—­ì˜ ì´ì ì€ ëŒ€ìƒ ì–¸ì–´ì˜ ìì› ìˆ˜ì¤€ê³¼ ê¸°ê³„ ë²ˆì—­ ì‹œìŠ¤í…œì˜ í’ˆì§ˆê³¼ ê°•í•˜ê²Œ ìƒê´€ê´€ê³„ê°€ ìˆìŠµë‹ˆë‹¤.

- 4. ì „í†µì ì¸ ë¶„ë¥˜ê¸°ê°€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM) íŒì‚¬ë³´ë‹¤ ìš°ìˆ˜í•˜ë©°, íŠ¹íˆ ìì›ì´ ì ì€ ì–¸ì–´ì—ì„œ ê·¸ ì°¨ì´ê°€ ë‘ë“œëŸ¬ì§‘ë‹ˆë‹¤.

- 5. ê¸°ê³„ ë²ˆì—­(MT) íŠ¹í™” ë¯¸ì„¸ ì¡°ì •ì´ ê±°ë¶€ìœ¨ì„ ë‚®ì¶œ ìˆ˜ ìˆì§€ë§Œ, ìì›ì´ ì ì€ ì–¸ì–´ì—ì„œëŠ” ìœ í•´ì„± íƒì§€ ì •í™•ë„ì— ë¶€ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

*Generated on 2025-09-19 15:48:47*