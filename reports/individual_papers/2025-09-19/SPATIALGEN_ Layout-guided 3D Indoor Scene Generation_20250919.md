
# SPATIALGEN: Layout-guided 3D Indoor Scene Generation

**Korean Title:** SPATIALGEN: ë ˆì´ì•„ì›ƒ ê¸°ë°˜ 3D ì‹¤ë‚´ ì¥ë©´ ìƒì„±

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-19|2025-09-19]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Layout-guided Scene Generation

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[Evolution Meets Diffusion Efficient Neural Architecture Generation]] (80.3% similar)
- [[Imagined Autocurricula]] (80.2% similar)
- [[Seeing 3D Through 2D Lenses 3D Few-Shot Class-Incremental Learning via Cross-Modal Geometric Rectification]] (80.1% similar)
- [[StyleSculptor Zero-Shot Style-Controllable 3D Asset Generation with Texture-Geometry Dual Guidance]] (80.0% similar)
- [[Style Transfer with Diffusion Models for Synthetic-to-Real Domain Adaptation_20250919|Style Transfer with Diffusion Models for Synthetic-to-Real Domain Adaptation]] (79.9% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.14981v1 Announce Type: new 
Abstract: Creating high-fidelity 3D models of indoor environments is essential for applications in design, virtual reality, and robotics. However, manual 3D modeling remains time-consuming and labor-intensive. While recent advances in generative AI have enabled automated scene synthesis, existing methods often face challenges in balancing visual quality, diversity, semantic consistency, and user control. A major bottleneck is the lack of a large-scale, high-quality dataset tailored to this task. To address this gap, we introduce a comprehensive synthetic dataset, featuring 12,328 structured annotated scenes with 57,440 rooms, and 4.7M photorealistic 2D renderings. Leveraging this dataset, we present SpatialGen, a novel multi-view multi-modal diffusion model that generates realistic and semantically consistent 3D indoor scenes. Given a 3D layout and a reference image (derived from a text prompt), our model synthesizes appearance (color image), geometry (scene coordinate map), and semantic (semantic segmentation map) from arbitrary viewpoints, while preserving spatial consistency across modalities. SpatialGen consistently generates superior results to previous methods in our experiments. We are open-sourcing our data and models to empower the community and advance the field of indoor scene understanding and generation.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.14981v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: ì‹¤ë‚´ í™˜ê²½ì˜ ê³ ì¶©ì‹¤ë„ 3D ëª¨ë¸ì„ ë§Œë“œëŠ” ê²ƒì€ ë””ìì¸, ê°€ìƒ í˜„ì‹¤, ë¡œë´‡ ê³µí•™ ë¶„ì•¼ì˜ ì‘ìš©ì— í•„ìˆ˜ì ì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ìˆ˜ë™ 3D ëª¨ë¸ë§ì€ ì—¬ì „íˆ ì‹œê°„ì´ ë§ì´ ê±¸ë¦¬ê³  ë…¸ë™ ì§‘ì•½ì ì…ë‹ˆë‹¤. ìµœê·¼ ìƒì„±í˜• AIì˜ ë°œì „ìœ¼ë¡œ ìë™ ì¥ë©´ í•©ì„±ì´ ê°€ëŠ¥í•´ì¡Œì§€ë§Œ, ê¸°ì¡´ ë°©ë²•ë“¤ì€ ì‹œê°ì  í’ˆì§ˆ, ë‹¤ì–‘ì„±, ì˜ë¯¸ë¡ ì  ì¼ê´€ì„±, ì‚¬ìš©ì ì œì–´ ê°„ì˜ ê· í˜•ì„ ë§ì¶”ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªê³  ìˆìŠµë‹ˆë‹¤. ì£¼ìš” ë³‘ëª© í˜„ìƒì€ ì´ ì‘ì—…ì— ë§ì¶˜ ëŒ€ê·œëª¨ ê³ í’ˆì§ˆ ë°ì´í„°ì…‹ì˜ ë¶€ì¡±ì…ë‹ˆë‹¤. ì´ ê²©ì°¨ë¥¼ í•´ì†Œí•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” 12,328ê°œì˜ êµ¬ì¡°í™”ëœ ì£¼ì„ì´ ë‹¬ë¦° ì¥ë©´ê³¼ 57,440ê°œì˜ ë°©, ê·¸ë¦¬ê³  470ë§Œ ê°œì˜ ì‚¬ì§„ ì‹¤ì‚¬ 2D ë Œë”ë§ì„ íŠ¹ì§•ìœ¼ë¡œ í•˜ëŠ” í¬ê´„ì ì¸ í•©ì„± ë°ì´í„°ì…‹ì„ ì†Œê°œí•©ë‹ˆë‹¤. ì´ ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬, ìš°ë¦¬ëŠ” í˜„ì‹¤ì ì´ê³  ì˜ë¯¸ë¡ ì ìœ¼ë¡œ ì¼ê´€ëœ 3D ì‹¤ë‚´ ì¥ë©´ì„ ìƒì„±í•˜ëŠ” ìƒˆë¡œìš´ ë‹¤ì¤‘ ë·° ë‹¤ì¤‘ ëª¨ë‹¬ í™•ì‚° ëª¨ë¸ì¸ SpatialGenì„ ì œì‹œí•©ë‹ˆë‹¤. 3D ë ˆì´ì•„ì›ƒê³¼ ì°¸ì¡° ì´ë¯¸ì§€(í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ì—ì„œ íŒŒìƒëœ)ë¥¼ ì£¼ì–´ì§€ë©´, ìš°ë¦¬ì˜ ëª¨ë¸ì€ ì„ì˜ì˜ ê´€ì ì—ì„œ ì™¸ê´€(ì»¬ëŸ¬ ì´ë¯¸ì§€), ê¸°í•˜í•™(ì¥ë©´ ì¢Œí‘œ ë§µ), ì˜ë¯¸ë¡ ì (ì˜ë¯¸ë¡ ì  ë¶„í•  ë§µ)ì„ í•©ì„±í•˜ë©°, ëª¨ë‹¬ë¦¬í‹° ê°„ì˜ ê³µê°„ì  ì¼ê´€ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤. SpatialGenì€ ìš°ë¦¬ì˜ ì‹¤í—˜ì—ì„œ ì´ì „ ë°©ë²•ë“¤ë³´ë‹¤ ì¼ê´€ë˜ê²Œ ìš°ìˆ˜í•œ ê²°ê³¼ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì‹¤ë‚´ ì¥ë©´ ì´í•´ ë° ìƒì„± ë¶„ì•¼ë¥¼ ë°œì „ì‹œí‚¤ê³  ì»¤ë®¤ë‹ˆí‹°ë¥¼ ì§€ì›í•˜ê¸° ìœ„í•´ ìš°ë¦¬ì˜ ë°ì´í„°ì™€ ëª¨ë¸ì„ ì˜¤í”ˆ ì†ŒìŠ¤ë¡œ ê³µê°œí•˜ê³  ìˆìŠµë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì‹¤ë‚´ í™˜ê²½ì˜ ê³ í’ˆì§ˆ 3D ëª¨ë¸ ìƒì„±ì„ ìœ„í•œ ìƒˆë¡œìš´ ì ‘ê·¼ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ìë™ ì¥ë©´ ìƒì„± ë°©ë²•ì€ ì‹œê°ì  í’ˆì§ˆ, ë‹¤ì–‘ì„±, ì˜ë¯¸ì  ì¼ê´€ì„±, ì‚¬ìš©ì ì œì–´ ê°„ì˜ ê· í˜•ì„ ë§ì¶”ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªê³  ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, 12,328ê°œì˜ ì£¼ì„ì´ ë‹¬ë¦° ì¥ë©´ê³¼ 57,440ê°œì˜ ë°©, 470ë§Œ ê°œì˜ ì‚¬ì‹¤ì ì¸ 2D ë Œë”ë§ì„ í¬í•¨í•œ ëŒ€ê·œëª¨ í•©ì„± ë°ì´í„°ì…‹ì„ ì†Œê°œí•©ë‹ˆë‹¤. ì´ ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬, SpatialGenì´ë¼ëŠ” ìƒˆë¡œìš´ ë‹¤ì¤‘ ë·° ë‹¤ì¤‘ ëª¨ë‹¬ í™•ì‚° ëª¨ë¸ì„ ê°œë°œí•˜ì˜€ìŠµë‹ˆë‹¤. ì´ ëª¨ë¸ì€ 3D ë ˆì´ì•„ì›ƒê³¼ ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ, ë‹¤ì–‘í•œ ê´€ì ì—ì„œ ì‹¤ë‚´ ì¥ë©´ì˜ ìƒ‰ìƒ ì´ë¯¸ì§€, ì¥ë©´ ì¢Œí‘œ ì§€ë„, ì˜ë¯¸ì  ë¶„í•  ì§€ë„ë¥¼ ìƒì„±í•˜ë©°, ê³µê°„ì  ì¼ê´€ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, SpatialGenì€ ê¸°ì¡´ ë°©ë²•ë“¤ë³´ë‹¤ ìš°ìˆ˜í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ì—ˆìœ¼ë©°, ë°ì´í„°ì™€ ëª¨ë¸ì„ ê³µê°œí•˜ì—¬ ì‹¤ë‚´ ì¥ë©´ ì´í•´ ë° ìƒì„± ë¶„ì•¼ì˜ ë°œì „ì„ ë„ëª¨í•˜ê³ ì í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì‹¤ë‚´ í™˜ê²½ì˜ ê³ í’ˆì§ˆ 3D ëª¨ë¸ ìƒì„±ì€ ë””ìì¸, ê°€ìƒ í˜„ì‹¤, ë¡œë´‡ ê³µí•™ì— í•„ìˆ˜ì ì´ë‹¤.

- 2. ê¸°ì¡´ì˜ ìë™ ì¥ë©´ í•©ì„± ë°©ë²•ì€ ì‹œê°ì  í’ˆì§ˆ, ë‹¤ì–‘ì„±, ì˜ë¯¸ì  ì¼ê´€ì„±, ì‚¬ìš©ì ì œì–´ ê°„ì˜ ê· í˜•ì„ ë§ì¶”ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªê³  ìˆë‹¤.

- 3. ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ 12,328ê°œì˜ êµ¬ì¡°í™”ëœ ì£¼ì„ ì¥ë©´ê³¼ 57,440ê°œì˜ ë°©, 470ë§Œ ê°œì˜ ì‚¬ì‹¤ì ì¸ 2D ë Œë”ë§ì„ í¬í•¨í•œ ì¢…í•©ì ì¸ í•©ì„± ë°ì´í„°ì…‹ì„ ì†Œê°œí•œë‹¤.

- 4. SpatialGenì€ ë‹¤ì¤‘ ë·° ë‹¤ì¤‘ ëª¨ë‹¬ í™•ì‚° ëª¨ë¸ë¡œ, í˜„ì‹¤ì ì´ê³  ì˜ë¯¸ì ìœ¼ë¡œ ì¼ê´€ëœ 3D ì‹¤ë‚´ ì¥ë©´ì„ ìƒì„±í•œë‹¤.

- 5. ë°ì´í„°ì™€ ëª¨ë¸ì„ ì˜¤í”ˆ ì†ŒìŠ¤ë¡œ ì œê³µí•˜ì—¬ ì‹¤ë‚´ ì¥ë©´ ì´í•´ ë° ìƒì„± ë¶„ì•¼ì˜ ë°œì „ì„ ë„ëª¨í•œë‹¤.

---

*Generated on 2025-09-19 16:08:27*