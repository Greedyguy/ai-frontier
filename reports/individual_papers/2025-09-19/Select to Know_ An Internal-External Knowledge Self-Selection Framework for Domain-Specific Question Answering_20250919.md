
# Select to Know: An Internal-External Knowledge Self-Selection Framework for Domain-Specific Question Answering

**Korean Title:** 도메인 특화 질문 응답을 위한 내부-외부 지식 자기 선택 프레임워크: 선택하여 알기

## 📋 메타데이터

**Links**: [[daily/2025-09-19|2025-09-19]] [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Internal-External Knowledge Self-Selection

## 🔗 유사한 논문
- [[KBM Delineating Knowledge Boundary for Adaptive Retrieval in Large Language Models]] (86.4% similar)
- [[Causal-Counterfactual RAG The Integration of Causal-Counterfactual Reasoning into RAG]] (84.8% similar)
- [[Enhancing Retrieval Augmentation via Adversarial Collaboration_20250919|Enhancing Retrieval Augmentation via Adversarial Collaboration]] (84.4% similar)
- [[Evaluating and Improving the Robustness of Security Attack Detectors Generated by LLMs_20250918|Evaluating and Improving the Robustness of Security Attack Detectors Generated by LLMs]] (83.9% similar)
- [[GRADA Graph-based Reranking against Adversarial Documents Attack]] (83.4% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2508.15213v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) perform well in general QA but often struggle in domain-specific scenarios. Retrieval-Augmented Generation (RAG) introduces external knowledge but suffers from hallucinations and latency due to noisy retrievals. Continued pretraining internalizes domain knowledge but is costly and lacks cross-domain flexibility. We attribute this challenge to the long-tail distribution of domain knowledge, which leaves partial yet useful internal knowledge underutilized. We further argue that knowledge acquisition should be progressive, mirroring human learning: first understanding concepts, then applying them to complex reasoning. To address this, we propose Selct2Know (S2K), a cost-effective framework that internalizes domain knowledge through an internal-external knowledge self-selection strategy and selective supervised fine-tuning. We also introduce a structured reasoning data generation pipeline and integrate GRPO to enhance reasoning ability. Experiments on medical, legal, and financial QA benchmarks show that S2K consistently outperforms existing methods and matches domain-pretrained LLMs with significantly lower cost.

## 🔍 Abstract (한글 번역)

arXiv:2508.15213v2 발표 유형: 교체  
초록: 대형 언어 모델(LLMs)은 일반적인 질문 응답(QA)에서는 우수한 성능을 보이지만, 특정 분야의 시나리오에서는 종종 어려움을 겪습니다. Retrieval-Augmented Generation (RAG)은 외부 지식을 도입하지만, 잡음이 많은 검색으로 인해 환각과 지연 문제가 발생합니다. 지속적인 사전 훈련은 분야 지식을 내재화하지만 비용이 많이 들고, 분야 간 유연성이 부족합니다. 우리는 이러한 도전 과제가 분야 지식의 긴 꼬리 분포에 기인한다고 보고, 이로 인해 부분적이지만 유용한 내부 지식이 충분히 활용되지 못한다고 봅니다. 또한 지식 습득은 인간의 학습을 반영하여 점진적으로 이루어져야 한다고 주장합니다: 먼저 개념을 이해하고, 그런 다음 복잡한 추론에 이를 적용해야 합니다. 이를 해결하기 위해, 우리는 Selct2Know (S2K)를 제안합니다. 이는 내부-외부 지식 자기 선택 전략과 선택적 지도 미세 조정을 통해 분야 지식을 내재화하는 비용 효율적인 프레임워크입니다. 우리는 또한 구조화된 추론 데이터 생성 파이프라인을 도입하고, GRPO를 통합하여 추론 능력을 강화합니다. 의료, 법률, 금융 QA 벤치마크에 대한 실험 결과, S2K는 기존 방법을 일관되게 능가하며, 훨씬 낮은 비용으로 분야 사전 훈련된 LLMs와 동등한 성능을 보입니다.

## 📝 요약

이 논문은 대형 언어 모델(LLM)이 일반적인 질문 응답에서는 뛰어나지만, 특정 도메인에서는 어려움을 겪는 문제를 다룹니다. Retrieval-Augmented Generation(RAG)은 외부 지식을 도입하지만, 잡음 있는 검색으로 인해 환각과 지연 문제가 발생합니다. 도메인 지식을 내재화하는 추가 사전 학습은 비용이 크고, 도메인 간 유연성이 부족합니다. 이러한 문제의 원인을 도메인 지식의 긴 꼬리 분포로 보고, 지식 습득은 인간 학습처럼 점진적이어야 한다고 주장합니다. 이를 해결하기 위해, 내부-외부 지식 자기 선택 전략과 선택적 지도 미세 조정을 통해 도메인 지식을 내재화하는 비용 효율적인 프레임워크 Selct2Know(S2K)를 제안합니다. 또한, 구조화된 추론 데이터 생성 파이프라인을 도입하고 GRPO를 통합하여 추론 능력을 향상시킵니다. 의료, 법률, 금융 QA 벤치마크 실험에서 S2K는 기존 방법을 일관되게 능가하며, 도메인 사전 학습된 LLM과 유사한 성능을 훨씬 낮은 비용으로 달성합니다.

## 🎯 주요 포인트

- 1. 대형 언어 모델(LLM)은 일반적인 질문 응답에서는 우수한 성능을 보이지만, 특정 도메인에서는 어려움을 겪는다.

- 2. Retrieval-Augmented Generation(RAG)은 외부 지식을 도입하지만, 잡음이 많은 검색으로 인해 환각과 지연 문제가 발생한다.

- 3. Selct2Know(S2K)는 내부-외부 지식 자기 선택 전략과 선택적 지도 학습을 통해 도메인 지식을 내재화하는 비용 효율적인 프레임워크를 제안한다.

- 4. S2K는 의료, 법률, 금융 QA 벤치마크 실험에서 기존 방법을 지속적으로 능가하며, 도메인 사전 학습된 LLM과 유사한 성능을 훨씬 낮은 비용으로 달성한다.

- 5. GRPO를 통합하여 추론 능력을 강화하고, 구조화된 추론 데이터 생성 파이프라인을 도입한다.

---

*Generated on 2025-09-19 16:01:27*