
# Affordance-Based Disambiguation of Surgical Instructions for Collaborative Robot-Assisted Surgery

**Korean Title:** 수술 지침의 협업 로봇 보조 수술을 위한 어포던스 기반의 모호성 해소

## 📋 메타데이터

**Links**: [[daily/2025-09-19|2025-09-19]] [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Affordance Based Reasoning

## 🔗 유사한 논문
- [[Intelligent Healthcare Imaging Platform An VLM-Based Framework for Automated Medical Image Analysis and Clinical Report Generation]] (81.4% similar)
- [[When Avatars Have Personality Effects on Engagement and Communication in Immersive Medical Training]] (81.2% similar)
- [[Embracing Bulky Objects with Humanoid Robots Whole-Body Manipulation with Reinforcement Learning]] (80.9% similar)
- [[Human Interaction for Collaborative Semantic SLAM using Extended Reality_20250919|Human Interaction for Collaborative Semantic SLAM using Extended Reality]] (80.4% similar)
- [[Learning Discrete Abstractions for Visual Rearrangement Tasks Using Vision-Guided Graph Coloring_20250919|Learning Discrete Abstractions for Visual Rearrangement Tasks Using Vision-Guided Graph Coloring]] (80.3% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.14967v1 Announce Type: new 
Abstract: Effective human-robot collaboration in surgery is affected by the inherent ambiguity of verbal communication. This paper presents a framework for a robotic surgical assistant that interprets and disambiguates verbal instructions from a surgeon by grounding them in the visual context of the operating field. The system employs a two-level affordance-based reasoning process that first analyzes the surgical scene using a multimodal vision-language model and then reasons about the instruction using a knowledge base of tool capabilities. To ensure patient safety, a dual-set conformal prediction method is used to provide a statistically rigorous confidence measure for robot decisions, allowing it to identify and flag ambiguous commands. We evaluated our framework on a curated dataset of ambiguous surgical requests from cholecystectomy videos, demonstrating a general disambiguation rate of 60% and presenting a method for safer human-robot interaction in the operating room.

## 🔍 Abstract (한글 번역)

arXiv:2509.14967v1 발표 유형: 신규  
초록: 수술에서의 효과적인 인간-로봇 협업은 언어적 의사소통의 본질적인 모호성에 의해 영향을 받습니다. 본 논문은 수술 현장의 시각적 맥락에 기반하여 외과의사의 언어 지시를 해석하고 모호성을 제거하는 로봇 수술 보조 시스템을 위한 프레임워크를 제시합니다. 이 시스템은 다중 모달 비전-언어 모델을 사용하여 수술 장면을 분석한 후 도구의 기능에 대한 지식 기반을 사용하여 지시를 추론하는 두 단계의 어포던스 기반 추론 과정을 채택합니다. 환자의 안전을 보장하기 위해, 이중 집합 적합 예측 방법을 사용하여 로봇 결정에 대한 통계적으로 엄격한 신뢰도를 제공함으로써 모호한 명령을 식별하고 표시할 수 있습니다. 우리는 담낭절제술 비디오에서 모호한 수술 요청의 큐레이션된 데이터 세트를 사용하여 프레임워크를 평가하였으며, 일반적인 모호성 제거율 60%를 입증하고 수술실에서의 보다 안전한 인간-로봇 상호작용 방법을 제시합니다.

## 📝 요약

이 논문은 수술 중 인간-로봇 협업에서 발생하는 언어적 모호성을 해결하기 위한 로봇 수술 보조 시스템을 제안합니다. 이 시스템은 수술 장면을 멀티모달 비전-언어 모델로 분석하고, 도구의 기능 지식을 활용하여 지시를 해석합니다. 환자 안전을 위해 이중 집합 적합 예측 방법을 사용하여 로봇 결정에 대한 신뢰도를 제공합니다. 담낭 절제술 비디오에서 수집한 모호한 수술 요청 데이터셋을 통해 평가한 결과, 60%의 일반적인 모호성 해소율을 보였습니다. 이는 수술실에서의 안전한 인간-로봇 상호작용을 위한 방법을 제시합니다.

## 🎯 주요 포인트

- 1. 이 논문은 수술 중 인간-로봇 협업에서 발생하는 언어적 모호성을 해결하기 위한 로봇 수술 보조 시스템의 프레임워크를 제시합니다.

- 2. 시스템은 수술 장면을 다중 모달 비전-언어 모델로 분석하고, 도구의 기능 지식을 활용하여 지시를 해석합니다.

- 3. 환자 안전을 위해 이중 집합 적합 예측 방법을 사용하여 로봇 결정에 대한 통계적으로 엄격한 신뢰도를 제공합니다.

- 4. 담낭절제술 비디오에서 모호한 수술 요청을 포함한 데이터셋을 통해 프레임워크를 평가한 결과, 60%의 일반적인 모호성 해소율을 보였습니다.

- 5. 이 연구는 수술실에서의 인간-로봇 상호작용을 보다 안전하게 만드는 방법을 제시합니다.

---

*Generated on 2025-09-19 16:34:36*