---
keywords:
  - Large Language Models
  - Computer Vision
  - Quasi-Experimental Design
category: cs.AI
publish_date: 2025-09-19
arxiv_id: 2509.15132
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 21:42:53.099089",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Models",
    "Computer Vision",
    "Quasi-Experimental Design"
  ],
  "rejected_keywords": [
    "Socio-environmental Legacy Effects"
  ],
  "similarity_scores": {
    "Large Language Models": 0.88,
    "Computer Vision": 0.8,
    "Quasi-Experimental Design": 0.82
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->


# From Pixels to Urban Policy-Intelligence: Recovering Legacy Effects of Redlining with a Multimodal LLM

**Korean Title:** "í”½ì…€ì—ì„œ ë„ì‹œ ì •ì±…-ì§€ëŠ¥ìœ¼ë¡œ: ë‹¤ì¤‘ ëª¨ë‹¬ LLMì„ ì‚¬ìš©í•˜ì—¬ ì ìƒ‰ì„  ì •ì±…ì˜ ìœ ì‚° íš¨ê³¼ ë³µêµ¬"

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[digests/daily_digest_20250919|2025-09-19]]   [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸŒ Broad Technical**: [[keywords/Computer Vision|street-view imagery]]
**ğŸ”— Specific Connectable**: [[keywords/Quasi-Experimental Design|quasi-experimental design]]
**ğŸš€ Evolved Concepts**: [[keywords/Large Language Models|multimodal large language model]]

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[Decoupled Proxy Alignment Mitigating Language Prior Conflict for Multimodal Alignment in MLLM]] (82.6% similar)
- [[Assessing Historical Structural Oppression Worldwide via Rule-Guided Prompting of Large Language Models_20250919|Assessing Historical Structural Oppression Worldwide via Rule-Guided Prompting of Large Language Models]] (82.3% similar)
- [[Forget What You Know about LLMs Evaluations -- LLMs are Like a Chameleon]] (82.0% similar)
- [[Middo Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning]] (81.8% similar)
- [[Modular Machine Learning An Indispensable Path towards New-Generation Large Language Models]] (81.6% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15132v1 Announce Type: cross 
Abstract: This paper shows how a multimodal large language model (MLLM) can expand urban measurement capacity and support tracking of place-based policy interventions. Using a structured, reason-then-estimate pipeline on street-view imagery, GPT-4o infers neighborhood poverty and tree canopy, which we embed in a quasi-experimental design evaluating the legacy of 1930s redlining. GPT-4o recovers the expected adverse socio-environmental legacy effects of redlining, with estimates statistically indistinguishable from authoritative sources, and it outperforms a conventional pixel-based segmentation baseline-consistent with the idea that holistic scene reasoning extracts higher-order information beyond object counts alone. These results position MLLMs as policy-grade instruments for neighborhood measurement and motivate broader validation across policy-evaluation settings.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15132v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ì´ ë…¼ë¬¸ì€ ë‹¤ì¤‘ ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(MLLM)ì´ ë„ì‹œ ì¸¡ì • ëŠ¥ë ¥ì„ í™•ì¥í•˜ê³  ì¥ì†Œ ê¸°ë°˜ ì •ì±… ê°œì…ì˜ ì¶”ì ì„ ì§€ì›í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ê±°ë¦¬ ë·° ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ êµ¬ì¡°í™”ëœ 'ì´ìœ  í›„ ì¶”ì •' íŒŒì´í”„ë¼ì¸ì„ í†µí•´ GPT-4oëŠ” ì§€ì—­ ë¹ˆê³¤ê³¼ ìˆ˜ê´€ì„ ì¶”ë¡ í•˜ë©°, ì´ë¥¼ 1930ë…„ëŒ€ ì ì„ (redlining)ì˜ ìœ ì‚°ì„ í‰ê°€í•˜ëŠ” ì¤€ì‹¤í—˜ì  ì„¤ê³„ì— í¬í•¨ì‹œí‚µë‹ˆë‹¤. GPT-4oëŠ” ì ì„ ì˜ ì˜ˆìƒë˜ëŠ” ë¶€ì •ì  ì‚¬íšŒ-í™˜ê²½ì  ìœ ì‚° íš¨ê³¼ë¥¼ íšŒë³µí•˜ë©°, ì¶”ì •ì¹˜ëŠ” ê¶Œìœ„ ìˆëŠ” ì¶œì²˜ì™€ í†µê³„ì ìœ¼ë¡œ êµ¬ë³„ë˜ì§€ ì•Šê³ , ì „í†µì ì¸ í”½ì…€ ê¸°ë°˜ ì„¸ë¶„í™” ê¸°ì¤€ì„ ëŠ¥ê°€í•©ë‹ˆë‹¤. ì´ëŠ” ì „ì²´ì ì¸ ì¥ë©´ ì¶”ë¡ ì´ ë‹¨ìˆœí•œ ê°ì²´ ìˆ˜ë¥¼ ë„˜ì–´ì„œëŠ” ê³ ì°¨ì› ì •ë³´ë¥¼ ì¶”ì¶œí•œë‹¤ëŠ” ì•„ì´ë””ì–´ì™€ ì¼ì¹˜í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ê²°ê³¼ëŠ” MLLMì„ ì§€ì—­ ì¸¡ì •ì„ ìœ„í•œ ì •ì±… ë“±ê¸‰ ë„êµ¬ë¡œ ìë¦¬ë§¤ê¹€í•˜ë©°, ì •ì±… í‰ê°€ í™˜ê²½ ì „ë°˜ì— ê±¸ì¹œ ë” ë„“ì€ ê²€ì¦ì„ ì´‰ì§„í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë‹¤ì¤‘ ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(MLLM)ì´ ë„ì‹œ ì¸¡ì • ëŠ¥ë ¥ì„ í™•ì¥í•˜ê³  ì¥ì†Œ ê¸°ë°˜ ì •ì±… ê°œì…ì„ ì¶”ì í•˜ëŠ” ë° ì–´ë–»ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆëŠ”ì§€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ê±°ë¦¬ ë·° ì´ë¯¸ì§€ë¥¼ í™œìš©í•œ êµ¬ì¡°í™”ëœ ì¶”ë¡ -ì¶”ì • íŒŒì´í”„ë¼ì¸ì„ í†µí•´ GPT-4oëŠ” ì§€ì—­ ë¹ˆê³¤ê³¼ ë‚˜ë¬´ ë®ê°œë¥¼ ì¶”ë¡ í•˜ë©°, ì´ë¥¼ 1930ë…„ëŒ€ ë ˆë“œë¼ì´ë‹ì˜ ìœ ì‚°ì„ í‰ê°€í•˜ëŠ” ì¤€ì‹¤í—˜ì  ì„¤ê³„ì— ì ìš©í•©ë‹ˆë‹¤. GPT-4oëŠ” ë ˆë“œë¼ì´ë‹ì˜ ë¶€ì •ì ì¸ ì‚¬íšŒ-í™˜ê²½ì  ìœ ì‚° íš¨ê³¼ë¥¼ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¶œì²˜ì™€ í†µê³„ì ìœ¼ë¡œ êµ¬ë³„í•  ìˆ˜ ì—†ëŠ” ìˆ˜ì¤€ìœ¼ë¡œ íšŒë³µí•˜ë©°, ì „í†µì ì¸ í”½ì…€ ê¸°ë°˜ ë¶„í•  ê¸°ë²•ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤. ì´ëŠ” MLLMì´ ì •ì±… í‰ê°€ í™˜ê²½ì—ì„œ ì´ì›ƒ ì¸¡ì •ì„ ìœ„í•œ ì •ì±… ë“±ê¸‰ ë„êµ¬ë¡œ í™œìš©ë  ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë‹¤ì¤‘ ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(MLLM)ì´ ë„ì‹œ ì¸¡ì • ëŠ¥ë ¥ì„ í™•ì¥í•˜ê³  ì¥ì†Œ ê¸°ë°˜ ì •ì±… ê°œì…ì˜ ì¶”ì ì„ ì§€ì›í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

- 2. GPT-4oëŠ” ê±°ë¦¬ ë·° ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ êµ¬ì¡°í™”ëœ ì¶”ë¡ -ì¶”ì • íŒŒì´í”„ë¼ì¸ì„ í†µí•´ ì§€ì—­ ë¹ˆê³¤ê³¼ ë‚˜ë¬´ ë®ê°œë¥¼ ì¶”ë¡ í•©ë‹ˆë‹¤.

- 3. 1930ë…„ëŒ€ ë ˆë“œë¼ì´ë‹ì˜ ìœ ì‚°ì„ í‰ê°€í•˜ëŠ” ì¤€ì‹¤í—˜ì  ì„¤ê³„ì— GPT-4oë¥¼ ì ìš©í•˜ì—¬ ì˜ˆìƒë˜ëŠ” ë¶€ì •ì ì¸ ì‚¬íšŒ-í™˜ê²½ì  ìœ ì‚° íš¨ê³¼ë¥¼ íšŒë³µí•©ë‹ˆë‹¤.

- 4. GPT-4oëŠ” ì „í†µì ì¸ í”½ì…€ ê¸°ë°˜ ì„¸ë¶„í™” ê¸°ì¤€ì„ ëŠ¥ê°€í•˜ë©°, ì´ëŠ” ì „ì²´ì ì¸ ì¥ë©´ ì¶”ë¡ ì´ ë‹¨ìˆœí•œ ê°ì²´ ìˆ˜ ì´ìƒì˜ ê³ ì°¨ ì •ë³´ë¥¼ ì¶”ì¶œí•œë‹¤ëŠ” ì•„ì´ë””ì–´ì™€ ì¼ì¹˜í•©ë‹ˆë‹¤.

- 5. MLLMì€ ì •ì±… ë“±ê¸‰ì˜ ë„êµ¬ë¡œì„œì˜ ê°€ëŠ¥ì„±ì„ ì œì‹œí•˜ë©°, ì •ì±… í‰ê°€ ì„¤ì • ì „ë°˜ì— ê±¸ì¹œ ê´‘ë²”ìœ„í•œ ê²€ì¦ì„ ì´‰ì§„í•©ë‹ˆë‹¤.

---

*Generated on 2025-09-19 16:13:01*