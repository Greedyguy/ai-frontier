
# Single- vs. Dual-Prompt Dialogue Generation with LLMs for Job Interviews in Human Resources

**Korean Title:** 단일 및 이중 프롬프트를 활용한 대규모 언어 모델(LLM)의 인사 관리 직무 면접 대화 생성 비교 연구

## 📋 메타데이터

**Links**: [[daily/2025-09-19|2025-09-19]] [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Synthetic Dialogue Generation

## 🔗 유사한 논문
- [[A Multi-To-One Interview Paradigm for Efficient MLLM Evaluation_20250919|A Multi-To-One Interview Paradigm for Efficient MLLM Evaluation]] (83.7% similar)
- [[Towards Human-like Multimodal Conversational Agent by Generating Engaging Speech_20250919|Towards Human-like Multimodal Conversational Agent by Generating Engaging Speech]] (83.3% similar)
- [[Controlling Language Difficulty in Dialogues with Linguistic Features_20250919|Controlling Language Difficulty in Dialogues with Linguistic Features]] (82.4% similar)
- [[DuetUI A Bidirectional Context Loop for Human-Agent Co-Generation of Task-Oriented Interfaces]] (81.3% similar)
- [[Process-Supervised Reinforcement Learning for Interactive Multimodal Tool-Use Agents_20250919|Process-Supervised Reinforcement Learning for Interactive Multimodal Tool-Use Agents]] (80.8% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2502.18650v2 Announce Type: replace 
Abstract: Optimizing language models for use in conversational agents requires large quantities of example dialogues. Increasingly, these dialogues are synthetically generated by using powerful large language models (LLMs), especially in domains where obtaining authentic human data is challenging. One such domain is human resources (HR). In this context, we compare two LLM-based dialogue generation methods for producing HR job interviews, and assess which method generates higher-quality dialogues, i.e., those more difficult to distinguish from genuine human discourse. The first method uses a single prompt to generate the complete interview dialogue. The second method uses two agents that converse with each other. To evaluate dialogue quality under each method, we ask a judge LLM to determine whether AI was used for interview generation, using pairwise interview comparisons. We empirically find that, at the expense of a sixfold increase in token count, interviews generated with the dual-prompt method achieve a win rate 2 to 10 times higher than those generated with the single-prompt method. This difference remains consistent regardless of whether GPT-4o or Llama 3.3 70B is used for either interview generation or quality judging.

## 🔍 Abstract (한글 번역)

arXiv:2502.18650v2 발표 유형: 교체  
초록: 대화형 에이전트에 사용하기 위한 언어 모델을 최적화하려면 대량의 예시 대화가 필요합니다. 이러한 대화는 점점 더 강력한 대형 언어 모델(LLM)을 사용하여 합성적으로 생성되며, 특히 진정한 인간 데이터를 얻기 어려운 분야에서 그렇습니다. 그러한 분야 중 하나는 인적 자원(HR)입니다. 이 맥락에서 우리는 HR 직무 인터뷰를 생성하기 위한 두 가지 LLM 기반 대화 생성 방법을 비교하고, 어떤 방법이 더 높은 품질의 대화, 즉 진정한 인간 담화와 구별하기 어려운 대화를 생성하는지를 평가합니다. 첫 번째 방법은 단일 프롬프트를 사용하여 전체 인터뷰 대화를 생성합니다. 두 번째 방법은 서로 대화하는 두 에이전트를 사용합니다. 각 방법에 따른 대화 품질을 평가하기 위해, 우리는 판사 LLM에게 인터뷰 생성에 AI가 사용되었는지를 쌍별 인터뷰 비교를 통해 판단하도록 요청합니다. 우리는 경험적으로, 토큰 수가 여섯 배 증가하는 대가를 치르더라도, 이중 프롬프트 방법으로 생성된 인터뷰가 단일 프롬프트 방법으로 생성된 인터뷰보다 2배에서 10배 더 높은 승률을 달성한다는 것을 발견했습니다. 이 차이는 인터뷰 생성이나 품질 평가에 GPT-4o 또는 Llama 3.3 70B 중 어느 것을 사용하든 일관되게 유지됩니다.

## 📝 요약

이 논문은 대화형 에이전트에 사용되는 언어 모델 최적화를 위해 HR 분야에서 대화 예시를 생성하는 두 가지 방법을 비교합니다. 첫 번째 방법은 단일 프롬프트를 사용하여 인터뷰 대화를 생성하고, 두 번째 방법은 두 에이전트가 서로 대화하는 방식입니다. 대화 품질을 평가하기 위해 판정 LLM을 사용하여 AI 사용 여부를 판단하게 했습니다. 연구 결과, 두 번째 방법이 토큰 수가 여섯 배 증가함에도 불구하고 품질 면에서 더 높은 승률을 보였습니다. 이 차이는 GPT-4o나 Llama 3.3 70B를 사용하더라도 일관되게 나타났습니다.

## 🎯 주요 포인트

- 1. 대화형 에이전트에 적합한 언어 모델 최적화를 위해 대량의 예시 대화가 필요하며, 특히 HR 분야에서는 대화의 합성 생성이 중요하다.

- 2. HR 면접 대화를 생성하기 위해 두 가지 LLM 기반 방법을 비교했으며, 두 에이전트가 대화하는 방법이 더 높은 품질의 대화를 생성한다.

- 3. 두 번째 방법은 토큰 수가 6배 증가하는 대가로, 단일 프롬프트 방법보다 2~10배 높은 승률을 기록했다.

- 4. 이 차이는 GPT-4o나 Llama 3.3 70B를 사용하더라도 일관되게 유지된다.

---

*Generated on 2025-09-19 15:58:08*