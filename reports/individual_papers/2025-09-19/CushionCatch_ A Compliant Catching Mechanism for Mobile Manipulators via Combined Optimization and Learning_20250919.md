
# CushionCatch: A Compliant Catching Mechanism for Mobile Manipulators via Combined Optimization and Learning

**Korean Title:** CushionCatch: ìµœì í™”ì™€ í•™ìŠµì„ ê²°í•©í•œ ì´ë™ ë§¤ë‹ˆí“°ë ˆì´í„°ë¥¼ ìœ„í•œ ìœ ì—°í•œ í¬íš ë©”ì»¤ë‹ˆì¦˜

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-19|2025-09-19]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: LSTM, Optimization

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[ActivePusher Active Learning and Planning with Residual Physics for Nonprehensile Manipulation]] (83.1% similar)
- [[M4Diffuser Multi-View Diffusion Policy with Manipulability-Aware Control for Robust Mobile Manipulation]] (82.8% similar)
- [[Embracing Bulky Objects with Humanoid Robots Whole-Body Manipulation with Reinforcement Learning]] (82.6% similar)
- [[One-Step Model Predictive Path Integral for Manipulator Motion Planning Using Configuration Space Distance Fields_20250918|One-Step Model Predictive Path Integral for Manipulator Motion Planning Using Configuration Space Distance Fields]] (81.9% similar)
- [[Semantic Exploration and Dense Mapping of Complex Environments using Ground Robot with Panoramic LiDAR-Camera Fusion_20250919|Semantic Exploration and Dense Mapping of Complex Environments using Ground Robot with Panoramic LiDAR-Camera Fusion]] (81.8% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2409.14754v4 Announce Type: replace 
Abstract: Catching flying objects with a cushioning process is a skill commonly performed by humans, yet it remains a significant challenge for robots. In this paper, we present a framework that combines optimization and learning to achieve compliant catching on mobile manipulators (CCMM). First, we propose a high-level capture planner for mobile manipulators (MM) that calculates the optimal capture point and joint configuration. Next, the pre-catching (PRC) planner ensures the robot reaches the target joint configuration as quickly as possible. To learn compliant catching strategies, we propose a network that leverages the strengths of LSTM for capturing temporal dependencies and positional encoding for spatial context (P-LSTM). This network is designed to effectively learn compliant strategies from human demonstrations. Following this, the post-catching (POC) planner tracks the compliant sequence output by the P-LSTM while avoiding potential collisions due to structural differences between humans and robots. We validate the CCMM framework through both simulated and real-world ball-catching scenarios, achieving a success rate of 98.70% in simulation, 92.59% in real-world tests, and a 28.7% reduction in impact torques. The open source code has be released for the reference of the community.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2409.14754v4 ë°œí‘œ ìœ í˜•: êµì²´  
ì´ˆë¡: ì¿ ì…˜ ê³¼ì •ì„ í†µí•´ ë¹„í–‰ ë¬¼ì²´ë¥¼ ì¡ëŠ” ê²ƒì€ ì¸ê°„ì´ í”íˆ ìˆ˜í–‰í•˜ëŠ” ê¸°ìˆ ì´ì§€ë§Œ, ë¡œë´‡ì—ê²ŒëŠ” ì—¬ì „íˆ ì¤‘ìš”í•œ ë„ì „ ê³¼ì œì…ë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì´ë™ ë§¤ë‹ˆí“°ë ˆì´í„°ì—ì„œ ìœ ì—°í•œ í¬íšì„ ë‹¬ì„±í•˜ê¸° ìœ„í•´ ìµœì í™”ì™€ í•™ìŠµì„ ê²°í•©í•œ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤ (CCMM). ë¨¼ì €, ì´ë™ ë§¤ë‹ˆí“°ë ˆì´í„°(MM)ë¥¼ ìœ„í•œ ê³ ìˆ˜ì¤€ í¬íš ê³„íšìë¥¼ ì œì•ˆí•˜ì—¬ ìµœì ì˜ í¬íš ì§€ì ê³¼ ê´€ì ˆ êµ¬ì„±ì„ ê³„ì‚°í•©ë‹ˆë‹¤. ë‹¤ìŒìœ¼ë¡œ, ì‚¬ì „ í¬íš(PRC) ê³„íšìëŠ” ë¡œë´‡ì´ ëª©í‘œ ê´€ì ˆ êµ¬ì„±ì— ìµœëŒ€í•œ ë¹¨ë¦¬ ë„ë‹¬í•˜ë„ë¡ ë³´ì¥í•©ë‹ˆë‹¤. ìœ ì—°í•œ í¬íš ì „ëµì„ í•™ìŠµí•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” LSTMì˜ ì‹œê°„ì  ì˜ì¡´ì„± í¬ì°© ê°•ì ê³¼ ê³µê°„ì  ë§¥ë½ì„ ìœ„í•œ ìœ„ì¹˜ ì¸ì½”ë”©ì„ í™œìš©í•˜ëŠ” ë„¤íŠ¸ì›Œí¬(P-LSTM)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ë„¤íŠ¸ì›Œí¬ëŠ” ì¸ê°„ì˜ ì‹œì—°ìœ¼ë¡œë¶€í„° ìœ ì—°í•œ ì „ëµì„ íš¨ê³¼ì ìœ¼ë¡œ í•™ìŠµí•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ì´í›„, í¬íš í›„(POC) ê³„íšìëŠ” ì¸ê°„ê³¼ ë¡œë´‡ ê°„ì˜ êµ¬ì¡°ì  ì°¨ì´ë¡œ ì¸í•œ ì ì¬ì  ì¶©ëŒì„ í”¼í•˜ë©´ì„œ P-LSTMì´ ì¶œë ¥í•œ ìœ ì—°í•œ ì‹œí€€ìŠ¤ë¥¼ ì¶”ì í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì‹œë®¬ë ˆì´ì…˜ê³¼ ì‹¤ì œ ê³µ ì¡ê¸° ì‹œë‚˜ë¦¬ì˜¤ ëª¨ë‘ì—ì„œ CCMM í”„ë ˆì„ì›Œí¬ë¥¼ ê²€ì¦í•˜ì˜€ìœ¼ë©°, ì‹œë®¬ë ˆì´ì…˜ì—ì„œ 98.70%, ì‹¤ì œ í…ŒìŠ¤íŠ¸ì—ì„œ 92.59%ì˜ ì„±ê³µë¥ ê³¼ ì¶©ê²© í† í¬ì˜ 28.7% ê°ì†Œë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. ì»¤ë®¤ë‹ˆí‹°ì˜ ì°¸ê³ ë¥¼ ìœ„í•´ ì˜¤í”ˆ ì†ŒìŠ¤ ì½”ë“œê°€ ê³µê°œë˜ì—ˆìŠµë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë¡œë´‡ì´ ë¹„í–‰ ë¬¼ì²´ë¥¼ ì¡ëŠ” ê¸°ìˆ ì„ ê°œì„ í•˜ê¸° ìœ„í•œ ìµœì í™”ì™€ í•™ìŠµì„ ê²°í•©í•œ í”„ë ˆì„ì›Œí¬(CCMM)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì£¼ìš” ê¸°ì—¬ëŠ” ëª¨ë°”ì¼ ë§¤ë‹ˆí“°ë ˆì´í„°(MM)ë¥¼ ìœ„í•œ ìµœì  ìº¡ì²˜ ì§€ì ê³¼ ê´€ì ˆ êµ¬ì„±ì„ ê³„ì‚°í•˜ëŠ” ìº¡ì²˜ í”Œë˜ë„ˆì™€ ëª©í‘œ ê´€ì ˆ êµ¬ì„±ì„ ë¹ ë¥´ê²Œ ë„ë‹¬í•˜ëŠ” ì‚¬ì „ ìº¡ì²˜(Pre-catching) í”Œë˜ë„ˆì…ë‹ˆë‹¤. ë˜í•œ, ì¸ê°„ì˜ ì‹œì—°ì„ í†µí•´ ìˆœì‘ì  ì¡ê¸° ì „ëµì„ í•™ìŠµí•˜ëŠ” P-LSTM ë„¤íŠ¸ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ë„¤íŠ¸ì›Œí¬ëŠ” LSTMê³¼ ìœ„ì¹˜ ì¸ì½”ë”©ì„ í™œìš©í•˜ì—¬ ì‹œê°„ì  ì˜ì¡´ì„±ê³¼ ê³µê°„ì  ë§¥ë½ì„ íš¨ê³¼ì ìœ¼ë¡œ í•™ìŠµí•©ë‹ˆë‹¤. ì´í›„, í¬ìŠ¤íŠ¸ ìº¡ì²˜(Post-catching) í”Œë˜ë„ˆëŠ” P-LSTMì˜ ìˆœì‘ì  ì‹œí€€ìŠ¤ë¥¼ ì¶”ì í•˜ë©° ì¶©ëŒì„ í”¼í•©ë‹ˆë‹¤. ì‹œë®¬ë ˆì´ì…˜ê³¼ ì‹¤ì œ ì‹¤í—˜ì—ì„œ ê°ê° 98.70%ì™€ 92.59%ì˜ ì„±ê³µë¥ ì„ ê¸°ë¡í–ˆìœ¼ë©°, ì¶©ê²© í† í¬ë¥¼ 28.7% ê°ì†Œì‹œì¼°ìŠµë‹ˆë‹¤. ì—°êµ¬ ê²°ê³¼ëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ë¡œ ê³µê°œë˜ì—ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì´ ë…¼ë¬¸ì€ ìµœì í™”ì™€ í•™ìŠµì„ ê²°í•©í•˜ì—¬ ëª¨ë°”ì¼ ë§¤ë‹ˆí“°ë ˆì´í„°ì—ì„œ ìœ ì—°í•œ ë¬¼ì²´ ì¡ê¸°ë¥¼ êµ¬í˜„í•˜ëŠ” í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.

- 2. ì œì•ˆëœ í”„ë ˆì„ì›Œí¬ëŠ” ìµœì ì˜ í¬íš ì§€ì ê³¼ ê´€ì ˆ êµ¬ì„±ì„ ê³„ì‚°í•˜ëŠ” ê³ ìˆ˜ì¤€ ìº¡ì²˜ ê³„íšìì™€ ëª©í‘œ ê´€ì ˆ êµ¬ì„±ì— ì‹ ì†íˆ ë„ë‹¬í•˜ëŠ” ì‚¬ì „ í¬íš ê³„íšìë¥¼ í¬í•¨í•©ë‹ˆë‹¤.

- 3. ì¸ê°„ì˜ ì‹œì—°ì—ì„œ ìœ ì—°í•œ ì¡ê¸° ì „ëµì„ í•™ìŠµí•˜ê¸° ìœ„í•´ LSTMê³¼ ìœ„ì¹˜ ì¸ì½”ë”©ì„ í™œìš©í•œ ë„¤íŠ¸ì›Œí¬(P-LSTM)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.

- 4. ì œì•ˆëœ CCMM í”„ë ˆì„ì›Œí¬ëŠ” ì‹œë®¬ë ˆì´ì…˜ì—ì„œ 98.70%, ì‹¤ì œ í…ŒìŠ¤íŠ¸ì—ì„œ 92.59%ì˜ ì„±ê³µë¥ ì„ ë‹¬ì„±í–ˆìœ¼ë©°, ì¶©ê²© í† í¬ë¥¼ 28.7% ê°ì†Œì‹œì¼°ìŠµë‹ˆë‹¤.

- 5. ì´ ì—°êµ¬ì˜ ì˜¤í”ˆ ì†ŒìŠ¤ ì½”ë“œëŠ” ì»¤ë®¤ë‹ˆí‹°ì˜ ì°¸ì¡°ë¥¼ ìœ„í•´ ê³µê°œë˜ì—ˆìŠµë‹ˆë‹¤.

---

*Generated on 2025-09-19 16:37:32*