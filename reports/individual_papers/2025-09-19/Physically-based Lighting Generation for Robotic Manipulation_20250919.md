---
keywords:
  - Diffusion Models
  - Robotic Manipulation
  - Imitation Learning
category: cs.AI
publish_date: 2025-09-19
arxiv_id: 2508.01442
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 21:29:24.515515",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Diffusion Models",
    "Robotic Manipulation",
    "Imitation Learning"
  ],
  "rejected_keywords": [
    "Inverse Rendering"
  ],
  "similarity_scores": {
    "Diffusion Models": 0.85,
    "Robotic Manipulation": 0.82,
    "Imitation Learning": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->


# Physically-based Lighting Generation for Robotic Manipulation

**Korean Title:** ë¬¼ë¦¬ ê¸°ë°˜ ì¡°ëª… ìƒì„±ì˜ ë¡œë´‡ ì¡°ì‘ì—ì˜ ì‘ìš©

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[digests/daily_digest_20250919|2025-09-19]]   [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Robotic Manipulation|robotic manipulation]], [[keywords/Imitation Learning|imitation learning]]

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[PhysicalAgent Towards General Cognitive Robotics with Foundation World Models]] (85.7% similar)
- [[textsc{Gen2Real} Towards Demo-Free Dexterous Manipulation by Harnessing Generated Video]] (83.7% similar)
- [[LLM-I LLMs are Naturally Interleaved Multimodal Creators]] (80.9% similar)
- [[M4Diffuser Multi-View Diffusion Policy with Manipulability-Aware Control for Robust Mobile Manipulation]] (80.7% similar)
- [[WorldForge Unlocking Emergent 3D4D Generation in Video Diffusion Model via Training-Free Guidance]] (80.5% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2508.01442v2 Announce Type: replace 
Abstract: In this paper, we propose the first framework that leverages physically-based inverse rendering for novel lighting generation on existing real-world human demonstrations of robotic manipulation tasks. Specifically, inverse rendering decomposes the first frame in each demonstration into geometric (surface normal, depth) and material (albedo, roughness, metallic) properties, which are then used to render appearance changes under different lighting sources. To improve efficiency and maintain consistency across each generated sequence, we fine-tune Stable Video Diffusion on robot execution videos for temporal lighting propagation. We evaluate our framework by measuring the visual quality of the generated sequences, assessing its effectiveness in improving the imitation learning policy performance (38.75\%) under six unseen real-world lighting conditions, and conduct ablation studies on individual modules of the proposed framework. We further showcase three downstream applications enabled by the proposed framework: background generation, object texture generation and distractor positioning. The code for the framework will be made publicly available.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2508.01442v2 ë°œí‘œ ìœ í˜•: êµì²´  
ì´ˆë¡: ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ë¡œë´‡ ì¡°ì‘ ì‘ì—…ì˜ ê¸°ì¡´ ì‹¤ì œ ì‹œì—°ì—ì„œ ìƒˆë¡œìš´ ì¡°ëª… ìƒì„±ì„ ìœ„í•´ ë¬¼ë¦¬ ê¸°ë°˜ì˜ ì—­ ë Œë”ë§ì„ í™œìš©í•˜ëŠ” ìµœì´ˆì˜ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. êµ¬ì²´ì ìœ¼ë¡œ, ì—­ ë Œë”ë§ì€ ê° ì‹œì—°ì˜ ì²« ë²ˆì§¸ í”„ë ˆì„ì„ ê¸°í•˜í•™ì (í‘œë©´ ë²•ì„ , ê¹Šì´) ë° ë¬¼ì§ˆì (ë°˜ì‚¬ìœ¨, ê±°ì¹ ê¸°, ê¸ˆì†ì„±) ì†ì„±ìœ¼ë¡œ ë¶„í•´í•˜ì—¬, ì´ë¥¼ ë‹¤ì–‘í•œ ì¡°ëª… ì†ŒìŠ¤ í•˜ì—ì„œì˜ ì™¸ê´€ ë³€í™”ë¥¼ ë Œë”ë§í•˜ëŠ” ë° ì‚¬ìš©í•©ë‹ˆë‹¤. ê° ìƒì„±ëœ ì‹œí€€ìŠ¤ì˜ íš¨ìœ¨ì„±ì„ ë†’ì´ê³  ì¼ê´€ì„±ì„ ìœ ì§€í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ë¡œë´‡ ì‹¤í–‰ ë¹„ë””ì˜¤ì—ì„œ ì‹œê°„ì  ì¡°ëª… ì „íŒŒë¥¼ ìœ„í•´ ì•ˆì •ì ì¸ ë¹„ë””ì˜¤ í™•ì‚°ì„ ë¯¸ì„¸ ì¡°ì •í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ìƒì„±ëœ ì‹œí€€ìŠ¤ì˜ ì‹œê°ì  í’ˆì§ˆì„ ì¸¡ì •í•˜ê³ , ì—¬ì„¯ ê°€ì§€ ë³´ì§€ ëª»í•œ ì‹¤ì œ ì¡°ëª… ì¡°ê±´ì—ì„œ ëª¨ë°© í•™ìŠµ ì •ì±… ì„±ëŠ¥ì„ 38.75% í–¥ìƒì‹œí‚¤ëŠ” íš¨ê³¼ë¥¼ í‰ê°€í•˜ë©°, ì œì•ˆëœ í”„ë ˆì„ì›Œí¬ì˜ ê°œë³„ ëª¨ë“ˆì— ëŒ€í•œ ì†Œê±° ì—°êµ¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤. ë˜í•œ, ì œì•ˆëœ í”„ë ˆì„ì›Œí¬ê°€ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ì„¸ ê°€ì§€ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ìš© í”„ë¡œê·¸ë¨ì¸ ë°°ê²½ ìƒì„±, ê°ì²´ í…ìŠ¤ì²˜ ìƒì„± ë° ë°©í•´ë¬¼ ë°°ì¹˜ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. í”„ë ˆì„ì›Œí¬ì˜ ì½”ë“œëŠ” ê³µê°œì ìœ¼ë¡œ ì œê³µë  ì˜ˆì •ì…ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì—ì„œëŠ” ë¡œë´‡ ì¡°ì‘ ì‘ì—…ì˜ ì‹¤ì œ ì‹œì—°ì—ì„œ ìƒˆë¡œìš´ ì¡°ëª… ìƒì„±ì„ ìœ„í•´ ë¬¼ë¦¬ ê¸°ë°˜ì˜ ì—­ ë Œë”ë§ì„ í™œìš©í•˜ëŠ” ìµœì´ˆì˜ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì—­ ë Œë”ë§ì€ ì‹œì—°ì˜ ì²« í”„ë ˆì„ì„ ê¸°í•˜í•™ì (í‘œë©´ ë²•ì„ , ê¹Šì´) ë° ì¬ì§ˆ(ë°˜ì‚¬ìœ¨, ê±°ì¹ ê¸°, ê¸ˆì†ì„±) ì†ì„±ìœ¼ë¡œ ë¶„í•´í•˜ì—¬ ë‹¤ì–‘í•œ ì¡°ëª… ì¡°ê±´ì—ì„œì˜ ì™¸ê´€ ë³€í™”ë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤. íš¨ìœ¨ì„±ì„ ë†’ì´ê³  ì¼ê´€ì„±ì„ ìœ ì§€í•˜ê¸° ìœ„í•´ ë¡œë´‡ ì‹¤í–‰ ë¹„ë””ì˜¤ì—ì„œ ì•ˆì •ì ì¸ ë¹„ë””ì˜¤ í™•ì‚° ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ì—¬ ì‹œê°„ì  ì¡°ëª… ì „íŒŒë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì œì•ˆëœ í”„ë ˆì„ì›Œí¬ëŠ” ìƒì„±ëœ ì‹œí€€ìŠ¤ì˜ ì‹œê°ì  í’ˆì§ˆì„ í‰ê°€í•˜ê³ , ì—¬ì„¯ ê°€ì§€ ìƒˆë¡œìš´ ì¡°ëª… ì¡°ê±´ì—ì„œ ëª¨ë°© í•™ìŠµ ì •ì±… ì„±ëŠ¥ì„ 38.75% í–¥ìƒì‹œí‚¤ëŠ” íš¨ê³¼ë¥¼ ì…ì¦í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, í”„ë ˆì„ì›Œí¬ì˜ ê°œë³„ ëª¨ë“ˆì— ëŒ€í•œ ì†Œê±° ì—°êµ¬ë¥¼ ìˆ˜í–‰í•˜ê³ , ë°°ê²½ ìƒì„±, ê°ì²´ í…ìŠ¤ì²˜ ìƒì„±, ë°©í•´ë¬¼ ë°°ì¹˜ì™€ ê°™ì€ ì„¸ ê°€ì§€ ì‘ìš© ì‚¬ë¡€ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. í”„ë ˆì„ì›Œí¬ì˜ ì½”ë“œëŠ” ê³µê°œë  ì˜ˆì •ì…ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë¬¼ë¦¬ ê¸°ë°˜ ì—­ ë Œë”ë§ì„ í™œìš©í•˜ì—¬ ë¡œë´‡ ì¡°ì‘ ì‘ì—…ì˜ ìƒˆë¡œìš´ ì¡°ëª… ìƒì„± í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí–ˆìŠµë‹ˆë‹¤.

- 2. ì—­ ë Œë”ë§ì€ ì‹œì—°ì˜ ì²« í”„ë ˆì„ì„ ê¸°í•˜í•™ì  ë° ë¬¼ì§ˆì  ì†ì„±ìœ¼ë¡œ ë¶„í•´í•˜ì—¬ ë‹¤ì–‘í•œ ì¡°ëª… ì¡°ê±´ì—ì„œ ì™¸ê´€ ë³€í™”ë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤.

- 3. ë¡œë´‡ ì‹¤í–‰ ë¹„ë””ì˜¤ì—ì„œ ì•ˆì •ì ì¸ ë¹„ë””ì˜¤ í™•ì‚°ì„ ë¯¸ì„¸ ì¡°ì •í•˜ì—¬ ìƒì„±ëœ ì‹œí€€ìŠ¤ì˜ íš¨ìœ¨ì„±ê³¼ ì¼ê´€ì„±ì„ ê°œì„ í–ˆìŠµë‹ˆë‹¤.

- 4. ì œì•ˆëœ í”„ë ˆì„ì›Œí¬ëŠ” 6ê°€ì§€ ìƒˆë¡œìš´ ì‹¤ì œ ì¡°ëª… ì¡°ê±´ì—ì„œ ëª¨ë°© í•™ìŠµ ì •ì±… ì„±ëŠ¥ì„ 38.75% í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.

- 5. ì œì•ˆëœ í”„ë ˆì„ì›Œí¬ë¥¼ í†µí•´ ë°°ê²½ ìƒì„±, ê°ì²´ í…ìŠ¤ì²˜ ìƒì„± ë° ë°©í•´ë¬¼ ìœ„ì¹˜ ì§€ì •ê³¼ ê°™ì€ ì„¸ ê°€ì§€ ì‘ìš© í”„ë¡œê·¸ë¨ì„ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

*Generated on 2025-09-19 16:38:21*