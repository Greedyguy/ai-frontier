---
keywords:
  - Foundation Models
  - Affective Computing
  - Audio Effects
category: cs.AI
publish_date: 2025-09-19
arxiv_id: 2509.15151
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 21:44:38.572442",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Foundation Models",
    "Affective Computing",
    "Audio Effects"
  ],
  "rejected_keywords": [
    "Deep Learning"
  ],
  "similarity_scores": {
    "Foundation Models": 0.8,
    "Affective Computing": 0.77,
    "Audio Effects": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->


# Exploring How Audio Effects Alter Emotion with Foundation Models

**Korean Title:** ì˜¤ë””ì˜¤ íš¨ê³¼ê°€ ê°ì •ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ê¸°ì´ˆ ëª¨ë¸ì„ í†µí•´ íƒêµ¬í•˜ê¸°

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[digests/daily_digest_20250919|2025-09-19]]   [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Affective Computing|affective computing]]
**âš¡ Unique Technical**: [[keywords/Audio Effects|audio effects]]
**ğŸš€ Evolved Concepts**: [[keywords/Foundation Models|foundation models]]

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[Mixture of Low-Rank Adapter Experts in Generalizable Audio Deepfake Detection]] (77.5% similar)
- [[Empowering Time Series Analysis with Foundation Models A Comprehensive Survey]] (75.4% similar)
- [[An_Attention-Based_Denoising_Framework_for_Personality_Detection_in_Social_Media_Texts_20250918|An Attention-Based Denoising Framework for Personality Detection in Social Media Texts]] (73.9% similar)
- [[Cross-Modal_Knowledge_Distillation_for_Speech_Large_Language_Models_20250919|Cross-Modal Knowledge Distillation for Speech Large Language Models]] (73.5% similar)
- [[Omni-CLST Error-aware Curriculum Learning with guided Selective chain-of-Thought for audio question answering]] (73.4% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15151v1 Announce Type: cross 
Abstract: Audio effects (FX) such as reverberation, distortion, modulation, and dynamic range processing play a pivotal role in shaping emotional responses during music listening. While prior studies have examined links between low-level audio features and affective perception, the systematic impact of audio FX on emotion remains underexplored. This work investigates how foundation models - large-scale neural architectures pretrained on multimodal data - can be leveraged to analyze these effects. Such models encode rich associations between musical structure, timbre, and affective meaning, offering a powerful framework for probing the emotional consequences of sound design techniques. By applying various probing methods to embeddings from deep learning models, we examine the complex, nonlinear relationships between audio FX and estimated emotion, uncovering patterns tied to specific effects and evaluating the robustness of foundation audio models. Our findings aim to advance understanding of the perceptual impact of audio production practices, with implications for music cognition, performance, and affective computing.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15151v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ì”í–¥, ì™œê³¡, ë³€ì¡°, ë™ì  ë²”ìœ„ ì²˜ë¦¬ì™€ ê°™ì€ ì˜¤ë””ì˜¤ íš¨ê³¼(FX)ëŠ” ìŒì•… ê°ìƒ ì¤‘ ê°ì •ì  ë°˜ì‘ì„ í˜•ì„±í•˜ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤. ì´ì „ ì—°êµ¬ì—ì„œëŠ” ì €ìˆ˜ì¤€ ì˜¤ë””ì˜¤ íŠ¹ì§•ê³¼ ê°ì •ì  ì¸ì‹ ê°„ì˜ ì—°ê´€ì„±ì„ ì¡°ì‚¬í–ˆì§€ë§Œ, ì˜¤ë””ì˜¤ FXê°€ ê°ì •ì— ë¯¸ì¹˜ëŠ” ì²´ê³„ì ì¸ ì˜í–¥ì€ ì¶©ë¶„íˆ íƒêµ¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ëŠ” ëŒ€ê·œëª¨ ì‹ ê²½ ì•„í‚¤í…ì²˜ë¡œì„œ ë‹¤ì¤‘ ëª¨ë‹¬ ë°ì´í„°ì— ì‚¬ì „ í•™ìŠµëœ ê¸°ì´ˆ ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ì´ëŸ¬í•œ íš¨ê³¼ë¥¼ ë¶„ì„í•˜ëŠ” ë°©ë²•ì„ ì¡°ì‚¬í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ëª¨ë¸ì€ ìŒì•… êµ¬ì¡°, ìŒìƒ‰, ê°ì •ì  ì˜ë¯¸ ê°„ì˜ í’ë¶€í•œ ì—°ê´€ì„±ì„ ì¸ì½”ë”©í•˜ì—¬ ì‚¬ìš´ë“œ ë””ìì¸ ê¸°ë²•ì˜ ê°ì •ì  ê²°ê³¼ë¥¼ íƒêµ¬í•˜ëŠ” ê°•ë ¥í•œ í”„ë ˆì„ì›Œí¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ ì„ë² ë”©ì— ë‹¤ì–‘í•œ íƒìƒ‰ ë°©ë²•ì„ ì ìš©í•¨ìœ¼ë¡œì¨, ì˜¤ë””ì˜¤ FXì™€ ì¶”ì •ëœ ê°ì • ê°„ì˜ ë³µì¡í•˜ê³  ë¹„ì„ í˜•ì ì¸ ê´€ê³„ë¥¼ ì¡°ì‚¬í•˜ê³ , íŠ¹ì • íš¨ê³¼ì™€ ê´€ë ¨ëœ íŒ¨í„´ì„ ë°í˜€ë‚´ë©°, ê¸°ì´ˆ ì˜¤ë””ì˜¤ ëª¨ë¸ì˜ ê²¬ê³ ì„±ì„ í‰ê°€í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì—°êµ¬ ê²°ê³¼ëŠ” ìŒì•… ì¸ì§€, ê³µì—°, ê°ì • ì»´í“¨íŒ…ì— ëŒ€í•œ í•¨ì˜ë¥¼ í†µí•´ ì˜¤ë””ì˜¤ ì œì‘ ê´€í–‰ì˜ ì§€ê°ì  ì˜í–¥ì„ ì´í•´í•˜ëŠ” ë° ê¸°ì—¬í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” ì˜¤ë””ì˜¤ íš¨ê³¼(FX)ê°€ ìŒì•… ê°ìƒ ì‹œ ê°ì •ì  ë°˜ì‘ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì¡°ì‚¬í•©ë‹ˆë‹¤. ê¸°ì¡´ ì—°êµ¬ëŠ” ì €ìˆ˜ì¤€ì˜ ì˜¤ë””ì˜¤ íŠ¹ì§•ê³¼ ê°ì • ì¸ì‹ì„ ë‹¤ë£¨ì—ˆì§€ë§Œ, ì˜¤ë””ì˜¤ FXì˜ ì²´ê³„ì ì¸ ê°ì •ì  ì˜í–¥ì€ ì¶©ë¶„íˆ íƒêµ¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ëŠ” ëŒ€ê·œëª¨ ë©€í‹°ëª¨ë‹¬ ë°ì´í„°ë¡œ ì‚¬ì „ í•™ìŠµëœ ê¸°ì´ˆ ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ì´ëŸ¬í•œ íš¨ê³¼ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ëª¨ë¸ì€ ìŒì•… êµ¬ì¡°, ìŒìƒ‰, ê°ì •ì  ì˜ë¯¸ ê°„ì˜ í’ë¶€í•œ ì—°ê´€ì„±ì„ ì¸ì½”ë”©í•˜ì—¬ ì‚¬ìš´ë“œ ë””ìì¸ ê¸°ìˆ ì˜ ê°ì •ì  ê²°ê³¼ë¥¼ íƒêµ¬í•˜ëŠ” ê°•ë ¥í•œ í‹€ì„ ì œê³µí•©ë‹ˆë‹¤. ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ ì„ë² ë”©ì— ë‹¤ì–‘í•œ íƒìƒ‰ ë°©ë²•ì„ ì ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ FXì™€ ì¶”ì •ëœ ê°ì • ê°„ì˜ ë³µì¡í•˜ê³  ë¹„ì„ í˜•ì ì¸ ê´€ê³„ë¥¼ ì¡°ì‚¬í•˜ê³ , íŠ¹ì • íš¨ê³¼ì™€ ê´€ë ¨ëœ íŒ¨í„´ì„ ë°œê²¬í•˜ë©°, ê¸°ì´ˆ ì˜¤ë””ì˜¤ ëª¨ë¸ì˜ ê²¬ê³ ì„±ì„ í‰ê°€í•©ë‹ˆë‹¤. ì—°êµ¬ ê²°ê³¼ëŠ” ìŒì•… ì¸ì§€, ê³µì—°, ê°ì • ì»´í“¨íŒ…ì— ëŒ€í•œ ì´í•´ë¥¼ ì¦ì§„ì‹œí‚¤ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì˜¤ë””ì˜¤ íš¨ê³¼(FX)ëŠ” ìŒì•… ê°ìƒ ì‹œ ê°ì •ì  ë°˜ì‘ì„ í˜•ì„±í•˜ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í•œë‹¤.

- 2. ê¸°ì¡´ ì—°êµ¬ì—ì„œëŠ” ì €ìˆ˜ì¤€ ì˜¤ë””ì˜¤ íŠ¹ì§•ê³¼ ê°ì •ì  ì§€ê° ê°„ì˜ ì—°ê´€ì„±ì„ íƒêµ¬í–ˆì§€ë§Œ, ì˜¤ë””ì˜¤ FXê°€ ê°ì •ì— ë¯¸ì¹˜ëŠ” ì²´ê³„ì ì¸ ì˜í–¥ì€ ì¶©ë¶„íˆ ì—°êµ¬ë˜ì§€ ì•Šì•˜ë‹¤.

- 3. ë³¸ ì—°êµ¬ëŠ” ëŒ€ê·œëª¨ ì‹ ê²½ ì•„í‚¤í…ì²˜ì¸ ê¸°ì´ˆ ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ì˜¤ë””ì˜¤ FXì™€ ê°ì • ê°„ì˜ ë³µì¡í•˜ê³  ë¹„ì„ í˜•ì ì¸ ê´€ê³„ë¥¼ ë¶„ì„í•œë‹¤.

- 4. ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ ì„ë² ë”©ì— ë‹¤ì–‘í•œ í”„ë¡œë¹™ ë°©ë²•ì„ ì ìš©í•˜ì—¬ íŠ¹ì • íš¨ê³¼ì™€ ê´€ë ¨ëœ íŒ¨í„´ì„ ë°œê²¬í•˜ê³  ê¸°ì´ˆ ì˜¤ë””ì˜¤ ëª¨ë¸ì˜ ê²¬ê³ ì„±ì„ í‰ê°€í•œë‹¤.

- 5. ì—°êµ¬ ê²°ê³¼ëŠ” ìŒì•… ì¸ì§€, ê³µì—°, ê°ì • ì»´í“¨íŒ… ë¶„ì•¼ì— ëŒ€í•œ ì˜¤ë””ì˜¤ ì œì‘ ê´€í–‰ì˜ ì§€ê°ì  ì˜í–¥ì„ ì´í•´í•˜ëŠ” ë° ê¸°ì—¬í•œë‹¤.

---

*Generated on 2025-09-19 15:06:52*