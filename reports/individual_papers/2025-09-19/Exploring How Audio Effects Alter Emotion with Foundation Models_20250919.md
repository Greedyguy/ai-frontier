---
keywords:
  - Foundation Models
  - Affective Computing
  - Audio Effects
category: cs.AI
publish_date: 2025-09-19
arxiv_id: 2509.15151
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 21:44:38.572442",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Foundation Models",
    "Affective Computing",
    "Audio Effects"
  ],
  "rejected_keywords": [
    "Deep Learning"
  ],
  "similarity_scores": {
    "Foundation Models": 0.8,
    "Affective Computing": 0.77,
    "Audio Effects": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->


# Exploring How Audio Effects Alter Emotion with Foundation Models

**Korean Title:** 오디오 효과가 감정에 미치는 영향을 기초 모델을 통해 탐구하기

## 📋 메타데이터

**Links**: [[digests/daily_digest_20250919|2025-09-19]]   [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Affective Computing|affective computing]]
**⚡ Unique Technical**: [[keywords/Audio Effects|audio effects]]
**🚀 Evolved Concepts**: [[keywords/Foundation Models|foundation models]]

## 🔗 유사한 논문
- [[Mixture of Low-Rank Adapter Experts in Generalizable Audio Deepfake Detection]] (77.5% similar)
- [[Empowering Time Series Analysis with Foundation Models A Comprehensive Survey]] (75.4% similar)
- [[An_Attention-Based_Denoising_Framework_for_Personality_Detection_in_Social_Media_Texts_20250918|An Attention-Based Denoising Framework for Personality Detection in Social Media Texts]] (73.9% similar)
- [[Cross-Modal_Knowledge_Distillation_for_Speech_Large_Language_Models_20250919|Cross-Modal Knowledge Distillation for Speech Large Language Models]] (73.5% similar)
- [[Omni-CLST Error-aware Curriculum Learning with guided Selective chain-of-Thought for audio question answering]] (73.4% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.15151v1 Announce Type: cross 
Abstract: Audio effects (FX) such as reverberation, distortion, modulation, and dynamic range processing play a pivotal role in shaping emotional responses during music listening. While prior studies have examined links between low-level audio features and affective perception, the systematic impact of audio FX on emotion remains underexplored. This work investigates how foundation models - large-scale neural architectures pretrained on multimodal data - can be leveraged to analyze these effects. Such models encode rich associations between musical structure, timbre, and affective meaning, offering a powerful framework for probing the emotional consequences of sound design techniques. By applying various probing methods to embeddings from deep learning models, we examine the complex, nonlinear relationships between audio FX and estimated emotion, uncovering patterns tied to specific effects and evaluating the robustness of foundation audio models. Our findings aim to advance understanding of the perceptual impact of audio production practices, with implications for music cognition, performance, and affective computing.

## 🔍 Abstract (한글 번역)

arXiv:2509.15151v1 발표 유형: 교차  
초록: 잔향, 왜곡, 변조, 동적 범위 처리와 같은 오디오 효과(FX)는 음악 감상 중 감정적 반응을 형성하는 데 중요한 역할을 합니다. 이전 연구에서는 저수준 오디오 특징과 감정적 인식 간의 연관성을 조사했지만, 오디오 FX가 감정에 미치는 체계적인 영향은 충분히 탐구되지 않았습니다. 본 연구는 대규모 신경 아키텍처로서 다중 모달 데이터에 사전 학습된 기초 모델을 활용하여 이러한 효과를 분석하는 방법을 조사합니다. 이러한 모델은 음악 구조, 음색, 감정적 의미 간의 풍부한 연관성을 인코딩하여 사운드 디자인 기법의 감정적 결과를 탐구하는 강력한 프레임워크를 제공합니다. 딥러닝 모델의 임베딩에 다양한 탐색 방법을 적용함으로써, 오디오 FX와 추정된 감정 간의 복잡하고 비선형적인 관계를 조사하고, 특정 효과와 관련된 패턴을 밝혀내며, 기초 오디오 모델의 견고성을 평가합니다. 우리의 연구 결과는 음악 인지, 공연, 감정 컴퓨팅에 대한 함의를 통해 오디오 제작 관행의 지각적 영향을 이해하는 데 기여하는 것을 목표로 합니다.

## 📝 요약

이 연구는 오디오 효과(FX)가 음악 감상 시 감정적 반응에 미치는 영향을 조사합니다. 기존 연구는 저수준의 오디오 특징과 감정 인식을 다루었지만, 오디오 FX의 체계적인 감정적 영향은 충분히 탐구되지 않았습니다. 본 연구는 대규모 멀티모달 데이터로 사전 학습된 기초 모델을 활용하여 이러한 효과를 분석합니다. 이러한 모델은 음악 구조, 음색, 감정적 의미 간의 풍부한 연관성을 인코딩하여 사운드 디자인 기술의 감정적 결과를 탐구하는 강력한 틀을 제공합니다. 딥러닝 모델의 임베딩에 다양한 탐색 방법을 적용하여 오디오 FX와 추정된 감정 간의 복잡하고 비선형적인 관계를 조사하고, 특정 효과와 관련된 패턴을 발견하며, 기초 오디오 모델의 견고성을 평가합니다. 연구 결과는 음악 인지, 공연, 감정 컴퓨팅에 대한 이해를 증진시키는 것을 목표로 합니다.

## 🎯 주요 포인트

- 1. 오디오 효과(FX)는 음악 감상 시 감정적 반응을 형성하는 데 중요한 역할을 한다.

- 2. 기존 연구에서는 저수준 오디오 특징과 감정적 지각 간의 연관성을 탐구했지만, 오디오 FX가 감정에 미치는 체계적인 영향은 충분히 연구되지 않았다.

- 3. 본 연구는 대규모 신경 아키텍처인 기초 모델을 활용하여 오디오 FX와 감정 간의 복잡하고 비선형적인 관계를 분석한다.

- 4. 딥러닝 모델의 임베딩에 다양한 프로빙 방법을 적용하여 특정 효과와 관련된 패턴을 발견하고 기초 오디오 모델의 견고성을 평가한다.

- 5. 연구 결과는 음악 인지, 공연, 감정 컴퓨팅 분야에 대한 오디오 제작 관행의 지각적 영향을 이해하는 데 기여한다.

---

*Generated on 2025-09-19 15:06:52*