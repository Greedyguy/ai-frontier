---
keywords:
  - Human-in-the-Loop
  - Semantic SLAM
  - Graph-based Semantic Fusion
category: cs.AI
publish_date: 2025-09-19
arxiv_id: 2509.14949
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 21:40:28.795690",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Human-in-the-Loop",
    "Semantic SLAM",
    "Graph-based Semantic Fusion"
  ],
  "rejected_keywords": [
    "Extended Reality"
  ],
  "similarity_scores": {
    "Human-in-the-Loop": 0.79,
    "Semantic SLAM": 0.78,
    "Graph-based Semantic Fusion": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->


# Human Interaction for Collaborative Semantic SLAM using Extended Reality

**Korean Title:** 인간 상호작용을 통한 협업적 의미론적 SLAM을 위한 확장 현실 활용

## 📋 메타데이터

**Links**: [[digests/daily_digest_20250919|2025-09-19]]   [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**⚡ Unique Technical**: [[keywords/Semantic SLAM|Semantic SLAM]], [[keywords/Graph-based Semantic Fusion|Graph-based Semantic Fusion]]
**🚀 Evolved Concepts**: [[keywords/Human-in-the-Loop|Human-in-the-Loop]]

## 🔗 유사한 논문
- [[BIM Informed Visual SLAM for Construction Monitoring_20250918|BIM Informed Visual SLAM for Construction Monitoring]] (83.3% similar)
- [[Semantic Exploration and Dense Mapping of Complex Environments using Ground Robot with Panoramic LiDAR-Camera Fusion_20250919|Semantic Exploration and Dense Mapping of Complex Environments using Ground Robot with Panoramic LiDAR-Camera Fusion]] (82.1% similar)
- [[FSR-VLN Fast and Slow Reasoning for Vision-Language Navigation with Hierarchical Multi-modal Scene Graph]] (80.4% similar)
- [[MCGS-SLAM A Multi-Camera SLAM Framework Using Gaussian Splatting for High-Fidelity Mapping]] (80.4% similar)
- [[Embracing Bulky Objects with Humanoid Robots Whole-Body Manipulation with Reinforcement Learning]] (78.9% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.14949v1 Announce Type: new 
Abstract: Semantic SLAM (Simultaneous Localization and Mapping) systems enrich robot maps with structural and semantic information, enabling robots to operate more effectively in complex environments. However, these systems struggle in real-world scenarios with occlusions, incomplete data, or ambiguous geometries, as they cannot fully leverage the higher-level spatial and semantic knowledge humans naturally apply. We introduce HICS-SLAM, a Human-in-the-Loop semantic SLAM framework that uses a shared extended reality environment for real-time collaboration. The system allows human operators to directly interact with and visualize the robot's 3D scene graph, and add high-level semantic concepts (e.g., rooms or structural entities) into the mapping process. We propose a graph-based semantic fusion methodology that integrates these human interventions with robot perception, enabling scalable collaboration for enhanced situational awareness. Experimental evaluations on real-world construction site datasets demonstrate improvements in room detection accuracy, map precision, and semantic completeness compared to automated baselines, demonstrating both the effectiveness of the approach and its potential for future extensions.

## 🔍 Abstract (한글 번역)

arXiv:2509.14949v1 발표 유형: 신규  
초록: 의미론적 SLAM(동시 위치 추정 및 지도 작성) 시스템은 로봇 지도를 구조적 및 의미론적 정보로 풍부하게 하여 로봇이 복잡한 환경에서 보다 효과적으로 작동할 수 있도록 합니다. 그러나 이러한 시스템은 가림, 불완전한 데이터 또는 모호한 기하학적 형태가 있는 실제 시나리오에서 어려움을 겪습니다. 이는 인간이 자연스럽게 적용하는 고차원 공간 및 의미론적 지식을 완전히 활용할 수 없기 때문입니다. 우리는 실시간 협업을 위한 공유 확장 현실 환경을 사용하는 인간 참여형 의미론적 SLAM 프레임워크인 HICS-SLAM을 소개합니다. 이 시스템은 인간 운영자가 로봇의 3D 장면 그래프와 직접 상호 작용하고 시각화하며, 고차원 의미론적 개념(예: 방 또는 구조적 엔티티)을 매핑 프로세스에 추가할 수 있도록 합니다. 우리는 이러한 인간 개입을 로봇의 인식과 통합하는 그래프 기반 의미 융합 방법론을 제안하여 상황 인식 향상을 위한 확장 가능한 협업을 가능하게 합니다. 실제 건설 현장 데이터셋에 대한 실험적 평가 결과, 자동화된 기준선과 비교하여 방 탐지 정확도, 지도 정밀도 및 의미론적 완전성이 개선되어 접근 방식의 효과와 향후 확장의 잠재력을 입증합니다.

## 📝 요약

이 논문은 HICS-SLAM이라는 인간 참여형 시맨틱 SLAM 프레임워크를 제안합니다. 이 시스템은 확장 현실 환경을 통해 인간 운영자가 로봇의 3D 장면 그래프와 상호작용하고, 고급 시맨틱 개념을 매핑 과정에 추가할 수 있도록 합니다. 제안된 그래프 기반 시맨틱 융합 방법론은 인간의 개입을 로봇의 인식과 통합하여 상황 인식을 향상시킵니다. 실제 건설 현장 데이터셋을 활용한 실험 결과, 이 시스템이 방 탐지 정확도, 지도 정밀도, 시맨틱 완전성에서 자동화된 기준보다 개선된 성능을 보였습니다.

## 🎯 주요 포인트

- 1. HICS-SLAM은 인간과 로봇 간의 실시간 협업을 위한 확장 현실 환경을 활용하는 인간 참여형 시맨틱 SLAM 프레임워크입니다.

- 2. 이 시스템은 인간 운영자가 로봇의 3D 장면 그래프와 직접 상호작용하고, 고수준의 시맨틱 개념을 매핑 과정에 추가할 수 있도록 합니다.

- 3. 제안된 그래프 기반 시맨틱 융합 방법론은 인간의 개입을 로봇의 인식과 통합하여 상황 인식을 향상시키고 협업을 확장할 수 있게 합니다.

- 4. 실제 건설 현장 데이터셋을 통한 실험 평가에서, HICS-SLAM은 자동화된 기준선과 비교하여 방 탐지 정확도, 지도 정밀도, 시맨틱 완전성에서 개선을 보여주었습니다.

- 5. 이 접근 방식은 효과적일 뿐만 아니라 향후 확장의 가능성도 보여줍니다.

---

*Generated on 2025-09-19 16:34:11*