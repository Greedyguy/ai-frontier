
# When Content is Goliath and Algorithm is David: The Style and Semantic Effects of Generative Search Engine

**Korean Title:** 콘텐츠가 골리앗이고 알고리즘이 다윗일 때: 생성적 검색 엔진의 스타일 및 의미 효과

## 📋 메타데이터

**Links**: [[daily/2025-09-19|2025-09-19]] [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Generative Expression Patterns

## 🔗 유사한 논문
- [[Large Language Models for Information Retrieval A Survey]] (82.1% similar)
- [[JU-NLP at Touch'e Covert Advertisement in Conversational AI-Generation and Detection Strategies]] (80.4% similar)
- [[GEM-Bench A Benchmark for Ad-Injected Response Generation within Generative Engine Marketing]] (80.2% similar)
- [[AI_as_a_teaching_tool_and_learning_partner_20250918|AI as a teaching tool and learning partner]] (80.0% similar)
- [[Evaluating_and_Improving_the_Robustness_of_Security_Attack_Detectors_Generated_by_LLMs_20250918|Evaluating and Improving the Robustness of Security Attack Detectors Generated by LLMs]] (79.6% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.14436v1 Announce Type: cross 
Abstract: Generative search engines (GEs) leverage large language models (LLMs) to deliver AI-generated summaries with website citations, establishing novel traffic acquisition channels while fundamentally altering the search engine optimization landscape. To investigate the distinctive characteristics of GEs, we collect data through interactions with Google's generative and conventional search platforms, compiling a dataset of approximately ten thousand websites across both channels. Our empirical analysis reveals that GEs exhibit preferences for citing content characterized by significantly higher predictability for underlying LLMs and greater semantic similarity among selected sources. Through controlled experiments utilizing retrieval augmented generation (RAG) APIs, we demonstrate that these citation preferences emerge from intrinsic LLM tendencies to favor content aligned with their generative expression patterns. Motivated by applications of LLMs to optimize website content, we conduct additional experimentation to explore how LLM-based content polishing by website proprietors alters AI summaries, finding that such polishing paradoxically enhances information diversity within AI summaries. Finally, to assess the user-end impact of LLM-induced information increases, we design a generative search engine and recruit Prolific participants to conduct a randomized controlled experiment involving an information-seeking and writing task. We find that higher-educated users exhibit minimal changes in their final outputs' information diversity but demonstrate significantly reduced task completion time when original sites undergo polishing. Conversely, lower-educated users primarily benefit through enhanced information density in their task outputs while maintaining similar completion times across experimental groups.

## 🔍 Abstract (한글 번역)

arXiv:2509.14436v1 발표 유형: 교차  
초록: 생성적 검색 엔진(GE)은 대형 언어 모델(LLM)을 활용하여 웹사이트 인용과 함께 AI 생성 요약을 제공함으로써 새로운 트래픽 획득 채널을 구축하고 검색 엔진 최적화 환경을 근본적으로 변화시킵니다. GE의 독특한 특성을 조사하기 위해, 우리는 구글의 생성적 및 전통적 검색 플랫폼과의 상호작용을 통해 데이터를 수집하고, 두 채널에 걸쳐 약 만 개의 웹사이트로 구성된 데이터셋을 작성합니다. 우리의 실증 분석은 GE가 기본 LLM에 대한 예측 가능성이 현저히 높은 콘텐츠와 선택된 출처 간의 의미적 유사성이 큰 콘텐츠를 인용하는 경향이 있음을 보여줍니다. 검색 증강 생성(RAG) API를 활용한 통제된 실험을 통해, 이러한 인용 선호가 LLM의 내재적 경향에서 비롯되어 생성적 표현 패턴과 일치하는 콘텐츠를 선호함을 입증합니다. 웹사이트 콘텐츠 최적화를 위한 LLM의 응용에 동기부여되어, 우리는 웹사이트 소유자가 LLM 기반 콘텐츠 다듬기를 통해 AI 요약을 어떻게 변화시키는지 추가 실험을 수행하며, 이러한 다듬기가 역설적으로 AI 요약 내 정보 다양성을 향상시킨다는 것을 발견합니다. 마지막으로, LLM으로 인한 정보 증가가 사용자에게 미치는 영향을 평가하기 위해, 우리는 생성적 검색 엔진을 설계하고 Prolific 참가자를 모집하여 정보 탐색 및 작성 작업을 포함한 무작위 통제 실험을 수행합니다. 우리는 고학력 사용자가 최종 결과물의 정보 다양성에는 거의 변화를 보이지 않지만, 원본 사이트가 다듬어질 때 작업 완료 시간이 크게 단축된다는 것을 발견합니다. 반면, 저학력 사용자는 주로 작업 결과물의 정보 밀도가 향상되는 이점을 누리며, 실험 그룹 간 유사한 완료 시간을 유지합니다.

## 📝 요약

이 논문은 생성형 검색 엔진(GE)이 대형 언어 모델(LLM)을 활용하여 웹사이트 인용과 함께 AI 생성 요약을 제공하는 방식을 연구합니다. 연구를 위해 구글의 생성형 및 전통적 검색 플랫폼과 상호작용하여 약 만 개의 웹사이트 데이터를 수집했습니다. 실험 결과, GE는 LLM이 예측하기 쉬운 콘텐츠와 의미적으로 유사한 소스를 선호하는 경향을 보였습니다. LLM을 활용한 웹사이트 콘텐츠 최적화 실험에서는, 콘텐츠를 다듬을 경우 AI 요약의 정보 다양성이 증가하는 것을 발견했습니다. 사용자 실험에서는 교육 수준에 따라 정보 다양성 및 작업 시간의 변화가 달라짐을 확인했습니다. 고학력 사용자는 작업 시간이 단축되었고, 저학력 사용자는 정보 밀도가 증가했습니다.

## 🎯 주요 포인트

- 1. 생성형 검색 엔진(GEs)은 대형 언어 모델(LLMs)을 활용하여 웹사이트 인용과 함께 AI 생성 요약을 제공하며, 검색 엔진 최적화 환경을 근본적으로 변화시킵니다.

- 2. GEs는 LLM의 예측 가능성이 높고 선택된 소스 간 의미적 유사성이 큰 콘텐츠를 선호하여 인용하는 경향이 있습니다.

- 3. 웹사이트 소유자가 LLM 기반 콘텐츠를 다듬으면 AI 요약에서 정보 다양성이 향상되는 역설적인 결과가 나타납니다.

- 4. 고학력 사용자는 정보 다양성 변화가 적지만 작업 완료 시간이 단축되며, 저학력 사용자는 정보 밀도가 증가하여 이점을 얻습니다.

---

*Generated on 2025-09-19 14:55:02*