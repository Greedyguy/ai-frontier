---
keywords:
  - Large Language Models
  - Collaborative Consensus Defense
  - Compositional Privacy Leakage
category: cs.AI
publish_date: 2025-09-19
arxiv_id: 2509.14284
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 21:21:32.855339",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Models",
    "Collaborative Consensus Defense",
    "Compositional Privacy Leakage"
  ],
  "rejected_keywords": [
    "Theory-of-Mind Defense",
    "Multi-Agent Systems"
  ],
  "similarity_scores": {
    "Large Language Models": 0.8,
    "Collaborative Consensus Defense": 0.72,
    "Compositional Privacy Leakage": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->


# The Sum Leaks More Than Its Parts: Compositional Privacy Risks and Mitigations in Multi-Agent Collaboration

**Korean Title:** ë¶€ë¶„ì˜ í•©ë³´ë‹¤ ë” ë§ì´ ìœ ì¶œë¨: ë‹¤ì¤‘ ì—ì´ì „íŠ¸ í˜‘ì—…ì—ì„œì˜ êµ¬ì„±ì  í”„ë¼ì´ë²„ì‹œ ìœ„í—˜ê³¼ ì™„í™” ë°©ì•ˆ

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[digests/daily_digest_20250919|2025-09-19]]   [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Large Language Models|Large Language Models]]
**âš¡ Unique Technical**: [[keywords/Collaborative Consensus Defense|Collaborative Consensus Defense]], [[keywords/Compositional Privacy Leakage|Compositional Privacy Leakage]]

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[Language Models Identify Ambiguities and Exploit Loopholes]] (83.9% similar)
- [[Internalizing Self-Consistency in Language Models Multi-Agent Consensus Alignment]] (83.4% similar)
- [[Understanding and Mitigating Overrefusal in LLMs from an Unveiling Perspective of Safety Decision Boundary]] (83.4% similar)
- [[CyberLLMInstruct A Pseudo-malicious Dataset Revealing Safety-performance Trade-offs in Cyber Security LLM Fine-tuning]] (83.2% similar)
- [[From Capabilities to Performance Evaluating Key Functional Properties of LLM Architectures in Penetration Testing]] (82.4% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.14284v1 Announce Type: cross 
Abstract: As large language models (LLMs) become integral to multi-agent systems, new privacy risks emerge that extend beyond memorization, direct inference, or single-turn evaluations. In particular, seemingly innocuous responses, when composed across interactions, can cumulatively enable adversaries to recover sensitive information, a phenomenon we term compositional privacy leakage. We present the first systematic study of such compositional privacy leaks and possible mitigation methods in multi-agent LLM systems. First, we develop a framework that models how auxiliary knowledge and agent interactions jointly amplify privacy risks, even when each response is benign in isolation. Next, to mitigate this, we propose and evaluate two defense strategies: (1) Theory-of-Mind defense (ToM), where defender agents infer a questioner's intent by anticipating how their outputs may be exploited by adversaries, and (2) Collaborative Consensus Defense (CoDef), where responder agents collaborate with peers who vote based on a shared aggregated state to restrict sensitive information spread. Crucially, we balance our evaluation across compositions that expose sensitive information and compositions that yield benign inferences. Our experiments quantify how these defense strategies differ in balancing the privacy-utility trade-off. We find that while chain-of-thought alone offers limited protection to leakage (~39% sensitive blocking rate), our ToM defense substantially improves sensitive query blocking (up to 97%) but can reduce benign task success. CoDef achieves the best balance, yielding the highest Balanced Outcome (79.8%), highlighting the benefit of combining explicit reasoning with defender collaboration. Together, our results expose a new class of risks in collaborative LLM deployments and provide actionable insights for designing safeguards against compositional, context-driven privacy leakage.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.14284v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì´ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì˜ í•„ìˆ˜ ìš”ì†Œê°€ ë¨ì— ë”°ë¼, ì•”ê¸°, ì§ì ‘ ì¶”ë¡  ë˜ëŠ” ë‹¨ì¼ í„´ í‰ê°€ë¥¼ ë„˜ì–´ì„œëŠ” ìƒˆë¡œìš´ í”„ë¼ì´ë²„ì‹œ ìœ„í—˜ì´ ë°œìƒí•˜ê³  ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ, ê°œë³„ì ìœ¼ë¡œëŠ” ë¬´í•´í•´ ë³´ì´ëŠ” ì‘ë‹µë“¤ì´ ìƒí˜¸ì‘ìš©ì„ í†µí•´ ì¡°í•©ë  ë•Œ, ì ëŒ€ìê°€ ë¯¼ê°í•œ ì •ë³´ë¥¼ ë³µêµ¬í•  ìˆ˜ ìˆê²Œ í•˜ëŠ” í˜„ìƒì„ ìš°ë¦¬ëŠ” ì¡°í•©ì  í”„ë¼ì´ë²„ì‹œ ëˆ„ì¶œ(compositional privacy leakage)ì´ë¼ê³  ëª…ëª…í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ë‹¤ì¤‘ ì—ì´ì „íŠ¸ LLM ì‹œìŠ¤í…œì—ì„œ ì´ëŸ¬í•œ ì¡°í•©ì  í”„ë¼ì´ë²„ì‹œ ëˆ„ì¶œê³¼ ê°€ëŠ¥í•œ ì™„í™” ë°©ë²•ì— ëŒ€í•œ ìµœì´ˆì˜ ì²´ê³„ì ì¸ ì—°êµ¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ë¨¼ì €, ë³´ì¡° ì§€ì‹ê³¼ ì—ì´ì „íŠ¸ ìƒí˜¸ì‘ìš©ì´ ì–´ë–»ê²Œ ê°œë³„ ì‘ë‹µì´ ë¬´í•´í•  ë•Œì—ë„ í”„ë¼ì´ë²„ì‹œ ìœ„í—˜ì„ ì¦í­ì‹œí‚¤ëŠ”ì§€ë¥¼ ëª¨ë¸ë§í•˜ëŠ” í”„ë ˆì„ì›Œí¬ë¥¼ ê°œë°œí•©ë‹ˆë‹¤. ë‹¤ìŒìœ¼ë¡œ, ì´ë¥¼ ì™„í™”í•˜ê¸° ìœ„í•´ ë‘ ê°€ì§€ ë°©ì–´ ì „ëµì„ ì œì•ˆí•˜ê³  í‰ê°€í•©ë‹ˆë‹¤: (1) ë§ˆìŒ ì´ë¡  ë°©ì–´(ToM), ì—¬ê¸°ì„œ ë°©ì–´ ì—ì´ì „íŠ¸ëŠ” ì ëŒ€ìê°€ ìì‹ ì˜ ì¶œë ¥ì„ ì–´ë–»ê²Œ ì•…ìš©í•  ìˆ˜ ìˆì„ì§€ë¥¼ ì˜ˆìƒí•˜ì—¬ ì§ˆë¬¸ìì˜ ì˜ë„ë¥¼ ì¶”ë¡ í•˜ë©°, (2) í˜‘ë ¥ì  í•©ì˜ ë°©ì–´(CoDef), ì—¬ê¸°ì„œ ì‘ë‹µ ì—ì´ì „íŠ¸ëŠ” ê³µìœ ëœ ì§‘ê³„ ìƒíƒœì— ê¸°ë°˜í•˜ì—¬ íˆ¬í‘œí•˜ëŠ” ë™ë£Œë“¤ê³¼ í˜‘ë ¥í•˜ì—¬ ë¯¼ê°í•œ ì •ë³´ í™•ì‚°ì„ ì œí•œí•©ë‹ˆë‹¤. ì¤‘ìš”í•œ ê²ƒì€, ìš°ë¦¬ëŠ” ë¯¼ê°í•œ ì •ë³´ë¥¼ ë…¸ì¶œí•˜ëŠ” ì¡°í•©ê³¼ ë¬´í•´í•œ ì¶”ë¡ ì„ ì‚°ì¶œí•˜ëŠ” ì¡°í•© ê°„ì˜ í‰ê°€ ê· í˜•ì„ ë§ì¶¥ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì‹¤í—˜ì€ ì´ëŸ¬í•œ ë°©ì–´ ì „ëµì´ í”„ë¼ì´ë²„ì‹œ-ìœ ìš©ì„± ê· í˜•ì„ ë§ì¶”ëŠ” ë° ì–´ë–»ê²Œ ì°¨ì´ê°€ ìˆëŠ”ì§€ë¥¼ ì •ëŸ‰í™”í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì—°ì‡„ ì‚¬ê³ (chain-of-thought)ë§Œìœ¼ë¡œëŠ” ëˆ„ì¶œì— ëŒ€í•œ ë³´í˜¸ê°€ ì œí•œì ì„ì„ ë°œê²¬í–ˆìœ¼ë©°(~39% ë¯¼ê° ì°¨ë‹¨ìœ¨), ìš°ë¦¬ì˜ ToM ë°©ì–´ëŠ” ë¯¼ê°í•œ ì¿¼ë¦¬ ì°¨ë‹¨ì„ ìƒë‹¹íˆ ê°œì„ í•˜ì§€ë§Œ(ìµœëŒ€ 97%), ë¬´í•´í•œ ì‘ì—… ì„±ê³µë¥ ì„ ê°ì†Œì‹œí‚¬ ìˆ˜ ìˆìŒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. CoDefëŠ” ìµœê³ ì˜ ê· í˜•ì„ ë‹¬ì„±í•˜ì—¬, ê°€ì¥ ë†’ì€ ê· í˜• ê²°ê³¼(79.8%)ë¥¼ ì œê³µí•˜ë©°, ëª…ì‹œì  ì¶”ë¡ ê³¼ ë°©ì–´ì í˜‘ë ¥ì˜ ê²°í•© ì´ì ì„ ê°•ì¡°í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ê²°ê³¼ëŠ” í˜‘ë ¥ì  LLM ë°°ì¹˜ì—ì„œ ìƒˆë¡œìš´ ìœ í˜•ì˜ ìœ„í—˜ì„ ë“œëŸ¬ë‚´ë©°, ì¡°í•©ì , ë§¥ë½ ê¸°ë°˜ í”„ë¼ì´ë²„ì‹œ ëˆ„ì¶œì— ëŒ€í•œ ì•ˆì „ì¥ì¹˜ë¥¼ ì„¤ê³„í•˜ê¸° ìœ„í•œ ì‹¤ì§ˆì ì¸ í†µì°°ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì´ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì— í†µí•©ë¨ì— ë”°ë¼ ìƒˆë¡œìš´ í”„ë¼ì´ë²„ì‹œ ìœ„í—˜ì´ ë°œìƒí•©ë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ì´ëŸ¬í•œ ì¡°í•©ì  í”„ë¼ì´ë²„ì‹œ ëˆ„ì¶œì„ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ê³  ì™„í™” ë°©ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤. ì—°êµ¬ì—ì„œëŠ” ë³´ì¡° ì§€ì‹ê³¼ ì—ì´ì „íŠ¸ ê°„ ìƒí˜¸ì‘ìš©ì´ í”„ë¼ì´ë²„ì‹œ ìœ„í—˜ì„ ì¦ëŒ€ì‹œí‚¤ëŠ” ëª¨ë¸ì„ ê°œë°œí•˜ì˜€ìœ¼ë©°, ì´ë¥¼ ì™„í™”í•˜ê¸° ìœ„í•´ ë‘ ê°€ì§€ ë°©ì–´ ì „ëµì„ ì œì•ˆí•©ë‹ˆë‹¤. ì²«ì§¸, 'ë§ˆìŒ ì´ë¡  ë°©ì–´(ToM)'ëŠ” ì§ˆë¬¸ìì˜ ì˜ë„ë¥¼ ì˜ˆì¸¡í•˜ì—¬ ë¯¼ê°í•œ ì •ë³´ì˜ ì•…ìš©ì„ ë°©ì§€í•˜ê³ , ë‘˜ì§¸, 'í˜‘ë ¥ì  í•©ì˜ ë°©ì–´(CoDef)'ëŠ” ì—ì´ì „íŠ¸ë“¤ì´ í˜‘ë ¥í•˜ì—¬ ë¯¼ê°í•œ ì •ë³´ í™•ì‚°ì„ ì œí•œí•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ToM ë°©ì–´ëŠ” ë¯¼ê°í•œ ì¿¼ë¦¬ ì°¨ë‹¨ì„ í¬ê²Œ ê°œì„ í•˜ì§€ë§Œ, ë¬´í•´í•œ ì‘ì—… ì„±ê³µë¥ ì„ ê°ì†Œì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. CoDefëŠ” ê°€ì¥ ê· í˜• ì¡íŒ ê²°ê³¼ë¥¼ ì œê³µí•˜ì—¬ í”„ë¼ì´ë²„ì‹œì™€ ìœ ìš©ì„± ê°„ì˜ ê· í˜•ì„ ìµœì í™”í•©ë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” í˜‘ë ¥ì  LLM ë°°ì¹˜ì—ì„œì˜ ìƒˆë¡œìš´ ìœ„í—˜ì„ ë“œëŸ¬ë‚´ê³ , ì¡°í•©ì  í”„ë¼ì´ë²„ì‹œ ëˆ„ì¶œì„ ë°©ì§€í•˜ê¸° ìœ„í•œ í†µì°°ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM) ê¸°ë°˜ì˜ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì—ì„œ ì¡°í•©ì  í”„ë¼ì´ë²„ì‹œ ëˆ„ì¶œ(compositional privacy leakage)ì´ ë°œìƒí•  ìˆ˜ ìˆë‹¤.

- 2. ë³´ì¡° ì§€ì‹ê³¼ ì—ì´ì „íŠ¸ ê°„ì˜ ìƒí˜¸ì‘ìš©ì´ í”„ë¼ì´ë²„ì‹œ ìœ„í—˜ì„ ì¦í­ì‹œí‚¬ ìˆ˜ ìˆìŒì„ ëª¨ë¸ë§í•˜ëŠ” í”„ë ˆì„ì›Œí¬ë¥¼ ê°œë°œí•˜ì˜€ë‹¤.

- 3. í”„ë¼ì´ë²„ì‹œ ëˆ„ì¶œì„ ì™„í™”í•˜ê¸° ìœ„í•´ Theory-of-Mind ë°©ì–´(ToM)ì™€ í˜‘ë ¥ì  í•©ì˜ ë°©ì–´(CoDef)ë¼ëŠ” ë‘ ê°€ì§€ ë°©ì–´ ì „ëµì„ ì œì•ˆí•˜ê³  í‰ê°€í•˜ì˜€ë‹¤.

- 4. ToM ë°©ì–´ëŠ” ë¯¼ê°í•œ ì¿¼ë¦¬ ì°¨ë‹¨ì„ í¬ê²Œ ê°œì„ í•  ìˆ˜ ìˆì§€ë§Œ, ë¬´í•´í•œ ì‘ì—… ì„±ê³µë¥ ì„ ê°ì†Œì‹œí‚¬ ìˆ˜ ìˆë‹¤.

- 5. CoDefëŠ” ë¯¼ê° ì •ë³´ ì°¨ë‹¨ê³¼ ë¬´í•´í•œ ì¶”ë¡ ì˜ ê· í˜•ì„ ê°€ì¥ ì˜ ë§ì¶”ë©°, ëª…ì‹œì  ì¶”ë¡ ê³¼ ë°©ì–´ì í˜‘ë ¥ì˜ ì´ì ì„ ê°•ì¡°í•œë‹¤.

---

*Generated on 2025-09-19 14:53:40*