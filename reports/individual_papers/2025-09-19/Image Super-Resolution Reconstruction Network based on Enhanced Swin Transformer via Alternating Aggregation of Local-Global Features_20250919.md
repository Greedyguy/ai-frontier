---
keywords:
  - Transformer Architecture
  - Attention Mechanism
  - Image Super-Resolution
category: cs.AI
publish_date: 2025-09-19
arxiv_id: 2401.00241
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 21:40:12.739506",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Transformer Architecture",
    "Attention Mechanism",
    "Image Super-Resolution"
  ],
  "rejected_keywords": [
    "Local-Global Feature Aggregation"
  ],
  "similarity_scores": {
    "Transformer Architecture": 0.8,
    "Attention Mechanism": 0.78,
    "Image Super-Resolution": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->


# Image Super-Resolution Reconstruction Network based on Enhanced Swin Transformer via Alternating Aggregation of Local-Global Features

**Korean Title:** ê°•í™”ëœ ìŠ¤ìœˆ ë³€í™˜ê¸°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì´ë¯¸ì§€ ì´ˆí•´ìƒë„ ë³µì› ë„¤íŠ¸ì›Œí¬: ì§€ì—­-ì „ì—­ íŠ¹ì§•ì˜ êµì°¨ ì§‘ê³„ë¥¼ í†µí•œ ì ‘ê·¼

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[digests/daily_digest_20250919|2025-09-19]]   [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Transformer Architecture|Swin Transformer]], [[keywords/Attention Mechanism|Attention Mechanism]]
**âš¡ Unique Technical**: [[keywords/Image Super-Resolution|Image Super-Resolution]]

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[NDLPNet A Location-Aware Nighttime Deraining Network and a Real-World Benchmark Dataset]] (78.5% similar)
- [[Utilizing Novelty-based Evolution Strategies to Train Transformers in Reinforcement Learning]] (78.0% similar)
- [[Superpose Task-specific Features for Model Merging_20250919|Superpose Task-specific Features for Model Merging]] (78.0% similar)
- [[Style Transfer with Diffusion Models for Synthetic-to-Real Domain Adaptation_20250919|Style Transfer with Diffusion Models for Synthetic-to-Real Domain Adaptation]] (76.9% similar)
- [[Taylor-Series Expanded Kolmogorov-Arnold Network for Medical Imaging Classification_20250918|Taylor-Series Expanded Kolmogorov-Arnold Network for Medical Imaging Classification]] (76.9% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2401.00241v5 Announce Type: replace 
Abstract: The Swin Transformer image super-resolution (SR) reconstruction network primarily depends on the long-range relationship of the window and shifted window attention to explore features. However, this approach focuses only on global features, ignoring local ones, and considers only spatial interactions, disregarding channel and spatial-channel feature interactions, limiting its nonlinear mapping capability. Therefore, this study proposes an enhanced Swin Transformer network (ESTN) that alternately aggregates local and global features. During local feature aggregation, shift convolution facilitates the interaction between local spatial and channel information. During global feature aggregation, a block sparse global perception module is introduced, wherein spatial information is reorganized and the recombined features are then processed by a dense layer to achieve global perception. Additionally, multiscale self-attention and low-parameter residual channel attention modules are introduced to aggregate information across different scales. Finally, the effectiveness of ESTN on five public datasets and a local attribution map (LAM) are analyzed. Experimental results demonstrate that the proposed ESTN achieves higher average PSNR, surpassing SRCNN, ELAN-light, SwinIR-light, and SMFANER+ models by 2.17dB, 0.13dB, 0.12dB, and 0.1dB, respectively, with LAM further confirming its larger receptive field. ESTN delivers improved quality of SR images. The source code can be found at https://github.com/huangyuming2021/ESTN.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2401.00241v5 ë°œí‘œ ìœ í˜•: êµì²´  
ì´ˆë¡: Swin Transformer ì´ë¯¸ì§€ ì´ˆí•´ìƒë„(SR) ì¬êµ¬ì„± ë„¤íŠ¸ì›Œí¬ëŠ” ì£¼ë¡œ ìœˆë„ìš°ì™€ ì‹œí”„íŠ¸ ìœˆë„ìš° ì£¼ì˜(attention)ì˜ ì¥ê±°ë¦¬ ê´€ê³„ì— ì˜ì¡´í•˜ì—¬ íŠ¹ì§•ì„ íƒìƒ‰í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ ì ‘ê·¼ë²•ì€ ì „ì—­ íŠ¹ì§•ì—ë§Œ ì§‘ì¤‘í•˜ê³ , ì§€ì—­ì  íŠ¹ì§•ì„ ë¬´ì‹œí•˜ë©°, ê³µê°„ì  ìƒí˜¸ì‘ìš©ë§Œ ê³ ë ¤í•˜ê³  ì±„ë„ ë° ê³µê°„-ì±„ë„ íŠ¹ì§• ìƒí˜¸ì‘ìš©ì„ ë¬´ì‹œí•˜ì—¬ ë¹„ì„ í˜• ë§¤í•‘ ëŠ¥ë ¥ì„ ì œí•œí•©ë‹ˆë‹¤. ë”°ë¼ì„œ ë³¸ ì—°êµ¬ì—ì„œëŠ” ì§€ì—­ ë° ì „ì—­ íŠ¹ì§•ì„ ë²ˆê°ˆì•„ ì§‘ê³„í•˜ëŠ” í–¥ìƒëœ Swin Transformer ë„¤íŠ¸ì›Œí¬(ESTN)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì§€ì—­ íŠ¹ì§• ì§‘ê³„ ë™ì•ˆ, ì‹œí”„íŠ¸ ì»¨ë³¼ë£¨ì…˜ì€ ì§€ì—­ ê³µê°„ ë° ì±„ë„ ì •ë³´ ê°„ì˜ ìƒí˜¸ì‘ìš©ì„ ì´‰ì§„í•©ë‹ˆë‹¤. ì „ì—­ íŠ¹ì§• ì§‘ê³„ ë™ì•ˆì—ëŠ” ë¸”ë¡ í¬ì†Œ ì „ì—­ ì¸ì‹ ëª¨ë“ˆì´ ë„ì…ë˜ì–´ ê³µê°„ ì •ë³´ê°€ ì¬êµ¬ì„±ë˜ê³ , ì¬êµ¬ì„±ëœ íŠ¹ì§•ì€ ë°€ì§‘ì¸µì— ì˜í•´ ì²˜ë¦¬ë˜ì–´ ì „ì—­ ì¸ì‹ì„ ë‹¬ì„±í•©ë‹ˆë‹¤. ë˜í•œ, ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ìê¸° ì£¼ì˜ ë° ì €-íŒŒë¼ë¯¸í„° ì”ì—¬ ì±„ë„ ì£¼ì˜ ëª¨ë“ˆì´ ë„ì…ë˜ì–´ ë‹¤ì–‘í•œ ìŠ¤ì¼€ì¼ì— ê±¸ì³ ì •ë³´ë¥¼ ì§‘ê³„í•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ, ë‹¤ì„¯ ê°œì˜ ê³µê³µ ë°ì´í„°ì…‹ê³¼ ì§€ì—­ ì†ì„± ë§µ(LAM)ì— ëŒ€í•œ ESTNì˜ íš¨ê³¼ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ESTNì€ í‰ê·  PSNRì´ ë” ë†’ì•„ SRCNN, ELAN-light, SwinIR-light, SMFANER+ ëª¨ë¸ì„ ê°ê° 2.17dB, 0.13dB, 0.12dB, 0.1dB ì´ˆê³¼í•˜ë©°, LAMì€ ë” í° ìˆ˜ìš© ì˜ì—­ì„ í™•ì¸í•©ë‹ˆë‹¤. ESTNì€ SR ì´ë¯¸ì§€ì˜ í’ˆì§ˆì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì†ŒìŠ¤ ì½”ë“œëŠ” https://github.com/huangyuming2021/ESTNì—ì„œ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” Swin Transformer ê¸°ë°˜ì˜ ì´ë¯¸ì§€ ì´ˆí•´ìƒë„(SR) ì¬êµ¬ì„± ë„¤íŠ¸ì›Œí¬ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ê°œì„ ëœ Swin Transformer ë„¤íŠ¸ì›Œí¬(ESTN)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ ë°©ë²•ì´ ê¸€ë¡œë²Œ íŠ¹ì§•ì—ë§Œ ì§‘ì¤‘í•˜ê³  ì§€ì—­ì  ë° ì±„ë„ ê°„ ìƒí˜¸ì‘ìš©ì„ ë¬´ì‹œí•˜ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ESTNì€ ì§€ì—­ ë° ê¸€ë¡œë²Œ íŠ¹ì§•ì„ ë²ˆê°ˆì•„ ì§‘ê³„í•©ë‹ˆë‹¤. ì§€ì—­ íŠ¹ì§• ì§‘ê³„ ì‹œ, ì‹œí”„íŠ¸ ì»¨ë³¼ë£¨ì…˜ì„ í†µí•´ ì§€ì—­ ê³µê°„ ë° ì±„ë„ ì •ë³´ì˜ ìƒí˜¸ì‘ìš©ì„ ì´‰ì§„í•˜ë©°, ê¸€ë¡œë²Œ íŠ¹ì§• ì§‘ê³„ ì‹œ ë¸”ë¡ í¬ì†Œ ê¸€ë¡œë²Œ ì¸ì‹ ëª¨ë“ˆì„ ë„ì…í•˜ì—¬ ê³µê°„ ì •ë³´ë¥¼ ì¬êµ¬ì„±í•©ë‹ˆë‹¤. ë˜í•œ, ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ìê¸° ì£¼ì˜ ë° ì €ë§¤ê°œë³€ìˆ˜ ì”ì—¬ ì±„ë„ ì£¼ì˜ ëª¨ë“ˆì„ ë„ì…í•˜ì—¬ ë‹¤ì–‘í•œ ìŠ¤ì¼€ì¼ì˜ ì •ë³´ë¥¼ ì§‘ê³„í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ESTNì€ ë‹¤ì„¯ ê°œì˜ ê³µê³µ ë°ì´í„°ì…‹ì—ì„œ í‰ê·  PSNRì´ ê¸°ì¡´ ëª¨ë¸ë“¤ë³´ë‹¤ ìµœëŒ€ 2.17dB ë†’ì•„ì¡Œìœ¼ë©°, LAM ë¶„ì„ì„ í†µí•´ ë” í° ìˆ˜ìš© ì˜ì—­ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ESTNì€ SR ì´ë¯¸ì§€ì˜ í’ˆì§ˆì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì†ŒìŠ¤ ì½”ë“œëŠ” https://github.com/huangyuming2021/ESTNì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Swin Transformer ê¸°ë°˜ ì´ë¯¸ì§€ ì´ˆí•´ìƒë„ ë„¤íŠ¸ì›Œí¬ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´, ë³¸ ì—°êµ¬ëŠ” ì§€ì—­ ë° ì „ì—­ íŠ¹ì§•ì„ êµëŒ€ë¡œ ì§‘ê³„í•˜ëŠ” í–¥ìƒëœ Swin Transformer ë„¤íŠ¸ì›Œí¬(ESTN)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.

- 2. ì§€ì—­ íŠ¹ì§• ì§‘ê³„ ì‹œ, ì‹œí”„íŠ¸ ì»¨ë³¼ë£¨ì…˜ì„ í†µí•´ ì§€ì—­ ê³µê°„ ë° ì±„ë„ ì •ë³´ ê°„ì˜ ìƒí˜¸ì‘ìš©ì„ ì´‰ì§„í•©ë‹ˆë‹¤.

- 3. ì „ì—­ íŠ¹ì§• ì§‘ê³„ ì‹œ, ë¸”ë¡ í¬ì†Œ ì „ì—­ ì¸ì‹ ëª¨ë“ˆì„ ë„ì…í•˜ì—¬ ê³µê°„ ì •ë³´ë¥¼ ì¬êµ¬ì„±í•˜ê³ , ì¡°í•©ëœ íŠ¹ì§•ì„ ë°€ì§‘ì¸µì—ì„œ ì²˜ë¦¬í•˜ì—¬ ì „ì—­ ì¸ì‹ì„ ë‹¬ì„±í•©ë‹ˆë‹¤.

- 4. ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ìê¸° ì£¼ì˜ ë° ì €ë§¤ê°œë³€ìˆ˜ ì”ì—¬ ì±„ë„ ì£¼ì˜ ëª¨ë“ˆì„ ë„ì…í•˜ì—¬ ë‹¤ì–‘í•œ ìŠ¤ì¼€ì¼ì˜ ì •ë³´ë¥¼ ì§‘ê³„í•©ë‹ˆë‹¤.

- 5. ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ESTNì€ í‰ê·  PSNRì—ì„œ SRCNN, ELAN-light, SwinIR-light, SMFANER+ ëª¨ë¸ì„ ê°ê° 2.17dB, 0.13dB, 0.12dB, 0.1dB ì´ˆê³¼í•˜ë©°, LAM ë¶„ì„ì„ í†µí•´ ë” í° ìˆ˜ìš© ì˜ì—­ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.

---

*Generated on 2025-09-19 16:14:21*