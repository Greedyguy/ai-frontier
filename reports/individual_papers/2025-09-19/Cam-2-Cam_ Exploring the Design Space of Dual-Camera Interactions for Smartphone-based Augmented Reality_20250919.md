---
keywords:
  - Smartphone-based Augmented Reality
  - Dual-Camera Interactions
  - Embodiment and Immersion
category: cs.AI
publish_date: 2025-09-19
arxiv_id: 2504.20035
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 21:53:47.473238",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Smartphone-based Augmented Reality",
    "Dual-Camera Interactions",
    "Embodiment and Immersion"
  ],
  "rejected_keywords": [
    "Preventing Disorientation in AR"
  ],
  "similarity_scores": {
    "Smartphone-based Augmented Reality": 0.78,
    "Dual-Camera Interactions": 0.77,
    "Embodiment and Immersion": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->


# Cam-2-Cam: Exploring the Design Space of Dual-Camera Interactions for Smartphone-based Augmented Reality

**Korean Title:** 카메라-투-카메라: 스마트폰 기반 증강 현실을 위한 듀얼 카메라 상호작용의 설계 공간 탐색

## 📋 메타데이터

**Links**: [[digests/daily_digest_20250919|2025-09-19]]   [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**⚡ Unique Technical**: [[keywords/Smartphone-based Augmented Reality|smartphone-based augmented reality]], [[keywords/Dual-Camera Interactions|dual-camera interactions]]
**🚀 Evolved Concepts**: [[keywords/Embodiment and Immersion|embodiment and immersion]]

## 🔗 유사한 논문
- [[Investigating the Ways in Which Mobile Phone Images with Open-Source Data Can Be Used to Create an Augmented Virtual Environment (AVE)_20250919|Investigating the Ways in Which Mobile Phone Images with Open-Source Data Can Be Used to Create an Augmented Virtual Environment (AVE)]] (78.6% similar)
- [[MCGS-SLAM A Multi-Camera SLAM Framework Using Gaussian Splatting for High-Fidelity Mapping]] (78.1% similar)
- [[MIRA Empowering One-Touch AI Services on Smartphones with MLLM-based Instruction Recommendation]] (78.1% similar)
- [[Boost 3D Reconstruction using Diffusion-based Monocular Camera Calibration_20250919|Boost 3D Reconstruction using Diffusion-based Monocular Camera Calibration]] (77.6% similar)
- [[Human Interaction for Collaborative Semantic SLAM using Extended Reality_20250919|Human Interaction for Collaborative Semantic SLAM using Extended Reality]] (77.3% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2504.20035v5 Announce Type: replace 
Abstract: Off-the-shelf smartphone-based AR systems typically use a single front-facing or rear-facing camera, which restricts user interactions to a narrow field of view and small screen size, thus reducing their practicality. We present Cam-2-Cam, an interaction concept implemented in three smartphone-based AR applications with interactions that span both cameras. Results from our qualitative analysis conducted on 30 participants presented two major design lessons that explore the interaction space of smartphone AR while maintaining critical AR interface attributes like embodiment and immersion: (1) Balancing Contextual Relevance and Feedback Quality serves to outline a delicate balance between implementing familiar interactions people do in the real world and the quality of multimodal AR responses and (2) Preventing Disorientation using Simultaneous Capture and Alternating Cameras which details how to prevent disorientation during AR interactions using the two distinct camera techniques we implemented in the paper. Additionally, we consider observed user assumptions or natural tendencies to inform future implementations of dual-camera setups for smartphone-based AR. We envision our design lessons as an initial pioneering step toward expanding the interaction space of smartphone-based AR, potentially driving broader adoption and overcoming limitations of single-camera AR.

## 🔍 Abstract (한글 번역)

arXiv:2504.20035v5 발표 유형: 교체  
초록: 기존의 스마트폰 기반 AR 시스템은 일반적으로 전면 또는 후면 카메라 하나만을 사용하여 사용자 상호작용을 좁은 시야각과 작은 화면 크기로 제한하여 실용성을 감소시킵니다. 우리는 Cam-2-Cam을 소개합니다. 이는 두 카메라를 아우르는 상호작용을 가진 세 가지 스마트폰 기반 AR 애플리케이션에서 구현된 상호작용 개념입니다. 30명의 참가자를 대상으로 한 질적 분석 결과, 스마트폰 AR의 상호작용 공간을 탐색하면서 구현체와 몰입감 같은 중요한 AR 인터페이스 속성을 유지하는 두 가지 주요 설계 교훈을 제시했습니다: (1) 맥락적 관련성과 피드백 품질의 균형은 사람들이 실제 세계에서 수행하는 익숙한 상호작용의 구현과 다중 모드 AR 응답의 품질 사이의 미세한 균형을 설명하고, (2) 동시 캡처 및 교대 카메라 사용을 통한 방향 감각 상실 방지는 논문에서 구현한 두 가지 독특한 카메라 기술을 사용하여 AR 상호작용 중 방향 감각 상실을 방지하는 방법을 상세히 설명합니다. 또한, 스마트폰 기반 AR의 듀얼 카메라 설정의 향후 구현을 알리기 위해 관찰된 사용자 가정이나 자연스러운 경향을 고려합니다. 우리는 우리의 설계 교훈을 스마트폰 기반 AR의 상호작용 공간을 확장하고, 잠재적으로 더 넓은 채택을 유도하며 단일 카메라 AR의 한계를 극복하기 위한 초기 개척 단계로 상상합니다.

## 📝 요약

이 논문은 스마트폰 기반 증강현실(AR) 시스템의 상호작용을 확장하기 위해 Cam-2-Cam이라는 개념을 제안합니다. 이 개념은 전면 및 후면 카메라를 모두 활용하여 상호작용을 구현한 세 가지 AR 애플리케이션에서 테스트되었습니다. 30명의 참가자를 대상으로 한 질적 분석 결과, 두 가지 주요 설계 교훈이 도출되었습니다. 첫째, 현실 세계에서의 익숙한 상호작용과 AR의 다중 모달 반응 품질 간의 균형을 맞추는 것이 중요합니다. 둘째, 두 카메라를 번갈아 사용하여 방향 감각 상실을 방지하는 방법을 제시합니다. 이러한 설계 교훈은 스마트폰 기반 AR의 상호작용 영역을 확장하고, 단일 카메라 AR의 한계를 극복하는 데 기여할 수 있습니다.

## 🎯 주요 포인트

- 1. Cam-2-Cam은 스마트폰의 전면 및 후면 카메라를 모두 활용하여 AR 상호작용의 범위를 확장하는 개념을 제시합니다.

- 2. 연구는 AR 인터페이스의 구현에서 맥락적 관련성과 피드백 품질의 균형을 강조합니다.

- 3. 두 개의 카메라 기법을 사용하여 AR 상호작용 중 방향 감각 상실을 방지하는 방법을 제안합니다.

- 4. 사용자의 자연스러운 가정이나 경향을 고려하여 스마트폰 기반 AR의 듀얼 카메라 설정을 위한 미래 구현에 대한 통찰을 제공합니다.

- 5. 이 연구는 스마트폰 기반 AR의 상호작용 공간을 확장하고 단일 카메라 AR의 한계를 극복하기 위한 초기 단계로 자리매김합니다.

---

*Generated on 2025-09-19 16:48:31*