
# Vulnerable Agent Identification in Large-Scale Multi-Agent Reinforcement Learning

**Korean Title:** ëŒ€ê·œëª¨ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ê°•í™” í•™ìŠµì—ì„œ ì·¨ì•½í•œ ì—ì´ì „íŠ¸ ì‹ë³„

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-19|2025-09-19]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Vulnerable Agent Identification

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[MIMIC-D Multi-modal Imitation for MultI-agent Coordination with Decentralized Diffusion Policies]] (82.1% similar)
- [[Reinforcement_Learning_Agent_for_a_2D_Shooter_Game_20250919|Reinforcement Learning Agent for a 2D Shooter Game]] (80.3% similar)
- [[Sentinel_Agents_for_Secure_and_Trustworthy_Agentic_AI_in_Multi-Agent_Systems_20250919|Sentinel Agents for Secure and Trustworthy Agentic AI in Multi-Agent Systems]] (80.1% similar)
- [[MARIC Multi-Agent Reasoning for Image Classification]] (80.1% similar)
- [[Internalizing Self-Consistency in Language Models Multi-Agent Consensus Alignment]] (80.0% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15103v1 Announce Type: cross 
Abstract: Partial agent failure becomes inevitable when systems scale up, making it crucial to identify the subset of agents whose compromise would most severely degrade overall performance. In this paper, we study this Vulnerable Agent Identification (VAI) problem in large-scale multi-agent reinforcement learning (MARL). We frame VAI as a Hierarchical Adversarial Decentralized Mean Field Control (HAD-MFC), where the upper level involves an NP-hard combinatorial task of selecting the most vulnerable agents, and the lower level learns worst-case adversarial policies for these agents using mean-field MARL. The two problems are coupled together, making HAD-MFC difficult to solve. To solve this, we first decouple the hierarchical process by Fenchel-Rockafellar transform, resulting a regularized mean-field Bellman operator for upper level that enables independent learning at each level, thus reducing computational complexity. We then reformulate the upper-level combinatorial problem as a MDP with dense rewards from our regularized mean-field Bellman operator, enabling us to sequentially identify the most vulnerable agents by greedy and RL algorithms. This decomposition provably preserves the optimal solution of the original HAD-MFC. Experiments show our method effectively identifies more vulnerable agents in large-scale MARL and the rule-based system, fooling system into worse failures, and learns a value function that reveals the vulnerability of each agent.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15103v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ì‹œìŠ¤í…œì´ í™•ì¥ë¨ì— ë”°ë¼ ì¼ë¶€ ì—ì´ì „íŠ¸ì˜ ì‹¤íŒ¨ëŠ” ë¶ˆê°€í”¼í•´ì§€ë©°, ì „ì²´ ì„±ëŠ¥ì„ ê°€ì¥ ì‹¬ê°í•˜ê²Œ ì €í•˜ì‹œí‚¬ ìˆ˜ ìˆëŠ” ì—ì´ì „íŠ¸ì˜ í•˜ìœ„ ì§‘í•©ì„ ì‹ë³„í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•´ì§‘ë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ëŒ€ê·œëª¨ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ê°•í™” í•™ìŠµ(MARL)ì—ì„œ ì´ ì·¨ì•½ ì—ì´ì „íŠ¸ ì‹ë³„(VAI) ë¬¸ì œë¥¼ ì—°êµ¬í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” VAIë¥¼ ê³„ì¸µì  ì ëŒ€ì  ë¶„ì‚° í‰ê· ì¥ ì œì–´(HAD-MFC)ë¡œ êµ¬ì„±í•˜ë©°, ìƒìœ„ ìˆ˜ì¤€ì€ ê°€ì¥ ì·¨ì•½í•œ ì—ì´ì „íŠ¸ë¥¼ ì„ íƒí•˜ëŠ” NP-ë‚œí•´í•œ ì¡°í•© ê³¼ì œë¥¼ í¬í•¨í•˜ê³ , í•˜ìœ„ ìˆ˜ì¤€ì€ í‰ê· ì¥ MARLì„ ì‚¬ìš©í•˜ì—¬ ì´ëŸ¬í•œ ì—ì´ì „íŠ¸ì— ëŒ€í•œ ìµœì•…ì˜ ì ëŒ€ì  ì •ì±…ì„ í•™ìŠµí•©ë‹ˆë‹¤. ì´ ë‘ ë¬¸ì œëŠ” ì„œë¡œ ê²°í•©ë˜ì–´ ìˆì–´ HAD-MFCë¥¼ í•´ê²°í•˜ê¸° ì–´ë µê²Œ ë§Œë“­ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ë¨¼ì € Fenchel-Rockafellar ë³€í™˜ì„ í†µí•´ ê³„ì¸µì  ê³¼ì •ì„ ë¶„ë¦¬í•˜ì—¬ ìƒìœ„ ìˆ˜ì¤€ì— ëŒ€í•´ ì •ê·œí™”ëœ í‰ê· ì¥ ë²¨ë§Œ ì—°ì‚°ìë¥¼ ë„ì¶œí•˜ê³ , ê° ìˆ˜ì¤€ì—ì„œ ë…ë¦½ì ì¸ í•™ìŠµì„ ê°€ëŠ¥í•˜ê²Œ í•˜ì—¬ ê³„ì‚° ë³µì¡ì„±ì„ ì¤„ì…ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ ìƒìœ„ ìˆ˜ì¤€ì˜ ì¡°í•© ë¬¸ì œë¥¼ ìš°ë¦¬ì˜ ì •ê·œí™”ëœ í‰ê· ì¥ ë²¨ë§Œ ì—°ì‚°ìë¡œë¶€í„°ì˜ ë°€ì§‘ ë³´ìƒì„ ê°€ì§„ MDPë¡œ ì¬êµ¬ì„±í•˜ì—¬, íƒìš• ë° RL ì•Œê³ ë¦¬ì¦˜ì„ í†µí•´ ê°€ì¥ ì·¨ì•½í•œ ì—ì´ì „íŠ¸ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹ë³„í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤. ì´ ë¶„í•´ëŠ” ì›ë˜ HAD-MFCì˜ ìµœì  ì†”ë£¨ì…˜ì„ ë³´ì¡´í•¨ì„ ì¦ëª…í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ìš°ë¦¬ì˜ ë°©ë²•ì€ ëŒ€ê·œëª¨ MARL ë° ê·œì¹™ ê¸°ë°˜ ì‹œìŠ¤í…œì—ì„œ ë” ë§ì€ ì·¨ì•½ ì—ì´ì „íŠ¸ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì‹ë³„í•˜ì—¬ ì‹œìŠ¤í…œì„ ë” ì‹¬ê°í•œ ì‹¤íŒ¨ë¡œ ìœ ë„í•˜ê³ , ê° ì—ì´ì „íŠ¸ì˜ ì·¨ì•½ì„±ì„ ë“œëŸ¬ë‚´ëŠ” ê°€ì¹˜ í•¨ìˆ˜ë¥¼ í•™ìŠµí•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€ê·œëª¨ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ê°•í™” í•™ìŠµ(MARL)ì—ì„œ ì·¨ì•½í•œ ì—ì´ì „íŠ¸ë¥¼ ì‹ë³„í•˜ëŠ” ë¬¸ì œë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. ì €ìë“¤ì€ ì´ ë¬¸ì œë¥¼ ê³„ì¸µì  ì ëŒ€ì  ë¶„ì‚° í‰ê· ì¥ ì œì–´(HAD-MFC)ë¡œ ì •ì˜í•˜ê³ , ìµœìƒìœ„ ë‹¨ê³„ì—ì„œ ê°€ì¥ ì·¨ì•½í•œ ì—ì´ì „íŠ¸ë¥¼ ì„ íƒí•˜ëŠ” NP-ë‚œí•´í•œ ì¡°í•© ë¬¸ì œì™€ í•˜ìœ„ ë‹¨ê³„ì—ì„œ í‰ê· ì¥ MARLì„ í†µí•´ ìµœì•…ì˜ ì ëŒ€ì  ì •ì±…ì„ í•™ìŠµí•˜ëŠ” ë¬¸ì œë¡œ ë‚˜ëˆ•ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ Fenchel-Rockafellar ë³€í™˜ì„ ì‚¬ìš©í•˜ì—¬ ê³„ì¸µì  ê³¼ì •ì„ ë¶„ë¦¬í•˜ê³ , ê° ë‹¨ê³„ì—ì„œ ë…ë¦½ì ì¸ í•™ìŠµì´ ê°€ëŠ¥í•˜ë„ë¡ í•˜ì—¬ ê³„ì‚° ë³µì¡ì„±ì„ ì¤„ì˜€ìŠµë‹ˆë‹¤. ìƒìœ„ ë‹¨ê³„ì˜ ì¡°í•© ë¬¸ì œë¥¼ MDPë¡œ ì¬êµ¬ì„±í•˜ì—¬ íƒìš•ì  ì•Œê³ ë¦¬ì¦˜ê³¼ ê°•í™” í•™ìŠµì„ í†µí•´ ì·¨ì•½í•œ ì—ì´ì „íŠ¸ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹ë³„í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì´ ë°©ë²•ì´ ëŒ€ê·œëª¨ MARLì—ì„œ ë” ë§ì€ ì·¨ì•½ ì—ì´ì „íŠ¸ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì‹ë³„í•˜ê³ , ì‹œìŠ¤í…œì˜ ì·¨ì•½ì„±ì„ ë“œëŸ¬ë‚´ëŠ” ê°€ì¹˜ í•¨ìˆ˜ë¥¼ í•™ìŠµí•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€ê·œëª¨ ì‹œìŠ¤í…œì—ì„œ ë¶€ë¶„ì ì¸ ì—ì´ì „íŠ¸ ì‹¤íŒ¨ëŠ” ë¶ˆê°€í”¼í•˜ë©°, ê°€ì¥ ì·¨ì•½í•œ ì—ì´ì „íŠ¸ë¥¼ ì‹ë³„í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤.

- 2. ì·¨ì•½í•œ ì—ì´ì „íŠ¸ ì‹ë³„ ë¬¸ì œë¥¼ ê³„ì¸µì  ì ëŒ€ì  ë¶„ì‚° í‰ê· ì¥ ì œì–´(HAD-MFC)ë¡œ ì •ì˜í•˜ì˜€ë‹¤.

- 3. Fenchel-Rockafellar ë³€í™˜ì„ í†µí•´ ê³„ì¸µì  ê³¼ì •ì„ ë¶„ë¦¬í•˜ì—¬ ê³„ì‚° ë³µì¡ì„±ì„ ì¤„ì˜€ë‹¤.

- 4. ìƒìœ„ ìˆ˜ì¤€ì˜ ì¡°í•© ë¬¸ì œë¥¼ MDPë¡œ ì¬êµ¬ì„±í•˜ì—¬ ì·¨ì•½í•œ ì—ì´ì „íŠ¸ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹ë³„í•  ìˆ˜ ìˆê²Œ í•˜ì˜€ë‹¤.

- 5. ì œì•ˆëœ ë°©ë²•ì€ ëŒ€ê·œëª¨ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ê°•í™” í•™ìŠµì—ì„œ ë” ë§ì€ ì·¨ì•½í•œ ì—ì´ì „íŠ¸ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì‹ë³„í•œë‹¤.

---

*Generated on 2025-09-19 15:05:52*