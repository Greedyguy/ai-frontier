
# Middo: Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning

**Korean Title:** ë¯¸ë„: íë£¨í”„ í•™ìŠµì„ í†µí•œ í–¥ìƒëœ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM) ë¯¸ì„¸ ì¡°ì •ì„ ìœ„í•œ ëª¨ë¸ ì •ë³´ ê¸°ë°˜ ë™ì  ë°ì´í„° ìµœì í™”

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-19|2025-09-19]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Dynamic Data Optimization

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[Modular Machine Learning An Indispensable Path towards New-Generation Large Language Models]] (86.7% similar)
- [[DetectAnyLLM Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models]] (85.1% similar)
- [[Forget What You Know about LLMs Evaluations -- LLMs are Like a Chameleon]] (85.1% similar)
- [[LLM-I LLMs are Naturally Interleaved Multimodal Creators]] (84.9% similar)
- [[MedVAL Toward Expert-Level Medical Text Validation with Language Models]] (84.5% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2508.21589v2 Announce Type: replace-cross 
Abstract: Supervised Fine-Tuning (SFT) Large Language Models (LLM) fundamentally rely on high-quality training data. While data selection and data synthesis are two common strategies to improve data quality, existing approaches often face limitations in static dataset curation that fail to adapt to evolving model capabilities. In this paper, we introduce Middo, a self-evolving Model-informed dynamic data optimization framework that uses model-aware data selection and context-preserving data refinement. Unlike conventional one-off filtering/synthesis methods, our framework establishes a closed-loop optimization system: (1) A self-referential diagnostic module proactively identifies suboptimal samples through tri-axial model signals - loss patterns (complexity), embedding cluster dynamics (diversity), and self-alignment scores (quality); (2) An adaptive optimization engine then transforms suboptimal samples into pedagogically valuable training points while preserving semantic integrity; (3) This optimization process continuously evolves with model capability through dynamic learning principles. Experiments on multiple benchmarks demonstrate that our Middo consistently enhances the quality of seed data and boosts LLM's performance with improving accuracy by 7.15% on average while maintaining the original dataset scale. This work establishes a new paradigm for sustainable LLM training through dynamic human-AI co-evolution of data and models. Our datasets, models, and code are coming soon. Our datasets, models, and code are publicly available at https://github.com/Word2VecT/Middo

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2508.21589v2 ë°œí‘œ ìœ í˜•: êµì°¨ êµì²´  
ì´ˆë¡: ì§€ë„ í•™ìŠµ ë¯¸ì„¸ ì¡°ì •(SFT) ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ ë³¸ì§ˆì ìœ¼ë¡œ ê³ í’ˆì§ˆì˜ í›ˆë ¨ ë°ì´í„°ì— ì˜ì¡´í•©ë‹ˆë‹¤. ë°ì´í„° ì„ íƒê³¼ ë°ì´í„° í•©ì„±ì€ ë°ì´í„° í’ˆì§ˆì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ë‘ ê°€ì§€ ì¼ë°˜ì ì¸ ì „ëµì´ì§€ë§Œ, ê¸°ì¡´ ì ‘ê·¼ë²•ì€ ì§„í™”í•˜ëŠ” ëª¨ë¸ ëŠ¥ë ¥ì— ì ì‘í•˜ì§€ ëª»í•˜ëŠ” ì •ì  ë°ì´í„°ì…‹ íë ˆì´ì…˜ì˜ í•œê³„ì— ì§ë©´í•˜ê³¤ í•©ë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ëª¨ë¸ ì¸ì‹ ë°ì´í„° ì„ íƒê³¼ ë¬¸ë§¥ ë³´ì¡´ ë°ì´í„° ì •ì œë¥¼ ì‚¬ìš©í•˜ëŠ” ìê°€ ì§„í™” ëª¨ë¸ ì •ë³´ ê¸°ë°˜ ë™ì  ë°ì´í„° ìµœì í™” í”„ë ˆì„ì›Œí¬ì¸ Middoë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ì¼íšŒì„± í•„í„°ë§/í•©ì„± ë°©ë²•ê³¼ ë‹¬ë¦¬, ìš°ë¦¬ì˜ í”„ë ˆì„ì›Œí¬ëŠ” íì‡„ ë£¨í”„ ìµœì í™” ì‹œìŠ¤í…œì„ êµ¬ì¶•í•©ë‹ˆë‹¤: (1) ìê¸° ì°¸ì¡° ì§„ë‹¨ ëª¨ë“ˆì€ ì†ì‹¤ íŒ¨í„´(ë³µì¡ì„±), ì„ë² ë”© í´ëŸ¬ìŠ¤í„° ë™ì—­í•™(ë‹¤ì–‘ì„±), ìê¸° ì •ë ¬ ì ìˆ˜(í’ˆì§ˆ)ë¼ëŠ” ì‚¼ì¶• ëª¨ë¸ ì‹ í˜¸ë¥¼ í†µí•´ ë¹„ìµœì  ìƒ˜í”Œì„ ëŠ¥ë™ì ìœ¼ë¡œ ì‹ë³„í•©ë‹ˆë‹¤; (2) ì ì‘í˜• ìµœì í™” ì—”ì§„ì€ ì˜ë¯¸ì  ë¬´ê²°ì„±ì„ ìœ ì§€í•˜ë©´ì„œ ë¹„ìµœì  ìƒ˜í”Œì„ êµìœ¡ì ìœ¼ë¡œ ê°€ì¹˜ ìˆëŠ” í›ˆë ¨ í¬ì¸íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤; (3) ì´ ìµœì í™” ê³¼ì •ì€ ë™ì  í•™ìŠµ ì›ì¹™ì„ í†µí•´ ëª¨ë¸ ëŠ¥ë ¥ê³¼ í•¨ê»˜ ì§€ì†ì ìœ¼ë¡œ ì§„í™”í•©ë‹ˆë‹¤. ì—¬ëŸ¬ ë²¤ì¹˜ë§ˆí¬ ì‹¤í—˜ì—ì„œ ìš°ë¦¬ì˜ MiddoëŠ” ì‹œë“œ ë°ì´í„°ì˜ í’ˆì§ˆì„ ì§€ì†ì ìœ¼ë¡œ í–¥ìƒì‹œí‚¤ê³ , ì›ë˜ ë°ì´í„°ì…‹ ê·œëª¨ë¥¼ ìœ ì§€í•˜ë©´ì„œ í‰ê·  7.15%ì˜ ì •í™•ë„ í–¥ìƒì„ í†µí•´ LLMì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ë°ì´í„°ì™€ ëª¨ë¸ì˜ ë™ì  ì¸ê°„-AI ê³µë™ ì§„í™”ë¥¼ í†µí•œ ì§€ì† ê°€ëŠ¥í•œ LLM í›ˆë ¨ì˜ ìƒˆë¡œìš´ íŒ¨ëŸ¬ë‹¤ì„ì„ í™•ë¦½í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ë°ì´í„°ì…‹, ëª¨ë¸ ë° ì½”ë“œëŠ” ê³§ ê³µê°œë  ì˜ˆì •ì…ë‹ˆë‹¤. ìš°ë¦¬ì˜ ë°ì´í„°ì…‹, ëª¨ë¸ ë° ì½”ë“œëŠ” https://github.com/Word2VecT/Middoì—ì„œ ê³µê°œì ìœ¼ë¡œ ì´ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì—ì„œëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì§€ë„ í•™ìŠµì„ ìœ„í•œ ë°ì´í„° í’ˆì§ˆ í–¥ìƒì„ ìœ„í•´ Middoë¼ëŠ” ë™ì  ë°ì´í„° ìµœì í™” í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. MiddoëŠ” ëª¨ë¸ ì¸ì‹ ë°ì´í„° ì„ íƒê³¼ ë¬¸ë§¥ ë³´ì¡´ ë°ì´í„° ì •ì œë¥¼ í†µí•´ ë°ì´í„° í’ˆì§ˆì„ ê°œì„ í•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ì •ì  ë°ì´í„° í•„í„°ë§/í•©ì„± ë°©ë²•ê³¼ ë‹¬ë¦¬, MiddoëŠ” íì‡„í˜• ìµœì í™” ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ì—¬ ëª¨ë¸ ì‹ í˜¸ë¥¼ í†µí•´ ë¹„íš¨ìœ¨ì ì¸ ìƒ˜í”Œì„ ì‹ë³„í•˜ê³ , ì´ë¥¼ êµìœ¡ì ìœ¼ë¡œ ê°€ì¹˜ ìˆëŠ” ë°ì´í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, MiddoëŠ” ë°ì´í„° í’ˆì§ˆì„ í–¥ìƒì‹œí‚¤ê³  ëª¨ë¸ì˜ ì •í™•ë„ë¥¼ í‰ê·  7.15% ì¦ê°€ì‹œì¼°ìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ë°ì´í„°ì™€ ëª¨ë¸ì˜ ë™ì  ê³µë™ ì§„í™”ë¥¼ í†µí•´ ì§€ì† ê°€ëŠ¥í•œ LLM í•™ìŠµì˜ ìƒˆë¡œìš´ íŒ¨ëŸ¬ë‹¤ì„ì„ ì œì‹œí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. MiddoëŠ” ëª¨ë¸ ì¸ì‹ ë°ì´í„° ì„ íƒê³¼ ë¬¸ë§¥ ë³´ì¡´ ë°ì´í„° ì •ì œë¥¼ í™œìš©í•˜ì—¬ ë°ì´í„° ìµœì í™”ë¥¼ ìˆ˜í–‰í•˜ëŠ” ìê°€ ì§„í™” í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.

- 2. ê¸°ì¡´ì˜ ì¼íšŒì„± í•„í„°ë§/í•©ì„± ë°©ë²•ê³¼ ë‹¬ë¦¬, MiddoëŠ” ì†ì‹¤ íŒ¨í„´, ì„ë² ë”© í´ëŸ¬ìŠ¤í„° ë™íƒœ, ìê¸° ì •ë ¬ ì ìˆ˜ë¥¼ í™œìš©í•œ ì‚¼ì¶• ëª¨ë¸ ì‹ í˜¸ë¡œ ë¹„ìµœì  ìƒ˜í”Œì„ ì‹ë³„í•©ë‹ˆë‹¤.

- 3. ì ì‘í˜• ìµœì í™” ì—”ì§„ì€ ë¹„ìµœì  ìƒ˜í”Œì„ êµìœ¡ì ìœ¼ë¡œ ê°€ì¹˜ ìˆëŠ” í›ˆë ¨ ë°ì´í„°ë¡œ ë³€í™˜í•˜ë©°, ì˜ë¯¸ì  ë¬´ê²°ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤.

- 4. MiddoëŠ” ëª¨ë¸ì˜ ëŠ¥ë ¥ì— ë”°ë¼ ì§€ì†ì ìœ¼ë¡œ ì§„í™”í•˜ë©°, í‰ê·  7.15%ì˜ ì •í™•ë„ í–¥ìƒì„ ë‹¬ì„±í•©ë‹ˆë‹¤.

- 5. ì´ ì—°êµ¬ëŠ” ë™ì  ì¸ê°„-AI ê³µë™ ì§„í™”ë¥¼ í†µí•´ ì§€ì† ê°€ëŠ¥í•œ LLM í›ˆë ¨ì˜ ìƒˆë¡œìš´ íŒ¨ëŸ¬ë‹¤ì„ì„ ì œì‹œí•©ë‹ˆë‹¤.

---

*Generated on 2025-09-19 15:20:26*