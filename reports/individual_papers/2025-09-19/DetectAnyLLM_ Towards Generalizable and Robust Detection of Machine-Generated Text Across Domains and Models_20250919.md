---
keywords:
  - Large Language Models
  - Direct Discrepancy Learning
  - Machine-Generated Text Detection
category: cs.AI
publish_date: 2025-09-19
arxiv_id: 2509.14268
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 21:48:46.419867",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Models",
    "Direct Discrepancy Learning",
    "Machine-Generated Text Detection"
  ],
  "rejected_keywords": [
    "Natural Language Processing",
    "MIRAGE Benchmark"
  ],
  "similarity_scores": {
    "Large Language Models": 0.9,
    "Direct Discrepancy Learning": 0.85,
    "Machine-Generated Text Detection": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->


# DetectAnyLLM: Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models

**Korean Title:** DetectAnyLLM: 도메인 및 모델 전반에 걸쳐 기계 생성 텍스트의 일반화 가능하고 견고한 탐지를 향하여

## 📋 메타데이터

**Links**: [[digests/daily_digest_20250919|2025-09-19]]   [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**⚡ Unique Technical**: [[keywords/Direct Discrepancy Learning|Direct Discrepancy Learning]], [[keywords/Machine-Generated Text Detection|Machine-Generated Text Detection]]
**🚀 Evolved Concepts**: [[keywords/Large Language Models|Large Language Models]]

## 🔗 유사한 논문
- [[LLM-I LLMs are Naturally Interleaved Multimodal Creators]] (85.8% similar)
- [[Forget What You Know about LLMs Evaluations -- LLMs are Like a Chameleon]] (85.3% similar)
- [[Evaluating_and_Improving_the_Robustness_of_Security_Attack_Detectors_Generated_by_LLMs_20250918|Evaluating and Improving the Robustness of Security Attack Detectors Generated by LLMs]] (83.4% similar)
- [[Using LLMs in Generating Design Rationale for Software Architecture Decisions]] (82.8% similar)
- [[From Capabilities to Performance Evaluating Key Functional Properties of LLM Architectures in Penetration Testing]] (82.8% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.14268v1 Announce Type: cross 
Abstract: The rapid advancement of large language models (LLMs) has drawn urgent attention to the task of machine-generated text detection (MGTD). However, existing approaches struggle in complex real-world scenarios: zero-shot detectors rely heavily on scoring model's output distribution while training-based detectors are often constrained by overfitting to the training data, limiting generalization. We found that the performance bottleneck of training-based detectors stems from the misalignment between training objective and task needs. To address this, we propose Direct Discrepancy Learning (DDL), a novel optimization strategy that directly optimizes the detector with task-oriented knowledge. DDL enables the detector to better capture the core semantics of the detection task, thereby enhancing both robustness and generalization. Built upon this, we introduce DetectAnyLLM, a unified detection framework that achieves state-of-the-art MGTD performance across diverse LLMs. To ensure a reliable evaluation, we construct MIRAGE, the most diverse multi-task MGTD benchmark. MIRAGE samples human-written texts from 10 corpora across 5 text-domains, which are then re-generated or revised using 17 cutting-edge LLMs, covering a wide spectrum of proprietary models and textual styles. Extensive experiments on MIRAGE reveal the limitations of existing methods in complex environment. In contrast, DetectAnyLLM consistently outperforms them, achieving over a 70% performance improvement under the same training data and base scoring model, underscoring the effectiveness of our DDL. Project page: {https://fjc2005.github.io/detectanyllm}.

## 🔍 Abstract (한글 번역)

arXiv:2509.14268v1 발표 유형: 교차  
초록: 대형 언어 모델(LLM)의 급속한 발전은 기계 생성 텍스트 감지(MGTD) 작업에 대한 긴급한 관심을 불러일으켰습니다. 그러나 기존 접근 방식은 복잡한 실제 시나리오에서 어려움을 겪고 있습니다. 제로샷 탐지기는 모델의 출력 분포에 크게 의존하는 반면, 훈련 기반 탐지기는 종종 훈련 데이터에 대한 과적합으로 인해 일반화가 제한됩니다. 우리는 훈련 기반 탐지기의 성능 병목 현상이 훈련 목표와 작업 요구 사이의 불일치에서 비롯된다는 것을 발견했습니다. 이를 해결하기 위해, 우리는 작업 지향적 지식을 통해 탐지기를 직접 최적화하는 새로운 최적화 전략인 직접 불일치 학습(DDL)을 제안합니다. DDL은 탐지기가 탐지 작업의 핵심 의미를 더 잘 포착할 수 있게 하여 견고성과 일반화를 모두 향상시킵니다. 이를 바탕으로 다양한 LLM에서 최첨단 MGTD 성능을 달성하는 통합 탐지 프레임워크인 DetectAnyLLM을 소개합니다. 신뢰할 수 있는 평가를 보장하기 위해, 우리는 가장 다양한 다중 작업 MGTD 벤치마크인 MIRAGE를 구축합니다. MIRAGE는 5개의 텍스트 도메인에 걸쳐 10개의 코퍼스에서 인간이 작성한 텍스트를 샘플링한 후, 17개의 최첨단 LLM을 사용하여 재생성하거나 수정하여 광범위한 독점 모델과 텍스트 스타일을 포괄합니다. MIRAGE에 대한 광범위한 실험은 복잡한 환경에서 기존 방법의 한계를 드러냅니다. 반면에, DetectAnyLLM은 동일한 훈련 데이터와 기본 점수 모델 하에서 70% 이상의 성능 향상을 달성하여 DDL의 효과를 강조합니다. 프로젝트 페이지: {https://fjc2005.github.io/detectanyllm}.

## 📝 요약

이 논문은 대형 언어 모델(LLM)의 발전에 따라 기계 생성 텍스트 탐지(MGTD)의 중요성이 커지고 있는 상황에서, 기존 방법들이 복잡한 실제 환경에서 한계를 보인다는 문제를 다룹니다. 제로샷 탐지기는 모델의 출력 분포에 지나치게 의존하고, 학습 기반 탐지기는 과적합 문제로 일반화에 어려움을 겪습니다. 이를 해결하기 위해, 저자들은 Direct Discrepancy Learning(DDL)이라는 새로운 최적화 전략을 제안하여 탐지기의 성능을 향상시켰습니다. DDL은 탐지기가 핵심 의미를 더 잘 포착하도록 하여 강건성과 일반화를 개선합니다. 이를 바탕으로 DetectAnyLLM이라는 통합 탐지 프레임워크를 개발하여 다양한 LLM에 대해 최첨단 MGTD 성능을 달성했습니다. 또한, 다양한 다중 작업 MGTD 벤치마크인 MIRAGE를 구축하여 신뢰성 있는 평가를 가능하게 했습니다. 실험 결과, DetectAnyLLM은 기존 방법들보다 70% 이상 성능이 개선되었음을 보여주며, DDL의 효과를 입증합니다.

## 🎯 주요 포인트

- 1. 대형 언어 모델(LLM)의 발전으로 인해 기계 생성 텍스트 탐지(MGTD)의 중요성이 증가하고 있습니다.

- 2. 기존 탐지 방법은 복잡한 실제 환경에서 제약을 받으며, 특히 훈련 기반 탐지기는 과적합 문제로 일반화에 어려움을 겪고 있습니다.

- 3. Direct Discrepancy Learning(DDL)은 탐지기의 성능 병목을 해결하기 위해 제안된 새로운 최적화 전략으로, 탐지기의 핵심 의미를 더 잘 포착하여 강건성과 일반화를 향상시킵니다.

- 4. DetectAnyLLM은 다양한 LLM에서 최첨단 MGTD 성능을 달성하는 통합 탐지 프레임워크로, DDL의 효과를 입증합니다.

- 5. MIRAGE 벤치마크를 통해 기존 방법의 한계를 드러내며, DetectAnyLLM이 동일한 훈련 데이터와 모델에서 70% 이상의 성능 향상을 보여줍니다.

---

*Generated on 2025-09-19 14:52:29*