---
keywords:
  - Vision Transformers
  - Multimodal Contrastive Learning
  - Foundation Models
category: cs.AI
publish_date: 2025-09-19
arxiv_id: 2509.14084
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 21:59:06.523965",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Vision Transformers",
    "Multimodal Contrastive Learning",
    "Foundation Models"
  ],
  "rejected_keywords": [
    "Zero-Shot Anomaly Detection",
    "Anomaly-Aware Calibration Module"
  ],
  "similarity_scores": {
    "Vision Transformers": 0.82,
    "Multimodal Contrastive Learning": 0.79,
    "Foundation Models": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->


# AD-DINOv3: Enhancing DINOv3 for Zero-Shot Anomaly Detection with Anomaly-Aware Calibration

**Korean Title:** AD-DINOv3: ì´ìƒ ê°ì§€ ì¸ì‹ ë³´ì •ì„ í†µí•œ ì œë¡œìƒ· ì´ìƒ ê°ì§€ë¥¼ ìœ„í•œ DINOv3 ê°œì„ 

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[digests/daily_digest_20250919|2025-09-19]]   [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Vision Transformers|Vision Transformers]], [[keywords/Foundation Models|Foundation Models]]
**ğŸš€ Evolved Concepts**: [[keywords/Multimodal Contrastive Learning|Multimodal Contrastive Learning]]

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[Singular Value Few-shot Adaptation of Vision-Language Models_20250918|Singular Value Few-shot Adaptation of Vision-Language Models]] (81.4% similar)
- [[Multi-label Scene Classification for Autonomous Vehicles Acquiring and Accumulating Knowledge from Diverse Datasets]] (80.1% similar)
- [[DACoN DINO for Anime Paint Bucket Colorization with Any Number of Reference Images]] (79.8% similar)
- [[Seeing 3D Through 2D Lenses 3D Few-Shot Class-Incremental Learning via Cross-Modal Geometric Rectification]] (79.5% similar)
- [[An Empirical Analysis of VLM-based OOD Detection Mechanisms, Advantages, and Sensitivity]] (79.2% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.14084v2 Announce Type: replace 
Abstract: Zero-Shot Anomaly Detection (ZSAD) seeks to identify anomalies from arbitrary novel categories, offering a scalable and annotation-efficient solution. Traditionally, most ZSAD works have been based on the CLIP model, which performs anomaly detection by calculating the similarity between visual and text embeddings. Recently, vision foundation models such as DINOv3 have demonstrated strong transferable representation capabilities. In this work, we are the first to adapt DINOv3 for ZSAD. However, this adaptation presents two key challenges: (i) the domain bias between large-scale pretraining data and anomaly detection tasks leads to feature misalignment; and (ii) the inherent bias toward global semantics in pretrained representations often leads to subtle anomalies being misinterpreted as part of the normal foreground objects, rather than being distinguished as abnormal regions. To overcome these challenges, we introduce AD-DINOv3, a novel vision-language multimodal framework designed for ZSAD. Specifically, we formulate anomaly detection as a multimodal contrastive learning problem, where DINOv3 is employed as the visual backbone to extract patch tokens and a CLS token, and the CLIP text encoder provides embeddings for both normal and abnormal prompts. To bridge the domain gap, lightweight adapters are introduced in both modalities, enabling their representations to be recalibrated for the anomaly detection task. Beyond this baseline alignment, we further design an Anomaly-Aware Calibration Module (AACM), which explicitly guides the CLS token to attend to anomalous regions rather than generic foreground semantics, thereby enhancing discriminability. Extensive experiments on eight industrial and medical benchmarks demonstrate that AD-DINOv3 consistently matches or surpasses state-of-the-art methods.The code will be available at https://github.com/Kaisor-Yuan/AD-DINOv3.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.14084v2 ë°œí‘œ ìœ í˜•: êµì²´  
ì´ˆë¡: ì œë¡œìƒ· ì´ìƒ íƒì§€(ZSAD)ëŠ” ì„ì˜ì˜ ìƒˆë¡œìš´ ë²”ì£¼ì—ì„œ ì´ìƒì„ ì‹ë³„í•˜ì—¬ í™•ì¥ ê°€ëŠ¥í•˜ê³  ì£¼ì„ íš¨ìœ¨ì ì¸ ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤. ì „í†µì ìœ¼ë¡œ ëŒ€ë¶€ë¶„ì˜ ZSAD ì—°êµ¬ëŠ” ì‹œê° ë° í…ìŠ¤íŠ¸ ì„ë² ë”© ê°„ì˜ ìœ ì‚¬ì„±ì„ ê³„ì‚°í•˜ì—¬ ì´ìƒ íƒì§€ë¥¼ ìˆ˜í–‰í•˜ëŠ” CLIP ëª¨ë¸ì— ê¸°ë°˜ì„ ë‘ê³  ìˆìŠµë‹ˆë‹¤. ìµœê·¼ DINOv3ì™€ ê°™ì€ ë¹„ì „ ê¸°ë°˜ ëª¨ë¸ì€ ê°•ë ¥í•œ ì „ì´ í‘œí˜„ ëŠ¥ë ¥ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” DINOv3ë¥¼ ZSADì— ìµœì´ˆë¡œ ì ìš©í–ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ ì ì‘ì—ëŠ” ë‘ ê°€ì§€ ì£¼ìš” ê³¼ì œê°€ ìˆìŠµë‹ˆë‹¤: (i) ëŒ€ê·œëª¨ ì‚¬ì „ í•™ìŠµ ë°ì´í„°ì™€ ì´ìƒ íƒì§€ ì‘ì—… ê°„ì˜ ë„ë©”ì¸ í¸í–¥ìœ¼ë¡œ ì¸í•´ íŠ¹ì§• ì •ë ¬ì´ ì˜ëª»ë  ìˆ˜ ìˆìœ¼ë©°; (ii) ì‚¬ì „ í•™ìŠµëœ í‘œí˜„ì˜ ì „ì—­ ì˜ë¯¸ë¡ ì— ëŒ€í•œ ë‚´ì¬ì  í¸í–¥ìœ¼ë¡œ ì¸í•´ ë¯¸ì„¸í•œ ì´ìƒì´ ì •ìƒì ì¸ ì „ê²½ ê°ì²´ì˜ ì¼ë¶€ë¡œ ì˜ëª» í•´ì„ë˜ì–´ ë¹„ì •ìƒ ì˜ì—­ìœ¼ë¡œ êµ¬ë³„ë˜ì§€ ì•ŠëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ê³¼ì œë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ZSADë¥¼ ìœ„í•´ ì„¤ê³„ëœ ìƒˆë¡œìš´ ë¹„ì „-ì–¸ì–´ ë©€í‹°ëª¨ë‹¬ í”„ë ˆì„ì›Œí¬ì¸ AD-DINOv3ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. êµ¬ì²´ì ìœ¼ë¡œ, ìš°ë¦¬ëŠ” ì´ìƒ íƒì§€ë¥¼ ë©€í‹°ëª¨ë‹¬ ëŒ€ì¡° í•™ìŠµ ë¬¸ì œë¡œ ê³µì‹í™”í•˜ë©°, DINOv3ë¥¼ ì‹œê°ì  ë°±ë³¸ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ íŒ¨ì¹˜ í† í°ê³¼ CLS í† í°ì„ ì¶”ì¶œí•˜ê³ , CLIP í…ìŠ¤íŠ¸ ì¸ì½”ë”ëŠ” ì •ìƒ ë° ë¹„ì •ìƒ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•œ ì„ë² ë”©ì„ ì œê³µí•©ë‹ˆë‹¤. ë„ë©”ì¸ ê²©ì°¨ë¥¼ í•´ì†Œí•˜ê¸° ìœ„í•´, ë‘ ê°€ì§€ ëª¨ë‹¬ë¦¬í‹°ì— ê²½ëŸ‰ ì–´ëŒ‘í„°ë¥¼ ë„ì…í•˜ì—¬ ì´ìƒ íƒì§€ ì‘ì—…ì— ë§ê²Œ í‘œí˜„ì„ ì¬ì¡°ì •í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. ì´ ê¸°ë³¸ ì •ë ¬ì„ ë„˜ì–´, ìš°ë¦¬ëŠ” CLS í† í°ì´ ì¼ë°˜ì ì¸ ì „ê²½ ì˜ë¯¸ë¡ ë³´ë‹¤ ë¹„ì •ìƒ ì˜ì—­ì— ì£¼ëª©í•˜ë„ë¡ ëª…ì‹œì ìœ¼ë¡œ ì•ˆë‚´í•˜ëŠ” ì´ìƒ ì¸ì‹ ë³´ì • ëª¨ë“ˆ(AACM)ì„ ì¶”ê°€ ì„¤ê³„í•˜ì—¬ ë³€ë³„ë ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. 8ê°œì˜ ì‚°ì—… ë° ì˜ë£Œ ë²¤ì¹˜ë§ˆí¬ì— ëŒ€í•œ ê´‘ë²”ìœ„í•œ ì‹¤í—˜ì„ í†µí•´ AD-DINOv3ê°€ ì¼ê´€ë˜ê²Œ ìµœì²¨ë‹¨ ë°©ë²•ê³¼ ë™ë“±í•˜ê±°ë‚˜ ê·¸ ì´ìƒì˜ ì„±ëŠ¥ì„ ë°œíœ˜í•¨ì„ ì…ì¦í•©ë‹ˆë‹¤. ì½”ë“œëŠ” https://github.com/Kaisor-Yuan/AD-DINOv3ì—ì„œ ì œê³µë  ì˜ˆì •ì…ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ Zero-Shot Anomaly Detection(ZSAD)ì—ì„œ DINOv3 ëª¨ë¸ì„ ìµœì´ˆë¡œ ì ìš©í•˜ì—¬ ìƒˆë¡œìš´ ë¹„ì •ìƒ ë²”ì£¼ë¥¼ ì‹ë³„í•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ CLIP ëª¨ë¸ ê¸°ë°˜ì˜ ZSAD ì ‘ê·¼ë²•ê³¼ ë‹¬ë¦¬, DINOv3ì˜ ê°•ë ¥í•œ ì „ì´ í•™ìŠµ ëŠ¥ë ¥ì„ í™œìš©í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ëŒ€ê·œëª¨ ì‚¬ì „ í•™ìŠµ ë°ì´í„°ì™€ ë¹„ì •ìƒ íƒì§€ ì‘ì—… ê°„ì˜ ë„ë©”ì¸ í¸í–¥, ê·¸ë¦¬ê³  ì‚¬ì „ í•™ìŠµëœ í‘œí˜„ì˜ ì „ì—­ ì˜ë¯¸ í¸í–¥ìœ¼ë¡œ ì¸í•´ ë°œìƒí•˜ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, AD-DINOv3ë¼ëŠ” ìƒˆë¡œìš´ ë¹„ì „-ì–¸ì–´ ë©€í‹°ëª¨ë‹¬ í”„ë ˆì„ì›Œí¬ë¥¼ ë„ì…í–ˆìŠµë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ë©€í‹°ëª¨ë‹¬ ëŒ€ì¡° í•™ìŠµ ë¬¸ì œë¡œ ë¹„ì •ìƒ íƒì§€ë¥¼ ì •ì˜í•˜ê³ , DINOv3ë¥¼ ì‹œê°ì  ë°±ë³¸ìœ¼ë¡œ ì‚¬ìš©í•˜ë©°, CLIP í…ìŠ¤íŠ¸ ì¸ì½”ë”ë¥¼ í†µí•´ ì •ìƒ ë° ë¹„ì •ìƒ í”„ë¡¬í”„íŠ¸ì˜ ì„ë² ë”©ì„ ì œê³µí•©ë‹ˆë‹¤. ë„ë©”ì¸ ê²©ì°¨ë¥¼ ì¤„ì´ê¸° ìœ„í•´ ê²½ëŸ‰ ì–´ëŒ‘í„°ë¥¼ ë„ì…í•˜ê³ , Anomaly-Aware Calibration Module(AACM)ì„ ì„¤ê³„í•˜ì—¬ CLS í† í°ì´ ë¹„ì •ìƒ ì˜ì—­ì— ì§‘ì¤‘í•˜ë„ë¡ ìœ ë„í•©ë‹ˆë‹¤. 8ê°œì˜ ì‚°ì—… ë° ì˜ë£Œ ë²¤ì¹˜ë§ˆí¬ ì‹¤í—˜ì—ì„œ AD-DINOv3ëŠ” ìµœì‹  ê¸°ë²•ê³¼ ë™ë“±í•˜ê±°ë‚˜ ì´ë¥¼ ëŠ¥ê°€í•˜ëŠ” ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Zero-Shot Anomaly Detection(ZSAD)ëŠ” ìƒˆë¡œìš´ ë²”ì£¼ì˜ ì´ìƒì„ ì‹ë³„í•˜ì—¬ í™•ì¥ ê°€ëŠ¥í•˜ê³  ì£¼ì„ íš¨ìœ¨ì ì¸ ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.

- 2. ê¸°ì¡´ ZSAD ì—°êµ¬ëŠ” ì£¼ë¡œ CLIP ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ í–ˆìœ¼ë‚˜, ë³¸ ì—°êµ¬ì—ì„œëŠ” DINOv3ë¥¼ ìµœì´ˆë¡œ ZSADì— ì ìš©í–ˆìŠµë‹ˆë‹¤.

- 3. DINOv3ì˜ ZSAD ì ìš© ì‹œ, ëŒ€ê·œëª¨ ì‚¬ì „ í•™ìŠµ ë°ì´í„°ì™€ ì´ìƒ íƒì§€ ì‘ì—… ê°„ì˜ ë„ë©”ì¸ í¸í–¥ ë° ì „ì—­ ì˜ë¯¸ì— ëŒ€í•œ í¸í–¥ì´ ë¬¸ì œë¡œ ì‘ìš©í•©ë‹ˆë‹¤.

- 4. AD-DINOv3ëŠ” ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì„¤ê³„ëœ ìƒˆë¡œìš´ ë¹„ì „-ì–¸ì–´ ë©€í‹°ëª¨ë‹¬ í”„ë ˆì„ì›Œí¬ë¡œ, ë©€í‹°ëª¨ë‹¬ ëŒ€ì¡° í•™ìŠµ ë¬¸ì œë¡œ ì´ìƒ íƒì§€ë¥¼ ê³µì‹í™”í•©ë‹ˆë‹¤.

- 5. AD-DINOv3ëŠ” 8ê°œì˜ ì‚°ì—… ë° ì˜ë£Œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìµœì‹  ë°©ë²•ê³¼ ë¹„êµí•˜ì—¬ ì¼ê´€ë˜ê²Œ ë™ë“±í•˜ê±°ë‚˜ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

---

*Generated on 2025-09-19 16:19:58*