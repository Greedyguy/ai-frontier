
# Hybrid Autoregressive-Diffusion Model for Real-Time Sign Language Production

**Korean Title:** ì‹¤ì‹œê°„ ìˆ˜ì–´ ìƒì„±ìš© í•˜ì´ë¸Œë¦¬ë“œ ìê¸°íšŒê·€-í™•ì‚° ëª¨ë¸

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-19|2025-09-19]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Hybrid Autoregressive-Diffusion Model

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[SSL-SSAW Self-Supervised Learning with Sigmoid Self-Attention Weighting for Question-Based Sign Language Translation]] (82.8% similar)
- [[Towards Human-like Multimodal Conversational Agent by Generating Engaging Speech_20250919|Towards Human-like Multimodal Conversational Agent by Generating Engaging Speech]] (81.6% similar)
- [[Kling-Avatar Grounding Multimodal Instructions for Cascaded Long-Duration Avatar Animation Synthesis]] (81.6% similar)
- [[DSCC-HS A Dynamic Self-Reinforcing Framework for Hallucination Suppression in Large Language Models]] (80.4% similar)
- [[Diffusion-Based Unsupervised Audio-Visual Speech Separation in Noisy Environments with Noise Prior_20250919|Diffusion-Based Unsupervised Audio-Visual Speech Separation in Noisy Environments with Noise Prior]] (80.2% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2507.09105v3 Announce Type: replace 
Abstract: Earlier Sign Language Production (SLP) models typically relied on autoregressive methods that generate output tokens one by one, which inherently provide temporal alignment. Although techniques like Teacher Forcing can prevent model collapse during training, they still cannot solve the problem of error accumulation during inference, since ground truth is unavailable at that stage. In contrast, more recent approaches based on diffusion models leverage step-by-step denoising to enable high-quality generation. However, the iterative nature of these models and the requirement to denoise entire sequences limit their applicability in real-time tasks like SLP. To address it, we explore a hybrid approach that combines autoregressive and diffusion models for SLP, leveraging the strengths of both models in sequential dependency modeling and output refinement. To capture fine-grained body movements, we design a Multi-Scale Pose Representation module that separately extracts detailed features from distinct articulators and integrates them via a Multi-Scale Fusion module. Furthermore, we introduce a Confidence-Aware Causal Attention mechanism that utilizes joint-level confidence scores to dynamically guide the pose generation process, improving accuracy and robustness. Extensive experiments on the PHOENIX14T and How2Sign datasets demonstrate the effectiveness of our method in both generation quality and real-time efficiency.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2507.09105v3 ë°œí‘œ ìœ í˜•: êµì²´  
ì´ˆë¡: ì´ˆê¸° ìˆ˜ì–´ ìƒì„±(SLP) ëª¨ë¸ì€ ì¼ë°˜ì ìœ¼ë¡œ ì¶œë ¥ í† í°ì„ í•˜ë‚˜ì”© ìƒì„±í•˜ëŠ” ìê¸°íšŒê·€ ë°©ë²•ì— ì˜ì¡´í–ˆìœ¼ë©°, ì´ëŠ” ë³¸ì§ˆì ìœ¼ë¡œ ì‹œê°„ì  ì •ë ¬ì„ ì œê³µí•©ë‹ˆë‹¤. êµì‚¬ ê°•ì œ(Teacher Forcing)ì™€ ê°™ì€ ê¸°ë²•ì€ í›ˆë ¨ ì¤‘ ëª¨ë¸ ë¶•ê´´ë¥¼ ë°©ì§€í•  ìˆ˜ ìˆì§€ë§Œ, ì¶”ë¡  ë‹¨ê³„ì—ì„œëŠ” ì •ë‹µì´ ì—†ê¸° ë•Œë¬¸ì— ì˜¤ë¥˜ ëˆ„ì  ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°˜ë©´ì—, ìµœê·¼ì˜ í™•ì‚° ëª¨ë¸ ê¸°ë°˜ ì ‘ê·¼ ë°©ì‹ì€ ë‹¨ê³„ë³„ ë…¸ì´ì¦ˆ ì œê±°ë¥¼ í†µí•´ ê³ í’ˆì§ˆ ìƒì„±ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ëŸ¬í•œ ëª¨ë¸ì˜ ë°˜ë³µì  íŠ¹ì„±ê³¼ ì „ì²´ ì‹œí€€ìŠ¤ë¥¼ ë…¸ì´ì¦ˆ ì œê±°í•´ì•¼ í•˜ëŠ” ìš”êµ¬ì‚¬í•­ì€ SLPì™€ ê°™ì€ ì‹¤ì‹œê°„ ì‘ì—…ì—ì„œì˜ ì ìš© ê°€ëŠ¥ì„±ì„ ì œí•œí•©ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ìê¸°íšŒê·€ ëª¨ë¸ê³¼ í™•ì‚° ëª¨ë¸ì„ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ ë°©ì‹ì„ íƒêµ¬í•˜ì—¬, ìˆœì°¨ì  ì¢…ì†ì„± ëª¨ë¸ë§ê³¼ ì¶œë ¥ ì •ì œì—ì„œ ë‘ ëª¨ë¸ì˜ ê°•ì ì„ í™œìš©í•©ë‹ˆë‹¤. ì„¸ë°€í•œ ì‹ ì²´ ì›€ì§ì„ì„ í¬ì°©í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ì„œë¡œ ë‹¤ë¥¸ ê´€ì ˆì—ì„œ ì„¸ë¶€ì ì¸ íŠ¹ì§•ì„ ê°œë³„ì ìœ¼ë¡œ ì¶”ì¶œí•˜ê³  ì´ë¥¼ ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ìœµí•© ëª¨ë“ˆì„ í†µí•´ í†µí•©í•˜ëŠ” ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ìì„¸ í‘œí˜„ ëª¨ë“ˆì„ ì„¤ê³„í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, ê´€ì ˆ ìˆ˜ì¤€ì˜ ì‹ ë¢°ë„ ì ìˆ˜ë¥¼ í™œìš©í•˜ì—¬ ìì„¸ ìƒì„± ê³¼ì •ì„ ë™ì ìœ¼ë¡œ ì•ˆë‚´í•¨ìœ¼ë¡œì¨ ì •í™•ì„±ê³¼ ê²¬ê³ ì„±ì„ í–¥ìƒì‹œí‚¤ëŠ” ì‹ ë¢°ë„ ì¸ì‹ ì¸ê³¼ì  ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì„ ë„ì…í–ˆìŠµë‹ˆë‹¤. PHOENIX14T ë° How2Sign ë°ì´í„°ì…‹ì— ëŒ€í•œ ê´‘ë²”ìœ„í•œ ì‹¤í—˜ì€ ìƒì„± í’ˆì§ˆê³¼ ì‹¤ì‹œê°„ íš¨ìœ¨ì„± ëª¨ë‘ì—ì„œ ìš°ë¦¬ì˜ ë°©ë²•ì˜ íš¨ê³¼ë¥¼ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ìˆ˜ì–´ ìƒì„±(SLP) ëª¨ë¸ì—ì„œì˜ ìƒˆë¡œìš´ ì ‘ê·¼ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ìíšŒê·€ ëª¨ë¸ì€ ì‹œê°„ ì •ë ¬ì„ ì œê³µí•˜ì§€ë§Œ, ì˜¤ë¥˜ ëˆ„ì  ë¬¸ì œë¥¼ í•´ê²°í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ìµœê·¼ì˜ í™•ì‚° ëª¨ë¸ì€ ê³ í’ˆì§ˆ ìƒì„±ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ì§€ë§Œ, ì‹¤ì‹œê°„ ì‘ì—…ì—ëŠ” í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ëŠ” ìíšŒê·€ ëª¨ë¸ê³¼ í™•ì‚° ëª¨ë¸ì„ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ë²•ì„ í†µí•´ ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³ ì í•©ë‹ˆë‹¤. ì„¸ë°€í•œ ì‹ ì²´ ì›€ì§ì„ì„ í¬ì°©í•˜ê¸° ìœ„í•´ ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ìì„¸ í‘œí˜„ ëª¨ë“ˆì„ ì„¤ê³„í•˜ê³ , ìì‹ ê° ì¸ì‹ ì¸ê³¼ì£¼ì˜ ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì„ ë„ì…í•˜ì—¬ ìì„¸ ìƒì„±ì˜ ì •í™•ì„±ê³¼ ê²¬ê³ ì„±ì„ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤. PHOENIX14Tì™€ How2Sign ë°ì´í„°ì…‹ì„ í™œìš©í•œ ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì´ ìƒì„± í’ˆì§ˆê³¼ ì‹¤ì‹œê°„ íš¨ìœ¨ì„±ì—ì„œ ìš°ìˆ˜í•¨ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ê¸°ì¡´ ìˆ˜ì–´ ìƒì„± ëª¨ë¸ì€ ìˆœì°¨ì ìœ¼ë¡œ ì¶œë ¥ì„ ìƒì„±í•˜ëŠ” ìê¸°íšŒê·€ ë°©ì‹ì„ ì‚¬ìš©í•˜ì—¬ ì‹œê°„ì  ì •ë ¬ì„ ì œê³µí–ˆìœ¼ë‚˜, ì˜¤ë¥˜ ëˆ„ì  ë¬¸ì œë¥¼ í•´ê²°í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.

- 2. ìµœê·¼ í™•ì‚° ëª¨ë¸ ê¸°ë°˜ ì ‘ê·¼ë²•ì€ ë‹¨ê³„ë³„ ë…¸ì´ì¦ˆ ì œê±°ë¥¼ í†µí•´ ê³ í’ˆì§ˆ ìƒì„±ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ì§€ë§Œ, ì‹¤ì‹œê°„ ì‘ì—…ì—ëŠ” í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤.

- 3. ìê¸°íšŒê·€ ëª¨ë¸ê³¼ í™•ì‚° ëª¨ë¸ì„ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ë²•ì„ í†µí•´ ìˆœì°¨ì  ì˜ì¡´ì„± ëª¨ë¸ë§ê³¼ ì¶œë ¥ ì •ì œë¥¼ ë™ì‹œì— í™œìš©í•©ë‹ˆë‹¤.

- 4. ì„¸ë°€í•œ ì‹ ì²´ ì›€ì§ì„ì„ í¬ì°©í•˜ê¸° ìœ„í•´ Multi-Scale Pose Representation ëª¨ë“ˆì„ ì„¤ê³„í•˜ì—¬ ë‹¤ì–‘í•œ ê´€ì ˆì—ì„œ ì„¸ë¶€ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ê³  í†µí•©í•©ë‹ˆë‹¤.

- 5. Confidence-Aware Causal Attention ë©”ì»¤ë‹ˆì¦˜ì„ ë„ì…í•˜ì—¬ ê´€ì ˆ ìˆ˜ì¤€ì˜ ì‹ ë¢°ë„ ì ìˆ˜ë¥¼ í™œìš©í•´ ìì„¸ ìƒì„± ê³¼ì •ì„ ë™ì ìœ¼ë¡œ ì•ˆë‚´í•¨ìœ¼ë¡œì¨ ì •í™•ì„±ê³¼ ê²¬ê³ ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

---

*Generated on 2025-09-19 16:18:09*