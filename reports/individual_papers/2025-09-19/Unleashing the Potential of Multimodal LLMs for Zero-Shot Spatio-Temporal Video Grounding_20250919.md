
# Unleashing the Potential of Multimodal LLMs for Zero-Shot Spatio-Temporal Video Grounding

**Korean Title:** ë‹¤ì¤‘ ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì ì¬ë ¥ ë°œíœ˜ë¥¼ í†µí•œ ì œë¡œìƒ· ì‹œê³µê°„ ë¹„ë””ì˜¤ ê·¸ë¼ìš´ë”©

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-19|2025-09-19]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Temporal-Augmented Assembling

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[DetectAnyLLM Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models]] (83.4% similar)
- [[Modular Machine Learning An Indispensable Path towards New-Generation Large Language Models]] (82.5% similar)
- [[LLM-I LLMs are Naturally Interleaved Multimodal Creators]] (82.4% similar)
- [[Large Multi-modal Models Can Interpret Features in Large Multi-modal Models_20250919|Large Multi-modal Models Can Interpret Features in Large Multi-modal Models]] (82.4% similar)
- [[Decoupled Proxy Alignment Mitigating Language Prior Conflict for Multimodal Alignment in MLLM]] (82.2% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15178v1 Announce Type: new 
Abstract: Spatio-temporal video grounding (STVG) aims at localizing the spatio-temporal tube of a video, as specified by the input text query. In this paper, we utilize multimodal large language models (MLLMs) to explore a zero-shot solution in STVG. We reveal two key insights about MLLMs: (1) MLLMs tend to dynamically assign special tokens, referred to as \textit{grounding tokens}, for grounding the text query; and (2) MLLMs often suffer from suboptimal grounding due to the inability to fully integrate the cues in the text query (\textit{e.g.}, attributes, actions) for inference. Based on these insights, we propose a MLLM-based zero-shot framework for STVG, which includes novel decomposed spatio-temporal highlighting (DSTH) and temporal-augmented assembling (TAS) strategies to unleash the reasoning ability of MLLMs. The DSTH strategy first decouples the original query into attribute and action sub-queries for inquiring the existence of the target both spatially and temporally. It then uses a novel logit-guided re-attention (LRA) module to learn latent variables as spatial and temporal prompts, by regularizing token predictions for each sub-query. These prompts highlight attribute and action cues, respectively, directing the model's attention to reliable spatial and temporal related visual regions. In addition, as the spatial grounding by the attribute sub-query should be temporally consistent, we introduce the TAS strategy to assemble the predictions using the original video frames and the temporal-augmented frames as inputs to help improve temporal consistency. We evaluate our method on various MLLMs, and show that it outperforms SOTA methods on three common STVG benchmarks.
  The code will be available at https://github.com/zaiquanyang/LLaVA_Next_STVG.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15178v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: ì‹œê³µê°„ ë¹„ë””ì˜¤ ê·¸ë¼ìš´ë”©(STVG)ì€ ì…ë ¥ í…ìŠ¤íŠ¸ ì¿¼ë¦¬ì— ì˜í•´ ì§€ì •ëœ ë¹„ë””ì˜¤ì˜ ì‹œê³µê°„ íŠœë¸Œë¥¼ ë¡œì»¬ë¼ì´ì§•í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤. ì´ ë…¼ë¬¸ì—ì„œëŠ” ë‹¤ì¤‘ ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(MLLMs)ì„ í™œìš©í•˜ì—¬ STVGì—ì„œ ì œë¡œìƒ· ì†”ë£¨ì…˜ì„ íƒêµ¬í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” MLLMsì— ëŒ€í•œ ë‘ ê°€ì§€ ì£¼ìš” í†µì°°ì„ ì œì‹œí•©ë‹ˆë‹¤: (1) MLLMsëŠ” í…ìŠ¤íŠ¸ ì¿¼ë¦¬ë¥¼ ê·¸ë¼ìš´ë”©í•˜ê¸° ìœ„í•´ \textit{ê·¸ë¼ìš´ë”© í† í°}ì´ë¼ê³  ë¶ˆë¦¬ëŠ” íŠ¹ë³„í•œ í† í°ì„ ë™ì ìœ¼ë¡œ í• ë‹¹í•˜ëŠ” ê²½í–¥ì´ ìˆìœ¼ë©°; (2) MLLMsëŠ” í…ìŠ¤íŠ¸ ì¿¼ë¦¬ì˜ ë‹¨ì„œë¥¼ ì™„ì „íˆ í†µí•©í•˜ì§€ ëª»í•´ (\textit{ì˜ˆ:} ì†ì„±, í–‰ë™) ìµœì ì´ ì•„ë‹Œ ê·¸ë¼ìš´ë”©ì„ ê²½í—˜í•˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ í†µì°°ì„ ë°”íƒ•ìœ¼ë¡œ, ìš°ë¦¬ëŠ” MLLMs ê¸°ë°˜ì˜ ì œë¡œìƒ· STVG í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•˜ë©°, ì´ëŠ” MLLMsì˜ ì¶”ë¡  ëŠ¥ë ¥ì„ ë°œíœ˜í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ë¶„í•´ëœ ì‹œê³µê°„ ê°•ì¡°(DSTH) ë° ì‹œê°„ ë³´ê°• ì¡°ë¦½(TAS) ì „ëµì„ í¬í•¨í•©ë‹ˆë‹¤. DSTH ì „ëµì€ ë¨¼ì € ì›ë˜ ì¿¼ë¦¬ë¥¼ ì†ì„±ê³¼ í–‰ë™ í•˜ìœ„ ì¿¼ë¦¬ë¡œ ë¶„ë¦¬í•˜ì—¬ ëŒ€ìƒì˜ ì¡´ì¬ë¥¼ ì‹œê³µê°„ì ìœ¼ë¡œ ë¬»ìŠµë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ ìƒˆë¡œìš´ ë¡œì§“ ìœ ë„ ì¬ì£¼ì˜(LRA) ëª¨ë“ˆì„ ì‚¬ìš©í•˜ì—¬ ê° í•˜ìœ„ ì¿¼ë¦¬ì— ëŒ€í•œ í† í° ì˜ˆì¸¡ì„ ì •ê·œí™”í•¨ìœ¼ë¡œì¨ ì ì¬ ë³€ìˆ˜ë¥¼ ì‹œê³µê°„ í”„ë¡¬í”„íŠ¸ë¡œ í•™ìŠµí•©ë‹ˆë‹¤. ì´ëŸ¬í•œ í”„ë¡¬í”„íŠ¸ëŠ” ê°ê° ì†ì„±ê³¼ í–‰ë™ ë‹¨ì„œë¥¼ ê°•ì¡°í•˜ì—¬ ëª¨ë¸ì˜ ì£¼ì˜ë¥¼ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì‹œê³µê°„ ê´€ë ¨ ì‹œê°ì  ì˜ì—­ìœ¼ë¡œ ìœ ë„í•©ë‹ˆë‹¤. ë˜í•œ, ì†ì„± í•˜ìœ„ ì¿¼ë¦¬ì— ì˜í•œ ê³µê°„ì  ê·¸ë¼ìš´ë”©ì€ ì‹œê°„ì ìœ¼ë¡œ ì¼ê´€ë˜ì–´ì•¼ í•˜ë¯€ë¡œ, ìš°ë¦¬ëŠ” ì›ë˜ ë¹„ë””ì˜¤ í”„ë ˆì„ê³¼ ì‹œê°„ ë³´ê°• í”„ë ˆì„ì„ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ì„ ì¡°ë¦½í•˜ëŠ” TAS ì „ëµì„ ë„ì…í•˜ì—¬ ì‹œê°„ì  ì¼ê´€ì„±ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ë‹¤ì–‘í•œ MLLMsì—ì„œ ìš°ë¦¬ì˜ ë°©ë²•ì„ í‰ê°€í•˜ì˜€ìœ¼ë©°, ì„¸ ê°€ì§€ ì¼ë°˜ì ì¸ STVG ë²¤ì¹˜ë§ˆí¬ì—ì„œ SOTA ë°©ë²•ì„ ëŠ¥ê°€í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  
ì½”ë“œëŠ” https://github.com/zaiquanyang/LLaVA_Next_STVGì—ì„œ ì œê³µë  ì˜ˆì •ì…ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì‹œê³µê°„ ë¹„ë””ì˜¤ ê·¸ë¼ìš´ë”©(STVG) ë¬¸ì œë¥¼ ë‹¤ë£¨ë©°, ë©€í‹°ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(MLLM)ì„ í™œìš©í•œ ì œë¡œìƒ· ì ‘ê·¼ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì£¼ìš” ê¸°ì—¬ëŠ” MLLMì˜ ë‘ ê°€ì§€ í†µì°°ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¡œ, ì²«ì§¸, MLLMì€ í…ìŠ¤íŠ¸ ì¿¼ë¦¬ë¥¼ ê·¸ë¼ìš´ë”©í•˜ê¸° ìœ„í•´ ë™ì ìœ¼ë¡œ íŠ¹ë³„ í† í°ì„ í• ë‹¹í•˜ê³ , ë‘˜ì§¸, í…ìŠ¤íŠ¸ ì¿¼ë¦¬ì˜ ë‹¨ì„œë¥¼ ì™„ì „íˆ í†µí•©í•˜ì§€ ëª»í•´ ìµœì ì˜ ê·¸ë¼ìš´ë”©ì„ ë‹¬ì„±í•˜ì§€ ëª»í•œë‹¤ëŠ” ì ì…ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ì†ì„±ê³¼ í–‰ë™ ì„œë¸Œ ì¿¼ë¦¬ë¡œ ì›ë˜ ì¿¼ë¦¬ë¥¼ ë¶„í•´í•˜ì—¬ ì‹œê³µê°„ì  í•˜ì´ë¼ì´íŒ…(DSTH)ê³¼ ì‹œê°„ ë³´ê°• ì¡°ë¦½(TAS) ì „ëµì„ ì œì•ˆí•©ë‹ˆë‹¤. DSTHëŠ” ì†ì„±ê³¼ í–‰ë™ ë‹¨ì„œë¥¼ ê°•ì¡°í•˜ì—¬ ëª¨ë¸ì˜ ì£¼ì˜ë¥¼ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì‹œê³µê°„ ê´€ë ¨ ì‹œê° ì˜ì—­ìœ¼ë¡œ ìœ ë„í•©ë‹ˆë‹¤. TASëŠ” ì‹œê°„ì  ì¼ê´€ì„±ì„ ë†’ì´ê¸° ìœ„í•´ ì›ë³¸ ë¹„ë””ì˜¤ í”„ë ˆì„ê³¼ ì‹œê°„ ë³´ê°• í”„ë ˆì„ì„ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ì„ ì¡°ë¦½í•©ë‹ˆë‹¤. ì œì•ˆëœ ë°©ë²•ì€ ì„¸ ê°€ì§€ STVG ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìµœì‹  ë°©ë²•ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë³¸ ë…¼ë¬¸ì€ ë‹¤ì¤‘ ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(MLLMs)ì„ í™œìš©í•˜ì—¬ ê³µê°„-ì‹œê°„ ë¹„ë””ì˜¤ ê·¸ë¼ìš´ë”©(STVG)ì˜ ì œë¡œìƒ· ì†”ë£¨ì…˜ì„ íƒêµ¬í•©ë‹ˆë‹¤.

- 2. MLLMsëŠ” í…ìŠ¤íŠ¸ ì¿¼ë¦¬ë¥¼ ê·¸ë¼ìš´ë”©í•˜ê¸° ìœ„í•´ ë™ì ìœ¼ë¡œ íŠ¹ìˆ˜ í† í°ì„ í• ë‹¹í•˜ì§€ë§Œ, í…ìŠ¤íŠ¸ ì¿¼ë¦¬ì˜ ë‹¨ì„œë¥¼ ì™„ì „íˆ í†µí•©í•˜ì§€ ëª»í•´ ìµœì ì˜ ê·¸ë¼ìš´ë”©ì„ ìˆ˜í–‰í•˜ì§€ ëª»í•˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.

- 3. ì œì•ˆëœ MLLM ê¸°ë°˜ ì œë¡œìƒ· í”„ë ˆì„ì›Œí¬ëŠ” ë¶„í•´ëœ ì‹œê³µê°„ ê°•ì¡°(DSTH)ì™€ ì‹œê°„ ë³´ê°• ì¡°ë¦½(TAS) ì „ëµì„ í¬í•¨í•˜ì—¬ MLLMsì˜ ì¶”ë¡  ëŠ¥ë ¥ì„ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤.

- 4. DSTH ì „ëµì€ ì†ì„±ê³¼ í–‰ë™ í•˜ìœ„ ì¿¼ë¦¬ë¡œ ì›ë˜ ì¿¼ë¦¬ë¥¼ ë¶„ë¦¬í•˜ì—¬ ëŒ€ìƒì˜ ì¡´ì¬ë¥¼ ê³µê°„ì  ë° ì‹œê°„ì ìœ¼ë¡œ íƒìƒ‰í•˜ê³ , ìƒˆë¡œìš´ ë¡œì§“ ìœ ë„ ì¬ì£¼ëª©(LRA) ëª¨ë“ˆì„ ì‚¬ìš©í•˜ì—¬ ì ì¬ ë³€ìˆ˜ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.

- 5. TAS ì „ëµì€ ì†ì„± í•˜ìœ„ ì¿¼ë¦¬ì— ì˜í•œ ê³µê°„ì  ê·¸ë¼ìš´ë”©ì´ ì‹œê°„ì ìœ¼ë¡œ ì¼ê´€ë˜ë„ë¡ ì›ë³¸ ë¹„ë””ì˜¤ í”„ë ˆì„ê³¼ ì‹œê°„ ë³´ê°• í”„ë ˆì„ì„ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ì„ ì¡°ë¦½í•©ë‹ˆë‹¤.

---

*Generated on 2025-09-19 16:10:40*