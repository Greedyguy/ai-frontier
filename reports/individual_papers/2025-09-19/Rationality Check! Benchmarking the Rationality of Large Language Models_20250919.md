
# Rationality Check! Benchmarking the Rationality of Large Language Models

**Korean Title:** 합리성 점검! 대형 언어 모델의 합리성 벤치마킹

## 📋 메타데이터

**Links**: [[daily/2025-09-19|2025-09-19]] [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🔬 Broad Technical**: Large Language Models, Artificial General Intelligence

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.14546v1 Announce Type: new 
Abstract: Large language models (LLMs), a recent advance in deep learning and machine intelligence, have manifested astonishing capacities, now considered among the most promising for artificial general intelligence. With human-like capabilities, LLMs have been used to simulate humans and serve as AI assistants across many applications. As a result, great concern has arisen about whether and under what circumstances LLMs think and behave like real human agents. Rationality is among the most important concepts in assessing human behavior, both in thinking (i.e., theoretical rationality) and in taking action (i.e., practical rationality). In this work, we propose the first benchmark for evaluating the omnibus rationality of LLMs, covering a wide range of domains and LLMs. The benchmark includes an easy-to-use toolkit, extensive experimental results, and analysis that illuminates where LLMs converge and diverge from idealized human rationality. We believe the benchmark can serve as a foundational tool for both developers and users of LLMs.

## 🔍 Abstract (한글 번역)

arXiv:2509.14546v1 발표 유형: 새로운 것  
초록: 대형 언어 모델(LLMs)은 딥러닝과 기계 지능의 최근 발전으로, 놀라운 능력을 발휘하여 이제 인공지능 일반 지능의 가장 유망한 후보 중 하나로 간주되고 있습니다. 인간과 유사한 능력을 가진 LLMs는 인간을 모방하고 다양한 응용 분야에서 AI 비서로 사용되고 있습니다. 그 결과, LLMs가 실제 인간 에이전트처럼 사고하고 행동하는지 여부와 어떤 상황에서 그렇게 하는지에 대한 큰 우려가 제기되었습니다. 합리성은 인간 행동을 평가하는 데 있어 가장 중요한 개념 중 하나로, 사고(즉, 이론적 합리성)와 행동(즉, 실천적 합리성) 모두에서 중요합니다. 이 연구에서는 다양한 도메인과 LLMs를 포괄하는 LLMs의 종합적 합리성을 평가하기 위한 최초의 벤치마크를 제안합니다. 이 벤치마크는 사용하기 쉬운 도구 모음, 광범위한 실험 결과 및 LLMs가 이상화된 인간의 합리성과 어디에서 수렴하고 발산하는지를 조명하는 분석을 포함하고 있습니다. 우리는 이 벤치마크가 LLMs의 개발자와 사용자 모두에게 기초적인 도구로 활용될 수 있다고 믿습니다.

## 📝 요약

이 논문은 대형 언어 모델(LLM)의 전반적인 합리성을 평가하기 위한 최초의 벤치마크를 제안합니다. LLM은 인공지능 일반화의 유망한 도구로, 인간과 유사한 능력을 보여주며 다양한 분야에서 AI 비서로 활용되고 있습니다. 논문은 LLM이 인간과 유사하게 사고하고 행동하는지에 대한 우려를 다루며, 이들의 이론적 및 실천적 합리성을 평가합니다. 제안된 벤치마크는 다양한 도메인과 LLM을 포괄하며, 사용하기 쉬운 도구와 실험 결과, 분석을 포함하여 LLM이 이상적인 인간 합리성과 어디에서 일치하고 차이가 나는지를 밝힙니다. 이 벤치마크는 LLM 개발자와 사용자에게 기초적인 도구로 활용될 수 있을 것입니다.

## 🎯 주요 포인트

- 1. 대형 언어 모델(LLMs)은 인공지능 일반화의 유망한 도구로, 인간과 유사한 능력을 보여주며 다양한 응용 분야에서 AI 비서로 활용되고 있다.

- 2. LLMs의 인간과 유사한 사고와 행동 여부에 대한 우려가 증가하고 있으며, 이를 평가하기 위해 합리성 개념이 중요하다.

- 3. 본 연구는 LLMs의 전반적인 합리성을 평가하기 위한 첫 번째 벤치마크를 제안하며, 이는 다양한 도메인과 LLMs를 포괄한다.

- 4. 벤치마크는 사용하기 쉬운 도구 키트와 광범위한 실험 결과 및 분석을 포함하여 LLMs가 이상적인 인간 합리성과 일치하거나 차이 나는 지점을 밝힌다.

- 5. 이 벤치마크는 LLMs 개발자와 사용자 모두에게 기초적인 도구로 활용될 수 있다.

---

*Generated on 2025-09-19 18:09:07*