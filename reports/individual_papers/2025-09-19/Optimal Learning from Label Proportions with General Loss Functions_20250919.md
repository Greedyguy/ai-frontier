---
keywords:
  - Sample Complexity
  - Learning from Label Proportions
  - Loss Functions
category: cs.AI
publish_date: 2025-09-19
arxiv_id: 2509.15145
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 21:30:22.570195",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Sample Complexity",
    "Learning from Label Proportions",
    "Loss Functions"
  ],
  "rejected_keywords": [
    "De-biasing Techniques"
  ],
  "similarity_scores": {
    "Sample Complexity": 0.79,
    "Learning from Label Proportions": 0.78,
    "Loss Functions": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->


# Optimal Learning from Label Proportions with General Loss Functions

**Korean Title:** ë¼ë²¨ ë¹„ìœ¨ë¡œë¶€í„°ì˜ ìµœì  í•™ìŠµê³¼ ì¼ë°˜ ì†ì‹¤ í•¨ìˆ˜

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[digests/daily_digest_20250919|2025-09-19]]   [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸŒ Broad Technical**: [[keywords/Loss Functions|loss functions]]
**ğŸ”— Specific Connectable**: [[keywords/Sample Complexity|sample complexity guarantees]]
**âš¡ Unique Technical**: [[keywords/Learning from Label Proportions|Learning from Label Proportions]]

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[Zero-Shot LLMs in Human-in-the-Loop RL Replacing Human Feedback for Reward Shaping]] (81.0% similar)
- [[Middo Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning]] (79.4% similar)
- [[Multi-Fidelity_Hybrid_Reinforcement_Learning_via_Information_Gain_Maximization_20250919|Multi-Fidelity Hybrid Reinforcement Learning via Information Gain Maximization]] (79.3% similar)
- [[SMARTER A Data-efficient Framework to Improve Toxicity Detection with Explanation via Self-augmenting Large Language Models]] (78.9% similar)
- [[FlowRL Matching Reward Distributions for LLM Reasoning]] (78.8% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15145v1 Announce Type: new 
Abstract: Motivated by problems in online advertising, we address the task of Learning from Label Proportions (LLP). In this partially-supervised setting, training data consists of groups of examples, termed bags, for which we only observe the average label value. The main goal, however, remains the design of a predictor for the labels of individual examples. We introduce a novel and versatile low-variance de-biasing methodology to learn from aggregate label information, significantly advancing the state of the art in LLP. Our approach exhibits remarkable flexibility, seamlessly accommodating a broad spectrum of practically relevant loss functions across both binary and multi-class classification settings. By carefully combining our estimators with standard techniques, we substantially improve sample complexity guarantees for a large class of losses of practical relevance. We also empirically validate the efficacy of our proposed approach across a diverse array of benchmark datasets, demonstrating compelling empirical advantages over standard baselines.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15145v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: ì˜¨ë¼ì¸ ê´‘ê³  ë¬¸ì œì—ì„œ ë™ê¸°ë¥¼ ì–»ì–´, ìš°ë¦¬ëŠ” ë¹„ìœ¨ì— ë”°ë¥¸ í•™ìŠµ(LLP) ê³¼ì œë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. ì´ ë¶€ë¶„ì ìœ¼ë¡œ ì§€ë„ëœ í™˜ê²½ì—ì„œ, í›ˆë ¨ ë°ì´í„°ëŠ” 'ê°€ë°©'ì´ë¼ê³  ë¶ˆë¦¬ëŠ” ì˜ˆì œ ê·¸ë£¹ìœ¼ë¡œ êµ¬ì„±ë˜ë©°, ìš°ë¦¬ëŠ” ì´ ê·¸ë£¹ì˜ í‰ê·  ë ˆì´ë¸” ê°’ë§Œì„ ê´€ì°°í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì£¼ëœ ëª©í‘œëŠ” ê°œë³„ ì˜ˆì œì˜ ë ˆì´ë¸”ì— ëŒ€í•œ ì˜ˆì¸¡ê¸°ë¥¼ ì„¤ê³„í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì§‘ê³„ëœ ë ˆì´ë¸” ì •ë³´ë¥¼ í•™ìŠµí•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ë‹¤ëª©ì  ì €ë¶„ì‚° í¸í–¥ ì œê±° ë°©ë²•ë¡ ì„ ì†Œê°œí•˜ì—¬ LLPì˜ ìµœì‹  ê¸°ìˆ  ìˆ˜ì¤€ì„ í¬ê²Œ ë°œì „ì‹œì¼°ìŠµë‹ˆë‹¤. ìš°ë¦¬ì˜ ì ‘ê·¼ë²•ì€ ì´ì§„ ë° ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ ì„¤ì • ëª¨ë‘ì—ì„œ ì‹¤ì§ˆì ìœ¼ë¡œ ê´€ë ¨ ìˆëŠ” ì†ì‹¤ í•¨ìˆ˜ì˜ ê´‘ë²”ìœ„í•œ ìŠ¤í™íŠ¸ëŸ¼ì„ ì›í™œí•˜ê²Œ ìˆ˜ìš©í•˜ë©° ë†€ë¼ìš´ ìœ ì—°ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì¶”ì •ê¸°ë¥¼ í‘œì¤€ ê¸°ë²•ê³¼ ì‹ ì¤‘í•˜ê²Œ ê²°í•©í•¨ìœ¼ë¡œì¨, ì‹¤ì§ˆì ìœ¼ë¡œ ê´€ë ¨ ìˆëŠ” ì†ì‹¤ì˜ í° ë²”ì£¼ì— ëŒ€í•´ ìƒ˜í”Œ ë³µì¡ì„± ë³´ì¥ì„ ìƒë‹¹íˆ ê°œì„ í–ˆìŠµë‹ˆë‹¤. ë˜í•œ ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì—ì„œ ì œì•ˆëœ ì ‘ê·¼ë²•ì˜ íš¨ëŠ¥ì„ ì‹¤ì¦ì ìœ¼ë¡œ ê²€ì¦í•˜ì—¬, í‘œì¤€ ê¸°ì¤€ë³´ë‹¤ ì„¤ë“ë ¥ ìˆëŠ” ì‹¤ì¦ì  ì´ì ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì˜¨ë¼ì¸ ê´‘ê³  ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë¼ë²¨ ë¹„ìœ¨ í•™ìŠµ(LLP) ë¬¸ì œë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. LLPëŠ” ë¶€ë¶„ì ìœ¼ë¡œ ê°ë…ëœ í•™ìŠµ ì„¤ì •ìœ¼ë¡œ, í›ˆë ¨ ë°ì´í„°ëŠ” í‰ê·  ë¼ë²¨ ê°’ë§Œ ê´€ì¸¡ë˜ëŠ” ê·¸ë£¹(ë°±)ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. ì£¼ìš” ëª©í‘œëŠ” ê°œë³„ ì˜ˆì œì˜ ë¼ë²¨ì„ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì €ìë“¤ì€ ì§‘ê³„ëœ ë¼ë²¨ ì •ë³´ë¡œë¶€í„° í•™ìŠµí•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ì €ë¶„ì‚° í¸í–¥ ì œê±° ë°©ë²•ë¡ ì„ ì œì•ˆí•˜ì—¬ LLP ë¶„ì•¼ì˜ ìµœì²¨ë‹¨ì„ í¬ê²Œ ë°œì „ì‹œì¼°ìŠµë‹ˆë‹¤. ì´ ë°©ë²•ë¡ ì€ ì´ì§„ ë° ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ ì„¤ì •ì—ì„œ ë‹¤ì–‘í•œ ì†ì‹¤ í•¨ìˆ˜ë¥¼ ìœ ì—°í•˜ê²Œ ìˆ˜ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì œì•ˆëœ ë°©ë²•ì€ í‘œì¤€ ê¸°ë²•ê³¼ ê²°í•©í•˜ì—¬ ì‹¤ì§ˆì ìœ¼ë¡œ ì¤‘ìš”í•œ ì†ì‹¤ í´ë˜ìŠ¤ì— ëŒ€í•œ ìƒ˜í”Œ ë³µì¡ì„± ë³´ì¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì„ í†µí•´ ì œì•ˆëœ ë°©ë²•ì˜ íš¨ìœ¨ì„±ì„ ì‹¤ì¦ì ìœ¼ë¡œ ê²€ì¦í•˜ì˜€ìœ¼ë©°, ê¸°ì¡´ì˜ ê¸°ì¤€ë³´ë‹¤ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì˜¨ë¼ì¸ ê´‘ê³  ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë¼ë²¨ ë¹„ìœ¨ í•™ìŠµ(LLP) ë¬¸ì œë¥¼ ë‹¤ë£¹ë‹ˆë‹¤.

- 2. ì§‘ë‹¨ì˜ í‰ê·  ë¼ë²¨ ê°’ë§Œ ê´€ì°° ê°€ëŠ¥í•œ ë¶€ë¶„ì ìœ¼ë¡œ ì§€ë„ëœ í™˜ê²½ì—ì„œ ê°œë³„ ì˜ˆì œì˜ ë¼ë²¨ì„ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì´ ì£¼ìš” ëª©í‘œì…ë‹ˆë‹¤.

- 3. ì§‘í•© ë¼ë²¨ ì •ë³´ë¡œë¶€í„° í•™ìŠµí•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ì €ë¶„ì‚° í¸í–¥ ì œê±° ë°©ë²•ë¡ ì„ ë„ì…í•˜ì—¬ LLPì˜ ìµœì‹  ê¸°ìˆ ì„ í¬ê²Œ ë°œì „ì‹œì¼°ìŠµë‹ˆë‹¤.

- 4. ì œì•ˆëœ ë°©ë²•ì€ ì´ì§„ ë° ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ ì„¤ì •ì—ì„œ ë‹¤ì–‘í•œ ì†ì‹¤ í•¨ìˆ˜ì— ìœ ì—°í•˜ê²Œ ì ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.

- 5. ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì—ì„œ ì œì•ˆëœ ì ‘ê·¼ë²•ì˜ íš¨ëŠ¥ì„ ì‹¤ì¦ì ìœ¼ë¡œ ê²€ì¦í•˜ì—¬ í‘œì¤€ ê¸°ì¤€ë³´ë‹¤ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.

---

*Generated on 2025-09-19 15:31:36*