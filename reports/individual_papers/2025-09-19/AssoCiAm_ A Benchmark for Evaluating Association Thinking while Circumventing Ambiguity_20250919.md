---
keywords:
  - Artificial General Intelligence
  - Cognition and Association
  - Large Language Models
category: cs.AI
publish_date: 2025-09-19
arxiv_id: 2509.14171
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 21:55:50.855415",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Artificial General Intelligence",
    "Cognition and Association",
    "Large Language Models"
  ],
  "rejected_keywords": [
    "Association Thinking",
    "Ambiguity in Association Tasks"
  ],
  "similarity_scores": {
    "Artificial General Intelligence": 0.82,
    "Cognition and Association": 0.77,
    "Large Language Models": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->


# AssoCiAm: A Benchmark for Evaluating Association Thinking while Circumventing Ambiguity

**Korean Title:** AssoCiAm: 모호성을 피하면서 연상 사고를 평가하기 위한 벤치마크

## 📋 메타데이터

**Links**: [[digests/daily_digest_20250919|2025-09-19]]   [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**⚡ Unique Technical**: [[keywords/Artificial General Intelligence|artificial general intelligence]]
**🚀 Evolved Concepts**: [[keywords/Cognition and Association|cognition and association]]

## 🔗 유사한 논문
- [[Internalizing Self-Consistency in Language Models Multi-Agent Consensus Alignment]] (82.2% similar)
- [[RAcQUEt Unveiling the Dangers of Overlooked Referential Ambiguity in Visual LLMs]] (82.1% similar)
- [[Language Models Identify Ambiguities and Exploit Loopholes]] (82.1% similar)
- [[Modular Machine Learning An Indispensable Path towards New-Generation Large Language Models]] (81.8% similar)
- [[A Multi-To-One Interview Paradigm for Efficient MLLM Evaluation_20250919|A Multi-To-One Interview Paradigm for Efficient MLLM Evaluation]] (80.9% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.14171v2 Announce Type: replace 
Abstract: Recent advancements in multimodal large language models (MLLMs) have garnered significant attention, offering a promising pathway toward artificial general intelligence (AGI). Among the essential capabilities required for AGI, creativity has emerged as a critical trait for MLLMs, with association serving as its foundation. Association reflects a model' s ability to think creatively, making it vital to evaluate and understand. While several frameworks have been proposed to assess associative ability, they often overlook the inherent ambiguity in association tasks, which arises from the divergent nature of associations and undermines the reliability of evaluations. To address this issue, we decompose ambiguity into two types-internal ambiguity and external ambiguity-and introduce AssoCiAm, a benchmark designed to evaluate associative ability while circumventing the ambiguity through a hybrid computational method. We then conduct extensive experiments on MLLMs, revealing a strong positive correlation between cognition and association. Additionally, we observe that the presence of ambiguity in the evaluation process causes MLLMs' behavior to become more random-like. Finally, we validate the effectiveness of our method in ensuring more accurate and reliable evaluations. See Project Page for the data and codes.

## 🔍 Abstract (한글 번역)

arXiv:2509.14171v2 발표 유형: 교체  
초록: 최근 다중 모드 대형 언어 모델(MLLMs)의 발전은 인공지능 일반화(AGI)를 향한 유망한 경로를 제공하며 큰 주목을 받고 있습니다. AGI에 필요한 필수 능력 중 창의성은 MLLMs에서 중요한 특성으로 부각되고 있으며, 연관성이 그 기초를 이룹니다. 연관성은 모델이 창의적으로 사고할 수 있는 능력을 반영하며, 이를 평가하고 이해하는 것이 중요합니다. 연관 능력을 평가하기 위한 여러 프레임워크가 제안되었지만, 이들은 종종 연관 작업의 본질적인 모호성을 간과하며, 이는 연관의 분기적 특성에서 기인하여 평가의 신뢰성을 저해합니다. 이 문제를 해결하기 위해, 우리는 모호성을 내부 모호성과 외부 모호성 두 가지 유형으로 분해하고, 하이브리드 계산 방법을 통해 모호성을 피하면서 연관 능력을 평가하기 위해 설계된 벤치마크인 AssoCiAm을 소개합니다. 그런 다음 MLLMs에 대한 광범위한 실험을 수행하여 인지와 연관 사이의 강한 양의 상관관계를 밝혀냅니다. 또한, 평가 과정에서의 모호성 존재가 MLLMs의 행동을 보다 무작위적으로 만드는 것을 관찰합니다. 마지막으로, 보다 정확하고 신뢰할 수 있는 평가를 보장하는 데 있어 우리의 방법의 효과성을 검증합니다. 데이터와 코드는 프로젝트 페이지를 참조하십시오.

## 📝 요약

최근 다중 모달 대형 언어 모델(MLLMs)의 발전은 인공지능 일반화(AGI)로 가는 유망한 경로를 제시하고 있습니다. AGI에 필요한 중요한 능력 중 하나인 창의성은 연관성을 기반으로 하며, 이는 모델의 창의적 사고 능력을 평가하는 데 필수적입니다. 기존의 연관성 평가 프레임워크는 연관 작업의 모호성을 간과하여 평가의 신뢰성을 저해합니다. 이를 해결하기 위해, 우리는 모호성을 내부 모호성과 외부 모호성으로 나누고, AssoCiAm이라는 벤치마크를 도입하여 혼합 계산 방법으로 모호성을 극복하며 연관성을 평가합니다. 실험 결과, 인지와 연관성 간의 강한 양의 상관관계를 발견했으며, 평가 과정에서의 모호성이 MLLMs의 행동을 무작위적으로 만드는 것을 관찰했습니다. 우리의 방법은 보다 정확하고 신뢰할 수 있는 평가를 보장하는 데 효과적임을 검증했습니다.

## 🎯 주요 포인트

- 1. 다중모달 대형 언어 모델(MLLMs)의 발전은 인공지능 일반화(AGI)로 가는 유망한 경로를 제공하며, 창의성은 MLLMs의 필수 능력 중 하나로 부각되고 있습니다.

- 2. 연관성은 모델의 창의적 사고 능력을 반영하며, 이를 평가하고 이해하는 것이 중요합니다.

- 3. 기존의 연관성 평가 프레임워크는 연관 작업의 본질적인 모호성을 간과하여 평가의 신뢰성을 저하시킵니다.

- 4. AssoCiAm 벤치마크는 내부 및 외부 모호성을 분해하여 하이브리드 계산 방법을 통해 연관성 평가의 모호성을 극복하고자 합니다.

- 5. 실험 결과, 인지와 연관성 사이의 강한 양의 상관관계를 발견했으며, 평가 과정의 모호성이 MLLMs의 행동을 무작위적으로 만드는 것을 관찰했습니다.

---

*Generated on 2025-09-19 16:01:55*