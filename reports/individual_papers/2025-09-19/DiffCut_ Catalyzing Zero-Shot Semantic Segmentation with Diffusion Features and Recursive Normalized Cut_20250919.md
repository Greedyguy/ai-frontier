---
keywords:
  - Diffusion Models
  - Foundation Models
  - Zero-Shot Learning
category: cs.AI
publish_date: 2025-09-19
arxiv_id: 2406.02842
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 21:48:22.244397",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Diffusion Models",
    "Foundation Models",
    "Zero-Shot Learning"
  ],
  "rejected_keywords": [
    "Graph-Based Segmentation"
  ],
  "similarity_scores": {
    "Diffusion Models": 0.82,
    "Foundation Models": 0.8,
    "Zero-Shot Learning": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->


# DiffCut: Catalyzing Zero-Shot Semantic Segmentation with Diffusion Features and Recursive Normalized Cut

**Korean Title:** DiffCut: í™•ì‚° íŠ¹ì§•ê³¼ ì¬ê·€ ì •ê·œí™” ì ˆë‹¨ì„ í†µí•œ ì œë¡œìƒ· ì˜ë¯¸ë¡ ì  ë¶„í•  ì´‰ì§„

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[digests/daily_digest_20250919|2025-09-19]]   [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Diffusion Models|Diffusion Features]]
**ğŸš€ Evolved Concepts**: [[keywords/Foundation Models|Foundation Vision Encoder]], [[keywords/Zero-Shot Learning|Zero-Shot Segmentation]]

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[Semi-MoE Mixture-of-Experts meets Semi-Supervised Histopathology Segmentation]] (80.9% similar)
- [[Seeing 3D Through 2D Lenses 3D Few-Shot Class-Incremental Learning via Cross-Modal Geometric Rectification]] (80.2% similar)
- [[FlightDiffusion Revolutionising Autonomous Drone Training with Diffusion Models Generating FPV Video]] (80.1% similar)
- [[Controllable Localized Face Anonymization Via Diffusion Inpainting_20250919|Controllable Localized Face Anonymization Via Diffusion Inpainting]] (80.0% similar)
- [[Reconstruction Alignment Improves Unified Multimodal Models_20250919|Reconstruction Alignment Improves Unified Multimodal Models]] (79.8% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2406.02842v3 Announce Type: replace 
Abstract: Foundation models have emerged as powerful tools across various domains including language, vision, and multimodal tasks. While prior works have addressed unsupervised image segmentation, they significantly lag behind supervised models. In this paper, we use a diffusion UNet encoder as a foundation vision encoder and introduce DiffCut, an unsupervised zero-shot segmentation method that solely harnesses the output features from the final self-attention block. Through extensive experimentation, we demonstrate that the utilization of these diffusion features in a graph based segmentation algorithm, significantly outperforms previous state-of-the-art methods on zero-shot segmentation. Specifically, we leverage a recursive Normalized Cut algorithm that softly regulates the granularity of detected objects and produces well-defined segmentation maps that precisely capture intricate image details. Our work highlights the remarkably accurate semantic knowledge embedded within diffusion UNet encoders that could then serve as foundation vision encoders for downstream tasks. Project page at https://diffcut-segmentation.github.io

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2406.02842v3 ë°œí‘œ ìœ í˜•: êµì²´  
ì´ˆë¡: ê¸°ì´ˆ ëª¨ë¸ì€ ì–¸ì–´, ë¹„ì „, ë©€í‹°ëª¨ë‹¬ ì‘ì—…ì„ í¬í•¨í•œ ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ê°•ë ¥í•œ ë„êµ¬ë¡œ ë¶€ìƒí–ˆìŠµë‹ˆë‹¤. ì´ì „ ì—°êµ¬ì—ì„œëŠ” ë¹„ì§€ë„ ì´ë¯¸ì§€ ë¶„í• ì„ ë‹¤ë£¨ì—ˆìœ¼ë‚˜, ì§€ë„ í•™ìŠµ ëª¨ë¸ì— ë¹„í•´ ìƒë‹¹íˆ ë’¤ì²˜ì ¸ ìˆìŠµë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” í™•ì‚° UNet ì¸ì½”ë”ë¥¼ ê¸°ì´ˆ ë¹„ì „ ì¸ì½”ë”ë¡œ ì‚¬ìš©í•˜ê³ , ìµœì¢… ìê¸° ì£¼ì˜ ë¸”ë¡ì˜ ì¶œë ¥ íŠ¹ì§•ë§Œì„ í™œìš©í•˜ëŠ” ë¹„ì§€ë„ ì œë¡œìƒ· ë¶„í•  ë°©ë²•ì¸ DiffCutì„ ì†Œê°œí•©ë‹ˆë‹¤. ê´‘ë²”ìœ„í•œ ì‹¤í—˜ì„ í†µí•´, ê·¸ë˜í”„ ê¸°ë°˜ ë¶„í•  ì•Œê³ ë¦¬ì¦˜ì—ì„œ ì´ëŸ¬í•œ í™•ì‚° íŠ¹ì§•ì„ í™œìš©í•¨ìœ¼ë¡œì¨ ì œë¡œìƒ· ë¶„í• ì—ì„œ ì´ì „ ìµœì²¨ë‹¨ ë°©ë²•ë“¤ì„ ìƒë‹¹íˆ ëŠ¥ê°€í•¨ì„ ì…ì¦í•©ë‹ˆë‹¤. êµ¬ì²´ì ìœ¼ë¡œ, íƒì§€ëœ ê°ì²´ì˜ ì„¸ë¶„ì„±ì„ ë¶€ë“œëŸ½ê²Œ ì¡°ì ˆí•˜ê³  ë³µì¡í•œ ì´ë¯¸ì§€ ì„¸ë¶€ ì‚¬í•­ì„ ì •í™•í•˜ê²Œ í¬ì°©í•˜ëŠ” ì˜ ì •ì˜ëœ ë¶„í•  ì§€ë„ë¥¼ ìƒì„±í•˜ëŠ” ì¬ê·€ì  ì •ê·œí™” ì»· ì•Œê³ ë¦¬ì¦˜ì„ í™œìš©í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì—°êµ¬ëŠ” í™•ì‚° UNet ì¸ì½”ë”ì— ë‚´ì¬ëœ ë†€ëë„ë¡ ì •í™•í•œ ì˜ë¯¸ì  ì§€ì‹ì„ ê°•ì¡°í•˜ë©°, ì´ëŠ” ì´í›„ ì‘ì—…ì„ ìœ„í•œ ê¸°ì´ˆ ë¹„ì „ ì¸ì½”ë”ë¡œ í™œìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í”„ë¡œì íŠ¸ í˜ì´ì§€: https://diffcut-segmentation.github.io

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ DiffCutì´ë¼ëŠ” ë¹„ì§€ë„ í•™ìŠµ ê¸°ë°˜ì˜ ì œë¡œìƒ· ì´ë¯¸ì§€ ì„¸ë¶„í™” ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ í™•ì‚° UNet ì¸ì½”ë”ì˜ ìµœì¢… ì…€í”„ ì–´í…ì…˜ ë¸”ë¡ì—ì„œ ì¶”ì¶œí•œ íŠ¹ì§•ì„ í™œìš©í•©ë‹ˆë‹¤. ì œì•ˆëœ ë°©ë²•ì€ ê·¸ë˜í”„ ê¸°ë°˜ ì„¸ë¶„í™” ì•Œê³ ë¦¬ì¦˜ì„ í†µí•´ ì´ì „ ìµœì²¨ë‹¨ ë°©ë²•ë“¤ë³´ë‹¤ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤. íŠ¹íˆ, ë°˜ë³µì ì¸ ì •ê·œí™” ì»· ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ê°ì²´ì˜ ì„¸ë¶„í™” ìˆ˜ì¤€ì„ ì¡°ì ˆí•˜ê³ , ì´ë¯¸ì§€ì˜ ì„¸ë¶€ ì‚¬í•­ì„ ì •í™•í•˜ê²Œ í¬ì°©í•˜ëŠ” ì„¸ë¶„í™” ì§€ë„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” í™•ì‚° UNet ì¸ì½”ë”ê°€ ë‚´í¬í•œ ì •í™•í•œ ì˜ë¯¸ë¡ ì  ì§€ì‹ì„ ê°•ì¡°í•˜ë©°, ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ë¹„ì „ ì¸ì½”ë”ê°€ ë‹¤ì–‘í•œ í›„ì† ì‘ì—…ì— í™œìš©ë  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. DiffCutì€ í™•ì‚° UNet ì¸ì½”ë”ë¥¼ í™œìš©í•˜ì—¬ ë¹„ì§€ë„ í•™ìŠµ ê¸°ë°˜ì˜ ì œë¡œìƒ· ì´ë¯¸ì§€ ë¶„í• ì„ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.

- 2. ìµœì¢… ì…€í”„ ì–´í…ì…˜ ë¸”ë¡ì˜ ì¶œë ¥ íŠ¹ì§•ì„ í™œìš©í•˜ì—¬ ê·¸ë˜í”„ ê¸°ë°˜ ë¶„í•  ì•Œê³ ë¦¬ì¦˜ì—ì„œ ì´ì „ ìµœì²¨ë‹¨ ë°©ë²•ë“¤ì„ ëŠ¥ê°€í•˜ëŠ” ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

- 3. ì¬ê·€ì ì¸ Normalized Cut ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ê°ì²´ì˜ ì„¸ë¶„í™”ë¥¼ ë¶€ë“œëŸ½ê²Œ ì¡°ì ˆí•˜ê³ , ì •êµí•œ ì´ë¯¸ì§€ ì„¸ë¶€ ì‚¬í•­ì„ ì •í™•í•˜ê²Œ í¬ì°©í•˜ëŠ” ë¶„í•  ì§€ë„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

- 4. í™•ì‚° UNet ì¸ì½”ë”ì— ë‚´ì¬ëœ ì •í™•í•œ ì˜ë¯¸ë¡ ì  ì§€ì‹ì€ í›„ì† ì‘ì—…ì„ ìœ„í•œ ë¹„ì „ ì¸ì½”ë”ë¡œ í™œìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

*Generated on 2025-09-19 16:14:42*