
# The Art of Saying "Maybe": A Conformal Lens for Uncertainty Benchmarking in VLMs

**Korean Title:** "아마도"라고 말하는 기술: VLM에서 불확실성 벤치마킹을 위한 적합한 렌즈

## 📋 메타데이터

**Links**: [[daily/2025-09-19|2025-09-19]] [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Uncertainty Benchmarking

## 🔗 유사한 논문
- [[Visible Yet Unreadable A Systematic Blind Spot of Vision Language Models Across Writing Systems]] (81.4% similar)
- [[Explicit Reasoning Makes Better Judges A Systematic Study on Accuracy, Efficiency, and Robustness]] (80.3% similar)
- [[Forget What You Know about LLMs Evaluations -- LLMs are Like a Chameleon]] (80.2% similar)
- [[An Empirical Analysis of VLM-based OOD Detection Mechanisms, Advantages, and Sensitivity]] (79.8% similar)
- [[SAIL-VL2_Technical_Report_20250918|SAIL-VL2 Technical Report]] (79.1% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.13379v2 Announce Type: replace 
Abstract: Vision-Language Models (VLMs) have achieved remarkable progress in complex visual understanding across scientific and reasoning tasks. While performance benchmarking has advanced our understanding of these capabilities, the critical dimension of uncertainty quantification has received insufficient attention. Therefore, unlike prior conformal prediction studies that focused on limited settings, we conduct a comprehensive uncertainty benchmarking study, evaluating 16 state-of-the-art VLMs (open and closed-source) across 6 multimodal datasets with 3 distinct scoring functions. Our findings demonstrate that larger models consistently exhibit better uncertainty quantification; models that know more also know better what they don't know. More certain models achieve higher accuracy, while mathematical and reasoning tasks elicit poorer uncertainty performance across all models compared to other domains. This work establishes a foundation for reliable uncertainty evaluation in multimodal systems.

## 🔍 Abstract (한글 번역)

arXiv:2509.13379v2 발표 유형: 교체  
초록: 비전-언어 모델(VLMs)은 과학적 및 추론 작업 전반에 걸쳐 복잡한 시각적 이해에서 놀라운 발전을 이루었습니다. 성능 벤치마킹은 이러한 능력에 대한 우리의 이해를 진전시켰지만, 불확실성 정량화라는 중요한 측면은 충분한 주목을 받지 못했습니다. 따라서 제한된 설정에 초점을 맞춘 이전의 적합 예측 연구와 달리, 우리는 6개의 다중 모달 데이터셋과 3개의 서로 다른 점수 함수에 걸쳐 16개의 최신 VLMs(오픈 소스 및 클로즈드 소스)를 평가하는 포괄적인 불확실성 벤치마킹 연구를 수행합니다. 우리의 연구 결과는 더 큰 모델이 일관되게 더 나은 불확실성 정량화를 보여준다는 것을 입증합니다. 더 많이 아는 모델은 자신이 모르는 것을 더 잘 알고 있습니다. 더 확실한 모델은 더 높은 정확도를 달성하며, 수학적 및 추론 작업은 다른 도메인에 비해 모든 모델에서 더 낮은 불확실성 성능을 유발합니다. 이 연구는 다중 모달 시스템에서 신뢰할 수 있는 불확실성 평가의 기초를 확립합니다.

## 📝 요약

이 논문은 비전-언어 모델(VLMs)의 불확실성 정량화에 대한 포괄적인 벤치마킹 연구를 수행합니다. 16개의 최신 VLMs를 6개의 멀티모달 데이터셋과 3개의 점수 함수로 평가하여, 큰 모델일수록 불확실성 정량화가 우수하다는 것을 발견했습니다. 또한, 불확실성이 낮은 모델이 더 높은 정확도를 보이며, 수학 및 추론 작업에서는 모든 모델이 다른 분야에 비해 불확실성 성능이 떨어지는 경향을 보였습니다. 이 연구는 멀티모달 시스템에서 신뢰할 수 있는 불확실성 평가의 기초를 마련합니다.

## 🎯 주요 포인트

- 1. Vision-Language Models(VLMs)는 과학 및 추론 작업에서 복잡한 시각적 이해에 있어 놀라운 발전을 이루었습니다.

- 2. 본 연구는 16개의 최신 VLM을 6개의 멀티모달 데이터셋과 3개의 서로 다른 스코어링 함수로 평가하여 포괄적인 불확실성 벤치마킹을 수행했습니다.

- 3. 더 큰 모델은 일관되게 더 나은 불확실성 정량화를 보여주며, 더 많이 아는 모델이 자신이 모르는 것도 더 잘 인식합니다.

- 4. 수학 및 추론 작업은 다른 도메인에 비해 모든 모델에서 불확실성 성능이 저조했습니다.

- 5. 본 연구는 멀티모달 시스템에서 신뢰할 수 있는 불확실성 평가의 기초를 마련합니다.

---

*Generated on 2025-09-19 15:10:14*