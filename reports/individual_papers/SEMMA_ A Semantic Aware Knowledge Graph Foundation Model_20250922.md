# SEMMA: A Semantic Aware Knowledge Graph Foundation Model

**Korean Title:** SEMMA: ì˜ë¯¸ ì¸ì‹ ì§€ì‹ ê·¸ë˜í”„ ê¸°ì´ˆ ëª¨ë¸

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Semantic Embeddings

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Opening the Black Box_ Interpretable LLMs via Semantic Resonance Architecture_20250919|Opening the Black Box Interpretable LLMs via Semantic Resonance Architecture]] (83.7% similar)
- [[2025-09-22/Can Large Language Models Infer Causal Relationships from Real-World Text_20250922|Can Large Language Models Infer Causal Relationships from Real-World Text]] (82.7% similar)
- [[2025-09-19/Modular Machine Learning_ An Indispensable Path towards New-Generation Large Language Models_20250919|Modular Machine Learning An Indispensable Path towards New-Generation Large Language Models]] (81.6% similar)
- [[2025-09-19/Select to Know_ An Internal-External Knowledge Self-Selection Framework for Domain-Specific Question Answering_20250919|Select to Know An Internal-External Knowledge Self-Selection Framework for Domain-Specific Question Answering]] (81.6% similar)
- [[2025-09-18/KBM_ Delineating Knowledge Boundary for Adaptive Retrieval in Large Language Models_20250918|KBM Delineating Knowledge Boundary for Adaptive Retrieval in Large Language Models]] (81.3% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2505.20422v2 Announce Type: replace-cross 
Abstract: Knowledge Graph Foundation Models (KGFMs) have shown promise in enabling zero-shot reasoning over unseen graphs by learning transferable patterns. However, most existing KGFMs rely solely on graph structure, overlooking the rich semantic signals encoded in textual attributes. We introduce SEMMA, a dual-module KGFM that systematically integrates transferable textual semantics alongside structure. SEMMA leverages Large Language Models (LLMs) to enrich relation identifiers, generating semantic embeddings that subsequently form a textual relation graph, which is fused with the structural component. Across 54 diverse KGs, SEMMA outperforms purely structural baselines like ULTRA in fully inductive link prediction. Crucially, we show that in more challenging generalization settings, where the test-time relation vocabulary is entirely unseen, structural methods collapse while SEMMA is 2x more effective. Our findings demonstrate that textual semantics are critical for generalization in settings where structure alone fails, highlighting the need for foundation models that unify structural and linguistic signals in knowledge reasoning.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2505.20422v2 ë°œí‘œ ìœ í˜•: êµì°¨ êµì²´  
ì´ˆë¡: ì§€ì‹ ê·¸ë˜í”„ ê¸°ì´ˆ ëª¨ë¸(KGFMs)ì€ ì „ì´ ê°€ëŠ¥í•œ íŒ¨í„´ì„ í•™ìŠµí•˜ì—¬ ë³´ì§€ ëª»í•œ ê·¸ë˜í”„ì— ëŒ€í•œ ì œë¡œìƒ· ì¶”ë¡ ì„ ê°€ëŠ¥í•˜ê²Œ í•¨ìœ¼ë¡œì¨ ì ì¬ë ¥ì„ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ëŒ€ë¶€ë¶„ì˜ ê¸°ì¡´ KGFMsì€ ê·¸ë˜í”„ êµ¬ì¡°ì—ë§Œ ì˜ì¡´í•˜ë©°, í…ìŠ¤íŠ¸ ì†ì„±ì— ì¸ì½”ë”©ëœ í’ë¶€í•œ ì˜ë¯¸ ì‹ í˜¸ë¥¼ ê°„ê³¼í•˜ê³  ìˆìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” êµ¬ì¡°ì™€ í•¨ê»˜ ì „ì´ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ ì˜ë¯¸ë¥¼ ì²´ê³„ì ìœ¼ë¡œ í†µí•©í•˜ëŠ” ì´ì¤‘ ëª¨ë“ˆ KGFMì¸ SEMMAë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. SEMMAëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì„ í™œìš©í•˜ì—¬ ê´€ê³„ ì‹ë³„ìë¥¼ í’ë¶€í•˜ê²Œ í•˜ê³ , ì´ë¥¼ í†µí•´ ìƒì„±ëœ ì˜ë¯¸ ì„ë² ë”©ì´ í…ìŠ¤íŠ¸ ê´€ê³„ ê·¸ë˜í”„ë¥¼ í˜•ì„±í•˜ì—¬ êµ¬ì¡°ì  êµ¬ì„± ìš”ì†Œì™€ ìœµí•©ë©ë‹ˆë‹¤. 54ê°œì˜ ë‹¤ì–‘í•œ KGsì— ê±¸ì³, SEMMAëŠ” ì™„ì „ ê·€ë‚©ì  ë§í¬ ì˜ˆì¸¡ì—ì„œ ULTRAì™€ ê°™ì€ ìˆœìˆ˜ êµ¬ì¡°ì  ê¸°ì¤€ì„ ì„ ëŠ¥ê°€í•©ë‹ˆë‹¤. íŠ¹íˆ, í…ŒìŠ¤íŠ¸ ì‹œ ê´€ê³„ ì–´íœ˜ê°€ ì™„ì „íˆ ë³´ì§€ ëª»í•œ ê²½ìš°ì™€ ê°™ì€ ë” ì–´ë ¤ìš´ ì¼ë°˜í™” ì„¤ì •ì—ì„œ êµ¬ì¡°ì  ë°©ë²•ì´ ë¶•ê´´ë˜ëŠ” ë°˜ë©´, SEMMAëŠ” ë‘ ë°° ë” íš¨ê³¼ì ì„ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì—°êµ¬ ê²°ê³¼ëŠ” êµ¬ì¡°ë§Œìœ¼ë¡œ ì‹¤íŒ¨í•˜ëŠ” ì„¤ì •ì—ì„œ ì¼ë°˜í™”ë¥¼ ìœ„í•´ í…ìŠ¤íŠ¸ ì˜ë¯¸ê°€ ì¤‘ìš”í•˜ë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì£¼ë©°, ì§€ì‹ ì¶”ë¡ ì—ì„œ êµ¬ì¡°ì  ë° ì–¸ì–´ì  ì‹ í˜¸ë¥¼ í†µí•©í•˜ëŠ” ê¸°ì´ˆ ëª¨ë¸ì˜ í•„ìš”ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì—ì„œëŠ” ìƒˆë¡œìš´ ì§€ì‹ ê·¸ë˜í”„ ê¸°ë°˜ ëª¨ë¸ì¸ SEMMAë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. SEMMAëŠ” ê·¸ë˜í”„ êµ¬ì¡°ë¿ë§Œ ì•„ë‹ˆë¼ í…ìŠ¤íŠ¸ ì†ì— ë‹´ê¸´ ì˜ë¯¸ë¥¼ í•¨ê»˜ í™œìš©í•˜ì—¬, ì´ì „ì— ë³´ì§€ ëª»í•œ ê·¸ë˜í”„ì—ì„œë„ íš¨ê³¼ì ìœ¼ë¡œ ì¶”ë¡ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ ì‚¬ìš©í•˜ì—¬ ê´€ê³„ ì‹ë³„ìë¥¼ í’ë¶€í•˜ê²Œ í•˜ê³ , ì´ë¥¼ í†µí•´ ìƒì„±ëœ ì˜ë¯¸ì  ì„ë² ë”©ì„ êµ¬ì¡°ì  ìš”ì†Œì™€ ê²°í•©í•©ë‹ˆë‹¤. 54ê°œì˜ ë‹¤ì–‘í•œ ì§€ì‹ ê·¸ë˜í”„ì—ì„œ SEMMAëŠ” ê¸°ì¡´ì˜ êµ¬ì¡°ì  ëª¨ë¸ë³´ë‹¤ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë©°, íŠ¹íˆ í…ŒìŠ¤íŠ¸ ì‹œì ì— ì™„ì „íˆ ìƒˆë¡œìš´ ê´€ê³„ê°€ ì£¼ì–´ì§€ëŠ” ì–´ë ¤ìš´ ì¼ë°˜í™” í™˜ê²½ì—ì„œë„ ë‘ ë°° ë” íš¨ê³¼ì ì„ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” í…ìŠ¤íŠ¸ ì˜ë¯¸ê°€ êµ¬ì¡°ë§Œìœ¼ë¡œëŠ” í•´ê²°í•  ìˆ˜ ì—†ëŠ” ì¼ë°˜í™” ë¬¸ì œì—ì„œ ì¤‘ìš”í•˜ë‹¤ëŠ” ì ì„ ê°•ì¡°í•˜ë©°, êµ¬ì¡°ì™€ ì–¸ì–´ì  ì‹ í˜¸ë¥¼ í†µí•©í•œ ëª¨ë¸ì˜ í•„ìš”ì„±ì„ ì œì‹œí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. SEMMAëŠ” êµ¬ì¡°ì™€ í•¨ê»˜ ì „ì´ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ ì˜ë¯¸ë¥¼ ì²´ê³„ì ìœ¼ë¡œ í†µí•©í•˜ëŠ” ì´ì¤‘ ëª¨ë“ˆ KGFMì…ë‹ˆë‹¤.

- 2. SEMMAëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì„ í™œìš©í•˜ì—¬ ê´€ê³„ ì‹ë³„ìë¥¼ í’ë¶€í•˜ê²Œ í•˜ê³ , ì´ë¥¼ í†µí•´ ìƒì„±ëœ ì˜ë¯¸ ì„ë² ë”©ì„ êµ¬ì¡°ì  êµ¬ì„± ìš”ì†Œì™€ ìœµí•©í•©ë‹ˆë‹¤.

- 3. 54ê°œì˜ ë‹¤ì–‘í•œ ì§€ì‹ ê·¸ë˜í”„(KG)ì—ì„œ SEMMAëŠ” ì™„ì „ ìœ ë„ ë§í¬ ì˜ˆì¸¡ì—ì„œ ìˆœìˆ˜ êµ¬ì¡°ì  ê¸°ì¤€ì„ ì¸ ULTRAë³´ë‹¤ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.

- 4. í…ŒìŠ¤íŠ¸ ì‹œì ì˜ ê´€ê³„ ì–´íœ˜ê°€ ì „í˜€ ë³´ì´ì§€ ì•ŠëŠ” ë” ì–´ë ¤ìš´ ì¼ë°˜í™” ì„¤ì •ì—ì„œ êµ¬ì¡°ì  ë°©ë²•ì´ ì‹¤íŒ¨í•˜ëŠ” ë°˜ë©´, SEMMAëŠ” ë‘ ë°° ë” íš¨ê³¼ì ì…ë‹ˆë‹¤.

- 5. ìš°ë¦¬ì˜ ì—°êµ¬ ê²°ê³¼ëŠ” êµ¬ì¡°ë§Œìœ¼ë¡œ ì‹¤íŒ¨í•˜ëŠ” ì„¤ì •ì—ì„œ ì¼ë°˜í™”ë¥¼ ìœ„í•´ í…ìŠ¤íŠ¸ ì˜ë¯¸ê°€ ì¤‘ìš”í•˜ë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì£¼ë©°, ì§€ì‹ ì¶”ë¡ ì—ì„œ êµ¬ì¡°ì  ë° ì–¸ì–´ì  ì‹ í˜¸ë¥¼ í†µí•©í•˜ëŠ” ê¸°ì´ˆ ëª¨ë¸ì˜ í•„ìš”ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤.

---

*Generated on 2025-09-22 14:51:37*