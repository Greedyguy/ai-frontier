
# Utilizing Novelty-based Evolution Strategies to Train Transformers in Reinforcement Learning

**Korean Title:** 혁신 기반 진화 전략을 활용하여 강화 학습에서 트랜스포머를 훈련시키는 것

## 📋 메타데이터

**Links**: [[daily/2025-09-18|2025-09-18]] [[keywords/broad/Reinforcement Learning|Reinforcement Learning]] [[keywords/broad/Transformer|Transformer]] [[keywords/specific/Decision Transformers|Decision Transformers]] [[keywords/unique/NS-ES|NS-ES]] [[keywords/unique/NSR-ES|NSR-ES]] [[categories/cs.LG|cs.LG]]

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Novelty-based Evolution Strategies
**🔬 Broad Technical**: Reinforcement Learning, Transformer
**🔗 Specific Connectable**: Decision Transformers
**⭐ Unique Technical**: NS-ES

**ArXiv ID**: [2502.06301](https://arxiv.org/abs/2502.06301)
**Published**: 2025-09-18
**Category**: cs.LG
**PDF**: [Download](https://arxiv.org/pdf/2502.06301.pdf)


## 🏷️ 추출된 키워드



`Reinforcement Learning` • 

`Transformers` • 

`Decision Transformers` • 

`NS-ES` • 

`NSR-ES`



## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2502.06301v2 Announce Type: replace 
Abstract: In this paper, we experiment with novelty-based variants of OpenAI-ES, the NS-ES and NSR-ES algorithms, and evaluate their effectiveness in training complex, transformer-based architectures designed for the problem of reinforcement learning, such as Decision Transformers. We also test if we can accelerate the novelty-based training of these larger models by seeding the training with a pretrained models. The experimental results were mixed. NS-ES showed progress, but it would clearly need many more iterations for it to yield interesting agents. NSR-ES, on the other hand, proved quite capable of being straightforwardly used on larger models, since its performance appears as similar between the feed-forward model and Decision Transformer, as it was for the OpenAI-ES in our previous work.

## 🔍 Abstract (한글 번역)

arXiv:2502.06301v2 발표 유형: 대체
요약: 본 논문에서는 OpenAI-ES의 새로운 변형인 NS-ES 및 NSR-ES 알고리즘을 실험하고, 강화 학습 문제를 위해 설계된 복잡한 트랜스포머 기반 아키텍처를 훈련하는 데 그 효과를 평가합니다. 또한 사전 훈련된 모델로 훈련을 시작함으로써 이러한 대규모 모델의 창의성 중심 훈련을 가속화할 수 있는지도 테스트합니다. 실험 결과는 복합적이었습니다. NS-ES는 진전을 보였지만 흥미로운 에이전트를 얻기 위해서는 더 많은 반복이 필요했습니다. 반면에 NSR-ES는 큰 모델에서도 쉽게 사용될 수 있는 능력을 입증했습니다. 이는 Feed-forward 모델과 Decision Transformer 간의 성능이 이전 연구에서의 OpenAI-ES와 유사했기 때문입니다.

## 📝 요약

본 논문에서는 OpenAI-ES의 새로운 변형 알고리즘인 NS-ES 및 NSR-ES를 실험하고, 강화학습 문제에 적합한 복잡한 transformer 기반 아키텍처를 학습하는 효과를 평가했습니다. 또한 사전 훈련된 모델로 학습을 초기화하여 이러한 대규모 모델의 신선도 기반 학습을 가속화할 수 있는지도 테스트했습니다. 실험 결과는 혼합되었으며, NS-ES는 진전을 보였지만 흥미로운 에이전트를 얻기 위해서는 더 많은 반복이 필요했습니다. 반면 NSR-ES는 feed-forward 모델과 Decision Transformer 간에 성능이 유사하여 큰 모델에 쉽게 사용될 수 있음을 입증했습니다.

## 🎯 주요 포인트


- 1. 본 논문은 OpenAI-ES의 새로운 변형 알고리즘인 NS-ES 및 NSR-ES 알고리즘을 실험하고, 이들이 강화 학습 문제를 위해 설계된 복잡한 transformer 기반 아키텍처를 훈련하는 데 효과적인지를 평가한다.

- 2. 더 큰 모델의 신선도 기반 훈련을 가속화할 수 있는지를 테스트하기 위해 사전 훈련된 모델로 훈련을 시작한다.

- 3. 실험 결과, NS-ES는 진전을 보였지만 흥미로운 에이전트를 얻기 위해서는 더 많은 반복이 필요하다.

- 4. NSR-ES는 큰 모델에서도 쉽게 사용될 수 있는 능력을 입증했으며, 이전 연구에서의 OpenAI-ES와 유사한 성능을 보였다.


---

*Generated on 2025-09-18 16:46:45*