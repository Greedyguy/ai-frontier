# Nonconvex Decentralized Stochastic Bilevel Optimization under Heavy-Tailed Noises

**Korean Title:** ë¹„ëŒ€ì¹­ ê¼¬ë¦¬ ì¡ìŒ í•˜ì˜ ë¹„ë³¼ë¡ ë¶„ì‚° í™•ë¥ ì  ì´ì¸µ ìµœì í™”

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Nonconvex Optimization under Heavy-Tailed Noises

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/Stochastic Bilevel Optimization with Heavy-Tailed Noise_20250918|Stochastic Bilevel Optimization with Heavy-Tailed Noise]] (88.5% similar)
- [[2025-09-22/Adaptive Algorithms with Sharp Convergence Rates for Stochastic Hierarchical Optimization_20250922|Adaptive Algorithms with Sharp Convergence Rates for Stochastic Hierarchical Optimization]] (87.1% similar)
- [[2025-09-18/Data-Driven Distributed Optimization via Aggregative Tracking and Deep-Learning_20250918|Data-Driven Distributed Optimization via Aggregative Tracking and Deep-Learning]] (83.7% similar)
- [[2025-09-17/Decentralized Optimization with Topology-Independent Communication_20250917|Decentralized Optimization with Topology-Independent Communication]] (83.4% similar)
- [[2025-09-18/Stochastic Adaptive Gradient Descent Without Descent_20250918|Stochastic Adaptive Gradient Descent Without Descent]] (80.9% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15543v1 Announce Type: new 
Abstract: Existing decentralized stochastic optimization methods assume the lower-level loss function is strongly convex and the stochastic gradient noise has finite variance. These strong assumptions typically are not satisfied in real-world machine learning models. To address these limitations, we develop a novel decentralized stochastic bilevel optimization algorithm for the nonconvex bilevel optimization problem under heavy-tailed noises. Specifically, we develop a normalized stochastic variance-reduced bilevel gradient descent algorithm, which does not rely on any clipping operation. Moreover, we establish its convergence rate by innovatively bounding interdependent gradient sequences under heavy-tailed noises for nonconvex decentralized bilevel optimization problems. As far as we know, this is the first decentralized bilevel optimization algorithm with rigorous theoretical guarantees under heavy-tailed noises. The extensive experimental results confirm the effectiveness of our algorithm in handling heavy-tailed noises.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15543v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: ê¸°ì¡´ì˜ ë¶„ì‚° í™•ë¥ ì  ìµœì í™” ë°©ë²•ì€ í•˜ìœ„ ìˆ˜ì¤€ì˜ ì†ì‹¤ í•¨ìˆ˜ê°€ ê°•í•˜ê²Œ ë³¼ë¡í•˜ê³  í™•ë¥ ì  ê¸°ìš¸ê¸° ë…¸ì´ì¦ˆê°€ ìœ í•œí•œ ë¶„ì‚°ì„ ê°–ëŠ”ë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ê°•í•œ ê°€ì •ì€ ì¼ë°˜ì ìœ¼ë¡œ ì‹¤ì œ ì„¸ê³„ì˜ ê¸°ê³„ í•™ìŠµ ëª¨ë¸ì—ì„œëŠ” ì¶©ì¡±ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ í•œê³„ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ë¹„ë³¼ë¡ ì´ì¤‘ ìˆ˜ì¤€ ìµœì í™” ë¬¸ì œì—ì„œ ì¤‘ê°„ ê¼¬ë¦¬ ë…¸ì´ì¦ˆ í•˜ì— ìƒˆë¡œìš´ ë¶„ì‚° í™•ë¥ ì  ì´ì¤‘ ìˆ˜ì¤€ ìµœì í™” ì•Œê³ ë¦¬ì¦˜ì„ ê°œë°œí•©ë‹ˆë‹¤. êµ¬ì²´ì ìœ¼ë¡œ, ìš°ë¦¬ëŠ” í´ë¦¬í•‘ ì‘ì—…ì— ì˜ì¡´í•˜ì§€ ì•ŠëŠ” ì •ê·œí™”ëœ í™•ë¥ ì  ë¶„ì‚° ê°ì†Œ ì´ì¤‘ ìˆ˜ì¤€ ê¸°ìš¸ê¸° í•˜ê°• ì•Œê³ ë¦¬ì¦˜ì„ ê°œë°œí•©ë‹ˆë‹¤. ë”ìš±ì´, ìš°ë¦¬ëŠ” ë¹„ë³¼ë¡ ë¶„ì‚° ì´ì¤‘ ìˆ˜ì¤€ ìµœì í™” ë¬¸ì œì— ëŒ€í•´ ì¤‘ê°„ ê¼¬ë¦¬ ë…¸ì´ì¦ˆ í•˜ì—ì„œ ìƒí˜¸ ì˜ì¡´ì ì¸ ê¸°ìš¸ê¸° ì‹œí€€ìŠ¤ë¥¼ í˜ì‹ ì ìœ¼ë¡œ ì œí•œí•¨ìœ¼ë¡œì¨ ê·¸ ìˆ˜ë ´ ì†ë„ë¥¼ í™•ë¦½í•©ë‹ˆë‹¤. ìš°ë¦¬ê°€ ì•„ëŠ” í•œ, ì´ê²ƒì€ ì¤‘ê°„ ê¼¬ë¦¬ ë…¸ì´ì¦ˆ í•˜ì—ì„œ ì—„ê²©í•œ ì´ë¡ ì  ë³´ì¥ì„ ê°–ì¶˜ ìµœì´ˆì˜ ë¶„ì‚° ì´ì¤‘ ìˆ˜ì¤€ ìµœì í™” ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤. ê´‘ë²”ìœ„í•œ ì‹¤í—˜ ê²°ê³¼ëŠ” ì¤‘ê°„ ê¼¬ë¦¬ ë…¸ì´ì¦ˆë¥¼ ì²˜ë¦¬í•˜ëŠ” ë° ìˆì–´ ìš°ë¦¬ì˜ ì•Œê³ ë¦¬ì¦˜ì˜ íš¨ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ê¸°ì¡´ì˜ ë¶„ì‚° í™•ë¥  ìµœì í™” ë°©ë²•ì´ ê°•í•œ ë³¼ë¡ì„±ê³¼ ìœ í•œí•œ ë¶„ì‚°ì˜ í™•ë¥ ì  ê¸°ìš¸ê¸° ë…¸ì´ì¦ˆë¥¼ ê°€ì •í•˜ëŠ” í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´, ë¹„ë³¼ë¡ ì´ì¤‘ ìˆ˜ì¤€ ìµœì í™” ë¬¸ì œì—ì„œ ì¤‘ëŒ€í•œ ë…¸ì´ì¦ˆë¥¼ ë‹¤ë£¨ëŠ” ìƒˆë¡œìš´ ì•Œê³ ë¦¬ì¦˜ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì œì•ˆëœ ì•Œê³ ë¦¬ì¦˜ì€ ì •ê·œí™”ëœ í™•ë¥ ì  ë¶„ì‚° ê°ì†Œ ì´ì¤‘ ìˆ˜ì¤€ ê¸°ìš¸ê¸° í•˜ê°•ë²•ì„ ì‚¬ìš©í•˜ë©°, í´ë¦¬í•‘ ì—°ì‚°ì— ì˜ì¡´í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë˜í•œ, ì¤‘ëŒ€í•œ ë…¸ì´ì¦ˆ í•˜ì—ì„œ ë¹„ë³¼ë¡ ë¶„ì‚° ì´ì¤‘ ìˆ˜ì¤€ ìµœì í™” ë¬¸ì œì˜ ìˆ˜ë ´ ì†ë„ë¥¼ ì´ë¡ ì ìœ¼ë¡œ ë³´ì¥í•©ë‹ˆë‹¤. ì´ëŠ” ì¤‘ëŒ€í•œ ë…¸ì´ì¦ˆ í•˜ì—ì„œ ì´ë¡ ì  ë³´ì¥ì„ ì œê³µí•˜ëŠ” ìµœì´ˆì˜ ë¶„ì‚° ì´ì¤‘ ìˆ˜ì¤€ ìµœì í™” ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼ëŠ” ì œì•ˆëœ ì•Œê³ ë¦¬ì¦˜ì˜ íš¨ê³¼ì„±ì„ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ê¸°ì¡´ì˜ ë¶„ì‚° í™•ë¥  ìµœì í™” ë°©ë²•ì€ í•˜ìœ„ ìˆ˜ì¤€ ì†ì‹¤ í•¨ìˆ˜ê°€ ê°•í•˜ê²Œ ë³¼ë¡í•˜ê³  í™•ë¥ ì  ê¸°ìš¸ê¸° ë…¸ì´ì¦ˆê°€ ìœ í•œí•œ ë¶„ì‚°ì„ ê°€ì§„ë‹¤ê³  ê°€ì •í•˜ì§€ë§Œ, ì´ëŠ” ì‹¤ì œ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì—ì„œëŠ” ì˜ ì„±ë¦½ë˜ì§€ ì•ŠëŠ”ë‹¤.

- 2. ë¹„ë³¼ë¡ ì´ì¤‘ ìˆ˜ì¤€ ìµœì í™” ë¬¸ì œì—ì„œ ì¤‘ëŒ€í•œ ë…¸ì´ì¦ˆë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ìƒˆë¡œìš´ ë¶„ì‚° í™•ë¥  ì´ì¤‘ ìˆ˜ì¤€ ìµœì í™” ì•Œê³ ë¦¬ì¦˜ì„ ê°œë°œí•˜ì˜€ë‹¤.

- 3. í´ë¦¬í•‘ ì‘ì—…ì— ì˜ì¡´í•˜ì§€ ì•ŠëŠ” ì •ê·œí™”ëœ í™•ë¥ ì  ë¶„ì‚° ê°ì†Œ ì´ì¤‘ ìˆ˜ì¤€ ê¸°ìš¸ê¸° í•˜ê°• ì•Œê³ ë¦¬ì¦˜ì„ ì œì•ˆí•˜ì˜€ë‹¤.

- 4. ë¹„ë³¼ë¡ ë¶„ì‚° ì´ì¤‘ ìˆ˜ì¤€ ìµœì í™” ë¬¸ì œì—ì„œ ì¤‘ëŒ€í•œ ë…¸ì´ì¦ˆ í•˜ì—ì„œ ìƒí˜¸ ì˜ì¡´ì ì¸ ê¸°ìš¸ê¸° ì‹œí€€ìŠ¤ë¥¼ í˜ì‹ ì ìœ¼ë¡œ ì œí•œí•˜ì—¬ ìˆ˜ë ´ ì†ë„ë¥¼ í™•ë¦½í•˜ì˜€ë‹¤.

- 5. ì œì•ˆëœ ì•Œê³ ë¦¬ì¦˜ì€ ì¤‘ëŒ€í•œ ë…¸ì´ì¦ˆë¥¼ ì²˜ë¦¬í•˜ëŠ” ë° ìˆì–´ íš¨ê³¼ì ì„ì„ ì‹¤í—˜ ê²°ê³¼ë¥¼ í†µí•´ í™•ì¸í•˜ì˜€ë‹¤.

---

*Generated on 2025-09-22 15:18:55*