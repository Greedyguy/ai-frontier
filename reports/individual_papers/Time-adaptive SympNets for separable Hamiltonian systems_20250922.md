# Time-adaptive SympNets for separable Hamiltonian systems

**Korean Title:** 시간 적응형 SympNets를 분리 가능한 해밀토니안 시스템에 적용하기 위한 연구

## 📋 메타데이터

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Time-adaptive Symplectic Integrators

## 🔗 유사한 논문
- [[2025-09-18/Probabilistic and nonlinear compressive sensing_20250918|Probabilistic and nonlinear compressive sensing]] (81.4% similar)
- [[2025-09-22/Gradient Alignment in Physics-informed Neural Networks_ A Second-Order Optimization Perspective_20250922|Gradient Alignment in Physics-informed Neural Networks A Second-Order Optimization Perspective]] (80.1% similar)
- [[2025-09-22/TISDiSS_ A Training-Time and Inference-Time Scalable Framework for Discriminative Source Separation_20250922|TISDiSS A Training-Time and Inference-Time Scalable Framework for Discriminative Source Separation]] (78.9% similar)
- [[2025-09-17/A Neural Network for the Identical Kuramoto Equation_ Architectural Considerations and Performance Evaluation_20250917|A Neural Network for the Identical Kuramoto Equation Architectural Considerations and Performance Evaluation]] (78.8% similar)
- [[2025-09-18/Data-Driven Distributed Optimization via Aggregative Tracking and Deep-Learning_20250918|Data-Driven Distributed Optimization via Aggregative Tracking and Deep-Learning]] (78.8% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.16026v1 Announce Type: new 
Abstract: Measurement data is often sampled irregularly i.e. not on equidistant time grids. This is also true for Hamiltonian systems. However, existing machine learning methods, which learn symplectic integrators, such as SympNets [20] and H\'enonNets [4] still require training data generated by fixed step sizes. To learn time-adaptive symplectic integrators, an extension to SympNets, which we call TSympNets, was introduced in [20]. We adapt the architecture of TSympNets and extend them to non-autonomous Hamiltonian systems. So far the approximation qualities of TSympNets were unknown. We close this gap by providing a universal approximation theorem for separable Hamiltonian systems and show that it is not possible to extend it to non-separable Hamiltonian systems. To investigate these theoretical approximation capabilities, we perform different numerical experiments. Furthermore we fix a mistake in a proof of a substantial theorem [25, Theorem 2] for the approximation of symplectic maps in general, but specifically for symplectic machine learning methods.

## 🔍 Abstract (한글 번역)

arXiv:2509.16026v1 발표 유형: 신규  
초록: 측정 데이터는 종종 불규칙하게 샘플링되며, 이는 등간격 시간 그리드에서 이루어지지 않습니다. 이는 해밀토니안 시스템에서도 마찬가지입니다. 그러나 SympNets [20] 및 HénonNets [4]와 같은 심플렉틱 적분기를 학습하는 기존의 기계 학습 방법은 여전히 고정된 스텝 크기로 생성된 학습 데이터를 필요로 합니다. 시간 적응형 심플렉틱 적분기를 학습하기 위해, 우리는 SympNets의 확장판인 TSympNets를 [20]에서 도입했습니다. 우리는 TSympNets의 아키텍처를 비자율 해밀토니안 시스템에 맞게 조정하고 확장합니다. 현재까지 TSympNets의 근사 품질은 알려지지 않았습니다. 우리는 분리 가능한 해밀토니안 시스템에 대한 보편적 근사 정리를 제공함으로써 이 격차를 해소하고, 비분리 가능한 해밀토니안 시스템으로 확장하는 것은 불가능하다는 것을 보여줍니다. 이러한 이론적 근사 능력을 조사하기 위해 다양한 수치 실험을 수행합니다. 또한, 일반적으로 심플렉틱 사상 근사에 대한 중요한 정리 [25, 정리 2]의 증명에서 실수를 수정하며, 특히 심플렉틱 기계 학습 방법에 대해 수정합니다.

## 📝 요약

이 논문은 불규칙하게 샘플링된 데이터를 처리할 수 있는 시간 적응형 심플렉틱 적분기 학습 방법을 제안합니다. 기존의 SympNets와 HénonNets는 고정된 간격의 데이터를 필요로 하지만, TSympNets는 이를 확장하여 비자율적 해밀토니안 시스템에도 적용할 수 있도록 설계되었습니다. 저자들은 TSympNets의 보편적 근사 정리를 제시하여 분리 가능한 해밀토니안 시스템에 대한 이론적 근사 능력을 입증하고, 비분리 가능한 시스템에는 적용할 수 없음을 보여줍니다. 또한, 다양한 수치 실험을 통해 이론적 근사 성능을 검증하고, 기존 증명에서 발견된 오류를 수정하여 심플렉틱 지도 근사에 대한 새로운 통찰을 제공합니다.

## 🎯 주요 포인트

- 1. 기존의 심플렉틱 적분기를 학습하는 기계 학습 방법들은 고정된 스텝 크기로 생성된 훈련 데이터를 필요로 한다.

- 2. TSympNets는 시간 적응형 심플렉틱 적분기를 학습하기 위해 SympNets의 확장으로 도입되었다.

- 3. TSympNets의 근사 품질에 대한 보편 근사 정리를 제공하여 분리 가능한 해밀토니안 시스템에 대해 설명하였다.

- 4. 비분리 가능한 해밀토니안 시스템으로의 확장은 불가능함을 증명하였다.

- 5. 일반적인 심플렉틱 맵의 근사에 관한 중요한 정리의 증명에서 발생한 오류를 수정하였다.

---

*Generated on 2025-09-22 15:30:23*