# RespoDiff: Dual-Module Bottleneck Transformation for Responsible & Faithful T2I Generation

**Korean Title:** ì±…ì„ ìˆê³  ì¶©ì‹¤í•œ í…ìŠ¤íŠ¸-íˆ¬-ì´ë¯¸ì§€(T2I) ìƒì„±ì„ ìœ„í•œ ì´ì¤‘ ëª¨ë“ˆ ë³‘ëª© ë³€í™˜: RespoDiff

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Responsible Generation

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/Iterative Prompt Refinement for Safer Text-to-Image Generation_20250918|Iterative Prompt Refinement for Safer Text-to-Image Generation]] (85.2% similar)
- [[2025-09-19/TIDE_ Achieving Balanced Subject-Driven Image Generation via Target-Instructed Diffusion Enhancement_20250919|TIDE Achieving Balanced Subject-Driven Image Generation via Target-Instructed Diffusion Enhancement]] (84.2% similar)
- [[2025-09-22/Dynamic Classifier-Free Diffusion Guidance via Online Feedback_20250922|Dynamic Classifier-Free Diffusion Guidance via Online Feedback]] (83.2% similar)
- [[2025-09-18/BiasMap_ Leveraging Cross-Attentions to Discover and Mitigate Hidden Social Biases in Text-to-Image Generation_20250918|BiasMap Leveraging Cross-Attentions to Discover and Mitigate Hidden Social Biases in Text-to-Image Generation]] (82.6% similar)
- [[2025-09-22/Diffusion-Based Cross-Modal Feature Extraction for Multi-Label Classification_20250922|Diffusion-Based Cross-Modal Feature Extraction for Multi-Label Classification]] (82.4% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15257v1 Announce Type: cross 
Abstract: The rapid advancement of diffusion models has enabled high-fidelity and semantically rich text-to-image generation; however, ensuring fairness and safety remains an open challenge. Existing methods typically improve fairness and safety at the expense of semantic fidelity and image quality. In this work, we propose RespoDiff, a novel framework for responsible text-to-image generation that incorporates a dual-module transformation on the intermediate bottleneck representations of diffusion models. Our approach introduces two distinct learnable modules: one focused on capturing and enforcing responsible concepts, such as fairness and safety, and the other dedicated to maintaining semantic alignment with neutral prompts. To facilitate the dual learning process, we introduce a novel score-matching objective that enables effective coordination between the modules. Our method outperforms state-of-the-art methods in responsible generation by ensuring semantic alignment while optimizing both objectives without compromising image fidelity. Our approach improves responsible and semantically coherent generation by 20% across diverse, unseen prompts. Moreover, it integrates seamlessly into large-scale models like SDXL, enhancing fairness and safety. Code will be released upon acceptance.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15257v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: í™•ì‚° ëª¨ë¸ì˜ ê¸‰ì†í•œ ë°œì „ì€ ê³ í’ˆì§ˆì˜ ì˜ë¯¸ì ìœ¼ë¡œ í’ë¶€í•œ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ìƒì„±ì´ ê°€ëŠ¥í•˜ê²Œ í–ˆìœ¼ë‚˜, ê³µì •ì„±ê³¼ ì•ˆì „ì„±ì„ ë³´ì¥í•˜ëŠ” ê²ƒì€ ì—¬ì „íˆ í•´ê²°ë˜ì§€ ì•Šì€ ê³¼ì œì…ë‹ˆë‹¤. ê¸°ì¡´ ë°©ë²•ë“¤ì€ ì¼ë°˜ì ìœ¼ë¡œ ì˜ë¯¸ì  ì¶©ì‹¤ë„ì™€ ì´ë¯¸ì§€ í’ˆì§ˆì„ í¬ìƒí•˜ì—¬ ê³µì •ì„±ê³¼ ì•ˆì „ì„±ì„ ê°œì„ í•©ë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” í™•ì‚° ëª¨ë¸ì˜ ì¤‘ê°„ ë³‘ëª© í‘œí˜„ì— ì´ì¤‘ ëª¨ë“ˆ ë³€í™˜ì„ í†µí•©í•œ ì±…ì„ ìˆëŠ” í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•œ ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ì¸ RespoDiffë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì ‘ê·¼ ë°©ì‹ì€ ê³µì •ì„±ê³¼ ì•ˆì „ì„± ê°™ì€ ì±…ì„ ìˆëŠ” ê°œë…ì„ í¬ì°©í•˜ê³  ê°•í™”í•˜ëŠ” ë° ì¤‘ì ì„ ë‘” ëª¨ë“ˆê³¼ ì¤‘ë¦½ì ì¸ í”„ë¡¬í”„íŠ¸ì™€ì˜ ì˜ë¯¸ì  ì •ë ¬ì„ ìœ ì§€í•˜ëŠ” ë° ì „ë…í•˜ëŠ” ë‘ ê°€ì§€ í•™ìŠµ ê°€ëŠ¥í•œ ëª¨ë“ˆì„ ë„ì…í•©ë‹ˆë‹¤. ì´ì¤‘ í•™ìŠµ ê³¼ì •ì„ ì´‰ì§„í•˜ê¸° ìœ„í•´, ëª¨ë“ˆ ê°„ì˜ íš¨ê³¼ì ì¸ ì¡°ì •ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ìƒˆë¡œìš´ ì ìˆ˜ ë§¤ì¹­ ëª©í‘œë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ë°©ë²•ì€ ì´ë¯¸ì§€ ì¶©ì‹¤ë„ë¥¼ ì†ìƒì‹œí‚¤ì§€ ì•Šìœ¼ë©´ì„œ ë‘ ëª©í‘œë¥¼ ìµœì í™”í•˜ì—¬ ì˜ë¯¸ì  ì •ë ¬ì„ ë³´ì¥í•¨ìœ¼ë¡œì¨ ì±…ì„ ìˆëŠ” ìƒì„±ì—ì„œ ìµœì²¨ë‹¨ ë°©ë²•ë“¤ì„ ëŠ¥ê°€í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì ‘ê·¼ ë°©ì‹ì€ ë‹¤ì–‘í•œ ë³´ì§€ ëª»í•œ í”„ë¡¬í”„íŠ¸ì—ì„œ ì±…ì„ ìˆê³  ì˜ë¯¸ì ìœ¼ë¡œ ì¼ê´€ëœ ìƒì„±ì„ 20% ê°œì„ í•©ë‹ˆë‹¤. ë˜í•œ, SDXLê³¼ ê°™ì€ ëŒ€ê·œëª¨ ëª¨ë¸ì— ì›í™œí•˜ê²Œ í†µí•©ë˜ì–´ ê³µì •ì„±ê³¼ ì•ˆì „ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì½”ë“œëŠ” ìŠ¹ì¸ í›„ ê³µê°œë  ì˜ˆì •ì…ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì—ì„œëŠ” í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ìƒì„±ì—ì„œ ê³µì •ì„±ê³¼ ì•ˆì „ì„±ì„ ë³´ì¥í•˜ë©´ì„œë„ ì´ë¯¸ì§€ í’ˆì§ˆê³¼ ì˜ë¯¸ì  ì¶©ì‹¤ì„±ì„ ìœ ì§€í•˜ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ì¸ RespoDiffë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. RespoDiffëŠ” í™•ì‚° ëª¨ë¸ì˜ ì¤‘ê°„ í‘œí˜„ì— ì´ì¤‘ ëª¨ë“ˆ ë³€í™˜ì„ ì ìš©í•˜ì—¬ ê³µì •ì„±ê³¼ ì•ˆì „ì„±ì„ ê°•í™”í•˜ëŠ” ëª¨ë“ˆê³¼ ì¤‘ë¦½ì ì¸ í”„ë¡¬í”„íŠ¸ì™€ì˜ ì˜ë¯¸ì  ì •ë ¬ì„ ìœ ì§€í•˜ëŠ” ëª¨ë“ˆì„ í¬í•¨í•©ë‹ˆë‹¤. ì´ì¤‘ í•™ìŠµì„ ìœ„í•´ ìƒˆë¡œìš´ ìŠ¤ì½”ì–´ ë§¤ì¹­ ëª©í‘œë¥¼ ë„ì…í•˜ì—¬ ëª¨ë“ˆ ê°„ íš¨ê³¼ì ì¸ ì¡°ìœ¨ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ì´ë¯¸ì§€ ì¶©ì‹¤ë„ë¥¼ ì†ìƒì‹œí‚¤ì§€ ì•Šìœ¼ë©´ì„œ ì˜ë¯¸ì  ì •ë ¬ê³¼ ì±…ì„ ìˆëŠ” ìƒì„±ì„ ìµœì í™”í•˜ì—¬ ê¸°ì¡´ ë°©ë²•ë³´ë‹¤ 20% í–¥ìƒëœ ì„±ê³¼ë¥¼ ë³´ì…ë‹ˆë‹¤. ë˜í•œ, ëŒ€ê·œëª¨ ëª¨ë¸ì— í†µí•©ë˜ì–´ ê³µì •ì„±ê³¼ ì•ˆì „ì„±ì„ ê°•í™”í•©ë‹ˆë‹¤. ì½”ë“œ ê³µê°œëŠ” ë…¼ë¬¸ ìˆ˜ë½ í›„ ì˜ˆì •ì…ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. RespoDiffëŠ” í™•ì‚° ëª¨ë¸ì˜ ì¤‘ê°„ ë³‘ëª© í‘œí˜„ì— ì´ì¤‘ ëª¨ë“ˆ ë³€í™˜ì„ ë„ì…í•˜ì—¬ ì±…ì„ ìˆëŠ” í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ìƒì„±ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.

- 2. í•˜ë‚˜ì˜ ëª¨ë“ˆì€ ê³µì •ì„±ê³¼ ì•ˆì „ì„± ê°™ì€ ì±…ì„ ìˆëŠ” ê°œë…ì„ í¬ì°©í•˜ê³  ê°•í™”í•˜ëŠ” ë° ì¤‘ì ì„ ë‘ê³ , ë‹¤ë¥¸ ëª¨ë“ˆì€ ì¤‘ë¦½ì ì¸ í”„ë¡¬í”„íŠ¸ì™€ì˜ ì˜ë¯¸ì  ì •ë ¬ì„ ìœ ì§€í•˜ëŠ” ë° ì „ë…í•©ë‹ˆë‹¤.

- 3. ìƒˆë¡œìš´ ìŠ¤ì½”ì–´ ë§¤ì¹­ ëª©í‘œë¥¼ ë„ì…í•˜ì—¬ ë‘ ëª¨ë“ˆ ê°„ì˜ íš¨ê³¼ì ì¸ ì¡°ì •ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.

- 4. ì œì•ˆëœ ë°©ë²•ì€ ì˜ë¯¸ì  ì •ë ¬ì„ ë³´ì¥í•˜ë©´ì„œ ì´ë¯¸ì§€ ì¶©ì‹¤ë„ë¥¼ ì†ìƒì‹œí‚¤ì§€ ì•Šê³  ë‘ ê°€ì§€ ëª©í‘œë¥¼ ìµœì í™”í•˜ì—¬ ì±…ì„ ìˆëŠ” ìƒì„±ì—ì„œ ìµœì²¨ë‹¨ ë°©ë²•ì„ ëŠ¥ê°€í•©ë‹ˆë‹¤.

- 5. ë‹¤ì–‘í•œ ë¯¸ì§€ì˜ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•´ ì±…ì„ ìˆê³  ì˜ë¯¸ì ìœ¼ë¡œ ì¼ê´€ëœ ìƒì„±ì„ 20% ê°œì„ í•˜ë©°, ëŒ€ê·œëª¨ ëª¨ë¸ì— ì›í™œí•˜ê²Œ í†µí•©ë©ë‹ˆë‹¤.

---

*Generated on 2025-09-22 15:36:07*