# ViSpec: Accelerating Vision-Language Models with Vision-Aware Speculative Decoding

**Korean Title:** ViSpec: ë¹„ì „ ì¸ì‹ ì¶”ì¸¡ ë””ì½”ë”©ì„ í†µí•œ ë¹„ì „-ì–¸ì–´ ëª¨ë¸ ê°€ì†í™”

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[reports/digests/daily_digest_20250922|2025-09-22]] [[keywords/evolved/Multimodal Coherence|Multimodal Coherence]] [[keywords/specific/Attention Mechanism|Attention Mechanism]] [[keywords/broad/Vision Language Models|Vision Language Models]] [[keywords/broad/Speculative Decoding|Speculative Decoding]] [[keywords/unique/Vision Aware Speculative Decoding|Vision Aware Speculative Decoding]] [[categories/cs.CL|cs.CL]] [[2025-09-22/LLMs Can Compensate for Deficiencies in Visual Representations_20250922|LLMs Can Compensate for Deficiencies in Visual Representations]] (84.9% similar) [[2025-09-22/Distribution-Aligned Decoding for Efficient LLM Task Adaptation_20250922|Distribution-Aligned Decoding for Efficient LLM Task Adaptation]] (84.0% similar) [[2025-09-22/Robust Vision-Language Models via Tensor Decomposition_ A Defense Against Adversarial Attacks_20250922|Robust Vision-Language Models via Tensor Decomposition: A Defense Against Adversarial Attacks]] (83.9% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Multimodal Coherence
**ğŸ”— Specific Connectable**: Attention Mechanism
**ğŸ”¬ Broad Technical**: Vision Language Models, Speculative Decoding
**â­ Unique Technical**: Vision Aware Speculative Decoding
## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/LLMs Can Compensate for Deficiencies in Visual Representations_20250922|LLMs Can Compensate for Deficiencies in Visual Representations]] (84.9% similar)
- [[2025-09-22/Distribution-Aligned Decoding for Efficient LLM Task Adaptation_20250922|Distribution-Aligned Decoding for Efficient LLM Task Adaptation]] (84.0% similar)
- [[2025-09-22/Robust Vision-Language Models via Tensor Decomposition_ A Defense Against Adversarial Attacks_20250922|Robust Vision-Language Models via Tensor Decomposition A Defense Against Adversarial Attacks]] (83.9% similar)
- [[2025-09-22/CARD_ A Cache-Assisted Parallel Speculative Decoding Framework via Query-and-Correct Paradigm for Accelerating LLM Inference_20250922|CARD A Cache-Assisted Parallel Speculative Decoding Framework via Query-and-Correct Paradigm for Accelerating LLM Inference]] (83.7% similar)
- [[2025-09-19/V-SEAM_ Visual Semantic Editing and Attention Modulating for Causal Interpretability of Vision-Language Models_20250919|V-SEAM Visual Semantic Editing and Attention Modulating for Causal Interpretability of Vision-Language Models]] (83.6% similar)


**ArXiv ID**: [2509.15235](https://arxiv.org/abs/2509.15235)
**Published**: 2025-09-22
**Category**: cs.CL
**PDF**: [Download](https://arxiv.org/pdf/2509.15235.pdf)


**ArXiv ID**: [2509.15235](https://arxiv.org/abs/2509.15235)
**Published**: 2025-09-22
**Category**: cs.CL
**PDF**: [Download](https://arxiv.org/pdf/2509.15235.pdf)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Multimodal Coherence
**ğŸ”— Specific Connectable**: Attention Mechanism
**â­ Unique Technical**: Vision Aware Speculative Decoding
**ğŸ”¬ Broad Technical**: Vision Language Models, Speculative Decoding

## ğŸ·ï¸ ì¶”ì¶œëœ í‚¤ì›Œë“œ



`Vision Language Models` â€¢ 

`Speculative Decoding` â€¢ 

`Attention Mechanism` â€¢ 

`Vision Aware Speculative Decoding` â€¢ 

`Multimodal Coherence`



## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸

Similar papers will be displayed here based on embedding similarity.

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15235v1 Announce Type: cross 
Abstract: Speculative decoding is a widely adopted technique for accelerating inference in large language models (LLMs), yet its application to vision-language models (VLMs) remains underexplored, with existing methods achieving only modest speedups (<1.5x). This gap is increasingly significant as multimodal capabilities become central to large-scale models. We hypothesize that large VLMs can effectively filter redundant image information layer by layer without compromising textual comprehension, whereas smaller draft models struggle to do so. To address this, we introduce Vision-Aware Speculative Decoding (ViSpec), a novel framework tailored for VLMs. ViSpec employs a lightweight vision adaptor module to compress image tokens into a compact representation, which is seamlessly integrated into the draft model's attention mechanism while preserving original image positional information. Additionally, we extract a global feature vector for each input image and augment all subsequent text tokens with this feature to enhance multimodal coherence. To overcome the scarcity of multimodal datasets with long assistant responses, we curate a specialized training dataset by repurposing existing datasets and generating extended outputs using the target VLM with modified prompts. Our training strategy mitigates the risk of the draft model exploiting direct access to the target model's hidden states, which could otherwise lead to shortcut learning when training solely on target model outputs. Extensive experiments validate ViSpec, achieving, to our knowledge, the first substantial speedup in VLM speculative decoding.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15235v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ì¶”ë¡  ì†ë„ë¥¼ ë†’ì´ê¸° ìœ„í•œ ì¶”ì¸¡ ë””ì½”ë”©ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì—ì„œ ë„ë¦¬ ì±„íƒëœ ê¸°ë²•ì´ì§€ë§Œ, ì‹œê°-ì–¸ì–´ ëª¨ë¸(VLM)ì— ëŒ€í•œ ì ìš©ì€ ì•„ì§ ì¶©ë¶„íˆ íƒêµ¬ë˜ì§€ ì•Šì•˜ìœ¼ë©°, ê¸°ì¡´ ë°©ë²•ë“¤ì€ ê²¨ìš° 1.5ë°° ë¯¸ë§Œì˜ ì†ë„ í–¥ìƒë§Œì„ ë‹¬ì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë‹¤ì¤‘ ëª¨ë‹¬ ê¸°ëŠ¥ì´ ëŒ€ê·œëª¨ ëª¨ë¸ì˜ ì¤‘ì‹¬ì´ ë˜ë©´ì„œ ì´ ê²©ì°¨ëŠ” ì ì  ë” ì¤‘ìš”í•´ì§€ê³  ìˆìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” ëŒ€í˜• VLMì´ í…ìŠ¤íŠ¸ ì´í•´ë¥¼ ì†ìƒì‹œí‚¤ì§€ ì•Šìœ¼ë©´ì„œ ê³„ì¸µë³„ë¡œ ì¤‘ë³µëœ ì´ë¯¸ì§€ ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í•„í„°ë§í•  ìˆ˜ ìˆëŠ” ë°˜ë©´, ì‘ì€ ì´ˆì•ˆ ëª¨ë¸ì€ ê·¸ëŸ¬í•œ ëŠ¥ë ¥ì´ ë¶€ì¡±í•˜ë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” VLMì— íŠ¹í™”ëœ ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ì¸ Vision-Aware Speculative Decoding (ViSpec)ì„ ì†Œê°œí•©ë‹ˆë‹¤. ViSpecì€ ê²½ëŸ‰ì˜ ë¹„ì „ ì–´ëŒ‘í„° ëª¨ë“ˆì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ í† í°ì„ ì••ì¶•ëœ í‘œí˜„ìœ¼ë¡œ ë³€í™˜í•˜ê³ , ì´ë¥¼ ì´ˆì•ˆ ëª¨ë¸ì˜ ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì— ì›ë˜ì˜ ì´ë¯¸ì§€ ìœ„ì¹˜ ì •ë³´ë¥¼ ìœ ì§€í•˜ë©´ì„œ ë§¤ë„ëŸ½ê²Œ í†µí•©í•©ë‹ˆë‹¤. ë˜í•œ, ê° ì…ë ¥ ì´ë¯¸ì§€ì— ëŒ€í•œ ì „ì—­ íŠ¹ì§• ë²¡í„°ë¥¼ ì¶”ì¶œí•˜ê³ , ì´ë¥¼ ëª¨ë“  í›„ì† í…ìŠ¤íŠ¸ í† í°ì— ì¶”ê°€í•˜ì—¬ ë‹¤ì¤‘ ëª¨ë‹¬ ì¼ê´€ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ê¸´ ë³´ì¡° ì‘ë‹µì„ ê°€ì§„ ë‹¤ì¤‘ ëª¨ë‹¬ ë°ì´í„°ì…‹ì˜ ë¶€ì¡± ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ê¸°ì¡´ ë°ì´í„°ì…‹ì„ ì¬í™œìš©í•˜ê³  ìˆ˜ì •ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€ìƒ VLMìœ¼ë¡œ í™•ì¥ëœ ì¶œë ¥ì„ ìƒì„±í•¨ìœ¼ë¡œì¨ íŠ¹í™”ëœ í›ˆë ¨ ë°ì´í„°ì…‹ì„ êµ¬ì„±í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ í›ˆë ¨ ì „ëµì€ ì´ˆì•ˆ ëª¨ë¸ì´ ëŒ€ìƒ ëª¨ë¸ì˜ ìˆ¨ê²¨ì§„ ìƒíƒœì— ì§ì ‘ ì ‘ê·¼í•˜ì—¬ ì§€ë¦„ê¸¸ í•™ìŠµì„ í•  ìœ„í—˜ì„ ì™„í™”í•˜ë©°, ì´ëŠ” ëŒ€ìƒ ëª¨ë¸ ì¶œë ¥ë§Œìœ¼ë¡œ í›ˆë ¨í•  ê²½ìš° ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê´‘ë²”ìœ„í•œ ì‹¤í—˜ì„ í†µí•´ ViSpecì€ VLM ì¶”ì¸¡ ë””ì½”ë”©ì—ì„œ ìµœì´ˆë¡œ ì‹¤ì§ˆì ì¸ ì†ë„ í–¥ìƒì„ ë‹¬ì„±í–ˆìŒì„ ê²€ì¦í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€í˜• ë¹„ì „-ì–¸ì–´ ëª¨ë¸(VLM)ì˜ ì¶”ë¡  ì†ë„ë¥¼ ë†’ì´ê¸° ìœ„í•œ ìƒˆë¡œìš´ ë°©ë²•ë¡ ì¸ Vision-Aware Speculative Decoding(ViSpec)ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë°©ë²•ë“¤ì´ 1.5ë°° ë¯¸ë§Œì˜ ì†ë„ í–¥ìƒì— ê·¸ì¹œ ë°˜ë©´, ViSpecì€ ì´ë¯¸ì§€ ì •ë³´ë¥¼ ì••ì¶•í•˜ì—¬ í…ìŠ¤íŠ¸ ì´í•´ë¥¼ ìœ ì§€í•˜ë©´ì„œë„ ë¶ˆí•„ìš”í•œ ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì œê±°í•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ê²½ëŸ‰ì˜ ë¹„ì „ ì–´ëŒ‘í„° ëª¨ë“ˆì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ í† í°ì„ ì••ì¶•í•˜ê³ , ì´ ì •ë³´ë¥¼ ì´ˆì•ˆ ëª¨ë¸ì˜ ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì— í†µí•©í•©ë‹ˆë‹¤. ë˜í•œ, ê° ì´ë¯¸ì§€ì— ëŒ€í•œ ì „ì—­ íŠ¹ì§• ë²¡í„°ë¥¼ ì¶”ì¶œí•˜ì—¬ í…ìŠ¤íŠ¸ í† í°ì— ì¶”ê°€í•¨ìœ¼ë¡œì¨ ë‹¤ì¤‘ ëª¨ë‹¬ ì¼ê´€ì„±ì„ ë†’ì…ë‹ˆë‹¤. ViSpecì€ íŠ¹ë³„íˆ êµ¬ì„±ëœ í•™ìŠµ ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬ ëŒ€í˜• VLMì˜ ìˆ¨ê²¨ì§„ ìƒíƒœì— ëŒ€í•œ ì§ì ‘ ì ‘ê·¼ì„ í”¼í•˜ê³ , ì‹¤í—˜ì„ í†µí•´ VLM ì¶”ë¡  ì†ë„ì—ì„œ ìµœì´ˆë¡œ ìœ ì˜ë¯¸í•œ ê°œì„ ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸


- 1. ViSpecëŠ” VLMsì— íŠ¹í™”ëœ ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¡œ, ê²½ëŸ‰ì˜ ë¹„ì „ ì–´ëŒ‘í„° ëª¨ë“ˆì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ í† í°ì„ ì••ì¶•ëœ í‘œí˜„ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

- 2. ViSpecëŠ” ì…ë ¥ ì´ë¯¸ì§€ì˜ ê¸€ë¡œë²Œ í”¼ì²˜ ë²¡í„°ë¥¼ ì¶”ì¶œí•˜ì—¬ ëª¨ë“  í…ìŠ¤íŠ¸ í† í°ì— ì¶”ê°€í•¨ìœ¼ë¡œì¨ ë©€í‹°ëª¨ë‹¬ ì¼ê´€ì„±ì„ ê°•í™”í•©ë‹ˆë‹¤.

- 3. ViSpecëŠ” ê¸°ì¡´ ë°ì´í„°ì…‹ì„ ì¬í™œìš©í•˜ê³  ìˆ˜ì •ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ í™•ì¥ëœ ì¶œë ¥ì„ ìƒì„±í•¨ìœ¼ë¡œì¨ ë©€í‹°ëª¨ë‹¬ ë°ì´í„°ì…‹ì˜ ë¶€ì¡± ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤.

- 4. ViSpecëŠ” ëŒ€ê·œëª¨ VLMì˜ ì¶”ë¡  ì†ë„ë¥¼ ì‹¤ì§ˆì ìœ¼ë¡œ í–¥ìƒì‹œì¼œ, VLM ì¶”ë¡ ì—ì„œ ìµœì´ˆë¡œ ì˜ë¯¸ ìˆëŠ” ì†ë„ í–¥ìƒì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.

- 5. ViSpecì˜ í›ˆë ¨ ì „ëµì€ ì´ˆì•ˆ ëª¨ë¸ì´ ëª©í‘œ ëª¨ë¸ì˜ ìˆ¨ê²¨ì§„ ìƒíƒœì— ì§ì ‘ ì ‘ê·¼í•˜ì—¬ ë°œìƒí•  ìˆ˜ ìˆëŠ” ì§€ë¦„ê¸¸ í•™ìŠµì„ ë°©ì§€í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-22 16:30:55*