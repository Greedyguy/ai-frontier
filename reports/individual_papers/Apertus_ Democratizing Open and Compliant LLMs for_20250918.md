
# Apertus: Democratizing Open and Compliant LLMs for Global Language Environments

**Korean Title:** ì•„í˜ë¥´íˆ¬ìŠ¤: ì „ ì„¸ê³„ ì–¸ì–´ í™˜ê²½ì„ ìœ„í•œ ê°œë°©ì ì´ê³  ì¤€ìˆ˜í•˜ëŠ” LLMs ë¯¼ì£¼í™”

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-18|2025-09-18]] [[keywords/evolved/Transparent Audit|Transparent Audit]] [[keywords/broad/Large Language Models|Large Language Models]] [[keywords/broad/Multilingual Representation|Multilingual Representation]] [[keywords/specific/Goldfish Objective|Goldfish Objective]] [[keywords/unique/Apertus|Apertus]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Transparent Audit
**ğŸ”¬ Broad Technical**: Large Language Models, Multilingual Representation
**ğŸ”— Specific Connectable**: Goldfish Objective
**â­ Unique Technical**: Apertus

**ArXiv ID**: [2509.14233](https://arxiv.org/abs/2509.14233)
**Published**: 2025-09-18
**Category**: cs.AI
**PDF**: [Download](https://arxiv.org/pdf/2509.14233.pdf)


## ğŸ·ï¸ ì¶”ì¶œëœ í‚¤ì›Œë“œ



`Large Language Models` â€¢ 

`Multilingual Representation` â€¢ 

`Goldfish Objective` â€¢ 

`Apertus` â€¢ 

`Transparent Audit`



## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.14233v1 Announce Type: cross 
Abstract: We present Apertus, a fully open suite of large language models (LLMs) designed to address two systemic shortcomings in today's open model ecosystem: data compliance and multilingual representation. Unlike many prior models that release weights without reproducible data pipelines or regard for content-owner rights, Apertus models are pretrained exclusively on openly available data, retroactively respecting robots.txt exclusions and filtering for non-permissive, toxic, and personally identifiable content. To mitigate risks of memorization, we adopt the Goldfish objective during pretraining, strongly suppressing verbatim recall of data while retaining downstream task performance. The Apertus models also expand multilingual coverage, training on 15T tokens from over 1800 languages, with ~40% of pretraining data allocated to non-English content. Released at 8B and 70B scales, Apertus approaches state-of-the-art results among fully open models on multilingual benchmarks, rivalling or surpassing open-weight counterparts. Beyond model weights, we release all scientific artifacts from our development cycle with a permissive license, including data preparation scripts, checkpoints, evaluation suites, and training code, enabling transparent audit and extension.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.14233v1 ë°œí‘œ ìœ í˜•: êµì°¨
ìš”ì•½: ìš°ë¦¬ëŠ” ì˜¤ëŠ˜ë‚ ì˜ ì˜¤í”ˆ ëª¨ë¸ ìƒíƒœê³„ì—ì„œ ë‘ ê°€ì§€ ì‹œìŠ¤í…œì ì¸ ê²°ì ì„ í•´ê²°í•˜ê¸° ìœ„í•´ ì„¤ê³„ëœ ì™„ì „íˆ ì˜¤í”ˆ ì†ŒìŠ¤ì˜ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ (LLMs) ìŠ¤ìœ„íŠ¸ì¸ Apertusë¥¼ ì œì‹œí•©ë‹ˆë‹¤: ë°ì´í„° ì¤€ìˆ˜ ë° ë‹¤êµ­ì–´ í‘œí˜„. ì´ì „ ëª¨ë¸ê³¼ëŠ” ë‹¬ë¦¬, Apertus ëª¨ë¸ì€ ì¬í˜„ ê°€ëŠ¥í•œ ë°ì´í„° íŒŒì´í”„ë¼ì¸ì´ë‚˜ ì½˜í…ì¸  ì†Œìœ ìì˜ ê¶Œë¦¬ë¥¼ ê³ ë ¤í•˜ì§€ ì•Šê³  ê°€ì¤‘ì¹˜ë¥¼ ê³µê°œí•˜ëŠ” ë§ì€ ì´ì „ ëª¨ë¸ê³¼ ë‹¬ë¦¬, Apertus ëª¨ë¸ì€ ì˜¤ì§ ê³µê°œì ìœ¼ë¡œ ì´ìš© ê°€ëŠ¥í•œ ë°ì´í„°ë¡œ ì‚¬ì „ í›ˆë ¨ë˜ì–´, robots.txt ì œì™¸ ì‚¬í•­ì„ í›„í–‰ì ìœ¼ë¡œ ì¡´ì¤‘í•˜ê³  ë¹„í—ˆê°€, ìœ í•´ ë° ê°œì¸ ì‹ë³„ ê°€ëŠ¥í•œ ì½˜í…ì¸ ë¥¼ í•„í„°ë§í•©ë‹ˆë‹¤. ê¸°ì–µ ìœ„í—˜ì„ ì™„í™”í•˜ê¸° ìœ„í•´ ì‚¬ì „ í›ˆë ¨ ì¤‘ì— Goldfish ëª©í‘œë¥¼ ì±„íƒí•˜ì—¬, ë°ì´í„°ì˜ ë‹¨ìˆœ ë°˜ë³µ ê¸°ì–µì„ ê°•ë ¥í•˜ê²Œ ì–µì œí•˜ë©´ì„œ í•˜ë¥˜ ì‘ì—… ì„±ëŠ¥ì„ ìœ ì§€í•©ë‹ˆë‹¤. Apertus ëª¨ë¸ì€ ë˜í•œ ë‹¤êµ­ì–´ ì»¤ë²„ë¦¬ì§€ë¥¼ í™•ëŒ€í•˜ì—¬, 1800ê°œ ì´ìƒì˜ ì–¸ì–´ë¡œë¶€í„° 15ì¡° í† í°ì„ í•™ìŠµí•˜ë©°, ì‚¬ì „ í›ˆë ¨ ë°ì´í„°ì˜ ì•½ 40%ê°€ ì˜ì–´ ì´ì™¸ì˜ ì½˜í…ì¸ ì— í• ë‹¹ë©ë‹ˆë‹¤. 8B ë° 70B ê·œëª¨ë¡œ ê³µê°œëœ ApertusëŠ” ë‹¤êµ­ì–´ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ì™„ì „íˆ ì˜¤í”ˆëœ ëª¨ë¸ ì¤‘ ìµœì‹  ê²°ê³¼ì— ê·¼ì ‘í•˜ê±°ë‚˜ ì´ˆì›”í•˜ì—¬ ì˜¤í”ˆ ê°€ì¤‘ì¹˜ ëŒ€ì‘ ëª¨ë¸ê³¼ ê²½ìŸí•©ë‹ˆë‹¤. ëª¨ë¸ ê°€ì¤‘ì¹˜ ì´ì™¸ì—ë„, ìš°ë¦¬ëŠ” í—ˆìš© ë¼ì´ì„ ìŠ¤ë¡œ ê°œë°œ ì£¼ê¸°ì—ì„œ ëª¨ë“  ê³¼í•™ì  ìì‚°ì„ ê³µê°œí•˜ë©°, ë°ì´í„° ì¤€ë¹„ ìŠ¤í¬ë¦½íŠ¸, ì²´í¬í¬ì¸íŠ¸, í‰ê°€ ìŠ¤ìœ„íŠ¸ ë° í›ˆë ¨ ì½”ë“œë¥¼ í¬í•¨í•˜ì—¬ íˆ¬ëª…í•œ ê°ì‚¬ì™€ í™•ì¥ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

í•œêµ­ì–´ ìš”ì•½:
ë³¸ ì—°êµ¬ëŠ” Apertusë¼ëŠ” ì™„ì „íˆ ì˜¤í”ˆëœ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ ìŠ¤ìœ„íŠ¸ë¥¼ ì œì‹œí•œë‹¤. ì´ ëª¨ë¸ì€ ë°ì´í„° ì¤€ìˆ˜ ë° ë‹¤êµ­ì–´ í‘œí˜„ì´ë¼ëŠ” ë‘ ê°€ì§€ ì‹œìŠ¤í…œì ì¸ ê²°í•¨ì„ í•´ê²°í•˜ê¸° ìœ„í•´ ì„¤ê³„ë˜ì—ˆë‹¤. Apertus ëª¨ë¸ì€ ê³µê°œì ìœ¼ë¡œ ì´ìš© ê°€ëŠ¥í•œ ë°ì´í„°ë§Œì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ì „ í›ˆë ¨ë˜ë©°, robots.txt ì œì™¸ ì‚¬í•­ì„ ì¡´ì¤‘í•˜ê³  ë¹„í—ˆê°€, ìœ í•´ ë° ê°œì¸ ì‹ë³„ ê°€ëŠ¥í•œ ì½˜í…ì¸ ë¥¼ í•„í„°ë§í•œë‹¤. ë˜í•œ, Goldfish ëª©í‘œë¥¼ ì±„íƒí•˜ì—¬ ê¸°ì–µ ìœ„í—˜ì„ ì™„í™”í•˜ê³ , ë‹¤êµ­ì–´ ì»¤ë²„ë¦¬ì§€ë¥¼ í™•ëŒ€í•˜ì—¬ 1800ê°œ ì´ìƒì˜ ì–¸ì–´ë¡œë¶€í„° 15ì¡° í† í°ì„ í•™ìŠµí•œë‹¤. ì´ëŸ¬í•œ ëª¨ë¸ì€ ë‹¤êµ­ì–´ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìµœì²¨ë‹¨ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ë©°, ëª¨ë“  ê³¼í•™ì  ìì‚°ì„ í—ˆìš©í•˜ëŠ” ë¼ì´ì„ ìŠ¤ë¡œ ê³µê°œí•˜ì—¬ íˆ¬ëª…í•œ ê°ì‚¬ì™€ í™•ì¥ì„ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸


- 1. ApertusëŠ” ë°ì´í„° ì¤€ìˆ˜ ë° ë‹¤êµ­ì–´ í‘œí˜„ì„ ìœ„í•´ ì„¤ê³„ëœ ì™„ì „íˆ ì˜¤í”ˆ ì†ŒìŠ¤ì˜ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ ìŠ¤ìœ„íŠ¸ì´ë‹¤.

- 2. Apertus ëª¨ë¸ì€ ê³µê°œì ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ë§Œì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ì „ í›ˆë ¨ë˜ë©°, ë‹¤êµ­ì–´ ì»¤ë²„ë¦¬ì§€ë¥¼ í™•ì¥í•œë‹¤.

- 3. ApertusëŠ” ë‹¤êµ­ì–´ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìµœì²¨ë‹¨ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ë©°, ê³¼ê±°ì˜ ì˜¤í”ˆ ì†ŒìŠ¤ ëª¨ë¸ì„ ëŠ¥ê°€í•œë‹¤.

- 4. Apertus ê°œë°œ ì£¼ê¸°ì—ì„œ ëª¨ë“  ê³¼í•™ì  ìì‚°ì„ í¼ë¯¸ì‹œë¸Œ ë¼ì´ì„¼ìŠ¤ë¡œ ê³µê°œí•˜ì—¬ íˆ¬ëª…í•œ ê°ì‚¬ì™€ í™•ì¥ì„ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤.


---

*Generated on 2025-09-18 16:26:24*