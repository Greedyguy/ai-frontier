# CORE-RAG: Lossless Compression for Retrieval-Augmented LLMs via Reinforcement Learning

**Korean Title:** CORE-RAG: 강화 학습을 통한 검색 증강 대형 언어 모델의 무손실 압축

## 📋 메타데이터

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Lossless Context Compression

## 🔗 유사한 논문
- [[2025-09-19/Enhancing Retrieval Augmentation via Adversarial Collaboration_20250919|Enhancing Retrieval Augmentation via Adversarial Collaboration]] (86.5% similar)
- [[2025-09-22/Relevance to Utility_ Process-Supervised Rewrite for RAG_20250922|Relevance to Utility Process-Supervised Rewrite for RAG]] (85.8% similar)
- [[2025-09-19/GRADA_ Graph-based Reranking against Adversarial Documents Attack_20250919|GRADA Graph-based Reranking against Adversarial Documents Attack]] (85.7% similar)
- [[2025-09-19/Causal-Counterfactual RAG_ The Integration of Causal-Counterfactual Reasoning into RAG_20250919|Causal-Counterfactual RAG The Integration of Causal-Counterfactual Reasoning into RAG]] (85.5% similar)
- [[2025-09-19/Engineering RAG Systems for Real-World Applications_ Design, Development, and Evaluation_20250919|Engineering RAG Systems for Real-World Applications Design, Development, and Evaluation]] (85.4% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2508.19282v2 Announce Type: replace-cross 
Abstract: Retrieval-Augmented Generation (RAG) has emerged as a promising approach to enhance the timeliness of knowledge and the factual accuracy of responses in Large Language Models (LLMs). However, the inclusion of excessive retrieved documents substantially increases the input length, leading to higher computational costs. Previous studies have attempted to compress retrieved documents into shorter texts before in-context integration, but such methods often compromise end-task performance. The lack of well-defined compression targets forces many approaches to rely on fixed heuristics, which cannot guarantee that the compressed content will effectively support the end task. To address these limitations, we propose CORE, a novel method designed to achieve lossless context compression for RAG. CORE employs reinforcement learning to optimize the compression process without relying on predefined compression labels, which enables the compressor to generate summaries that maximize the accuracy of answers generated by the LLM. Extensive experiments on four datasets demonstrate the superiority of our approach. With a high compression ratio of 3\%, our method not only avoids performance degradation compared to prepending full documents across all datasets but also improves the average Exact Match (EM) score by 3.3 points. The code will be released soon.

## 🔍 Abstract (한글 번역)

arXiv:2508.19282v2 발표 유형: 교차 대체  
초록: 검색 증강 생성(Retrieval-Augmented Generation, RAG)은 대형 언어 모델(LLM)에서 지식의 적시성과 응답의 사실적 정확성을 향상시키기 위한 유망한 접근 방식으로 부상하고 있습니다. 그러나 과도한 검색 문서의 포함은 입력 길이를 상당히 증가시켜 계산 비용을 높입니다. 이전 연구에서는 맥락 내 통합 전에 검색된 문서를 더 짧은 텍스트로 압축하려고 시도했지만, 이러한 방법은 종종 최종 작업 성능을 저하시킵니다. 명확하게 정의된 압축 목표의 부재로 인해 많은 접근 방식이 고정된 휴리스틱에 의존하게 되며, 이는 압축된 콘텐츠가 최종 작업을 효과적으로 지원할 것이라는 보장을 제공하지 못합니다. 이러한 한계를 해결하기 위해, 우리는 RAG를 위한 무손실 맥락 압축을 달성하기 위해 설계된 새로운 방법인 CORE를 제안합니다. CORE는 사전 정의된 압축 레이블에 의존하지 않고 강화 학습을 통해 압축 과정을 최적화하여, LLM이 생성한 답변의 정확성을 극대화하는 요약을 생성할 수 있도록 합니다. 네 개의 데이터셋에 대한 광범위한 실험은 우리의 접근 방식의 우수성을 입증합니다. 3%의 높은 압축 비율을 가진 우리의 방법은 모든 데이터셋에서 전체 문서를 미리 첨부하는 것과 비교하여 성능 저하를 피할 뿐만 아니라 평균 정확한 일치(Exact Match, EM) 점수를 3.3점 향상시킵니다. 코드는 곧 공개될 예정입니다.

## 📝 요약

이 논문은 대규모 언어 모델(LLM)의 응답 정확성과 지식의 최신성을 향상시키기 위한 검색 증강 생성(RAG) 방법을 다룹니다. 기존의 문서 압축 방법은 성능 저하를 초래할 수 있는 반면, 저자들은 새로운 방법인 CORE를 제안하여 이러한 문제를 해결합니다. CORE는 강화 학습을 통해 사전 정의된 압축 레이블 없이도 문서 압축을 최적화하여 LLM의 응답 정확성을 극대화합니다. 네 개의 데이터셋에서 실험한 결과, CORE는 성능 저하 없이 평균 정확도 점수를 3.3점 향상시키며, 높은 압축률(3%)을 달성했습니다. 이 방법의 코드도 곧 공개될 예정입니다.

## 🎯 주요 포인트

- 1. Retrieval-Augmented Generation (RAG)은 대형 언어 모델(LLM)의 지식 최신성과 사실적 정확성을 향상시키는 유망한 접근법으로 부상하고 있다.

- 2. 기존 연구들은 문서 압축을 시도했으나, 고정된 휴리스틱에 의존하여 최종 작업 성능을 저하시킬 위험이 있었다.

- 3. CORE는 강화 학습을 활용하여 사전 정의된 압축 레이블 없이 압축 과정을 최적화하여 LLM의 답변 정확성을 극대화하는 요약을 생성한다.

- 4. CORE는 3%의 높은 압축 비율을 달성하면서도 성능 저하 없이 평균 정확 일치(EM) 점수를 3.3점 향상시켰다.

- 5. CORE의 우수성은 네 가지 데이터셋에 대한 광범위한 실험을 통해 입증되었으며, 코드가 곧 공개될 예정이다.

---

*Generated on 2025-09-22 14:59:17*