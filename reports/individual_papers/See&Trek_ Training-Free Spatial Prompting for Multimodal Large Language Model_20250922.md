# See&Trek: Training-Free Spatial Prompting for Multimodal Large Language Model

**Korean Title:** See&Trek: ë©€í‹°ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì„ ìœ„í•œ í›ˆë ¨ì´ í•„ìš” ì—†ëŠ” ê³µê°„ì  í”„ë¡¬í”„íŒ…

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Training Free Prompting

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Unleashing the Potential of Multimodal LLMs for Zero-Shot Spatio-Temporal Video Grounding_20250919|Unleashing the Potential of Multimodal LLMs for Zero-Shot Spatio-Temporal Video Grounding]] (83.0% similar)
- [[2025-09-22/SmolRGPT_ Efficient Spatial Reasoning for Warehouse Environments with 600M Parameters_20250922|SmolRGPT Efficient Spatial Reasoning for Warehouse Environments with 600M Parameters]] (82.7% similar)
- [[2025-09-17/ST-LINK_ Spatially-Aware Large Language Models for Spatio-Temporal Forecasting_20250917|ST-LINK Spatially-Aware Large Language Models for Spatio-Temporal Forecasting]] (82.6% similar)
- [[2025-09-18/VSE-MOT_ Multi-Object Tracking in Low-Quality Video Scenes Guided by Visual Semantic Enhancement_20250918|VSE-MOT Multi-Object Tracking in Low-Quality Video Scenes Guided by Visual Semantic Enhancement]] (82.1% similar)
- [[2025-09-19/V-SEAM_ Visual Semantic Editing and Attention Modulating for Causal Interpretability of Vision-Language Models_20250919|V-SEAM Visual Semantic Editing and Attention Modulating for Causal Interpretability of Vision-Language Models]] (81.1% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16087v1 Announce Type: cross 
Abstract: We introduce SEE&amp;TREK, the first training-free prompting framework tailored to enhance the spatial understanding of Multimodal Large Language Models (MLLMS) under vision-only constraints. While prior efforts have incorporated modalities like depth or point clouds to improve spatial reasoning, purely visualspatial understanding remains underexplored. SEE&amp;TREK addresses this gap by focusing on two core principles: increasing visual diversity and motion reconstruction. For visual diversity, we conduct Maximum Semantic Richness Sampling, which employs an off-the-shell perception model to extract semantically rich keyframes that capture scene structure. For motion reconstruction, we simulate visual trajectories and encode relative spatial positions into keyframes to preserve both spatial relations and temporal coherence. Our method is training&amp;GPU-free, requiring only a single forward pass, and can be seamlessly integrated into existing MLLM'S. Extensive experiments on the VSI-B ENCH and STI-B ENCH show that S EE &amp;T REK consistently boosts various MLLM S performance across diverse spatial reasoning tasks with the most +3.5% improvement, offering a promising path toward stronger spatial intelligence.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.16087v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ìš°ë¦¬ëŠ” ì‹œê°ì  ì œì•½ ì¡°ê±´ í•˜ì—ì„œ ë‹¤ì¤‘ ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(Multimodal Large Language Models, MLLMs)ì˜ ê³µê°„ ì´í•´ë¥¼ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ì„¤ê³„ëœ ìµœì´ˆì˜ í›ˆë ¨ ë¶ˆí•„ìš” í”„ë¡¬í”„íŠ¸ í”„ë ˆì„ì›Œí¬ì¸ SEE&TREKì„ ì†Œê°œí•©ë‹ˆë‹¤. ì´ì „ì˜ ì—°êµ¬ë“¤ì€ ê¹Šì´(depth)ë‚˜ í¬ì¸íŠ¸ í´ë¼ìš°ë“œì™€ ê°™ì€ ëª¨ë‹¬ë¦¬í‹°ë¥¼ í¬í•¨í•˜ì—¬ ê³µê°„ ì¶”ë¡ ì„ ê°œì„ í•˜ë ¤ê³  í–ˆìœ¼ë‚˜, ìˆœìˆ˜í•œ ì‹œê°ì  ê³µê°„ ì´í•´ëŠ” ì—¬ì „íˆ ì¶©ë¶„íˆ íƒêµ¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. SEE&TREKì€ ì‹œê°ì  ë‹¤ì–‘ì„± ì¦ê°€ì™€ ìš´ë™ ì¬êµ¬ì„±ì´ë¼ëŠ” ë‘ ê°€ì§€ í•µì‹¬ ì›ì¹™ì— ì´ˆì ì„ ë§ì¶”ì–´ ì´ ê²©ì°¨ë¥¼ í•´ì†Œí•©ë‹ˆë‹¤. ì‹œê°ì  ë‹¤ì–‘ì„±ì„ ìœ„í•´, ìš°ë¦¬ëŠ” ì¥ë©´ êµ¬ì¡°ë¥¼ í¬ì°©í•˜ëŠ” ì˜ë¯¸ì ìœ¼ë¡œ í’ë¶€í•œ í‚¤í”„ë ˆì„ì„ ì¶”ì¶œí•˜ê¸° ìœ„í•´ ì˜¤í”„ë”ì‰˜í”„ ì¸ì‹ ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ìµœëŒ€ ì˜ë¯¸ í’ë¶€ì„± ìƒ˜í”Œë§ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ìš´ë™ ì¬êµ¬ì„±ì„ ìœ„í•´, ìš°ë¦¬ëŠ” ì‹œê°ì  ê¶¤ì ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ê³  ìƒëŒ€ì  ê³µê°„ ìœ„ì¹˜ë¥¼ í‚¤í”„ë ˆì„ì— ì¸ì½”ë”©í•˜ì—¬ ê³µê°„ì  ê´€ê³„ì™€ ì‹œê°„ì  ì¼ê´€ì„±ì„ ëª¨ë‘ ìœ ì§€í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ë°©ë²•ì€ í›ˆë ¨ ë° GPUê°€ í•„ìš” ì—†ìœ¼ë©°, ë‹¨ì¼ ì „ë°© íŒ¨ìŠ¤ë§Œ ìš”êµ¬ë˜ë©° ê¸°ì¡´ì˜ MLLMì— ì›í™œí•˜ê²Œ í†µí•©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. VSI-BENCHì™€ STI-BENCHì— ëŒ€í•œ ê´‘ë²”ìœ„í•œ ì‹¤í—˜ ê²°ê³¼, SEE&TREKì´ ë‹¤ì–‘í•œ ê³µê°„ ì¶”ë¡  ì‘ì—…ì—ì„œ ì—¬ëŸ¬ MLLMì˜ ì„±ëŠ¥ì„ ì¼ê´€ë˜ê²Œ í–¥ìƒì‹œí‚¤ë©° ìµœëŒ€ 3.5%ì˜ ê°œì„ ì„ ë³´ì—¬ì£¼ì–´ ê°•ë ¥í•œ ê³µê°„ ì§€ëŠ¥ìœ¼ë¡œ ê°€ëŠ” ìœ ë§í•œ ê²½ë¡œë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

SEE&TREKì€ ì‹œê°ì  ì œì•½ í•˜ì—ì„œ ë‹¤ì¤‘ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(MLLM)ì˜ ê³µê°„ ì´í•´ë¥¼ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ìµœì´ˆì˜ í›ˆë ¨ ë¶ˆí•„ìš” í”„ë¡¬í”„íŒ… í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ê¸°ì¡´ ì—°êµ¬ë“¤ì´ ê¹Šì´ ì •ë³´ë‚˜ í¬ì¸íŠ¸ í´ë¼ìš°ë“œë¥¼ í™œìš©í•œ ê³µê°„ ì¶”ë¡ ì„ ì‹œë„í•œ ë°˜ë©´, ìˆœìˆ˜ ì‹œê°ì  ê³µê°„ ì´í•´ëŠ” ì¶©ë¶„íˆ íƒêµ¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. SEE&TREKì€ ì‹œê°ì  ë‹¤ì–‘ì„± ì¦ëŒ€ì™€ ìš´ë™ ì¬êµ¬ì„±ì´ë¼ëŠ” ë‘ ê°€ì§€ ì›ì¹™ì— ì¤‘ì ì„ ë‘¡ë‹ˆë‹¤. ì‹œê°ì  ë‹¤ì–‘ì„±ì„ ìœ„í•´, ìš°ë¦¬ëŠ” ì˜¤í”„ë”ì…¸ ì¸ì‹ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì¥ë©´ êµ¬ì¡°ë¥¼ í¬ì°©í•˜ëŠ” ì˜ë¯¸ì ìœ¼ë¡œ í’ë¶€í•œ í‚¤í”„ë ˆì„ì„ ì¶”ì¶œí•©ë‹ˆë‹¤. ìš´ë™ ì¬êµ¬ì„±ì„ ìœ„í•´, ì‹œê°ì  ê¶¤ì ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ê³  ìƒëŒ€ì  ê³µê°„ ìœ„ì¹˜ë¥¼ í‚¤í”„ë ˆì„ì— ì¸ì½”ë”©í•˜ì—¬ ê³µê°„ ê´€ê³„ì™€ ì‹œê°„ì  ì¼ê´€ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ í›ˆë ¨ ë° GPUê°€ í•„ìš” ì—†ìœ¼ë©°, ê¸°ì¡´ MLLMì— ì‰½ê²Œ í†µí•©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. VSI-BENCHì™€ STI-BENCHì—ì„œì˜ ê´‘ë²”ìœ„í•œ ì‹¤í—˜ ê²°ê³¼, SEE&TREKì€ ë‹¤ì–‘í•œ ê³µê°„ ì¶”ë¡  ì‘ì—…ì—ì„œ MLLMì˜ ì„±ëŠ¥ì„ ìµœëŒ€ 3.5% í–¥ìƒì‹œí‚µë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. SEE&TREKì€ ì‹œê°ì  ì œì•½ í•˜ì—ì„œ ë‹¤ì¤‘ ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ ê³µê°„ ì´í•´ë¥¼ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ìµœì´ˆì˜ í›ˆë ¨ ë¶ˆí•„ìš” í”„ë¡¬íŒ… í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.

- 2. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ì‹œê°ì  ë‹¤ì–‘ì„± ì¦ê°€ì™€ ìš´ë™ ì¬êµ¬ì„±ì´ë¼ëŠ” ë‘ ê°€ì§€ í•µì‹¬ ì›ì¹™ì— ì¤‘ì ì„ ë‘¡ë‹ˆë‹¤.

- 3. ì‹œê°ì  ë‹¤ì–‘ì„±ì„ ìœ„í•´, ìµœëŒ€ ì˜ë¯¸ì  í’ë¶€ì„± ìƒ˜í”Œë§ì„ í†µí•´ ì¥ë©´ êµ¬ì¡°ë¥¼ í¬ì°©í•˜ëŠ” ì˜ë¯¸ì ìœ¼ë¡œ í’ë¶€í•œ í‚¤í”„ë ˆì„ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.

- 4. ìš´ë™ ì¬êµ¬ì„±ì„ ìœ„í•´, ì‹œê°ì  ê¶¤ì ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ê³  í‚¤í”„ë ˆì„ì— ìƒëŒ€ì  ê³µê°„ ìœ„ì¹˜ë¥¼ ì¸ì½”ë”©í•˜ì—¬ ê³µê°„ ê´€ê³„ì™€ ì‹œê°„ì  ì¼ê´€ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤.

- 5. SEE&TREKì€ í›ˆë ¨ê³¼ GPUê°€ í•„ìš” ì—†ìœ¼ë©°, ë‹¤ì–‘í•œ ê³µê°„ ì¶”ë¡  ì‘ì—…ì—ì„œ ì„±ëŠ¥ì„ +3.5%ê¹Œì§€ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

---

*Generated on 2025-09-22 14:24:24*