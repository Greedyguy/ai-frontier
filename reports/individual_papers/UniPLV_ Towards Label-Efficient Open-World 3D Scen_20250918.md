
# UniPLV: Towards Label-Efficient Open-World 3D Scene Understanding by Regional Visual Language Supervision

**Korean Title:** UniPLV: μ§€μ—­ μ‹κ° μ–Έμ–΄ κ°λ…μ— μν• λ μ΄λΈ” ν¨μ¨μ μΈ μ¤ν” μ›”λ“ 3D μ¥λ©΄ μ΄ν•΄λ΅ ν–¥ν•λ©°

## π“‹ λ©”νƒ€λ°μ΄ν„°

**Links**: [[daily/2025-09-18|2025-09-18]] [[keywords/broad/3D Scene Understanding|3D Scene Understanding]] [[keywords/broad/Multimodal Alignment|Multimodal Alignment]] [[keywords/specific/Point Clouds|Point Clouds]] [[keywords/specific/Shared Feature Space|Shared Feature Space]] [[keywords/unique/UniPLV|UniPLV]] [[categories/cs.CV|cs.CV]]

## π·οΈ μΉ΄ν…κ³ λ¦¬ν™”λ ν‚¤μ›λ“
**π”¬ Broad Technical**: 3D Scene Understanding, Multimodal Alignment
**π”— Specific Connectable**: Point Clouds, Shared Feature Space
**β­ Unique Technical**: UniPLV

**ArXiv ID**: [2412.18131](https://arxiv.org/abs/2412.18131)
**Published**: 2025-09-18
**Category**: cs.CV
**PDF**: [Download](https://arxiv.org/pdf/2412.18131.pdf)


## π·οΈ μ¶”μ¶λ ν‚¤μ›λ“



`3D Scene Understanding` β€Ά 

`Multimodal Alignment` β€Ά 

`Logit and feature distillation modules` β€Ά 

`UniPLV` β€Ά 

`Annotation-Free tasks`



## π“‹ μ €μ μ •λ³΄

**Authors:** 

## π“„ Abstract (μ›λ¬Έ)

arXiv:2412.18131v2 Announce Type: replace 
Abstract: Open-world 3D scene understanding is a critical challenge that involves recognizing and distinguishing diverse objects and categories from 3D data, such as point clouds, without relying on manual annotations. Traditional methods struggle with this open-world task, especially due to the limitations of constructing extensive point cloud-text pairs and handling multimodal data effectively. In response to these challenges, we present UniPLV, a robust framework that unifies point clouds, images, and text within a single learning paradigm for comprehensive 3D scene understanding. UniPLV leverages images as a bridge to co-embed 3D points with pre-aligned images and text in a shared feature space, eliminating the need for labor-intensive point cloud-text pair crafting. Our framework achieves precise multimodal alignment through two innovative strategies: (i) Logit and feature distillation modules between images and point clouds to enhance feature coherence; (ii) A vision-point matching module that implicitly corrects 3D semantic predictions affected by projection inaccuracies from points to pixels. To further boost performance, we implement four task-specific losses alongside a two-stage training strategy. Extensive experiments demonstrate that UniPLV significantly surpasses state-of-the-art methods, with average improvements of 15.6% and 14.8% in semantic segmentation for Base-Annotated and Annotation-Free tasks, respectively. These results underscore UniPLV's efficacy in pushing the boundaries of open-world 3D scene understanding. We will release the code to support future research and development.

## π” Abstract (ν•κΈ€ λ²μ—­)

arXiv:2412.18131v2 λ°ν‘ μ ν•: λ€μ²΄
μ”μ•½: μ¤ν” μ›”λ“ 3D μ¥λ©΄ μ΄ν•΄λ” ν¬μΈνΈ ν΄λΌμ°λ“μ™€ κ°™μ€ 3D λ°μ΄ν„°μ—μ„ λ‹¤μ–‘ν• κ°μ²΄μ™€ λ²”μ£Όλ¥Ό μΈμ‹ν•κ³  κµ¬λ³„ν•λ” μ¤‘μ”ν• κ³Όμ μ΄λ©° μλ™ μ£Όμ„μ— μμ΅΄ν•μ§€ μ•μµλ‹λ‹¤. μ „ν†µμ μΈ λ°©λ²•μ€ νΉν κ΄‘λ²”μ„ν• ν¬μΈνΈ ν΄λΌμ°λ“-ν…μ¤νΈ μμ„ κµ¬μ„±ν•κ³  λ‹¤μ¤‘ λ¨λ‹¬ λ°μ΄ν„°λ¥Ό ν¨κ³Όμ μΌλ΅ μ²λ¦¬ν•λ” μ ν•μΌλ΅ μΈν•΄μ΄ μ¤ν” μ›”λ“ μ‘μ—…μ— μ–΄λ ¤μ›€μ„ κ²μµλ‹λ‹¤. μ΄λ¬ν• λ„μ „μ— λ€μ‘ν•μ—¬ μ°λ¦¬λ” ν¬κ΄„μ μΈ 3D μ¥λ©΄ μ΄ν•΄λ¥Ό μ„ν•΄ ν¬μΈνΈ ν΄λΌμ°λ“, μ΄λ―Έμ§€ λ° ν…μ¤νΈλ¥Ό ν•λ‚μ ν•™μµ ν¨λ¬λ‹¤μ„μ—μ„ ν†µν•©ν•λ” κ°•λ ¥ν• ν”„λ μ„μ›ν¬ μΈ UniPLVλ¥Ό μ μ‹ν•©λ‹λ‹¤. UniPLVλ” μ΄λ―Έμ§€λ¥Ό μ‚¬μ©ν•μ—¬ 3D ν¬μΈνΈλ¥Ό μ‚¬μ „ μ •λ ¬λ μ΄λ―Έμ§€ λ° ν…μ¤νΈμ™€ ν•¨κ» κ³µμ λ νΉμ§• κ³µκ°„μ— λ™μ‹μ— μ„λ² λ“ν•λ” λ‹¤λ¦¬λ΅ ν™μ©ν•μ—¬ λ…Έλ™ μ§‘μ•½μ μΈ ν¬μΈνΈ ν΄λΌμ°λ“-ν…μ¤νΈ μ μ‘μ—…μ„ μ—†μ• μ¤λ‹λ‹¤. μ°λ¦¬μ ν”„λ μ„μ›ν¬λ” λ‘ κ°€μ§€ νμ‹ μ μΈ μ „λµμ„ ν†µν•΄ μ •ν™•ν• λ‹¤μ¤‘ λ¨λ‹¬ μ •λ ¬μ„ λ‹¬μ„±ν•©λ‹λ‹¤: (i) μ΄λ―Έμ§€μ™€ ν¬μΈνΈ ν΄λΌμ°λ“ μ‚¬μ΄μ λ΅μ§“ λ° νΉμ§• μ¦λ¥ λ¨λ“μ„ ν†µν•΄ νΉμ§• μΌκ΄€μ„±μ„ ν–¥μƒμ‹ν‚µλ‹λ‹¤; (ii) ν¬μΈνΈμ—μ„ ν”½μ…€λ΅μ ν¬μ μ¤μ°¨μ— μν–¥μ„ λ°›λ” 3D μλ―Έλ΅ μ  μμΈ΅μ„ μ•”λ¬µμ μΌλ΅ μμ •ν•λ” λΉ„μ „-ν¬μΈνΈ λ§¤μΉ­ λ¨λ“. μ„±λ¥μ„ λ” ν–¥μƒμ‹ν‚¤κΈ° μ„ν•΄ μ°λ¦¬λ” λ‘ λ‹¨κ³„ ν•™μµ μ „λµκ³Ό ν•¨κ» λ„¤ κ°€μ§€ μ‘μ—…λ³„ μ†μ‹¤μ„ κµ¬ν„ν•©λ‹λ‹¤. κ΄‘λ²”μ„ν• μ‹¤ν— κ²°κ³Ό UniPLVκ°€ μµμ‹  κΈ°μ  λ°©λ²•μ„ ν¬κ² λ¥κ°€ν•λ©° Base-Annotated λ° Annotation-Free μ‘μ—…μ— λ€ν•΄ κ°κ° 15.6% λ° 14.8%μ ν‰κ·  ν–¥μƒμ„ λ‹¬μ„±ν•λ‹¤λ” κ²ƒμ„ λ³΄μ—¬μ¤λ‹λ‹¤. μ΄λ¬ν• κ²°κ³Όλ” UniPLVκ°€ μ¤ν” μ›”λ“ 3D μ¥λ©΄ μ΄ν•΄μ κ²½κ³„λ¥Ό λ„“νλ” λ° ν¨κ³Όμ μ„μ„ κ°•μ΅°ν•©λ‹λ‹¤. μ°λ¦¬λ” λ―Έλ μ—°κµ¬ λ° κ°λ°μ„ μ§€μ›ν•κΈ° μ„ν•΄ μ½”λ“λ¥Ό κ³µκ°ν•  κ²ƒμ…λ‹λ‹¤.

## π“ μ”μ•½

λ³Έ μ—°κµ¬λ” μ¤ν” μ›”λ“ 3D μ¥λ©΄ μ΄ν•΄λ¥Ό μ„ν• UniPLV ν”„λ μ„μ›ν¬λ¥Ό μ μ•ν•λ‹¤. UniPLVλ” μ΄λ―Έμ§€λ¥Ό ν†µν•΄ 3D ν¬μΈνΈμ™€ μ‚¬μ „ μ •λ ¬λ μ΄λ―Έμ§€ λ° ν…μ¤νΈλ¥Ό κ³µμ λ νΉμ§• κ³µκ°„μ— ν•¨κ» μ„λ² λ”©ν•μ—¬ labor-intensiveν• ν¬μΈνΈ ν΄λΌμ°λ“-ν…μ¤νΈ νμ–΄ μ‘μ—…μ„ μ—†μ• κ³  μ •ν™•ν• λ©€ν‹°λ¨λ‹¬ μ •λ ¬μ„ λ‹¬μ„±ν•λ‹¤. μ΄λ¥Ό μ„ν•΄ μ΄λ―Έμ§€μ™€ ν¬μΈνΈ ν΄λΌμ°λ“ κ°„μ Logit λ° ν”Όμ² λ””μ¤ν‹Έλ μ΄μ… λ¨λ“, κ·Έλ¦¬κ³  λΉ„μ „-ν¬μΈνΈ λ§¤μΉ­ λ¨λ“μ„ ν†µν•΄ μ„Έλ¶„ν™”λ νΉμ§•μ„ ν–¥μƒμ‹ν‚¤κ³  3D μ‹λ§¨ν‹± μμΈ΅μ„ λ³΄μ •ν•λ‹¤. μ‹¤ν— κ²°κ³Όλ” UniPLVκ°€ μ¤ν” μ›”λ“ 3D μ¥λ©΄ μ΄ν•΄ λ¶„μ•Όμ—μ„ μµμ²¨λ‹¨ λ°©λ²•λ“¤μ„ ν¬κ² λ¥κ°€ν•¨μ„ λ³΄μ—¬μ¤€λ‹¤.

## π― μ£Όμ” ν¬μΈνΈ


- 1. 3D μ¥λ©΄ μ΄ν•΄λ¥Ό μ„ν• UniPLV ν”„λ μ„μ›ν¬ μ†κ°

- 2. μ΄λ―Έμ§€λ¥Ό ν™μ©ν• 3D ν¬μΈνΈ λ° ν…μ¤νΈ ν†µν•© ν•™μµ

- 3. λ‹¤μ¤‘ λ¨λ‹¬ λ°μ΄ν„° μ²λ¦¬λ¥Ό μ„ν• νμ‹ μ μΈ μ „λµ μ μ©

- 4. Base-Annotated λ° Annotation-Free μ‘μ—…μ—μ„ μ„±λ¥ ν–¥μƒμ„ λ³΄μ—¬μ¤

- 5. λ―Έλ μ—°κµ¬ λ° κ°λ°μ„ μ§€μ›ν•κΈ° μ„ν•΄ μ½”λ“ κ³µκ°ν•  μμ •


---

*Generated on 2025-09-18 17:06:08*