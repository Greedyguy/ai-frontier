---
keywords:
  - LEO-MINI
  - Conditional Token Reduction
  - Mixture of Multi-Modal Experts
  - Multimodal Learning
  - Vision-Language Model
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2504.04653
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T04:15:34.686369",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "LEO-MINI",
    "Conditional Token Reduction",
    "Mixture of Multi-Modal Experts",
    "Multimodal Learning",
    "Vision-Language Model"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "LEO-MINI": 0.85,
    "Conditional Token Reduction": 0.8,
    "Mixture of Multi-Modal Experts": 0.82,
    "Multimodal Learning": 0.78,
    "Vision-Language Model": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "LEO-MINI",
        "canonical": "LEO-MINI",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "LEO-MINI is a novel model introduced in the paper, representing a unique approach to multimodal language models.",
        "novelty_score": 0.95,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.85
      },
      {
        "surface": "Conditional Token Reduction",
        "canonical": "Conditional Token Reduction",
        "aliases": [
          "CoTR"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel token reduction technique specific to the paper, enhancing the model's efficiency.",
        "novelty_score": 0.88,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Mixture of Multi-Modal Experts",
        "canonical": "Mixture of Multi-Modal Experts",
        "aliases": [
          "MMoE"
        ],
        "category": "unique_technical",
        "rationale": "MMoE is a key component of LEO-MINI, crucial for understanding its multimodal capabilities.",
        "novelty_score": 0.87,
        "connectivity_score": 0.7,
        "specificity_score": 0.88,
        "link_intent_score": 0.82
      },
      {
        "surface": "Multimodal",
        "canonical": "Multimodal Learning",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Multimodal learning is central to the paper's theme and connects with other multimodal research.",
        "novelty_score": 0.4,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.78
      },
      {
        "surface": "Vision-Language",
        "canonical": "Vision-Language Model",
        "aliases": [],
        "category": "evolved_concepts",
        "rationale": "Vision-Language models are an evolved concept that directly relates to the paper's focus on vision-language tasks.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.75,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "efficiency"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "LEO-MINI",
      "resolved_canonical": "LEO-MINI",
      "decision": "linked",
      "scores": {
        "novelty": 0.95,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Conditional Token Reduction",
      "resolved_canonical": "Conditional Token Reduction",
      "decision": "linked",
      "scores": {
        "novelty": 0.88,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Mixture of Multi-Modal Experts",
      "resolved_canonical": "Mixture of Multi-Modal Experts",
      "decision": "linked",
      "scores": {
        "novelty": 0.87,
        "connectivity": 0.7,
        "specificity": 0.88,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Multimodal",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Vision-Language",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.75,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# LEO-MINI: An Efficient Multimodal Large Language Model using Conditional Token Reduction and Mixture of Multi-Modal Experts

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2504.04653.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2504.04653](https://arxiv.org/abs/2504.04653)

## 🔗 유사한 논문
- [[2025-09-22/Perception-R1_ Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward_20250922|Perception-R1: Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward]] (86.7% similar)
- [[2025-09-23/L-MTP_ Leap Multi-Token Prediction Beyond Adjacent Context for Large Language Models_20250923|L-MTP: Leap Multi-Token Prediction Beyond Adjacent Context for Large Language Models]] (86.5% similar)
- [[2025-09-19/Modular Machine Learning_ An Indispensable Path towards New-Generation Large Language Models_20250919|Modular Machine Learning: An Indispensable Path towards New-Generation Large Language Models]] (86.1% similar)
- [[2025-09-23/ProReason_ Multi-Modal Proactive Reasoning with Decoupled Eyesight and Wisdom_20250923|ProReason: Multi-Modal Proactive Reasoning with Decoupled Eyesight and Wisdom]] (86.0% similar)
- [[2025-09-22/Beyond Spurious Signals_ Debiasing Multimodal Large Language Models via Counterfactual Inference and Adaptive Expert Routing_20250922|Beyond Spurious Signals: Debiasing Multimodal Large Language Models via Counterfactual Inference and Adaptive Expert Routing]] (85.9% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**⚡ Unique Technical**: [[keywords/LEO-MINI|LEO-MINI]], [[keywords/Conditional Token Reduction|Conditional Token Reduction]], [[keywords/Mixture of Multi-Modal Experts|Mixture of Multi-Modal Experts]]
**🚀 Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2504.04653v2 Announce Type: replace-cross 
Abstract: Redundancy of visual tokens in multi-modal large language models (MLLMs) significantly reduces their computational efficiency. Recent approaches, such as resamplers and summarizers, have sought to reduce the number of visual tokens, but at the cost of visual reasoning ability. To address this, we propose LEO-MINI, a novel MLLM that significantly reduces the number of visual tokens and simultaneously boosts visual reasoning capabilities. For efficiency, LEO-MINI incorporates CoTR, a novel token reduction module to consolidate a large number of visual tokens into a smaller set of tokens, using the similarity between visual tokens, text tokens, and a compact learnable query. For effectiveness, to scale up the model's ability with minimal computational overhead, LEO-MINI employs MMoE, a novel mixture of multi-modal experts module. MMOE employs a set of LoRA experts with a novel router to switch between them based on the input text and visual tokens instead of only using the input hidden state. MMoE also includes a general LoRA expert that is always activated to learn general knowledge for LLM reasoning. For extracting richer visual features, MMOE employs a set of vision experts trained on diverse domain-specific data. To demonstrate LEO-MINI's improved efficiency and performance, we evaluate it against existing efficient MLLMs on various benchmark vision-language tasks.

## 📝 요약

LEO-MINI는 다중 모달 대형 언어 모델(MLLM)에서 시각적 토큰의 중복 문제를 해결하여 계산 효율성을 높이는 새로운 접근법입니다. 기존 방법들은 시각적 추론 능력을 희생하면서 토큰 수를 줄였으나, LEO-MINI는 CoTR 모듈을 사용하여 시각적 토큰을 유사성에 기반해 압축하고, MMoE 모듈을 통해 최소한의 계산 비용으로 모델의 능력을 확장합니다. MMoE는 입력 텍스트와 시각적 토큰에 따라 LoRA 전문가를 전환하며, 일반적인 지식을 학습하는 전문가도 포함합니다. 다양한 도메인 데이터로 훈련된 비전 전문가를 활용하여 풍부한 시각적 특징을 추출합니다. LEO-MINI는 여러 벤치마크 과제를 통해 기존 MLLM과 비교하여 향상된 효율성과 성능을 입증합니다.

## 🎯 주요 포인트

- 1. LEO-MINI는 시각 토큰의 수를 크게 줄이면서 시각 추론 능력을 향상시키는 새로운 다중 모달 대형 언어 모델입니다.
- 2. CoTR 모듈은 시각 토큰, 텍스트 토큰, 학습 가능한 쿼리 간의 유사성을 활용하여 많은 시각 토큰을 소수의 토큰으로 통합합니다.
- 3. MMoE 모듈은 입력 텍스트와 시각 토큰에 따라 LoRA 전문가 세트를 전환하는 새로운 라우터를 사용하여 모델의 능력을 최소한의 계산 오버헤드로 확장합니다.
- 4. MMoE는 다양한 도메인별 데이터로 훈련된 비전 전문가 세트를 사용하여 더 풍부한 시각적 특징을 추출합니다.
- 5. LEO-MINI는 다양한 벤치마크 비전-언어 작업에서 기존의 효율적인 MLLM과 비교하여 향상된 효율성과 성능을 입증합니다.


---

*Generated on 2025-09-24 04:15:34*