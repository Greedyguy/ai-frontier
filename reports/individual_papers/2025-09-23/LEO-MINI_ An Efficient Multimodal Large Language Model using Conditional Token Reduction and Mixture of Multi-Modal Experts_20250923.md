---
keywords:
  - LEO-MINI
  - Conditional Token Reduction
  - Mixture of Multi-Modal Experts
  - Multimodal Learning
  - Vision-Language Model
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2504.04653
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T04:15:34.686369",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "LEO-MINI",
    "Conditional Token Reduction",
    "Mixture of Multi-Modal Experts",
    "Multimodal Learning",
    "Vision-Language Model"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "LEO-MINI": 0.85,
    "Conditional Token Reduction": 0.8,
    "Mixture of Multi-Modal Experts": 0.82,
    "Multimodal Learning": 0.78,
    "Vision-Language Model": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "LEO-MINI",
        "canonical": "LEO-MINI",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "LEO-MINI is a novel model introduced in the paper, representing a unique approach to multimodal language models.",
        "novelty_score": 0.95,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.85
      },
      {
        "surface": "Conditional Token Reduction",
        "canonical": "Conditional Token Reduction",
        "aliases": [
          "CoTR"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel token reduction technique specific to the paper, enhancing the model's efficiency.",
        "novelty_score": 0.88,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Mixture of Multi-Modal Experts",
        "canonical": "Mixture of Multi-Modal Experts",
        "aliases": [
          "MMoE"
        ],
        "category": "unique_technical",
        "rationale": "MMoE is a key component of LEO-MINI, crucial for understanding its multimodal capabilities.",
        "novelty_score": 0.87,
        "connectivity_score": 0.7,
        "specificity_score": 0.88,
        "link_intent_score": 0.82
      },
      {
        "surface": "Multimodal",
        "canonical": "Multimodal Learning",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Multimodal learning is central to the paper's theme and connects with other multimodal research.",
        "novelty_score": 0.4,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.78
      },
      {
        "surface": "Vision-Language",
        "canonical": "Vision-Language Model",
        "aliases": [],
        "category": "evolved_concepts",
        "rationale": "Vision-Language models are an evolved concept that directly relates to the paper's focus on vision-language tasks.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.75,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "efficiency"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "LEO-MINI",
      "resolved_canonical": "LEO-MINI",
      "decision": "linked",
      "scores": {
        "novelty": 0.95,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Conditional Token Reduction",
      "resolved_canonical": "Conditional Token Reduction",
      "decision": "linked",
      "scores": {
        "novelty": 0.88,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Mixture of Multi-Modal Experts",
      "resolved_canonical": "Mixture of Multi-Modal Experts",
      "decision": "linked",
      "scores": {
        "novelty": 0.87,
        "connectivity": 0.7,
        "specificity": 0.88,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Multimodal",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Vision-Language",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.75,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# LEO-MINI: An Efficient Multimodal Large Language Model using Conditional Token Reduction and Mixture of Multi-Modal Experts

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2504.04653.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2504.04653](https://arxiv.org/abs/2504.04653)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Perception-R1_ Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward_20250922|Perception-R1: Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward]] (86.7% similar)
- [[2025-09-23/L-MTP_ Leap Multi-Token Prediction Beyond Adjacent Context for Large Language Models_20250923|L-MTP: Leap Multi-Token Prediction Beyond Adjacent Context for Large Language Models]] (86.5% similar)
- [[2025-09-19/Modular Machine Learning_ An Indispensable Path towards New-Generation Large Language Models_20250919|Modular Machine Learning: An Indispensable Path towards New-Generation Large Language Models]] (86.1% similar)
- [[2025-09-23/ProReason_ Multi-Modal Proactive Reasoning with Decoupled Eyesight and Wisdom_20250923|ProReason: Multi-Modal Proactive Reasoning with Decoupled Eyesight and Wisdom]] (86.0% similar)
- [[2025-09-22/Beyond Spurious Signals_ Debiasing Multimodal Large Language Models via Counterfactual Inference and Adaptive Expert Routing_20250922|Beyond Spurious Signals: Debiasing Multimodal Large Language Models via Counterfactual Inference and Adaptive Expert Routing]] (85.9% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**âš¡ Unique Technical**: [[keywords/LEO-MINI|LEO-MINI]], [[keywords/Conditional Token Reduction|Conditional Token Reduction]], [[keywords/Mixture of Multi-Modal Experts|Mixture of Multi-Modal Experts]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2504.04653v2 Announce Type: replace-cross 
Abstract: Redundancy of visual tokens in multi-modal large language models (MLLMs) significantly reduces their computational efficiency. Recent approaches, such as resamplers and summarizers, have sought to reduce the number of visual tokens, but at the cost of visual reasoning ability. To address this, we propose LEO-MINI, a novel MLLM that significantly reduces the number of visual tokens and simultaneously boosts visual reasoning capabilities. For efficiency, LEO-MINI incorporates CoTR, a novel token reduction module to consolidate a large number of visual tokens into a smaller set of tokens, using the similarity between visual tokens, text tokens, and a compact learnable query. For effectiveness, to scale up the model's ability with minimal computational overhead, LEO-MINI employs MMoE, a novel mixture of multi-modal experts module. MMOE employs a set of LoRA experts with a novel router to switch between them based on the input text and visual tokens instead of only using the input hidden state. MMoE also includes a general LoRA expert that is always activated to learn general knowledge for LLM reasoning. For extracting richer visual features, MMOE employs a set of vision experts trained on diverse domain-specific data. To demonstrate LEO-MINI's improved efficiency and performance, we evaluate it against existing efficient MLLMs on various benchmark vision-language tasks.

## ğŸ“ ìš”ì•½

LEO-MINIëŠ” ë‹¤ì¤‘ ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(MLLM)ì—ì„œ ì‹œê°ì  í† í°ì˜ ì¤‘ë³µ ë¬¸ì œë¥¼ í•´ê²°í•˜ì—¬ ê³„ì‚° íš¨ìœ¨ì„±ì„ ë†’ì´ëŠ” ìƒˆë¡œìš´ ì ‘ê·¼ë²•ì…ë‹ˆë‹¤. ê¸°ì¡´ ë°©ë²•ë“¤ì€ ì‹œê°ì  ì¶”ë¡  ëŠ¥ë ¥ì„ í¬ìƒí•˜ë©´ì„œ í† í° ìˆ˜ë¥¼ ì¤„ì˜€ìœ¼ë‚˜, LEO-MINIëŠ” CoTR ëª¨ë“ˆì„ ì‚¬ìš©í•˜ì—¬ ì‹œê°ì  í† í°ì„ ìœ ì‚¬ì„±ì— ê¸°ë°˜í•´ ì••ì¶•í•˜ê³ , MMoE ëª¨ë“ˆì„ í†µí•´ ìµœì†Œí•œì˜ ê³„ì‚° ë¹„ìš©ìœ¼ë¡œ ëª¨ë¸ì˜ ëŠ¥ë ¥ì„ í™•ì¥í•©ë‹ˆë‹¤. MMoEëŠ” ì…ë ¥ í…ìŠ¤íŠ¸ì™€ ì‹œê°ì  í† í°ì— ë”°ë¼ LoRA ì „ë¬¸ê°€ë¥¼ ì „í™˜í•˜ë©°, ì¼ë°˜ì ì¸ ì§€ì‹ì„ í•™ìŠµí•˜ëŠ” ì „ë¬¸ê°€ë„ í¬í•¨í•©ë‹ˆë‹¤. ë‹¤ì–‘í•œ ë„ë©”ì¸ ë°ì´í„°ë¡œ í›ˆë ¨ëœ ë¹„ì „ ì „ë¬¸ê°€ë¥¼ í™œìš©í•˜ì—¬ í’ë¶€í•œ ì‹œê°ì  íŠ¹ì§•ì„ ì¶”ì¶œí•©ë‹ˆë‹¤. LEO-MINIëŠ” ì—¬ëŸ¬ ë²¤ì¹˜ë§ˆí¬ ê³¼ì œë¥¼ í†µí•´ ê¸°ì¡´ MLLMê³¼ ë¹„êµí•˜ì—¬ í–¥ìƒëœ íš¨ìœ¨ì„±ê³¼ ì„±ëŠ¥ì„ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. LEO-MINIëŠ” ì‹œê° í† í°ì˜ ìˆ˜ë¥¼ í¬ê²Œ ì¤„ì´ë©´ì„œ ì‹œê° ì¶”ë¡  ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ìƒˆë¡œìš´ ë‹¤ì¤‘ ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤.
- 2. CoTR ëª¨ë“ˆì€ ì‹œê° í† í°, í…ìŠ¤íŠ¸ í† í°, í•™ìŠµ ê°€ëŠ¥í•œ ì¿¼ë¦¬ ê°„ì˜ ìœ ì‚¬ì„±ì„ í™œìš©í•˜ì—¬ ë§ì€ ì‹œê° í† í°ì„ ì†Œìˆ˜ì˜ í† í°ìœ¼ë¡œ í†µí•©í•©ë‹ˆë‹¤.
- 3. MMoE ëª¨ë“ˆì€ ì…ë ¥ í…ìŠ¤íŠ¸ì™€ ì‹œê° í† í°ì— ë”°ë¼ LoRA ì „ë¬¸ê°€ ì„¸íŠ¸ë¥¼ ì „í™˜í•˜ëŠ” ìƒˆë¡œìš´ ë¼ìš°í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ ëŠ¥ë ¥ì„ ìµœì†Œí•œì˜ ê³„ì‚° ì˜¤ë²„í—¤ë“œë¡œ í™•ì¥í•©ë‹ˆë‹¤.
- 4. MMoEëŠ” ë‹¤ì–‘í•œ ë„ë©”ì¸ë³„ ë°ì´í„°ë¡œ í›ˆë ¨ëœ ë¹„ì „ ì „ë¬¸ê°€ ì„¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë” í’ë¶€í•œ ì‹œê°ì  íŠ¹ì§•ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
- 5. LEO-MINIëŠ” ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ ë¹„ì „-ì–¸ì–´ ì‘ì—…ì—ì„œ ê¸°ì¡´ì˜ íš¨ìœ¨ì ì¸ MLLMê³¼ ë¹„êµí•˜ì—¬ í–¥ìƒëœ íš¨ìœ¨ì„±ê³¼ ì„±ëŠ¥ì„ ì…ì¦í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 04:15:34*