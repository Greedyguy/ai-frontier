---
keywords:
  - Vision-Language Model
  - Visual Fairness
  - Demographic Attributes
  - Zero-Shot Learning
  - Chain-of-Thought Strategy
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2406.17974
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:43:13.782039",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Vision-Language Model",
    "Visual Fairness",
    "Demographic Attributes",
    "Zero-Shot Learning",
    "Chain-of-Thought Strategy"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Vision-Language Model": 0.85,
    "Visual Fairness": 0.78,
    "Demographic Attributes": 0.7,
    "Zero-Shot Learning": 0.8,
    "Chain-of-Thought Strategy": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large vision-language models",
        "canonical": "Vision-Language Model",
        "aliases": [
          "LVLM",
          "Vision-Language Models"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-Language Models are central to the paper's focus on fairness across demographic attributes, making them a key concept for linking.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "visual fairness",
        "canonical": "Visual Fairness",
        "aliases": [
          "Fairness in Vision",
          "Demographic Fairness"
        ],
        "category": "unique_technical",
        "rationale": "This term is unique to the study's focus on fairness in visual models, offering a novel concept for linking.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "demographic attributes",
        "canonical": "Demographic Attributes",
        "aliases": [
          "Demographic Factors",
          "Demographic Characteristics"
        ],
        "category": "specific_connectable",
        "rationale": "Understanding demographic attributes is crucial for evaluating fairness, providing a strong link to related research.",
        "novelty_score": 0.5,
        "connectivity_score": 0.75,
        "specificity_score": 0.65,
        "link_intent_score": 0.7
      },
      {
        "surface": "zero-shot prompting",
        "canonical": "Zero-Shot Learning",
        "aliases": [
          "Zero-Shot Prompting"
        ],
        "category": "specific_connectable",
        "rationale": "Zero-Shot Learning is a trending concept that is directly applied in the study's evaluation framework.",
        "novelty_score": 0.55,
        "connectivity_score": 0.82,
        "specificity_score": 0.72,
        "link_intent_score": 0.8
      },
      {
        "surface": "Chain-of-thought strategy",
        "canonical": "Chain-of-Thought Strategy",
        "aliases": [
          "CoT Strategy",
          "Chain-of-Thought"
        ],
        "category": "unique_technical",
        "rationale": "This strategy is proposed as a novel method for fairness mitigation, offering a unique concept for linking.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.78,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "fairness evaluation",
      "performance disparities"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large vision-language models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "visual fairness",
      "resolved_canonical": "Visual Fairness",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "demographic attributes",
      "resolved_canonical": "Demographic Attributes",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.75,
        "specificity": 0.65,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "zero-shot prompting",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.82,
        "specificity": 0.72,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Chain-of-thought strategy",
      "resolved_canonical": "Chain-of-Thought Strategy",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.78,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Evaluating Fairness in Large Vision-Language Models Across Diverse Demographic Attributes and Prompts

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2406.17974.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2406.17974](https://arxiv.org/abs/2406.17974)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Datasets for Fairness in Language Models_ An In-Depth Survey_20250923|Datasets for Fairness in Language Models: An In-Depth Survey]] (87.9% similar)
- [[2025-09-23/Intrinsic Meets Extrinsic Fairness_ Assessing the Downstream Impact of Bias Mitigation in Large Language Models_20250923|Intrinsic Meets Extrinsic Fairness: Assessing the Downstream Impact of Bias Mitigation in Large Language Models]] (85.9% similar)
- [[2025-09-23/Auto-Search and Refinement_ An Automated Framework for Gender Bias Mitigation in Large Language Models_20250923|Auto-Search and Refinement: An Automated Framework for Gender Bias Mitigation in Large Language Models]] (84.9% similar)
- [[2025-09-23/Mitigating Hallucinations in Large Vision-Language Models via Entity-Centric Multimodal Preference Optimization_20250923|Mitigating Hallucinations in Large Vision-Language Models via Entity-Centric Multimodal Preference Optimization]] (83.7% similar)
- [[2025-09-22/REFER_ Mitigating Bias in Opinion Summarisation via Frequency Framed Prompting_20250922|REFER: Mitigating Bias in Opinion Summarisation via Frequency Framed Prompting]] (83.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Demographic Attributes|Demographic Attributes]], [[keywords/Zero-Shot Learning|Zero-Shot Learning]]
**âš¡ Unique Technical**: [[keywords/Visual Fairness|Visual Fairness]], [[keywords/Chain-of-Thought Strategy|Chain-of-Thought Strategy]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2406.17974v3 Announce Type: replace 
Abstract: Large vision-language models (LVLMs) have recently achieved significant progress, demonstrating strong capabilities in open-world visual understanding. However, it is not yet clear how LVLMs address demographic biases in real life, especially the disparities across attributes such as gender, skin tone, age and race. In this paper, We empirically investigate \emph{visual fairness} in several mainstream LVLMs by auditing their performance disparities across demographic attributes using public fairness benchmark datasets (e.g., FACET, UTKFace). Our fairness evaluation framework employs direct and single-choice question prompt on visual question-answering/classification tasks. Despite advancements in visual understanding, our zero-shot prompting results show that both open-source and closed-source LVLMs continue to exhibit fairness issues across different prompts and demographic groups. Furthermore, we propose a potential multi-modal Chain-of-thought (CoT) based strategy for unfairness mitigation, applicable to both open-source and closed-source LVLMs. This approach enhances transparency and offers a scalable solution for addressing fairness, providing a solid foundation for future research and practical efforts in unfairness mitigation. The dataset and code used in this study are publicly available at this GitHub Repository.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€ê·œëª¨ ë¹„ì „-ì–¸ì–´ ëª¨ë¸(LVLMs)ì˜ ì‹œê°ì  ê³µì •ì„±ì„ ì¡°ì‚¬í•©ë‹ˆë‹¤. ì—°êµ¬ëŠ” ì„±ë³„, í”¼ë¶€ìƒ‰, ì—°ë ¹, ì¸ì¢… ë“± ì¸êµ¬í†µê³„ì  ì†ì„±ì— ë”°ë¥¸ ì„±ëŠ¥ ì°¨ì´ë¥¼ ê³µì •ì„± ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹(FACET, UTKFace)ì„ ì‚¬ìš©í•´ í‰ê°€í•©ë‹ˆë‹¤. ê²°ê³¼ì ìœ¼ë¡œ, LVLMsëŠ” ì—¬ì „íˆ ê³µì •ì„± ë¬¸ì œë¥¼ ë³´ì´ë©°, ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë©€í‹°ëª¨ë‹¬ Chain-of-thought(CoT) ì „ëµì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ì ‘ê·¼ë²•ì€ íˆ¬ëª…ì„±ì„ ë†’ì´ê³  ê³µì •ì„± ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ í™•ì¥ ê°€ëŠ¥í•œ ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤. ì—°êµ¬ì— ì‚¬ìš©ëœ ë°ì´í„°ì…‹ê³¼ ì½”ë“œëŠ” GitHubì—ì„œ ê³µê°œë©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€ê·œëª¨ ë¹„ì „-ì–¸ì–´ ëª¨ë¸(LVLMs)ì€ ì‹œê°ì  ì´í•´ì—ì„œ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë‚˜, ì‹¤ì œ ìƒí™œì—ì„œì˜ ì¸êµ¬í†µê³„í•™ì  í¸í–¥ ë¬¸ì œëŠ” ì—¬ì „íˆ í•´ê²°ë˜ì§€ ì•Šì•˜ë‹¤.
- 2. ë³¸ ì—°êµ¬ëŠ” LVLMsì˜ ì¸êµ¬í†µê³„í•™ì  ì†ì„±(ì„±ë³„, í”¼ë¶€ìƒ‰, ë‚˜ì´, ì¸ì¢… ë“±)ì— ë”°ë¥¸ ì„±ëŠ¥ ì°¨ì´ë¥¼ ê³µì •ì„± ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì„ í†µí•´ ì‹¤ì¦ì ìœ¼ë¡œ ì¡°ì‚¬í•˜ì˜€ë‹¤.
- 3. ì‹¤í—˜ ê²°ê³¼, ì˜¤í”ˆì†ŒìŠ¤ ë° ë¹„ê³µê°œ LVLMs ëª¨ë‘ ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸ì™€ ì¸êµ¬í†µê³„í•™ì  ê·¸ë£¹ì—ì„œ ì—¬ì „íˆ ê³µì •ì„± ë¬¸ì œë¥¼ ë³´ì˜€ë‹¤.
- 4. ë¶ˆê³µì •ì„± ì™„í™”ë¥¼ ìœ„í•´ ë‹¤ì¤‘ ëª¨ë‹¬ ì²´ì¸ ì˜¤ë¸Œ ì˜íŠ¸(CoT) ê¸°ë°˜ ì „ëµì„ ì œì•ˆí•˜ì˜€ìœ¼ë©°, ì´ëŠ” íˆ¬ëª…ì„±ì„ ë†’ì´ê³  ê³µì •ì„± ë¬¸ì œ í•´ê²°ì— ëŒ€í•œ í™•ì¥ ê°€ëŠ¥í•œ ì†”ë£¨ì…˜ì„ ì œê³µí•œë‹¤.
- 5. ì—°êµ¬ì— ì‚¬ìš©ëœ ë°ì´í„°ì…‹ê³¼ ì½”ë“œëŠ” GitHub ì €ì¥ì†Œì—ì„œ ê³µê°œì ìœ¼ë¡œ ì œê³µëœë‹¤.


---

*Generated on 2025-09-24 03:43:13*