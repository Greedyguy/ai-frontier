---
keywords:
  - Speech-Aware Large Language Models
  - Group Relative Policy Optimization
  - Spoken Question Answering
  - Automatic Speech Translation
  - BLEU
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.16990
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T23:40:20.931624",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Speech-Aware Large Language Models",
    "Group Relative Policy Optimization",
    "Spoken Question Answering",
    "Automatic Speech Translation",
    "BLEU"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Speech-Aware Large Language Models": 0.78,
    "Group Relative Policy Optimization": 0.8,
    "Spoken Question Answering": 0.75,
    "Automatic Speech Translation": 0.77,
    "BLEU": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Speech-Aware Large Language Models",
        "canonical": "Speech-Aware Large Language Models",
        "aliases": [
          "SALLMs"
        ],
        "category": "unique_technical",
        "rationale": "This represents a specialized application of language models in speech understanding, offering unique insights into model training and optimization.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.78
      },
      {
        "surface": "Group Relative Policy Optimization",
        "canonical": "Group Relative Policy Optimization",
        "aliases": [
          "GRPO"
        ],
        "category": "unique_technical",
        "rationale": "GRPO is a novel optimization technique that enhances model training efficiency, relevant for linking to optimization strategies.",
        "novelty_score": 0.88,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Spoken Question Answering",
        "canonical": "Spoken Question Answering",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "This task is a specific application of language models in speech, relevant for connecting to similar tasks in NLP.",
        "novelty_score": 0.65,
        "connectivity_score": 0.78,
        "specificity_score": 0.72,
        "link_intent_score": 0.75
      },
      {
        "surface": "Automatic Speech Translation",
        "canonical": "Automatic Speech Translation",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "This task bridges speech and language processing, facilitating connections to translation and speech technologies.",
        "novelty_score": 0.6,
        "connectivity_score": 0.8,
        "specificity_score": 0.7,
        "link_intent_score": 0.77
      },
      {
        "surface": "BLEU",
        "canonical": "BLEU",
        "aliases": [
          "Bilingual Evaluation Understudy"
        ],
        "category": "specific_connectable",
        "rationale": "BLEU is a widely used metric for evaluating translation tasks, relevant for linking to evaluation methodologies.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.65,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "method",
      "task",
      "model",
      "approach",
      "research"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Speech-Aware Large Language Models",
      "resolved_canonical": "Speech-Aware Large Language Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Group Relative Policy Optimization",
      "resolved_canonical": "Group Relative Policy Optimization",
      "decision": "linked",
      "scores": {
        "novelty": 0.88,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Spoken Question Answering",
      "resolved_canonical": "Spoken Question Answering",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.78,
        "specificity": 0.72,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Automatic Speech Translation",
      "resolved_canonical": "Automatic Speech Translation",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.8,
        "specificity": 0.7,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "BLEU",
      "resolved_canonical": "BLEU",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.65,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# Advancing Speech Understanding in Speech-Aware Language Models with GRPO

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16990.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.16990](https://arxiv.org/abs/2509.16990)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/GPO_ Learning from Critical Steps to Improve LLM Reasoning_20250923|GPO: Learning from Critical Steps to Improve LLM Reasoning]] (82.9% similar)
- [[2025-09-22/Exploring Fine-Tuning of Large Audio Language Models for Spoken Language Understanding under Limited Speech data_20250922|Exploring Fine-Tuning of Large Audio Language Models for Spoken Language Understanding under Limited Speech data]] (81.7% similar)
- [[2025-09-22/Session-Level Spoken Language Assessment with a Multimodal Foundation Model via Multi-Target Learning_20250922|Session-Level Spoken Language Assessment with a Multimodal Foundation Model via Multi-Target Learning]] (80.9% similar)
- [[2025-09-22/A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages_20250922|A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages]] (80.6% similar)
- [[2025-09-19/Select to Know_ An Internal-External Knowledge Self-Selection Framework for Domain-Specific Question Answering_20250919|Select to Know: An Internal-External Knowledge Self-Selection Framework for Domain-Specific Question Answering]] (80.4% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Spoken Question Answering|Spoken Question Answering]], [[keywords/Automatic Speech Translation|Automatic Speech Translation]], [[keywords/BLEU|BLEU]]
**âš¡ Unique Technical**: [[keywords/Speech-Aware Large Language Models|Speech-Aware Large Language Models]], [[keywords/Group Relative Policy Optimization|Group Relative Policy Optimization]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16990v1 Announce Type: cross 
Abstract: In this paper, we introduce a Group Relative Policy Optimization (GRPO)-based method for training Speech-Aware Large Language Models (SALLMs) on open-format speech understanding tasks, such as Spoken Question Answering and Automatic Speech Translation. SALLMs have proven highly effective for speech understanding tasks. GRPO has recently gained traction for its efficiency in training LLMs, and prior work has explored its application to SALLMs, primarily in multiple-choice tasks. Building on this, we focus on open-format tasks that better reflect the generative abilities of the models. Our approach leverages GRPO with BLEU as the reward signal to optimize SALLMs, and we demonstrate empirically that it surpasses standard SFT across several key metrics. Finally, we explore the potential of incorporating off-policy samples within GRPO for these tasks, highlighting avenues for further improvement and further research.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì—ì„œëŠ” ìŒì„± ì¸ì‹ ì‘ì—…ì„ ìœ„í•œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(SALLMs)ì„ í›ˆë ¨í•˜ê¸° ìœ„í•´ GRPO(Group Relative Policy Optimization) ê¸°ë°˜ ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. GRPOëŠ” LLMs í›ˆë ¨ì˜ íš¨ìœ¨ì„±ìœ¼ë¡œ ì£¼ëª©ë°›ê³  ìˆìœ¼ë©°, ê¸°ì¡´ ì—°êµ¬ì—ì„œëŠ” ì£¼ë¡œ ì„ íƒí˜• ê³¼ì œì— ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ëŠ” ìƒì„± ëŠ¥ë ¥ì„ ì˜ ë°˜ì˜í•˜ëŠ” ê°œë°©í˜• ê³¼ì œì— ì´ˆì ì„ ë§ì¶”ì–´ GRPOì™€ BLEUë¥¼ ë³´ìƒ ì‹ í˜¸ë¡œ í™œìš©í•˜ì—¬ SALLMsë¥¼ ìµœì í™”í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì´ ì—¬ëŸ¬ ì£¼ìš” ì§€í‘œì—ì„œ ê¸°ì¡´ SFTë¥¼ ëŠ¥ê°€í•¨ì„ ì…ì¦í•˜ì˜€ìœ¼ë©°, GRPO ë‚´ ì˜¤í”„ ì •ì±… ìƒ˜í”Œì˜ ì ì¬ë ¥ì„ íƒêµ¬í•˜ì—¬ ì¶”ê°€ ì—°êµ¬ ê°€ëŠ¥ì„±ì„ ì œì‹œí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” GRPO ê¸°ë°˜ ë°©ë²•ì„ ì‚¬ìš©í•˜ì—¬ SALLMsë¥¼ ê°œë°©í˜• ìŒì„± ì´í•´ ì‘ì—…ì— í›ˆë ¨ì‹œí‚¤ëŠ” ë°©ë²•ì„ ì†Œê°œí•©ë‹ˆë‹¤.
- 2. SALLMsëŠ” ìŒì„± ì´í•´ ì‘ì—…ì—ì„œ ë†’ì€ íš¨ê³¼ë¥¼ ë°œíœ˜í•˜ë©°, GRPOëŠ” LLMs í›ˆë ¨ì˜ íš¨ìœ¨ì„±ìœ¼ë¡œ ì£¼ëª©ë°›ê³  ìˆìŠµë‹ˆë‹¤.
- 3. ë³¸ ì—°êµ¬ëŠ” BLEUë¥¼ ë³´ìƒ ì‹ í˜¸ë¡œ í™œìš©í•˜ì—¬ SALLMsë¥¼ ìµœì í™”í•˜ë©°, í‘œì¤€ SFTë¥¼ ì—¬ëŸ¬ ì£¼ìš” ì§€í‘œì—ì„œ ëŠ¥ê°€í•¨ì„ ì‹¤ì¦ì ìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.
- 4. GRPO ë‚´ì—ì„œ ì˜¤í”„-ì •ì±… ìƒ˜í”Œì„ í†µí•©í•˜ëŠ” ê°€ëŠ¥ì„±ì„ íƒêµ¬í•˜ì—¬ ì¶”ê°€ì ì¸ ê°œì„  ë° ì—°êµ¬ì˜ ê°€ëŠ¥ì„±ì„ ì œì‹œí•©ë‹ˆë‹¤.


---

*Generated on 2025-09-23 23:40:20*