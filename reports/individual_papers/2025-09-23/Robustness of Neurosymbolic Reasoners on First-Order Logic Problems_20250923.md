---
keywords:
  - Large Language Model
  - Neurosymbolic Reasoning
  - First-Order Logic
  - Counterfactual Variants
  - Chain-of-Thought Prompting
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2509.17377
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:23:40.458192",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Neurosymbolic Reasoning",
    "First-Order Logic",
    "Counterfactual Variants",
    "Chain-of-Thought Prompting"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Neurosymbolic Reasoning": 0.8,
    "First-Order Logic": 0.82,
    "Counterfactual Variants": 0.78,
    "Chain-of-Thought Prompting": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Large Language Model"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's discussion on reasoning capabilities and robustness.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Neurosymbolic Reasoning",
        "canonical": "Neurosymbolic Reasoning",
        "aliases": [
          "NS Reasoning",
          "Neurosymbolic"
        ],
        "category": "unique_technical",
        "rationale": "Key focus of the paper, offering a novel approach to integrate symbolic and neural methods.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "First-Order Logic",
        "canonical": "First-Order Logic",
        "aliases": [
          "FOL"
        ],
        "category": "specific_connectable",
        "rationale": "Essential for understanding the logical framework used in the study.",
        "novelty_score": 0.5,
        "connectivity_score": 0.78,
        "specificity_score": 0.8,
        "link_intent_score": 0.82
      },
      {
        "surface": "Counterfactual Variants",
        "canonical": "Counterfactual Variants",
        "aliases": [
          "Counterfactual Tasks",
          "Counterfactuals"
        ],
        "category": "unique_technical",
        "rationale": "Highlights the method used to test robustness in reasoning systems.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.75,
        "link_intent_score": 0.78
      },
      {
        "surface": "Chain-of-Thought Prompting",
        "canonical": "Chain-of-Thought Prompting",
        "aliases": [
          "CoT Prompting",
          "Chain-of-Thought"
        ],
        "category": "specific_connectable",
        "rationale": "Important technique discussed for enhancing reasoning in LLMs.",
        "novelty_score": 0.6,
        "connectivity_score": 0.72,
        "specificity_score": 0.78,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "robustness",
      "performance",
      "method"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Neurosymbolic Reasoning",
      "resolved_canonical": "Neurosymbolic Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "First-Order Logic",
      "resolved_canonical": "First-Order Logic",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.78,
        "specificity": 0.8,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Counterfactual Variants",
      "resolved_canonical": "Counterfactual Variants",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.75,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Chain-of-Thought Prompting",
      "resolved_canonical": "Chain-of-Thought Prompting",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.72,
        "specificity": 0.78,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Robustness of Neurosymbolic Reasoners on First-Order Logic Problems

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17377.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2509.17377](https://arxiv.org/abs/2509.17377)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Are LLMs Better Formalizers than Solvers on Complex Problems?_20250922|Are LLMs Better Formalizers than Solvers on Complex Problems?]] (85.8% similar)
- [[2025-09-19/Enhancing Logical Reasoning in Language Models via Symbolically-Guided Monte Carlo Process Supervision_20250919|Enhancing Logical Reasoning in Language Models via Symbolically-Guided Monte Carlo Process Supervision]] (85.4% similar)
- [[2025-09-23/Correlation or Causation_ Analyzing the Causal Structures of LLM and LRM Reasoning Process_20250923|Correlation or Causation: Analyzing the Causal Structures of LLM and LRM Reasoning Process]] (85.0% similar)
- [[2025-09-23/Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates_20250923|Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates]] (84.8% similar)
- [[2025-09-22/FLARE_ Faithful Logic-Aided Reasoning and Exploration_20250922|FLARE: Faithful Logic-Aided Reasoning and Exploration]] (84.7% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/First-Order Logic|First-Order Logic]], [[keywords/Chain-of-Thought Prompting|Chain-of-Thought Prompting]]
**âš¡ Unique Technical**: [[keywords/Neurosymbolic Reasoning|Neurosymbolic Reasoning]], [[keywords/Counterfactual Variants|Counterfactual Variants]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17377v1 Announce Type: new 
Abstract: Recent trends in NLP aim to improve reasoning capabilities in Large Language Models (LLMs), with key focus on generalization and robustness to variations in tasks. Counterfactual task variants introduce minimal but semantically meaningful changes to otherwise valid first-order logic (FOL) problem instances altering a single predicate or swapping roles of constants to probe whether a reasoning system can maintain logical consistency under perturbation. Previous studies showed that LLMs becomes brittle on counterfactual variations, suggesting that they often rely on spurious surface patterns to generate responses. In this work, we explore if a neurosymbolic (NS) approach that integrates an LLM and a symbolic logical solver could mitigate this problem. Experiments across LLMs of varying sizes show that NS methods are more robust but perform worse overall that purely neural methods. We then propose NSCoT that combines an NS method and Chain-of-Thought (CoT) prompting and demonstrate that while it improves performance, NSCoT still lags behind standard CoT. Our analysis opens research directions for future work.

## ğŸ“ ìš”ì•½

ìµœê·¼ NLP ë¶„ì•¼ì—ì„œëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì¶”ë¡  ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ì¼ë°˜í™”ì™€ ì‘ì—… ë³€í˜•ì— ëŒ€í•œ ê°•ê±´ì„±ì„ ì¤‘ì ìœ¼ë¡œ ì—°êµ¬í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë°˜ì‚¬ì‹¤ì  ì‘ì—… ë³€í˜•ì€ ë…¼ë¦¬ì  ì¼ê´€ì„±ì„ ìœ ì§€í•  ìˆ˜ ìˆëŠ”ì§€ë¥¼ ì¡°ì‚¬í•˜ê¸° ìœ„í•´ FOL ë¬¸ì œì˜ ì¼ë¶€ë¥¼ ë¯¸ì„¸í•˜ê²Œ ë³€ê²½í•©ë‹ˆë‹¤. ê¸°ì¡´ ì—°êµ¬ì— ë”°ë¥´ë©´ LLMì€ ì´ëŸ¬í•œ ë³€í˜•ì— ì·¨ì•½í•˜ì—¬ í‘œë©´ì  íŒ¨í„´ì— ì˜ì¡´í•˜ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ëŠ” LLMê³¼ ë…¼ë¦¬ì  í•´ê²°ê¸°ë¥¼ í†µí•©í•œ ì‹ ê²½-ê¸°í˜¸(NS) ì ‘ê·¼ë²•ì´ ì´ ë¬¸ì œë¥¼ ì™„í™”í•  ìˆ˜ ìˆëŠ”ì§€ë¥¼ íƒêµ¬í•˜ì˜€ìŠµë‹ˆë‹¤. ë‹¤ì–‘í•œ í¬ê¸°ì˜ LLMì„ ëŒ€ìƒìœ¼ë¡œ í•œ ì‹¤í—˜ ê²°ê³¼, NS ë°©ë²•ì´ ë” ê°•ê±´í•˜ì§€ë§Œ ì „ë°˜ì ì¸ ì„±ëŠ¥ì€ ìˆœìˆ˜ ì‹ ê²½ ë°©ë²•ë³´ë‹¤ ë‚®ì•˜ìŠµë‹ˆë‹¤. ì´ì— NS ë°©ë²•ê³¼ Chain-of-Thought(CoT) í”„ë¡¬í”„íŠ¸ë¥¼ ê²°í•©í•œ NSCoTë¥¼ ì œì•ˆí•˜ì˜€ìœ¼ë©°, ì„±ëŠ¥ì€ í–¥ìƒë˜ì—ˆì§€ë§Œ ì—¬ì „íˆ í‘œì¤€ CoTë³´ë‹¤ ë’¤ì²˜ì¡ŒìŠµë‹ˆë‹¤. ì´ ë¶„ì„ì€ í–¥í›„ ì—°êµ¬ ë°©í–¥ì„ ì œì‹œí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ìµœê·¼ NLP ì—°êµ¬ëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì¶”ë¡  ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ì¼ë°˜í™” ë° ê³¼ì œ ë³€ë™ì— ëŒ€í•œ ê²¬ê³ ì„±ì— ì¤‘ì ì„ ë‘ê³  ìˆë‹¤.
- 2. ë°˜ì‚¬ì‹¤ì  ê³¼ì œ ë³€í˜•ì€ ìµœì†Œí•œì˜ ë³€í™”ë¡œ ì˜ë¯¸ ìˆëŠ” ë³€í™”ë¥¼ ë„ì…í•˜ì—¬ ë…¼ë¦¬ì  ì¼ê´€ì„±ì„ ìœ ì§€í•  ìˆ˜ ìˆëŠ”ì§€ í‰ê°€í•œë‹¤.
- 3. ì´ì „ ì—°êµ¬ì— ë”°ë¥´ë©´ LLMì€ ë°˜ì‚¬ì‹¤ì  ë³€í˜•ì— ì·¨ì•½í•˜ë©°, ì¢…ì¢… í‘œë©´ì  íŒ¨í„´ì— ì˜ì¡´í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•œë‹¤.
- 4. ì‹ ê²½-ê¸°í˜¸ì (NS) ì ‘ê·¼ë²•ì´ ì´ëŸ¬í•œ ë¬¸ì œë¥¼ ì™„í™”í•  ìˆ˜ ìˆëŠ”ì§€ íƒêµ¬í–ˆìœ¼ë©°, NS ë°©ë²•ì´ ë” ê²¬ê³ í•˜ì§€ë§Œ ìˆœìˆ˜ ì‹ ê²½ ë°©ë²•ë³´ë‹¤ ì„±ëŠ¥ì´ ë–¨ì–´ì§„ë‹¤ëŠ” ê²ƒì„ ë°œê²¬í–ˆë‹¤.
- 5. NSCoTëŠ” NS ë°©ë²•ê³¼ Chain-of-Thought(CoT) í”„ë¡¬í”„íŠ¸ë¥¼ ê²°í•©í•˜ì—¬ ì„±ëŠ¥ì„ ê°œì„ í•˜ì§€ë§Œ, ì—¬ì „íˆ í‘œì¤€ CoTë³´ë‹¤ ë’¤ì²˜ì§„ë‹¤.


---

*Generated on 2025-09-24 03:23:40*