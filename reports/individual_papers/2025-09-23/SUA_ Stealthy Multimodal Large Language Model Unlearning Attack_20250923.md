---
keywords:
  - Multimodal Learning
  - Unlearning Attack
  - Stealthy Unlearning Attack
  - Embedding Alignment Loss
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2506.17265
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T01:08:28.987332",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multimodal Learning",
    "Unlearning Attack",
    "Stealthy Unlearning Attack",
    "Embedding Alignment Loss"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multimodal Learning": 0.82,
    "Unlearning Attack": 0.79,
    "Stealthy Unlearning Attack": 0.77,
    "Embedding Alignment Loss": 0.74
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multimodal Large Language Models",
        "canonical": "Multimodal Learning",
        "aliases": [
          "MLLM",
          "Multimodal LLM"
        ],
        "category": "specific_connectable",
        "rationale": "Connects to the trending concept of integrating multiple data modalities in learning models.",
        "novelty_score": 0.55,
        "connectivity_score": 0.85,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "Unlearning Attack",
        "canonical": "Unlearning Attack",
        "aliases": [
          "Knowledge Recovery Attack"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel concept of reversing unlearning in models, relevant for privacy and security discussions.",
        "novelty_score": 0.92,
        "connectivity_score": 0.65,
        "specificity_score": 0.88,
        "link_intent_score": 0.79
      },
      {
        "surface": "Stealthy Unlearning Attack",
        "canonical": "Stealthy Unlearning Attack",
        "aliases": [
          "SUA"
        ],
        "category": "unique_technical",
        "rationale": "Highlights a specific method within unlearning attacks that emphasizes stealth, crucial for security research.",
        "novelty_score": 0.88,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      },
      {
        "surface": "Embedding Alignment Loss",
        "canonical": "Embedding Alignment Loss",
        "aliases": [
          "Alignment Loss"
        ],
        "category": "unique_technical",
        "rationale": "Focuses on a technique for minimizing differences in embeddings, relevant for model robustness and stealth.",
        "novelty_score": 0.75,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.74
      }
    ],
    "ban_list_suggestions": [
      "fine-tune",
      "massive data",
      "sensitive information"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multimodal Large Language Models",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.85,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Unlearning Attack",
      "resolved_canonical": "Unlearning Attack",
      "decision": "linked",
      "scores": {
        "novelty": 0.92,
        "connectivity": 0.65,
        "specificity": 0.88,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Stealthy Unlearning Attack",
      "resolved_canonical": "Stealthy Unlearning Attack",
      "decision": "linked",
      "scores": {
        "novelty": 0.88,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Embedding Alignment Loss",
      "resolved_canonical": "Embedding Alignment Loss",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.74
      }
    }
  ]
}
-->

# SUA: Stealthy Multimodal Large Language Model Unlearning Attack

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2506.17265.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2506.17265](https://arxiv.org/abs/2506.17265)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Sparse-Autoencoder-Guided Internal Representation Unlearning for Large Language Models_20250922|Sparse-Autoencoder-Guided Internal Representation Unlearning for Large Language Models]] (86.3% similar)
- [[2025-09-18/Reveal and Release_ Iterative LLM Unlearning with Self-generated Data_20250918|Reveal and Release: Iterative LLM Unlearning with Self-generated Data]] (85.8% similar)
- [[2025-09-22/Concept Unlearning in Large Language Models via Self-Constructed Knowledge Triplets_20250922|Concept Unlearning in Large Language Models via Self-Constructed Knowledge Triplets]] (85.0% similar)
- [[2025-09-23/Both Text and Images Leaked! A Systematic Analysis of Data Contamination in Multimodal LLM_20250923|Both Text and Images Leaked! A Systematic Analysis of Data Contamination in Multimodal LLM]] (83.6% similar)
- [[2025-09-17/Scrub It Out! Erasing Sensitive Memorization in Code Language Models via Machine Unlearning_20250917|Scrub It Out! Erasing Sensitive Memorization in Code Language Models via Machine Unlearning]] (83.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**âš¡ Unique Technical**: [[keywords/Unlearning Attack|Unlearning Attack]], [[keywords/Stealthy Unlearning Attack|Stealthy Unlearning Attack]], [[keywords/Embedding Alignment Loss|Embedding Alignment Loss]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2506.17265v2 Announce Type: replace-cross 
Abstract: Multimodal Large Language Models (MLLMs) trained on massive data may memorize sensitive personal information and photos, posing serious privacy risks. To mitigate this, MLLM unlearning methods are proposed, which fine-tune MLLMs to reduce the ``forget'' sensitive information. However, it remains unclear whether the knowledge has been truly forgotten or just hidden in the model. Therefore, we propose to study a novel problem of LLM unlearning attack, which aims to recover the unlearned knowledge of an unlearned LLM. To achieve the goal, we propose a novel framework Stealthy Unlearning Attack (SUA) framework that learns a universal noise pattern. When applied to input images, this noise can trigger the model to reveal unlearned content. While pixel-level perturbations may be visually subtle, they can be detected in the semantic embedding space, making such attacks vulnerable to potential defenses. To improve stealthiness, we introduce an embedding alignment loss that minimizes the difference between the perturbed and denoised image embeddings, ensuring the attack is semantically unnoticeable. Experimental results show that SUA can effectively recover unlearned information from MLLMs. Furthermore, the learned noise generalizes well: a single perturbation trained on a subset of samples can reveal forgotten content in unseen images. This indicates that knowledge reappearance is not an occasional failure, but a consistent behavior.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€ê·œëª¨ ë°ì´í„°ë¡œ í•™ìŠµëœ ë‹¤ì¤‘ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(MLLM)ì´ ë¯¼ê°í•œ ê°œì¸ ì •ë³´ì™€ ì‚¬ì§„ì„ ê¸°ì–µí•  ìˆ˜ ìˆì–´ í”„ë¼ì´ë²„ì‹œ ìœ„í—˜ì„ ì´ˆë˜í•  ìˆ˜ ìˆìŒì„ ì§€ì í•©ë‹ˆë‹¤. ì´ë¥¼ ì™„í™”í•˜ê¸° ìœ„í•´ MLLMì˜ ë¯¼ê°í•œ ì •ë³´ë¥¼ 'ìŠê²Œ' í•˜ëŠ” ë°©ë²•ë“¤ì´ ì œì•ˆë˜ì—ˆì§€ë§Œ, ì •ë³´ê°€ ì§„ì •ìœ¼ë¡œ ìŠí˜€ì¡ŒëŠ”ì§€ ì—¬ë¶€ëŠ” ë¶ˆë¶„ëª…í•©ë‹ˆë‹¤. ì´ì— ë”°ë¼, ìŠí˜€ì§„ ì§€ì‹ì„ ë³µêµ¬í•˜ëŠ” 'LLM ìŠí˜ ê³µê²©' ë¬¸ì œë¥¼ ì œì•ˆí•˜ê³ , ì´ë¥¼ ìœ„í•´ 'ì€ë°€í•œ ìŠí˜ ê³µê²©(SUA)' í”„ë ˆì„ì›Œí¬ë¥¼ ê°œë°œí–ˆìŠµë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ì…ë ¥ ì´ë¯¸ì§€ì— ë³´í¸ì ì¸ ë…¸ì´ì¦ˆ íŒ¨í„´ì„ ì ìš©í•˜ì—¬ ëª¨ë¸ì´ ìŠí˜€ì§„ ë‚´ìš©ì„ ë“œëŸ¬ë‚´ë„ë¡ ìœ ë„í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, SUAëŠ” MLLMì—ì„œ ìŠí˜€ì§„ ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ë³µêµ¬í•  ìˆ˜ ìˆìœ¼ë©°, í•™ìŠµëœ ë…¸ì´ì¦ˆëŠ” ìƒˆë¡œìš´ ì´ë¯¸ì§€ì—ì„œë„ ìŠí˜€ì§„ ë‚´ìš©ì„ ë“œëŸ¬ë‚¼ ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŠ” ì§€ì‹ì˜ ì¬ë“±ì¥ì´ ì¼ì‹œì ì¸ ì‹¤íŒ¨ê°€ ì•„ë‹Œ ì¼ê´€ëœ í–‰ë™ì„ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€ê·œëª¨ ë°ì´í„°ë¡œ í›ˆë ¨ëœ ë‹¤ì¤‘ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(MLLMs)ì€ ë¯¼ê°í•œ ê°œì¸ ì •ë³´ì™€ ì‚¬ì§„ì„ ê¸°ì–µí•  ìˆ˜ ìˆì–´ ì‹¬ê°í•œ í”„ë¼ì´ë²„ì‹œ ìœ„í—˜ì„ ì´ˆë˜í•  ìˆ˜ ìˆë‹¤.
- 2. MLLM ë§ê° ê³µê²© ë¬¸ì œë¥¼ ì—°êµ¬í•˜ì—¬ ë§ê°ëœ ëª¨ë¸ì˜ ì§€ì‹ì„ íšŒë³µí•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí•œë‹¤.
- 3. Stealthy Unlearning Attack (SUA) í”„ë ˆì„ì›Œí¬ëŠ” ì…ë ¥ ì´ë¯¸ì§€ì— ì ìš©ë  ë•Œ ë§ê°ëœ ì½˜í…ì¸ ë¥¼ ë“œëŸ¬ë‚´ëŠ” ë³´í¸ì ì¸ ë…¸ì´ì¦ˆ íŒ¨í„´ì„ í•™ìŠµí•œë‹¤.
- 4. í”½ì…€ ìˆ˜ì¤€ì˜ êµë€ì€ ì‹œê°ì ìœ¼ë¡œ ë¯¸ë¬˜í•  ìˆ˜ ìˆì§€ë§Œ, ì˜ë¯¸ì  ì„ë² ë”© ê³µê°„ì—ì„œ íƒì§€ ê°€ëŠ¥í•˜ì—¬ ì ì¬ì  ë°©ì–´ì— ì·¨ì•½í•˜ë‹¤.
- 5. ì‹¤í—˜ ê²°ê³¼, SUAëŠ” MLLMsì—ì„œ ë§ê°ëœ ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ íšŒë³µí•  ìˆ˜ ìˆìœ¼ë©°, í•™ìŠµëœ ë…¸ì´ì¦ˆëŠ” ìƒˆë¡œìš´ ì´ë¯¸ì§€ì—ì„œë„ ì˜ ì¼ë°˜í™”ëœë‹¤.


---

*Generated on 2025-09-24 01:08:28*