---
keywords:
  - Multimodal Learning
  - Data Contamination
  - Vision-Language Model
  - Unimodal Pre-training
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2411.03823
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T00:41:30.429656",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multimodal Learning",
    "Data Contamination",
    "Vision-Language Model",
    "Unimodal Pre-training"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multimodal Learning": 0.88,
    "Data Contamination": 0.79,
    "Vision-Language Model": 0.83,
    "Unimodal Pre-training": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multimodal Large Language Models",
        "canonical": "Multimodal Learning",
        "aliases": [
          "MLLMs",
          "Multimodal LLMs"
        ],
        "category": "specific_connectable",
        "rationale": "This term is central to the paper's focus on multimodal data contamination and aligns with the trending concept of Multimodal Learning.",
        "novelty_score": 0.45,
        "connectivity_score": 0.85,
        "specificity_score": 0.78,
        "link_intent_score": 0.88
      },
      {
        "surface": "Data Contamination",
        "canonical": "Data Contamination",
        "aliases": [
          "Contamination",
          "Data Leakage"
        ],
        "category": "unique_technical",
        "rationale": "The concept of data contamination is unique to this study's analysis of model training and evaluation, offering a new perspective on model reliability.",
        "novelty_score": 0.72,
        "connectivity_score": 0.65,
        "specificity_score": 0.82,
        "link_intent_score": 0.79
      },
      {
        "surface": "Visual Question Answering",
        "canonical": "Vision-Language Model",
        "aliases": [
          "VQA"
        ],
        "category": "evolved_concepts",
        "rationale": "Visual Question Answering is a specific application of Vision-Language Models, which are relevant to the paper's analysis of multimodal benchmarks.",
        "novelty_score": 0.55,
        "connectivity_score": 0.78,
        "specificity_score": 0.8,
        "link_intent_score": 0.83
      },
      {
        "surface": "Unimodal Pre-training",
        "canonical": "Unimodal Pre-training",
        "aliases": [
          "Single-modal Pre-training"
        ],
        "category": "unique_technical",
        "rationale": "This term highlights a specific phase in model training that contributes to data contamination, providing insights into model development processes.",
        "novelty_score": 0.68,
        "connectivity_score": 0.6,
        "specificity_score": 0.77,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "benchmark",
      "model training",
      "evaluation"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multimodal Large Language Models",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.85,
        "specificity": 0.78,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "Data Contamination",
      "resolved_canonical": "Data Contamination",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.65,
        "specificity": 0.82,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Visual Question Answering",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.78,
        "specificity": 0.8,
        "link_intent": 0.83
      }
    },
    {
      "candidate_surface": "Unimodal Pre-training",
      "resolved_canonical": "Unimodal Pre-training",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.6,
        "specificity": 0.77,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Both Text and Images Leaked! A Systematic Analysis of Data Contamination in Multimodal LLM

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2411.03823.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2411.03823](https://arxiv.org/abs/2411.03823)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/LNE-Blocking_ An Efficient Framework for Contamination Mitigation Evaluation on Large Language Models_20250918|LNE-Blocking: An Efficient Framework for Contamination Mitigation Evaluation on Large Language Models]] (87.5% similar)
- [[2025-09-19/Decoupled Proxy Alignment_ Mitigating Language Prior Conflict for Multimodal Alignment in MLLM_20250919|Decoupled Proxy Alignment: Mitigating Language Prior Conflict for Multimodal Alignment in MLLM]] (86.4% similar)
- [[2025-09-22/Beyond Spurious Signals_ Debiasing Multimodal Large Language Models via Counterfactual Inference and Adaptive Expert Routing_20250922|Beyond Spurious Signals: Debiasing Multimodal Large Language Models via Counterfactual Inference and Adaptive Expert Routing]] (85.5% similar)
- [[2025-09-17/Simulating a Bias Mitigation Scenario in Large Language Models_20250917|Simulating a Bias Mitigation Scenario in Large Language Models]] (85.2% similar)
- [[2025-09-19/DetectAnyLLM_ Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models_20250919|DetectAnyLLM: Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models]] (85.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**âš¡ Unique Technical**: [[keywords/Data Contamination|Data Contamination]], [[keywords/Unimodal Pre-training|Unimodal Pre-training]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2411.03823v3 Announce Type: replace-cross 
Abstract: The rapid advancement of multimodal large language models (MLLMs) has significantly enhanced performance across benchmarks. However, data contamination-unintentional memorization of benchmark data during model training-poses critical challenges for fair evaluation. Existing detection methods for unimodal large language models (LLMs) are inadequate for MLLMs due to multimodal data complexity and multi-phase training. We systematically analyze multimodal data contamination using our analytical framework, MM-Detect, which defines two contamination categories-unimodal and cross-modal-and effectively quantifies contamination severity across multiple-choice and caption-based Visual Question Answering tasks. Evaluations on twelve MLLMs and five benchmarks reveal significant contamination, particularly in proprietary models and older benchmarks. Crucially, contamination sometimes originates during unimodal pre-training rather than solely from multimodal fine-tuning. Our insights refine contamination understanding, guiding evaluation practices and improving multimodal model reliability.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë©€í‹°ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(MLLM)ì˜ ë°ì´í„° ì˜¤ì—¼ ë¬¸ì œë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. ë°ì´í„° ì˜¤ì—¼ì€ ëª¨ë¸ í›ˆë ¨ ì¤‘ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ë¥¼ ì˜ë„ì¹˜ ì•Šê²Œ ì•”ê¸°í•˜ëŠ” í˜„ìƒì„ ë§í•˜ë©°, ì´ëŠ” ê³µì •í•œ í‰ê°€ì— í° ë¬¸ì œë¥¼ ì´ˆë˜í•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë‹¨ì¼ ëª¨ë‹¬ ì–¸ì–´ ëª¨ë¸(LLM) íƒì§€ ë°©ë²•ì€ ë©€í‹°ëª¨ë‹¬ ë°ì´í„°ì˜ ë³µì¡ì„±ê³¼ ë‹¤ë‹¨ê³„ í›ˆë ¨ ê³¼ì • ë•Œë¬¸ì— MLLMì— ì í•©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì €ìë“¤ì€ MM-Detectë¼ëŠ” ë¶„ì„ í”„ë ˆì„ì›Œí¬ë¥¼ í†µí•´ ë©€í‹°ëª¨ë‹¬ ë°ì´í„° ì˜¤ì—¼ì„ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ê³ , ì˜¤ì—¼ì„ ë‹¨ì¼ ëª¨ë‹¬ê³¼ êµì°¨ ëª¨ë‹¬ë¡œ ë¶„ë¥˜í•˜ì—¬ ë‹¤ì–‘í•œ ì‹œê°ì  ì§ˆë¬¸ ì‘ë‹µ ê³¼ì œì—ì„œ ì˜¤ì—¼ì˜ ì‹¬ê°ì„±ì„ ì •ëŸ‰í™”í–ˆìŠµë‹ˆë‹¤. 12ê°œì˜ MLLMê³¼ 5ê°œì˜ ë²¤ì¹˜ë§ˆí¬ë¥¼ í‰ê°€í•œ ê²°ê³¼, íŠ¹íˆ ë…ì  ëª¨ë¸ê³¼ ì˜¤ë˜ëœ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìƒë‹¹í•œ ì˜¤ì—¼ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ì¤‘ìš”í•œ ì ì€ ì˜¤ì—¼ì´ ë©€í‹°ëª¨ë‹¬ ì„¸ë¶€ ì¡°ì •ë¿ë§Œ ì•„ë‹ˆë¼ ë‹¨ì¼ ëª¨ë‹¬ ì‚¬ì „ í›ˆë ¨ ì¤‘ì—ë„ ë°œìƒí•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ëŸ¬í•œ í†µì°°ì€ ì˜¤ì—¼ ì´í•´ë¥¼ ê°œì„ í•˜ê³  í‰ê°€ ê´€í–‰ì„ ì•ˆë‚´í•˜ë©° ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì˜ ì‹ ë¢°ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë©€í‹°ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(MLLMs)ì˜ ë°œì „ì€ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œì¼°ìœ¼ë‚˜, ë°ì´í„° ì˜¤ì—¼ ë¬¸ì œê°€ ê³µì •í•œ í‰ê°€ì— ë„ì „ ê³¼ì œë¥¼ ì œê¸°í•œë‹¤.
- 2. ê¸°ì¡´ì˜ ë‹¨ì¼ ëª¨ë‹¬ ì–¸ì–´ ëª¨ë¸(LLMs) íƒì§€ ë°©ë²•ì€ ë©€í‹°ëª¨ë‹¬ ë°ì´í„°ì˜ ë³µì¡ì„±ê³¼ ë‹¤ë‹¨ê³„ í›ˆë ¨ ë•Œë¬¸ì— MLLMsì— ì í•©í•˜ì§€ ì•Šë‹¤.
- 3. MM-Detectë¼ëŠ” ë¶„ì„ í”„ë ˆì„ì›Œí¬ë¥¼ í†µí•´ ë©€í‹°ëª¨ë‹¬ ë°ì´í„° ì˜¤ì—¼ì„ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ê³ , ì˜¤ì—¼ì˜ ì‹¬ê°ì„±ì„ íš¨ê³¼ì ìœ¼ë¡œ ì •ëŸ‰í™”í•œë‹¤.
- 4. ì—´ë‘ ê°œì˜ MLLMsê³¼ ë‹¤ì„¯ ê°œì˜ ë²¤ì¹˜ë§ˆí¬ í‰ê°€ì—ì„œ, íŠ¹íˆ ë…ì  ëª¨ë¸ê³¼ ì˜¤ë˜ëœ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìƒë‹¹í•œ ì˜¤ì—¼ì´ ë°œê²¬ë˜ì—ˆë‹¤.
- 5. ì˜¤ì—¼ì€ ë©€í‹°ëª¨ë‹¬ ë¯¸ì„¸ ì¡°ì •ë¿ë§Œ ì•„ë‹ˆë¼ ë‹¨ì¼ ëª¨ë‹¬ ì‚¬ì „ í›ˆë ¨ì—ì„œë„ ë°œìƒí•  ìˆ˜ ìˆìœ¼ë©°, ì´ëŠ” í‰ê°€ ê´€í–‰ì„ ê°œì„ í•˜ê³  ëª¨ë¸ ì‹ ë¢°ì„±ì„ ë†’ì´ëŠ” ë° ê¸°ì—¬í•œë‹¤.


---

*Generated on 2025-09-24 00:41:30*