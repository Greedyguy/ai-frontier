---
keywords:
  - Neural Program Synthesis
  - Test-Time Fine-Tuning
  - Out-of-Distribution Generalization
  - ARC-AGI Domain
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2507.15877
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T00:29:49.523717",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Neural Program Synthesis",
    "Test-Time Fine-Tuning",
    "Out-of-Distribution Generalization",
    "ARC-AGI Domain"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Neural Program Synthesis": 0.78,
    "Test-Time Fine-Tuning": 0.77,
    "Out-of-Distribution Generalization": 0.81,
    "ARC-AGI Domain": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "neural program synthesis",
        "canonical": "Neural Program Synthesis",
        "aliases": [
          "program synthesis",
          "NPS"
        ],
        "category": "unique_technical",
        "rationale": "Neural program synthesis is a specialized technique relevant to the ARC-AGI domain, offering unique insights into compositional generalization.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "test-time fine-tuning",
        "canonical": "Test-Time Fine-Tuning",
        "aliases": [
          "TTFT"
        ],
        "category": "unique_technical",
        "rationale": "Test-time fine-tuning is a distinct approach that enhances model adaptability, crucial for out-of-distribution generalization.",
        "novelty_score": 0.68,
        "connectivity_score": 0.72,
        "specificity_score": 0.82,
        "link_intent_score": 0.77
      },
      {
        "surface": "out-of-distribution generalization",
        "canonical": "Out-of-Distribution Generalization",
        "aliases": [
          "OOD generalization"
        ],
        "category": "specific_connectable",
        "rationale": "This concept is central to the ARC-AGI domain, facilitating connections with other generalization techniques.",
        "novelty_score": 0.58,
        "connectivity_score": 0.85,
        "specificity_score": 0.78,
        "link_intent_score": 0.81
      },
      {
        "surface": "ARC-AGI domain",
        "canonical": "ARC-AGI Domain",
        "aliases": [
          "ARC domain"
        ],
        "category": "unique_technical",
        "rationale": "The ARC-AGI domain is a specific context for studying generalization, providing a unique framework for related research.",
        "novelty_score": 0.72,
        "connectivity_score": 0.62,
        "specificity_score": 0.88,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "experiment",
      "success",
      "ability"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "neural program synthesis",
      "resolved_canonical": "Neural Program Synthesis",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "test-time fine-tuning",
      "resolved_canonical": "Test-Time Fine-Tuning",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.72,
        "specificity": 0.82,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "out-of-distribution generalization",
      "resolved_canonical": "Out-of-Distribution Generalization",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.85,
        "specificity": 0.78,
        "link_intent": 0.81
      }
    },
    {
      "candidate_surface": "ARC-AGI domain",
      "resolved_canonical": "ARC-AGI Domain",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.62,
        "specificity": 0.88,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Out-of-Distribution Generalization in the ARC-AGI Domain: Comparing Execution-Guided Neural Program Synthesis and Test-Time Fine-Tuning

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2507.15877.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2507.15877](https://arxiv.org/abs/2507.15877)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Program Synthesis via Test-Time Transduction_20250923|Program Synthesis via Test-Time Transduction]] (81.4% similar)
- [[2025-09-23/Generalizable End-to-End Tool-Use RL with Synthetic CodeGym_20250923|Generalizable End-to-End Tool-Use RL with Synthetic CodeGym]] (79.9% similar)
- [[2025-09-19/DetectAnyLLM_ Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models_20250919|DetectAnyLLM: Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models]] (79.6% similar)
- [[2025-09-17/Class-invariant Test-Time Augmentation for Domain Generalization_20250917|Class-invariant Test-Time Augmentation for Domain Generalization]] (79.6% similar)
- [[2025-09-23/Evaluating Multimodal Large Language Models with Daily Composite Tasks in Home Environments_20250923|Evaluating Multimodal Large Language Models with Daily Composite Tasks in Home Environments]] (79.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Out-of-Distribution Generalization|Out-of-Distribution Generalization]]
**âš¡ Unique Technical**: [[keywords/Neural Program Synthesis|Neural Program Synthesis]], [[keywords/Test-Time Fine-Tuning|Test-Time Fine-Tuning]], [[keywords/ARC-AGI Domain|ARC-AGI Domain]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2507.15877v2 Announce Type: replace 
Abstract: We run a controlled compositional generalization experiment in the ARC-AGI domain: an open-world problem domain in which the ability to generalize out-of-distribution is, by design, an essential characteristic for success. We compare neural program synthesis and test-time fine-tuning approaches on this experiment. We find that execution-guided neural program synthesis outperforms all reference algorithms in its ability to compose novel solutions. Our empirical findings also suggest that the success of TTFT on ARC-AGI lies mainly in eliciting in-distribution knowledge that the LLM otherwise fails to rely on directly.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” ARC-AGI ë„ë©”ì¸ì—ì„œì˜ ì¡°í•©ì  ì¼ë°˜í™” ì‹¤í—˜ì„ í†µí•´ ì‹ ê²½ë§ í”„ë¡œê·¸ë¨ í•©ì„±ê³¼ í…ŒìŠ¤íŠ¸ ì‹œì  ë¯¸ì„¸ ì¡°ì •(TTFT) ì ‘ê·¼ë²•ì„ ë¹„êµí•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì‹¤í–‰ ìœ ë„ ì‹ ê²½ë§ í”„ë¡œê·¸ë¨ í•©ì„±ì´ ìƒˆë¡œìš´ í•´ê²°ì±…ì„ êµ¬ì„±í•˜ëŠ” ë° ìˆì–´ ë‹¤ë¥¸ ì•Œê³ ë¦¬ì¦˜ë³´ë‹¤ ìš°ìˆ˜í•¨ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, TTFTì˜ ì„±ê³µì€ ì£¼ë¡œ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì´ ì§ì ‘ í™œìš©í•˜ì§€ ì•ŠëŠ” ë¶„í¬ ë‚´ ì§€ì‹ì„ ì´ëŒì–´ë‚´ëŠ” ë° ìˆë‹¤ëŠ” ê²ƒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ARC-AGI ë„ë©”ì¸ì—ì„œì˜ ì‹¤í—˜ì€ ë¶„í¬ ì™¸ ì¼ë°˜í™” ëŠ¥ë ¥ì´ ì„±ê³µì˜ í•„ìˆ˜ ìš”ì†Œì„ì„ ë³´ì—¬ì¤€ë‹¤.
- 2. ì‹¤í–‰ ìœ ë„ ì‹ ê²½ í”„ë¡œê·¸ë¨ í•©ì„±ì´ ìƒˆë¡œìš´ ì†”ë£¨ì…˜ì„ êµ¬ì„±í•˜ëŠ” ë° ìˆì–´ ëª¨ë“  ì°¸ì¡° ì•Œê³ ë¦¬ì¦˜ì„ ëŠ¥ê°€í•œë‹¤.
- 3. TTFTì˜ ì„±ê³µì€ ì£¼ë¡œ LLMì´ ì§ì ‘ì ìœ¼ë¡œ ì˜ì¡´í•˜ì§€ ì•ŠëŠ” ë¶„í¬ ë‚´ ì§€ì‹ì„ ì´ëŒì–´ë‚´ëŠ” ë° ìˆë‹¤.


---

*Generated on 2025-09-24 00:29:49*