---
keywords:
  - Cross-Lingual Generation
  - XL-Instruct
  - Large Language Model
  - Zero-Shot Learning
  - XL-AlpacaEval
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2503.22973
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T00:52:25.387126",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Cross-Lingual Generation",
    "XL-Instruct",
    "Large Language Model",
    "Zero-Shot Learning",
    "XL-AlpacaEval"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Cross-Lingual Generation": 0.78,
    "XL-Instruct": 0.77,
    "Large Language Model": 0.85,
    "Zero-Shot Learning": 0.8,
    "XL-AlpacaEval": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "cross-lingual open-ended generation",
        "canonical": "Cross-Lingual Generation",
        "aliases": [
          "cross-lingual generation",
          "multilingual generation"
        ],
        "category": "unique_technical",
        "rationale": "This term represents a specific and emerging area of research in NLP, focusing on generating responses in different languages.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.82,
        "link_intent_score": 0.78
      },
      {
        "surface": "XL-Instruct",
        "canonical": "XL-Instruct",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "XL-Instruct is a novel technique introduced in the paper, crucial for generating synthetic data for cross-lingual tasks.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      },
      {
        "surface": "Large Language Model",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "LLMs are central to the paper's experiments and are a fundamental concept in NLP.",
        "novelty_score": 0.4,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "zero-shot improvements",
        "canonical": "Zero-Shot Learning",
        "aliases": [
          "zero-shot"
        ],
        "category": "specific_connectable",
        "rationale": "Zero-shot learning is a trending concept relevant to the paper's findings on model improvements.",
        "novelty_score": 0.5,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "XL-AlpacaEval",
        "canonical": "XL-AlpacaEval",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This is a new benchmark introduced by the authors, significant for evaluating cross-lingual capabilities.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "cross-lingual open-ended generation",
      "resolved_canonical": "Cross-Lingual Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.82,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "XL-Instruct",
      "resolved_canonical": "XL-Instruct",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Large Language Model",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "zero-shot improvements",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "XL-AlpacaEval",
      "resolved_canonical": "XL-AlpacaEval",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# XL-Suite: Cross-Lingual Synthetic Training and Evaluation Data for Open-Ended Generation

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2503.22973.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2503.22973](https://arxiv.org/abs/2503.22973)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages_20250922|A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages]] (85.6% similar)
- [[2025-09-22/MUG-Eval_ A Proxy Evaluation Framework for Multilingual Generation Capabilities in Any Language_20250922|MUG-Eval: A Proxy Evaluation Framework for Multilingual Generation Capabilities in Any Language]] (83.2% similar)
- [[2025-09-22/Enhancing LLM Language Adaption through Cross-lingual In-Context Pre-training_20250922|Enhancing LLM Language Adaption through Cross-lingual In-Context Pre-training]] (83.2% similar)
- [[2025-09-22/SyGra_ A Unified Graph-Based Framework for Scalable Generation, Quality Tagging, and Management of Synthetic Data_20250922|SyGra: A Unified Graph-Based Framework for Scalable Generation, Quality Tagging, and Management of Synthetic Data]] (82.8% similar)
- [[2025-09-23/Investigating Bias_ A Multilingual Pipeline for Generating, Solving, and Evaluating Math Problems with LLMs_20250923|Investigating Bias: A Multilingual Pipeline for Generating, Solving, and Evaluating Math Problems with LLMs]] (82.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Zero-Shot Learning|Zero-Shot Learning]]
**âš¡ Unique Technical**: [[keywords/Cross-Lingual Generation|Cross-Lingual Generation]], [[keywords/XL-Instruct|XL-Instruct]], [[keywords/XL-AlpacaEval|XL-AlpacaEval]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2503.22973v2 Announce Type: replace-cross 
Abstract: Cross-lingual open-ended generation - responding in a language different from that of the query - is an important yet understudied problem. This work proposes XL-Instruct, a novel technique for generating high-quality synthetic data, and introduces XL-AlpacaEval, a new benchmark for evaluating cross-lingual generation capabilities of large language models (LLMs). Our experiments show that fine-tuning with just 8K instructions generated using XL-Instruct significantly improves model performance, increasing the win rate against GPT-4o-Mini from 7.4% to 21.5% and improving on several fine-grained quality metrics. Moreover, base LLMs fine-tuned on XL-Instruct exhibit strong zero-shot improvements to question answering in the same language, as shown on our machine-translated m-AlpacaEval. These consistent gains highlight the promising role of XL-Instruct in the post-training of multilingual LLMs. Finally, we publicly release XL-Suite, a collection of training and evaluation data to facilitate research in cross-lingual open-ended generation.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” ë‹¤êµ­ì–´ ê°„ ê°œë°©í˜• ìƒì„± ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ XL-Instructë¼ëŠ” ìƒˆë¡œìš´ ê¸°ë²•ì„ ì œì•ˆí•˜ê³ , ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ë‹¤êµ­ì–´ ìƒì„± ëŠ¥ë ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ XL-AlpacaEval ë²¤ì¹˜ë§ˆí¬ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. XL-Instructë¡œ ìƒì„±ëœ 8,000ê°œì˜ ì§€ì‹œë¬¸ìœ¼ë¡œ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•œ ê²°ê³¼, GPT-4o-Miniì™€ì˜ ë¹„êµì—ì„œ ìŠ¹ë¥ ì´ 7.4%ì—ì„œ 21.5%ë¡œ í¬ê²Œ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤. ë˜í•œ, XL-Instructë¡œ ë¯¸ì„¸ ì¡°ì •ëœ ê¸°ë³¸ LLMì€ ë™ì¼ ì–¸ì–´ì˜ ì§ˆë¬¸ ì‘ë‹µì—ì„œ ê°•ë ¥í•œ ì œë¡œìƒ· ê°œì„ ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ê²°ê³¼ëŠ” ë‹¤êµ­ì–´ LLMì˜ í›„ì† í•™ìŠµì—ì„œ XL-Instructì˜ ì ì¬ë ¥ì„ ê°•ì¡°í•©ë‹ˆë‹¤. ì—°êµ¬ì§„ì€ XL-Suiteë¼ëŠ” í›ˆë ¨ ë° í‰ê°€ ë°ì´í„° ì„¸íŠ¸ë¥¼ ê³µê°œí•˜ì—¬ ê´€ë ¨ ì—°êµ¬ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. XL-InstructëŠ” ê³ í’ˆì§ˆ í•©ì„± ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ìƒˆë¡œìš´ ê¸°ë²•ìœ¼ë¡œ, ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ êµì°¨ ì–¸ì–´ ìƒì„± ëŠ¥ë ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ì¸ XL-AlpacaEvalì„ ë„ì…í–ˆìŠµë‹ˆë‹¤.
- 2. XL-Instructë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒì„±ëœ 8K ì§€ì‹œë¬¸ìœ¼ë¡œ ë¯¸ì„¸ ì¡°ì •í•˜ë©´ ëª¨ë¸ ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë˜ë©°, GPT-4o-Miniì™€ì˜ ìŠ¹ë¥ ì´ 7.4%ì—ì„œ 21.5%ë¡œ ì¦ê°€í–ˆìŠµë‹ˆë‹¤.
- 3. XL-Instructë¡œ ë¯¸ì„¸ ì¡°ì •ëœ ê¸°ë³¸ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì€ ë™ì¼í•œ ì–¸ì–´ì˜ ì§ˆë¬¸ ì‘ë‹µì—ì„œ ê°•ë ¥í•œ ì œë¡œìƒ· ê°œì„ ì„ ë³´ì´ë©°, ì´ëŠ” ê¸°ê³„ ë²ˆì—­ëœ m-AlpacaEvalì—ì„œ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.
- 4. XL-InstructëŠ” ë‹¤êµ­ì–´ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ì‚¬í›„ í›ˆë ¨ì—ì„œ ìœ ë§í•œ ì—­í• ì„ í•˜ë©°, ì¼ê´€ëœ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
- 5. êµì°¨ ì–¸ì–´ ê°œë°©í˜• ìƒì„± ì—°êµ¬ë¥¼ ì´‰ì§„í•˜ê¸° ìœ„í•´ XL-Suiteë¼ëŠ” í›ˆë ¨ ë° í‰ê°€ ë°ì´í„° ëª¨ìŒì„ ê³µê°œí–ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 00:52:25*