---
keywords:
  - Text-to-Image Diffusion
  - Attention Mechanism
  - Semantic Segmentation
  - Multimodal Learning
category: cs.CV
publish_date: 2025-09-23
arxiv_id: 2509.18096
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T05:09:04.806502",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Text-to-Image Diffusion",
    "Attention Mechanism",
    "Semantic Segmentation",
    "Multimodal Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Text-to-Image Diffusion": 0.78,
    "Attention Mechanism": 0.8,
    "Semantic Segmentation": 0.77,
    "Multimodal Learning": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Text-to-image diffusion models",
        "canonical": "Text-to-Image Diffusion",
        "aliases": [
          "Text-to-Image Generation",
          "Diffusion Models"
        ],
        "category": "unique_technical",
        "rationale": "This concept is central to the paper and represents a specific application of diffusion models in generating images from text.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.82,
        "link_intent_score": 0.78
      },
      {
        "surface": "Attention Mechanism",
        "canonical": "Attention Mechanism",
        "aliases": [
          "Attention Maps"
        ],
        "category": "specific_connectable",
        "rationale": "The paper focuses on how attention mechanisms contribute to image generation, making it a key linkable concept.",
        "novelty_score": 0.45,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Semantic Segmentation",
        "canonical": "Semantic Segmentation",
        "aliases": [
          "Segmentation Masks"
        ],
        "category": "specific_connectable",
        "rationale": "Semantic segmentation is a critical outcome of the proposed framework, linking vision and language processing.",
        "novelty_score": 0.55,
        "connectivity_score": 0.79,
        "specificity_score": 0.78,
        "link_intent_score": 0.77
      },
      {
        "surface": "Multimodal Diffusion Transformers",
        "canonical": "Multimodal Learning",
        "aliases": [
          "MM-DiT",
          "Multimodal Transformers"
        ],
        "category": "evolved_concepts",
        "rationale": "This represents an evolved concept in the integration of multiple modalities, crucial for the paper's framework.",
        "novelty_score": 0.68,
        "connectivity_score": 0.72,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "framework",
      "performance",
      "method"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Text-to-image diffusion models",
      "resolved_canonical": "Text-to-Image Diffusion",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.82,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Attention Mechanism",
      "resolved_canonical": "Attention Mechanism",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Semantic Segmentation",
      "resolved_canonical": "Semantic Segmentation",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.79,
        "specificity": 0.78,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Multimodal Diffusion Transformers",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.72,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Seg4Diff: Unveiling Open-Vocabulary Segmentation in Text-to-Image Diffusion Transformers

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18096.pdf)
**Category**: cs.CV
**Published**: 2025-09-23
**ArXiv ID**: [2509.18096](https://arxiv.org/abs/2509.18096)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/MaskAttn-SDXL_ Controllable Region-Level Text-To-Image Generation_20250922|MaskAttn-SDXL: Controllable Region-Level Text-To-Image Generation]] (87.0% similar)
- [[2025-09-22/RespoDiff_ Dual-Module Bottleneck Transformation for Responsible & Faithful T2I Generation_20250922|RespoDiff: Dual-Module Bottleneck Transformation for Responsible & Faithful T2I Generation]] (86.5% similar)
- [[2025-09-19/DiffCut_ Catalyzing Zero-Shot Semantic Segmentation with Diffusion Features and Recursive Normalized Cut_20250919|DiffCut: Catalyzing Zero-Shot Semantic Segmentation with Diffusion Features and Recursive Normalized Cut]] (84.7% similar)
- [[2025-09-23/AlignedGen_ Aligning Style Across Generated Images_20250923|AlignedGen: Aligning Style Across Generated Images]] (84.4% similar)
- [[2025-09-23/Penalizing Boundary Activation for Object Completeness in Diffusion Models_20250923|Penalizing Boundary Activation for Object Completeness in Diffusion Models]] (83.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Attention Mechanism|Attention Mechanism]], [[keywords/Semantic Segmentation|Semantic Segmentation]]
**âš¡ Unique Technical**: [[keywords/Text-to-Image Diffusion|Text-to-Image Diffusion]]
**ğŸš€ Evolved Concepts**: [[keywords/Multimodal Learning|Multimodal Learning]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18096v1 Announce Type: new 
Abstract: Text-to-image diffusion models excel at translating language prompts into photorealistic images by implicitly grounding textual concepts through their cross-modal attention mechanisms. Recent multi-modal diffusion transformers extend this by introducing joint self-attention over concatenated image and text tokens, enabling richer and more scalable cross-modal alignment. However, a detailed understanding of how and where these attention maps contribute to image generation remains limited. In this paper, we introduce Seg4Diff (Segmentation for Diffusion), a systematic framework for analyzing the attention structures of MM-DiT, with a focus on how specific layers propagate semantic information from text to image. Through comprehensive analysis, we identify a semantic grounding expert layer, a specific MM-DiT block that consistently aligns text tokens with spatially coherent image regions, naturally producing high-quality semantic segmentation masks. We further demonstrate that applying a lightweight fine-tuning scheme with mask-annotated image data enhances the semantic grouping capabilities of these layers and thereby improves both segmentation performance and generated image fidelity. Our findings demonstrate that semantic grouping is an emergent property of diffusion transformers and can be selectively amplified to advance both segmentation and generation performance, paving the way for unified models that bridge visual perception and generation.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ë³€í™˜ ëª¨ë¸ì˜ ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì„ ë¶„ì„í•˜ëŠ” Seg4Diffë¼ëŠ” ì²´ê³„ì ì¸ í”„ë ˆì„ì›Œí¬ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. íŠ¹íˆ, MM-DiTì˜ íŠ¹ì • ë ˆì´ì–´ê°€ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ ì‚¬ì´ì˜ ì˜ë¯¸ì  ì •ë³´ë¥¼ ì–´ë–»ê²Œ ì „ë‹¬í•˜ëŠ”ì§€ë¥¼ ì¤‘ì ì ìœ¼ë¡œ ì—°êµ¬í–ˆìŠµë‹ˆë‹¤. ì—°êµ¬ ê²°ê³¼, íŠ¹ì • MM-DiT ë¸”ë¡ì´ í…ìŠ¤íŠ¸ í† í°ì„ ê³µê°„ì ìœ¼ë¡œ ì¼ê´€ëœ ì´ë¯¸ì§€ ì˜ì—­ê³¼ ì •ë ¬í•˜ì—¬ ê³ í’ˆì§ˆì˜ ì˜ë¯¸ ë¶„í•  ë§ˆìŠ¤í¬ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, ë§ˆìŠ¤í¬ë¡œ ì£¼ì„ëœ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ í™œìš©í•œ ê²½ëŸ‰í™”ëœ ë¯¸ì„¸ ì¡°ì •ì´ ì´ëŸ¬í•œ ë ˆì´ì–´ì˜ ì˜ë¯¸ì  ê·¸ë£¹í™” ëŠ¥ë ¥ì„ í–¥ìƒì‹œì¼œ, ë¶„í•  ì„±ëŠ¥ê³¼ ìƒì„± ì´ë¯¸ì§€ì˜ í’ˆì§ˆì„ ëª¨ë‘ ê°œì„ í•¨ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ì˜ë¯¸ì  ê·¸ë£¹í™”ê°€ í™•ì‚° ë³€í™˜ê¸°ì˜ ìì—° ë°œìƒì  íŠ¹ì„±ì„ì„ ì…ì¦í•˜ë©°, ì‹œê°ì  ì¸ì‹ê³¼ ìƒì„± ê°„ì˜ í†µí•© ëª¨ë¸ ê°œë°œ ê°€ëŠ¥ì„±ì„ ì œì‹œí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ í™•ì‚° ëª¨ë¸ì€ êµì°¨ ëª¨ë‹¬ ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´ ì–¸ì–´ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ì§„ê³¼ ê°™ì€ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ëŠ” ë° ë›°ì–´ë‚˜ë‹¤.
- 2. Seg4DiffëŠ” MM-DiTì˜ ì£¼ì˜ êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ì—¬ í…ìŠ¤íŠ¸ì—ì„œ ì´ë¯¸ì§€ë¡œ ì˜ë¯¸ ì •ë³´ë¥¼ ì „íŒŒí•˜ëŠ” ë°©ë²•ì„ ì²´ê³„ì ìœ¼ë¡œ ì—°êµ¬í•˜ëŠ” í”„ë ˆì„ì›Œí¬ì´ë‹¤.
- 3. íŠ¹ì • MM-DiT ë¸”ë¡ì€ í…ìŠ¤íŠ¸ í† í°ì„ ê³µê°„ì ìœ¼ë¡œ ì¼ê´€ëœ ì´ë¯¸ì§€ ì˜ì—­ê³¼ ì •ë ¬í•˜ì—¬ ê³ í’ˆì§ˆì˜ ì˜ë¯¸ ë¶„í•  ë§ˆìŠ¤í¬ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ìƒì„±í•œë‹¤.
- 4. ë§ˆìŠ¤í¬ ì£¼ì„ì´ ë‹¬ë¦° ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ ê²½ëŸ‰ì˜ ë¯¸ì„¸ ì¡°ì •ì€ ì˜ë¯¸ ê·¸ë£¹í™” ê¸°ëŠ¥ì„ í–¥ìƒì‹œì¼œ ë¶„í•  ì„±ëŠ¥ê³¼ ìƒì„± ì´ë¯¸ì§€ì˜ ì¶©ì‹¤ë„ë¥¼ ê°œì„ í•œë‹¤.
- 5. ì˜ë¯¸ ê·¸ë£¹í™”ëŠ” í™•ì‚° ë³€í™˜ê¸°ì˜ ìì—° ë°œìƒì  ì†ì„±ìœ¼ë¡œ, ì´ë¥¼ ì„ íƒì ìœ¼ë¡œ ì¦í­í•˜ì—¬ ë¶„í•  ë° ìƒì„± ì„±ëŠ¥ì„ ë°œì „ì‹œí‚¬ ìˆ˜ ìˆë‹¤.


---

*Generated on 2025-09-24 05:09:04*