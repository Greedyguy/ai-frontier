---
keywords:
  - Gated-Mechanism Mixture-of-Experts
  - Low-Light Enhancement
  - Dynamic Gated Network
  - Feature Fusion
category: cs.CV
publish_date: 2025-09-23
arxiv_id: 2503.07417
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T05:18:55.287975",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Gated-Mechanism Mixture-of-Experts",
    "Low-Light Enhancement",
    "Dynamic Gated Network",
    "Feature Fusion"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Gated-Mechanism Mixture-of-Experts": 0.78,
    "Low-Light Enhancement": 0.72,
    "Dynamic Gated Network": 0.7,
    "Feature Fusion": 0.68
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Gated-Mechanism Mixture-of-Experts",
        "canonical": "Gated-Mechanism Mixture-of-Experts",
        "aliases": [
          "GM-MoE"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel approach specifically for low-light enhancement, which can be linked to similar innovations in image processing.",
        "novelty_score": 0.85,
        "connectivity_score": 0.68,
        "specificity_score": 0.92,
        "link_intent_score": 0.78
      },
      {
        "surface": "low-light enhancement",
        "canonical": "Low-Light Enhancement",
        "aliases": [
          "low-light image enhancement"
        ],
        "category": "specific_connectable",
        "rationale": "A specific task within computer vision that can connect to broader image processing techniques.",
        "novelty_score": 0.45,
        "connectivity_score": 0.82,
        "specificity_score": 0.78,
        "link_intent_score": 0.72
      },
      {
        "surface": "dynamic gated weight conditioning network",
        "canonical": "Dynamic Gated Network",
        "aliases": [
          "gated weight network"
        ],
        "category": "unique_technical",
        "rationale": "Represents a specific mechanism that can be linked to other gated or dynamic network architectures.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      },
      {
        "surface": "local and global feature fusion",
        "canonical": "Feature Fusion",
        "aliases": [
          "local-global feature fusion"
        ],
        "category": "specific_connectable",
        "rationale": "A technique relevant to enhancing image quality, connecting to broader feature extraction methods.",
        "novelty_score": 0.5,
        "connectivity_score": 0.78,
        "specificity_score": 0.75,
        "link_intent_score": 0.68
      }
    ],
    "ban_list_suggestions": [
      "autonomous driving",
      "3D reconstruction",
      "remote sensing",
      "surveillance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Gated-Mechanism Mixture-of-Experts",
      "resolved_canonical": "Gated-Mechanism Mixture-of-Experts",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.68,
        "specificity": 0.92,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "low-light enhancement",
      "resolved_canonical": "Low-Light Enhancement",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.82,
        "specificity": 0.78,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "dynamic gated weight conditioning network",
      "resolved_canonical": "Dynamic Gated Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "local and global feature fusion",
      "resolved_canonical": "Feature Fusion",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.78,
        "specificity": 0.75,
        "link_intent": 0.68
      }
    }
  ]
}
-->

# GM-MoE: Low-Light Enhancement with Gated-Mechanism Mixture-of-Experts

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2503.07417.pdf)
**Category**: cs.CV
**Published**: 2025-09-23
**ArXiv ID**: [2503.07417](https://arxiv.org/abs/2503.07417)

## 🔗 유사한 논문
- [[2025-09-22/TrueMoE_ Dual-Routing Mixture of Discriminative Experts for Synthetic Image Detection_20250922|TrueMoE: Dual-Routing Mixture of Discriminative Experts for Synthetic Image Detection]] (86.9% similar)
- [[2025-09-18/Semi-MoE_ Mixture-of-Experts meets Semi-Supervised Histopathology Segmentation_20250918|Semi-MoE: Mixture-of-Experts meets Semi-Supervised Histopathology Segmentation]] (86.5% similar)
- [[2025-09-23/CoBEVMoE_ Heterogeneity-aware Feature Fusion with Dynamic Mixture-of-Experts for Collaborative Perception_20250923|CoBEVMoE: Heterogeneity-aware Feature Fusion with Dynamic Mixture-of-Experts for Collaborative Perception]] (85.7% similar)
- [[2025-09-22/MoE-CE_ Enhancing Generalization for Deep Learning based Channel Estimation via a Mixture-of-Experts Framework_20250922|MoE-CE: Enhancing Generalization for Deep Learning based Channel Estimation via a Mixture-of-Experts Framework]] (85.7% similar)
- [[2025-09-19/HPGN_ Hybrid Priors-Guided Network for Compressed Low-Light Image Enhancement_20250919|HPGN: Hybrid Priors-Guided Network for Compressed Low-Light Image Enhancement]] (85.6% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Low-Light Enhancement|Low-Light Enhancement]], [[keywords/Feature Fusion|Feature Fusion]]
**⚡ Unique Technical**: [[keywords/Gated-Mechanism Mixture-of-Experts|Gated-Mechanism Mixture-of-Experts]], [[keywords/Dynamic Gated Network|Dynamic Gated Network]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2503.07417v4 Announce Type: replace 
Abstract: Low-light enhancement has wide applications in autonomous driving, 3D reconstruction, remote sensing, surveillance, and so on, which can significantly improve information utilization. However, most existing methods lack generalization and are limited to specific tasks such as image recovery. To address these issues, we propose Gated-Mechanism Mixture-of-Experts (GM-MoE), the first framework to introduce a mixture-of-experts network for low-light image enhancement. GM-MoE comprises a dynamic gated weight conditioning network and three sub-expert networks, each specializing in a distinct enhancement task. Combining a self-designed gated mechanism that dynamically adjusts the weights of the sub-expert networks for different data domains. Additionally, we integrate local and global feature fusion within sub-expert networks to enhance image quality by capturing multi-scale features. Experimental results demonstrate that the GM-MoE achieves superior generalization with respect to 25 compared approaches, reaching state-of-the-art performance on PSNR on 5 benchmarks and SSIM on 4 benchmarks, respectively.

## 📝 요약

이 논문은 저조도 이미지 향상을 위한 Gated-Mechanism Mixture-of-Experts (GM-MoE)라는 새로운 프레임워크를 제안합니다. GM-MoE는 동적 게이트 가중치 조건 네트워크와 세 개의 하위 전문가 네트워크로 구성되어 있으며, 각각 다른 향상 작업에 특화되어 있습니다. 이 프레임워크는 데이터 도메인에 따라 하위 전문가 네트워크의 가중치를 동적으로 조정하는 게이트 메커니즘을 도입하고, 지역 및 글로벌 특징 융합을 통해 이미지 품질을 향상시킵니다. 실험 결과, GM-MoE는 25개의 기존 방법과 비교하여 우수한 일반화 성능을 보였으며, 5개의 벤치마크에서 PSNR, 4개의 벤치마크에서 SSIM에서 최첨단 성능을 달성했습니다.

## 🎯 주요 포인트

- 1. 저조도 이미지 향상을 위한 Gated-Mechanism Mixture-of-Experts (GM-MoE) 프레임워크를 제안하였습니다.
- 2. GM-MoE는 동적 게이트 가중치 조정 네트워크와 세 가지 하위 전문가 네트워크로 구성되어 있습니다.
- 3. 하위 전문가 네트워크 내에서 지역 및 전역 특징 융합을 통합하여 이미지 품질을 향상시킵니다.
- 4. 실험 결과, GM-MoE는 25개의 비교 방법에 비해 우수한 일반화를 달성하였으며, 5개의 벤치마크에서 PSNR, 4개의 벤치마크에서 SSIM에서 최첨단 성능을 기록하였습니다.


---

*Generated on 2025-09-24 05:18:55*