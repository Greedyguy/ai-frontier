---
keywords:
  - DA-Mamba
  - Multimodal Learning
  - Dialogue-Aware Encoder
  - Modality-Group Fusion
  - Partner-Group Fusion
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.17711
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T23:03:06.915877",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "DA-Mamba",
    "Multimodal Learning",
    "Dialogue-Aware Encoder",
    "Modality-Group Fusion",
    "Partner-Group Fusion"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "DA-Mamba": 0.8,
    "Multimodal Learning": 0.78,
    "Dialogue-Aware Encoder": 0.77,
    "Modality-Group Fusion": 0.75,
    "Partner-Group Fusion": 0.74
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "DA-Mamba",
        "canonical": "DA-Mamba",
        "aliases": [
          "Dialogue-aware Mamba"
        ],
        "category": "unique_technical",
        "rationale": "DA-Mamba is a novel architecture introduced in the paper, making it a unique technical concept.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "Multimodal engagement estimation",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal engagement"
        ],
        "category": "specific_connectable",
        "rationale": "Multimodal engagement estimation is a specific application of multimodal learning, which is a trending concept.",
        "novelty_score": 0.7,
        "connectivity_score": 0.85,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Dialogue-Aware Encoder",
        "canonical": "Dialogue-Aware Encoder",
        "aliases": [
          "Dialogue Encoder"
        ],
        "category": "unique_technical",
        "rationale": "The Dialogue-Aware Encoder is a core component of the proposed model, highlighting its unique role.",
        "novelty_score": 0.75,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      },
      {
        "surface": "Modality-Group Fusion",
        "canonical": "Modality-Group Fusion",
        "aliases": [
          "Modality Fusion"
        ],
        "category": "unique_technical",
        "rationale": "Modality-Group Fusion is a specific fusion mechanism introduced in the paper, emphasizing its unique technical contribution.",
        "novelty_score": 0.8,
        "connectivity_score": 0.68,
        "specificity_score": 0.88,
        "link_intent_score": 0.75
      },
      {
        "surface": "Partner-Group Fusion",
        "canonical": "Partner-Group Fusion",
        "aliases": [
          "Partner Fusion"
        ],
        "category": "unique_technical",
        "rationale": "Partner-Group Fusion is another fusion mechanism that is central to the proposed model, adding to its uniqueness.",
        "novelty_score": 0.78,
        "connectivity_score": 0.66,
        "specificity_score": 0.87,
        "link_intent_score": 0.74
      }
    ],
    "ban_list_suggestions": [
      "adaptive tutoring",
      "remote healthcare assessment",
      "socially aware human-computer interaction"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "DA-Mamba",
      "resolved_canonical": "DA-Mamba",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Multimodal engagement estimation",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.85,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Dialogue-Aware Encoder",
      "resolved_canonical": "Dialogue-Aware Encoder",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Modality-Group Fusion",
      "resolved_canonical": "Modality-Group Fusion",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.68,
        "specificity": 0.88,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Partner-Group Fusion",
      "resolved_canonical": "Partner-Group Fusion",
      "decision": "linked",
      "scores": {
        "novelty": 0.78,
        "connectivity": 0.66,
        "specificity": 0.87,
        "link_intent": 0.74
      }
    }
  ]
}
-->

# DA-Mamba: Dialogue-aware selective state-space model for multimodal engagement estimation

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17711.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.17711](https://arxiv.org/abs/2509.17711)

## 🔗 유사한 논문
- [[2025-09-19/Towards Human-like Multimodal Conversational Agent by Generating Engaging Speech_20250919|Towards Human-like Multimodal Conversational Agent by Generating Engaging Speech]] (83.2% similar)
- [[2025-09-19/A Multi-To-One Interview Paradigm for Efficient MLLM Evaluation_20250919|A Multi-To-One Interview Paradigm for Efficient MLLM Evaluation]] (81.8% similar)
- [[2025-09-22/DC-Mamba_ Bi-temporal deformable alignment and scale-sparse enhancement for remote sensing change detection_20250922|DC-Mamba: Bi-temporal deformable alignment and scale-sparse enhancement for remote sensing change detection]] (81.3% similar)
- [[2025-09-22/MEDAL_ A Framework for Benchmarking LLMs as Multilingual Open-Domain Dialogue Evaluators_20250922|MEDAL: A Framework for Benchmarking LLMs as Multilingual Open-Domain Dialogue Evaluators]] (81.2% similar)
- [[2025-09-18/MUSE_ MCTS-Driven Red Teaming Framework for Enhanced Multi-Turn Dialogue Safety in Large Language Models_20250918|MUSE: MCTS-Driven Red Teaming Framework for Enhanced Multi-Turn Dialogue Safety in Large Language Models]] (81.0% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**⚡ Unique Technical**: [[keywords/DA-Mamba|DA-Mamba]], [[keywords/Dialogue-Aware Encoder|Dialogue-Aware Encoder]], [[keywords/Modality-Group Fusion|Modality-Group Fusion]], [[keywords/Partner-Group Fusion|Partner-Group Fusion]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.17711v1 Announce Type: new 
Abstract: Human engagement estimation in conversational scenarios is essential for applications such as adaptive tutoring, remote healthcare assessment, and socially aware human--computer interaction. Engagement is a dynamic, multimodal signal conveyed by facial expressions, speech, gestures, and behavioral cues over time. In this work we introduce DA-Mamba, a dialogue-aware multimodal architecture that replaces attention-heavy dialogue encoders with Mamba-based selective state-space processing to achieve linear time and memory complexity while retaining expressive cross-modal reasoning. We design a Mamba dialogue-aware selective state-space model composed of three core modules: a Dialogue-Aware Encoder, and two Mamba-based fusion mechanisms: Modality-Group Fusion and Partner-Group Fusion, these modules achieve expressive dialogue understanding. Extensive experiments on three standard benchmarks (NoXi, NoXi-Add, and MPIIGI) show that DA-Mamba surpasses prior state-of-the-art (SOTA) methods in concordance correlation coefficient (CCC), while reducing training time and peak memory; these gains enable processing much longer sequences and facilitate real-time deployment in resource-constrained, multi-party conversational settings. The source code will be available at: https://github.com/kksssssss-ssda/MMEA.

## 📝 요약

이 논문은 대화 상황에서의 인간 참여도 추정을 위한 DA-Mamba라는 대화 인식 멀티모달 아키텍처를 소개합니다. DA-Mamba는 주의 기반 대화 인코더를 대체하여 선형 시간 및 메모리 복잡성을 유지하면서도 표현력 있는 교차 모달 추론을 제공합니다. 이 모델은 대화 인식 인코더와 두 가지 Mamba 기반 융합 메커니즘으로 구성되어 있으며, 이를 통해 대화 이해를 향상시킵니다. NoXi, NoXi-Add, MPIIGI 등 세 가지 표준 벤치마크 실험에서 DA-Mamba는 기존 최첨단 방법보다 우수한 일치 상관 계수를 기록하며, 학습 시간과 메모리 사용을 줄였습니다. 이는 자원이 제한된 다자 대화 환경에서 실시간 처리를 가능하게 합니다.

## 🎯 주요 포인트

- 1. DA-Mamba는 주의 기반 대화 인코더를 대체하여 선형 시간 및 메모리 복잡성을 달성하면서도 표현력 있는 교차 모달 추론을 유지합니다.
- 2. Mamba 기반 선택적 상태 공간 처리를 통해 대화 인식 멀티모달 아키텍처를 구현하였습니다.
- 3. DA-Mamba는 세 가지 핵심 모듈로 구성되어 있으며, 대화 인식 인코더와 두 가지 Mamba 기반 융합 메커니즘(모달리티 그룹 융합 및 파트너 그룹 융합)을 포함합니다.
- 4. NoXi, NoXi-Add, MPIIGI 등 세 가지 표준 벤치마크에서 DA-Mamba는 기존 최첨단 방법보다 우수한 성능을 보이며, 훈련 시간과 메모리 사용량을 줄입니다.
- 5. DA-Mamba의 성능 향상은 자원이 제한된 다자간 대화 환경에서 실시간 배포를 용이하게 합니다.


---

*Generated on 2025-09-23 23:03:06*