---
keywords:
  - Large Language Model
  - Attention Mechanism
  - Multiple-Instance Learning
  - Emotion, Logic, and Behavior components
  - Cognitive Distortion Detection
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.17292
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T23:51:15.606498",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Attention Mechanism",
    "Multiple-Instance Learning",
    "Emotion, Logic, and Behavior components",
    "Cognitive Distortion Detection"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Attention Mechanism": 0.82,
    "Multiple-Instance Learning": 0.78,
    "Emotion, Logic, and Behavior components": 0.8,
    "Cognitive Distortion Detection": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are central to the proposed framework and connect well with existing NLP concepts.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Multi-View Gated Attention",
        "canonical": "Attention Mechanism",
        "aliases": [
          "Gated Attention"
        ],
        "category": "specific_connectable",
        "rationale": "This mechanism is a specific application of attention, enhancing its connectivity with attention-based models.",
        "novelty_score": 0.58,
        "connectivity_score": 0.87,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "Multiple-Instance Learning",
        "canonical": "Multiple-Instance Learning",
        "aliases": [
          "MIL"
        ],
        "category": "unique_technical",
        "rationale": "This is a unique approach within the framework, providing specific insights into learning methods.",
        "novelty_score": 0.72,
        "connectivity_score": 0.65,
        "specificity_score": 0.81,
        "link_intent_score": 0.78
      },
      {
        "surface": "Emotion, Logic, and Behavior components",
        "canonical": "Emotion, Logic, and Behavior components",
        "aliases": [
          "ELB components"
        ],
        "category": "unique_technical",
        "rationale": "These components are unique to the paper's methodology, offering a novel perspective on cognitive distortion detection.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Cognitive Distortion Detection",
        "canonical": "Cognitive Distortion Detection",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This is the core application of the paper, crucial for linking mental health and NLP research.",
        "novelty_score": 0.68,
        "connectivity_score": 0.7,
        "specificity_score": 0.82,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "automatic detection",
      "classification performance",
      "psychologically grounded"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Multi-View Gated Attention",
      "resolved_canonical": "Attention Mechanism",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.87,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Multiple-Instance Learning",
      "resolved_canonical": "Multiple-Instance Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.65,
        "specificity": 0.81,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Emotion, Logic, and Behavior components",
      "resolved_canonical": "Emotion, Logic, and Behavior components",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Cognitive Distortion Detection",
      "resolved_canonical": "Cognitive Distortion Detection",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.7,
        "specificity": 0.82,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Multi-View Attention Multiple-Instance Learning Enhanced by LLM Reasoning for Cognitive Distortion Detection

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17292.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.17292](https://arxiv.org/abs/2509.17292)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/A Layered Multi-Expert Framework for Long-Context Mental Health Assessments_20250922|A Layered Multi-Expert Framework for Long-Context Mental Health Assessments]] (85.7% similar)
- [[2025-09-22/It Depends_ Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge_20250922|It Depends: Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge]] (83.2% similar)
- [[2025-09-17/DSCC-HS_ A Dynamic Self-Reinforcing Framework for Hallucination Suppression in Large Language Models_20250917|DSCC-HS: A Dynamic Self-Reinforcing Framework for Hallucination Suppression in Large Language Models]] (83.1% similar)
- [[2025-09-23/AIPsychoBench_ Understanding the Psychometric Differences between LLMs and Humans_20250923|AIPsychoBench: Understanding the Psychometric Differences between LLMs and Humans]] (82.5% similar)
- [[2025-09-22/Quantifying Self-Awareness of Knowledge in Large Language Models_20250922|Quantifying Self-Awareness of Knowledge in Large Language Models]] (82.4% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Attention Mechanism|Attention Mechanism]]
**âš¡ Unique Technical**: [[keywords/Multiple-Instance Learning|Multiple-Instance Learning]], [[keywords/Emotion, Logic, and Behavior components|Emotion, Logic, and Behavior components]], [[keywords/Cognitive Distortion Detection|Cognitive Distortion Detection]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17292v1 Announce Type: cross 
Abstract: Cognitive distortions have been closely linked to mental health disorders, yet their automatic detection remained challenging due to contextual ambiguity, co-occurrence, and semantic overlap. We proposed a novel framework that combines Large Language Models (LLMs) with Multiple-Instance Learning (MIL) architecture to enhance interpretability and expression-level reasoning. Each utterance was decomposed into Emotion, Logic, and Behavior (ELB) components, which were processed by LLMs to infer multiple distortion instances, each with a predicted type, expression, and model-assigned salience score. These instances were integrated via a Multi-View Gated Attention mechanism for final classification. Experiments on Korean (KoACD) and English (Therapist QA) datasets demonstrate that incorporating ELB and LLM-inferred salience scores improves classification performance, especially for distortions with high interpretive ambiguity. Our results suggested a psychologically grounded and generalizable approach for fine-grained reasoning in mental health NLP.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì •ì‹  ê±´ê°• ì¥ì• ì™€ ê´€ë ¨ëœ ì¸ì§€ ì™œê³¡ì˜ ìë™ íƒì§€ë¥¼ ê°œì„ í•˜ê¸° ìœ„í•´ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ê³¼ ë‹¤ì¤‘ ì¸ìŠ¤í„´ìŠ¤ í•™ìŠµ(MIL) ì•„í‚¤í…ì²˜ë¥¼ ê²°í•©í•œ ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê° ë°œí™”ë¥¼ ê°ì •, ë…¼ë¦¬, í–‰ë™(ELB) ìš”ì†Œë¡œ ë¶„í•´í•˜ì—¬ LLMsê°€ ë‹¤ì–‘í•œ ì™œê³¡ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì¶”ë¡ í•˜ë„ë¡ í•˜ì˜€ìœ¼ë©°, ì´ë¥¼ í†µí•´ ì˜ˆì¸¡ ìœ í˜•, í‘œí˜„, ì¤‘ìš”ë„ ì ìˆ˜ë¥¼ í• ë‹¹í–ˆìŠµë‹ˆë‹¤. ìµœì¢… ë¶„ë¥˜ëŠ” ë‹¤ì¤‘ ë·° ê²Œì´íŠ¸ ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´ ì´ë£¨ì–´ì¡ŒìŠµë‹ˆë‹¤. í•œêµ­ì–´(KoACD)ì™€ ì˜ì–´(Therapist QA) ë°ì´í„°ì…‹ ì‹¤í—˜ ê²°ê³¼, ELBì™€ LLM ê¸°ë°˜ ì¤‘ìš”ë„ ì ìˆ˜ë¥¼ í™œìš©í•˜ë©´ í•´ì„ì  ëª¨í˜¸ì„±ì´ ë†’ì€ ì™œê³¡ì˜ ë¶„ë¥˜ ì„±ëŠ¥ì´ í–¥ìƒë¨ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤. ì´ëŠ” ì •ì‹  ê±´ê°• ìì—°ì–´ ì²˜ë¦¬(NLP)ì—ì„œ ì‹¬ë¦¬ì ìœ¼ë¡œ ê·¼ê±° ìˆëŠ” ì„¸ë°€í•œ ì¶”ë¡  ì ‘ê·¼ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì¸ì§€ ì™œê³¡ì˜ ìë™ íƒì§€ê°€ ë¬¸ë§¥ì  ëª¨í˜¸ì„±, ë™ì‹œ ë°œìƒ, ì˜ë¯¸ì  ì¤‘ì²© ë•Œë¬¸ì— ì–´ë ¤ì›€ì„ ê²ªê³  ìˆìŠµë‹ˆë‹¤.
- 2. ë³¸ ì—°êµ¬ëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ê³¼ ë‹¤ì¤‘ ì¸ìŠ¤í„´ìŠ¤ í•™ìŠµ(MIL) ì•„í‚¤í…ì²˜ë¥¼ ê²°í•©í•œ ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.
- 3. ë°œí™”ëŠ” ê°ì •, ë…¼ë¦¬, í–‰ë™(ELB) êµ¬ì„± ìš”ì†Œë¡œ ë¶„í•´ë˜ì–´ LLMsì— ì˜í•´ ë‹¤ì–‘í•œ ì™œê³¡ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì¶”ë¡ í•©ë‹ˆë‹¤.
- 4. í•œêµ­ì–´(KoACD)ì™€ ì˜ì–´(Therapist QA) ë°ì´í„°ì…‹ ì‹¤í—˜ì—ì„œ ELBì™€ LLM ì¶”ë¡  ì¤‘ìš”ë„ ì ìˆ˜ë¥¼ í¬í•¨í•˜ë©´ ë¶„ë¥˜ ì„±ëŠ¥ì´ í–¥ìƒë¨ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.
- 5. ë³¸ ì—°êµ¬ëŠ” ì •ì‹  ê±´ê°• NLPì—ì„œ ì„¸ë°€í•œ ì¶”ë¡ ì„ ìœ„í•œ ì‹¬ë¦¬í•™ì ìœ¼ë¡œ ê·¼ê±° ìˆê³  ì¼ë°˜í™” ê°€ëŠ¥í•œ ì ‘ê·¼ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤.


---

*Generated on 2025-09-23 23:51:15*