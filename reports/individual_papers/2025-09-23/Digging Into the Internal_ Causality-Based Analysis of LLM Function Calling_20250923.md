---
keywords:
  - Function Calling
  - Large Language Model
  - Causal Interventions
  - Safety Robustness
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.16268
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T23:10:35.570559",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Function Calling",
    "Large Language Model",
    "Causal Interventions",
    "Safety Robustness"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Function Calling": 0.78,
    "Large Language Model": 0.8,
    "Causal Interventions": 0.77,
    "Safety Robustness": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Function Calling",
        "canonical": "Function Calling",
        "aliases": [
          "FC"
        ],
        "category": "unique_technical",
        "rationale": "Function Calling is central to the paper's analysis and offers a unique perspective on LLM interaction.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "The study focuses on LLMs, which are a fundamental component in the discussed techniques.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Causal Interventions",
        "canonical": "Causal Interventions",
        "aliases": [
          "causal analysis"
        ],
        "category": "specific_connectable",
        "rationale": "Causal interventions are key to understanding the internal mechanisms of LLMs in the study.",
        "novelty_score": 0.68,
        "connectivity_score": 0.72,
        "specificity_score": 0.78,
        "link_intent_score": 0.77
      },
      {
        "surface": "Safety Robustness",
        "canonical": "Safety Robustness",
        "aliases": [
          "LLM safety"
        ],
        "category": "specific_connectable",
        "rationale": "Enhancing safety robustness is a critical application scenario discussed in the paper.",
        "novelty_score": 0.6,
        "connectivity_score": 0.7,
        "specificity_score": 0.82,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Function Calling",
      "resolved_canonical": "Function Calling",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Causal Interventions",
      "resolved_canonical": "Causal Interventions",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.72,
        "specificity": 0.78,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Safety Robustness",
      "resolved_canonical": "Safety Robustness",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.7,
        "specificity": 0.82,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Digging Into the Internal: Causality-Based Analysis of LLM Function Calling

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16268.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.16268](https://arxiv.org/abs/2509.16268)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates_20250923|Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates]] (86.8% similar)
- [[2025-09-19/From Capabilities to Performance_ Evaluating Key Functional Properties of LLM Architectures in Penetration Testing_20250919|From Capabilities to Performance: Evaluating Key Functional Properties of LLM Architectures in Penetration Testing]] (85.1% similar)
- [[2025-09-23/Correlation or Causation_ Analyzing the Causal Structures of LLM and LRM Reasoning Process_20250923|Correlation or Causation: Analyzing the Causal Structures of LLM and LRM Reasoning Process]] (83.8% similar)
- [[2025-09-22/Can Large Language Models Infer Causal Relationships from Real-World Text?_20250922|Can Large Language Models Infer Causal Relationships from Real-World Text?]] (83.6% similar)
- [[2025-09-22/Calibrating LLM Confidence by Probing Perturbed Representation Stability_20250922|Calibrating LLM Confidence by Probing Perturbed Representation Stability]] (83.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Causal Interventions|Causal Interventions]], [[keywords/Safety Robustness|Safety Robustness]]
**âš¡ Unique Technical**: [[keywords/Function Calling|Function Calling]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16268v1 Announce Type: cross 
Abstract: Function calling (FC) has emerged as a powerful technique for facilitating large language models (LLMs) to interact with external systems and perform structured tasks. However, the mechanisms through which it influences model behavior remain largely under-explored. Besides, we discover that in addition to the regular usage of FC, this technique can substantially enhance the compliance of LLMs with user instructions. These observations motivate us to leverage causality, a canonical analysis method, to investigate how FC works within LLMs. In particular, we conduct layer-level and token-level causal interventions to dissect FC's impact on the model's internal computational logic when responding to user queries. Our analysis confirms the substantial influence of FC and reveals several in-depth insights into its mechanisms. To further validate our findings, we conduct extensive experiments comparing the effectiveness of FC-based instructions against conventional prompting methods. We focus on enhancing LLM safety robustness, a critical LLM application scenario, and evaluate four mainstream LLMs across two benchmark datasets. The results are striking: FC shows an average performance improvement of around 135% over conventional prompting methods in detecting malicious inputs, demonstrating its promising potential to enhance LLM reliability and capability in practical applications.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ í•¨ìˆ˜ í˜¸ì¶œ(FC)ì´ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ê³¼ ì™¸ë¶€ ì‹œìŠ¤í…œ ê°„ì˜ ìƒí˜¸ì‘ìš©ì„ ì´‰ì§„í•˜ëŠ” ê°•ë ¥í•œ ê¸°ë²•ìœ¼ë¡œ ì£¼ëª©ë°›ê³  ìˆìœ¼ë©°, ëª¨ë¸ì˜ í–‰ë™ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì— ëŒ€í•œ ì—°êµ¬ê°€ ë¶€ì¡±í•˜ë‹¤ëŠ” ì ì„ ì§€ì í•©ë‹ˆë‹¤. ì—°êµ¬ì§„ì€ FCê°€ ì‚¬ìš©ì ì§€ì‹œì‚¬í•­ì— ëŒ€í•œ LLMì˜ ì¤€ìˆ˜ì„±ì„ í¬ê²Œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŒì„ ë°œê²¬í•˜ê³ , ì¸ê³¼ì„±ì„ í™œìš©í•´ FCê°€ LLM ë‚´ë¶€ì—ì„œ ì–´ë–»ê²Œ ì‘ìš©í•˜ëŠ”ì§€ ì¡°ì‚¬í–ˆìŠµë‹ˆë‹¤. ì¸µ ìˆ˜ì¤€ê³¼ í† í° ìˆ˜ì¤€ì—ì„œì˜ ì¸ê³¼ì  ê°œì…ì„ í†µí•´ FCê°€ ëª¨ë¸ì˜ ë‚´ë¶€ ê³„ì‚° ë…¼ë¦¬ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•œ ê²°ê³¼, FCì˜ ìƒë‹¹í•œ ì˜í–¥ë ¥ê³¼ ê·¸ ë©”ì»¤ë‹ˆì¦˜ì— ëŒ€í•œ ì‹¬ë„ ìˆëŠ” í†µì°°ì„ ì–»ì—ˆìŠµë‹ˆë‹¤. ë˜í•œ, FC ê¸°ë°˜ ì§€ì‹œì™€ ê¸°ì¡´ì˜ í”„ë¡¬í”„íŠ¸ ë°©ë²•ì„ ë¹„êµí•˜ëŠ” ì‹¤í—˜ì„ í†µí•´ LLMì˜ ì•ˆì „ì„± ë° ì•…ì˜ì  ì…ë ¥ íƒì§€ ì„±ëŠ¥ì„ í‰ê°€í•œ ê²°ê³¼, FCê°€ í‰ê· ì ìœ¼ë¡œ ì•½ 135%ì˜ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì´ë©°, LLMì˜ ì‹ ë¢°ì„±ê³¼ ê¸°ëŠ¥ì„ ê°•í™”í•  ìˆ˜ ìˆëŠ” ì ì¬ë ¥ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. í•¨ìˆ˜ í˜¸ì¶œ(FC)ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì´ ì™¸ë¶€ ì‹œìŠ¤í…œê³¼ ìƒí˜¸ì‘ìš©í•˜ê³  êµ¬ì¡°í™”ëœ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë° ì¤‘ìš”í•œ ê¸°ìˆ ë¡œ ë¶€ìƒí–ˆìŠµë‹ˆë‹¤.
- 2. FCëŠ” LLMì´ ì‚¬ìš©ì ì§€ì‹œë¥¼ ë”°ë¥´ëŠ” ëŠ¥ë ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- 3. ì¸ê³¼ê´€ê³„ë¥¼ í™œìš©í•˜ì—¬ FCê°€ LLM ë‚´ë¶€ì—ì„œ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€ ì¡°ì‚¬í•˜ì˜€ìŠµë‹ˆë‹¤.
- 4. FC ê¸°ë°˜ ì§€ì‹œì™€ ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ ë°©ë²•ì˜ íš¨ê³¼ë¥¼ ë¹„êµí•˜ëŠ” ì‹¤í—˜ì„ í†µí•´ FCì˜ ìƒë‹¹í•œ ì„±ëŠ¥ í–¥ìƒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.
- 5. FCëŠ” ì•…ì˜ì ì¸ ì…ë ¥ì„ ê°ì§€í•˜ëŠ” ë° ìˆì–´ ê¸°ì¡´ ë°©ë²•ë³´ë‹¤ í‰ê·  135%ì˜ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì—¬, LLMì˜ ì‹ ë¢°ì„±ê³¼ ê¸°ëŠ¥ì„ ê°•í™”í•  ìˆ˜ ìˆëŠ” ì ì¬ë ¥ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-23 23:10:35*