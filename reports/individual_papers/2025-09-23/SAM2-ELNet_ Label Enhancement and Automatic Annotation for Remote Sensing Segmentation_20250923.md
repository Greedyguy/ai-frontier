---
keywords:
  - Remote Sensing Segmentation
  - Automatic Annotation
  - Synthetic Aperture Radar
  - Very High Resolution Imagery
  - Label Enhancement
category: cs.CV
publish_date: 2025-09-23
arxiv_id: 2503.12404
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T05:19:43.321762",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Remote Sensing Segmentation",
    "Automatic Annotation",
    "Synthetic Aperture Radar",
    "Very High Resolution Imagery",
    "Label Enhancement"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Remote Sensing Segmentation": 0.78,
    "Automatic Annotation": 0.77,
    "Synthetic Aperture Radar": 0.79,
    "Very High Resolution Imagery": 0.75,
    "Label Enhancement": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Remote Sensing Segmentation",
        "canonical": "Remote Sensing Segmentation",
        "aliases": [
          "RS Segmentation"
        ],
        "category": "unique_technical",
        "rationale": "This is a specialized task within remote sensing, crucial for environmental applications, and not covered by existing canonical terms.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Automatic Annotation",
        "canonical": "Automatic Annotation",
        "aliases": [
          "Auto Annotation"
        ],
        "category": "unique_technical",
        "rationale": "This concept is central to the paper's contribution and enhances connectivity with machine learning and data processing fields.",
        "novelty_score": 0.65,
        "connectivity_score": 0.72,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      },
      {
        "surface": "Synthetic Aperture Radar",
        "canonical": "Synthetic Aperture Radar",
        "aliases": [
          "SAR"
        ],
        "category": "specific_connectable",
        "rationale": "SAR is a key technology in remote sensing, providing unique data types for segmentation tasks.",
        "novelty_score": 0.58,
        "connectivity_score": 0.85,
        "specificity_score": 0.82,
        "link_intent_score": 0.79
      },
      {
        "surface": "Very High Resolution Optical Imagery",
        "canonical": "Very High Resolution Imagery",
        "aliases": [
          "VHR Imagery"
        ],
        "category": "specific_connectable",
        "rationale": "VHR imagery is critical for detailed analysis and segmentation in remote sensing, linking to high-resolution data processing.",
        "novelty_score": 0.6,
        "connectivity_score": 0.8,
        "specificity_score": 0.78,
        "link_intent_score": 0.75
      },
      {
        "surface": "Label Enhancement",
        "canonical": "Label Enhancement",
        "aliases": [
          "Label Improvement"
        ],
        "category": "unique_technical",
        "rationale": "This process is vital for improving annotation quality, directly impacting model training and performance.",
        "novelty_score": 0.7,
        "connectivity_score": 0.7,
        "specificity_score": 0.76,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "environmental monitoring",
      "disaster assessment",
      "resource management"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Remote Sensing Segmentation",
      "resolved_canonical": "Remote Sensing Segmentation",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Automatic Annotation",
      "resolved_canonical": "Automatic Annotation",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.72,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Synthetic Aperture Radar",
      "resolved_canonical": "Synthetic Aperture Radar",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.85,
        "specificity": 0.82,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Very High Resolution Optical Imagery",
      "resolved_canonical": "Very High Resolution Imagery",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.8,
        "specificity": 0.78,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Label Enhancement",
      "resolved_canonical": "Label Enhancement",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.7,
        "specificity": 0.76,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# SAM2-ELNet: Label Enhancement and Automatic Annotation for Remote Sensing Segmentation

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2503.12404.pdf)
**Category**: cs.CV
**Published**: 2025-09-23
**ArXiv ID**: [2503.12404](https://arxiv.org/abs/2503.12404)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/LLM-Assisted Semantic Guidance for Sparsely Annotated Remote Sensing Object Detection_20250923|LLM-Assisted Semantic Guidance for Sparsely Annotated Remote Sensing Object Detection]] (86.1% similar)
- [[2025-09-22/pFedSAM_ Personalized Federated Learning of Segment Anything Model for Medical Image Segmentation_20250922|pFedSAM: Personalized Federated Learning of Segment Anything Model for Medical Image Segmentation]] (82.4% similar)
- [[2025-09-23/An Efficient Dual-Line Decoder Network with Multi-Scale Convolutional Attention for Multi-organ Segmentation_20250923|An Efficient Dual-Line Decoder Network with Multi-Scale Convolutional Attention for Multi-organ Segmentation]] (82.4% similar)
- [[2025-09-22/TASAM_ Terrain-and-Aware Segment Anything Model for Temporal-Scale Remote Sensing Segmentation_20250922|TASAM: Terrain-and-Aware Segment Anything Model for Temporal-Scale Remote Sensing Segmentation]] (82.3% similar)
- [[2025-09-23/Catching the Details_ Self-Distilled RoI Predictors for Fine-Grained MLLM Perception_20250923|Catching the Details: Self-Distilled RoI Predictors for Fine-Grained MLLM Perception]] (82.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Synthetic Aperture Radar|Synthetic Aperture Radar]], [[keywords/Very High Resolution Imagery|Very High Resolution Imagery]]
**âš¡ Unique Technical**: [[keywords/Remote Sensing Segmentation|Remote Sensing Segmentation]], [[keywords/Automatic Annotation|Automatic Annotation]], [[keywords/Label Enhancement|Label Enhancement]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2503.12404v2 Announce Type: replace 
Abstract: Remote sensing image segmentation is crucial for environmental monitoring, disaster assessment, and resource management, but its performance largely depends on the quality of the dataset. Although several high-quality datasets are broadly accessible, data scarcity remains for specialized tasks like marine oil spill segmentation. Such tasks still rely on manual annotation, which is both time-consuming and influenced by subjective human factors. The segment anything model 2 (SAM2) has strong potential as an automatic annotation framework but struggles to perform effectively on heterogeneous, low-contrast remote sensing imagery. To address these challenges, we introduce a novel label enhancement and automatic annotation framework, termed SAM2-ELNet (Enhancement and Labeling Network). Specifically, we employ the frozen Hiera backbone from the pretrained SAM2 as the encoder, while fine-tuning the adapter and decoder for different remote sensing tasks. In addition, the proposed framework includes a label quality evaluator for filtering, ensuring the reliability of the generated labels. We design a series of experiments targeting resource-limited remote sensing tasks and evaluate our method on two datasets: the Deep-SAR Oil Spill (SOS) dataset with Synthetic Aperture Radar (SAR) imagery, and the CHN6-CUG Road dataset with Very High Resolution (VHR) optical imagery. The proposed framework can enhance coarse annotations and generate reliable training data under resource-limited conditions. Fine-tuned on only 30% of the training data, it generates automatically labeled data. A model trained solely on these achieves slightly lower performance than using the full original annotations, while greatly reducing labeling costs and offering a practical solution for large-scale remote sensing interpretation.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì›ê²© ê°ì§€ ì´ë¯¸ì§€ ë¶„í• ì˜ ì„±ëŠ¥ì„ ê°œì„ í•˜ê¸° ìœ„í•œ SAM2-ELNetì´ë¼ëŠ” ìƒˆë¡œìš´ ìë™ ì£¼ì„ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. SAM2-ELNetì€ SAM2ì˜ ì‚¬ì „ í•™ìŠµëœ Hiera ë°±ë³¸ì„ ì¸ì½”ë”ë¡œ ì‚¬ìš©í•˜ê³ , ì–´ëŒ‘í„°ì™€ ë””ì½”ë”ë¥¼ ë¯¸ì„¸ ì¡°ì •í•˜ì—¬ ë‹¤ì–‘í•œ ì›ê²© ê°ì§€ ì‘ì—…ì— ì ìš©í•©ë‹ˆë‹¤. ë˜í•œ, ìƒì„±ëœ ë ˆì´ë¸”ì˜ ì‹ ë¢°ì„±ì„ ë³´ì¥í•˜ê¸° ìœ„í•´ ë ˆì´ë¸” í’ˆì§ˆ í‰ê°€ê¸°ë¥¼ í¬í•¨í•©ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ì œí•œëœ ìì› í™˜ê²½ì—ì„œì˜ ì›ê²© ê°ì§€ ì‘ì—…ì„ ëª©í‘œë¡œ í•˜ë©°, Deep-SAR Oil Spill ë°ì´í„°ì…‹ê³¼ CHN6-CUG Road ë°ì´í„°ì…‹ì—ì„œ í‰ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. ì œì•ˆëœ ë°©ë²•ì€ 30%ì˜ í›ˆë ¨ ë°ì´í„°ë§Œìœ¼ë¡œ ìë™ ë ˆì´ë¸”ë§ì„ ìˆ˜í–‰í•˜ë©°, ì „ì²´ ì›ë³¸ ì£¼ì„ì„ ì‚¬ìš©í•  ë•Œë³´ë‹¤ ì•½ê°„ ë‚®ì€ ì„±ëŠ¥ì„ ë³´ì´ì§€ë§Œ, ë ˆì´ë¸”ë§ ë¹„ìš©ì„ í¬ê²Œ ì¤„ì´ê³  ëŒ€ê·œëª¨ ì›ê²© ê°ì§€ í•´ì„ì— ì‹¤ìš©ì ì¸ ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì›ê²© ê°ì§€ ì´ë¯¸ì§€ ì„¸ë¶„í™”ëŠ” í™˜ê²½ ëª¨ë‹ˆí„°ë§, ì¬ë‚œ í‰ê°€ ë° ìì› ê´€ë¦¬ì— í•„ìˆ˜ì ì´ì§€ë§Œ, ë°ì´í„°ì…‹ì˜ í’ˆì§ˆì— í¬ê²Œ ì˜ì¡´í•©ë‹ˆë‹¤.
- 2. SAM2-ELNetì€ ë‹¤ì–‘í•œ ì›ê²© ê°ì§€ ì‘ì—…ì„ ìœ„í•œ ìë™ ì£¼ì„ í”„ë ˆì„ì›Œí¬ë¡œ, ì´ì§ˆì ì´ê³  ë‚®ì€ ëŒ€ë¹„ì˜ ì›ê²© ê°ì§€ ì´ë¯¸ì§€ì—ì„œ íš¨ê³¼ì ìœ¼ë¡œ ì‘ë™í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.
- 3. ì œì•ˆëœ í”„ë ˆì„ì›Œí¬ëŠ” ë¼ë²¨ í’ˆì§ˆ í‰ê°€ê¸°ë¥¼ í¬í•¨í•˜ì—¬ ìƒì„±ëœ ë¼ë²¨ì˜ ì‹ ë¢°ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤.
- 4. ì œí•œëœ ìì›ì˜ ì›ê²© ê°ì§€ ì‘ì—…ì—ì„œ ì œì•ˆëœ í”„ë ˆì„ì›Œí¬ëŠ” ê±°ì¹œ ì£¼ì„ì„ ê°œì„ í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” í•™ìŠµ ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- 5. ì „ì²´ ì›ë³¸ ì£¼ì„ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒë³´ë‹¤ ì•½ê°„ ë‚®ì€ ì„±ëŠ¥ì„ ë³´ì´ì§€ë§Œ, ë¼ë²¨ë§ ë¹„ìš©ì„ í¬ê²Œ ì¤„ì´ê³  ëŒ€ê·œëª¨ ì›ê²© ê°ì§€ í•´ì„ì— ì‹¤ìš©ì ì¸ ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 05:19:43*