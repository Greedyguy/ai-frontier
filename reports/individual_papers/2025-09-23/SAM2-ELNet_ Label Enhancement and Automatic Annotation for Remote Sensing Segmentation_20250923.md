---
keywords:
  - Remote Sensing Segmentation
  - Automatic Annotation
  - Synthetic Aperture Radar
  - Very High Resolution Imagery
  - Label Enhancement
category: cs.CV
publish_date: 2025-09-23
arxiv_id: 2503.12404
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T05:19:43.321762",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Remote Sensing Segmentation",
    "Automatic Annotation",
    "Synthetic Aperture Radar",
    "Very High Resolution Imagery",
    "Label Enhancement"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Remote Sensing Segmentation": 0.78,
    "Automatic Annotation": 0.77,
    "Synthetic Aperture Radar": 0.79,
    "Very High Resolution Imagery": 0.75,
    "Label Enhancement": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Remote Sensing Segmentation",
        "canonical": "Remote Sensing Segmentation",
        "aliases": [
          "RS Segmentation"
        ],
        "category": "unique_technical",
        "rationale": "This is a specialized task within remote sensing, crucial for environmental applications, and not covered by existing canonical terms.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Automatic Annotation",
        "canonical": "Automatic Annotation",
        "aliases": [
          "Auto Annotation"
        ],
        "category": "unique_technical",
        "rationale": "This concept is central to the paper's contribution and enhances connectivity with machine learning and data processing fields.",
        "novelty_score": 0.65,
        "connectivity_score": 0.72,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      },
      {
        "surface": "Synthetic Aperture Radar",
        "canonical": "Synthetic Aperture Radar",
        "aliases": [
          "SAR"
        ],
        "category": "specific_connectable",
        "rationale": "SAR is a key technology in remote sensing, providing unique data types for segmentation tasks.",
        "novelty_score": 0.58,
        "connectivity_score": 0.85,
        "specificity_score": 0.82,
        "link_intent_score": 0.79
      },
      {
        "surface": "Very High Resolution Optical Imagery",
        "canonical": "Very High Resolution Imagery",
        "aliases": [
          "VHR Imagery"
        ],
        "category": "specific_connectable",
        "rationale": "VHR imagery is critical for detailed analysis and segmentation in remote sensing, linking to high-resolution data processing.",
        "novelty_score": 0.6,
        "connectivity_score": 0.8,
        "specificity_score": 0.78,
        "link_intent_score": 0.75
      },
      {
        "surface": "Label Enhancement",
        "canonical": "Label Enhancement",
        "aliases": [
          "Label Improvement"
        ],
        "category": "unique_technical",
        "rationale": "This process is vital for improving annotation quality, directly impacting model training and performance.",
        "novelty_score": 0.7,
        "connectivity_score": 0.7,
        "specificity_score": 0.76,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "environmental monitoring",
      "disaster assessment",
      "resource management"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Remote Sensing Segmentation",
      "resolved_canonical": "Remote Sensing Segmentation",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Automatic Annotation",
      "resolved_canonical": "Automatic Annotation",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.72,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Synthetic Aperture Radar",
      "resolved_canonical": "Synthetic Aperture Radar",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.85,
        "specificity": 0.82,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Very High Resolution Optical Imagery",
      "resolved_canonical": "Very High Resolution Imagery",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.8,
        "specificity": 0.78,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Label Enhancement",
      "resolved_canonical": "Label Enhancement",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.7,
        "specificity": 0.76,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# SAM2-ELNet: Label Enhancement and Automatic Annotation for Remote Sensing Segmentation

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2503.12404.pdf)
**Category**: cs.CV
**Published**: 2025-09-23
**ArXiv ID**: [2503.12404](https://arxiv.org/abs/2503.12404)

## 🔗 유사한 논문
- [[2025-09-23/LLM-Assisted Semantic Guidance for Sparsely Annotated Remote Sensing Object Detection_20250923|LLM-Assisted Semantic Guidance for Sparsely Annotated Remote Sensing Object Detection]] (86.1% similar)
- [[2025-09-22/pFedSAM_ Personalized Federated Learning of Segment Anything Model for Medical Image Segmentation_20250922|pFedSAM: Personalized Federated Learning of Segment Anything Model for Medical Image Segmentation]] (82.4% similar)
- [[2025-09-23/An Efficient Dual-Line Decoder Network with Multi-Scale Convolutional Attention for Multi-organ Segmentation_20250923|An Efficient Dual-Line Decoder Network with Multi-Scale Convolutional Attention for Multi-organ Segmentation]] (82.4% similar)
- [[2025-09-22/TASAM_ Terrain-and-Aware Segment Anything Model for Temporal-Scale Remote Sensing Segmentation_20250922|TASAM: Terrain-and-Aware Segment Anything Model for Temporal-Scale Remote Sensing Segmentation]] (82.3% similar)
- [[2025-09-23/Catching the Details_ Self-Distilled RoI Predictors for Fine-Grained MLLM Perception_20250923|Catching the Details: Self-Distilled RoI Predictors for Fine-Grained MLLM Perception]] (82.3% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Synthetic Aperture Radar|Synthetic Aperture Radar]], [[keywords/Very High Resolution Imagery|Very High Resolution Imagery]]
**⚡ Unique Technical**: [[keywords/Remote Sensing Segmentation|Remote Sensing Segmentation]], [[keywords/Automatic Annotation|Automatic Annotation]], [[keywords/Label Enhancement|Label Enhancement]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2503.12404v2 Announce Type: replace 
Abstract: Remote sensing image segmentation is crucial for environmental monitoring, disaster assessment, and resource management, but its performance largely depends on the quality of the dataset. Although several high-quality datasets are broadly accessible, data scarcity remains for specialized tasks like marine oil spill segmentation. Such tasks still rely on manual annotation, which is both time-consuming and influenced by subjective human factors. The segment anything model 2 (SAM2) has strong potential as an automatic annotation framework but struggles to perform effectively on heterogeneous, low-contrast remote sensing imagery. To address these challenges, we introduce a novel label enhancement and automatic annotation framework, termed SAM2-ELNet (Enhancement and Labeling Network). Specifically, we employ the frozen Hiera backbone from the pretrained SAM2 as the encoder, while fine-tuning the adapter and decoder for different remote sensing tasks. In addition, the proposed framework includes a label quality evaluator for filtering, ensuring the reliability of the generated labels. We design a series of experiments targeting resource-limited remote sensing tasks and evaluate our method on two datasets: the Deep-SAR Oil Spill (SOS) dataset with Synthetic Aperture Radar (SAR) imagery, and the CHN6-CUG Road dataset with Very High Resolution (VHR) optical imagery. The proposed framework can enhance coarse annotations and generate reliable training data under resource-limited conditions. Fine-tuned on only 30% of the training data, it generates automatically labeled data. A model trained solely on these achieves slightly lower performance than using the full original annotations, while greatly reducing labeling costs and offering a practical solution for large-scale remote sensing interpretation.

## 📝 요약

이 논문은 원격 감지 이미지 분할의 성능을 개선하기 위한 SAM2-ELNet이라는 새로운 자동 주석 프레임워크를 제안합니다. SAM2-ELNet은 SAM2의 사전 학습된 Hiera 백본을 인코더로 사용하고, 어댑터와 디코더를 미세 조정하여 다양한 원격 감지 작업에 적용합니다. 또한, 생성된 레이블의 신뢰성을 보장하기 위해 레이블 품질 평가기를 포함합니다. 이 프레임워크는 제한된 자원 환경에서의 원격 감지 작업을 목표로 하며, Deep-SAR Oil Spill 데이터셋과 CHN6-CUG Road 데이터셋에서 평가되었습니다. 제안된 방법은 30%의 훈련 데이터만으로 자동 레이블링을 수행하며, 전체 원본 주석을 사용할 때보다 약간 낮은 성능을 보이지만, 레이블링 비용을 크게 줄이고 대규모 원격 감지 해석에 실용적인 솔루션을 제공합니다.

## 🎯 주요 포인트

- 1. 원격 감지 이미지 세분화는 환경 모니터링, 재난 평가 및 자원 관리에 필수적이지만, 데이터셋의 품질에 크게 의존합니다.
- 2. SAM2-ELNet은 다양한 원격 감지 작업을 위한 자동 주석 프레임워크로, 이질적이고 낮은 대비의 원격 감지 이미지에서 효과적으로 작동하도록 설계되었습니다.
- 3. 제안된 프레임워크는 라벨 품질 평가기를 포함하여 생성된 라벨의 신뢰성을 보장합니다.
- 4. 제한된 자원의 원격 감지 작업에서 제안된 프레임워크는 거친 주석을 개선하고 신뢰할 수 있는 학습 데이터를 생성할 수 있습니다.
- 5. 전체 원본 주석을 사용하는 것보다 약간 낮은 성능을 보이지만, 라벨링 비용을 크게 줄이고 대규모 원격 감지 해석에 실용적인 솔루션을 제공합니다.


---

*Generated on 2025-09-24 05:19:43*