---
keywords:
  - AI Fairness
  - Stakeholder Decision-Making
  - Fairness Metrics
  - Protected Features
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.17956
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T23:04:28.007391",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "AI Fairness",
    "Stakeholder Decision-Making",
    "Fairness Metrics",
    "Protected Features"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "AI Fairness": 0.79,
    "Stakeholder Decision-Making": 0.77,
    "Fairness Metrics": 0.8,
    "Protected Features": 0.81
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "AI Fairness Assessment",
        "canonical": "AI Fairness",
        "aliases": [
          "Fairness in AI",
          "AI Fairness Evaluation"
        ],
        "category": "unique_technical",
        "rationale": "AI Fairness is a specialized area that connects to broader discussions on ethical AI and governance.",
        "novelty_score": 0.65,
        "connectivity_score": 0.78,
        "specificity_score": 0.82,
        "link_intent_score": 0.79
      },
      {
        "surface": "Stakeholder Decision-Making",
        "canonical": "Stakeholder Decision-Making",
        "aliases": [
          "Stakeholder Choices",
          "Stakeholder Judgments"
        ],
        "category": "unique_technical",
        "rationale": "Understanding stakeholder decision-making is crucial for linking to governance and ethics in AI.",
        "novelty_score": 0.7,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      },
      {
        "surface": "Fairness Metrics",
        "canonical": "Fairness Metrics",
        "aliases": [
          "Equity Metrics",
          "Bias Metrics"
        ],
        "category": "specific_connectable",
        "rationale": "Fairness metrics are a key component in evaluating AI systems, linking to technical and ethical discussions.",
        "novelty_score": 0.58,
        "connectivity_score": 0.85,
        "specificity_score": 0.76,
        "link_intent_score": 0.8
      },
      {
        "surface": "Protected Features",
        "canonical": "Protected Features",
        "aliases": [
          "Sensitive Attributes",
          "Protected Attributes"
        ],
        "category": "specific_connectable",
        "rationale": "Protected features are central to discussions on bias and fairness in AI, connecting to legal and ethical frameworks.",
        "novelty_score": 0.6,
        "connectivity_score": 0.82,
        "specificity_score": 0.78,
        "link_intent_score": 0.81
      }
    ],
    "ban_list_suggestions": [
      "AI experts",
      "credit rating scenario"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "AI Fairness Assessment",
      "resolved_canonical": "AI Fairness",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.78,
        "specificity": 0.82,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Stakeholder Decision-Making",
      "resolved_canonical": "Stakeholder Decision-Making",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Fairness Metrics",
      "resolved_canonical": "Fairness Metrics",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.85,
        "specificity": 0.76,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Protected Features",
      "resolved_canonical": "Protected Features",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.82,
        "specificity": 0.78,
        "link_intent": 0.81
      }
    }
  ]
}
-->

# "I think this is fair'': Uncovering the Complexities of Stakeholder Decision-Making in AI Fairness Assessment

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17956.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.17956](https://arxiv.org/abs/2509.17956)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Algorithmic Fairness_ Not a Purely Technical but Socio-Technical Property_20250922|Algorithmic Fairness: Not a Purely Technical but Socio-Technical Property]] (86.7% similar)
- [[2025-09-22/Where Fact Ends and Fairness Begins_ Redefining AI Bias Evaluation through Cognitive Biases_20250922|Where Fact Ends and Fairness Begins: Redefining AI Bias Evaluation through Cognitive Biases]] (82.9% similar)
- [[2025-09-22/Who is Responsible When AI Fails? Mapping Causes, Entities, and Consequences of AI Privacy and Ethical Incidents_20250922|Who is Responsible When AI Fails? Mapping Causes, Entities, and Consequences of AI Privacy and Ethical Incidents]] (82.2% similar)
- [[2025-09-22/The Great AI Witch Hunt_ Reviewers Perception and (Mis)Conception of Generative AI in Research Writing_20250922|The Great AI Witch Hunt: Reviewers Perception and (Mis)Conception of Generative AI in Research Writing]] (81.7% similar)
- [[2025-09-22/Fairness-in-the-Workflow_ How Machine Learning Practitioners at Big Tech Companies Approach Fairness in Recommender Systems_20250922|Fairness-in-the-Workflow: How Machine Learning Practitioners at Big Tech Companies Approach Fairness in Recommender Systems]] (81.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Fairness Metrics|Fairness Metrics]], [[keywords/Protected Features|Protected Features]]
**âš¡ Unique Technical**: [[keywords/AI Fairness|AI Fairness]], [[keywords/Stakeholder Decision-Making|Stakeholder Decision-Making]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17956v1 Announce Type: new 
Abstract: Assessing fairness in artificial intelligence (AI) typically involves AI experts who select protected features, fairness metrics, and set fairness thresholds. However, little is known about how stakeholders, particularly those affected by AI outcomes but lacking AI expertise, assess fairness. To address this gap, we conducted a qualitative study with 30 stakeholders without AI expertise, representing potential decision subjects in a credit rating scenario, to examine how they assess fairness when placed in the role of deciding on features with priority, metrics, and thresholds. We reveal that stakeholders' fairness decisions are more complex than typical AI expert practices: they considered features far beyond legally protected features, tailored metrics for specific contexts, set diverse yet stricter fairness thresholds, and even preferred designing customized fairness. Our results extend the understanding of how stakeholders can meaningfully contribute to AI fairness governance and mitigation, underscoring the importance of incorporating stakeholders' nuanced fairness judgments.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ AI ê³µì •ì„± í‰ê°€ì—ì„œ AI ì „ë¬¸ê°€ê°€ ì•„ë‹Œ ì´í•´ê´€ê³„ìë“¤ì´ ì–´ë–»ê²Œ ê³µì •ì„±ì„ í‰ê°€í•˜ëŠ”ì§€ë¥¼ ì¡°ì‚¬í•©ë‹ˆë‹¤. AI ì „ë¬¸ ì§€ì‹ì´ ì—†ëŠ” 30ëª…ì˜ ì´í•´ê´€ê³„ìë¥¼ ëŒ€ìƒìœ¼ë¡œ ì‹ ìš© í‰ê°€ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ê³µì •ì„± íŒë‹¨ ê³¼ì •ì„ ì—°êµ¬í•œ ê²°ê³¼, ì´ë“¤ì€ ë²•ì ìœ¼ë¡œ ë³´í˜¸ë˜ëŠ” íŠ¹ì„± ì™¸ì—ë„ ë‹¤ì–‘í•œ íŠ¹ì„±ì„ ê³ ë ¤í•˜ê³ , íŠ¹ì • ë§¥ë½ì— ë§ì¶˜ ì§€í‘œë¥¼ ì‚¬ìš©í•˜ë©°, ë” ì—„ê²©í•œ ê³µì •ì„± ê¸°ì¤€ì„ ì„¤ì •í•˜ëŠ” ë“± ë³µì¡í•œ ê²°ì •ì„ ë‚´ë ¸ìŠµë‹ˆë‹¤. ì—°êµ¬ëŠ” ì´í•´ê´€ê³„ìì˜ ê³µì •ì„± íŒë‹¨ì´ AI ê³µì •ì„± ê´€ë¦¬ì™€ ì™„í™”ì— ì˜ë¯¸ ìˆëŠ” ê¸°ì—¬ë¥¼ í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì£¼ë©°, ì´ë“¤ì˜ ì„¸ë°€í•œ íŒë‹¨ì„ ë°˜ì˜í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤ê³  ê°•ì¡°í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. AI ì „ë¬¸ê°€ê°€ ì•„ë‹Œ ì´í•´ê´€ê³„ìë“¤ì€ ë²•ì ìœ¼ë¡œ ë³´í˜¸ëœ íŠ¹ì„±ì„ ë„˜ì–´ ë‹¤ì–‘í•œ íŠ¹ì„±ì„ ê³ ë ¤í•˜ì—¬ ê³µì •ì„±ì„ í‰ê°€í•©ë‹ˆë‹¤.
- 2. ì´í•´ê´€ê³„ìë“¤ì€ íŠ¹ì • ë§¥ë½ì— ë§ì¶˜ ë§ì¶¤í˜• ì§€í‘œë¥¼ ì„ í˜¸í•˜ë©°, ë” ë‹¤ì–‘í•˜ê³  ì—„ê²©í•œ ê³µì •ì„± ê¸°ì¤€ì„ ì„¤ì •í•©ë‹ˆë‹¤.
- 3. ì´í•´ê´€ê³„ìë“¤ì€ ë§ì¶¤í˜• ê³µì •ì„± ì„¤ê³„ë¥¼ ì„ í˜¸í•˜ë©°, ì´ëŠ” AI ê³µì •ì„± ê´€ë¦¬ì™€ ì™„í™”ì— ì˜ë¯¸ ìˆëŠ” ê¸°ì—¬ë¥¼ í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
- 4. ì—°êµ¬ ê²°ê³¼ëŠ” ì´í•´ê´€ê³„ìì˜ ì„¸ì‹¬í•œ ê³µì •ì„± íŒë‹¨ì„ AI ê³µì •ì„± ê±°ë²„ë„ŒìŠ¤ì— í†µí•©í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•¨ì„ ê°•ì¡°í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-23 23:04:28*