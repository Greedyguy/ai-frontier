---
keywords:
  - Large Language Model
  - Retrieval Augmented Generation
  - Rationale-Guided Retrieval Augmented Generation
  - Biomedical Corpus
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2411.00300
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:44:26.903187",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Retrieval Augmented Generation",
    "Rationale-Guided Retrieval Augmented Generation",
    "Biomedical Corpus"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Retrieval Augmented Generation": 0.88,
    "Rationale-Guided Retrieval Augmented Generation": 0.8,
    "Biomedical Corpus": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Large Language Models"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are central to the study and link well with other NLP concepts.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Retrieval Augmented Generation",
        "canonical": "Retrieval Augmented Generation",
        "aliases": [
          "RAG"
        ],
        "category": "specific_connectable",
        "rationale": "RAG is a key technique discussed in the paper and connects with retrieval and generation methods.",
        "novelty_score": 0.55,
        "connectivity_score": 0.9,
        "specificity_score": 0.8,
        "link_intent_score": 0.88
      },
      {
        "surface": "Rationale-Guided RAG",
        "canonical": "Rationale-Guided Retrieval Augmented Generation",
        "aliases": [
          "RAG^2"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel framework introduced in the paper, enhancing the reliability of RAG in biomedical contexts.",
        "novelty_score": 0.75,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Biomedical Corpora",
        "canonical": "Biomedical Corpus",
        "aliases": [
          "Biomedical Corpora"
        ],
        "category": "specific_connectable",
        "rationale": "Biomedical corpora are crucial for the retrieval process in the paper, linking to domain-specific datasets.",
        "novelty_score": 0.5,
        "connectivity_score": 0.78,
        "specificity_score": 0.72,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Retrieval Augmented Generation",
      "resolved_canonical": "Retrieval Augmented Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.9,
        "specificity": 0.8,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "Rationale-Guided RAG",
      "resolved_canonical": "Rationale-Guided Retrieval Augmented Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Biomedical Corpora",
      "resolved_canonical": "Biomedical Corpus",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.78,
        "specificity": 0.72,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Rationale-Guided Retrieval Augmented Generation for Medical Question Answering

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2411.00300.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2411.00300](https://arxiv.org/abs/2411.00300)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Causal-Counterfactual RAG_ The Integration of Causal-Counterfactual Reasoning into RAG_20250919|Causal-Counterfactual RAG: The Integration of Causal-Counterfactual Reasoning into RAG]] (88.4% similar)
- [[2025-09-23/GRIL_ Knowledge Graph Retrieval-Integrated Learning with Large Language Models_20250923|GRIL: Knowledge Graph Retrieval-Integrated Learning with Large Language Models]] (88.3% similar)
- [[2025-09-23/UR$^2$_ Unify RAG and Reasoning through Reinforcement Learning_20250923|UR$^2$: Unify RAG and Reasoning through Reinforcement Learning]] (87.7% similar)
- [[2025-09-19/Enhancing Retrieval Augmentation via Adversarial Collaboration_20250919|Enhancing Retrieval Augmentation via Adversarial Collaboration]] (87.7% similar)
- [[2025-09-23/Comparing RAG and GraphRAG for Page-Level Retrieval Question Answering on Math Textbook_20250923|Comparing RAG and GraphRAG for Page-Level Retrieval Question Answering on Math Textbook]] (87.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Retrieval Augmented Generation|Retrieval Augmented Generation]], [[keywords/Biomedical Corpus|Biomedical Corpus]]
**âš¡ Unique Technical**: [[keywords/Rationale-Guided Retrieval Augmented Generation|Rationale-Guided Retrieval Augmented Generation]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2411.00300v2 Announce Type: replace 
Abstract: Large language models (LLM) hold significant potential for applications in biomedicine, but they struggle with hallucinations and outdated knowledge. While retrieval-augmented generation (RAG) is generally employed to address these issues, it also has its own set of challenges: (1) LLMs are vulnerable to irrelevant or incorrect context, (2) medical queries are often not well-targeted for helpful information, and (3) retrievers are prone to bias toward the specific source corpus they were trained on. In this study, we present RAG$^2$ (RAtionale-Guided RAG), a new framework for enhancing the reliability of RAG in biomedical contexts. RAG$^2$ incorporates three key innovations: a small filtering model trained on perplexity-based labels of rationales, which selectively augments informative snippets of documents while filtering out distractors; LLM-generated rationales as queries to improve the utility of retrieved snippets; a structure designed to retrieve snippets evenly from a comprehensive set of four biomedical corpora, effectively mitigating retriever bias. Our experiments demonstrate that RAG$^2$ improves the state-of-the-art LLMs of varying sizes, with improvements of up to 6.1\%, and it outperforms the previous best medical RAG model by up to 5.6\% across three medical question-answering benchmarks. Our code is available at https://github.com/dmis-lab/RAG2.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ìƒì˜í•™ ë¶„ì•¼ì—ì„œ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì‹ ë¢°ì„±ì„ ë†’ì´ê¸° ìœ„í•œ ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ì¸ RAG$^2$ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ê²€ìƒ‰ ë³´ê°• ìƒì„±(RAG) ë°©ì‹ì´ ê°€ì§„ ë¬¸ì œì ì„ í•´ê²°í•˜ê¸° ìœ„í•´, RAG$^2$ëŠ” ì„¸ ê°€ì§€ í˜ì‹ ì„ ë„ì…í–ˆìŠµë‹ˆë‹¤. ì²«ì§¸, í•©ë¦¬ì„± ê¸°ë°˜ì˜ ë¼ë²¨ë¡œ í›ˆë ¨ëœ í•„í„°ë§ ëª¨ë¸ì„ í†µí•´ ìœ ìš©í•œ ì •ë³´ë§Œ ì„ íƒì ìœ¼ë¡œ ë³´ê°•í•©ë‹ˆë‹¤. ë‘˜ì§¸, LLMì´ ìƒì„±í•œ í•©ë¦¬ì„±ì„ ì¿¼ë¦¬ë¡œ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ëœ ì •ë³´ì˜ ìœ ìš©ì„±ì„ ë†’ì…ë‹ˆë‹¤. ì…‹ì§¸, ë„¤ ê°€ì§€ ìƒì˜í•™ ì½”í¼ìŠ¤ì—ì„œ ê³ ë¥´ê²Œ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ í¸í–¥ì„ ì¤„ì…ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, RAG$^2$ëŠ” ê¸°ì¡´ ìµœê³  ìˆ˜ì¤€ì˜ LLM ì„±ëŠ¥ì„ ìµœëŒ€ 6.1% í–¥ìƒì‹œì¼°ìœ¼ë©°, ì´ì „ì˜ ìµœê³  ì˜ë£Œ RAG ëª¨ë¸ì„ ìµœëŒ€ 5.6% ëŠ¥ê°€í–ˆìŠµë‹ˆë‹¤. ì½”ë“œì™€ ê´€ë ¨ ìë£ŒëŠ” GitHubì—ì„œ ì œê³µë©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ ìƒì˜í•™ ë¶„ì•¼ì—ì„œ ì ì¬ë ¥ì´ í¬ì§€ë§Œ í™˜ê° ë° ì˜¤ë˜ëœ ì§€ì‹ ë¬¸ì œë¥¼ ê²ªê³  ìˆìŠµë‹ˆë‹¤.
- 2. RAG$^2$ëŠ” ìƒì˜í•™ì  ë¬¸ë§¥ì—ì„œ RAGì˜ ì‹ ë¢°ì„±ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¡œ, ì„¸ ê°€ì§€ ì£¼ìš” í˜ì‹ ì„ í¬í•¨í•©ë‹ˆë‹¤.
- 3. RAG$^2$ëŠ” í˜¼ë€ ìš”ì†Œë¥¼ ê±¸ëŸ¬ë‚´ê³  ìœ ìš©í•œ ì •ë³´ ì¡°ê°ì„ ì„ íƒì ìœ¼ë¡œ ë³´ê°•í•˜ëŠ” ì†Œí˜• í•„í„°ë§ ëª¨ë¸ì„ ë„ì…í•©ë‹ˆë‹¤.
- 4. LLMì´ ìƒì„±í•œ ê·¼ê±°ë¥¼ ì¿¼ë¦¬ë¡œ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ëœ ì •ë³´ ì¡°ê°ì˜ ìœ ìš©ì„±ì„ ê°œì„ í•©ë‹ˆë‹¤.
- 5. RAG$^2$ëŠ” ë„¤ ê°€ì§€ ìƒì˜í•™ ì½”í¼ìŠ¤ì—ì„œ ì •ë³´ë¥¼ ê³ ë¥´ê²Œ ê²€ìƒ‰í•˜ì—¬ ê²€ìƒ‰ í¸í–¥ì„ ì™„í™”í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 03:44:26*