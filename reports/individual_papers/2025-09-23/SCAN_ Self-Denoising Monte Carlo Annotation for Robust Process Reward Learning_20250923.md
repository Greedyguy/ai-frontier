---
keywords:
  - Process Reward Models
  - Self-Denoising Monte Carlo Annotation
  - Monte Carlo Estimation
  - Large Language Model
  - Noise-Tolerant Learning Framework
category: cs.LG
publish_date: 2025-09-23
arxiv_id: 2509.16548
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T01:39:40.318959",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Process Reward Models",
    "Self-Denoising Monte Carlo Annotation",
    "Monte Carlo Estimation",
    "Large Language Model",
    "Noise-Tolerant Learning Framework"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Process Reward Models": 0.85,
    "Self-Denoising Monte Carlo Annotation": 0.88,
    "Monte Carlo Estimation": 0.8,
    "Large Language Model": 0.82,
    "Noise-Tolerant Learning Framework": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Process Reward Models",
        "canonical": "Process Reward Models",
        "aliases": [
          "PRMs"
        ],
        "category": "unique_technical",
        "rationale": "This concept is central to the paper and represents a specific type of model that enhances reasoning in LLMs.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.85
      },
      {
        "surface": "Self-Denoising Monte Carlo Annotation",
        "canonical": "Self-Denoising Monte Carlo Annotation",
        "aliases": [
          "SCAN"
        ],
        "category": "unique_technical",
        "rationale": "SCAN is a novel framework introduced in the paper, crucial for understanding the proposed methodology.",
        "novelty_score": 0.85,
        "connectivity_score": 0.7,
        "specificity_score": 0.9,
        "link_intent_score": 0.88
      },
      {
        "surface": "Monte Carlo Estimation",
        "canonical": "Monte Carlo Estimation",
        "aliases": [
          "MC Estimation"
        ],
        "category": "broad_technical",
        "rationale": "Monte Carlo Estimation is a foundational technique used in the paper for synthetic data generation.",
        "novelty_score": 0.5,
        "connectivity_score": 0.78,
        "specificity_score": 0.65,
        "link_intent_score": 0.8
      },
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "LLMs are integral to the paper's context, as they are the primary application area for the proposed models.",
        "novelty_score": 0.4,
        "connectivity_score": 0.85,
        "specificity_score": 0.6,
        "link_intent_score": 0.82
      },
      {
        "surface": "Noise-Tolerant Learning Framework",
        "canonical": "Noise-Tolerant Learning Framework",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This framework is a key innovation in the paper, addressing noise issues in synthetic data.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.75,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "synthetic data",
      "human-annotated data",
      "inference cost"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Process Reward Models",
      "resolved_canonical": "Process Reward Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Self-Denoising Monte Carlo Annotation",
      "resolved_canonical": "Self-Denoising Monte Carlo Annotation",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.7,
        "specificity": 0.9,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "Monte Carlo Estimation",
      "resolved_canonical": "Monte Carlo Estimation",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.78,
        "specificity": 0.65,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.85,
        "specificity": 0.6,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Noise-Tolerant Learning Framework",
      "resolved_canonical": "Noise-Tolerant Learning Framework",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.75,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# SCAN: Self-Denoising Monte Carlo Annotation for Robust Process Reward Learning

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16548.pdf)
**Category**: cs.LG
**Published**: 2025-09-23
**ArXiv ID**: [2509.16548](https://arxiv.org/abs/2509.16548)

## 🔗 유사한 논문
- [[2025-09-22/MT-RewardTree_ A Comprehensive Framework for Advancing LLM-Based Machine Translation via Reward Modeling_20250922|MT-RewardTree: A Comprehensive Framework for Advancing LLM-Based Machine Translation via Reward Modeling]] (85.9% similar)
- [[2025-09-22/Entropy-Regularized Process Reward Model_20250922|Entropy-Regularized Process Reward Model]] (84.9% similar)
- [[2025-09-19/Enhancing Logical Reasoning in Language Models via Symbolically-Guided Monte Carlo Process Supervision_20250919|Enhancing Logical Reasoning in Language Models via Symbolically-Guided Monte Carlo Process Supervision]] (84.5% similar)
- [[2025-09-19/PMPO_ Probabilistic Metric Prompt Optimization for Small and Large Language Models_20250919|PMPO: Probabilistic Metric Prompt Optimization for Small and Large Language Models]] (81.8% similar)
- [[2025-09-22/BaseReward_ A Strong Baseline for Multimodal Reward Model_20250922|BaseReward: A Strong Baseline for Multimodal Reward Model]] (81.6% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Monte Carlo Estimation|Monte Carlo Estimation]], [[keywords/Large Language Model|Large Language Model]]
**⚡ Unique Technical**: [[keywords/Process Reward Models|Process Reward Models]], [[keywords/Self-Denoising Monte Carlo Annotation|Self-Denoising Monte Carlo Annotation]], [[keywords/Noise-Tolerant Learning Framework|Noise-Tolerant Learning Framework]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.16548v1 Announce Type: new 
Abstract: Process reward models (PRMs) offer fine-grained, step-level evaluations that facilitate deeper reasoning processes in large language models (LLMs), proving effective in complex tasks like mathematical reasoning. However, developing PRMs is challenging due to the high cost and limited scalability of human-annotated data. Synthetic data from Monte Carlo (MC) estimation is a promising alternative but suffers from a high noise ratio, which can cause overfitting and hinder large-scale training. In this work, we conduct a preliminary study on the noise distribution in synthetic data from MC estimation, identifying that annotation models tend to both underestimate and overestimate step correctness due to limitations in their annotation capabilities. Building on these insights, we propose Self-Denoising Monte Carlo Annotation (SCAN), an efficient data synthesis and noise-tolerant learning framework. Our key findings indicate that: (1) Even lightweight models (e.g., 1.5B parameters) can produce high-quality annotations through a self-denoising strategy, enabling PRMs to achieve superior performance with only 6% the inference cost required by vanilla MC estimation. (2) With our robust learning strategy, PRMs can effectively learn from this weak supervision, achieving a 39.2 F1 score improvement (from 19.9 to 59.1) in ProcessBench. Despite using only a compact synthetic dataset, our models surpass strong baselines, including those trained on large-scale human-annotated datasets such as PRM800K. Furthermore, performance continues to improve as we scale up the synthetic data, highlighting the potential of SCAN for scalable, cost-efficient, and robust PRM training.

## 📝 요약

이 논문은 대형 언어 모델(LLM)의 복잡한 작업 수행을 돕는 프로세스 보상 모델(PRM)의 개발을 다룹니다. 기존의 인간 주석 데이터는 비용이 높고 확장성이 제한적이므로, 저자는 몬테카를로(MC) 추정에서 생성된 합성 데이터를 대안으로 제안합니다. 그러나 이 데이터는 높은 잡음 비율로 인해 과적합 문제가 발생할 수 있습니다. 이를 해결하기 위해 저자는 자기-잡음 제거 몬테카를로 주석(SCAN)이라는 효율적인 데이터 합성 및 잡음 내성 학습 프레임워크를 제안합니다. 주요 발견 사항으로는 경량 모델도 자기-잡음 제거 전략을 통해 고품질 주석을 생성할 수 있으며, PRM이 적은 추론 비용으로도 우수한 성능을 달성한다는 점입니다. 또한, SCAN을 통해 학습된 PRM은 약한 감독에서도 높은 성능을 보이며, 대규모 인간 주석 데이터셋을 사용한 모델보다도 뛰어난 성과를 보였습니다. SCAN은 확장성과 비용 효율성 측면에서 PRM 훈련에 큰 잠재력을 가지고 있습니다.

## 🎯 주요 포인트

- 1. 프로세스 보상 모델(PRM)은 대형 언어 모델(LLM)에서 수학적 추론과 같은 복잡한 작업에 효과적이지만, 인간 주석 데이터의 높은 비용과 제한된 확장성 때문에 개발이 어렵다.
- 2. 몬테카를로(MC) 추정에서 생성된 합성 데이터는 유망한 대안이지만, 높은 노이즈 비율로 인해 과적합을 초래하고 대규모 학습을 방해할 수 있다.
- 3. Self-Denoising Monte Carlo Annotation(SCAN)은 효율적인 데이터 합성과 노이즈 내성 학습 프레임워크로, 경량 모델도 고품질 주석을 생성하여 PRM의 성능을 향상시킨다.
- 4. SCAN을 통해 PRM은 약한 감독에서도 효과적으로 학습할 수 있으며, ProcessBench에서 F1 점수를 19.9에서 59.1로 39.2점 향상시켰다.
- 5. SCAN은 대규모 인간 주석 데이터셋을 사용하지 않고도 강력한 기준선을 능가하며, 합성 데이터의 확장에 따라 성능이 계속 향상되어 비용 효율적이고 확장 가능한 PRM 학습의 잠재력을 보여준다.


---

*Generated on 2025-09-24 01:39:40*