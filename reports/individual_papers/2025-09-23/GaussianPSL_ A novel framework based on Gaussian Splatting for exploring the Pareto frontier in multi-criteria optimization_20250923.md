---
keywords:
  - Gaussian Splatting
  - Pareto Set Learning
  - Multi-objective Optimization
  - Non-convex Pareto Frontiers
category: cs.LG
publish_date: 2025-09-23
arxiv_id: 2509.17889
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T01:59:25.847524",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Gaussian Splatting",
    "Pareto Set Learning",
    "Multi-objective Optimization",
    "Non-convex Pareto Frontiers"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Gaussian Splatting": 0.78,
    "Pareto Set Learning": 0.82,
    "Multi-objective Optimization": 0.8,
    "Non-convex Pareto Frontiers": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Gaussian Splatting",
        "canonical": "Gaussian Splatting",
        "aliases": [
          "Gaussian Splatter"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel technique for handling non-convex Pareto frontiers in multi-objective optimization.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.78
      },
      {
        "surface": "Pareto Set Learning",
        "canonical": "Pareto Set Learning",
        "aliases": [
          "PSL"
        ],
        "category": "specific_connectable",
        "rationale": "Central to the paper's focus on improving learning of irregular Pareto fronts.",
        "novelty_score": 0.5,
        "connectivity_score": 0.8,
        "specificity_score": 0.85,
        "link_intent_score": 0.82
      },
      {
        "surface": "Multi-objective optimization",
        "canonical": "Multi-objective Optimization",
        "aliases": [
          "MOO"
        ],
        "category": "broad_technical",
        "rationale": "Fundamental concept in the paper, connecting to broader optimization techniques.",
        "novelty_score": 0.4,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Non-convex Pareto frontiers",
        "canonical": "Non-convex Pareto Frontiers",
        "aliases": [
          "Irregular Pareto Fronts"
        ],
        "category": "unique_technical",
        "rationale": "Highlights the specific challenge addressed by the proposed framework.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.88,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "experiment"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Gaussian Splatting",
      "resolved_canonical": "Gaussian Splatting",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Pareto Set Learning",
      "resolved_canonical": "Pareto Set Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.8,
        "specificity": 0.85,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Multi-objective optimization",
      "resolved_canonical": "Multi-objective Optimization",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Non-convex Pareto frontiers",
      "resolved_canonical": "Non-convex Pareto Frontiers",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.88,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# GaussianPSL: A novel framework based on Gaussian Splatting for exploring the Pareto frontier in multi-criteria optimization

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17889.pdf)
**Category**: cs.LG
**Published**: 2025-09-23
**ArXiv ID**: [2509.17889](https://arxiv.org/abs/2509.17889)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Scalable Multi-Objective Robot Reinforcement Learning through Gradient Conflict Resolution_20250919|Scalable Multi-Objective Robot Reinforcement Learning through Gradient Conflict Resolution]] (84.1% similar)
- [[2025-09-22/PVPO_ Pre-Estimated Value-Based Policy Optimization for Agentic Reasoning_20250922|PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic Reasoning]] (82.1% similar)
- [[2025-09-23/GPO_ Learning from Critical Steps to Improve LLM Reasoning_20250923|GPO: Learning from Critical Steps to Improve LLM Reasoning]] (81.9% similar)
- [[2025-09-23/Adaptive Kernel Design for Bayesian Optimization Is a Piece of CAKE with LLMs_20250923|Adaptive Kernel Design for Bayesian Optimization Is a Piece of CAKE with LLMs]] (81.6% similar)
- [[2025-09-17/APFEx_ Adaptive Pareto Front Explorer for Intersectional Fairness_20250917|APFEx: Adaptive Pareto Front Explorer for Intersectional Fairness]] (81.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Multi-objective Optimization|Multi-objective Optimization]]
**ğŸ”— Specific Connectable**: [[keywords/Pareto Set Learning|Pareto Set Learning]]
**âš¡ Unique Technical**: [[keywords/Gaussian Splatting|Gaussian Splatting]], [[keywords/Non-convex Pareto Frontiers|Non-convex Pareto Frontiers]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17889v1 Announce Type: new 
Abstract: Multi-objective optimization (MOO) is essential for solving complex real-world problems involving multiple conflicting objectives. However, many practical applications - including engineering design, autonomous systems, and machine learning - often yield non-convex, degenerate, or discontinuous Pareto frontiers, which involve traditional scalarization and Pareto Set Learning (PSL) methods that struggle to approximate accurately. Existing PSL approaches perform well on convex fronts but tend to fail in capturing the diversity and structure of irregular Pareto sets commonly observed in real-world scenarios. In this paper, we propose Gaussian-PSL, a novel framework that integrates Gaussian Splatting into PSL to address the challenges posed by non-convex Pareto frontiers. Our method dynamically partitions the preference vector space, enabling simple MLP networks to learn localized features within each region, which are then integrated by an additional MLP aggregator. This partition-aware strategy enhances both exploration and convergence, reduces sensi- tivity to initialization, and improves robustness against local optima. We first provide the mathematical formulation for controllable Pareto set learning using Gaussian Splat- ting. Then, we introduce the Gaussian-PSL architecture and evaluate its performance on synthetic and real-world multi-objective benchmarks. Experimental results demonstrate that our approach outperforms standard PSL models in learning irregular Pareto fronts while maintaining computational efficiency and model simplicity. This work offers a new direction for effective and scalable MOO under challenging frontier geometries.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë³µì¡í•œ í˜„ì‹¤ ë¬¸ì œì—ì„œ ë°œìƒí•˜ëŠ” ë¹„ë³¼ë¡, í‡´í™”, ë¶ˆì—°ì†ì ì¸ íŒŒë ˆí†  ì „ì„ ì„ íš¨ê³¼ì ìœ¼ë¡œ í•™ìŠµí•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ì¸ Gaussian-PSLì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ íŒŒë ˆí†  ì§‘í•© í•™ìŠµ(PSL) ë°©ë²•ì€ ë¹„ì •í˜• íŒŒë ˆí†  ì§‘í•©ì„ ì˜ í¬ì°©í•˜ì§€ ëª»í•˜ëŠ” í•œê³„ë¥¼ ë³´ì…ë‹ˆë‹¤. Gaussian-PSLì€ Gaussian Splattingì„ PSLì— í†µí•©í•˜ì—¬ ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ë©°, ì„ í˜¸ ë²¡í„° ê³µê°„ì„ ë™ì ìœ¼ë¡œ ë¶„í• í•˜ì—¬ ê° ì§€ì—­ì˜ íŠ¹ì„±ì„ í•™ìŠµí•˜ê³  ì´ë¥¼ MLP ì§‘ê³„ê¸°ë¡œ í†µí•©í•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ íƒìƒ‰ê³¼ ìˆ˜ë ´ì„ í–¥ìƒì‹œí‚¤ê³  ì´ˆê¸°í™”ì— ëŒ€í•œ ë¯¼ê°ë„ë¥¼ ì¤„ì´ë©°, ì§€ì—­ ìµœì ì ì— ëŒ€í•œ ê°•ê±´ì„±ì„ ë†’ì…ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, Gaussian-PSLì€ ë¹„ì •í˜• íŒŒë ˆí†  ì „ì„ ì„ í•™ìŠµí•˜ëŠ” ë° ìˆì–´ ê¸°ì¡´ PSL ëª¨ë¸ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì´ë©°, ê³„ì‚° íš¨ìœ¨ì„±ê³¼ ëª¨ë¸ ë‹¨ìˆœì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ë³µì¡í•œ íŒŒë ˆí†  ì „ì„ ì—ì„œ íš¨ê³¼ì ì´ê³  í™•ì¥ ê°€ëŠ¥í•œ ë‹¤ëª©ì  ìµœì í™”ì˜ ìƒˆë¡œìš´ ë°©í–¥ì„ ì œì‹œí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë‹¤ì¤‘ ëª©í‘œ ìµœì í™”(MOO)ëŠ” ì—¬ëŸ¬ ìƒì¶©í•˜ëŠ” ëª©í‘œë¥¼ í¬í•¨í•˜ëŠ” ë³µì¡í•œ í˜„ì‹¤ ë¬¸ì œ í•´ê²°ì— í•„ìˆ˜ì ì´ë‹¤.
- 2. ê¸°ì¡´ì˜ Pareto Set Learning(PSL) ë°©ë²•ì€ ë¹„ì •í˜•ì ì¸ Pareto ì§‘í•©ì˜ ë‹¤ì–‘ì„±ê³¼ êµ¬ì¡°ë¥¼ í¬ì°©í•˜ëŠ” ë° í•œê³„ê°€ ìˆë‹¤.
- 3. Gaussian-PSLì€ ë¹„ë³¼ë¡ Pareto ì „ì„  ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ Gaussian Splattingì„ PSLì— í†µí•©í•œ ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ì´ë‹¤.
- 4. ì œì•ˆëœ ë°©ë²•ì€ ì„ í˜¸ ë²¡í„° ê³µê°„ì„ ë™ì ìœ¼ë¡œ ë¶„í• í•˜ì—¬ ê° ì§€ì—­ ë‚´ì—ì„œ ë‹¨ìˆœí•œ MLP ë„¤íŠ¸ì›Œí¬ê°€ ì§€ì—­í™”ëœ íŠ¹ì§•ì„ í•™ìŠµí•˜ë„ë¡ í•œë‹¤.
- 5. ì‹¤í—˜ ê²°ê³¼, Gaussian-PSLì€ ë³µì¡í•œ Pareto ì „ì„ ì„ í•™ìŠµí•˜ëŠ” ë° ìˆì–´ ê¸°ì¡´ PSL ëª¨ë¸ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤.


---

*Generated on 2025-09-24 01:59:25*