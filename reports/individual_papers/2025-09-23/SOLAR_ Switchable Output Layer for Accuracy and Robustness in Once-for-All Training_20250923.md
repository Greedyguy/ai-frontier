---
keywords:
  - Once-for-All Training
  - Switchable Output Layer
  - Neural Network
  - Super-Net
  - Classification Head
category: cs.LG
publish_date: 2025-09-23
arxiv_id: 2509.16833
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T01:43:30.327976",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Once-for-All Training",
    "Switchable Output Layer",
    "Neural Network",
    "Super-Net",
    "Classification Head"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Once-for-All Training": 0.78,
    "Switchable Output Layer": 0.82,
    "Neural Network": 0.6,
    "Super-Net": 0.77,
    "Classification Head": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Once-for-All training",
        "canonical": "Once-for-All Training",
        "aliases": [
          "OFA training"
        ],
        "category": "unique_technical",
        "rationale": "This concept is central to the paper's methodology and distinguishes it from other training approaches.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Switchable Output Layer",
        "canonical": "Switchable Output Layer",
        "aliases": [
          "SOLAR",
          "SOL"
        ],
        "category": "unique_technical",
        "rationale": "A novel technique introduced in the paper, crucial for understanding the proposed improvements.",
        "novelty_score": 0.8,
        "connectivity_score": 0.7,
        "specificity_score": 0.9,
        "link_intent_score": 0.82
      },
      {
        "surface": "Neural Network",
        "canonical": "Neural Network",
        "aliases": [
          "NN"
        ],
        "category": "broad_technical",
        "rationale": "The paper discusses modifications applicable to neural networks, a fundamental concept in the field.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.5,
        "link_intent_score": 0.6
      },
      {
        "surface": "super-net",
        "canonical": "Super-Net",
        "aliases": [
          "supernet"
        ],
        "category": "specific_connectable",
        "rationale": "Key to understanding the architecture that allows multiple sub-nets to be generated.",
        "novelty_score": 0.65,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      },
      {
        "surface": "classification head",
        "canonical": "Classification Head",
        "aliases": [
          "output head"
        ],
        "category": "specific_connectable",
        "rationale": "Essential for understanding the decoupling process in the proposed method.",
        "novelty_score": 0.55,
        "connectivity_score": 0.7,
        "specificity_score": 0.75,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "accuracy",
      "robustness",
      "model-size"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Once-for-All training",
      "resolved_canonical": "Once-for-All Training",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Switchable Output Layer",
      "resolved_canonical": "Switchable Output Layer",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.7,
        "specificity": 0.9,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Neural Network",
      "resolved_canonical": "Neural Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.5,
        "link_intent": 0.6
      }
    },
    {
      "candidate_surface": "super-net",
      "resolved_canonical": "Super-Net",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "classification head",
      "resolved_canonical": "Classification Head",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.7,
        "specificity": 0.75,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# SOLAR: Switchable Output Layer for Accuracy and Robustness in Once-for-All Training

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16833.pdf)
**Category**: cs.LG
**Published**: 2025-09-23
**ArXiv ID**: [2509.16833](https://arxiv.org/abs/2509.16833)

## 🔗 유사한 논문
- [[2025-09-22/Efficient Long-Tail Learning in Latent Space by sampling Synthetic Data_20250922|Efficient Long-Tail Learning in Latent Space by sampling Synthetic Data]] (78.2% similar)
- [[2025-09-22/FOVAL_ Calibration-Free and Subject-Invariant Fixation Depth Estimation Across Diverse Eye-Tracking Datasets_20250922|FOVAL: Calibration-Free and Subject-Invariant Fixation Depth Estimation Across Diverse Eye-Tracking Datasets]] (77.9% similar)
- [[2025-09-22/LC-SLab -- An Object-based Deep Learning Framework for Large-scale Land Cover Classification from Satellite Imagery and Sparse In-situ Labels_20250922|LC-SLab -- An Object-based Deep Learning Framework for Large-scale Land Cover Classification from Satellite Imagery and Sparse In-situ Labels]] (77.8% similar)
- [[2025-09-22/ORCA_ Agentic Reasoning For Hallucination and Adversarial Robustness in Vision-Language Models_20250922|ORCA: Agentic Reasoning For Hallucination and Adversarial Robustness in Vision-Language Models]] (77.7% similar)
- [[2025-09-18/Lost in Translation? Vocabulary Alignment for Source-Free Domain Adaptation in Open-Vocabulary Semantic Segmentation_20250918|Lost in Translation? Vocabulary Alignment for Source-Free Domain Adaptation in Open-Vocabulary Semantic Segmentation]] (77.5% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Neural Network|Neural Network]]
**🔗 Specific Connectable**: [[keywords/Super-Net|Super-Net]], [[keywords/Classification Head|Classification Head]]
**⚡ Unique Technical**: [[keywords/Once-for-All Training|Once-for-All Training]], [[keywords/Switchable Output Layer|Switchable Output Layer]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.16833v1 Announce Type: new 
Abstract: Once-for-All (OFA) training enables a single super-net to generate multiple sub-nets tailored to diverse deployment scenarios, supporting flexible trade-offs among accuracy, robustness, and model-size without retraining. However, as the number of supported sub-nets increases, excessive parameter sharing in the backbone limits representational capacity, leading to degraded calibration and reduced overall performance. To address this, we propose SOLAR (Switchable Output Layer for Accuracy and Robustness in Once-for-All Training), a simple yet effective technique that assigns each sub-net a separate classification head. By decoupling the logit learning process across sub-nets, the Switchable Output Layer (SOL) reduces representational interference and improves optimization, without altering the shared backbone. We evaluate SOLAR on five datasets (SVHN, CIFAR-10, STL-10, CIFAR-100, and TinyImageNet) using four super-net backbones (ResNet-34, WideResNet-16-8, WideResNet-40-2, and MobileNetV2) for two OFA training frameworks (OATS and SNNs). Experiments show that SOLAR outperforms the baseline methods: compared to OATS, it improves accuracy of sub-nets up to 1.26 %, 4.71 %, 1.67 %, and 1.76 %, and robustness up to 9.01 %, 7.71 %, 2.72 %, and 1.26 % on SVHN, CIFAR-10, STL-10, and CIFAR-100, respectively. Compared to SNNs, it improves TinyImageNet accuracy by up to 2.93 %, 2.34 %, and 1.35 % using ResNet-34, WideResNet-16-8, and MobileNetV2 backbones (with 8 sub-nets), respectively.

## 📝 요약

Once-for-All (OFA) 훈련은 다양한 배포 시나리오에 맞춘 여러 서브넷을 생성할 수 있지만, 과도한 파라미터 공유로 인해 성능 저하가 발생합니다. 이를 해결하기 위해, 우리는 각 서브넷에 별도의 분류 헤드를 할당하는 SOLAR(Switchable Output Layer for Accuracy and Robustness)를 제안합니다. SOLAR는 서브넷 간 로짓 학습 과정을 분리하여 표현 간섭을 줄이고 최적화를 개선합니다. 5개의 데이터셋과 4개의 슈퍼넷 백본을 사용한 실험에서 SOLAR는 기존 방법보다 정확도와 강건성을 크게 향상시켰습니다. 예를 들어, OATS와 비교하여 SVHN, CIFAR-10, STL-10, CIFAR-100에서 최대 1.26%, 4.71%, 1.67%, 1.76%의 정확도 향상을 보였고, SNNs와 비교하여 TinyImageNet에서는 최대 2.93%의 정확도 향상을 달성했습니다.

## 🎯 주요 포인트

- 1. Once-for-All (OFA) 훈련은 다양한 배포 시나리오에 맞춰 여러 서브넷을 생성할 수 있는 단일 슈퍼넷을 지원하지만, 과도한 파라미터 공유로 인해 성능 저하가 발생할 수 있습니다.
- 2. SOLAR(Switchable Output Layer for Accuracy and Robustness)은 각 서브넷에 별도의 분류 헤드를 할당하여 표현 간섭을 줄이고 최적화를 개선하는 기법입니다.
- 3. SOLAR는 공유 백본을 변경하지 않고도 서브넷 간 로짓 학습 과정을 분리하여 성능을 향상시킵니다.
- 4. SOLAR는 SVHN, CIFAR-10, STL-10, CIFAR-100, TinyImageNet 데이터셋에서 OATS 및 SNNs 프레임워크와 비교하여 정확도와 강건성을 크게 향상시켰습니다.
- 5. 실험 결과, SOLAR는 다양한 백본을 사용하여 기존 방법보다 최대 9.01%의 강건성 향상과 최대 4.71%의 정확도 향상을 달성했습니다.


---

*Generated on 2025-09-24 01:43:30*