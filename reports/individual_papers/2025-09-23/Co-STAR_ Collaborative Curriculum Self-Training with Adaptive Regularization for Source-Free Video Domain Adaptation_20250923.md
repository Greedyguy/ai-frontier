---
keywords:
  - Source-Free Video Domain Adaptation
  - Vision-Language Model
  - Curriculum Learning
  - Adaptive Curriculum Regularization
  - Pseudo-Label Generation
category: cs.CV
publish_date: 2025-09-23
arxiv_id: 2504.11669
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T05:20:34.872396",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Source-Free Video Domain Adaptation",
    "Vision-Language Model",
    "Curriculum Learning",
    "Adaptive Curriculum Regularization",
    "Pseudo-Label Generation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Source-Free Video Domain Adaptation": 0.78,
    "Vision-Language Model": 0.8,
    "Curriculum Learning": 0.77,
    "Adaptive Curriculum Regularization": 0.82,
    "Pseudo-Label Generation": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Source-Free Unsupervised Video Domain Adaptation",
        "canonical": "Source-Free Video Domain Adaptation",
        "aliases": [
          "SFUVDA"
        ],
        "category": "unique_technical",
        "rationale": "This concept is central to the paper's contribution and is specific to the domain adaptation field.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Vision-Language Model",
        "canonical": "Vision-Language Model",
        "aliases": [
          "VLM",
          "CLIP"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-language models are crucial for the proposed method and are a trending area in AI research.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Curriculum Learning",
        "canonical": "Curriculum Learning",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Curriculum learning is a key technique used in the framework, enhancing the adaptability of models.",
        "novelty_score": 0.6,
        "connectivity_score": 0.75,
        "specificity_score": 0.72,
        "link_intent_score": 0.77
      },
      {
        "surface": "Adaptive Curriculum Regularization",
        "canonical": "Adaptive Curriculum Regularization",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This is a novel component introduced in the paper, enhancing the curriculum learning approach.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.9,
        "link_intent_score": 0.82
      },
      {
        "surface": "Pseudo-Label Generation",
        "canonical": "Pseudo-Label Generation",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Pseudo-label generation is a critical process in the adaptation method, influencing model training.",
        "novelty_score": 0.5,
        "connectivity_score": 0.7,
        "specificity_score": 0.68,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Source-Free Unsupervised Video Domain Adaptation",
      "resolved_canonical": "Source-Free Video Domain Adaptation",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Vision-Language Model",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Curriculum Learning",
      "resolved_canonical": "Curriculum Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.75,
        "specificity": 0.72,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Adaptive Curriculum Regularization",
      "resolved_canonical": "Adaptive Curriculum Regularization",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.9,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Pseudo-Label Generation",
      "resolved_canonical": "Pseudo-Label Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.7,
        "specificity": 0.68,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Co-STAR: Collaborative Curriculum Self-Training with Adaptive Regularization for Source-Free Video Domain Adaptation

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2504.11669.pdf)
**Category**: cs.CV
**Published**: 2025-09-23
**ArXiv ID**: [2504.11669](https://arxiv.org/abs/2504.11669)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Prototype-Based Pseudo-Label Denoising for Source-Free Domain Adaptation in Remote Sensing Semantic Segmentation_20250923|Prototype-Based Pseudo-Label Denoising for Source-Free Domain Adaptation in Remote Sensing Semantic Segmentation]] (83.4% similar)
- [[2025-09-18/Singular Value Few-shot Adaptation of Vision-Language Models_20250918|Singular Value Few-shot Adaptation of Vision-Language Models]] (82.9% similar)
- [[2025-09-23/TempSamp-R1_ Effective Temporal Sampling with Reinforcement Fine-Tuning for Video LLMs_20250923|TempSamp-R1: Effective Temporal Sampling with Reinforcement Fine-Tuning for Video LLMs]] (82.8% similar)
- [[2025-09-23/Training-Free Label Space Alignment for Universal Domain Adaptation_20250923|Training-Free Label Space Alignment for Universal Domain Adaptation]] (81.9% similar)
- [[2025-09-23/COLA_ Context-aware Language-driven Test-time Adaptation_20250923|COLA: Context-aware Language-driven Test-time Adaptation]] (81.4% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Curriculum Learning|Curriculum Learning]], [[keywords/Pseudo-Label Generation|Pseudo-Label Generation]]
**âš¡ Unique Technical**: [[keywords/Source-Free Video Domain Adaptation|Source-Free Video Domain Adaptation]], [[keywords/Adaptive Curriculum Regularization|Adaptive Curriculum Regularization]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2504.11669v2 Announce Type: replace 
Abstract: Recent advances in Source-Free Unsupervised Video Domain Adaptation (SFUVDA) leverage vision-language models to enhance pseudo-label generation. However, challenges such as noisy pseudo-labels and over-confident predictions limit their effectiveness in adapting well across domains. We propose Co-STAR, a novel framework that integrates curriculum learning with collaborative self-training between a source-trained teacher and a contrastive vision-language model (CLIP). Our curriculum learning approach employs a reliability-based weight function that measures bidirectional prediction alignment between the teacher and CLIP, balancing between confident and uncertain predictions. This function preserves uncertainty for difficult samples, while prioritizing reliable pseudo-labels when the predictions from both models closely align. To further improve adaptation, we propose Adaptive Curriculum Regularization, which modifies the learning priority of samples in a probabilistic, adaptive manner based on their confidence scores and prediction stability, mitigating overfitting to noisy and over-confident samples. Extensive experiments across multiple video domain adaptation benchmarks demonstrate that Co-STAR consistently outperforms state-of-the-art SFUVDA methods. Code is available at: https://github.com/Plrbear/Co-Star

## ğŸ“ ìš”ì•½

ìµœê·¼ì˜ Source-Free Unsupervised Video Domain Adaptation(SFUVDA) ì—°êµ¬ëŠ” ë¹„ì „-ì–¸ì–´ ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ê°€ì§œ ë ˆì´ë¸” ìƒì„±ì˜ íš¨ìœ¨ì„±ì„ ë†’ì´ê³ ì í•˜ì§€ë§Œ, ì—¬ì „íˆ ë…¸ì´ì¦ˆê°€ ë§ì€ ê°€ì§œ ë ˆì´ë¸”ê³¼ ê³¼ì‹ í•˜ëŠ” ì˜ˆì¸¡ìœ¼ë¡œ ì¸í•´ ë„ë©”ì¸ ê°„ ì ì‘ì— í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” Co-STARë¼ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. Co-STARëŠ” ì»¤ë¦¬í˜ëŸ¼ í•™ìŠµê³¼ ì†ŒìŠ¤ì—ì„œ í›ˆë ¨ëœ êµì‚¬ ëª¨ë¸ê³¼ ëŒ€ì¡°ì  ë¹„ì „-ì–¸ì–´ ëª¨ë¸(CLIP) ê°„ì˜ í˜‘ë ¥ì  ìê¸° í›ˆë ¨ì„ í†µí•©í•©ë‹ˆë‹¤. ì»¤ë¦¬í˜ëŸ¼ í•™ìŠµì€ êµì‚¬ì™€ CLIP ê°„ì˜ ì–‘ë°©í–¥ ì˜ˆì¸¡ ì •ë ¬ì„ ì¸¡ì •í•˜ëŠ” ì‹ ë¢° ê¸°ë°˜ ê°€ì¤‘ì¹˜ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬, í™•ì‹  ìˆëŠ” ì˜ˆì¸¡ê³¼ ë¶ˆí™•ì‹¤í•œ ì˜ˆì¸¡ ê°„ì˜ ê· í˜•ì„ ë§ì¶¥ë‹ˆë‹¤. ë˜í•œ, ì ì‘í˜• ì»¤ë¦¬í˜ëŸ¼ ì •ê·œí™”ë¥¼ ì œì•ˆí•˜ì—¬, ìƒ˜í”Œì˜ ì‹ ë¢°ë„ ì ìˆ˜ì™€ ì˜ˆì¸¡ ì•ˆì •ì„±ì— ê¸°ë°˜í•´ í•™ìŠµ ìš°ì„ ìˆœìœ„ë¥¼ í™•ë¥ ì ìœ¼ë¡œ ì¡°ì •í•¨ìœ¼ë¡œì¨ ë…¸ì´ì¦ˆì™€ ê³¼ì‹ í•˜ëŠ” ìƒ˜í”Œì— ëŒ€í•œ ê³¼ì í•©ì„ ì™„í™”í•©ë‹ˆë‹¤. ë‹¤ì–‘í•œ ë¹„ë””ì˜¤ ë„ë©”ì¸ ì ì‘ ë²¤ì¹˜ë§ˆí¬ ì‹¤í—˜ì—ì„œ Co-STARëŠ” ìµœì²¨ë‹¨ SFUVDA ë°©ë²•ë“¤ì„ ì¼ê´€ë˜ê²Œ ëŠ¥ê°€í•˜ëŠ” ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Co-STARëŠ” ì»¤ë¦¬í˜ëŸ¼ í•™ìŠµê³¼ í˜‘ë ¥ì  ìê¸° í•™ìŠµì„ ê²°í•©í•˜ì—¬ SFUVDAì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.
- 2. ì‹ ë¢°ì„± ê¸°ë°˜ ê°€ì¤‘ì¹˜ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ êµì‚¬ ëª¨ë¸ê³¼ CLIP ëª¨ë¸ ê°„ì˜ ì˜ˆì¸¡ ì •ë ¬ì„ ì¸¡ì •í•˜ê³ , ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê°€ì§œ ë ˆì´ë¸”ì„ ìš°ì„ ì‹œí•©ë‹ˆë‹¤.
- 3. ì ì‘í˜• ì»¤ë¦¬í˜ëŸ¼ ì •ê·œí™”ë¥¼ í†µí•´ ìƒ˜í”Œì˜ ì‹ ë¢°ë„ ì ìˆ˜ì™€ ì˜ˆì¸¡ ì•ˆì •ì„±ì— ë”°ë¼ í•™ìŠµ ìš°ì„ ìˆœìœ„ë¥¼ ì¡°ì •í•˜ì—¬ ì¡ìŒì´ ë§ê³  ê³¼ì‹ í•˜ëŠ” ìƒ˜í”Œì— ëŒ€í•œ ê³¼ì í•©ì„ ì™„í™”í•©ë‹ˆë‹¤.
- 4. ì—¬ëŸ¬ ë¹„ë””ì˜¤ ë„ë©”ì¸ ì ì‘ ë²¤ì¹˜ë§ˆí¬ì—ì„œ Co-STARëŠ” ìµœì‹  SFUVDA ë°©ë²•ì„ ì¼ê´€ë˜ê²Œ ëŠ¥ê°€í•˜ëŠ” ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 05:20:34*