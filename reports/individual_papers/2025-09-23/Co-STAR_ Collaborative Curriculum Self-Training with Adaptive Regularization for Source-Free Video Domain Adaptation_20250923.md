---
keywords:
  - Source-Free Video Domain Adaptation
  - Vision-Language Model
  - Curriculum Learning
  - Adaptive Curriculum Regularization
  - Pseudo-Label Generation
category: cs.CV
publish_date: 2025-09-23
arxiv_id: 2504.11669
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T05:20:34.872396",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Source-Free Video Domain Adaptation",
    "Vision-Language Model",
    "Curriculum Learning",
    "Adaptive Curriculum Regularization",
    "Pseudo-Label Generation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Source-Free Video Domain Adaptation": 0.78,
    "Vision-Language Model": 0.8,
    "Curriculum Learning": 0.77,
    "Adaptive Curriculum Regularization": 0.82,
    "Pseudo-Label Generation": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Source-Free Unsupervised Video Domain Adaptation",
        "canonical": "Source-Free Video Domain Adaptation",
        "aliases": [
          "SFUVDA"
        ],
        "category": "unique_technical",
        "rationale": "This concept is central to the paper's contribution and is specific to the domain adaptation field.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Vision-Language Model",
        "canonical": "Vision-Language Model",
        "aliases": [
          "VLM",
          "CLIP"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-language models are crucial for the proposed method and are a trending area in AI research.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Curriculum Learning",
        "canonical": "Curriculum Learning",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Curriculum learning is a key technique used in the framework, enhancing the adaptability of models.",
        "novelty_score": 0.6,
        "connectivity_score": 0.75,
        "specificity_score": 0.72,
        "link_intent_score": 0.77
      },
      {
        "surface": "Adaptive Curriculum Regularization",
        "canonical": "Adaptive Curriculum Regularization",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This is a novel component introduced in the paper, enhancing the curriculum learning approach.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.9,
        "link_intent_score": 0.82
      },
      {
        "surface": "Pseudo-Label Generation",
        "canonical": "Pseudo-Label Generation",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Pseudo-label generation is a critical process in the adaptation method, influencing model training.",
        "novelty_score": 0.5,
        "connectivity_score": 0.7,
        "specificity_score": 0.68,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Source-Free Unsupervised Video Domain Adaptation",
      "resolved_canonical": "Source-Free Video Domain Adaptation",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Vision-Language Model",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Curriculum Learning",
      "resolved_canonical": "Curriculum Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.75,
        "specificity": 0.72,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Adaptive Curriculum Regularization",
      "resolved_canonical": "Adaptive Curriculum Regularization",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.9,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Pseudo-Label Generation",
      "resolved_canonical": "Pseudo-Label Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.7,
        "specificity": 0.68,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Co-STAR: Collaborative Curriculum Self-Training with Adaptive Regularization for Source-Free Video Domain Adaptation

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2504.11669.pdf)
**Category**: cs.CV
**Published**: 2025-09-23
**ArXiv ID**: [2504.11669](https://arxiv.org/abs/2504.11669)

## 🔗 유사한 논문
- [[2025-09-23/Prototype-Based Pseudo-Label Denoising for Source-Free Domain Adaptation in Remote Sensing Semantic Segmentation_20250923|Prototype-Based Pseudo-Label Denoising for Source-Free Domain Adaptation in Remote Sensing Semantic Segmentation]] (83.4% similar)
- [[2025-09-18/Singular Value Few-shot Adaptation of Vision-Language Models_20250918|Singular Value Few-shot Adaptation of Vision-Language Models]] (82.9% similar)
- [[2025-09-23/TempSamp-R1_ Effective Temporal Sampling with Reinforcement Fine-Tuning for Video LLMs_20250923|TempSamp-R1: Effective Temporal Sampling with Reinforcement Fine-Tuning for Video LLMs]] (82.8% similar)
- [[2025-09-23/Training-Free Label Space Alignment for Universal Domain Adaptation_20250923|Training-Free Label Space Alignment for Universal Domain Adaptation]] (81.9% similar)
- [[2025-09-23/COLA_ Context-aware Language-driven Test-time Adaptation_20250923|COLA: Context-aware Language-driven Test-time Adaptation]] (81.4% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Curriculum Learning|Curriculum Learning]], [[keywords/Pseudo-Label Generation|Pseudo-Label Generation]]
**⚡ Unique Technical**: [[keywords/Source-Free Video Domain Adaptation|Source-Free Video Domain Adaptation]], [[keywords/Adaptive Curriculum Regularization|Adaptive Curriculum Regularization]]
**🚀 Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2504.11669v2 Announce Type: replace 
Abstract: Recent advances in Source-Free Unsupervised Video Domain Adaptation (SFUVDA) leverage vision-language models to enhance pseudo-label generation. However, challenges such as noisy pseudo-labels and over-confident predictions limit their effectiveness in adapting well across domains. We propose Co-STAR, a novel framework that integrates curriculum learning with collaborative self-training between a source-trained teacher and a contrastive vision-language model (CLIP). Our curriculum learning approach employs a reliability-based weight function that measures bidirectional prediction alignment between the teacher and CLIP, balancing between confident and uncertain predictions. This function preserves uncertainty for difficult samples, while prioritizing reliable pseudo-labels when the predictions from both models closely align. To further improve adaptation, we propose Adaptive Curriculum Regularization, which modifies the learning priority of samples in a probabilistic, adaptive manner based on their confidence scores and prediction stability, mitigating overfitting to noisy and over-confident samples. Extensive experiments across multiple video domain adaptation benchmarks demonstrate that Co-STAR consistently outperforms state-of-the-art SFUVDA methods. Code is available at: https://github.com/Plrbear/Co-Star

## 📝 요약

최근의 Source-Free Unsupervised Video Domain Adaptation(SFUVDA) 연구는 비전-언어 모델을 활용하여 가짜 레이블 생성의 효율성을 높이고자 하지만, 여전히 노이즈가 많은 가짜 레이블과 과신하는 예측으로 인해 도메인 간 적응에 한계가 있습니다. 이를 해결하기 위해, 우리는 Co-STAR라는 새로운 프레임워크를 제안합니다. Co-STAR는 커리큘럼 학습과 소스에서 훈련된 교사 모델과 대조적 비전-언어 모델(CLIP) 간의 협력적 자기 훈련을 통합합니다. 커리큘럼 학습은 교사와 CLIP 간의 양방향 예측 정렬을 측정하는 신뢰 기반 가중치 함수를 사용하여, 확신 있는 예측과 불확실한 예측 간의 균형을 맞춥니다. 또한, 적응형 커리큘럼 정규화를 제안하여, 샘플의 신뢰도 점수와 예측 안정성에 기반해 학습 우선순위를 확률적으로 조정함으로써 노이즈와 과신하는 샘플에 대한 과적합을 완화합니다. 다양한 비디오 도메인 적응 벤치마크 실험에서 Co-STAR는 최첨단 SFUVDA 방법들을 일관되게 능가하는 성능을 보였습니다.

## 🎯 주요 포인트

- 1. Co-STAR는 커리큘럼 학습과 협력적 자기 학습을 결합하여 SFUVDA의 성능을 향상시키는 새로운 프레임워크입니다.
- 2. 신뢰성 기반 가중치 함수를 사용하여 교사 모델과 CLIP 모델 간의 예측 정렬을 측정하고, 신뢰할 수 있는 가짜 레이블을 우선시합니다.
- 3. 적응형 커리큘럼 정규화를 통해 샘플의 신뢰도 점수와 예측 안정성에 따라 학습 우선순위를 조정하여 잡음이 많고 과신하는 샘플에 대한 과적합을 완화합니다.
- 4. 여러 비디오 도메인 적응 벤치마크에서 Co-STAR는 최신 SFUVDA 방법을 일관되게 능가하는 성능을 보였습니다.


---

*Generated on 2025-09-24 05:20:34*