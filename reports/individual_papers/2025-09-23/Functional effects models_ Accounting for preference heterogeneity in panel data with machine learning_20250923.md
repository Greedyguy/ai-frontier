---
keywords:
  - Functional Effects Models
  - Machine Learning
  - Gradient Boosting Decision Trees
  - Neural Network
  - RUMBoost
category: cs.LG
publish_date: 2025-09-23
arxiv_id: 2509.18047
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T02:30:26.790872",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Functional Effects Models",
    "Machine Learning",
    "Gradient Boosting Decision Trees",
    "Neural Network",
    "RUMBoost"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Functional Effects Models": 0.78,
    "Machine Learning": 0.85,
    "Gradient Boosting Decision Trees": 0.7,
    "Neural Network": 0.8,
    "RUMBoost": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Functional Effects Models",
        "canonical": "Functional Effects Models",
        "aliases": [
          "FEM"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel approach introduced in the paper, offering a unique perspective on modeling preference heterogeneity.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.88,
        "link_intent_score": 0.78
      },
      {
        "surface": "Machine Learning",
        "canonical": "Machine Learning",
        "aliases": [
          "ML"
        ],
        "category": "broad_technical",
        "rationale": "Machine Learning is a foundational technique used in the paper, connecting it to a wide range of related research.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Gradient Boosting Decision Trees",
        "canonical": "Gradient Boosting Decision Trees",
        "aliases": [
          "GBDT"
        ],
        "category": "specific_connectable",
        "rationale": "This specific machine learning technique is crucial for the implementation of the proposed model.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      },
      {
        "surface": "Deep Neural Networks",
        "canonical": "Neural Network",
        "aliases": [
          "DNN"
        ],
        "category": "broad_technical",
        "rationale": "Deep Neural Networks are a key component of the model's methodology, linking to extensive neural network research.",
        "novelty_score": 0.4,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "RUMBoost",
        "canonical": "RUMBoost",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "RUMBoost is a specific model variant discussed in the paper, relevant for its unique approach to preference modeling.",
        "novelty_score": 0.78,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "panel data",
      "socio-demographic characteristics"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Functional Effects Models",
      "resolved_canonical": "Functional Effects Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.88,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Machine Learning",
      "resolved_canonical": "Machine Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Gradient Boosting Decision Trees",
      "resolved_canonical": "Gradient Boosting Decision Trees",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Deep Neural Networks",
      "resolved_canonical": "Neural Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "RUMBoost",
      "resolved_canonical": "RUMBoost",
      "decision": "linked",
      "scores": {
        "novelty": 0.78,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Functional effects models: Accounting for preference heterogeneity in panel data with machine learning

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18047.pdf)
**Category**: cs.LG
**Published**: 2025-09-23
**ArXiv ID**: [2509.18047](https://arxiv.org/abs/2509.18047)

## 🔗 유사한 논문
- [[2025-09-22/NeuroRAD-FM_ A Foundation Model for Neuro-Oncology with Distributionally Robust Training_20250922|NeuroRAD-FM: A Foundation Model for Neuro-Oncology with Distributionally Robust Training]] (79.3% similar)
- [[2025-09-23/Intrinsic Meets Extrinsic Fairness_ Assessing the Downstream Impact of Bias Mitigation in Large Language Models_20250923|Intrinsic Meets Extrinsic Fairness: Assessing the Downstream Impact of Bias Mitigation in Large Language Models]] (78.8% similar)
- [[2025-09-19/Multi-Fidelity Hybrid Reinforcement Learning via Information Gain Maximization_20250919|Multi-Fidelity Hybrid Reinforcement Learning via Information Gain Maximization]] (78.7% similar)
- [[2025-09-22/Personalized Language Models via Privacy-Preserving Evolutionary Model Merging_20250922|Personalized Language Models via Privacy-Preserving Evolutionary Model Merging]] (78.7% similar)
- [[2025-09-17/APFEx_ Adaptive Pareto Front Explorer for Intersectional Fairness_20250917|APFEx: Adaptive Pareto Front Explorer for Intersectional Fairness]] (78.5% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Machine Learning|Machine Learning]], [[keywords/Neural Network|Neural Network]]
**🔗 Specific Connectable**: [[keywords/Gradient Boosting Decision Trees|Gradient Boosting Decision Trees]]
**⚡ Unique Technical**: [[keywords/Functional Effects Models|Functional Effects Models]], [[keywords/RUMBoost|RUMBoost]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.18047v1 Announce Type: cross 
Abstract: In this paper, we present a general specification for Functional Effects Models, which use Machine Learning (ML) methodologies to learn individual-specific preference parameters from socio-demographic characteristics, therefore accounting for inter-individual heterogeneity in panel choice data. We identify three specific advantages of the Functional Effects Model over traditional fixed, and random/mixed effects models: (i) by mapping individual-specific effects as a function of socio-demographic variables, we can account for these effects when forecasting choices of previously unobserved individuals (ii) the (approximate) maximum-likelihood estimation of functional effects avoids the incidental parameters problem of the fixed effects model, even when the number of observed choices per individual is small; and (iii) we do not rely on the strong distributional assumptions of the random effects model, which may not match reality. We learn functional intercept and functional slopes with powerful non-linear machine learning regressors for tabular data, namely gradient boosting decision trees and deep neural networks. We validate our proposed methodology on a synthetic experiment and three real-world panel case studies, demonstrating that the Functional Effects Model: (i) can identify the true values of individual-specific effects when the data generation process is known; (ii) outperforms both state-of-the-art ML choice modelling techniques that omit individual heterogeneity in terms of predictive performance, as well as traditional static panel choice models in terms of learning inter-individual heterogeneity. The results indicate that the FI-RUMBoost model, which combines the individual-specific constants of the Functional Effects Model with the complex, non-linear utilities of RUMBoost, performs marginally best on large-scale revealed preference panel data.

## 📝 요약

이 논문은 개별적인 선호 매개변수를 사회-인구학적 특성으로부터 학습하는 기능적 효과 모델을 제안합니다. 이 모델은 전통적인 고정 및 랜덤/혼합 효과 모델에 비해 세 가지 장점을 가집니다. 첫째, 개인별 효과를 사회-인구학적 변수의 함수로 매핑하여 관찰되지 않은 개인의 선택을 예측할 수 있습니다. 둘째, 기능적 효과의 최대우도 추정은 고정 효과 모델의 부수적 매개변수 문제를 피합니다. 셋째, 랜덤 효과 모델의 강한 분포 가정을 피할 수 있습니다. 이 모델은 강력한 비선형 머신러닝 회귀기인 그래디언트 부스팅 결정 트리와 심층 신경망을 사용하여 기능적 절편과 기울기를 학습합니다. 제안된 방법론은 합성 실험과 실제 사례 연구에서 검증되었으며, 개인별 이질성을 고려하지 않는 기존의 ML 선택 모델보다 예측 성능이 우수함을 보여줍니다. 특히 FI-RUMBoost 모델은 대규모 패널 데이터에서 가장 우수한 성능을 보였습니다.

## 🎯 주요 포인트

- 1. Functional Effects Model은 개인별 선호도를 사회인구학적 특성으로부터 학습하여 개별 이질성을 고려할 수 있다.
- 2. 이 모델은 관측되지 않은 개인의 선택을 예측할 때 개인별 효과를 고려할 수 있어 기존의 고정 및 혼합 효과 모델보다 유리하다.
- 3. 고정 효과 모델의 우발적 매개변수 문제를 피할 수 있으며, 관측된 선택의 수가 적어도 최대우도 추정이 가능하다.
- 4. 랜덤 효과 모델의 강한 분포 가정에 의존하지 않아 현실과의 불일치를 피할 수 있다.
- 5. FI-RUMBoost 모델은 대규모 패널 데이터에서 개인별 상수와 복잡한 비선형 유틸리티를 결합하여 최고의 성능을 보인다.


---

*Generated on 2025-09-24 02:30:26*