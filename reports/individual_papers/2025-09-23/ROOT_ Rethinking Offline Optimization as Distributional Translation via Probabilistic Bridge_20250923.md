---
keywords:
  - Black-Box Optimization
  - Probabilistic Bridge
  - Gaussian Processes
  - Distributional Translation
category: cs.LG
publish_date: 2025-09-23
arxiv_id: 2509.16300
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T01:33:59.507409",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Black-Box Optimization",
    "Probabilistic Bridge",
    "Gaussian Processes",
    "Distributional Translation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Black-Box Optimization": 0.75,
    "Probabilistic Bridge": 0.78,
    "Gaussian Processes": 0.8,
    "Distributional Translation": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "black-box optimization",
        "canonical": "Black-Box Optimization",
        "aliases": [
          "BBO"
        ],
        "category": "unique_technical",
        "rationale": "Black-box optimization is a specific technique that can connect with various optimization methods and applications.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      },
      {
        "surface": "probabilistic bridge",
        "canonical": "Probabilistic Bridge",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "The concept of a probabilistic bridge is novel and central to the paper's approach, offering potential connections to probabilistic modeling.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Gaussian processes",
        "canonical": "Gaussian Processes",
        "aliases": [
          "GP"
        ],
        "category": "broad_technical",
        "rationale": "Gaussian processes are a fundamental technique in machine learning, relevant for linking with probabilistic models.",
        "novelty_score": 0.4,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "distributional translation",
        "canonical": "Distributional Translation",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This term represents a unique approach to optimization, facilitating connections with translation and transformation methodologies.",
        "novelty_score": 0.75,
        "connectivity_score": 0.55,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "offline data",
      "surrogate function",
      "inverse modeling"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "black-box optimization",
      "resolved_canonical": "Black-Box Optimization",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "probabilistic bridge",
      "resolved_canonical": "Probabilistic Bridge",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Gaussian processes",
      "resolved_canonical": "Gaussian Processes",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "distributional translation",
      "resolved_canonical": "Distributional Translation",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.55,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# ROOT: Rethinking Offline Optimization as Distributional Translation via Probabilistic Bridge

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16300.pdf)
**Category**: cs.LG
**Published**: 2025-09-23
**ArXiv ID**: [2509.16300](https://arxiv.org/abs/2509.16300)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Multi-Fidelity Hybrid Reinforcement Learning via Information Gain Maximization_20250919|Multi-Fidelity Hybrid Reinforcement Learning via Information Gain Maximization]] (80.5% similar)
- [[2025-09-18/Data-Driven Distributed Optimization via Aggregative Tracking and Deep-Learning_20250918|Data-Driven Distributed Optimization via Aggregative Tracking and Deep-Learning]] (80.0% similar)
- [[2025-09-23/Dynamic Speculative Agent Planning_20250923|Dynamic Speculative Agent Planning]] (79.5% similar)
- [[2025-09-23/Adaptive Kernel Design for Bayesian Optimization Is a Piece of CAKE with LLMs_20250923|Adaptive Kernel Design for Bayesian Optimization Is a Piece of CAKE with LLMs]] (79.3% similar)
- [[2025-09-19/Online Multi-Robot Coordination and Cooperation with Task Precedence Relationships_20250919|Online Multi-Robot Coordination and Cooperation with Task Precedence Relationships]] (79.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Gaussian Processes|Gaussian Processes]]
**âš¡ Unique Technical**: [[keywords/Black-Box Optimization|Black-Box Optimization]], [[keywords/Probabilistic Bridge|Probabilistic Bridge]], [[keywords/Distributional Translation|Distributional Translation]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16300v1 Announce Type: new 
Abstract: This paper studies the black-box optimization task which aims to find the maxima of a black-box function using a static set of its observed input-output pairs. This is often achieved via learning and optimizing a surrogate function with that offline data. Alternatively, it can also be framed as an inverse modeling task that maps a desired performance to potential input candidates that achieve it. Both approaches are constrained by the limited amount of offline data. To mitigate this limitation, we introduce a new perspective that casts offline optimization as a distributional translation task. This is formulated as learning a probabilistic bridge transforming an implicit distribution of low-value inputs (i.e., offline data) into another distribution of high-value inputs (i.e., solution candidates). Such probabilistic bridge can be learned using low- and high-value inputs sampled from synthetic functions that resemble the target function. These synthetic functions are constructed as the mean posterior of multiple Gaussian processes fitted with different parameterizations on the offline data, alleviating the data bottleneck. The proposed approach is evaluated on an extensive benchmark comprising most recent methods, demonstrating significant improvement and establishing a new state-of-the-art performance.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë¸”ë™ë°•ìŠ¤ í•¨ìˆ˜ì˜ ìµœëŒ€ê°’ì„ ì°¾ê¸° ìœ„í•œ ë¸”ë™ë°•ìŠ¤ ìµœì í™” ë¬¸ì œë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. ê¸°ì¡´ ë°©ë²•ì€ ê´€ì°°ëœ ì…ë ¥-ì¶œë ¥ ìŒì„ ì‚¬ìš©í•˜ì—¬ ëŒ€ë¦¬ í•¨ìˆ˜ë¥¼ í•™ìŠµí•˜ê³  ìµœì í™”í•˜ê±°ë‚˜, ì›í•˜ëŠ” ì„±ëŠ¥ì„ ë‹¬ì„±í•  ìˆ˜ ìˆëŠ” ì…ë ¥ í›„ë³´ë¥¼ ì°¾ëŠ” ì—­ëª¨ë¸ë§ ë°©ì‹ìœ¼ë¡œ ì ‘ê·¼í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ëŸ¬í•œ ë°©ë²•ë“¤ì€ ì œí•œëœ ì˜¤í”„ë¼ì¸ ë°ì´í„°ì— ì˜í•´ ì œì•½ì„ ë°›ìŠµë‹ˆë‹¤. ì´ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ë³¸ ì—°êµ¬ëŠ” ì˜¤í”„ë¼ì¸ ìµœì í™”ë¥¼ ë¶„í¬ ë³€í™˜ ì‘ì—…ìœ¼ë¡œ ì¬êµ¬ì„±í•˜ëŠ” ìƒˆë¡œìš´ ê´€ì ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ëŠ” ë‚®ì€ ê°’ì˜ ì…ë ¥ ë¶„í¬ë¥¼ ë†’ì€ ê°’ì˜ ì…ë ¥ ë¶„í¬ë¡œ ë³€í™˜í•˜ëŠ” í™•ë¥ ì  ë‹¤ë¦¬ë¥¼ í•™ìŠµí•˜ëŠ” ê²ƒìœ¼ë¡œ, ëª©í‘œ í•¨ìˆ˜ì™€ ìœ ì‚¬í•œ í•©ì„± í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµí•©ë‹ˆë‹¤. í•©ì„± í•¨ìˆ˜ëŠ” ë‹¤ì–‘í•œ ë§¤ê°œë³€ìˆ˜ë¡œ ì˜¤í”„ë¼ì¸ ë°ì´í„°ì— ë§ì¶˜ ë‹¤ì¤‘ ê°€ìš°ì‹œì•ˆ í”„ë¡œì„¸ìŠ¤ì˜ í‰ê·  í›„í–‰ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. ì œì•ˆëœ ë°©ë²•ì€ ìµœì‹  ë°©ë²•ë“¤ì„ í¬í•¨í•œ ê´‘ë²”ìœ„í•œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ í‰ê°€ë˜ì—ˆìœ¼ë©°, ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë˜ì–´ ìƒˆë¡œìš´ ìµœì²¨ë‹¨ ì„±ê³¼ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë³¸ ë…¼ë¬¸ì€ ë¸”ë™ë°•ìŠ¤ í•¨ìˆ˜ì˜ ìµœëŒ€ê°’ì„ ì°¾ê¸° ìœ„í•œ ë¸”ë™ë°•ìŠ¤ ìµœì í™” ì‘ì—…ì„ ì—°êµ¬í•˜ë©°, ê´€ì°°ëœ ì…ë ¥-ì¶œë ¥ ìŒì˜ ì •ì  ì§‘í•©ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
- 2. ê¸°ì¡´ì˜ ë°©ë²•ë“¤ì€ ì œí•œëœ ì˜¤í”„ë¼ì¸ ë°ì´í„°ë¡œ ì¸í•´ ì œì•½ì„ ë°›ìœ¼ë©°, ì´ë¥¼ ì™„í™”í•˜ê¸° ìœ„í•´ ì˜¤í”„ë¼ì¸ ìµœì í™”ë¥¼ ë¶„í¬ ë²ˆì—­ ì‘ì—…ìœ¼ë¡œ ì¬êµ¬ì„±í•˜ëŠ” ìƒˆë¡œìš´ ê´€ì ì„ ì œì‹œí•©ë‹ˆë‹¤.
- 3. ì œì•ˆëœ ë°©ë²•ì€ ë‚®ì€ ê°€ì¹˜ì˜ ì…ë ¥ ë¶„í¬ë¥¼ ë†’ì€ ê°€ì¹˜ì˜ ì…ë ¥ ë¶„í¬ë¡œ ë³€í™˜í•˜ëŠ” í™•ë¥ ì  ë‹¤ë¦¬ë¥¼ í•™ìŠµí•˜ì—¬ ë°ì´í„° ë³‘ëª© í˜„ìƒì„ ì™„í™”í•©ë‹ˆë‹¤.
- 4. ì—¬ëŸ¬ ê°€ìš°ì‹œì•ˆ í”„ë¡œì„¸ìŠ¤ì˜ í‰ê·  ì‚¬í›„ í™•ë¥ ë¡œ êµ¬ì„±ëœ í•©ì„± í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª©í‘œ í•¨ìˆ˜ì™€ ìœ ì‚¬í•œ ì…ë ¥ì„ ìƒ˜í”Œë§í•©ë‹ˆë‹¤.
- 5. ì œì•ˆëœ ì ‘ê·¼ë²•ì€ ìµœì‹  ë°©ë²•ë“¤ì„ í¬í•¨í•œ ê´‘ë²”ìœ„í•œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ í‰ê°€ë˜ì—ˆìœ¼ë©°, ìƒë‹¹í•œ ê°œì„ ì„ ë³´ì—¬ì£¼ë©° ìƒˆë¡œìš´ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ í™•ë¦½í–ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 01:33:59*