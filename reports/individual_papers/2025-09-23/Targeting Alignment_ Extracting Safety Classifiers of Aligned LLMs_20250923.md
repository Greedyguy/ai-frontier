---
keywords:
  - Large Language Model
  - Jailbreak Attacks
  - Surrogate Classifier
  - Model Alignment
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2501.16534
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T00:43:31.559133",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Jailbreak Attacks",
    "Surrogate Classifier",
    "Model Alignment"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Jailbreak Attacks": 0.8,
    "Surrogate Classifier": 0.78,
    "Model Alignment": 0.82
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Large Language Models"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's discussion, connecting to a broad range of related research.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "jailbreak attacks",
        "canonical": "Jailbreak Attacks",
        "aliases": [
          "jailbreaking"
        ],
        "category": "unique_technical",
        "rationale": "A specific type of attack discussed in the paper, relevant for security-focused research.",
        "novelty_score": 0.75,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "surrogate classifier",
        "canonical": "Surrogate Classifier",
        "aliases": [
          "approximate classifier"
        ],
        "category": "unique_technical",
        "rationale": "Key concept introduced in the paper, important for understanding the methodology.",
        "novelty_score": 0.8,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "alignment",
        "canonical": "Model Alignment",
        "aliases": [
          "alignment"
        ],
        "category": "specific_connectable",
        "rationale": "Alignment is crucial for ensuring model safety, a central theme of the paper.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.82
      }
    ],
    "ban_list_suggestions": [
      "safety classifier",
      "attack success rate"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "jailbreak attacks",
      "resolved_canonical": "Jailbreak Attacks",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "surrogate classifier",
      "resolved_canonical": "Surrogate Classifier",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "alignment",
      "resolved_canonical": "Model Alignment",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.82
      }
    }
  ]
}
-->

# Targeting Alignment: Extracting Safety Classifiers of Aligned LLMs

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2501.16534.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2501.16534](https://arxiv.org/abs/2501.16534)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/SABER_ Uncovering Vulnerabilities in Safety Alignment via Cross-Layer Residual Connection_20250922|SABER: Uncovering Vulnerabilities in Safety Alignment via Cross-Layer Residual Connection]] (90.1% similar)
- [[2025-09-22/AdaSteer_ Your Aligned LLM is Inherently an Adaptive Jailbreak Defender_20250922|AdaSteer: Your Aligned LLM is Inherently an Adaptive Jailbreak Defender]] (89.1% similar)
- [[2025-09-23/AdaptiveGuard_ Towards Adaptive Runtime Safety for LLM-Powered Software_20250923|AdaptiveGuard: Towards Adaptive Runtime Safety for LLM-Powered Software]] (87.7% similar)
- [[2025-09-18/LLM Jailbreak Detection for (Almost) Free!_20250918|LLM Jailbreak Detection for (Almost) Free!]] (87.6% similar)
- [[2025-09-23/Large Language Models for Cyber Security_ A Systematic Literature Review_20250923|Large Language Models for Cyber Security: A Systematic Literature Review]] (86.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Model Alignment|Model Alignment]]
**âš¡ Unique Technical**: [[keywords/Jailbreak Attacks|Jailbreak Attacks]], [[keywords/Surrogate Classifier|Surrogate Classifier]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2501.16534v2 Announce Type: replace-cross 
Abstract: Alignment in large language models (LLMs) is used to enforce guidelines such as safety. Yet, alignment fails in the face of jailbreak attacks that modify inputs to induce unsafe outputs. In this paper, we introduce and evaluate a new technique for jailbreak attacks. We observe that alignment embeds a safety classifier in the LLM responsible for deciding between refusal and compliance, and seek to extract an approximation of this classifier: a surrogate classifier. To this end, we build candidate classifiers from subsets of the LLM. We first evaluate the degree to which candidate classifiers approximate the LLM's safety classifier in benign and adversarial settings. Then, we attack the candidates and measure how well the resulting adversarial inputs transfer to the LLM. Our evaluation shows that the best candidates achieve accurate agreement (an F1 score above 80%) using as little as 20% of the model architecture. Further, we find that attacks mounted on the surrogate classifiers can be transferred to the LLM with high success. For example, a surrogate using only 50% of the Llama 2 model achieved an attack success rate (ASR) of 70% with half the memory footprint and runtime -- a substantial improvement over attacking the LLM directly, where we only observed a 22% ASR. These results show that extracting surrogate classifiers is an effective and efficient means for modeling (and therein addressing) the vulnerability of aligned models to jailbreaking attacks.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì—ì„œëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì •ë ¬ì„ ìš°íšŒí•˜ëŠ” ìƒˆë¡œìš´ íƒˆì˜¥ ê³µê²© ê¸°ë²•ì„ ì†Œê°œí•˜ê³  í‰ê°€í•©ë‹ˆë‹¤. ì—°êµ¬ì§„ì€ LLM ë‚´ì— ë‚´ì¥ëœ ì•ˆì „ ë¶„ë¥˜ê¸°ë¥¼ ê·¼ì‚¬í•˜ëŠ” ëŒ€ë¦¬ ë¶„ë¥˜ê¸°ë¥¼ ì¶”ì¶œí•˜ì—¬ ê³µê²©ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. í›„ë³´ ë¶„ë¥˜ê¸°ë¥¼ LLMì˜ ì¼ë¶€ë¡œë¶€í„° êµ¬ì¶•í•˜ê³ , ì´ë“¤ì´ ì•ˆì „ ë¶„ë¥˜ê¸°ë¥¼ ì–¼ë§ˆë‚˜ ì˜ ê·¼ì‚¬í•˜ëŠ”ì§€ í‰ê°€í•œ í›„, ëŒ€ë¦¬ ë¶„ë¥˜ê¸°ì— ëŒ€í•œ ê³µê²©ì„ í†µí•´ LLMì— ì „ì´ë˜ëŠ”ì§€ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤. ê²°ê³¼ì ìœ¼ë¡œ, ëª¨ë¸ êµ¬ì¡°ì˜ 20%ë§Œìœ¼ë¡œë„ ë†’ì€ ì •í™•ë„ì˜ ëŒ€ë¦¬ ë¶„ë¥˜ê¸°ë¥¼ êµ¬ì¶•í•  ìˆ˜ ìˆì—ˆìœ¼ë©°, Llama 2 ëª¨ë¸ì˜ 50%ë¥¼ ì‚¬ìš©í•œ ëŒ€ë¦¬ ë¶„ë¥˜ê¸°ëŠ” 70%ì˜ ê³µê²© ì„±ê³µë¥ ì„ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ì§ì ‘ LLMì„ ê³µê²©í–ˆì„ ë•Œë³´ë‹¤ í›¨ì”¬ ë†’ì€ ì„±ê³µë¥ ë¡œ, ëŒ€ë¦¬ ë¶„ë¥˜ê¸°ë¥¼ í™œìš©í•œ ê³µê²©ì´ íš¨ìœ¨ì ì„ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì •ë ¬ì€ ì•ˆì „ì„± ë“±ì˜ ì§€ì¹¨ì„ ê°•ì œí•˜ê¸° ìœ„í•´ ì‚¬ìš©ë˜ì§€ë§Œ, ì •ë ¬ì€ ì…ë ¥ì„ ìˆ˜ì •í•˜ì—¬ ì•ˆì „í•˜ì§€ ì•Šì€ ì¶œë ¥ì„ ìœ ë„í•˜ëŠ” íƒˆì˜¥ ê³µê²©ì— ì·¨ì•½í•˜ë‹¤.
- 2. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” íƒˆì˜¥ ê³µê²©ì„ ìœ„í•œ ìƒˆë¡œìš´ ê¸°ë²•ì„ ì†Œê°œí•˜ê³  í‰ê°€í•˜ë©°, LLMì˜ ì•ˆì „ ë¶„ë¥˜ê¸°ë¥¼ ê·¼ì‚¬í™”í•œ ëŒ€ë¦¬ ë¶„ë¥˜ê¸°ë¥¼ ì¶”ì¶œí•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí•œë‹¤.
- 3. ëŒ€ë¦¬ ë¶„ë¥˜ê¸°ë¥¼ ì‚¬ìš©í•œ ê³µê²©ì€ LLMì— ë†’ì€ ì„±ê³µë¥ ë¡œ ì „ì´ë  ìˆ˜ ìˆìœ¼ë©°, Llama 2 ëª¨ë¸ì˜ 50%ë§Œ ì‚¬ìš©í•œ ëŒ€ë¦¬ ë¶„ë¥˜ê¸°ëŠ” 70%ì˜ ê³µê²© ì„±ê³µë¥ ì„ ë‹¬ì„±í–ˆë‹¤.
- 4. ëŒ€ë¦¬ ë¶„ë¥˜ê¸°ë¥¼ ì¶”ì¶œí•˜ëŠ” ê²ƒì€ ì •ë ¬ëœ ëª¨ë¸ì˜ íƒˆì˜¥ ê³µê²© ì·¨ì•½ì„±ì„ ëª¨ë¸ë§í•˜ê³  í•´ê²°í•˜ëŠ” íš¨ê³¼ì ì´ê³  íš¨ìœ¨ì ì¸ ë°©ë²•ì„ì„ ë³´ì—¬ì¤€ë‹¤.


---

*Generated on 2025-09-24 00:43:31*