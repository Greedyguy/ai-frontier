---
keywords:
  - Target Speaker Extraction
  - Brainprint-Modulated Target Speaker Extraction
  - EEG Signals
  - Auditory Attention Decoding
  - Adaptive Spectral Gain
category: cs.LG
publish_date: 2025-09-23
arxiv_id: 2509.17883
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T02:27:05.167521",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Target Speaker Extraction",
    "Brainprint-Modulated Target Speaker Extraction",
    "EEG Signals",
    "Auditory Attention Decoding",
    "Adaptive Spectral Gain"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Target Speaker Extraction": 0.78,
    "Brainprint-Modulated Target Speaker Extraction": 0.82,
    "EEG Signals": 0.75,
    "Auditory Attention Decoding": 0.77,
    "Adaptive Spectral Gain": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Target Speaker Extraction",
        "canonical": "Target Speaker Extraction",
        "aliases": [
          "TSE"
        ],
        "category": "unique_technical",
        "rationale": "This is a specific technique central to the paper's contribution, enabling personalized audio processing.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Brainprint-Modulated Target Speaker Extraction",
        "canonical": "Brainprint-Modulated Target Speaker Extraction",
        "aliases": [
          "BM-TSE"
        ],
        "category": "unique_technical",
        "rationale": "Represents the novel framework introduced in the paper, focusing on personalized audio extraction.",
        "novelty_score": 0.85,
        "connectivity_score": 0.6,
        "specificity_score": 0.9,
        "link_intent_score": 0.82
      },
      {
        "surface": "EEG signals",
        "canonical": "EEG Signals",
        "aliases": [
          "Electroencephalography Signals"
        ],
        "category": "specific_connectable",
        "rationale": "EEG signals are critical for the neuro-steered aspect of the technology discussed.",
        "novelty_score": 0.55,
        "connectivity_score": 0.8,
        "specificity_score": 0.7,
        "link_intent_score": 0.75
      },
      {
        "surface": "Auditory Attention Decoding",
        "canonical": "Auditory Attention Decoding",
        "aliases": [
          "AAD"
        ],
        "category": "specific_connectable",
        "rationale": "AAD is a key component in the personalized modulation mechanism of the framework.",
        "novelty_score": 0.6,
        "connectivity_score": 0.78,
        "specificity_score": 0.76,
        "link_intent_score": 0.77
      },
      {
        "surface": "Adaptive Spectral Gain",
        "canonical": "Adaptive Spectral Gain",
        "aliases": [
          "ASG"
        ],
        "category": "unique_technical",
        "rationale": "ASG is a novel module for extracting stable features, crucial for the proposed framework.",
        "novelty_score": 0.7,
        "connectivity_score": 0.55,
        "specificity_score": 0.8,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "neuro-steered",
      "personalized performance",
      "state-of-the-art performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Target Speaker Extraction",
      "resolved_canonical": "Target Speaker Extraction",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Brainprint-Modulated Target Speaker Extraction",
      "resolved_canonical": "Brainprint-Modulated Target Speaker Extraction",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.6,
        "specificity": 0.9,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "EEG signals",
      "resolved_canonical": "EEG Signals",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.8,
        "specificity": 0.7,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Auditory Attention Decoding",
      "resolved_canonical": "Auditory Attention Decoding",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.78,
        "specificity": 0.76,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Adaptive Spectral Gain",
      "resolved_canonical": "Adaptive Spectral Gain",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.55,
        "specificity": 0.8,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# Brainprint-Modulated Target Speaker Extraction

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17883.pdf)
**Category**: cs.LG
**Published**: 2025-09-23
**ArXiv ID**: [2509.17883](https://arxiv.org/abs/2509.17883)

## 🔗 유사한 논문
- [[2025-09-17/Personalization on a Budget_ Minimally-Labeled Continual Learning for Resource-Efficient Seizure Detection_20250917|Personalization on a Budget: Minimally-Labeled Continual Learning for Resource-Efficient Seizure Detection]] (81.1% similar)
- [[2025-09-23/Leveraging Multiple Speech Enhancers for Non-Intrusive Intelligibility Prediction for Hearing-Impaired Listeners_20250923|Leveraging Multiple Speech Enhancers for Non-Intrusive Intelligibility Prediction for Hearing-Impaired Listeners]] (80.8% similar)
- [[2025-09-22/IEFS-GMB_ Gradient Memory Bank-Guided Feature Selection Based on Information Entropy for EEG Classification of Neurological Disorders_20250922|IEFS-GMB: Gradient Memory Bank-Guided Feature Selection Based on Information Entropy for EEG Classification of Neurological Disorders]] (80.6% similar)
- [[2025-09-23/TMD-TTS_ A Unified Tibetan Multi-Dialect Text-to-Speech Synthesis for \"U-Tsang, Amdo and Kham Speech Dataset Generation_20250923|TMD-TTS: A Unified Tibetan Multi-Dialect Text-to-Speech Synthesis for \"U-Tsang, Amdo and Kham Speech Dataset Generation]] (80.5% similar)
- [[2025-09-19/UMind_ A Unified Multitask Network for Zero-Shot M/EEG Visual Decoding_20250919|UMind: A Unified Multitask Network for Zero-Shot M/EEG Visual Decoding]] (80.4% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/EEG Signals|EEG Signals]], [[keywords/Auditory Attention Decoding|Auditory Attention Decoding]]
**⚡ Unique Technical**: [[keywords/Target Speaker Extraction|Target Speaker Extraction]], [[keywords/Brainprint-Modulated Target Speaker Extraction|Brainprint-Modulated Target Speaker Extraction]], [[keywords/Adaptive Spectral Gain|Adaptive Spectral Gain]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.17883v1 Announce Type: cross 
Abstract: Achieving robust and personalized performance in neuro-steered Target Speaker Extraction (TSE) remains a significant challenge for next-generation hearing aids. This is primarily due to two factors: the inherent non-stationarity of EEG signals across sessions, and the high inter-subject variability that limits the efficacy of generalized models. To address these issues, we propose Brainprint-Modulated Target Speaker Extraction (BM-TSE), a novel framework for personalized and high-fidelity extraction. BM-TSE first employs a spatio-temporal EEG encoder with an Adaptive Spectral Gain (ASG) module to extract stable features resilient to non-stationarity. The core of our framework is a personalized modulation mechanism, where a unified brainmap embedding is learned under the joint supervision of subject identification (SID) and auditory attention decoding (AAD) tasks. This learned brainmap, encoding both static user traits and dynamic attentional states, actively refines the audio separation process, dynamically tailoring the output to each user. Evaluations on the public KUL and Cocktail Party datasets demonstrate that BM-TSE achieves state-of-the-art performance, significantly outperforming existing methods. Our code is publicly accessible at: https://github.com/rosshan-orz/BM-TSE.

## 📝 요약

뇌파 기반 목표 화자 추출(TSE)의 개인화된 성능을 향상시키기 위해 BM-TSE라는 새로운 프레임워크를 제안합니다. BM-TSE는 비정상적인 EEG 신호와 높은 개인 간 변동성을 극복하기 위해 적응형 스펙트럼 이득(ASG) 모듈을 사용하는 시공간 EEG 인코더를 활용합니다. 또한, 사용자 식별(SID)과 청각 주의 디코딩(AAD) 작업의 공동 감독 하에 학습된 통합 브레인맵 임베딩을 통해 개인화된 조절 메커니즘을 제공합니다. 이 브레인맵은 사용자 특성과 주의 상태를 인코딩하여 오디오 분리 과정을 사용자에 맞게 동적으로 조정합니다. KUL 및 칵테일 파티 데이터셋 평가에서 BM-TSE는 기존 방법을 능가하는 최첨단 성능을 보여주었습니다.

## 🎯 주요 포인트

- 1. BM-TSE는 비정상적인 EEG 신호와 높은 개인 간 변동성을 극복하기 위해 설계된 개인화된 고충실도 타겟 스피커 추출 프레임워크입니다.
- 2. BM-TSE는 적응형 스펙트럼 이득 모듈을 사용하여 비정상성에 강한 안정적인 특징을 추출하는 시공간 EEG 인코더를 활용합니다.
- 3. 개인화된 변조 메커니즘을 통해 사용자 식별 및 청각 주의 디코딩 작업의 공동 감독 하에 통합된 브레인맵 임베딩을 학습합니다.
- 4. 학습된 브레인맵은 정적 사용자 특성과 동적 주의 상태를 인코딩하여 오디오 분리 과정을 적극적으로 개선하고 사용자 맞춤형 출력을 제공합니다.
- 5. KUL 및 칵테일 파티 데이터셋 평가 결과, BM-TSE는 기존 방법을 크게 능가하며 최첨단 성능을 달성했습니다.


---

*Generated on 2025-09-24 02:27:05*