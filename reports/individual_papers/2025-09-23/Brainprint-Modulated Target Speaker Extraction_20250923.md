---
keywords:
  - Target Speaker Extraction
  - Brainprint-Modulated Target Speaker Extraction
  - EEG Signals
  - Auditory Attention Decoding
  - Adaptive Spectral Gain
category: cs.LG
publish_date: 2025-09-23
arxiv_id: 2509.17883
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T02:27:05.167521",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Target Speaker Extraction",
    "Brainprint-Modulated Target Speaker Extraction",
    "EEG Signals",
    "Auditory Attention Decoding",
    "Adaptive Spectral Gain"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Target Speaker Extraction": 0.78,
    "Brainprint-Modulated Target Speaker Extraction": 0.82,
    "EEG Signals": 0.75,
    "Auditory Attention Decoding": 0.77,
    "Adaptive Spectral Gain": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Target Speaker Extraction",
        "canonical": "Target Speaker Extraction",
        "aliases": [
          "TSE"
        ],
        "category": "unique_technical",
        "rationale": "This is a specific technique central to the paper's contribution, enabling personalized audio processing.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Brainprint-Modulated Target Speaker Extraction",
        "canonical": "Brainprint-Modulated Target Speaker Extraction",
        "aliases": [
          "BM-TSE"
        ],
        "category": "unique_technical",
        "rationale": "Represents the novel framework introduced in the paper, focusing on personalized audio extraction.",
        "novelty_score": 0.85,
        "connectivity_score": 0.6,
        "specificity_score": 0.9,
        "link_intent_score": 0.82
      },
      {
        "surface": "EEG signals",
        "canonical": "EEG Signals",
        "aliases": [
          "Electroencephalography Signals"
        ],
        "category": "specific_connectable",
        "rationale": "EEG signals are critical for the neuro-steered aspect of the technology discussed.",
        "novelty_score": 0.55,
        "connectivity_score": 0.8,
        "specificity_score": 0.7,
        "link_intent_score": 0.75
      },
      {
        "surface": "Auditory Attention Decoding",
        "canonical": "Auditory Attention Decoding",
        "aliases": [
          "AAD"
        ],
        "category": "specific_connectable",
        "rationale": "AAD is a key component in the personalized modulation mechanism of the framework.",
        "novelty_score": 0.6,
        "connectivity_score": 0.78,
        "specificity_score": 0.76,
        "link_intent_score": 0.77
      },
      {
        "surface": "Adaptive Spectral Gain",
        "canonical": "Adaptive Spectral Gain",
        "aliases": [
          "ASG"
        ],
        "category": "unique_technical",
        "rationale": "ASG is a novel module for extracting stable features, crucial for the proposed framework.",
        "novelty_score": 0.7,
        "connectivity_score": 0.55,
        "specificity_score": 0.8,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "neuro-steered",
      "personalized performance",
      "state-of-the-art performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Target Speaker Extraction",
      "resolved_canonical": "Target Speaker Extraction",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Brainprint-Modulated Target Speaker Extraction",
      "resolved_canonical": "Brainprint-Modulated Target Speaker Extraction",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.6,
        "specificity": 0.9,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "EEG signals",
      "resolved_canonical": "EEG Signals",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.8,
        "specificity": 0.7,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Auditory Attention Decoding",
      "resolved_canonical": "Auditory Attention Decoding",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.78,
        "specificity": 0.76,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Adaptive Spectral Gain",
      "resolved_canonical": "Adaptive Spectral Gain",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.55,
        "specificity": 0.8,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# Brainprint-Modulated Target Speaker Extraction

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17883.pdf)
**Category**: cs.LG
**Published**: 2025-09-23
**ArXiv ID**: [2509.17883](https://arxiv.org/abs/2509.17883)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-17/Personalization on a Budget_ Minimally-Labeled Continual Learning for Resource-Efficient Seizure Detection_20250917|Personalization on a Budget: Minimally-Labeled Continual Learning for Resource-Efficient Seizure Detection]] (81.1% similar)
- [[2025-09-23/Leveraging Multiple Speech Enhancers for Non-Intrusive Intelligibility Prediction for Hearing-Impaired Listeners_20250923|Leveraging Multiple Speech Enhancers for Non-Intrusive Intelligibility Prediction for Hearing-Impaired Listeners]] (80.8% similar)
- [[2025-09-22/IEFS-GMB_ Gradient Memory Bank-Guided Feature Selection Based on Information Entropy for EEG Classification of Neurological Disorders_20250922|IEFS-GMB: Gradient Memory Bank-Guided Feature Selection Based on Information Entropy for EEG Classification of Neurological Disorders]] (80.6% similar)
- [[2025-09-23/TMD-TTS_ A Unified Tibetan Multi-Dialect Text-to-Speech Synthesis for \"U-Tsang, Amdo and Kham Speech Dataset Generation_20250923|TMD-TTS: A Unified Tibetan Multi-Dialect Text-to-Speech Synthesis for \"U-Tsang, Amdo and Kham Speech Dataset Generation]] (80.5% similar)
- [[2025-09-19/UMind_ A Unified Multitask Network for Zero-Shot M/EEG Visual Decoding_20250919|UMind: A Unified Multitask Network for Zero-Shot M/EEG Visual Decoding]] (80.4% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/EEG Signals|EEG Signals]], [[keywords/Auditory Attention Decoding|Auditory Attention Decoding]]
**âš¡ Unique Technical**: [[keywords/Target Speaker Extraction|Target Speaker Extraction]], [[keywords/Brainprint-Modulated Target Speaker Extraction|Brainprint-Modulated Target Speaker Extraction]], [[keywords/Adaptive Spectral Gain|Adaptive Spectral Gain]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17883v1 Announce Type: cross 
Abstract: Achieving robust and personalized performance in neuro-steered Target Speaker Extraction (TSE) remains a significant challenge for next-generation hearing aids. This is primarily due to two factors: the inherent non-stationarity of EEG signals across sessions, and the high inter-subject variability that limits the efficacy of generalized models. To address these issues, we propose Brainprint-Modulated Target Speaker Extraction (BM-TSE), a novel framework for personalized and high-fidelity extraction. BM-TSE first employs a spatio-temporal EEG encoder with an Adaptive Spectral Gain (ASG) module to extract stable features resilient to non-stationarity. The core of our framework is a personalized modulation mechanism, where a unified brainmap embedding is learned under the joint supervision of subject identification (SID) and auditory attention decoding (AAD) tasks. This learned brainmap, encoding both static user traits and dynamic attentional states, actively refines the audio separation process, dynamically tailoring the output to each user. Evaluations on the public KUL and Cocktail Party datasets demonstrate that BM-TSE achieves state-of-the-art performance, significantly outperforming existing methods. Our code is publicly accessible at: https://github.com/rosshan-orz/BM-TSE.

## ğŸ“ ìš”ì•½

ë‡ŒíŒŒ ê¸°ë°˜ ëª©í‘œ í™”ì ì¶”ì¶œ(TSE)ì˜ ê°œì¸í™”ëœ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ BM-TSEë¼ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. BM-TSEëŠ” ë¹„ì •ìƒì ì¸ EEG ì‹ í˜¸ì™€ ë†’ì€ ê°œì¸ ê°„ ë³€ë™ì„±ì„ ê·¹ë³µí•˜ê¸° ìœ„í•´ ì ì‘í˜• ìŠ¤í™íŠ¸ëŸ¼ ì´ë“(ASG) ëª¨ë“ˆì„ ì‚¬ìš©í•˜ëŠ” ì‹œê³µê°„ EEG ì¸ì½”ë”ë¥¼ í™œìš©í•©ë‹ˆë‹¤. ë˜í•œ, ì‚¬ìš©ì ì‹ë³„(SID)ê³¼ ì²­ê° ì£¼ì˜ ë””ì½”ë”©(AAD) ì‘ì—…ì˜ ê³µë™ ê°ë… í•˜ì— í•™ìŠµëœ í†µí•© ë¸Œë ˆì¸ë§µ ì„ë² ë”©ì„ í†µí•´ ê°œì¸í™”ëœ ì¡°ì ˆ ë©”ì»¤ë‹ˆì¦˜ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ ë¸Œë ˆì¸ë§µì€ ì‚¬ìš©ì íŠ¹ì„±ê³¼ ì£¼ì˜ ìƒíƒœë¥¼ ì¸ì½”ë”©í•˜ì—¬ ì˜¤ë””ì˜¤ ë¶„ë¦¬ ê³¼ì •ì„ ì‚¬ìš©ìì— ë§ê²Œ ë™ì ìœ¼ë¡œ ì¡°ì •í•©ë‹ˆë‹¤. KUL ë° ì¹µí…Œì¼ íŒŒí‹° ë°ì´í„°ì…‹ í‰ê°€ì—ì„œ BM-TSEëŠ” ê¸°ì¡´ ë°©ë²•ì„ ëŠ¥ê°€í•˜ëŠ” ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. BM-TSEëŠ” ë¹„ì •ìƒì ì¸ EEG ì‹ í˜¸ì™€ ë†’ì€ ê°œì¸ ê°„ ë³€ë™ì„±ì„ ê·¹ë³µí•˜ê¸° ìœ„í•´ ì„¤ê³„ëœ ê°œì¸í™”ëœ ê³ ì¶©ì‹¤ë„ íƒ€ê²Ÿ ìŠ¤í”¼ì»¤ ì¶”ì¶œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.
- 2. BM-TSEëŠ” ì ì‘í˜• ìŠ¤í™íŠ¸ëŸ¼ ì´ë“ ëª¨ë“ˆì„ ì‚¬ìš©í•˜ì—¬ ë¹„ì •ìƒì„±ì— ê°•í•œ ì•ˆì •ì ì¸ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ëŠ” ì‹œê³µê°„ EEG ì¸ì½”ë”ë¥¼ í™œìš©í•©ë‹ˆë‹¤.
- 3. ê°œì¸í™”ëœ ë³€ì¡° ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´ ì‚¬ìš©ì ì‹ë³„ ë° ì²­ê° ì£¼ì˜ ë””ì½”ë”© ì‘ì—…ì˜ ê³µë™ ê°ë… í•˜ì— í†µí•©ëœ ë¸Œë ˆì¸ë§µ ì„ë² ë”©ì„ í•™ìŠµí•©ë‹ˆë‹¤.
- 4. í•™ìŠµëœ ë¸Œë ˆì¸ë§µì€ ì •ì  ì‚¬ìš©ì íŠ¹ì„±ê³¼ ë™ì  ì£¼ì˜ ìƒíƒœë¥¼ ì¸ì½”ë”©í•˜ì—¬ ì˜¤ë””ì˜¤ ë¶„ë¦¬ ê³¼ì •ì„ ì ê·¹ì ìœ¼ë¡œ ê°œì„ í•˜ê³  ì‚¬ìš©ì ë§ì¶¤í˜• ì¶œë ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
- 5. KUL ë° ì¹µí…Œì¼ íŒŒí‹° ë°ì´í„°ì…‹ í‰ê°€ ê²°ê³¼, BM-TSEëŠ” ê¸°ì¡´ ë°©ë²•ì„ í¬ê²Œ ëŠ¥ê°€í•˜ë©° ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 02:27:05*