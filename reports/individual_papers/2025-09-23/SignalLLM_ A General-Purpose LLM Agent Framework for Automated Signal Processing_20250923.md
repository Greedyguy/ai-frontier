---
keywords:
  - Large Language Model
  - Retrieval Augmented Generation
  - Few-Shot Learning
  - Zero-Shot Learning
  - Multimodal Learning
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.17197
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T23:48:24.674702",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Retrieval Augmented Generation",
    "Few-Shot Learning",
    "Zero-Shot Learning",
    "Multimodal Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Retrieval Augmented Generation": 0.79,
    "Few-Shot Learning": 0.78,
    "Zero-Shot Learning": 0.77,
    "Multimodal Learning": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Large Language Models"
        ],
        "category": "broad_technical",
        "rationale": "Central to the framework, LLMs offer general-purpose knowledge and reasoning capabilities.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Retrieval Augmented Generation",
        "canonical": "Retrieval Augmented Generation",
        "aliases": [
          "RAG"
        ],
        "category": "specific_connectable",
        "rationale": "RAG is a key component in the modular architecture for adaptive retrieval and generation.",
        "novelty_score": 0.58,
        "connectivity_score": 0.82,
        "specificity_score": 0.78,
        "link_intent_score": 0.79
      },
      {
        "surface": "Few-Shot Learning",
        "canonical": "Few-Shot Learning",
        "aliases": [
          "Few-Shot"
        ],
        "category": "specific_connectable",
        "rationale": "Few-Shot Learning is highlighted for its superior performance in experimental results.",
        "novelty_score": 0.5,
        "connectivity_score": 0.8,
        "specificity_score": 0.72,
        "link_intent_score": 0.78
      },
      {
        "surface": "Zero-Shot Learning",
        "canonical": "Zero-Shot Learning",
        "aliases": [
          "Zero-Shot"
        ],
        "category": "specific_connectable",
        "rationale": "Zero-Shot Learning is emphasized for its effectiveness in the framework's evaluation.",
        "novelty_score": 0.52,
        "connectivity_score": 0.79,
        "specificity_score": 0.73,
        "link_intent_score": 0.77
      },
      {
        "surface": "Cross-Modal Reasoning",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Cross-Modal",
          "Cross-Modal Reasoning"
        ],
        "category": "specific_connectable",
        "rationale": "Cross-modal reasoning is crucial for the framework's ability to handle different signal modalities.",
        "novelty_score": 0.6,
        "connectivity_score": 0.83,
        "specificity_score": 0.75,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "signal processing",
      "framework",
      "tasks"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Retrieval Augmented Generation",
      "resolved_canonical": "Retrieval Augmented Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.82,
        "specificity": 0.78,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Few-Shot Learning",
      "resolved_canonical": "Few-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.8,
        "specificity": 0.72,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Zero-Shot Learning",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.52,
        "connectivity": 0.79,
        "specificity": 0.73,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Cross-Modal Reasoning",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.83,
        "specificity": 0.75,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# SignalLLM: A General-Purpose LLM Agent Framework for Automated Signal Processing

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17197.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.17197](https://arxiv.org/abs/2509.17197)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/LLM-I_ LLMs are Naturally Interleaved Multimodal Creators_20250918|LLM-I: LLMs are Naturally Interleaved Multimodal Creators]] (84.9% similar)
- [[2025-09-23/Large Language Models as End-to-end Combinatorial Optimization Solvers_20250923|Large Language Models as End-to-end Combinatorial Optimization Solvers]] (83.8% similar)
- [[2025-09-23/LLMs as Layout Designers_ A Spatial Reasoning Perspective_20250923|LLMs as Layout Designers: A Spatial Reasoning Perspective]] (83.8% similar)
- [[2025-09-23/Question Answering with LLMs and Learning from Answer Sets_20250923|Question Answering with LLMs and Learning from Answer Sets]] (83.3% similar)
- [[2025-09-19/An LLM-based multi-agent framework for agile effort estimation_20250919|An LLM-based multi-agent framework for agile effort estimation]] (83.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Retrieval Augmented Generation|Retrieval Augmented Generation]], [[keywords/Few-Shot Learning|Few-Shot Learning]], [[keywords/Zero-Shot Learning|Zero-Shot Learning]], [[keywords/Multimodal Learning|Multimodal Learning]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17197v1 Announce Type: cross 
Abstract: Modern signal processing (SP) pipelines, whether model-based or data-driven, often constrained by complex and fragmented workflow, rely heavily on expert knowledge and manual engineering, and struggle with adaptability and generalization under limited data. In contrast, Large Language Models (LLMs) offer strong reasoning capabilities, broad general-purpose knowledge, in-context learning, and cross-modal transfer abilities, positioning them as powerful tools for automating and generalizing SP workflows. Motivated by these potentials, we introduce SignalLLM, the first general-purpose LLM-based agent framework for general SP tasks. Unlike prior LLM-based SP approaches that are limited to narrow applications or tricky prompting, SignalLLM introduces a principled, modular architecture. It decomposes high-level SP goals into structured subtasks via in-context learning and domain-specific retrieval, followed by hierarchical planning through adaptive retrieval-augmented generation (RAG) and refinement; these subtasks are then executed through prompt-based reasoning, cross-modal reasoning, code synthesis, model invocation, or data-driven LLM-assisted modeling. Its generalizable design enables the flexible selection of problem solving strategies across different signal modalities, task types, and data conditions. We demonstrate the versatility and effectiveness of SignalLLM through five representative tasks in communication and sensing, such as radar target detection, human activity recognition, and text compression. Experimental results show superior performance over traditional and existing LLM-based methods, particularly in few-shot and zero-shot settings.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì‹ í˜¸ ì²˜ë¦¬(SP) ì‘ì—…ì˜ ìë™í™”ì™€ ì¼ë°˜í™”ë¥¼ ìœ„í•´ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ í™œìš©í•œ SignalLLM í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ SP íŒŒì´í”„ë¼ì¸ì€ ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ì™€ ì œí•œëœ ë°ì´í„°ë¡œ ì¸í•´ ì ì‘ì„±ê³¼ ì¼ë°˜í™”ì— ì–´ë ¤ì›€ì„ ê²ªìŠµë‹ˆë‹¤. SignalLLMì€ LLMì˜ ê°•ë ¥í•œ ì¶”ë¡  ëŠ¥ë ¥ê³¼ ë‹¤ì–‘í•œ ì§€ì‹ ê¸°ë°˜ì„ í™œìš©í•˜ì—¬ SP ëª©í‘œë¥¼ êµ¬ì¡°í™”ëœ í•˜ìœ„ ì‘ì—…ìœ¼ë¡œ ë¶„í•´í•˜ê³ , ì ì‘í˜• ê²€ìƒ‰ ì¦ê°• ìƒì„±(RAG)ê³¼ ì •ì œë¥¼ í†µí•´ ê³„ì¸µì ìœ¼ë¡œ ê³„íší•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë‹¤ì–‘í•œ ì‹ í˜¸ ëª¨ë‹¬ë¦¬í‹°ì™€ ë°ì´í„° ì¡°ê±´ì— ë§ëŠ” ë¬¸ì œ í•´ê²° ì „ëµì„ ìœ ì—°í•˜ê²Œ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, SignalLLMì€ í†µì‹  ë° ê°ì§€ ë¶„ì•¼ì˜ ë‹¤ì„¯ ê°€ì§€ ëŒ€í‘œ ì‘ì—…ì—ì„œ ê¸°ì¡´ ë°©ë²•ë³´ë‹¤ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë©°, íŠ¹íˆ ì ì€ ë°ì´í„° í™˜ê²½ì—ì„œë„ ìš°ìˆ˜í•œ ì„±ê³¼ë¥¼ ë‚˜íƒ€ëƒˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. SignalLLMì€ ì¼ë°˜ ì‹ í˜¸ ì²˜ë¦¬ ì‘ì—…ì„ ìœ„í•œ ìµœì´ˆì˜ ë²”ìš© LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ í”„ë ˆì„ì›Œí¬ë¡œ ì†Œê°œë©ë‹ˆë‹¤.
- 2. SignalLLMì€ ê³ ìˆ˜ì¤€ì˜ ì‹ í˜¸ ì²˜ë¦¬ ëª©í‘œë¥¼ êµ¬ì¡°í™”ëœ í•˜ìœ„ ì‘ì—…ìœ¼ë¡œ ë¶„í•´í•˜ê³ , ì ì‘í˜• ê²€ìƒ‰ ë³´ê°• ìƒì„±(RAG) ë° ì •ì œë¥¼ í†µí•´ ê³„ì¸µì  ê³„íšì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
- 3. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ë‹¤ì–‘í•œ ì‹ í˜¸ ëª¨ë‹¬ë¦¬í‹°, ì‘ì—… ìœ í˜• ë° ë°ì´í„° ì¡°ê±´ì— ê±¸ì³ ë¬¸ì œ í•´ê²° ì „ëµì„ ìœ ì—°í•˜ê²Œ ì„ íƒí•  ìˆ˜ ìˆëŠ” ì¼ë°˜í™”ëœ ì„¤ê³„ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
- 4. ì‹¤í—˜ ê²°ê³¼, SignalLLMì€ íŠ¹íˆ ì†Œìˆ˜ ìƒ· ë° ì œë¡œ ìƒ· ì„¤ì •ì—ì„œ ê¸°ì¡´ì˜ ì „í†µì  ë° LLM ê¸°ë°˜ ë°©ë²•ë“¤ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.
- 5. SignalLLMì˜ ë‹¤ì¬ë‹¤ëŠ¥í•¨ê³¼ íš¨ê³¼ëŠ” ë ˆì´ë” ëª©í‘œ íƒì§€, ì¸ê°„ í™œë™ ì¸ì‹, í…ìŠ¤íŠ¸ ì••ì¶• ë“± í†µì‹  ë° ì„¼ì‹± ë¶„ì•¼ì˜ ë‹¤ì„¯ ê°€ì§€ ëŒ€í‘œ ì‘ì—…ì„ í†µí•´ ì…ì¦ë˜ì—ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-23 23:48:24*