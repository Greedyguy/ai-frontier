---
keywords:
  - Transformer
  - Shifted Position Embedding
  - Attention Mechanism
  - style consistency
category: cs.CV
publish_date: 2025-09-23
arxiv_id: 2509.17088
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T04:45:34.766306",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Transformer",
    "Shifted Position Embedding",
    "Attention Mechanism",
    "style consistency"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Transformer": 0.78,
    "Shifted Position Embedding": 0.81,
    "Attention Mechanism": 0.75,
    "style consistency": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Diffusion Transformer",
        "canonical": "Transformer",
        "aliases": [
          "DiT"
        ],
        "category": "broad_technical",
        "rationale": "Diffusion Transformer is a specific application of Transformer models, which are central to many machine learning tasks.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.78
      },
      {
        "surface": "Shifted Position Embedding",
        "canonical": "Shifted Position Embedding",
        "aliases": [
          "ShiftPE"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel technique introduced in the paper, crucial for resolving positional conflicts in the model.",
        "novelty_score": 0.92,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.81
      },
      {
        "surface": "Advanced Attention Sharing",
        "canonical": "Attention Mechanism",
        "aliases": [
          "AAS"
        ],
        "category": "specific_connectable",
        "rationale": "This technique builds on existing attention mechanisms, enhancing their application in diffusion models.",
        "novelty_score": 0.55,
        "connectivity_score": 0.79,
        "specificity_score": 0.72,
        "link_intent_score": 0.75
      },
      {
        "surface": "style consistency",
        "canonical": "style consistency",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Ensuring style consistency is a unique challenge addressed by the paper, relevant for linking to creative workflows.",
        "novelty_score": 0.68,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "training-free",
      "position embeddings",
      "query, key, and value feature extraction"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Diffusion Transformer",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Shifted Position Embedding",
      "resolved_canonical": "Shifted Position Embedding",
      "decision": "linked",
      "scores": {
        "novelty": 0.92,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.81
      }
    },
    {
      "candidate_surface": "Advanced Attention Sharing",
      "resolved_canonical": "Attention Mechanism",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.79,
        "specificity": 0.72,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "style consistency",
      "resolved_canonical": "style consistency",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# AlignedGen: Aligning Style Across Generated Images

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17088.pdf)
**Category**: cs.CV
**Published**: 2025-09-23
**ArXiv ID**: [2509.17088](https://arxiv.org/abs/2509.17088)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Style Transfer with Diffusion Models for Synthetic-to-Real Domain Adaptation_20250919|Style Transfer with Diffusion Models for Synthetic-to-Real Domain Adaptation]] (84.8% similar)
- [[2025-09-19/TIDE_ Achieving Balanced Subject-Driven Image Generation via Target-Instructed Diffusion Enhancement_20250919|TIDE: Achieving Balanced Subject-Driven Image Generation via Target-Instructed Diffusion Enhancement]] (84.4% similar)
- [[2025-09-22/RespoDiff_ Dual-Module Bottleneck Transformation for Responsible & Faithful T2I Generation_20250922|RespoDiff: Dual-Module Bottleneck Transformation for Responsible & Faithful T2I Generation]] (84.2% similar)
- [[2025-09-22/MaskAttn-SDXL_ Controllable Region-Level Text-To-Image Generation_20250922|MaskAttn-SDXL: Controllable Region-Level Text-To-Image Generation]] (83.5% similar)
- [[2025-09-22/Layout Stroke Imitation_ A Layout Guided Handwriting Stroke Generation for Style Imitation with Diffusion Model_20250922|Layout Stroke Imitation: A Layout Guided Handwriting Stroke Generation for Style Imitation with Diffusion Model]] (83.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Transformer|Transformer]]
**ğŸ”— Specific Connectable**: [[keywords/Attention Mechanism|Attention Mechanism]]
**âš¡ Unique Technical**: [[keywords/Shifted Position Embedding|Shifted Position Embedding]], [[keywords/style consistency|style consistency]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17088v1 Announce Type: new 
Abstract: Despite their generative power, diffusion models struggle to maintain style consistency across images conditioned on the same style prompt, hindering their practical deployment in creative workflows. While several training-free methods attempt to solve this, they are constrained to the U-Net architecture, which not only leads to low-quality results and artifacts like object repetition but also renders them incompatible with superior Diffusion Transformer (DiT). To address these issues, we introduce AlignedGen, a novel training-free framework that enhances style consistency across images generated by DiT models. Our work first reveals a critical insight: naive attention sharing fails in DiT due to conflicting positional signals from improper position embeddings. We introduce Shifted Position Embedding (ShiftPE), an effective solution that resolves this conflict by allocating a non-overlapping set of positional indices to each image. Building on this foundation, we develop Advanced Attention Sharing (AAS), a suite of three techniques meticulously designed to fully unleash the potential of attention sharing within the DiT. Furthermore, to broaden the applicability of our method, we present an efficient query, key, and value feature extraction algorithm, enabling our method to seamlessly incorporate external images as style references. Extensive experimental results validate that our method effectively enhances style consistency across generated images while maintaining precise text-to-image alignment.

## ğŸ“ ìš”ì•½

ë…¼ë¬¸ì€ ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸ì— ë”°ë¼ ìƒì„±ëœ ì´ë¯¸ì§€ ê°„ì˜ ìŠ¤íƒ€ì¼ ì¼ê´€ì„±ì„ ìœ ì§€í•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªëŠ” í™•ì‚° ëª¨ë¸ì˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ AlignedGenì´ë¼ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ ë°©ë²•ë“¤ì€ U-Net ì•„í‚¤í…ì²˜ì— êµ­í•œë˜ì–´ ë‚®ì€ í’ˆì§ˆì˜ ê²°ê³¼ë¥¼ ì´ˆë˜í–ˆì§€ë§Œ, AlignedGenì€ Diffusion Transformer(DiT) ëª¨ë¸ì—ì„œ ìŠ¤íƒ€ì¼ ì¼ê´€ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì£¼ìš” ê¸°ì—¬ë¡œëŠ” ìœ„ì¹˜ ì„ë² ë”© ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” Shifted Position Embedding(ShiftPE)ê³¼ Advanced Attention Sharing(AAS) ê¸°ìˆ ì´ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ì™¸ë¶€ ì´ë¯¸ì§€ë¥¼ ìŠ¤íƒ€ì¼ ì°¸ì¡°ë¡œ í™œìš©í•  ìˆ˜ ìˆëŠ” íš¨ìœ¨ì ì¸ íŠ¹ì§• ì¶”ì¶œ ì•Œê³ ë¦¬ì¦˜ì„ ì œì‹œí•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì´ ìƒì„±ëœ ì´ë¯¸ì§€ì˜ ìŠ¤íƒ€ì¼ ì¼ê´€ì„±ì„ íš¨ê³¼ì ìœ¼ë¡œ í–¥ìƒì‹œí‚¤ë©´ì„œ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ì •ë ¬ì„ ìœ ì§€í•¨ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. í™•ì‚° ëª¨ë¸ì€ ë™ì¼í•œ ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•´ ì´ë¯¸ì§€ ê°„ ìŠ¤íƒ€ì¼ ì¼ê´€ì„±ì„ ìœ ì§€í•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªìŠµë‹ˆë‹¤.
- 2. AlignedGenì€ DiT ëª¨ë¸ì—ì„œ ìƒì„±ëœ ì´ë¯¸ì§€ì˜ ìŠ¤íƒ€ì¼ ì¼ê´€ì„±ì„ í–¥ìƒì‹œí‚¤ëŠ” ìƒˆë¡œìš´ í›ˆë ¨ ì—†ëŠ” í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.
- 3. Shifted Position Embedding (ShiftPE)ì€ DiTì˜ ìœ„ì¹˜ ì„ë² ë”© ë¬¸ì œë¥¼ í•´ê²°í•˜ì—¬ ì£¼ì˜ ê³µìœ ì˜ ì ì¬ë ¥ì„ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤.
- 4. Advanced Attention Sharing (AAS)ì€ DiT ë‚´ì—ì„œ ì£¼ì˜ ê³µìœ ë¥¼ ìµœì í™”í•˜ê¸° ìœ„í•´ ì„¤ê³„ëœ ì„¸ ê°€ì§€ ê¸°ìˆ ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.
- 5. ì œì•ˆëœ ë°©ë²•ì€ ì™¸ë¶€ ì´ë¯¸ì§€ë¥¼ ìŠ¤íƒ€ì¼ ì°¸ì¡°ë¡œ í†µí•©í•  ìˆ˜ ìˆìœ¼ë©°, ì‹¤í—˜ ê²°ê³¼ ìŠ¤íƒ€ì¼ ì¼ê´€ì„±ì„ íš¨ê³¼ì ìœ¼ë¡œ í–¥ìƒì‹œí‚µë‹ˆë‹¤.


---

*Generated on 2025-09-24 04:45:34*