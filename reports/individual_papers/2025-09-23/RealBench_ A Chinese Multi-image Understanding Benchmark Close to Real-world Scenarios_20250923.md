---
keywords:
  - RealBench Dataset
  - Multimodal Learning
  - Closed-Source Models
  - Open-Source Visual Models
  - Multi-Image Understanding
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2509.17421
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:25:47.017690",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "RealBench Dataset",
    "Multimodal Learning",
    "Closed-Source Models",
    "Open-Source Visual Models",
    "Multi-Image Understanding"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "RealBench Dataset": 0.8,
    "Multimodal Learning": 0.78,
    "Closed-Source Models": 0.72,
    "Open-Source Visual Models": 0.74,
    "Multi-Image Understanding": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "RealBench",
        "canonical": "RealBench Dataset",
        "aliases": [
          "Chinese Multi-image Dataset"
        ],
        "category": "unique_technical",
        "rationale": "RealBench is a novel dataset specifically designed for Chinese multi-image understanding, providing a unique resource for research in this area.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "multimodal LLMs",
        "canonical": "Multimodal Learning",
        "aliases": [
          "multimodal models"
        ],
        "category": "specific_connectable",
        "rationale": "Multimodal Learning is crucial for understanding and processing multiple forms of data, linking to existing research on integrating different modalities.",
        "novelty_score": 0.7,
        "connectivity_score": 0.85,
        "specificity_score": 0.75,
        "link_intent_score": 0.78
      },
      {
        "surface": "closed-source models",
        "canonical": "Closed-Source Models",
        "aliases": [
          "proprietary models"
        ],
        "category": "unique_technical",
        "rationale": "Closed-source models are significant in the context of performance comparisons with open-source alternatives, highlighting differences in capabilities.",
        "novelty_score": 0.65,
        "connectivity_score": 0.6,
        "specificity_score": 0.7,
        "link_intent_score": 0.72
      },
      {
        "surface": "open-source visual/video models",
        "canonical": "Open-Source Visual Models",
        "aliases": [
          "open-source video models"
        ],
        "category": "unique_technical",
        "rationale": "Open-source visual models are important for community-driven research and development, providing a contrast to closed-source models.",
        "novelty_score": 0.68,
        "connectivity_score": 0.75,
        "specificity_score": 0.78,
        "link_intent_score": 0.74
      },
      {
        "surface": "multi-image understanding",
        "canonical": "Multi-Image Understanding",
        "aliases": [
          "multi-image analysis"
        ],
        "category": "specific_connectable",
        "rationale": "Multi-Image Understanding is a key challenge in computer vision, linking to broader research on image processing and analysis.",
        "novelty_score": 0.6,
        "connectivity_score": 0.8,
        "specificity_score": 0.82,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "evaluation",
      "performance gap"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "RealBench",
      "resolved_canonical": "RealBench Dataset",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "multimodal LLMs",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.85,
        "specificity": 0.75,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "closed-source models",
      "resolved_canonical": "Closed-Source Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.6,
        "specificity": 0.7,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "open-source visual/video models",
      "resolved_canonical": "Open-Source Visual Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.75,
        "specificity": 0.78,
        "link_intent": 0.74
      }
    },
    {
      "candidate_surface": "multi-image understanding",
      "resolved_canonical": "Multi-Image Understanding",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.8,
        "specificity": 0.82,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# RealBench: A Chinese Multi-image Understanding Benchmark Close to Real-world Scenarios

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17421.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2509.17421](https://arxiv.org/abs/2509.17421)

## 🔗 유사한 논문
- [[2025-09-22/Multi-Physics_ A Comprehensive Benchmark for Multimodal LLMs Reasoning on Chinese Multi-Subject Physics Problems_20250922|Multi-Physics: A Comprehensive Benchmark for Multimodal LLMs Reasoning on Chinese Multi-Subject Physics Problems]] (84.0% similar)
- [[2025-09-19/UnifiedVisual_ A Framework for Constructing Unified Vision-Language Datasets_20250919|UnifiedVisual: A Framework for Constructing Unified Vision-Language Datasets]] (81.1% similar)
- [[2025-09-22/Perception-R1_ Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward_20250922|Perception-R1: Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward]] (81.1% similar)
- [[2025-09-23/NUMINA_ A Natural Understanding Benchmark for Multi-dimensional Intelligence and Numerical Reasoning Abilities_20250923|NUMINA: A Natural Understanding Benchmark for Multi-dimensional Intelligence and Numerical Reasoning Abilities]] (80.8% similar)
- [[2025-09-22/A Benchmark for End-to-End Zero-Shot Biomedical Relation Extraction with LLMs_ Experiments with OpenAI Models_20250922|A Benchmark for End-to-End Zero-Shot Biomedical Relation Extraction with LLMs: Experiments with OpenAI Models]] (80.7% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]], [[keywords/Multi-Image Understanding|Multi-Image Understanding]]
**⚡ Unique Technical**: [[keywords/RealBench Dataset|RealBench Dataset]], [[keywords/Closed-Source Models|Closed-Source Models]], [[keywords/Open-Source Visual Models|Open-Source Visual Models]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.17421v1 Announce Type: new 
Abstract: While various multimodal multi-image evaluation datasets have been emerged, but these datasets are primarily based on English, and there has yet to be a Chinese multi-image dataset. To fill this gap, we introduce RealBench, the first Chinese multimodal multi-image dataset, which contains 9393 samples and 69910 images. RealBench distinguishes itself by incorporating real user-generated content, ensuring high relevance to real-world applications. Additionally, the dataset covers a wide variety of scenes, image resolutions, and image structures, further increasing the difficulty of multi-image understanding. Ultimately, we conduct a comprehensive evaluation of RealBench using 21 multimodal LLMs of different sizes, including closed-source models that support multi-image inputs as well as open-source visual and video models. The experimental results indicate that even the most powerful closed-source models still face challenges when handling multi-image Chinese scenarios. Moreover, there remains a noticeable performance gap of around 71.8\% on average between open-source visual/video models and closed-source models. These results show that RealBench provides an important research foundation for further exploring multi-image understanding capabilities in the Chinese context.

## 📝 요약

RealBench는 중국어 다중 이미지 데이터셋으로, 9393개의 샘플과 69910개의 이미지를 포함하고 있습니다. 이 데이터셋은 실제 사용자 생성 콘텐츠를 포함하여 현실 세계 응용에 높은 관련성을 지니며, 다양한 장면, 이미지 해상도, 이미지 구조를 다루어 다중 이미지 이해의 난이도를 높였습니다. 21개의 다양한 크기의 멀티모달 LLM을 사용한 평가 결과, 가장 강력한 폐쇄형 모델조차 중국어 다중 이미지 시나리오에서 어려움을 겪고 있으며, 오픈 소스 비주얼/비디오 모델과 폐쇄형 모델 간 평균 약 71.8%의 성능 차이가 존재함을 보여주었습니다. RealBench는 중국어 맥락에서 다중 이미지 이해 능력을 탐구하는 데 중요한 연구 기반을 제공합니다.

## 🎯 주요 포인트

- 1. RealBench는 중국어 다중 이미지 데이터셋으로, 9393개의 샘플과 69910개의 이미지를 포함하고 있습니다.
- 2. 이 데이터셋은 실제 사용자 생성 콘텐츠를 포함하여 현실 세계 응용에 높은 관련성을 보장합니다.
- 3. 다양한 장면, 이미지 해상도, 이미지 구조를 포함하여 다중 이미지 이해의 난이도를 높였습니다.
- 4. 21개의 다양한 크기의 멀티모달 LLM을 사용하여 RealBench를 평가한 결과, 강력한 폐쇄형 모델도 중국어 다중 이미지 시나리오에서 여전히 도전에 직면하고 있음을 보여줍니다.
- 5. 개방형 비주얼/비디오 모델과 폐쇄형 모델 간의 성능 격차는 평균 약 71.8%로 나타났습니다.


---

*Generated on 2025-09-24 03:25:47*