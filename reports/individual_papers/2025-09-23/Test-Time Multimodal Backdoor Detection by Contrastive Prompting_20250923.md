---
keywords:
  - Multimodal Learning
  - Backdoor Detection
  - Zero-Shot Learning
  - Vision-Language Model
category: cs.LG
publish_date: 2025-09-23
arxiv_id: 2405.15269
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T02:55:46.266793",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multimodal Learning",
    "Backdoor Detection",
    "Zero-Shot Learning",
    "Vision-Language Model"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multimodal Learning": 0.82,
    "Backdoor Detection": 0.79,
    "Zero-Shot Learning": 0.84,
    "Vision-Language Model": 0.85
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multimodal contrastive learning",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal contrastive methods",
          "Multimodal contrastive"
        ],
        "category": "specific_connectable",
        "rationale": "Links to the trending concept of integrating multiple modalities in learning systems.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "Backdoor detection",
        "canonical": "Backdoor Detection",
        "aliases": [
          "Backdoor attack defense",
          "Backdoor defense"
        ],
        "category": "unique_technical",
        "rationale": "A unique technical concept focusing on identifying and mitigating backdoor attacks in models.",
        "novelty_score": 0.72,
        "connectivity_score": 0.65,
        "specificity_score": 0.81,
        "link_intent_score": 0.79
      },
      {
        "surface": "Zero-shot classification",
        "canonical": "Zero-Shot Learning",
        "aliases": [
          "Zero-shot inference",
          "Zero-shot methods"
        ],
        "category": "specific_connectable",
        "rationale": "A specific learning paradigm that enhances model adaptability and is widely discussed in recent research.",
        "novelty_score": 0.58,
        "connectivity_score": 0.87,
        "specificity_score": 0.75,
        "link_intent_score": 0.84
      },
      {
        "surface": "Vision-Language Model",
        "canonical": "Vision-Language Model",
        "aliases": [
          "Vision-Language integration",
          "Vision-Language systems"
        ],
        "category": "evolved_concepts",
        "rationale": "Represents the integration of visual and textual data, a growing area in AI research.",
        "novelty_score": 0.6,
        "connectivity_score": 0.9,
        "specificity_score": 0.8,
        "link_intent_score": 0.85
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "experiment"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multimodal contrastive learning",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Backdoor detection",
      "resolved_canonical": "Backdoor Detection",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.65,
        "specificity": 0.81,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Zero-shot classification",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.87,
        "specificity": 0.75,
        "link_intent": 0.84
      }
    },
    {
      "candidate_surface": "Vision-Language Model",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.9,
        "specificity": 0.8,
        "link_intent": 0.85
      }
    }
  ]
}
-->

# Test-Time Multimodal Backdoor Detection by Contrastive Prompting

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2405.15269.pdf)
**Category**: cs.LG
**Published**: 2025-09-23
**ArXiv ID**: [2405.15269](https://arxiv.org/abs/2405.15269)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Backdoor Mitigation via Invertible Pruning Masks_20250922|Backdoor Mitigation via Invertible Pruning Masks]] (85.2% similar)
- [[2025-09-22/Inverting Trojans in LLMs_20250922|Inverting Trojans in LLMs]] (84.8% similar)
- [[2025-09-22/CLIPTTA_ Robust Contrastive Vision-Language Test-Time Adaptation_20250922|CLIPTTA: Robust Contrastive Vision-Language Test-Time Adaptation]] (83.7% similar)
- [[2025-09-22/CoDoL_ Conditional Domain Prompt Learning for Out-of-Distribution Generalization_20250922|CoDoL: Conditional Domain Prompt Learning for Out-of-Distribution Generalization]] (83.3% similar)
- [[2025-09-22/Robust Vision-Language Models via Tensor Decomposition_ A Defense Against Adversarial Attacks_20250922|Robust Vision-Language Models via Tensor Decomposition: A Defense Against Adversarial Attacks]] (82.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]], [[keywords/Zero-Shot Learning|Zero-Shot Learning]]
**âš¡ Unique Technical**: [[keywords/Backdoor Detection|Backdoor Detection]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2405.15269v3 Announce Type: replace-cross 
Abstract: While multimodal contrastive learning methods (e.g., CLIP) can achieve impressive zero-shot classification performance, recent research has revealed that these methods are vulnerable to backdoor attacks. To defend against backdoor attacks on CLIP, existing defense methods focus on either the pre-training stage or the fine-tuning stage, which would unfortunately cause high computational costs due to numerous parameter updates and are not applicable in black-box settings. In this paper, we provide the first attempt at a computationally efficient backdoor detection method to defend against backdoored CLIP in the \emph{inference} stage. We empirically find that the visual representations of backdoored images are \emph{insensitive} to \emph{benign} and \emph{malignant} changes in class description texts. Motivated by this observation, we propose BDetCLIP, a novel test-time backdoor detection method based on contrastive prompting. Specifically, we first prompt a language model (e.g., GPT-4) to produce class-related description texts (benign) and class-perturbed random texts (malignant) by specially designed instructions. Then, the distribution difference in cosine similarity between images and the two types of class description texts can be used as the criterion to detect backdoor samples. Extensive experiments validate that our proposed BDetCLIP is superior to state-of-the-art backdoor detection methods, in terms of both effectiveness and efficiency. Our codes are publicly available at: https://github.com/Purshow/BDetCLIP.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ CLIPê³¼ ê°™ì€ ë©€í‹°ëª¨ë‹¬ ëŒ€ì¡° í•™ìŠµ ë°©ë²•ì´ ë°±ë„ì–´ ê³µê²©ì— ì·¨ì•½í•˜ë‹¤ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ì¶”ë¡  ë‹¨ê³„ì—ì„œ íš¨ìœ¨ì ì¸ ë°±ë„ì–´ íƒì§€ ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ ë°©ì–´ ë°©ë²•ì€ ì‚¬ì „ í›ˆë ¨ì´ë‚˜ ë¯¸ì„¸ ì¡°ì • ë‹¨ê³„ì— ì´ˆì ì„ ë§ì¶° ë†’ì€ ê³„ì‚° ë¹„ìš©ì´ ë“¤ê³  ë¸”ë™ë°•ìŠ¤ í™˜ê²½ì—ì„œëŠ” ì ìš©ì´ ì–´ë µìŠµë‹ˆë‹¤. ì €ìë“¤ì€ ë°±ë„ì–´ ì´ë¯¸ì§€ì˜ ì‹œê°ì  í‘œí˜„ì´ í´ë˜ìŠ¤ ì„¤ëª… í…ìŠ¤íŠ¸ì˜ ë³€í™”ì— ë‘”ê°í•˜ë‹¤ëŠ” ì ì„ ë°œê²¬í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ BDetCLIPì´ë¼ëŠ” ìƒˆë¡œìš´ í…ŒìŠ¤íŠ¸ ë‹¨ê³„ ë°±ë„ì–´ íƒì§€ ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ì–¸ì–´ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í´ë˜ìŠ¤ ê´€ë ¨ ì„¤ëª… í…ìŠ¤íŠ¸ì™€ í´ë˜ìŠ¤ ë³€í˜• ëœë¤ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ê³ , ì´ë¯¸ì§€ì™€ ì´ ë‘ í…ìŠ¤íŠ¸ ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ë¶„í¬ ì°¨ì´ë¥¼ í†µí•´ ë°±ë„ì–´ ìƒ˜í”Œì„ íƒì§€í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, BDetCLIPì€ ê¸°ì¡´ ìµœì²¨ë‹¨ ë°©ë²•ë“¤ë³´ë‹¤ íš¨ê³¼ì ì´ê³  íš¨ìœ¨ì ì„ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë©€í‹°ëª¨ë‹¬ ëŒ€ì¡° í•™ìŠµ ë°©ë²•ì€ ë°±ë„ì–´ ê³µê²©ì— ì·¨ì•½í•˜ë‹¤ëŠ” ê²ƒì´ ìµœê·¼ ì—°êµ¬ì—ì„œ ë°í˜€ì¡ŒìŠµë‹ˆë‹¤.
- 2. ê¸°ì¡´ ë°©ì–´ ë°©ë²•ì€ ì‚¬ì „ í›ˆë ¨ ë‹¨ê³„ë‚˜ ë¯¸ì„¸ ì¡°ì • ë‹¨ê³„ì— ì´ˆì ì„ ë§ì¶”ì–´ ë†’ì€ ê³„ì‚° ë¹„ìš©ì„ ì´ˆë˜í•©ë‹ˆë‹¤.
- 3. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì¶”ë¡  ë‹¨ê³„ì—ì„œ ë°±ë„ì–´ ê³µê²©ì„ ë°©ì–´í•˜ê¸° ìœ„í•œ íš¨ìœ¨ì ì¸ ë°±ë„ì–´ íƒì§€ ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤.
- 4. ì œì•ˆëœ BDetCLIP ë°©ë²•ì€ ëŒ€ì¡°ì  í”„ë¡¬í”„íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ì—¬ í…ŒìŠ¤íŠ¸ ì‹œ ë°±ë„ì–´ ìƒ˜í”Œì„ íƒì§€í•©ë‹ˆë‹¤.
- 5. BDetCLIPì€ íš¨ê³¼ì„±ê³¼ íš¨ìœ¨ì„± ë©´ì—ì„œ ìµœì‹  ë°±ë„ì–´ íƒì§€ ë°©ë²•ë³´ë‹¤ ìš°ìˆ˜í•˜ë‹¤ëŠ” ê²ƒì´ ì‹¤í—˜ì„ í†µí•´ ê²€ì¦ë˜ì—ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 02:55:46*