---
keywords:
  - Transformer
  - Dimensionality Reduction
  - Clustering
  - Topic Coherence
  - Embedding-Based Topic Modeling
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.16835
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T23:35:33.718276",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Transformer",
    "Dimensionality Reduction",
    "Clustering",
    "Topic Coherence",
    "Embedding-Based Topic Modeling"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Transformer": 0.85,
    "Dimensionality Reduction": 0.72,
    "Clustering": 0.78,
    "Topic Coherence": 0.7,
    "Embedding-Based Topic Modeling": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "transformer-based embeddings",
        "canonical": "Transformer",
        "aliases": [
          "Sentence-BERT",
          "BERT embeddings"
        ],
        "category": "broad_technical",
        "rationale": "Transformers are a foundational model in NLP, crucial for understanding the semantic-driven approach in the paper.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "dimensionality reduction",
        "canonical": "Dimensionality Reduction",
        "aliases": [
          "UMAP"
        ],
        "category": "specific_connectable",
        "rationale": "Dimensionality reduction is key for processing high-dimensional data, facilitating better topic modeling.",
        "novelty_score": 0.55,
        "connectivity_score": 0.79,
        "specificity_score": 0.68,
        "link_intent_score": 0.72
      },
      {
        "surface": "clustering",
        "canonical": "Clustering",
        "aliases": [
          "HDBSCAN"
        ],
        "category": "specific_connectable",
        "rationale": "Clustering is essential for grouping similar ideas, enhancing the framework's ability to extract coherent themes.",
        "novelty_score": 0.5,
        "connectivity_score": 0.82,
        "specificity_score": 0.65,
        "link_intent_score": 0.78
      },
      {
        "surface": "topic coherence",
        "canonical": "Topic Coherence",
        "aliases": [
          "coherence score"
        ],
        "category": "unique_technical",
        "rationale": "Topic coherence is a unique metric used to evaluate the quality of topic models, pivotal for the study's findings.",
        "novelty_score": 0.7,
        "connectivity_score": 0.67,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      },
      {
        "surface": "embedding-based topic modeling",
        "canonical": "Embedding-Based Topic Modeling",
        "aliases": [
          "semantic-driven topic modeling"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel approach combining embeddings with topic modeling, central to the paper's contribution.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "manual coding",
      "structured Zoom brainstorming sessions"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "transformer-based embeddings",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "dimensionality reduction",
      "resolved_canonical": "Dimensionality Reduction",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.79,
        "specificity": 0.68,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "clustering",
      "resolved_canonical": "Clustering",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.82,
        "specificity": 0.65,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "topic coherence",
      "resolved_canonical": "Topic Coherence",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.67,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "embedding-based topic modeling",
      "resolved_canonical": "Embedding-Based Topic Modeling",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Semantic-Driven Topic Modeling for Analyzing Creativity in Virtual Brainstorming

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16835.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.16835](https://arxiv.org/abs/2509.16835)

## 🔗 유사한 논문
- [[2025-09-19/V-SEAM_ Visual Semantic Editing and Attention Modulating for Causal Interpretability of Vision-Language Models_20250919|V-SEAM: Visual Semantic Editing and Attention Modulating for Causal Interpretability of Vision-Language Models]] (80.7% similar)
- [[2025-09-19/UMind_ A Unified Multitask Network for Zero-Shot M/EEG Visual Decoding_20250919|UMind: A Unified Multitask Network for Zero-Shot M/EEG Visual Decoding]] (80.0% similar)
- [[2025-09-22/Cache-of-Thought_ Master-Apprentice Framework for Cost-Effective Vision Language Model Reasoning_20250922|Cache-of-Thought: Master-Apprentice Framework for Cost-Effective Vision Language Model Reasoning]] (79.9% similar)
- [[2025-09-22/Spatial Understanding from Videos_ Structured Prompts Meet Simulation Data_20250922|Spatial Understanding from Videos: Structured Prompts Meet Simulation Data]] (79.8% similar)
- [[2025-09-22/MuseScorer_ Idea Originality Scoring At Scale_20250922|MuseScorer: Idea Originality Scoring At Scale]] (79.8% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Transformer|Transformer]]
**🔗 Specific Connectable**: [[keywords/Dimensionality Reduction|Dimensionality Reduction]], [[keywords/Clustering|Clustering]]
**⚡ Unique Technical**: [[keywords/Topic Coherence|Topic Coherence]], [[keywords/Embedding-Based Topic Modeling|Embedding-Based Topic Modeling]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.16835v1 Announce Type: cross 
Abstract: Virtual brainstorming sessions have become a central component of collaborative problem solving, yet the large volume and uneven distribution of ideas often make it difficult to extract valuable insights efficiently. Manual coding of ideas is time-consuming and subjective, underscoring the need for automated approaches to support the evaluation of group creativity. In this study, we propose a semantic-driven topic modeling framework that integrates four modular components: transformer-based embeddings (Sentence-BERT), dimensionality reduction (UMAP), clustering (HDBSCAN), and topic extraction with refinement. The framework captures semantic similarity at the sentence level, enabling the discovery of coherent themes from brainstorming transcripts while filtering noise and identifying outliers. We evaluate our approach on structured Zoom brainstorming sessions involving student groups tasked with improving their university. Results demonstrate that our model achieves higher topic coherence compared to established methods such as LDA, ETM, and BERTopic, with an average coherence score of 0.687 (CV), outperforming baselines by a significant margin. Beyond improved performance, the model provides interpretable insights into the depth and diversity of topics explored, supporting both convergent and divergent dimensions of group creativity. This work highlights the potential of embedding-based topic modeling for analyzing collaborative ideation and contributes an efficient and scalable framework for studying creativity in synchronous virtual meetings.

## 📝 요약

이 연구는 가상 브레인스토밍 세션에서 생성된 아이디어의 효율적인 평가를 위해 자동화된 주제 모델링 프레임워크를 제안합니다. 이 프레임워크는 Sentence-BERT 기반 임베딩, UMAP 차원 축소, HDBSCAN 클러스터링, 주제 추출 및 정제를 통합하여 문장 수준의 의미적 유사성을 포착합니다. 이를 통해 브레인스토밍 기록에서 일관된 주제를 발견하고 잡음을 걸러내며 이상치를 식별할 수 있습니다. 대학 개선을 주제로 한 학생 그룹의 Zoom 세션을 평가한 결과, 제안된 모델은 기존 방법들(LDA, ETM, BERTopic)보다 높은 주제 일관성 점수(평균 0.687 CV)를 기록했습니다. 이 모델은 주제의 깊이와 다양성에 대한 해석 가능한 통찰을 제공하며, 그룹 창의성의 수렴적 및 발산적 차원을 지원합니다. 본 연구는 동기식 가상 회의에서 협력적 아이디어 창출 분석을 위한 효율적이고 확장 가능한 프레임워크를 제시합니다.

## 🎯 주요 포인트

- 1. 가상 브레인스토밍 세션에서 아이디어의 대량 및 불균등 분포 문제를 해결하기 위해 자동화된 평가 방법의 필요성이 강조됩니다.
- 2. 본 연구는 Sentence-BERT, UMAP, HDBSCAN을 통합한 의미 기반 주제 모델링 프레임워크를 제안하여 브레인스토밍 기록에서 일관된 주제를 발견합니다.
- 3. 제안된 모델은 LDA, ETM, BERTopic 등 기존 방법보다 평균 일관성 점수 0.687(CV)로 높은 주제 일관성을 달성합니다.
- 4. 모델은 주제의 깊이와 다양성에 대한 해석 가능한 통찰력을 제공하며, 그룹 창의성의 수렴적 및 발산적 차원을 지원합니다.
- 5. 본 연구는 동기식 가상 회의에서 협업적 아이디어 생성 분석을 위한 효율적이고 확장 가능한 프레임워크를 제공합니다.


---

*Generated on 2025-09-23 23:35:33*