---
keywords:
  - Deep Learning
  - Spatial Audio
  - QASTAnet
  - Codec Artifacts
category: cs.LG
publish_date: 2025-09-23
arxiv_id: 2509.16715
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T02:14:05.468207",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Deep Learning",
    "Spatial Audio",
    "QASTAnet",
    "Codec Artifacts"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Deep Learning": 0.85,
    "Spatial Audio": 0.8,
    "QASTAnet": 0.78,
    "Codec Artifacts": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Deep Neural Network",
        "canonical": "Deep Learning",
        "aliases": [
          "DNN"
        ],
        "category": "broad_technical",
        "rationale": "Deep Learning is a foundational technology in the development of advanced audio quality metrics like QASTAnet.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Spatial Audio",
        "canonical": "Spatial Audio",
        "aliases": [
          "3D Audio",
          "Ambisonics",
          "Binaural Audio"
        ],
        "category": "unique_technical",
        "rationale": "Spatial Audio is the core focus of the paper, linking it to advancements in audio technology and evaluation.",
        "novelty_score": 0.75,
        "connectivity_score": 0.7,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "Quality Assessment for Spatial Audio network",
        "canonical": "QASTAnet",
        "aliases": [
          "Quality Metric for Spatial Audio"
        ],
        "category": "unique_technical",
        "rationale": "QASTAnet is a novel metric introduced in the paper, representing a significant advancement in audio quality assessment.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.88,
        "link_intent_score": 0.78
      },
      {
        "surface": "Codec Artifacts",
        "canonical": "Codec Artifacts",
        "aliases": [
          "Compression Artifacts"
        ],
        "category": "specific_connectable",
        "rationale": "Understanding codec artifacts is crucial for evaluating audio quality, making it a relevant link for audio processing studies.",
        "novelty_score": 0.6,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "Listening Tests",
      "Subjective Scores",
      "Content Types"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Deep Neural Network",
      "resolved_canonical": "Deep Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Spatial Audio",
      "resolved_canonical": "Spatial Audio",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.7,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Quality Assessment for Spatial Audio network",
      "resolved_canonical": "QASTAnet",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.88,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Codec Artifacts",
      "resolved_canonical": "Codec Artifacts",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# QASTAnet: A DNN-based Quality Metric for Spatial Audio

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16715.pdf)
**Category**: cs.LG
**Published**: 2025-09-23
**ArXiv ID**: [2509.16715](https://arxiv.org/abs/2509.16715)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-17/DSpAST_ Disentangled Representations for Spatial Audio Reasoning with Large Language Models_20250917|DSpAST: Disentangled Representations for Spatial Audio Reasoning with Large Language Models]] (84.6% similar)
- [[2025-09-23/Audio-Guided Dynamic Modality Fusion with Stereo-Aware Attention for Audio-Visual Navigation_20250923|Audio-Guided Dynamic Modality Fusion with Stereo-Aware Attention for Audio-Visual Navigation]] (82.2% similar)
- [[2025-09-18/Spatial Audio Motion Understanding and Reasoning_20250918|Spatial Audio Motion Understanding and Reasoning]] (81.6% similar)
- [[2025-09-23/Cross-Attention with Confidence Weighting for Multi-Channel Audio Alignment_20250923|Cross-Attention with Confidence Weighting for Multi-Channel Audio Alignment]] (81.5% similar)
- [[2025-09-22/(SP)$^2$-Net_ A Neural Spatial Spectrum Method for DOA Estimation_20250922|(SP)$^2$-Net: A Neural Spatial Spectrum Method for DOA Estimation]] (80.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Deep Learning|Deep Learning]]
**ğŸ”— Specific Connectable**: [[keywords/Codec Artifacts|Codec Artifacts]]
**âš¡ Unique Technical**: [[keywords/Spatial Audio|Spatial Audio]], [[keywords/QASTAnet|QASTAnet]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16715v1 Announce Type: cross 
Abstract: In the development of spatial audio technologies, reliable and shared methods for evaluating audio quality are essential. Listening tests are currently the standard but remain costly in terms of time and resources. Several models predicting subjective scores have been proposed, but they do not generalize well to real-world signals. In this paper, we propose QASTAnet (Quality Assessment for SpaTial Audio network), a new metric based on a deep neural network, specialized on spatial audio (ambisonics and binaural). As training data is scarce, we aim for the model to be trainable with a small amount of data. To do so, we propose to rely on expert modeling of the low-level auditory system and use a neurnal network to model the high-level cognitive function of the quality judgement. We compare its performance to two reference metrics on a wide range of content types (speech, music, ambiance, anechoic, reverberated) and focusing on codec artifacts. Results demonstrate that QASTAnet overcomes the aforementioned limitations of the existing methods. The strong correlation between the proposed metric prediction and subjective scores makes it a good candidate for comparing codecs in their development.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ê³µê°„ ìŒí–¥ ê¸°ìˆ ì˜ í’ˆì§ˆ í‰ê°€ë¥¼ ìœ„í•œ ìƒˆë¡œìš´ ì§€í‘œì¸ QASTAnetì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ì²­ì·¨ í…ŒìŠ¤íŠ¸ëŠ” ì‹œê°„ê³¼ ìì›ì´ ë§ì´ ì†Œëª¨ë˜ë©°, ì£¼ê´€ì  ì ìˆ˜ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ë“¤ì€ ì‹¤ì œ ì‹ í˜¸ì— ì˜ ì¼ë°˜í™”ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. QASTAnetì€ ì‹¬ì¸µ ì‹ ê²½ë§ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ë©°, ì ì€ ì–‘ì˜ ë°ì´í„°ë¡œë„ í›ˆë ¨ì´ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ì €ìˆ˜ì¤€ ì²­ê° ì‹œìŠ¤í…œì˜ ì „ë¬¸ê°€ ëª¨ë¸ë§ê³¼ ê³ ìˆ˜ì¤€ ì¸ì§€ ê¸°ëŠ¥ì˜ ì‹ ê²½ë§ ëª¨ë¸ë§ì„ ê²°í•©í•˜ì—¬ í’ˆì§ˆ íŒë‹¨ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ë‹¤ì–‘í•œ ì½˜í…ì¸  ìœ í˜•ê³¼ ì½”ë± ì•„í‹°íŒ©íŠ¸ì— ëŒ€í•œ ì„±ëŠ¥ ë¹„êµ ê²°ê³¼, QASTAnetì€ ê¸°ì¡´ ë°©ë²•ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ë©° ì£¼ê´€ì  ì ìˆ˜ì™€ ë†’ì€ ìƒê´€ê´€ê³„ë¥¼ ë³´ì—¬ ì½”ë± ë¹„êµì— ìœ ìš©í•œ ì§€í‘œë¡œ í‰ê°€ë©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ê³µê°„ ìŒí–¥ ê¸°ìˆ ì˜ ë°œì „ì—ì„œ ì˜¤ë””ì˜¤ í’ˆì§ˆ í‰ê°€ë¥¼ ìœ„í•œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì´ í•„ìˆ˜ì ì…ë‹ˆë‹¤.
- 2. QASTAnetì€ ê³µê°„ ìŒí–¥ì— íŠ¹í™”ëœ ì‹¬ì¸µ ì‹ ê²½ë§ ê¸°ë°˜ì˜ ìƒˆë¡œìš´ í’ˆì§ˆ í‰ê°€ ì§€í‘œì…ë‹ˆë‹¤.
- 3. ì œí•œëœ í›ˆë ¨ ë°ì´í„°ë¡œë„ í•™ìŠµì´ ê°€ëŠ¥í•˜ë„ë¡ ì €ìˆ˜ì¤€ ì²­ê° ì‹œìŠ¤í…œì„ ì „ë¬¸ê°€ ëª¨ë¸ë§í•˜ê³ , ê³ ìˆ˜ì¤€ ì¸ì§€ ê¸°ëŠ¥ì€ ì‹ ê²½ë§ìœ¼ë¡œ ëª¨ë¸ë§í•©ë‹ˆë‹¤.
- 4. QASTAnetì€ ê¸°ì¡´ ë°©ë²•ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ë©°, ì£¼ê´€ì  ì ìˆ˜ì™€ì˜ ê°•í•œ ìƒê´€ê´€ê³„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
- 5. ì œì•ˆëœ ì§€í‘œëŠ” ì½”ë± ê°œë°œ ì‹œ ë¹„êµì— ìœ ìš©í•œ í›„ë³´ë¡œ í‰ê°€ë©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 02:14:05*