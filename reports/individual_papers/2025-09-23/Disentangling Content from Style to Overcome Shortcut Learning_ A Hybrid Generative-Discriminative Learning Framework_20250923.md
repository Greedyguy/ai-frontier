---
keywords:
  - Self-supervised Learning
  - Shortcut Learning
  - Hybrid Generative-Discriminative Learning Framework
  - Invariance Pre-training Principle
category: cs.LG
publish_date: 2025-09-23
arxiv_id: 2509.11598
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:09:26.044987",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Self-supervised Learning",
    "Shortcut Learning",
    "Hybrid Generative-Discriminative Learning Framework",
    "Invariance Pre-training Principle"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Self-supervised Learning": 0.85,
    "Shortcut Learning": 0.78,
    "Hybrid Generative-Discriminative Learning Framework": 0.8,
    "Invariance Pre-training Principle": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Self-Supervised Learning",
        "canonical": "Self-supervised Learning",
        "aliases": [
          "SSL"
        ],
        "category": "specific_connectable",
        "rationale": "Self-supervised Learning is a key paradigm discussed in the paper, crucial for linking with related works on learning frameworks.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Shortcut Learning",
        "canonical": "Shortcut Learning",
        "aliases": [
          "Shortcut Bias"
        ],
        "category": "unique_technical",
        "rationale": "Shortcut Learning is identified as a systemic issue in the paper, providing a unique angle for exploring model biases.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Hybrid Generative-Discriminative Learning Framework",
        "canonical": "Hybrid Generative-Discriminative Learning Framework",
        "aliases": [
          "HyGDL"
        ],
        "category": "unique_technical",
        "rationale": "This framework is the core contribution of the paper, offering a novel approach to disentangling content from style.",
        "novelty_score": 0.85,
        "connectivity_score": 0.6,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "Invariance Pre-training Principle",
        "canonical": "Invariance Pre-training Principle",
        "aliases": [
          "Invariant Learning"
        ],
        "category": "unique_technical",
        "rationale": "The principle underpins the proposed framework, crucial for understanding the paper's methodological innovation.",
        "novelty_score": 0.7,
        "connectivity_score": 0.55,
        "specificity_score": 0.85,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "MAE",
      "domain-specific features",
      "superficial features"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Self-Supervised Learning",
      "resolved_canonical": "Self-supervised Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Shortcut Learning",
      "resolved_canonical": "Shortcut Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Hybrid Generative-Discriminative Learning Framework",
      "resolved_canonical": "Hybrid Generative-Discriminative Learning Framework",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.6,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Invariance Pre-training Principle",
      "resolved_canonical": "Invariance Pre-training Principle",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.55,
        "specificity": 0.85,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Disentangling Content from Style to Overcome Shortcut Learning: A Hybrid Generative-Discriminative Learning Framework

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.11598.pdf)
**Category**: cs.LG
**Published**: 2025-09-23
**ArXiv ID**: [2509.11598](https://arxiv.org/abs/2509.11598)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/StyleSculptor_ Zero-Shot Style-Controllable 3D Asset Generation with Texture-Geometry Dual Guidance_20250918|StyleSculptor: Zero-Shot Style-Controllable 3D Asset Generation with Texture-Geometry Dual Guidance]] (82.9% similar)
- [[2025-09-19/Style Transfer with Diffusion Models for Synthetic-to-Real Domain Adaptation_20250919|Style Transfer with Diffusion Models for Synthetic-to-Real Domain Adaptation]] (82.3% similar)
- [[2025-09-18/Hybrid Diffusion Policies with Projective Geometric Algebra for Efficient Robot Manipulation Learning_20250918|Hybrid Diffusion Policies with Projective Geometric Algebra for Efficient Robot Manipulation Learning]] (81.2% similar)
- [[2025-09-22/Mind the Gap_ Data Rewriting for Stable Off-Policy Supervised Fine-Tuning_20250922|Mind the Gap: Data Rewriting for Stable Off-Policy Supervised Fine-Tuning]] (81.0% similar)
- [[2025-09-19/Seeing 3D Through 2D Lenses_ 3D Few-Shot Class-Incremental Learning via Cross-Modal Geometric Rectification_20250919|Seeing 3D Through 2D Lenses: 3D Few-Shot Class-Incremental Learning via Cross-Modal Geometric Rectification]] (81.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Self-supervised Learning|Self-supervised Learning]]
**âš¡ Unique Technical**: [[keywords/Shortcut Learning|Shortcut Learning]], [[keywords/Hybrid Generative-Discriminative Learning Framework|Hybrid Generative-Discriminative Learning Framework]], [[keywords/Invariance Pre-training Principle|Invariance Pre-training Principle]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.11598v3 Announce Type: replace-cross 
Abstract: Despite the remarkable success of Self-Supervised Learning (SSL), its generalization is fundamentally hindered by Shortcut Learning, where models exploit superficial features like texture instead of intrinsic structure. We experimentally verify this flaw within the generative paradigm (e.g., MAE) and argue it is a systemic issue also affecting discriminative methods, identifying it as the root cause of their failure on unseen domains. While existing methods often tackle this at a surface level by aligning or separating domain-specific features, they fail to alter the underlying learning mechanism that fosters shortcut dependency. To address this at its core, we propose HyGDL (Hybrid Generative-Discriminative Learning Framework), a hybrid framework that achieves explicit content-style disentanglement. Our approach is guided by the Invariance Pre-training Principle: forcing a model to learn an invariant essence by systematically varying a bias (e.g., style) at the input while keeping the supervision signal constant. HyGDL operates on a single encoder and analytically defines style as the component of a representation that is orthogonal to its style-invariant content, derived via vector projection. This is operationalized through a synergistic design: (1) a self-distillation objective learns a stable, style-invariant content direction; (2) an analytical projection then decomposes the representation into orthogonal content and style vectors; and (3) a style-conditioned reconstruction objective uses these vectors to restore the image, providing end-to-end supervision. Unlike prior methods that rely on implicit heuristics, this principled disentanglement allows HyGDL to learn truly robust representations, demonstrating superior performance on benchmarks designed to diagnose shortcut learning.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ìê¸° ì§€ë„ í•™ìŠµ(SSL)ì˜ ì¼ë°˜í™” ë¬¸ì œë¥¼ ë‹¤ë£¨ë©°, ëª¨ë¸ì´ ë³¸ì§ˆì  êµ¬ì¡° ëŒ€ì‹  í‘œë©´ì  íŠ¹ì§•ì„ ì´ìš©í•˜ëŠ” 'ì§€ë¦„ê¸¸ í•™ìŠµ'ì´ ê·¸ ì›ì¸ì„ì„ ì§€ì í•©ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ HyGDLì´ë¼ëŠ” í•˜ì´ë¸Œë¦¬ë“œ ìƒì„±-íŒë³„ í•™ìŠµ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. HyGDLì€ ë¶ˆë³€ì„± ì‚¬ì „ í•™ìŠµ ì›ì¹™ì„ ê¸°ë°˜ìœ¼ë¡œ ìŠ¤íƒ€ì¼ê³¼ ì½˜í…ì¸ ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ í•™ìŠµí•©ë‹ˆë‹¤. ë‹¨ì¼ ì¸ì½”ë”ë¥¼ ì‚¬ìš©í•˜ì—¬ ìŠ¤íƒ€ì¼ì„ ì½˜í…ì¸ ì™€ ì§êµí•˜ëŠ” ë²¡í„°ë¡œ ì •ì˜í•˜ê³ , ìê¸° ì¦ë¥˜ ëª©í‘œì™€ ìŠ¤íƒ€ì¼ ì¡°ê±´ ì¬êµ¬ì„± ëª©í‘œë¥¼ í†µí•´ ìŠ¤íƒ€ì¼-ë¶ˆë³€ ì½˜í…ì¸  ë°©í–¥ì„ í•™ìŠµí•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ì§€ë¦„ê¸¸ í•™ìŠµì„ ì§„ë‹¨í•˜ëŠ” ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ìê¸° ì§€ë„ í•™ìŠµ(SSL)ì€ ì§€ë¦„ê¸¸ í•™ìŠµìœ¼ë¡œ ì¸í•´ ì¼ë°˜í™”ì— í•œê³„ê°€ ìˆìœ¼ë©°, ì´ëŠ” ëª¨ë¸ì´ ë³¸ì§ˆì ì¸ êµ¬ì¡° ëŒ€ì‹  í‘œë©´ì ì¸ íŠ¹ì§•ì„ í™œìš©í•˜ëŠ” ë¬¸ì œì…ë‹ˆë‹¤.
- 2. ê¸°ì¡´ ë°©ë²•ë“¤ì€ ë„ë©”ì¸ íŠ¹í™”ëœ íŠ¹ì§•ì„ ì •ë ¬í•˜ê±°ë‚˜ ë¶„ë¦¬í•˜ëŠ” ë° ì§‘ì¤‘í•˜ì§€ë§Œ, ì§€ë¦„ê¸¸ ì˜ì¡´ì„±ì„ ì¡°ì¥í•˜ëŠ” í•™ìŠµ ë©”ì»¤ë‹ˆì¦˜ì„ ê·¼ë³¸ì ìœ¼ë¡œ ë°”ê¾¸ì§€ ëª»í•©ë‹ˆë‹¤.
- 3. HyGDLì€ ëª…ì‹œì ì¸ ì½˜í…ì¸ -ìŠ¤íƒ€ì¼ ë¶„ë¦¬ë¥¼ ë‹¬ì„±í•˜ëŠ” í•˜ì´ë¸Œë¦¬ë“œ ìƒì„±-íŒë³„ í•™ìŠµ í”„ë ˆì„ì›Œí¬ë¡œ, ë¶ˆë³€ì„± ì‚¬ì „ í•™ìŠµ ì›ì¹™ì— ë”°ë¼ ìŠ¤íƒ€ì¼ í¸í–¥ì„ ì²´ê³„ì ìœ¼ë¡œ ë³€í™”ì‹œí‚µë‹ˆë‹¤.
- 4. HyGDLì€ ë‹¨ì¼ ì¸ì½”ë”ë¥¼ ì‚¬ìš©í•˜ì—¬ ìŠ¤íƒ€ì¼ì„ ìŠ¤íƒ€ì¼ ë¶ˆë³€ ì½˜í…ì¸ ì™€ ì§êµí•˜ëŠ” í‘œí˜„ì˜ êµ¬ì„± ìš”ì†Œë¡œ ì •ì˜í•˜ë©°, ì´ë¥¼ í†µí•´ ì§„ì •ìœ¼ë¡œ ê°•ê±´í•œ í‘œí˜„ì„ í•™ìŠµí•©ë‹ˆë‹¤.
- 5. HyGDLì€ ì§€ë¦„ê¸¸ í•™ìŠµì„ ì§„ë‹¨í•˜ê¸° ìœ„í•œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì—¬, ê¸°ì¡´ì˜ ì•”ì‹œì  íœ´ë¦¬ìŠ¤í‹±ì— ì˜ì¡´í•˜ëŠ” ë°©ë²•ë“¤ê³¼ ì°¨ë³„í™”ë©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 03:09:26*