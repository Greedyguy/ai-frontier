---
keywords:
  - Large Language Model
  - ABX Discrimination Tasks
  - Language Identity
  - Semantic Meaning
  - Zero-Shot Learning
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2505.17747
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:58:35.846839",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "ABX Discrimination Tasks",
    "Language Identity",
    "Semantic Meaning",
    "Zero-Shot Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.79,
    "ABX Discrimination Tasks": 0.72,
    "Language Identity": 0.68,
    "Semantic Meaning": 0.7,
    "Zero-Shot Learning": 0.74
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "multilingual language models",
        "canonical": "Large Language Model",
        "aliases": [
          "multilingual models",
          "language models"
        ],
        "category": "broad_technical",
        "rationale": "Connects to a broad category of models used in NLP, facilitating links to related research.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.79
      },
      {
        "surface": "ABX-style discrimination tasks",
        "canonical": "ABX Discrimination Tasks",
        "aliases": [
          "ABX tasks",
          "discrimination tasks"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel task framework specific to the paper, useful for linking to similar evaluation methods.",
        "novelty_score": 0.78,
        "connectivity_score": 0.65,
        "specificity_score": 0.82,
        "link_intent_score": 0.72
      },
      {
        "surface": "language identity",
        "canonical": "Language Identity",
        "aliases": [
          "language form",
          "linguistic identity"
        ],
        "category": "specific_connectable",
        "rationale": "Key concept for understanding how models differentiate between languages, linking to linguistic studies.",
        "novelty_score": 0.6,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.68
      },
      {
        "surface": "semantic content",
        "canonical": "Semantic Meaning",
        "aliases": [
          "semantics",
          "meaning"
        ],
        "category": "specific_connectable",
        "rationale": "Central to evaluating how models understand content, linking to semantic analysis research.",
        "novelty_score": 0.55,
        "connectivity_score": 0.8,
        "specificity_score": 0.72,
        "link_intent_score": 0.7
      },
      {
        "surface": "zero-shot tasks",
        "canonical": "Zero-Shot Learning",
        "aliases": [
          "zero-shot evaluation",
          "zero-shot methods"
        ],
        "category": "specific_connectable",
        "rationale": "Aligns with trending concepts in model evaluation without prior training, enhancing connectivity to current research.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.68,
        "link_intent_score": 0.74
      }
    ],
    "ban_list_suggestions": [
      "training-free",
      "pretraining checkpoints",
      "probing tasks"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "multilingual language models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "ABX-style discrimination tasks",
      "resolved_canonical": "ABX Discrimination Tasks",
      "decision": "linked",
      "scores": {
        "novelty": 0.78,
        "connectivity": 0.65,
        "specificity": 0.82,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "language identity",
      "resolved_canonical": "Language Identity",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.68
      }
    },
    {
      "candidate_surface": "semantic content",
      "resolved_canonical": "Semantic Meaning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.8,
        "specificity": 0.72,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "zero-shot tasks",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.68,
        "link_intent": 0.74
      }
    }
  ]
}
-->

# Discriminating Form and Meaning in Multilingual Models with Minimal-Pair ABX Tasks

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2505.17747.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2505.17747](https://arxiv.org/abs/2505.17747)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Intrinsic Meets Extrinsic Fairness_ Assessing the Downstream Impact of Bias Mitigation in Large Language Models_20250923|Intrinsic Meets Extrinsic Fairness: Assessing the Downstream Impact of Bias Mitigation in Large Language Models]] (82.0% similar)
- [[2025-09-22/Language Mixing in Reasoning Language Models_ Patterns, Impact, and Internal Causes_20250922|Language Mixing in Reasoning Language Models: Patterns, Impact, and Internal Causes]] (81.9% similar)
- [[2025-09-23/Evaluating CxG Generalisation in LLMs via Construction-Based NLI Fine Tuning_20250923|Evaluating CxG Generalisation in LLMs via Construction-Based NLI Fine Tuning]] (81.6% similar)
- [[2025-09-22/PolBiX_ Detecting LLMs' Political Bias in Fact-Checking through X-phemisms_20250922|PolBiX: Detecting LLMs' Political Bias in Fact-Checking through X-phemisms]] (81.5% similar)
- [[2025-09-22/Layer-wise Minimal Pair Probing Reveals Contextual Grammatical-Conceptual Hierarchy in Speech Representations_20250922|Layer-wise Minimal Pair Probing Reveals Contextual Grammatical-Conceptual Hierarchy in Speech Representations]] (81.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Language Identity|Language Identity]], [[keywords/Semantic Meaning|Semantic Meaning]], [[keywords/Zero-Shot Learning|Zero-Shot Learning]]
**âš¡ Unique Technical**: [[keywords/ABX Discrimination Tasks|ABX Discrimination Tasks]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2505.17747v3 Announce Type: replace 
Abstract: We introduce a set of training-free ABX-style discrimination tasks to evaluate how multilingual language models represent language identity (form) and semantic content (meaning). Inspired from speech processing, these zero-shot tasks measure whether minimal differences in representation can be reliably detected. This offers a flexible and interpretable alternative to probing. Applied to XLM-R (Conneau et al, 2020) across pretraining checkpoints and layers, we find that language discrimination declines over training and becomes concentrated in lower layers, while meaning discrimination strengthens over time and stabilizes in deeper layers. We then explore probing tasks, showing some alignment between our metrics and linguistic learning performance. Our results position ABX tasks as a lightweight framework for analyzing the structure of multilingual representations.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë‹¤êµ­ì–´ ì–¸ì–´ ëª¨ë¸ì´ ì–¸ì–´ ì •ì²´ì„±ê³¼ ì˜ë¯¸ë¥¼ ì–´ë–»ê²Œ í‘œí˜„í•˜ëŠ”ì§€ë¥¼ í‰ê°€í•˜ê¸° ìœ„í•´ í›ˆë ¨ì´ í•„ìš” ì—†ëŠ” ABX ìŠ¤íƒ€ì¼ì˜ êµ¬ë³„ ê³¼ì œë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ê³¼ì œëŠ” ìµœì†Œí•œì˜ í‘œí˜„ ì°¨ì´ë¥¼ ê°ì§€í•  ìˆ˜ ìˆëŠ”ì§€ë¥¼ ì¸¡ì •í•˜ë©°, XLM-R ëª¨ë¸ì— ì ìš©í•œ ê²°ê³¼, ì–¸ì–´ êµ¬ë³„ ëŠ¥ë ¥ì€ í›ˆë ¨ì´ ì§„í–‰ë ìˆ˜ë¡ ê°ì†Œí•˜ê³  í•˜ìœ„ ì¸µì— ì§‘ì¤‘ë˜ëŠ” ë°˜ë©´, ì˜ë¯¸ êµ¬ë³„ ëŠ¥ë ¥ì€ ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ ê°•í™”ë˜ì–´ ì‹¬ì¸µ ì¸µì—ì„œ ì•ˆì •í™”ë¨ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, í”„ë¡œë¹™ ê³¼ì œì™€ì˜ ë¹„êµë¥¼ í†µí•´ ì œì•ˆëœ ë©”íŠ¸ë¦­ê³¼ ì–¸ì–´ í•™ìŠµ ì„±ê³¼ ê°„ì˜ ì¼ë¶€ ì¼ì¹˜ë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ABX ê³¼ì œê°€ ë‹¤êµ­ì–´ í‘œí˜„ êµ¬ì¡° ë¶„ì„ì— ìœ ìš©í•œ ê²½ëŸ‰ í”„ë ˆì„ì›Œí¬ì„ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë‹¤êµ­ì–´ ì–¸ì–´ ëª¨ë¸ì˜ ì–¸ì–´ ì •ì²´ì„±ê³¼ ì˜ë¯¸ í‘œí˜„ì„ í‰ê°€í•˜ê¸° ìœ„í•œ í›ˆë ¨ ì—†ëŠ” ABX ìŠ¤íƒ€ì¼ì˜ íŒë³„ ê³¼ì œë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.
- 2. ì œì•ˆëœ ê³¼ì œëŠ” ìµœì†Œí•œì˜ í‘œí˜„ ì°¨ì´ë¥¼ ê°ì§€í•  ìˆ˜ ìˆëŠ”ì§€ ì¸¡ì •í•˜ë©°, ì´ëŠ” íƒìƒ‰ì— ëŒ€í•œ ìœ ì—°í•˜ê³  í•´ì„ ê°€ëŠ¥í•œ ëŒ€ì•ˆì„ ì œê³µí•©ë‹ˆë‹¤.
- 3. XLM-R ëª¨ë¸ì— ì ìš©í•œ ê²°ê³¼, ì–¸ì–´ íŒë³„ ëŠ¥ë ¥ì€ í›ˆë ¨ì´ ì§„í–‰ë ìˆ˜ë¡ ê°ì†Œí•˜ê³  í•˜ìœ„ ê³„ì¸µì— ì§‘ì¤‘ë˜ë©°, ì˜ë¯¸ íŒë³„ ëŠ¥ë ¥ì€ ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ ê°•í™”ë˜ì–´ ì‹¬ì¸µ ê³„ì¸µì—ì„œ ì•ˆì •í™”ë©ë‹ˆë‹¤.
- 4. ìš°ë¦¬ì˜ ë©”íŠ¸ë¦­ê³¼ ì–¸ì–´ í•™ìŠµ ì„±ëŠ¥ ê°„ì˜ ì¼ë¶€ ì •ë ¬ì„ ë³´ì—¬ì£¼ëŠ” íƒìƒ‰ ê³¼ì œë¥¼ íƒêµ¬í•©ë‹ˆë‹¤.
- 5. ABX ê³¼ì œëŠ” ë‹¤êµ­ì–´ í‘œí˜„ì˜ êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ê¸° ìœ„í•œ ê²½ëŸ‰ í”„ë ˆì„ì›Œí¬ë¡œ ìë¦¬ë§¤ê¹€í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 03:58:35*