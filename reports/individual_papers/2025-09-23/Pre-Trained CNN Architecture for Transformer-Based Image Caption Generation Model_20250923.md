---
keywords:
  - Transformer
  - Attention Mechanism
  - EfficientNetB0
  - Image Captioning
  - Flickr30k Dataset
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.17365
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T23:54:13.450639",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Transformer",
    "Attention Mechanism",
    "EfficientNetB0",
    "Image Captioning",
    "Flickr30k Dataset"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Transformer": 0.85,
    "Attention Mechanism": 0.8,
    "EfficientNetB0": 0.7,
    "Image Captioning": 0.78,
    "Flickr30k Dataset": 0.65
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Transformer",
        "canonical": "Transformer",
        "aliases": [],
        "category": "broad_technical",
        "rationale": "Transformers are central to the paper's methodology and are a key concept in linking computer vision and NLP.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Attention Mechanism",
        "canonical": "Attention Mechanism",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Attention mechanisms are crucial for understanding the model's ability to capture dependencies in data.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.75,
        "link_intent_score": 0.8
      },
      {
        "surface": "EfficientNetB0",
        "canonical": "EfficientNetB0",
        "aliases": [
          "EfficientNet"
        ],
        "category": "unique_technical",
        "rationale": "EfficientNetB0 is a specific CNN architecture used for feature extraction in the model.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      },
      {
        "surface": "Image Captioning",
        "canonical": "Image Captioning",
        "aliases": [
          "Automatic Image Captioning"
        ],
        "category": "specific_connectable",
        "rationale": "Image captioning is the primary application of the discussed model, linking vision and language.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.78
      },
      {
        "surface": "Flickr30k dataset",
        "canonical": "Flickr30k Dataset",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "The Flickr30k dataset is a specific dataset used for training and evaluating the model.",
        "novelty_score": 0.65,
        "connectivity_score": 0.5,
        "specificity_score": 0.85,
        "link_intent_score": 0.65
      }
    ],
    "ban_list_suggestions": [
      "RNN",
      "LSTM",
      "CNN"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Transformer",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Attention Mechanism",
      "resolved_canonical": "Attention Mechanism",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.75,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "EfficientNetB0",
      "resolved_canonical": "EfficientNetB0",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Image Captioning",
      "resolved_canonical": "Image Captioning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Flickr30k dataset",
      "resolved_canonical": "Flickr30k Dataset",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.5,
        "specificity": 0.85,
        "link_intent": 0.65
      }
    }
  ]
}
-->

# Pre-Trained CNN Architecture for Transformer-Based Image Caption Generation Model

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17365.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.17365](https://arxiv.org/abs/2509.17365)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Efficient Multimodal Dataset Distillation via Generative Models_20250922|Efficient Multimodal Dataset Distillation via Generative Models]] (81.7% similar)
- [[2025-09-22/Hierarchical Self-Attention_ Generalizing Neural Attention Mechanics to Multi-Scale Problems_20250922|Hierarchical Self-Attention: Generalizing Neural Attention Mechanics to Multi-Scale Problems]] (81.6% similar)
- [[2025-09-22/Efficient Extractive Text Summarization for Online News Articles Using Machine Learning_20250922|Efficient Extractive Text Summarization for Online News Articles Using Machine Learning]] (81.3% similar)
- [[2025-09-22/RACap_ Relation-Aware Prompting for Lightweight Retrieval-Augmented Image Captioning_20250922|RACap: Relation-Aware Prompting for Lightweight Retrieval-Augmented Image Captioning]] (81.3% similar)
- [[2025-09-19/Superpose Task-specific Features for Model Merging_20250919|Superpose Task-specific Features for Model Merging]] (81.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Transformer|Transformer]]
**ğŸ”— Specific Connectable**: [[keywords/Attention Mechanism|Attention Mechanism]], [[keywords/Image Captioning|Image Captioning]]
**âš¡ Unique Technical**: [[keywords/EfficientNetB0|EfficientNetB0]], [[keywords/Flickr30k Dataset|Flickr30k Dataset]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17365v1 Announce Type: cross 
Abstract: Automatic image captioning, a multifaceted task bridging computer vision and natural lan- guage processing, aims to generate descriptive textual content from visual input. While Convolutional Neural Networks (CNNs) and Long Short-Term Memory (LSTM) networks have achieved significant advancements, they present limitations. The inherent sequential nature of RNNs leads to sluggish training and inference times. LSTMs further struggle with retaining information from earlier sequence elements when dealing with very long se- quences. This project presents a comprehensive guide to constructing and comprehending transformer models for image captioning. Transformers employ self-attention mechanisms, capturing both short- and long-range dependencies within the data. This facilitates efficient parallelization during both training and inference phases. We leverage the well-established Transformer architecture, recognized for its effectiveness in managing sequential data, and present a meticulous methodology. Utilizing the Flickr30k dataset, we conduct data pre- processing, construct a model architecture that integrates an EfficientNetB0 CNN for fea- ture extraction, and train the model with attention mechanisms incorporated. Our approach exemplifies the utilization of parallelization for efficient training and inference. You can find the project on GitHub.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì´ë¯¸ì§€ ìº¡ì…”ë‹ì„ ìœ„í•œ íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì˜ êµ¬ì¶•ê³¼ ì´í•´ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. ê¸°ì¡´ì˜ CNNê³¼ LSTM ê¸°ë°˜ ëª¨ë¸ì€ ìˆœì°¨ì  íŠ¹ì„±ìœ¼ë¡œ ì¸í•´ í›ˆë ¨ ë° ì¶”ë¡  ì†ë„ê°€ ëŠë¦¬ê³ , LSTMì€ ê¸´ ì‹œí€€ìŠ¤ì—ì„œ ì •ë³´ ìœ ì§€ì— ì–´ë ¤ì›€ì„ ê²ªìŠµë‹ˆë‹¤. ì´ì— ë¹„í•´ íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” ìê¸° ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì„ í™œìš©í•˜ì—¬ ë°ì´í„° ë‚´ì˜ ë‹¨ê¸° ë° ì¥ê¸° ì˜ì¡´ì„±ì„ íš¨ê³¼ì ìœ¼ë¡œ í¬ì°©í•˜ê³ , ë³‘ë ¬í™”ë¥¼ í†µí•´ íš¨ìœ¨ì ì¸ í›ˆë ¨ê³¼ ì¶”ë¡ ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” Flickr30k ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ EfficientNetB0 CNNì„ íŠ¹ì§• ì¶”ì¶œì— í†µí•©í•œ ëª¨ë¸ ì•„í‚¤í…ì²˜ë¥¼ êµ¬ì¶•í•˜ê³ , ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì„ í¬í•¨í•œ í›ˆë ¨ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë³‘ë ¬í™”ì˜ ì¥ì ì„ ê·¹ëŒ€í™”í•œ íš¨ìœ¨ì ì¸ ì´ë¯¸ì§€ ìº¡ì…”ë‹ ë°©ë²•ë¡ ì„ ì œì‹œí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ìë™ ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„±ì€ ì»´í“¨í„° ë¹„ì „ê³¼ ìì—°ì–´ ì²˜ë¦¬ë¥¼ ì—°ê²°í•˜ëŠ” ë³µí•©ì ì¸ ì‘ì—…ì´ë‹¤.
- 2. ê¸°ì¡´ì˜ CNNê³¼ LSTM ë„¤íŠ¸ì›Œí¬ëŠ” ì„±ê³¼ë¥¼ ì´ë£¨ì—ˆì§€ë§Œ, RNNì˜ ìˆœì°¨ì  íŠ¹ì„±ìœ¼ë¡œ ì¸í•´ í›ˆë ¨ ë° ì¶”ë¡  ì‹œê°„ì´ ëŠë¦¬ë‹¤ëŠ” í•œê³„ê°€ ìˆë‹¤.
- 3. ì´ í”„ë¡œì íŠ¸ëŠ” ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„±ì„ ìœ„í•œ íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ êµ¬ì¶•ê³¼ ì´í•´ë¥¼ ìœ„í•œ ì¢…í•©ì ì¸ ê°€ì´ë“œë¥¼ ì œê³µí•œë‹¤.
- 4. íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” ìê°€-ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì„ í™œìš©í•˜ì—¬ ë°ì´í„° ë‚´ì˜ ë‹¨ê¸° ë° ì¥ê¸° ì˜ì¡´ì„±ì„ í¬ì°©í•˜ê³ , í›ˆë ¨ê³¼ ì¶”ë¡  ë‹¨ê³„ì—ì„œ íš¨ìœ¨ì ì¸ ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤.
- 5. Flickr30k ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬ EfficientNetB0 CNNì„ í†µí•©í•œ ëª¨ë¸ ì•„í‚¤í…ì²˜ë¥¼ êµ¬ì¶•í•˜ê³ , ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì„ í¬í•¨í•œ ëª¨ë¸ì„ í›ˆë ¨í•œë‹¤.


---

*Generated on 2025-09-23 23:54:13*