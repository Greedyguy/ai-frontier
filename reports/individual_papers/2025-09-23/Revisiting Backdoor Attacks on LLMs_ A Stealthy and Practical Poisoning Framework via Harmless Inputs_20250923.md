---
keywords:
  - Large Language Model
  - Backdoor Attacks
  - Safety-Aligned Guardrails
  - Causal Reasoning
  - Gradient-Based Optimization
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2505.17601
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:58:13.211611",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Backdoor Attacks",
    "Safety-Aligned Guardrails",
    "Causal Reasoning",
    "Gradient-Based Optimization"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Backdoor Attacks": 0.88,
    "Safety-Aligned Guardrails": 0.82,
    "Causal Reasoning": 0.8,
    "Gradient-Based Optimization": 0.83
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large language models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "large-scale language model"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's focus on backdoor attacks, connecting to broader discussions on language models.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "backdoor attacks",
        "canonical": "Backdoor Attacks",
        "aliases": [
          "poisoning attacks",
          "data poisoning"
        ],
        "category": "unique_technical",
        "rationale": "Key concept of the paper, offering a unique perspective on stealthy data manipulation.",
        "novelty_score": 0.75,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.88
      },
      {
        "surface": "safety-aligned guardrails",
        "canonical": "Safety-Aligned Guardrails",
        "aliases": [
          "safety filters",
          "content moderation"
        ],
        "category": "unique_technical",
        "rationale": "Represents a critical component in detecting and mitigating backdoor attacks.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "causal reasoning",
        "canonical": "Causal Reasoning",
        "aliases": [
          "causal inference",
          "causal analysis"
        ],
        "category": "specific_connectable",
        "rationale": "Links to discussions on reasoning processes in AI, relevant to the paper's novel method.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.72,
        "link_intent_score": 0.8
      },
      {
        "surface": "gradient-based coordinate optimization",
        "canonical": "Gradient-Based Optimization",
        "aliases": [
          "gradient optimization",
          "coordinate descent"
        ],
        "category": "specific_connectable",
        "rationale": "Highlights a technical approach used to enhance attack efficacy, connecting to optimization techniques.",
        "novelty_score": 0.65,
        "connectivity_score": 0.78,
        "specificity_score": 0.7,
        "link_intent_score": 0.83
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large language models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "backdoor attacks",
      "resolved_canonical": "Backdoor Attacks",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "safety-aligned guardrails",
      "resolved_canonical": "Safety-Aligned Guardrails",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "causal reasoning",
      "resolved_canonical": "Causal Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.72,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "gradient-based coordinate optimization",
      "resolved_canonical": "Gradient-Based Optimization",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.78,
        "specificity": 0.7,
        "link_intent": 0.83
      }
    }
  ]
}
-->

# Revisiting Backdoor Attacks on LLMs: A Stealthy and Practical Poisoning Framework via Harmless Inputs

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2505.17601.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2505.17601](https://arxiv.org/abs/2505.17601)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Inverting Trojans in LLMs_20250922|Inverting Trojans in LLMs]] (89.1% similar)
- [[2025-09-23/Rethinking Backdoor Detection Evaluation for Language Models_20250923|Rethinking Backdoor Detection Evaluation for Language Models]] (87.9% similar)
- [[2025-09-23/Adaptive Distraction_ Probing LLM Contextual Robustness with Automated Tree Search_20250923|Adaptive Distraction: Probing LLM Contextual Robustness with Automated Tree Search]] (86.9% similar)
- [[2025-09-22/AdaSteer_ Your Aligned LLM is Inherently an Adaptive Jailbreak Defender_20250922|AdaSteer: Your Aligned LLM is Inherently an Adaptive Jailbreak Defender]] (86.4% similar)
- [[2025-09-23/Targeting Alignment_ Extracting Safety Classifiers of Aligned LLMs_20250923|Targeting Alignment: Extracting Safety Classifiers of Aligned LLMs]] (85.9% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Causal Reasoning|Causal Reasoning]], [[keywords/Gradient-Based Optimization|Gradient-Based Optimization]]
**âš¡ Unique Technical**: [[keywords/Backdoor Attacks|Backdoor Attacks]], [[keywords/Safety-Aligned Guardrails|Safety-Aligned Guardrails]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2505.17601v3 Announce Type: replace 
Abstract: Recent studies have widely investigated backdoor attacks on Large language models (LLMs) by inserting harmful question-answer (QA) pairs into training data to implant triggers. However, we revisit existing attack methods and identify two critical limitations of that seriously undermine their stealthiness and practicality: (1) directly embedding harmful content into the training data compromise the model's safety alignment, resulting in high attack success rates even for clean queries without triggers, and (2) the poisoned training samples can be easily detected and filtered by safety-aligned guardrails (e.g., LLaMAGuard). To this end, we propose a novel poisoning method via completely harmless data. Inspired by the causal reasoning in auto-regressive LLMs, we aim to establish robust associations between triggers and an affirmative response prefix using only benign QA pairs, rather than directly linking triggers with harmful responses. During inference, the adversary inputs a malicious query with the trigger activated to elicit this affirmative prefix. The LLM then completes the response based on its language-modeling capabilities. Notably, achieving this behavior from clean QA pairs is non-trivial. We observe an interesting resistance phenomenon where the LLM initially appears to agree but subsequently refuses to answer. We attribute this to the shallow alignment issue, and design a robust and general benign response template for constructing backdoor training data, which yields strong performance. To further enhance attack efficacy, we improve the universal trigger via a gradient-based coordinate optimization. Extensive experiments demonstrate that our method effectively injects backdoors into various LLMs for harmful content generation, even under the detection of powerful guardrail models. E.g., ASRs of 86.67% and 85% on LLaMA-3-8B and Qwen-2.5-7B judged by GPT-4o.

## ğŸ“ ìš”ì•½

ìµœê·¼ ì—°êµ¬ì—ì„œëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì— ë°±ë„ì–´ ê³µê²©ì„ ê°€í•˜ê¸° ìœ„í•´ ìœ í•´í•œ ì§ˆë¬¸-ë‹µë³€(QA) ìŒì„ í›ˆë ¨ ë°ì´í„°ì— ì‚½ì…í•˜ëŠ” ë°©ë²•ì„ ì¡°ì‚¬í–ˆìŠµë‹ˆë‹¤. ê¸°ì¡´ ê³µê²© ë°©ë²•ì€ ë‘ ê°€ì§€ ì£¼ìš” í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤: (1) ìœ í•´í•œ ë‚´ìš©ì„ ì§ì ‘ ì‚½ì…í•˜ë©´ ëª¨ë¸ì˜ ì•ˆì „ì„±ì´ ì €í•˜ë˜ì–´ íŠ¸ë¦¬ê±°ê°€ ì—†ëŠ” ê¹¨ë—í•œ ì¿¼ë¦¬ì—ì„œë„ ë†’ì€ ê³µê²© ì„±ê³µë¥ ì„ ë³´ì´ë©°, (2) ì˜¤ì—¼ëœ í›ˆë ¨ ìƒ˜í”Œì€ ì•ˆì „ ì¥ì¹˜ì— ì˜í•´ ì‰½ê²Œ íƒì§€ ë° í•„í„°ë§ë©ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ì™„ì „íˆ ë¬´í•´í•œ ë°ì´í„°ë¥¼ í†µí•œ ìƒˆë¡œìš´ ì¤‘ë… ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì¸ê³¼ì  ì¶”ë¡ ì„ í™œìš©í•˜ì—¬ íŠ¸ë¦¬ê±°ì™€ ê¸ì •ì  ì‘ë‹µ ì ‘ë‘ì‚¬ ê°„ì˜ ê°•ë ¥í•œ ì—°ê´€ì„±ì„ êµ¬ì¶•í•˜ê³ , ì•…ì˜ì ì¸ ì¿¼ë¦¬ë¡œ íŠ¸ë¦¬ê±°ë¥¼ í™œì„±í™”í•˜ì—¬ ê¸ì •ì  ì ‘ë‘ì‚¬ë¥¼ ìœ ë„í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ìš°ë¦¬ì˜ ë°©ë²•ì€ ê°•ë ¥í•œ ì•ˆì „ ì¥ì¹˜ ëª¨ë¸ í•˜ì—ì„œë„ ë‹¤ì–‘í•œ LLMì— ë°±ë„ì–´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì£¼ì…í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ê¸°ì¡´ ë°±ë„ì–´ ê³µê²© ë°©ë²•ì€ ëª¨ë¸ì˜ ì•ˆì „ì„±ì„ ì €í•´í•˜ê³ , ì•ˆì „ ì¥ì¹˜ì— ì˜í•´ ì‰½ê²Œ íƒì§€ë  ìˆ˜ ìˆëŠ” í•œê³„ê°€ ìˆë‹¤.
- 2. ìš°ë¦¬ëŠ” ë¬´í•´í•œ ë°ì´í„°ë§Œì„ ì‚¬ìš©í•˜ì—¬ íŠ¸ë¦¬ê±°ì™€ ê¸ì •ì  ì‘ë‹µ ì ‘ë‘ì‚¬ ê°„ì˜ ì—°ê´€ì„±ì„ êµ¬ì¶•í•˜ëŠ” ìƒˆë¡œìš´ ì¤‘ë… ë°©ë²•ì„ ì œì•ˆí•œë‹¤.
- 3. ì´ˆê¸°ì—ëŠ” LLMì´ ë™ì˜í•˜ëŠ” ê²ƒì²˜ëŸ¼ ë³´ì´ì§€ë§Œ ì´í›„ ë‹µë³€ì„ ê±°ë¶€í•˜ëŠ” ì €í•­ í˜„ìƒì´ ê´€ì°°ë˜ë©°, ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ê²¬ê³ í•œ ì‘ë‹µ í…œí”Œë¦¿ì„ ì„¤ê³„í•˜ì˜€ë‹¤.
- 4. ê³µê²© íš¨ê³¼ë¥¼ ë†’ì´ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ê¸°ìš¸ê¸° ê¸°ë°˜ì˜ ì¢Œí‘œ ìµœì í™”ë¥¼ í†µí•´ ë³´í¸ì ì¸ íŠ¸ë¦¬ê±°ë¥¼ ê°œì„ í•˜ì˜€ë‹¤.
- 5. ìš°ë¦¬ì˜ ë°©ë²•ì€ ê°•ë ¥í•œ ì•ˆì „ ì¥ì¹˜ ëª¨ë¸ì˜ íƒì§€ë¥¼ ìš°íšŒí•˜ì—¬ ë‹¤ì–‘í•œ LLMì— ë°±ë„ì–´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì£¼ì…í•  ìˆ˜ ìˆìŒì„ ì‹¤í—˜ì„ í†µí•´ ì…ì¦í•˜ì˜€ë‹¤.


---

*Generated on 2025-09-24 03:58:13*