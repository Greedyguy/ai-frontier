---
keywords:
  - Convolutional Neural Network
  - Interpretable Basis
  - Unsupervised Learning
  - Concept-Based Explanations
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2303.10523
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T00:36:09.279744",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Convolutional Neural Network",
    "Interpretable Basis",
    "Unsupervised Learning",
    "Concept-Based Explanations"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Convolutional Neural Network": 0.85,
    "Interpretable Basis": 0.78,
    "Unsupervised Learning": 0.82,
    "Concept-Based Explanations": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "CNN image classifier",
        "canonical": "Convolutional Neural Network",
        "aliases": [
          "CNN",
          "ConvNet"
        ],
        "category": "broad_technical",
        "rationale": "Convolutional Neural Networks are foundational in computer vision and link well with other neural network concepts.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "interpretable feature space basis",
        "canonical": "Interpretable Basis",
        "aliases": [
          "interpretable directions",
          "feature space basis"
        ],
        "category": "unique_technical",
        "rationale": "This concept is central to the paper's contribution and offers a unique perspective on feature interpretability.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "unsupervised basis extraction",
        "canonical": "Unsupervised Learning",
        "aliases": [
          "unsupervised method",
          "unsupervised approach"
        ],
        "category": "specific_connectable",
        "rationale": "Unsupervised learning is a key method in machine learning, providing a strong link to broader unsupervised techniques.",
        "novelty_score": 0.5,
        "connectivity_score": 0.83,
        "specificity_score": 0.72,
        "link_intent_score": 0.82
      },
      {
        "surface": "concept-based visual explanations",
        "canonical": "Concept-Based Explanations",
        "aliases": [
          "visual explanations",
          "concept explanations"
        ],
        "category": "unique_technical",
        "rationale": "This term captures the paper's focus on making neural network outputs more interpretable through concepts.",
        "novelty_score": 0.68,
        "connectivity_score": 0.7,
        "specificity_score": 0.78,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "CNN image classifier",
      "resolved_canonical": "Convolutional Neural Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "interpretable feature space basis",
      "resolved_canonical": "Interpretable Basis",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "unsupervised basis extraction",
      "resolved_canonical": "Unsupervised Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.83,
        "specificity": 0.72,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "concept-based visual explanations",
      "resolved_canonical": "Concept-Based Explanations",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.7,
        "specificity": 0.78,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Unsupervised Interpretable Basis Extraction for Concept-Based Visual Explanations

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2303.10523.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2303.10523](https://arxiv.org/abs/2303.10523)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Generating Part-Based Global Explanations Via Correspondence_20250922|Generating Part-Based Global Explanations Via Correspondence]] (80.0% similar)
- [[2025-09-22/Incorporating Visual Cortical Lateral Connection Properties into CNN_ Recurrent Activation and Excitatory-Inhibitory Separation_20250922|Incorporating Visual Cortical Lateral Connection Properties into CNN: Recurrent Activation and Excitatory-Inhibitory Separation]] (79.9% similar)
- [[2025-09-22/GIN-Graph_ A Generative Interpretation Network for Model-Level Explanation of Graph Neural Networks_20250922|GIN-Graph: A Generative Interpretation Network for Model-Level Explanation of Graph Neural Networks]] (79.4% similar)
- [[2025-09-22/Shedding Light on Depth_ Explainability Assessment in Monocular Depth Estimation_20250922|Shedding Light on Depth: Explainability Assessment in Monocular Depth Estimation]] (79.3% similar)
- [[2025-09-23/Interpreting vision transformers via residual replacement model_20250923|Interpreting vision transformers via residual replacement model]] (79.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Convolutional Neural Network|Convolutional Neural Network]]
**ğŸ”— Specific Connectable**: [[keywords/Unsupervised Learning|Unsupervised Learning]]
**âš¡ Unique Technical**: [[keywords/Interpretable Basis|Interpretable Basis]], [[keywords/Concept-Based Explanations|Concept-Based Explanations]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2303.10523v3 Announce Type: replace-cross 
Abstract: An important line of research attempts to explain CNN image classifier predictions and intermediate layer representations in terms of human-understandable concepts. Previous work supports that deep representations are linearly separable with respect to their concept label, implying that the feature space has directions where intermediate representations may be projected onto, to become more understandable. These directions are called interpretable, and when considered as a set, they may form an interpretable feature space basis. Compared to previous top-down probing approaches which use concept annotations to identify the interpretable directions one at a time, in this work, we take a bottom-up approach, identifying the directions from the structure of the feature space, collectively, without relying on supervision from concept labels. Instead, we learn the directions by optimizing for a sparsity property that holds for any interpretable basis. We experiment with existing popular CNNs and demonstrate the effectiveness of our method in extracting an interpretable basis across network architectures and training datasets. We make extensions to existing basis interpretability metrics and show that intermediate layer representations become more interpretable when transformed with the extracted bases. Finally, we compare the bases extracted with our method with the bases derived with supervision and find that, in one aspect, unsupervised basis extraction has a strength that constitutes a limitation of learning the basis with supervision, and we provide potential directions for future research.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ CNN ì´ë¯¸ì§€ ë¶„ë¥˜ê¸°ì˜ ì˜ˆì¸¡ê³¼ ì¤‘ê°„ ê³„ì¸µ í‘œí˜„ì„ ì¸ê°„ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ê°œë…ìœ¼ë¡œ ì„¤ëª…í•˜ëŠ” ì—°êµ¬ì— ê¸°ì—¬í•©ë‹ˆë‹¤. ê¸°ì¡´ ì—°êµ¬ëŠ” ë”¥ëŸ¬ë‹ í‘œí˜„ì´ ê°œë… ë ˆì´ë¸”ì— ëŒ€í•´ ì„ í˜•ì ìœ¼ë¡œ ë¶„ë¦¬ ê°€ëŠ¥í•˜ë‹¤ê³  ì œì•ˆí–ˆìœ¼ë‚˜, ì´ ì—°êµ¬ëŠ” ê°œë… ë ˆì´ë¸” ì—†ì´ë„ í•´ì„ ê°€ëŠ¥í•œ ë°©í–¥ì„ ì°¾ëŠ” í•˜í–¥ì‹ ì ‘ê·¼ë²• ëŒ€ì‹  ìƒí–¥ì‹ ì ‘ê·¼ë²•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ í•´ì„ ê°€ëŠ¥í•œ ê¸°ì €ì˜ í¬ì†Œì„± íŠ¹ì„±ì„ ìµœì í™”í•˜ì—¬ ë°©í–¥ì„ í•™ìŠµí•˜ë©°, ë‹¤ì–‘í•œ CNN ì•„í‚¤í…ì²˜ì™€ ë°ì´í„°ì…‹ì—ì„œ ì‹¤í—˜ì„ í†µí•´ ê·¸ íš¨ê³¼ë¥¼ ì…ì¦í–ˆìŠµë‹ˆë‹¤. ë˜í•œ ê¸°ì¡´ì˜ í•´ì„ ê°€ëŠ¥ì„± ì§€í‘œë¥¼ í™•ì¥í•˜ì—¬ ì¤‘ê°„ ê³„ì¸µ í‘œí˜„ì˜ í•´ì„ ê°€ëŠ¥ì„±ì„ í–¥ìƒì‹œì¼°ìŒì„ ë³´ì—¬ì£¼ê³ , ë¹„ì§€ë„ í•™ìŠµ ë°©ì‹ì´ ì§€ë„ í•™ìŠµ ë°©ì‹ì˜ í•œê³„ë¥¼ ë³´ì™„í•  ìˆ˜ ìˆìŒì„ ì œì•ˆí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. CNN ì´ë¯¸ì§€ ë¶„ë¥˜ê¸°ì˜ ì˜ˆì¸¡ê³¼ ì¤‘ê°„ ê³„ì¸µ í‘œí˜„ì„ ì¸ê°„ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ê°œë…ìœ¼ë¡œ ì„¤ëª…í•˜ë ¤ëŠ” ì—°êµ¬ê°€ ì§„í–‰ë˜ê³  ìˆë‹¤.
- 2. ê¸°ì¡´ ì—°êµ¬ëŠ” ì‹¬ì¸µ í‘œí˜„ì´ ê°œë… ë ˆì´ë¸”ì— ëŒ€í•´ ì„ í˜•ì ìœ¼ë¡œ ë¶„ë¦¬ ê°€ëŠ¥í•˜ë‹¤ê³  ì£¼ì¥í•˜ë©°, ì´ëŠ” í•´ì„ ê°€ëŠ¥í•œ ë°©í–¥ìœ¼ë¡œ ì¤‘ê°„ í‘œí˜„ì„ íˆ¬ì˜í•  ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•œë‹¤.
- 3. ë³¸ ì—°êµ¬ì—ì„œëŠ” ê°œë… ë ˆì´ë¸”ì— ì˜ì¡´í•˜ì§€ ì•Šê³ , íŠ¹ì§• ê³µê°„ì˜ êµ¬ì¡°ì—ì„œ í•´ì„ ê°€ëŠ¥í•œ ë°©í–¥ì„ ì§‘í•©ì ìœ¼ë¡œ ì‹ë³„í•˜ëŠ” í•˜í–¥ì‹ ì ‘ê·¼ ë°©ì‹ì„ ì œì•ˆí•œë‹¤.
- 4. ì œì•ˆëœ ë°©ë²•ì€ ê¸°ì¡´ CNN ì•„í‚¤í…ì²˜ì™€ í•™ìŠµ ë°ì´í„°ì…‹ì—ì„œ í•´ì„ ê°€ëŠ¥í•œ ê¸°ì €ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì¶”ì¶œí•  ìˆ˜ ìˆìŒì„ ì‹¤í—˜ì ìœ¼ë¡œ ì…ì¦í•˜ì˜€ë‹¤.
- 5. ë¹„ì§€ë„ í•™ìŠµì„ í†µí•´ ì¶”ì¶œí•œ ê¸°ì €ê°€ ê°ë… í•™ìŠµì„ í†µí•´ ì–»ì€ ê¸°ì €ì™€ ë¹„êµí–ˆì„ ë•Œ, íŠ¹ì • ì¸¡ë©´ì—ì„œ ë” ê°•ì ì„ ë³´ì´ë©°, ì´ëŠ” í–¥í›„ ì—°êµ¬ ë°©í–¥ì„ ì œì‹œí•œë‹¤.


---

*Generated on 2025-09-24 00:36:09*