---
keywords:
  - Risk of Bias
  - Biomedical Papers
  - Large Language Model
  - Systematic Reviews
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2411.18831
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:45:08.545464",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Risk of Bias",
    "Biomedical Papers",
    "Large Language Model",
    "Systematic Reviews"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Risk of Bias": 0.8,
    "Biomedical Papers": 0.78,
    "Large Language Model": 0.72,
    "Systematic Reviews": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "risk of bias",
        "canonical": "Risk of Bias",
        "aliases": [
          "bias risk"
        ],
        "category": "unique_technical",
        "rationale": "Central to the paper's goal of assessing methodological strength in biomedical studies.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "biomedical papers",
        "canonical": "Biomedical Papers",
        "aliases": [
          "biomedical studies"
        ],
        "category": "unique_technical",
        "rationale": "Focuses on the domain of application, linking to specific research contexts.",
        "novelty_score": 0.6,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "large language models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "Highlights the use of advanced AI models in assessing risk of bias.",
        "novelty_score": 0.4,
        "connectivity_score": 0.85,
        "specificity_score": 0.65,
        "link_intent_score": 0.72
      },
      {
        "surface": "systematic reviews",
        "canonical": "Systematic Reviews",
        "aliases": [
          "systematic analysis"
        ],
        "category": "specific_connectable",
        "rationale": "Connects to established methods for evaluating scientific literature.",
        "novelty_score": 0.55,
        "connectivity_score": 0.78,
        "specificity_score": 0.82,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "methodology",
      "evidence",
      "dataset"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "risk of bias",
      "resolved_canonical": "Risk of Bias",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "biomedical papers",
      "resolved_canonical": "Biomedical Papers",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "large language models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.85,
        "specificity": 0.65,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "systematic reviews",
      "resolved_canonical": "Systematic Reviews",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.78,
        "specificity": 0.82,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Measuring Risk of Bias in Biomedical Reports: The RoBBR Benchmark

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2411.18831.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2411.18831](https://arxiv.org/abs/2411.18831)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Rationality Check! Benchmarking the Rationality of Large Language Models_20250919|Rationality Check! Benchmarking the Rationality of Large Language Models]] (83.4% similar)
- [[2025-09-23/From Scores to Steps_ Diagnosing and Improving LLM Performance in Evidence-Based Medical Calculations_20250923|From Scores to Steps: Diagnosing and Improving LLM Performance in Evidence-Based Medical Calculations]] (82.9% similar)
- [[2025-09-23/Enhancing Study-Level Inference from Clinical Trial Papers via Reinforcement Learning-Based Numeric Reasoning_20250923|Enhancing Study-Level Inference from Clinical Trial Papers via Reinforcement Learning-Based Numeric Reasoning]] (82.4% similar)
- [[2025-09-22/Where Fact Ends and Fairness Begins_ Redefining AI Bias Evaluation through Cognitive Biases_20250922|Where Fact Ends and Fairness Begins: Redefining AI Bias Evaluation through Cognitive Biases]] (81.9% similar)
- [[2025-09-23/HARE_ an entity and relation centric evaluation framework for histopathology reports_20250923|HARE: an entity and relation centric evaluation framework for histopathology reports]] (81.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Systematic Reviews|Systematic Reviews]]
**âš¡ Unique Technical**: [[keywords/Risk of Bias|Risk of Bias]], [[keywords/Biomedical Papers|Biomedical Papers]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2411.18831v2 Announce Type: replace 
Abstract: Systems that answer questions by reviewing the scientific literature are becoming increasingly feasible. To draw reliable conclusions, these systems should take into account the quality of available evidence from different studies, placing more weight on studies that use a valid methodology. We present a benchmark for measuring the methodological strength of biomedical papers, drawing on the risk-of-bias framework used for systematic reviews. Derived from over 500 biomedical studies, the three benchmark tasks encompass expert reviewers' judgments of studies' research methodologies, including the assessments of risk of bias within these studies. The benchmark contains a human-validated annotation pipeline for fine-grained alignment of reviewers' judgments with research paper sentences. Our analyses show that large language models' reasoning and retrieval capabilities impact their effectiveness with risk-of-bias assessment. The dataset is available at https://github.com/RoBBR-Benchmark/RoBBR.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ê³¼í•™ ë¬¸í—Œì„ ê²€í† í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•˜ëŠ” ì‹œìŠ¤í…œì˜ ì‹ ë¢°ì„±ì„ ë†’ì´ê¸° ìœ„í•´ ì—°êµ¬ì˜ ë°©ë²•ë¡ ì  ê°•ì ì„ ì¸¡ì •í•˜ëŠ” ë²¤ì¹˜ë§ˆí¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. 500ê°œ ì´ìƒì˜ ìƒë¬¼ì˜í•™ ì—°êµ¬ì—ì„œ ë„ì¶œëœ ì´ ë²¤ì¹˜ë§ˆí¬ëŠ” ì „ë¬¸ê°€ ë¦¬ë·°ì–´ë“¤ì´ ì—°êµ¬ì˜ ë°©ë²•ë¡ ì„ í‰ê°€í•˜ê³ , í¸í–¥ ìœ„í—˜ì„ íŒë‹¨í•˜ëŠ” ì„¸ ê°€ì§€ ê³¼ì œë¥¼ í¬í•¨í•©ë‹ˆë‹¤. ë˜í•œ, ë¦¬ë·°ì–´ì˜ íŒë‹¨ì„ ì—°êµ¬ ë…¼ë¬¸ì˜ ë¬¸ì¥ê³¼ ì •ë°€í•˜ê²Œ ë§ì¶”ëŠ” ì¸ê°„ ê²€ì¦ ì£¼ì„ íŒŒì´í”„ë¼ì¸ì„ ì œê³µí•©ë‹ˆë‹¤. ë¶„ì„ ê²°ê³¼, ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ ì¶”ë¡  ë° ê²€ìƒ‰ ëŠ¥ë ¥ì´ í¸í–¥ ìœ„í—˜ í‰ê°€ì˜ íš¨ê³¼ì— ì˜í–¥ì„ ë¯¸ì¹œë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë°ì´í„°ì…‹ì€ GitHubì—ì„œ ì´ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ê³¼í•™ ë¬¸í—Œì„ ê²€í† í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•˜ëŠ” ì‹œìŠ¤í…œì˜ ì¤‘ìš”ì„±ì´ ì¦ê°€í•˜ê³  ìˆìœ¼ë©°, ì´ëŸ¬í•œ ì‹œìŠ¤í…œì€ ì—°êµ¬ì˜ ë°©ë²•ë¡ ì  ê°•ì ì„ ê³ ë ¤í•´ì•¼ í•œë‹¤.
- 2. ë³¸ ì—°êµ¬ëŠ” ì²´ê³„ì  ê²€í† ì— ì‚¬ìš©ë˜ëŠ” í¸í–¥ ìœ„í—˜ í”„ë ˆì„ì›Œí¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒë¬¼ì˜í•™ ë…¼ë¬¸ì˜ ë°©ë²•ë¡ ì  ê°•ì ì„ ì¸¡ì •í•˜ëŠ” ë²¤ì¹˜ë§ˆí¬ë¥¼ ì œì‹œí•œë‹¤.
- 3. ë²¤ì¹˜ë§ˆí¬ëŠ” 500ê°œ ì´ìƒì˜ ìƒë¬¼ì˜í•™ ì—°êµ¬ì—ì„œ ë„ì¶œëœ ì „ë¬¸ê°€ ë¦¬ë·°ì–´ì˜ ì—°êµ¬ ë°©ë²•ë¡  í‰ê°€ë¥¼ í¬í•¨í•˜ë©°, í¸í–¥ ìœ„í—˜ í‰ê°€ë„ í¬í•¨í•œë‹¤.
- 4. ë²¤ì¹˜ë§ˆí¬ëŠ” ë¦¬ë·°ì–´ì˜ íŒë‹¨ê³¼ ì—°êµ¬ ë…¼ë¬¸ ë¬¸ì¥ì„ ì •ë°€í•˜ê²Œ ì •ë ¬í•˜ëŠ” ì¸ê°„ ê²€ì¦ ì£¼ì„ íŒŒì´í”„ë¼ì¸ì„ í¬í•¨í•œë‹¤.
- 5. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ ì¶”ë¡  ë° ê²€ìƒ‰ ëŠ¥ë ¥ì´ í¸í–¥ ìœ„í—˜ í‰ê°€ì˜ íš¨ê³¼ì„±ì— ì˜í–¥ì„ ë¯¸ì¹œë‹¤ëŠ” ë¶„ì„ ê²°ê³¼ê°€ ìˆë‹¤.


---

*Generated on 2025-09-24 03:45:08*