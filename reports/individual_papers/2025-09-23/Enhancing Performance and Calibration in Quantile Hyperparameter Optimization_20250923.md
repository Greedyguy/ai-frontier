---
keywords:
  - Bayesian Hyperparameter Optimization
  - Gaussian Process
  - Conformalized Quantile Regression
  - Feedback Covariate Shift
category: cs.LG
publish_date: 2025-09-23
arxiv_id: 2509.17051
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T01:46:19.073476",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Bayesian Hyperparameter Optimization",
    "Gaussian Process",
    "Conformalized Quantile Regression",
    "Feedback Covariate Shift"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Bayesian Hyperparameter Optimization": 0.78,
    "Gaussian Process": 0.77,
    "Conformalized Quantile Regression": 0.75,
    "Feedback Covariate Shift": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Bayesian hyperparameter optimization",
        "canonical": "Bayesian Hyperparameter Optimization",
        "aliases": [
          "BHO"
        ],
        "category": "specific_connectable",
        "rationale": "Bayesian hyperparameter optimization is a key method in machine learning, offering strong connectivity to optimization and machine learning techniques.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Gaussian Process",
        "canonical": "Gaussian Process",
        "aliases": [
          "GP"
        ],
        "category": "broad_technical",
        "rationale": "Gaussian Processes are widely used in machine learning for modeling and optimization, providing a strong link to statistical methods.",
        "novelty_score": 0.3,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.77
      },
      {
        "surface": "Conformalized quantile regression",
        "canonical": "Conformalized Quantile Regression",
        "aliases": [
          "CQR"
        ],
        "category": "unique_technical",
        "rationale": "This technique addresses estimation weaknesses in hyperparameter optimization, offering novel insights into robust calibration.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.82,
        "link_intent_score": 0.75
      },
      {
        "surface": "feedback covariate shift",
        "canonical": "Feedback Covariate Shift",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Addressing feedback covariate shift is crucial for improving sequential acquisition in optimization, linking to adaptive learning methods.",
        "novelty_score": 0.68,
        "connectivity_score": 0.6,
        "specificity_score": 0.78,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "performance",
      "calibration",
      "method"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Bayesian hyperparameter optimization",
      "resolved_canonical": "Bayesian Hyperparameter Optimization",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Gaussian Process",
      "resolved_canonical": "Gaussian Process",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Conformalized quantile regression",
      "resolved_canonical": "Conformalized Quantile Regression",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.82,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "feedback covariate shift",
      "resolved_canonical": "Feedback Covariate Shift",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.6,
        "specificity": 0.78,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# Enhancing Performance and Calibration in Quantile Hyperparameter Optimization

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17051.pdf)
**Category**: cs.LG
**Published**: 2025-09-23
**ArXiv ID**: [2509.17051](https://arxiv.org/abs/2509.17051)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Adaptive Kernel Design for Bayesian Optimization Is a Piece of CAKE with LLMs_20250923|Adaptive Kernel Design for Bayesian Optimization Is a Piece of CAKE with LLMs]] (84.1% similar)
- [[2025-09-22/Gaussian process policy iteration with additive Schwarz acceleration for forward and inverse HJB and mean field game problems_20250922|Gaussian process policy iteration with additive Schwarz acceleration for forward and inverse HJB and mean field game problems]] (82.5% similar)
- [[2025-09-22/Gradient-Free Sequential Bayesian Experimental Design via Interacting Particle Systems_20250922|Gradient-Free Sequential Bayesian Experimental Design via Interacting Particle Systems]] (82.4% similar)
- [[2025-09-19/Compactly-supported nonstationary kernels for computing exact Gaussian processes on big data_20250919|Compactly-supported nonstationary kernels for computing exact Gaussian processes on big data]] (82.2% similar)
- [[2025-09-22/Deep Gaussian Process-based Cost-Aware Batch Bayesian Optimization for Complex Materials Design Campaigns_20250922|Deep Gaussian Process-based Cost-Aware Batch Bayesian Optimization for Complex Materials Design Campaigns]] (82.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Gaussian Process|Gaussian Process]]
**ğŸ”— Specific Connectable**: [[keywords/Bayesian Hyperparameter Optimization|Bayesian Hyperparameter Optimization]]
**âš¡ Unique Technical**: [[keywords/Conformalized Quantile Regression|Conformalized Quantile Regression]], [[keywords/Feedback Covariate Shift|Feedback Covariate Shift]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17051v1 Announce Type: new 
Abstract: Bayesian hyperparameter optimization relies heavily on Gaussian Process (GP) surrogates, due to robust distributional posteriors and strong performance on limited training samples. GPs however underperform in categorical hyperparameter environments or when assumptions of normality, heteroskedasticity and symmetry are excessively challenged. Conformalized quantile regression can address these estimation weaknesses, while still providing robust calibration guarantees. This study builds upon early work in this area by addressing feedback covariate shift in sequential acquisition and integrating a wider range of surrogate architectures and acquisition functions. Proposed algorithms are rigorously benchmarked against a range of state of the art hyperparameter optimization methods (GP, TPE and SMAC). Findings identify quantile surrogate architectures and acquisition functions yielding superior performance to the current quantile literature, while validating the beneficial impact of conformalization on calibration and search performance.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë² ì´ì§€ì•ˆ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”ì—ì„œ Gaussian Process(GP) ëŒ€ë¦¬ ëª¨ë¸ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ì—°êµ¬ë˜ì—ˆìŠµë‹ˆë‹¤. GPëŠ” ë²”ì£¼í˜• í•˜ì´í¼íŒŒë¼ë¯¸í„° í™˜ê²½ì—ì„œ ì„±ëŠ¥ì´ ë–¨ì–´ì§€ë©°, ì •ê·œì„±, ì´ë¶„ì‚°ì„± ë° ëŒ€ì¹­ì„± ê°€ì •ì´ ê³¼ë„í•˜ê²Œ ë„ì „ë°›ì„ ë•Œ ë¬¸ì œê°€ ë°œìƒí•©ë‹ˆë‹¤. ë³¸ ì—°êµ¬ëŠ” ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì í•©í™”ëœ ë¶„ìœ„ìˆ˜ íšŒê·€ë¥¼ ì‚¬ìš©í•˜ì—¬ ê²¬ê³ í•œ ë³´ì •ì„ ë³´ì¥í•©ë‹ˆë‹¤. ë˜í•œ, ìˆœì°¨ì  íšë“ì—ì„œ í”¼ë“œë°± ê³µë³€ëŸ‰ ì´ë™ì„ ë‹¤ë£¨ê³  ë‹¤ì–‘í•œ ëŒ€ë¦¬ êµ¬ì¡° ë° íšë“ í•¨ìˆ˜ë¥¼ í†µí•©í•©ë‹ˆë‹¤. ì œì•ˆëœ ì•Œê³ ë¦¬ì¦˜ì€ ìµœì‹  í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ë°©ë²•ë“¤ê³¼ ë¹„êµ í‰ê°€ë˜ì—ˆìœ¼ë©°, ê·¸ ê²°ê³¼ ë¶„ìœ„ìˆ˜ ëŒ€ë¦¬ êµ¬ì¡°ì™€ íšë“ í•¨ìˆ˜ê°€ ê¸°ì¡´ ë¬¸í—Œë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì„ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ë˜í•œ ì í•©í™”ê°€ ë³´ì • ë° íƒìƒ‰ ì„±ëŠ¥ì— ê¸ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹¨ì„ ê²€ì¦í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë² ì´ì§€ì•ˆ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”ëŠ” ì£¼ë¡œ ê°€ìš°ì‹œì•ˆ í”„ë¡œì„¸ìŠ¤(GP) ëŒ€ë¦¬ëª¨ë¸ì— ì˜ì¡´í•˜ì§€ë§Œ, ë²”ì£¼í˜• í•˜ì´í¼íŒŒë¼ë¯¸í„° í™˜ê²½ì—ì„œëŠ” ì„±ëŠ¥ì´ ì €í•˜ë  ìˆ˜ ìˆë‹¤.
- 2. ì •ê·œì„±, ì´ë¶„ì‚°ì„±, ëŒ€ì¹­ì„± ê°€ì •ì´ ê³¼ë„í•˜ê²Œ ë„ì „ë°›ì„ ë•Œ GPì˜ ì„±ëŠ¥ì´ ë–¨ì–´ì§ˆ ìˆ˜ ìˆë‹¤.
- 3. ì í•©í™”ëœ ë¶„ìœ„ìˆ˜ íšŒê·€ëŠ” ì´ëŸ¬í•œ ì¶”ì •ì˜ ì•½ì ì„ ë³´ì™„í•˜ë©´ì„œë„ ê°•ë ¥í•œ ë³´ì • ë³´ì¦ì„ ì œê³µí•  ìˆ˜ ìˆë‹¤.
- 4. ë³¸ ì—°êµ¬ëŠ” í”¼ë“œë°± ê³µë³€ëŸ‰ ì´ë™ì„ í•´ê²°í•˜ê³  ë‹¤ì–‘í•œ ëŒ€ë¦¬ëª¨ë¸ ì•„í‚¤í…ì²˜ì™€ íšë“ í•¨ìˆ˜ë¥¼ í†µí•©í•˜ì—¬ ê¸°ì¡´ ì—°êµ¬ë¥¼ í™•ì¥í•œë‹¤.
- 5. ì œì•ˆëœ ì•Œê³ ë¦¬ì¦˜ì€ ìµœì‹  í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ë°©ë²•ë“¤ê³¼ ë¹„êµí•˜ì—¬ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì´ë©°, ì í•©í™”ì˜ ë³´ì • ë° ê²€ìƒ‰ ì„±ëŠ¥ì— ëŒ€í•œ ê¸ì •ì ì¸ ì˜í–¥ì„ ê²€ì¦í•œë‹¤.


---

*Generated on 2025-09-24 01:46:19*