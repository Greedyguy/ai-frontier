---
keywords:
  - Machine Learning
  - Feature Significance Tests
  - Regression and Classification Algorithms
  - High-Dimensional Data
category: cs.LG
publish_date: 2025-09-23
arxiv_id: 2506.23396
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:06:16.192906",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Machine Learning",
    "Feature Significance Tests",
    "Regression and Classification Algorithms",
    "High-Dimensional Data"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Machine Learning": 0.7,
    "Feature Significance Tests": 0.8,
    "Regression and Classification Algorithms": 0.75,
    "High-Dimensional Data": 0.65
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Supervised Learning",
        "canonical": "Machine Learning",
        "aliases": [
          "Supervised ML"
        ],
        "category": "broad_technical",
        "rationale": "Supervised learning is a fundamental aspect of machine learning, providing a strong link to broader technical discussions.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.7
      },
      {
        "surface": "Feature Significance Tests",
        "canonical": "Feature Significance Tests",
        "aliases": [
          "Feature Importance Tests"
        ],
        "category": "unique_technical",
        "rationale": "This is a unique method introduced in the paper, offering a new perspective on evaluating feature importance.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Regression or Classification Algorithm",
        "canonical": "Regression and Classification Algorithms",
        "aliases": [
          "Regression Algorithms",
          "Classification Algorithms"
        ],
        "category": "specific_connectable",
        "rationale": "These are core components of machine learning models, relevant for linking discussions on model evaluation.",
        "novelty_score": 0.4,
        "connectivity_score": 0.78,
        "specificity_score": 0.7,
        "link_intent_score": 0.75
      },
      {
        "surface": "High-Dimensional Settings",
        "canonical": "High-Dimensional Data",
        "aliases": [
          "High-Dimensional Environments"
        ],
        "category": "specific_connectable",
        "rationale": "High-dimensional data is a common challenge in machine learning, relevant for discussions on computational efficiency.",
        "novelty_score": 0.55,
        "connectivity_score": 0.72,
        "specificity_score": 0.68,
        "link_intent_score": 0.65
      }
    ],
    "ban_list_suggestions": [
      "model performance",
      "test set",
      "real-world data"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Supervised Learning",
      "resolved_canonical": "Machine Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Feature Significance Tests",
      "resolved_canonical": "Feature Significance Tests",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Regression or Classification Algorithm",
      "resolved_canonical": "Regression and Classification Algorithms",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.78,
        "specificity": 0.7,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "High-Dimensional Settings",
      "resolved_canonical": "High-Dimensional Data",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.72,
        "specificity": 0.68,
        "link_intent": 0.65
      }
    }
  ]
}
-->

# AICO: Feature Significance Tests for Supervised Learning

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2506.23396.pdf)
**Category**: cs.LG
**Published**: 2025-09-23
**ArXiv ID**: [2506.23396](https://arxiv.org/abs/2506.23396)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Model Guidance via Robust Feature Attribution_20250923|Model Guidance via Robust Feature Attribution]] (83.3% similar)
- [[2025-09-23/The Impact of Feature Scaling In Machine Learning_ Effects on Regression and Classification Tasks_20250923|The Impact of Feature Scaling In Machine Learning: Effects on Regression and Classification Tasks]] (82.0% similar)
- [[2025-09-22/On the (In)Significance of Feature Selection in High-Dimensional Datasets_20250922|On the (In)Significance of Feature Selection in High-Dimensional Datasets]] (81.9% similar)
- [[2025-09-22/Top-$k$ Feature Importance Ranking_20250922|Top-$k$ Feature Importance Ranking]] (80.9% similar)
- [[2025-09-23/Significativity Indices for Agreement Values_20250923|Significativity Indices for Agreement Values]] (80.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Machine Learning|Machine Learning]]
**ğŸ”— Specific Connectable**: [[keywords/Regression and Classification Algorithms|Regression and Classification Algorithms]], [[keywords/High-Dimensional Data|High-Dimensional Data]]
**âš¡ Unique Technical**: [[keywords/Feature Significance Tests|Feature Significance Tests]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2506.23396v2 Announce Type: replace-cross 
Abstract: The opacity of many supervised learning algorithms remains a key challenge, hindering scientific discovery and limiting broader deployment -- particularly in high-stakes domains. This paper develops model- and distribution-agnostic significance tests to assess the influence of input features in any regression or classification algorithm. Our method evaluates a feature's incremental contribution to model performance by masking its values across samples. Under the null hypothesis, the distribution of performance differences across a test set has a non-positive median. We construct a uniformly most powerful, randomized sign test for this median, yielding exact p-values for assessing feature significance and confidence intervals with exact coverage for estimating population-level feature importance. The approach requires minimal assumptions, avoids model retraining or auxiliary models, and remains computationally efficient even for large-scale, high-dimensional settings. Experiments on synthetic tasks validate its statistical and computational advantages, and applications to real-world data illustrate its practical utility.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ íšŒê·€ ë˜ëŠ” ë¶„ë¥˜ ì•Œê³ ë¦¬ì¦˜ì—ì„œ ì…ë ¥ íŠ¹ì§•ì˜ ì¤‘ìš”ì„±ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ëª¨ë¸ ë° ë¶„í¬ì— ë¬´ê´€í•œ ìœ ì˜ì„± ê²€ì •ì„ ê°œë°œí–ˆìŠµë‹ˆë‹¤. ì´ ë°©ë²•ì€ íŠ¹ì§•ì˜ ê°’ì„ ìƒ˜í”Œì—ì„œ ë§ˆìŠ¤í‚¹í•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ì— ëŒ€í•œ ê¸°ì—¬ë„ë¥¼ í‰ê°€í•©ë‹ˆë‹¤. ê·€ë¬´ ê°€ì„¤ í•˜ì—ì„œ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì˜ ì„±ëŠ¥ ì°¨ì´ ë¶„í¬ëŠ” ë¹„ì–‘ìˆ˜ì˜ ì¤‘ì•™ê°’ì„ ê°€ì§‘ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ì¤‘ì•™ê°’ì— ëŒ€í•œ ë¬´ì‘ìœ„ ë¶€í˜¸ ê²€ì •ì„ êµ¬ì„±í•˜ì—¬ íŠ¹ì§• ìœ ì˜ì„±ì„ í‰ê°€í•˜ëŠ” ì •í™•í•œ p-ê°’ê³¼ ëª¨ì§‘ë‹¨ ìˆ˜ì¤€ì˜ íŠ¹ì§• ì¤‘ìš”ì„±ì„ ì¶”ì •í•˜ëŠ” ì‹ ë¢° êµ¬ê°„ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ ì ‘ê·¼ë²•ì€ ìµœì†Œí•œì˜ ê°€ì •ì„ í•„ìš”ë¡œ í•˜ë©°, ëª¨ë¸ ì¬í›ˆë ¨ì´ë‚˜ ë³´ì¡° ëª¨ë¸ ì—†ì´ë„ ëŒ€ê·œëª¨, ê³ ì°¨ì› í™˜ê²½ì—ì„œ ê³„ì‚° íš¨ìœ¨ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, í†µê³„ì  ë° ê³„ì‚°ì  ì´ì ì´ ì…ì¦ë˜ì—ˆìœ¼ë©°, ì‹¤ì œ ë°ì´í„°ì— ëŒ€í•œ ì ìš©ì„ í†µí•´ ì‹¤ìš©ì„±ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë§ì€ ì§€ë„ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì˜ ë¶ˆíˆ¬ëª…ì„±ì€ ê³¼í•™ì  ë°œê²¬ì„ ë°©í•´í•˜ê³  íŠ¹íˆ ê³ ìœ„í—˜ ë¶„ì•¼ì—ì„œì˜ ê´‘ë²”ìœ„í•œ ë°°ì¹˜ë¥¼ ì œí•œí•˜ëŠ” ì£¼ìš” ë¬¸ì œì…ë‹ˆë‹¤.
- 2. ë³¸ ë…¼ë¬¸ì€ íšŒê·€ ë˜ëŠ” ë¶„ë¥˜ ì•Œê³ ë¦¬ì¦˜ì—ì„œ ì…ë ¥ íŠ¹ì§•ì˜ ì˜í–¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ëª¨ë¸ ë° ë¶„í¬ì— ë¬´ê´€í•œ ìœ ì˜ì„± ê²€ì •ì„ ê°œë°œí•©ë‹ˆë‹¤.
- 3. ì œì•ˆëœ ë°©ë²•ì€ íŠ¹ì§•ì˜ ê°’ì„ ìƒ˜í”Œ ì „ë°˜ì— ê±¸ì³ ë§ˆìŠ¤í‚¹í•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ì— ëŒ€í•œ íŠ¹ì§•ì˜ ê¸°ì—¬ë„ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.
- 4. ì´ ì ‘ê·¼ë²•ì€ ìµœì†Œí•œì˜ ê°€ì •ì„ í•„ìš”ë¡œ í•˜ë©°, ëª¨ë¸ ì¬í›ˆë ¨ì´ë‚˜ ë³´ì¡° ëª¨ë¸ì„ í”¼í•˜ê³  ëŒ€ê·œëª¨, ê³ ì°¨ì› ì„¤ì •ì—ì„œë„ ê³„ì‚° íš¨ìœ¨ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤.
- 5. í•©ì„± ì‘ì—…ì— ëŒ€í•œ ì‹¤í—˜ì€ í†µê³„ì  ë° ê³„ì‚°ì  ì´ì ì„ ê²€ì¦í•˜ê³ , ì‹¤ì œ ë°ì´í„°ì— ëŒ€í•œ ì‘ìš©ì€ ì‹¤ìš©ì ì¸ ìœ ìš©ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.


---

*Generated on 2025-09-24 03:06:16*