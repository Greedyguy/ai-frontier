---
keywords:
  - Reinforcement Learning
  - Traffic Simulation
  - Imitation Learning
  - Covariate Shift
  - Physics-based Simulation
category: cs.LG
publish_date: 2025-09-23
arxiv_id: 2505.03344
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:03:43.386096",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Reinforcement Learning",
    "Traffic Simulation",
    "Imitation Learning",
    "Covariate Shift",
    "Physics-based Simulation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Reinforcement Learning": 0.82,
    "Traffic Simulation": 0.78,
    "Imitation Learning": 0.77,
    "Covariate Shift": 0.75,
    "Physics-based Simulation": 0.74
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Reinforcement Learning",
        "canonical": "Reinforcement Learning",
        "aliases": [
          "RL"
        ],
        "category": "broad_technical",
        "rationale": "Reinforcement Learning is a fundamental technique used in the proposed RIFT strategy, linking it to broader machine learning contexts.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.82
      },
      {
        "surface": "Traffic Simulation",
        "canonical": "Traffic Simulation",
        "aliases": [
          "Traffic Modeling"
        ],
        "category": "unique_technical",
        "rationale": "Traffic Simulation is central to the paper's focus, providing a unique context for applying RL techniques.",
        "novelty_score": 0.65,
        "connectivity_score": 0.75,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Imitation Learning",
        "canonical": "Imitation Learning",
        "aliases": [
          "IL"
        ],
        "category": "specific_connectable",
        "rationale": "Imitation Learning is used in the pre-training phase, crucial for understanding the dual-stage simulation framework.",
        "novelty_score": 0.55,
        "connectivity_score": 0.8,
        "specificity_score": 0.72,
        "link_intent_score": 0.77
      },
      {
        "surface": "Covariate Shift",
        "canonical": "Covariate Shift",
        "aliases": [
          "Distribution Shift"
        ],
        "category": "specific_connectable",
        "rationale": "Addressing Covariate Shift is a key challenge in the paper, linking to broader discussions on model reliability.",
        "novelty_score": 0.6,
        "connectivity_score": 0.78,
        "specificity_score": 0.76,
        "link_intent_score": 0.75
      },
      {
        "surface": "Physics-based Simulator",
        "canonical": "Physics-based Simulation",
        "aliases": [
          "Physics Simulation"
        ],
        "category": "unique_technical",
        "rationale": "Physics-based Simulation is essential for achieving controllability, a core aspect of the paper's methodology.",
        "novelty_score": 0.68,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.74
      }
    ],
    "ban_list_suggestions": [
      "realism",
      "controllability",
      "closed-loop"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Reinforcement Learning",
      "resolved_canonical": "Reinforcement Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Traffic Simulation",
      "resolved_canonical": "Traffic Simulation",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.75,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Imitation Learning",
      "resolved_canonical": "Imitation Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.8,
        "specificity": 0.72,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Covariate Shift",
      "resolved_canonical": "Covariate Shift",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.78,
        "specificity": 0.76,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Physics-based Simulator",
      "resolved_canonical": "Physics-based Simulation",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.74
      }
    }
  ]
}
-->

# RIFT: Group-Relative RL Fine-Tuning for Realistic and Controllable Traffic Simulation

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2505.03344.pdf)
**Category**: cs.LG
**Published**: 2025-09-23
**ArXiv ID**: [2505.03344](https://arxiv.org/abs/2505.03344)

## 🔗 유사한 논문
- [[2025-09-22/Implicit Kinodynamic Motion Retargeting for Human-to-humanoid Imitation Learning_20250922|Implicit Kinodynamic Motion Retargeting for Human-to-humanoid Imitation Learning]] (84.2% similar)
- [[2025-09-19/Resolve Highway Conflict in Multi-Autonomous Vehicle Controls with Local State Attention_20250919|Resolve Highway Conflict in Multi-Autonomous Vehicle Controls with Local State Attention]] (83.5% similar)
- [[2025-09-19/Rethinking Reference Trajectories in Agile Drone Racing_ A Unified Reference-Free Model-Based Controller via MPPI_20250919|Rethinking Reference Trajectories in Agile Drone Racing: A Unified Reference-Free Model-Based Controller via MPPI]] (83.5% similar)
- [[2025-09-22/Hierarchical Reinforcement Learning with Low-Level MPC for Multi-Agent Control_20250922|Hierarchical Reinforcement Learning with Low-Level MPC for Multi-Agent Control]] (83.0% similar)
- [[2025-09-19/Continuous-Time Value Iteration for Multi-Agent Reinforcement Learning_20250919|Continuous-Time Value Iteration for Multi-Agent Reinforcement Learning]] (82.7% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Reinforcement Learning|Reinforcement Learning]]
**🔗 Specific Connectable**: [[keywords/Imitation Learning|Imitation Learning]], [[keywords/Covariate Shift|Covariate Shift]]
**⚡ Unique Technical**: [[keywords/Traffic Simulation|Traffic Simulation]], [[keywords/Physics-based Simulation|Physics-based Simulation]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2505.03344v3 Announce Type: replace-cross 
Abstract: Achieving both realism and controllability in closed-loop traffic simulation remains a key challenge in autonomous driving. Dataset-based methods reproduce realistic trajectories but suffer from covariate shift in closed-loop deployment, compounded by simplified dynamics models that further reduce reliability. Conversely, physics-based simulation methods enhance reliable and controllable closed-loop interactions but often lack expert demonstrations, compromising realism. To address these challenges, we introduce a dual-stage AV-centric simulation framework that conducts imitation learning pre-training in a data-driven simulator to capture trajectory-level realism and route-level controllability, followed by reinforcement learning fine-tuning in a physics-based simulator to enhance style-level controllability and mitigate covariate shift. In the fine-tuning stage, we propose RIFT, a novel group-relative RL fine-tuning strategy that evaluates all candidate modalities through group-relative formulation and employs a surrogate objective for stable optimization, enhancing style-level controllability and mitigating covariate shift while preserving the trajectory-level realism and route-level controllability inherited from IL pre-training. Extensive experiments demonstrate that RIFT improves realism and controllability in traffic simulation while simultaneously exposing the limitations of modern AV systems in closed-loop evaluation. Project Page: https://currychen77.github.io/RIFT/

## 📝 요약

이 논문은 자율주행 차량의 폐쇄형 트래픽 시뮬레이션에서 현실성과 제어 가능성을 동시에 달성하기 위한 새로운 시뮬레이션 프레임워크를 제안합니다. 데이터 기반 방법은 현실적인 궤적을 재현하지만, 폐쇄형 배치에서 공변량 이동 문제와 단순화된 동역학 모델로 인해 신뢰성이 떨어집니다. 반면, 물리 기반 시뮬레이션은 신뢰성과 제어 가능성을 높이지만 현실성이 부족합니다. 이를 해결하기 위해, 본 연구는 모방 학습을 통해 궤적의 현실성과 경로 제어 가능성을 확보한 후, 물리 기반 시뮬레이터에서 강화 학습으로 세부 제어 가능성을 향상시키고 공변량 이동을 완화하는 이중 단계 시뮬레이션을 제안합니다. 특히, RIFT라는 새로운 그룹 상대적 강화 학습 전략을 통해 스타일 수준의 제어 가능성을 높이고 공변량 이동을 완화하면서도 초기 모방 학습의 장점을 유지합니다. 실험 결과, RIFT는 트래픽 시뮬레이션의 현실성과 제어 가능성을 개선하며, 현대 자율주행 시스템의 한계를 드러냅니다.

## 🎯 주요 포인트

- 1. 자율주행에서 현실성과 제어 가능성을 동시에 달성하는 것이 여전히 주요 과제입니다.
- 2. 데이터 기반 방법은 현실적인 궤적을 재현하지만, 폐쇄 루프 배치에서 공변량 이동 문제와 단순화된 동적 모델로 인해 신뢰성이 감소합니다.
- 3. 물리 기반 시뮬레이션 방법은 신뢰성과 제어 가능성을 향상시키지만, 전문가 시연이 부족하여 현실성이 떨어집니다.
- 4. 제안된 이중 단계 AV 중심 시뮬레이션 프레임워크는 데이터 기반 시뮬레이터에서 모방 학습을 통한 궤적 및 경로 수준의 현실성과 제어 가능성을 확보하고, 물리 기반 시뮬레이터에서 강화 학습을 통해 스타일 수준의 제어 가능성을 향상시킵니다.
- 5. RIFT는 그룹 상대적 RL 미세 조정 전략을 통해 스타일 수준의 제어 가능성을 향상시키고, 공변량 이동을 완화하며, 모방 학습 사전 훈련에서 계승된 궤적 및 경로 수준의 현실성과 제어 가능성을 유지합니다.


---

*Generated on 2025-09-24 03:03:43*