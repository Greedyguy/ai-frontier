---
keywords:
  - Transformer Encoder Tree
  - Multilingual Translation
  - Non-autoregressive Encoder
  - Connectionist Temporal Classification
  - Speech Translation
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.17930
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T00:12:43.153161",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Transformer Encoder Tree",
    "Multilingual Translation",
    "Non-autoregressive Encoder",
    "Connectionist Temporal Classification",
    "Speech Translation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Transformer Encoder Tree": 0.8,
    "Multilingual Translation": 0.75,
    "Non-autoregressive Encoder": 0.82,
    "Connectionist Temporal Classification": 0.78,
    "Speech Translation": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Transformer Encoder Tree",
        "canonical": "Transformer Encoder Tree",
        "aliases": [
          "TET"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel hierarchical structure that enhances multilingual translation efficiency.",
        "novelty_score": 0.85,
        "connectivity_score": 0.7,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "Multilingual Translation",
        "canonical": "Multilingual Translation",
        "aliases": [],
        "category": "broad_technical",
        "rationale": "Central to the paper's focus on improving translation across multiple languages.",
        "novelty_score": 0.4,
        "connectivity_score": 0.85,
        "specificity_score": 0.6,
        "link_intent_score": 0.75
      },
      {
        "surface": "Non-autoregressive Encoder",
        "canonical": "Non-autoregressive Encoder",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Highlights a key method for improving translation speed and efficiency.",
        "novelty_score": 0.65,
        "connectivity_score": 0.78,
        "specificity_score": 0.8,
        "link_intent_score": 0.82
      },
      {
        "surface": "Connectionist Temporal Classification",
        "canonical": "Connectionist Temporal Classification",
        "aliases": [
          "CTC"
        ],
        "category": "specific_connectable",
        "rationale": "A critical technique used in training the model for speech translation.",
        "novelty_score": 0.5,
        "connectivity_score": 0.8,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Speech Translation",
        "canonical": "Speech Translation",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "A significant application area for the proposed model, enhancing multilingual capabilities.",
        "novelty_score": 0.55,
        "connectivity_score": 0.82,
        "specificity_score": 0.75,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "computational redundancy",
      "intermediate representations"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Transformer Encoder Tree",
      "resolved_canonical": "Transformer Encoder Tree",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.7,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Multilingual Translation",
      "resolved_canonical": "Multilingual Translation",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.85,
        "specificity": 0.6,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Non-autoregressive Encoder",
      "resolved_canonical": "Non-autoregressive Encoder",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.78,
        "specificity": 0.8,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Connectionist Temporal Classification",
      "resolved_canonical": "Connectionist Temporal Classification",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.8,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Speech Translation",
      "resolved_canonical": "Speech Translation",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.82,
        "specificity": 0.75,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Transformer-Encoder Trees for Efficient Multilingual Machine Translation and Speech Translation

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17930.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.17930](https://arxiv.org/abs/2509.17930)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/Audio-Based Crowd-Sourced Evaluation of Machine Translation Quality_20250918|Audio-Based Crowd-Sourced Evaluation of Machine Translation Quality]] (81.3% similar)
- [[2025-09-22/Frustratingly Easy Data Augmentation for Low-Resource ASR_20250922|Frustratingly Easy Data Augmentation for Low-Resource ASR]] (80.7% similar)
- [[2025-09-19/Translate, then Detect_ Leveraging Machine Translation for Cross-Lingual Toxicity Classification_20250919|Translate, then Detect: Leveraging Machine Translation for Cross-Lingual Toxicity Classification]] (80.7% similar)
- [[2025-09-22/Translationese-index_ Using Likelihood Ratios for Graded and Generalizable Measurement of Translationese_20250922|Translationese-index: Using Likelihood Ratios for Graded and Generalizable Measurement of Translationese]] (80.6% similar)
- [[2025-09-23/Scaling, Simplification, and Adaptation_ Lessons from Pretraining on Machine-Translated Text_20250923|Scaling, Simplification, and Adaptation: Lessons from Pretraining on Machine-Translated Text]] (80.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Multilingual Translation|Multilingual Translation]]
**ğŸ”— Specific Connectable**: [[keywords/Non-autoregressive Encoder|Non-autoregressive Encoder]], [[keywords/Connectionist Temporal Classification|Connectionist Temporal Classification]], [[keywords/Speech Translation|Speech Translation]]
**âš¡ Unique Technical**: [[keywords/Transformer Encoder Tree|Transformer Encoder Tree]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17930v1 Announce Type: cross 
Abstract: Multilingual translation faces challenges of computational redundancy and limited accuracy for low-resource languages, especially in speech translation. To address this, we propose a novel hierarchical Transformer Encoder Tree (TET) combined with non-autoregressive encoder-only models trained with Connectionist Temporal Classification for multilingual translation. By sharing intermediate representations among linguistically similar target languages, TET can improve accuracy on low-resource languages, reduce computational redundancy, and allow generating all target languages in a single forward pass, thus eliminating sequential bottlenecks and improving parallelism. For speech translation, combining TET with a non-autoregressive speech recognition backbone (wav2vec2) shows promising results in terms of translation quality compared to autoregressive systems while being 7-14 times faster.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë‹¤êµ­ì–´ ë²ˆì—­ì—ì„œ ì €ìì› ì–¸ì–´ì˜ ë²ˆì—­ ì •í™•ë„ì™€ ê³„ì‚° ì¤‘ë³µ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ìƒˆë¡œìš´ ê³„ì¸µì  Transformer Encoder Tree (TET)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. TETëŠ” ìœ ì‚¬í•œ ì–¸ì–´ ê°„ì˜ ì¤‘ê°„ í‘œí˜„ì„ ê³µìœ í•˜ì—¬ ì €ìì› ì–¸ì–´ì˜ ë²ˆì—­ ì •í™•ë„ë¥¼ í–¥ìƒì‹œí‚¤ê³ , ê³„ì‚° ì¤‘ë³µì„ ì¤„ì´ë©°, ëª¨ë“  ëŒ€ìƒ ì–¸ì–´ë¥¼ í•œ ë²ˆì˜ ì²˜ë¦¬ë¡œ ìƒì„±í•  ìˆ˜ ìˆì–´ ë³‘ë ¬ì„±ì„ ê°œì„ í•©ë‹ˆë‹¤. ë˜í•œ, ë¹„ìê¸°íšŒê·€ì  ìŒì„± ì¸ì‹ ëª¨ë¸(wav2vec2)ê³¼ ê²°í•©í•˜ì—¬ ìŒì„± ë²ˆì—­ì—ì„œ ê¸°ì¡´ì˜ ìê¸°íšŒê·€ ì‹œìŠ¤í…œë³´ë‹¤ 7-14ë°° ë¹ ë¥´ë©´ì„œë„ ë†’ì€ ë²ˆì—­ í’ˆì§ˆì„ ë³´ì…ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë‹¤êµ­ì–´ ë²ˆì—­ì—ì„œ ì €ìë“¤ì€ ê³„ì¸µì  Transformer Encoder Tree (TET)ë¥¼ ì œì•ˆí•˜ì—¬ ì €ìì› ì–¸ì–´ì˜ ë²ˆì—­ ì •í™•ë„ë¥¼ ê°œì„ í•˜ê³  ê³„ì‚° ì¤‘ë³µì„±ì„ ì¤„ì…ë‹ˆë‹¤.
- 2. TETëŠ” ì–¸ì–´ì ìœ¼ë¡œ ìœ ì‚¬í•œ ëŒ€ìƒ ì–¸ì–´ ê°„ì˜ ì¤‘ê°„ í‘œí˜„ì„ ê³µìœ í•˜ì—¬ ì €ìì› ì–¸ì–´ì˜ ë²ˆì—­ ì •í™•ë„ë¥¼ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
- 3. TETëŠ” ëª¨ë“  ëŒ€ìƒ ì–¸ì–´ë¥¼ í•œ ë²ˆì˜ ì „ë°© íŒ¨ìŠ¤ë¡œ ìƒì„±í•  ìˆ˜ ìˆì–´ ìˆœì°¨ì  ë³‘ëª© í˜„ìƒì„ ì œê±°í•˜ê³  ë³‘ë ¬ì„±ì„ ê°œì„ í•©ë‹ˆë‹¤.
- 4. ë¹„ìê¸°íšŒê·€ì  ìŒì„± ì¸ì‹ ë°±ë³¸(wav2vec2)ê³¼ ê²°í•©ëœ TETëŠ” ë²ˆì—­ í’ˆì§ˆì—ì„œ ìê¸°íšŒê·€ ì‹œìŠ¤í…œì— ë¹„í•´ ìœ ë§í•œ ê²°ê³¼ë¥¼ ë³´ì´ë©°, ì†ë„ëŠ” 7-14ë°° ë¹ ë¦…ë‹ˆë‹¤.


---

*Generated on 2025-09-24 00:12:43*