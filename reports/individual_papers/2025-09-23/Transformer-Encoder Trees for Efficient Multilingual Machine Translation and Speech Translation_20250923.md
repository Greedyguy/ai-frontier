---
keywords:
  - Transformer Encoder Tree
  - Multilingual Translation
  - Non-autoregressive Encoder
  - Connectionist Temporal Classification
  - Speech Translation
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.17930
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T00:12:43.153161",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Transformer Encoder Tree",
    "Multilingual Translation",
    "Non-autoregressive Encoder",
    "Connectionist Temporal Classification",
    "Speech Translation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Transformer Encoder Tree": 0.8,
    "Multilingual Translation": 0.75,
    "Non-autoregressive Encoder": 0.82,
    "Connectionist Temporal Classification": 0.78,
    "Speech Translation": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Transformer Encoder Tree",
        "canonical": "Transformer Encoder Tree",
        "aliases": [
          "TET"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel hierarchical structure that enhances multilingual translation efficiency.",
        "novelty_score": 0.85,
        "connectivity_score": 0.7,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "Multilingual Translation",
        "canonical": "Multilingual Translation",
        "aliases": [],
        "category": "broad_technical",
        "rationale": "Central to the paper's focus on improving translation across multiple languages.",
        "novelty_score": 0.4,
        "connectivity_score": 0.85,
        "specificity_score": 0.6,
        "link_intent_score": 0.75
      },
      {
        "surface": "Non-autoregressive Encoder",
        "canonical": "Non-autoregressive Encoder",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Highlights a key method for improving translation speed and efficiency.",
        "novelty_score": 0.65,
        "connectivity_score": 0.78,
        "specificity_score": 0.8,
        "link_intent_score": 0.82
      },
      {
        "surface": "Connectionist Temporal Classification",
        "canonical": "Connectionist Temporal Classification",
        "aliases": [
          "CTC"
        ],
        "category": "specific_connectable",
        "rationale": "A critical technique used in training the model for speech translation.",
        "novelty_score": 0.5,
        "connectivity_score": 0.8,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Speech Translation",
        "canonical": "Speech Translation",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "A significant application area for the proposed model, enhancing multilingual capabilities.",
        "novelty_score": 0.55,
        "connectivity_score": 0.82,
        "specificity_score": 0.75,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "computational redundancy",
      "intermediate representations"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Transformer Encoder Tree",
      "resolved_canonical": "Transformer Encoder Tree",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.7,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Multilingual Translation",
      "resolved_canonical": "Multilingual Translation",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.85,
        "specificity": 0.6,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Non-autoregressive Encoder",
      "resolved_canonical": "Non-autoregressive Encoder",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.78,
        "specificity": 0.8,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Connectionist Temporal Classification",
      "resolved_canonical": "Connectionist Temporal Classification",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.8,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Speech Translation",
      "resolved_canonical": "Speech Translation",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.82,
        "specificity": 0.75,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Transformer-Encoder Trees for Efficient Multilingual Machine Translation and Speech Translation

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17930.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.17930](https://arxiv.org/abs/2509.17930)

## 🔗 유사한 논문
- [[2025-09-18/Audio-Based Crowd-Sourced Evaluation of Machine Translation Quality_20250918|Audio-Based Crowd-Sourced Evaluation of Machine Translation Quality]] (81.3% similar)
- [[2025-09-22/Frustratingly Easy Data Augmentation for Low-Resource ASR_20250922|Frustratingly Easy Data Augmentation for Low-Resource ASR]] (80.7% similar)
- [[2025-09-19/Translate, then Detect_ Leveraging Machine Translation for Cross-Lingual Toxicity Classification_20250919|Translate, then Detect: Leveraging Machine Translation for Cross-Lingual Toxicity Classification]] (80.7% similar)
- [[2025-09-22/Translationese-index_ Using Likelihood Ratios for Graded and Generalizable Measurement of Translationese_20250922|Translationese-index: Using Likelihood Ratios for Graded and Generalizable Measurement of Translationese]] (80.6% similar)
- [[2025-09-23/Scaling, Simplification, and Adaptation_ Lessons from Pretraining on Machine-Translated Text_20250923|Scaling, Simplification, and Adaptation: Lessons from Pretraining on Machine-Translated Text]] (80.1% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Multilingual Translation|Multilingual Translation]]
**🔗 Specific Connectable**: [[keywords/Non-autoregressive Encoder|Non-autoregressive Encoder]], [[keywords/Connectionist Temporal Classification|Connectionist Temporal Classification]], [[keywords/Speech Translation|Speech Translation]]
**⚡ Unique Technical**: [[keywords/Transformer Encoder Tree|Transformer Encoder Tree]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.17930v1 Announce Type: cross 
Abstract: Multilingual translation faces challenges of computational redundancy and limited accuracy for low-resource languages, especially in speech translation. To address this, we propose a novel hierarchical Transformer Encoder Tree (TET) combined with non-autoregressive encoder-only models trained with Connectionist Temporal Classification for multilingual translation. By sharing intermediate representations among linguistically similar target languages, TET can improve accuracy on low-resource languages, reduce computational redundancy, and allow generating all target languages in a single forward pass, thus eliminating sequential bottlenecks and improving parallelism. For speech translation, combining TET with a non-autoregressive speech recognition backbone (wav2vec2) shows promising results in terms of translation quality compared to autoregressive systems while being 7-14 times faster.

## 📝 요약

이 논문은 다국어 번역에서 저자원 언어의 번역 정확도와 계산 중복 문제를 해결하기 위해 새로운 계층적 Transformer Encoder Tree (TET)를 제안합니다. TET는 유사한 언어 간의 중간 표현을 공유하여 저자원 언어의 번역 정확도를 향상시키고, 계산 중복을 줄이며, 모든 대상 언어를 한 번의 처리로 생성할 수 있어 병렬성을 개선합니다. 또한, 비자기회귀적 음성 인식 모델(wav2vec2)과 결합하여 음성 번역에서 기존의 자기회귀 시스템보다 7-14배 빠르면서도 높은 번역 품질을 보입니다.

## 🎯 주요 포인트

- 1. 다국어 번역에서 저자들은 계층적 Transformer Encoder Tree (TET)를 제안하여 저자원 언어의 번역 정확도를 개선하고 계산 중복성을 줄입니다.
- 2. TET는 언어적으로 유사한 대상 언어 간의 중간 표현을 공유하여 저자원 언어의 번역 정확도를 향상시킵니다.
- 3. TET는 모든 대상 언어를 한 번의 전방 패스로 생성할 수 있어 순차적 병목 현상을 제거하고 병렬성을 개선합니다.
- 4. 비자기회귀적 음성 인식 백본(wav2vec2)과 결합된 TET는 번역 품질에서 자기회귀 시스템에 비해 유망한 결과를 보이며, 속도는 7-14배 빠릅니다.


---

*Generated on 2025-09-24 00:12:43*