---
keywords:
  - Chain-of-Thought Reasoning
  - Large Language Model
  - Shapley Value
  - Few-Shot Learning
  - Mathematical Expression Attribution
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.16561
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T22:50:12.518911",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Chain-of-Thought Reasoning",
    "Large Language Model",
    "Shapley Value",
    "Few-Shot Learning",
    "Mathematical Expression Attribution"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Chain-of-Thought Reasoning": 0.8,
    "Large Language Model": 0.7,
    "Shapley Value": 0.78,
    "Few-Shot Learning": 0.79,
    "Mathematical Expression Attribution": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Chain-of-Thought",
        "canonical": "Chain-of-Thought Reasoning",
        "aliases": [
          "CoT"
        ],
        "category": "specific_connectable",
        "rationale": "Chain-of-Thought reasoning is a key concept in enhancing the reasoning capabilities of LLMs, making it a strong link for related studies.",
        "novelty_score": 0.65,
        "connectivity_score": 0.85,
        "specificity_score": 0.78,
        "link_intent_score": 0.8
      },
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are central to the paper's focus, providing a broad technical foundation for linking.",
        "novelty_score": 0.4,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.7
      },
      {
        "surface": "Shapley Value",
        "canonical": "Shapley Value",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "The Shapley Value is a unique technical concept used for mathematical expression attribution in the paper.",
        "novelty_score": 0.7,
        "connectivity_score": 0.75,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Few-Shot CoT Reasoning",
        "canonical": "Few-Shot Learning",
        "aliases": [
          "Few-Shot CoT"
        ],
        "category": "specific_connectable",
        "rationale": "Few-Shot Learning is crucial for understanding the paper's methodology in CoT reasoning.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.82,
        "link_intent_score": 0.79
      },
      {
        "surface": "Mathematical Expression Attribution",
        "canonical": "Mathematical Expression Attribution",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This is a unique technical concept introduced in the paper, essential for understanding its methodology.",
        "novelty_score": 0.68,
        "connectivity_score": 0.7,
        "specificity_score": 0.88,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "methodology",
      "evaluation metric",
      "model performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Chain-of-Thought",
      "resolved_canonical": "Chain-of-Thought Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.85,
        "specificity": 0.78,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Shapley Value",
      "resolved_canonical": "Shapley Value",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.75,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Few-Shot CoT Reasoning",
      "resolved_canonical": "Few-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.82,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Mathematical Expression Attribution",
      "resolved_canonical": "Mathematical Expression Attribution",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.7,
        "specificity": 0.88,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# SalaMAnder: Shapley-based Mathematical Expression Attribution and Metric for Chain-of-Thought Reasoning

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16561.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.16561](https://arxiv.org/abs/2509.16561)

## 🔗 유사한 논문
- [[2025-09-17/Reasoning Efficiently Through Adaptive Chain-of-Thought Compression_ A Self-Optimizing Framework_20250917|Reasoning Efficiently Through Adaptive Chain-of-Thought Compression: A Self-Optimizing Framework]] (83.9% similar)
- [[2025-09-19/ASCoT_ An Adaptive Self-Correction Chain-of-Thought Method for Late-Stage Fragility in LLMs_20250919|ASCoT: An Adaptive Self-Correction Chain-of-Thought Method for Late-Stage Fragility in LLMs]] (83.8% similar)
- [[2025-09-18/Uni-cot_ Towards Unified Chain-of-Thought Reasoning Across Text and Vision_20250918|Uni-cot: Towards Unified Chain-of-Thought Reasoning Across Text and Vision]] (82.6% similar)
- [[2025-09-18/Early Stopping Chain-of-thoughts in Large Language Models_20250918|Early Stopping Chain-of-thoughts in Large Language Models]] (82.4% similar)
- [[2025-09-22/Cache-of-Thought_ Master-Apprentice Framework for Cost-Effective Vision Language Model Reasoning_20250922|Cache-of-Thought: Master-Apprentice Framework for Cost-Effective Vision Language Model Reasoning]] (82.0% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Chain-of-Thought Reasoning|Chain-of-Thought Reasoning]], [[keywords/Few-Shot Learning|Few-Shot Learning]]
**⚡ Unique Technical**: [[keywords/Shapley Value|Shapley Value]], [[keywords/Mathematical Expression Attribution|Mathematical Expression Attribution]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.16561v1 Announce Type: new 
Abstract: Chain-of-Thought (CoT) prompting enhances the math reasoning capability of large language models (LLMs) to a large margin. However, the mechanism underlying such improvements remains unexplored. In this paper, we present \textbf{SalaMAnder} (\textbf{S}h\textbf{a}p\textbf{l}ey-b\textbf{a}sed \textbf{M}athematical Expression \textbf{A}ttribution a\textbf{nd} M\textbf{e}t\textbf{r}ic), a theoretically grounded methodology as well as a mathematically rigorous evaluation metric for quantifying component-level contributions in few-shot CoT reasoning. Concretely, we leverage the Shapley value for mathematical expression attribution and develop an efficient stratified sampling algorithm that significantly reduces the computational complexity. Besides, we develop the \textbf{CoSP} (\textbf{C}ardinality \textbf{o}f \textbf{S}hapley \textbf{P}ositives) metric through covariance analysis. Comprehensive validation across popular LLM models and diverse mathematical benchmarks demonstrates that the CoSP metric within our SalaMAnder framework exhibits a robust monotonic correlation with model performance, not only providing theoretical explanations for the empirical success of existing few-shot CoT but also establishing mathematically rigorous principles for prompt construction optimization. Furthermore, we verify the reliability of the explanation, based on which we unify the insights of previous work.

## 📝 요약

이 논문은 대형 언어 모델(LLM)의 수학적 추론 능력을 향상시키는 Chain-of-Thought(CoT) 프롬프트의 개선 메커니즘을 탐구합니다. 저자들은 \textbf{SalaMAnder}라는 이론적 방법론과 수학적으로 엄밀한 평가 지표를 제시하여, 소수의 예시를 통한 CoT 추론에서 구성 요소별 기여도를 정량화합니다. Shapley 값을 활용하여 수학적 표현의 기여도를 평가하고, 효율적인 층화 샘플링 알고리즘을 개발해 계산 복잡성을 줄였습니다. 또한, \textbf{CoSP}라는 지표를 통해 모델 성능과의 상관관계를 분석했습니다. 다양한 LLM 모델과 수학적 벤치마크를 통해 검증한 결과, CoSP 지표는 모델 성능과 강한 단조 상관관계를 보여주며, 기존 CoT의 성공에 대한 이론적 설명을 제공하고 프롬프트 최적화의 원칙을 확립합니다. 이를 통해 이전 연구의 통찰을 통합할 수 있음을 확인했습니다.

## 🎯 주요 포인트

- 1. Chain-of-Thought (CoT) 프롬프트는 대형 언어 모델의 수학적 추론 능력을 크게 향상시킵니다.
- 2. SalaMAnder는 수학적 표현 귀속을 위한 Shapley 값을 활용하여 컴포넌트 수준의 기여도를 정량화하는 방법론입니다.
- 3. CoSP(CSP) 메트릭은 공분산 분석을 통해 개발되었으며, 모델 성능과 강력한 단조 상관관계를 보입니다.
- 4. SalaMAnder 프레임워크는 기존의 few-shot CoT의 성공에 대한 이론적 설명을 제공하고 프롬프트 최적화의 수학적 원칙을 확립합니다.
- 5. 연구는 다양한 수학적 벤치마크와 LLM 모델을 통해 SalaMAnder의 신뢰성을 검증하고 이전 연구의 통찰을 통합합니다.


---

*Generated on 2025-09-23 22:50:12*