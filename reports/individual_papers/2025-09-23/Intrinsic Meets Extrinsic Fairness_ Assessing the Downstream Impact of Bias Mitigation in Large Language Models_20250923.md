---
keywords:
  - Large Language Model
  - Bias Mitigation
  - Concept Unlearning
  - Counterfactual Data Augmentation
  - Demographic Parity
category: cs.LG
publish_date: 2025-09-23
arxiv_id: 2509.16462
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T02:09:09.226837",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Bias Mitigation",
    "Concept Unlearning",
    "Counterfactual Data Augmentation",
    "Demographic Parity"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Bias Mitigation": 0.78,
    "Concept Unlearning": 0.8,
    "Counterfactual Data Augmentation": 0.82,
    "Demographic Parity": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Large Language Model"
        ],
        "category": "broad_technical",
        "rationale": "Central to the study, linking to numerous related concepts in NLP and bias mitigation.",
        "novelty_score": 0.2,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "bias mitigation",
        "canonical": "Bias Mitigation",
        "aliases": [
          "bias reduction",
          "bias correction"
        ],
        "category": "unique_technical",
        "rationale": "Key concept in the paper, focusing on reducing biases in language models.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "concept unlearning",
        "canonical": "Concept Unlearning",
        "aliases": [
          "unlearning bias",
          "bias unlearning"
        ],
        "category": "unique_technical",
        "rationale": "A novel approach to intrinsic bias mitigation discussed in the paper.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "counterfactual data augmentation",
        "canonical": "Counterfactual Data Augmentation",
        "aliases": [
          "CDA",
          "counterfactual augmentation"
        ],
        "category": "specific_connectable",
        "rationale": "A method for extrinsic bias mitigation with potential connections to data manipulation techniques.",
        "novelty_score": 0.7,
        "connectivity_score": 0.78,
        "specificity_score": 0.82,
        "link_intent_score": 0.82
      },
      {
        "surface": "demographic parity",
        "canonical": "Demographic Parity",
        "aliases": [
          "fairness metric",
          "demographic fairness"
        ],
        "category": "specific_connectable",
        "rationale": "A specific fairness metric used to evaluate bias mitigation effectiveness.",
        "novelty_score": 0.6,
        "connectivity_score": 0.75,
        "specificity_score": 0.78,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "socio-economic biases",
      "financial classification tasks",
      "accuracy"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.2,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "bias mitigation",
      "resolved_canonical": "Bias Mitigation",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "concept unlearning",
      "resolved_canonical": "Concept Unlearning",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "counterfactual data augmentation",
      "resolved_canonical": "Counterfactual Data Augmentation",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.78,
        "specificity": 0.82,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "demographic parity",
      "resolved_canonical": "Demographic Parity",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.75,
        "specificity": 0.78,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Intrinsic Meets Extrinsic Fairness: Assessing the Downstream Impact of Bias Mitigation in Large Language Models

## π“‹ λ©”νƒ€λ°μ΄ν„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16462.pdf)
**Category**: cs.LG
**Published**: 2025-09-23
**ArXiv ID**: [2509.16462](https://arxiv.org/abs/2509.16462)

## π”— μ μ‚¬ν• λ…Όλ¬Έ
- [[2025-09-17/Simulating a Bias Mitigation Scenario in Large Language Models_20250917|Simulating a Bias Mitigation Scenario in Large Language Models]] (89.6% similar)
- [[2025-09-23/Steering Towards Fairness_ Mitigating Political Bias in LLMs_20250923|Steering Towards Fairness: Mitigating Political Bias in LLMs]] (88.3% similar)
- [[2025-09-23/Auto-Search and Refinement_ An Automated Framework for Gender Bias Mitigation in Large Language Models_20250923|Auto-Search and Refinement: An Automated Framework for Gender Bias Mitigation in Large Language Models]] (87.6% similar)
- [[2025-09-23/Justice in Judgment_ Unveiling (Hidden) Bias in LLM-assisted Peer Reviews_20250923|Justice in Judgment: Unveiling (Hidden) Bias in LLM-assisted Peer Reviews]] (87.2% similar)
- [[2025-09-22/Bias Beware_ The Impact of Cognitive Biases on LLM-Driven Product Recommendations_20250922|Bias Beware: The Impact of Cognitive Biases on LLM-Driven Product Recommendations]] (87.0% similar)

## π·οΈ μΉ΄ν…κ³ λ¦¬ν™”λ ν‚¤μ›λ“
**π§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**π”— Specific Connectable**: [[keywords/Counterfactual Data Augmentation|Counterfactual Data Augmentation]], [[keywords/Demographic Parity|Demographic Parity]]
**β΅ Unique Technical**: [[keywords/Bias Mitigation|Bias Mitigation]], [[keywords/Concept Unlearning|Concept Unlearning]]

## π“‹ μ €μ μ •λ³΄

**Authors:** 

## π“„ Abstract (μ›λ¬Έ)

arXiv:2509.16462v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) exhibit socio-economic biases that can propagate into downstream tasks. While prior studies have questioned whether intrinsic bias in LLMs affects fairness at the downstream task level, this work empirically investigates the connection. We present a unified evaluation framework to compare intrinsic bias mitigation via concept unlearning with extrinsic bias mitigation via counterfactual data augmentation (CDA). We examine this relationship through real-world financial classification tasks, including salary prediction, employment status, and creditworthiness assessment. Using three open-source LLMs, we evaluate models both as frozen embedding extractors and as fine-tuned classifiers. Our results show that intrinsic bias mitigation through unlearning reduces intrinsic gender bias by up to 94.9%, while also improving downstream task fairness metrics, such as demographic parity by up to 82%, without compromising accuracy. Our framework offers practical guidance on where mitigation efforts can be most effective and highlights the importance of applying early-stage mitigation before downstream deployment.

## π“ μ”μ•½

μ΄ λ…Όλ¬Έμ€ λ€ν• μ–Έμ–΄ λ¨λΈ(LLM)μ λ‚΄μ¬λ νΈν–¥μ΄ ν›„μ† μ‘μ—…μ— λ―ΈμΉλ” μν–¥μ„ μ΅°μ‚¬ν•©λ‹λ‹¤. μ €μλ“¤μ€ κ°λ… ν•™μµ μ κ±°λ¥Ό ν†µν• λ‚΄μ¬μ  νΈν–¥ μ™„ν™”μ™€ λ°μ‚¬μ‹¤μ  λ°μ΄ν„° μ¦κ°•(CDA)μ„ ν†µν• μ™Έμ¬μ  νΈν–¥ μ™„ν™”λ¥Ό λΉ„κµν•λ” ν‰κ°€ ν”„λ μ„μ›ν¬λ¥Ό μ μ‹ν•©λ‹λ‹¤. μ‹¤μ  κΈμµ λ¶„λ¥ μ‘μ—…μ—μ„ μ„Έ κ°€μ§€ μ¤ν” μ†μ¤ LLMμ„ μ‚¬μ©ν•μ—¬ λ¨λΈμ„ ν‰κ°€ν• κ²°κ³Ό, λ‚΄μ¬μ  νΈν–¥ μ™„ν™”κ°€ μ„±λ³„ νΈν–¥μ„ μµλ€ 94.9% μ¤„μ΄κ³ , μΈκµ¬ ν†µκ³„ν•™μ  κ· ν•κ³Ό κ°™μ€ κ³µμ •μ„± μ§€ν‘λ¥Ό μµλ€ 82% κ°μ„ ν•λ©΄μ„λ„ μ •ν™•μ„±μ„ μ μ§€ν•¨μ„ λ°κ²¬ν–μµλ‹λ‹¤. μ΄ μ—°κµ¬λ” μ΄κΈ° λ‹¨κ³„μ—μ„μ νΈν–¥ μ™„ν™”μ μ¤‘μ”μ„±μ„ κ°•μ΅°ν•λ©°, μ‹¤μ§μ μΈ κ°€μ΄λ“λ¥Ό μ κ³µν•©λ‹λ‹¤.

## π― μ£Όμ” ν¬μΈνΈ

- 1. λ€ν• μ–Έμ–΄ λ¨λΈ(LLMs)μ€ μ‚¬νκ²½μ μ  νΈν–¥μ„ λ‚νƒ€λ‚΄λ©°, μ΄λ” ν›„μ† μ‘μ—…μ— μν–¥μ„ λ―ΈμΉ  μ μλ‹¤.
- 2. λ³Έ μ—°κµ¬λ” κ°λ… ν•™μµ μ κ±°λ¥Ό ν†µν• λ‚΄μ¬μ  νΈν–¥ μ™„ν™”μ™€ λ°μ‚¬μ‹¤μ  λ°μ΄ν„° μ¦κ°•(CDA)μ„ ν†µν• μ™Έμ¬μ  νΈν–¥ μ™„ν™”λ¥Ό λΉ„κµν•λ” ν†µν•© ν‰κ°€ ν”„λ μ„μ›ν¬λ¥Ό μ μ‹ν•λ‹¤.
- 3. λ‚΄μ¬μ  νΈν–¥ μ™„ν™”λ¥Ό ν†µν•΄ μ„±λ³„ νΈν–¥μ„ μµλ€ 94.9% μ¤„μ΄κ³ , μΈκµ¬ ν†µκ³„μ  κ· ν•κ³Ό κ°™μ€ κ³µμ •μ„± μ§€ν‘λ¥Ό μµλ€ 82% κ°μ„ ν•  μ μμμ„ λ°κ²¬ν–λ‹¤.
- 4. μ μ•λ ν”„λ μ„μ›ν¬λ” νΈν–¥ μ™„ν™” λ…Έλ ¥μ΄ κ°€μ¥ ν¨κ³Όμ μΈ κ³³μ— λ€ν• μ‹¤μ§μ μΈ μ§€μΉ¨μ„ μ κ³µν•λ©°, ν›„μ† μ‘μ—… λ°°ν¬ μ „μ— μ΄κΈ° λ‹¨κ³„μ—μ„μ νΈν–¥ μ™„ν™”μ μ¤‘μ”μ„±μ„ κ°•μ΅°ν•λ‹¤.


---

*Generated on 2025-09-24 02:09:09*