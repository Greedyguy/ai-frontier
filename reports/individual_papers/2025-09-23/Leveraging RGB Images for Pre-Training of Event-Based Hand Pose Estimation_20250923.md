---
keywords:
  - Event-Based Hand Pose Estimation
  - RGB Images
  - Pseudo-Event Generation
  - Motion Reversal Constraint
  - High Temporal Resolution
category: cs.CV
publish_date: 2025-09-23
arxiv_id: 2509.16949
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T04:39:34.814330",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Event-Based Hand Pose Estimation",
    "RGB Images",
    "Pseudo-Event Generation",
    "Motion Reversal Constraint",
    "High Temporal Resolution"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Event-Based Hand Pose Estimation": 0.78,
    "RGB Images": 0.7,
    "Pseudo-Event Generation": 0.75,
    "Motion Reversal Constraint": 0.77,
    "High Temporal Resolution": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Event-Based Hand Pose Estimation",
        "canonical": "Event-Based Hand Pose Estimation",
        "aliases": [
          "Event-Based Pose Estimation"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel approach specific to the paper, providing a unique angle for linking event data with hand pose estimation.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.88,
        "link_intent_score": 0.78
      },
      {
        "surface": "RGB Images",
        "canonical": "RGB Images",
        "aliases": [
          "RGB Data"
        ],
        "category": "broad_technical",
        "rationale": "RGB images are a fundamental component in the paper's methodology, linking traditional vision data with event-based techniques.",
        "novelty_score": 0.45,
        "connectivity_score": 0.72,
        "specificity_score": 0.6,
        "link_intent_score": 0.7
      },
      {
        "surface": "Pseudo-Event Generation",
        "canonical": "Pseudo-Event Generation",
        "aliases": [
          "Synthetic Event Data"
        ],
        "category": "unique_technical",
        "rationale": "This technique is central to the paper's innovation, enabling the use of RGB datasets for event-based training.",
        "novelty_score": 0.78,
        "connectivity_score": 0.68,
        "specificity_score": 0.82,
        "link_intent_score": 0.75
      },
      {
        "surface": "Motion Reversal Constraint",
        "canonical": "Motion Reversal Constraint",
        "aliases": [
          "Reversed Motion Regularization"
        ],
        "category": "unique_technical",
        "rationale": "This constraint is a novel contribution that enhances the realism of generated event data, crucial for the paper's methodology.",
        "novelty_score": 0.83,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      },
      {
        "surface": "Temporal Resolution",
        "canonical": "High Temporal Resolution",
        "aliases": [
          "Temporal Precision"
        ],
        "category": "specific_connectable",
        "rationale": "High temporal resolution is a key advantage of event data, connecting it to broader discussions in event-based sensing.",
        "novelty_score": 0.5,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Event-Based Hand Pose Estimation",
      "resolved_canonical": "Event-Based Hand Pose Estimation",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.88,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "RGB Images",
      "resolved_canonical": "RGB Images",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.72,
        "specificity": 0.6,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Pseudo-Event Generation",
      "resolved_canonical": "Pseudo-Event Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.78,
        "connectivity": 0.68,
        "specificity": 0.82,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Motion Reversal Constraint",
      "resolved_canonical": "Motion Reversal Constraint",
      "decision": "linked",
      "scores": {
        "novelty": 0.83,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Temporal Resolution",
      "resolved_canonical": "High Temporal Resolution",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# Leveraging RGB Images for Pre-Training of Event-Based Hand Pose Estimation

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16949.pdf)
**Category**: cs.CV
**Published**: 2025-09-23
**ArXiv ID**: [2509.16949](https://arxiv.org/abs/2509.16949)

## 🔗 유사한 논문
- [[2025-09-23/End-to-end RL Improves Dexterous Grasping Policies_20250923|End-to-end RL Improves Dexterous Grasping Policies]] (79.2% similar)
- [[2025-09-19/Depth AnyEvent_ A Cross-Modal Distillation Paradigm for Event-Based Monocular Depth Estimation_20250919|Depth AnyEvent: A Cross-Modal Distillation Paradigm for Event-Based Monocular Depth Estimation]] (78.9% similar)
- [[2025-09-18/RoboEye_ Enhancing 2D Robotic Object Identification with Selective 3D Geometric Keypoint Matching_20250918|RoboEye: Enhancing 2D Robotic Object Identification with Selective 3D Geometric Keypoint Matching]] (78.7% similar)
- [[2025-09-22/GP3_ A 3D Geometry-Aware Policy with Multi-View Images for Robotic Manipulation_20250922|GP3: A 3D Geometry-Aware Policy with Multi-View Images for Robotic Manipulation]] (78.2% similar)
- [[2025-09-19/Roll Your Eyes_ Gaze Redirection via Explicit 3D Eyeball Rotation_20250919|Roll Your Eyes: Gaze Redirection via Explicit 3D Eyeball Rotation]] (78.1% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/RGB Images|RGB Images]]
**🔗 Specific Connectable**: [[keywords/High Temporal Resolution|High Temporal Resolution]]
**⚡ Unique Technical**: [[keywords/Event-Based Hand Pose Estimation|Event-Based Hand Pose Estimation]], [[keywords/Pseudo-Event Generation|Pseudo-Event Generation]], [[keywords/Motion Reversal Constraint|Motion Reversal Constraint]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.16949v1 Announce Type: new 
Abstract: This paper presents RPEP, the first pre-training method for event-based 3D hand pose estimation using labeled RGB images and unpaired, unlabeled event data. Event data offer significant benefits such as high temporal resolution and low latency, but their application to hand pose estimation is still limited by the scarcity of labeled training data. To address this, we repurpose real RGB datasets to train event-based estimators. This is done by constructing pseudo-event-RGB pairs, where event data is generated and aligned with the ground-truth poses of RGB images. Unfortunately, existing pseudo-event generation techniques assume stationary objects, thus struggling to handle non-stationary, dynamically moving hands. To overcome this, RPEP introduces a novel generation strategy that decomposes hand movements into smaller, step-by-step motions. This decomposition allows our method to capture temporal changes in articulation, constructing more realistic event data for a moving hand. Additionally, RPEP imposes a motion reversal constraint, regularizing event generation using reversed motion. Extensive experiments show that our pre-trained model significantly outperforms state-of-the-art methods on real event data, achieving up to 24% improvement on EvRealHands. Moreover, it delivers strong performance with minimal labeled samples for fine-tuning, making it well-suited for practical deployment.

## 📝 요약

이 논문은 RPEP라는 이벤트 기반 3D 손 자세 추정을 위한 최초의 사전 학습 방법을 제안합니다. 이 방법은 라벨이 있는 RGB 이미지와 라벨이 없는 이벤트 데이터를 활용합니다. 이벤트 데이터는 높은 시간 해상도와 낮은 지연 시간을 제공하지만, 라벨이 있는 학습 데이터의 부족으로 인해 손 자세 추정에 제한이 있습니다. 이를 해결하기 위해, 실제 RGB 데이터셋을 활용하여 이벤트 기반 추정기를 훈련합니다. 기존의 가상 이벤트 생성 기법은 정지된 객체를 가정하여 움직이는 손을 처리하는 데 어려움이 있었으나, RPEP는 손 움직임을 작은 단계로 분해하는 새로운 생성 전략을 도입하여 이를 극복합니다. 또한, 역방향 운동 제약을 통해 이벤트 생성을 규제합니다. 실험 결과, RPEP는 최신 기법보다 최대 24% 향상된 성능을 보였으며, 최소한의 라벨링 샘플로도 강력한 성능을 발휘하여 실용적인 배포에 적합합니다.

## 🎯 주요 포인트

- 1. RPEP는 라벨이 없는 이벤트 데이터를 활용하여 RGB 이미지로부터 3D 손 자세 추정을 위한 최초의 사전 학습 방법을 제안합니다.
- 2. 기존의 가상 이벤트 생성 기술은 정지된 객체를 가정하지만, RPEP는 손 움직임을 작은 단계로 분해하여 동적인 손의 이벤트 데이터를 보다 현실적으로 생성합니다.
- 3. RPEP는 움직임 역전 제약을 도입하여 이벤트 생성 시 역방향 움직임을 활용해 정규화합니다.
- 4. RPEP는 실제 이벤트 데이터에서 최신 방법들보다 최대 24% 향상된 성능을 보이며, 소량의 라벨된 샘플로도 강력한 성능을 발휘합니다.
- 5. RPEP는 실용적인 배포에 적합한 최소한의 라벨된 샘플로도 강력한 성능을 제공합니다.


---

*Generated on 2025-09-24 04:39:34*