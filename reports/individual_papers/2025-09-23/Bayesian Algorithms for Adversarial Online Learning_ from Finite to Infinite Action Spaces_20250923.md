---
keywords:
  - Thompson Sampling
  - Bayesian Optimization
  - Gaussian Process
  - Adversarial Online Learning
category: cs.LG
publish_date: 2025-09-23
arxiv_id: 2502.14790
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T02:39:28.882619",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Thompson Sampling",
    "Bayesian Optimization",
    "Gaussian Process",
    "Adversarial Online Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Thompson Sampling": 0.78,
    "Bayesian Optimization": 0.8,
    "Gaussian Process": 0.77,
    "Adversarial Online Learning": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Thompson sampling",
        "canonical": "Thompson Sampling",
        "aliases": [
          "Thompson sampling method"
        ],
        "category": "specific_connectable",
        "rationale": "Thompson Sampling is a well-known method in online learning and connects to Bayesian decision processes.",
        "novelty_score": 0.45,
        "connectivity_score": 0.85,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Bayesian optimization",
        "canonical": "Bayesian Optimization",
        "aliases": [
          "Bayesian optimization technique"
        ],
        "category": "specific_connectable",
        "rationale": "Bayesian Optimization is a key concept in machine learning for optimizing complex functions and connects well with Gaussian processes.",
        "novelty_score": 0.5,
        "connectivity_score": 0.88,
        "specificity_score": 0.82,
        "link_intent_score": 0.8
      },
      {
        "surface": "Gaussian process prior",
        "canonical": "Gaussian Process",
        "aliases": [
          "GP prior"
        ],
        "category": "specific_connectable",
        "rationale": "Gaussian Processes are fundamental in Bayesian statistics and optimization, providing a probabilistic approach to modeling.",
        "novelty_score": 0.4,
        "connectivity_score": 0.87,
        "specificity_score": 0.78,
        "link_intent_score": 0.77
      },
      {
        "surface": "adversarial online learning",
        "canonical": "Adversarial Online Learning",
        "aliases": [
          "adversarial learning"
        ],
        "category": "unique_technical",
        "rationale": "Adversarial Online Learning is a specialized area focusing on learning in the presence of adversarial conditions.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "finite-expert setting",
      "excess regret",
      "unit cube"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Thompson sampling",
      "resolved_canonical": "Thompson Sampling",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.85,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Bayesian optimization",
      "resolved_canonical": "Bayesian Optimization",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.88,
        "specificity": 0.82,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Gaussian process prior",
      "resolved_canonical": "Gaussian Process",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.87,
        "specificity": 0.78,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "adversarial online learning",
      "resolved_canonical": "Adversarial Online Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# Bayesian Algorithms for Adversarial Online Learning: from Finite to Infinite Action Spaces

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2502.14790.pdf)
**Category**: cs.LG
**Published**: 2025-09-23
**ArXiv ID**: [2502.14790](https://arxiv.org/abs/2502.14790)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-17/Online Bayesian Risk-Averse Reinforcement Learning_20250917|Online Bayesian Risk-Averse Reinforcement Learning]] (82.0% similar)
- [[2025-09-19/Constrained Feedback Learning for Non-Stationary Multi-Armed Bandits_20250919|Constrained Feedback Learning for Non-Stationary Multi-Armed Bandits]] (80.9% similar)
- [[2025-09-22/Online Robust Planning under Model Uncertainty_ A Sample-Based Approach_20250922|Online Robust Planning under Model Uncertainty: A Sample-Based Approach]] (80.6% similar)
- [[2025-09-19/Reinforcement Learning Agent for a 2D Shooter Game_20250919|Reinforcement Learning Agent for a 2D Shooter Game]] (80.5% similar)
- [[2025-09-19/Optimal Algorithms for Bandit Learning in Matching Markets_20250919|Optimal Algorithms for Bandit Learning in Matching Markets]] (80.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Thompson Sampling|Thompson Sampling]], [[keywords/Bayesian Optimization|Bayesian Optimization]], [[keywords/Gaussian Process|Gaussian Process]]
**âš¡ Unique Technical**: [[keywords/Adversarial Online Learning|Adversarial Online Learning]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2502.14790v5 Announce Type: replace 
Abstract: We develop a form Thompson sampling for online learning under full feedback - also known as prediction with expert advice - where the learner's prior is defined over the space of an adversary's future actions, rather than the space of experts. We show regret decomposes into regret the learner expected a priori, plus a prior-robustness-type term we call excess regret. In the classical finite-expert setting, this recovers optimal rates. As an initial step towards practical online learning in settings with a potentially-uncountably-infinite number of experts, we show that Thompson sampling over the $d$-dimensional unit cube, using a certain Gaussian process prior widely-used in the Bayesian optimization literature, has a $\mathcal{O}\Big(\beta\sqrt{Td\log(1+\sqrt{d}\frac{\lambda}{\beta})}\Big)$ rate against a $\beta$-bounded $\lambda$-Lipschitz adversary.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì˜¨ë¼ì¸ í•™ìŠµì—ì„œ ì „ì²´ í”¼ë“œë°±ì„ í™œìš©í•˜ëŠ” í†°ìŠ¨ ìƒ˜í”Œë§ ë°©ë²•ì„ ê°œë°œí–ˆìŠµë‹ˆë‹¤. ê¸°ì¡´ì˜ ì „ë¬¸ê°€ ì¡°ì–¸ ê¸°ë°˜ ì˜ˆì¸¡ê³¼ ë‹¬ë¦¬, í•™ìŠµìì˜ ì‚¬ì „ ì§€ì‹ì€ ì „ë¬¸ê°€ê°€ ì•„ë‹Œ ì ì˜ ë¯¸ë˜ í–‰ë™ì— ê¸°ë°˜í•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ í›„íšŒê°€ ì‚¬ì „ ê¸°ëŒ€ í›„íšŒì™€ ì´ˆê³¼ í›„íšŒë¡œ ë¶„í•´ë¨ì„ ë³´ì—¬ì£¼ë©°, ê³ ì „ì ì¸ ìœ í•œ ì „ë¬¸ê°€ ì„¤ì •ì—ì„œ ìµœì ì˜ ì†ë„ë¥¼ íšŒë³µí•©ë‹ˆë‹¤. ë˜í•œ, ë¬´í•œëŒ€ì˜ ì „ë¬¸ê°€ê°€ ì¡´ì¬í•  ìˆ˜ ìˆëŠ” í™˜ê²½ì—ì„œ ì‹¤ìš©ì ì¸ ì˜¨ë¼ì¸ í•™ìŠµì„ ìœ„í•œ ì´ˆê¸° ë‹¨ê³„ë¡œ, ë² ì´ì§€ì•ˆ ìµœì í™” ë¬¸í—Œì—ì„œ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” íŠ¹ì • ê°€ìš°ì‹œì•ˆ í”„ë¡œì„¸ìŠ¤ ì‚¬ì „ì„ í™œìš©í•˜ì—¬ $d$-ì°¨ì› ë‹¨ìœ„ íë¸Œì—ì„œ í†°ìŠ¨ ìƒ˜í”Œë§ì´ $\beta$-ì œí•œ $\lambda$-ë¦½ì‹œì¸  ì ì— ëŒ€í•´ $\mathcal{O}\Big(\beta\sqrt{Td\log(1+\sqrt{d}\frac{\lambda}{\beta})}\Big)$ ì†ë„ë¥¼ ë‹¬ì„±í•¨ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë³¸ ì—°êµ¬ëŠ” ì „ë¬¸ê°€ ì¡°ì–¸ì„ í†µí•œ ì˜ˆì¸¡ ë¬¸ì œì—ì„œ ì ì˜ ë¯¸ë˜ í–‰ë™ ê³µê°„ì— ëŒ€í•œ ì‚¬ì „ í™•ë¥ ì„ ì„¤ì •í•˜ì—¬ ì˜¨ë¼ì¸ í•™ìŠµì„ ìœ„í•œ í†°ìŠ¨ ìƒ˜í”Œë§ ê¸°ë²•ì„ ê°œë°œí•©ë‹ˆë‹¤.
- 2. í›„íšŒëŠ” ì‚¬ì „ì— ì˜ˆìƒëœ í›„íšŒì™€ ì´ˆê³¼ í›„íšŒë¼ëŠ” ì‚¬ì „ ê²¬ê³ ì„± ìœ í˜•ì˜ í•­ìœ¼ë¡œ ë¶„í•´ë  ìˆ˜ ìˆìŒì„ ë³´ì…ë‹ˆë‹¤.
- 3. ê³ ì „ì ì¸ ìœ í•œ ì „ë¬¸ê°€ ì„¤ì •ì—ì„œ ìµœì ì˜ ë¹„ìœ¨ì„ íšŒë³µí•  ìˆ˜ ìˆìŒì„ ì¦ëª…í•©ë‹ˆë‹¤.
- 4. ì ì¬ì ìœ¼ë¡œ ì…€ ìˆ˜ ì—†ì´ ë§ì€ ì „ë¬¸ê°€ê°€ ìˆëŠ” í™˜ê²½ì—ì„œ ì‹¤ìš©ì ì¸ ì˜¨ë¼ì¸ í•™ìŠµì„ ìœ„í•œ ì´ˆê¸° ë‹¨ê³„ë¡œ, $d$-ì°¨ì› ë‹¨ìœ„ íë¸Œì—ì„œì˜ í†°ìŠ¨ ìƒ˜í”Œë§ì´ íŠ¹ì • ê°€ìš°ì‹œì•ˆ í”„ë¡œì„¸ìŠ¤ ì‚¬ì „ì„ ì‚¬ìš©í•˜ì—¬ $\beta$-ì œí•œ $\lambda$-ë¦¬í”„ì‹œì¸  ì ì— ëŒ€í•´ íŠ¹ì •í•œ ë¹„ìœ¨ì„ ê°€ì§ì„ ë³´ì…ë‹ˆë‹¤.


---

*Generated on 2025-09-24 02:39:28*