---
keywords:
  - Point-RTD
  - Transformer
  - 3D Point Cloud
  - Discriminator-Generator Architecture
  - Chamfer Distance
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.17207
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T23:49:10.961785",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Point-RTD",
    "Transformer",
    "3D Point Cloud",
    "Discriminator-Generator Architecture",
    "Chamfer Distance"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Point-RTD": 0.78,
    "Transformer": 0.85,
    "3D Point Cloud": 0.82,
    "Discriminator-Generator Architecture": 0.8,
    "Chamfer Distance": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Point-RTD",
        "canonical": "Point-RTD",
        "aliases": [
          "Replaced Token Denoising"
        ],
        "category": "unique_technical",
        "rationale": "Point-RTD is a novel pretraining strategy specifically designed for 3D point cloud tasks, offering a unique approach that enhances model performance.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.78
      },
      {
        "surface": "Transformer Models",
        "canonical": "Transformer",
        "aliases": [
          "Transformer-based Models"
        ],
        "category": "broad_technical",
        "rationale": "Transformers are a foundational model architecture in machine learning, widely applicable across various domains including 3D point cloud tasks.",
        "novelty_score": 0.4,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "3D Point Cloud",
        "canonical": "3D Point Cloud",
        "aliases": [
          "Point Cloud"
        ],
        "category": "specific_connectable",
        "rationale": "3D point clouds are a critical data type in computer vision, and linking to this concept enhances understanding of spatial data processing.",
        "novelty_score": 0.5,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.82
      },
      {
        "surface": "Discriminator-Generator Architecture",
        "canonical": "Discriminator-Generator Architecture",
        "aliases": [
          "GAN Architecture"
        ],
        "category": "specific_connectable",
        "rationale": "This architecture is key in the proposed method, facilitating effective denoising and learning of structural priors in point clouds.",
        "novelty_score": 0.7,
        "connectivity_score": 0.78,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Chamfer Distance",
        "canonical": "Chamfer Distance",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Chamfer Distance is a crucial metric for evaluating the accuracy of 3D reconstructions, relevant for assessing model performance.",
        "novelty_score": 0.55,
        "connectivity_score": 0.72,
        "specificity_score": 0.88,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "pretraining strategy",
      "reconstruction error",
      "classification accuracy"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Point-RTD",
      "resolved_canonical": "Point-RTD",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Transformer Models",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "3D Point Cloud",
      "resolved_canonical": "3D Point Cloud",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Discriminator-Generator Architecture",
      "resolved_canonical": "Discriminator-Generator Architecture",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.78,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Chamfer Distance",
      "resolved_canonical": "Chamfer Distance",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.72,
        "specificity": 0.88,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Point-RTD: Replaced Token Denoising for Pretraining Transformer Models on Point Clouds

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17207.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.17207](https://arxiv.org/abs/2509.17207)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/No Need for Real 3D_ Fusing 2D Vision with Pseudo 3D Representations for Robotic Manipulation Learning_20250923|No Need for Real 3D: Fusing 2D Vision with Pseudo 3D Representations for Robotic Manipulation Learning]] (82.0% similar)
- [[2025-09-22/The Missing Piece_ A Case for Pre-Training in 3D Medical Object Detection_20250922|The Missing Piece: A Case for Pre-Training in 3D Medical Object Detection]] (81.6% similar)
- [[2025-09-18/Feature-aligned Motion Transformation for Efficient Dynamic Point Cloud Compression_20250918|Feature-aligned Motion Transformation for Efficient Dynamic Point Cloud Compression]] (81.2% similar)
- [[2025-09-22/PAN_ Pillars-Attention-Based Network for 3D Object Detection_20250922|PAN: Pillars-Attention-Based Network for 3D Object Detection]] (81.1% similar)
- [[2025-09-22/SegDINO3D_ 3D Instance Segmentation Empowered by Both Image-Level and Object-Level 2D Features_20250922|SegDINO3D: 3D Instance Segmentation Empowered by Both Image-Level and Object-Level 2D Features]] (80.9% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Transformer|Transformer]]
**ğŸ”— Specific Connectable**: [[keywords/3D Point Cloud|3D Point Cloud]], [[keywords/Discriminator-Generator Architecture|Discriminator-Generator Architecture]], [[keywords/Chamfer Distance|Chamfer Distance]]
**âš¡ Unique Technical**: [[keywords/Point-RTD|Point-RTD]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17207v1 Announce Type: cross 
Abstract: Pre-training strategies play a critical role in advancing the performance of transformer-based models for 3D point cloud tasks. In this paper, we introduce Point-RTD (Replaced Token Denoising), a novel pretraining strategy designed to improve token robustness through a corruption-reconstruction framework. Unlike traditional mask-based reconstruction tasks that hide data segments for later prediction, Point-RTD corrupts point cloud tokens and leverages a discriminator-generator architecture for denoising. This shift enables more effective learning of structural priors and significantly enhances model performance and efficiency. On the ShapeNet dataset, Point-RTD reduces reconstruction error by over 93% compared to PointMAE, and achieves more than 14x lower Chamfer Distance on the test set. Our method also converges faster and yields higher classification accuracy on ShapeNet, ModelNet10, and ModelNet40 benchmarks, clearly outperforming the baseline Point-MAE framework in every case.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì—ì„œëŠ” 3D í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ì‘ì—…ì—ì„œ íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ìƒˆë¡œìš´ ì‚¬ì „ í•™ìŠµ ì „ëµì¸ Point-RTD(ëŒ€ì²´ í† í° ë””ë…¸ì´ì§•)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. Point-RTDëŠ” ì „í†µì ì¸ ë§ˆìŠ¤í¬ ê¸°ë°˜ ì¬êµ¬ì„± ì‘ì—…ê³¼ ë‹¬ë¦¬ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ í† í°ì„ ì†ìƒì‹œí‚¤ê³ , ë””ìŠ¤í¬ë¦¬ë¯¸ë„¤ì´í„°-ì œë„ˆë ˆì´í„° ì•„í‚¤í…ì²˜ë¥¼ í™œìš©í•˜ì—¬ ë””ë…¸ì´ì§•ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ êµ¬ì¡°ì  ì‚¬ì „ ì •ë³´ë¥¼ ë” íš¨ê³¼ì ìœ¼ë¡œ í•™ìŠµí•˜ê³  ëª¨ë¸ ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„±ì„ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ShapeNet ë°ì´í„°ì…‹ì—ì„œ Point-RTDëŠ” PointMAE ëŒ€ë¹„ ì¬êµ¬ì„± ì˜¤ë¥˜ë¥¼ 93% ì´ìƒ ì¤„ì´ê³ , í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ Chamfer Distanceë¥¼ 14ë°° ì´ìƒ ë‚®ì¶¥ë‹ˆë‹¤. ë˜í•œ, ShapeNet, ModelNet10, ModelNet40 ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë” ë¹ ë¥´ê²Œ ìˆ˜ë ´í•˜ê³  ë†’ì€ ë¶„ë¥˜ ì •í™•ë„ë¥¼ ë‹¬ì„±í•˜ì—¬ ê¸°ì¡´ì˜ Point-MAE í”„ë ˆì„ì›Œí¬ë¥¼ ëŠ¥ê°€í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Point-RTDëŠ” 3D í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ì‘ì—…ì—ì„œ í† í° ê°•ì¸ì„±ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ê³ ì•ˆëœ ìƒˆë¡œìš´ ì‚¬ì „ í•™ìŠµ ì „ëµì…ë‹ˆë‹¤.
- 2. Point-RTDëŠ” ì „í†µì ì¸ ë§ˆìŠ¤í¬ ê¸°ë°˜ ë³µì› ì‘ì—…ê³¼ ë‹¬ë¦¬ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ í† í°ì„ ì†ìƒì‹œí‚¤ê³ , íŒë³„ì-ìƒì„±ì ì•„í‚¤í…ì²˜ë¥¼ í™œìš©í•˜ì—¬ ë…¸ì´ì¦ˆë¥¼ ì œê±°í•©ë‹ˆë‹¤.
- 3. ShapeNet ë°ì´í„°ì…‹ì—ì„œ Point-RTDëŠ” PointMAEì™€ ë¹„êµí•˜ì—¬ ì¬êµ¬ì„± ì˜¤ë¥˜ë¥¼ 93% ì´ìƒ ê°ì†Œì‹œí‚¤ê³ , í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ 14ë°° ì´ìƒ ë‚®ì€ Chamfer Distanceë¥¼ ë‹¬ì„±í•©ë‹ˆë‹¤.
- 4. Point-RTDëŠ” ShapeNet, ModelNet10, ModelNet40 ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë” ë¹ ë¥´ê²Œ ìˆ˜ë ´í•˜ë©°, ë” ë†’ì€ ë¶„ë¥˜ ì •í™•ë„ë¥¼ ê¸°ë¡í•˜ì—¬ Point-MAE í”„ë ˆì„ì›Œí¬ë¥¼ ëŠ¥ê°€í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-23 23:49:10*