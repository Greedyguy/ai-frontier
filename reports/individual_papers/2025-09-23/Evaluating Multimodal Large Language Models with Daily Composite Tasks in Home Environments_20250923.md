---
keywords:
  - Multimodal Learning
  - Composite Tasks
  - Embodied Agents
  - Object Understanding
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.17425
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T22:59:47.696377",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multimodal Learning",
    "Composite Tasks",
    "Embodied Agents",
    "Object Understanding"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multimodal Learning": 0.84,
    "Composite Tasks": 0.79,
    "Embodied Agents": 0.77,
    "Object Understanding": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multimodal Large Language Models",
        "canonical": "Multimodal Learning",
        "aliases": [
          "MLLMs"
        ],
        "category": "specific_connectable",
        "rationale": "Multimodal Learning is crucial for linking models that integrate multiple types of data, such as text and images.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.78,
        "link_intent_score": 0.84
      },
      {
        "surface": "Composite Tasks",
        "canonical": "Composite Tasks",
        "aliases": [
          "Complex Tasks"
        ],
        "category": "unique_technical",
        "rationale": "Composite Tasks are a unique concept in evaluating AGI capabilities, offering a new dimension for linking.",
        "novelty_score": 0.72,
        "connectivity_score": 0.65,
        "specificity_score": 0.81,
        "link_intent_score": 0.79
      },
      {
        "surface": "Embodied Agents",
        "canonical": "Embodied Agents",
        "aliases": [
          "Embodied AI"
        ],
        "category": "evolved_concepts",
        "rationale": "Embodied Agents represent a growing area in AI, linking physical interaction with cognitive models.",
        "novelty_score": 0.68,
        "connectivity_score": 0.73,
        "specificity_score": 0.82,
        "link_intent_score": 0.77
      },
      {
        "surface": "Object Understanding",
        "canonical": "Object Understanding",
        "aliases": [
          "Object Recognition"
        ],
        "category": "specific_connectable",
        "rationale": "Object Understanding is a key component in evaluating spatial intelligence and perception in AI.",
        "novelty_score": 0.58,
        "connectivity_score": 0.79,
        "specificity_score": 0.76,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "dynamic",
      "simulated",
      "preliminary framework"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multimodal Large Language Models",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.78,
        "link_intent": 0.84
      }
    },
    {
      "candidate_surface": "Composite Tasks",
      "resolved_canonical": "Composite Tasks",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.65,
        "specificity": 0.81,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Embodied Agents",
      "resolved_canonical": "Embodied Agents",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.73,
        "specificity": 0.82,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Object Understanding",
      "resolved_canonical": "Object Understanding",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.79,
        "specificity": 0.76,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Evaluating Multimodal Large Language Models with Daily Composite Tasks in Home Environments

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17425.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.17425](https://arxiv.org/abs/2509.17425)

## 🔗 유사한 논문
- [[2025-09-18/AssoCiAm_ A Benchmark for Evaluating Association Thinking while Circumventing Ambiguity_20250918|AssoCiAm: A Benchmark for Evaluating Association Thinking while Circumventing Ambiguity]] (83.6% similar)
- [[2025-09-18/LLM-I_ LLMs are Naturally Interleaved Multimodal Creators_20250918|LLM-I: LLMs are Naturally Interleaved Multimodal Creators]] (83.2% similar)
- [[2025-09-19/Modular Machine Learning_ An Indispensable Path towards New-Generation Large Language Models_20250919|Modular Machine Learning: An Indispensable Path towards New-Generation Large Language Models]] (83.2% similar)
- [[2025-09-19/From Capabilities to Performance_ Evaluating Key Functional Properties of LLM Architectures in Penetration Testing_20250919|From Capabilities to Performance: Evaluating Key Functional Properties of LLM Architectures in Penetration Testing]] (83.0% similar)
- [[2025-09-22/Using Natural Language for Human-Robot Collaboration in the Real World_20250922|Using Natural Language for Human-Robot Collaboration in the Real World]] (82.7% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]], [[keywords/Object Understanding|Object Understanding]]
**⚡ Unique Technical**: [[keywords/Composite Tasks|Composite Tasks]]
**🚀 Evolved Concepts**: [[keywords/Embodied Agents|Embodied Agents]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.17425v1 Announce Type: new 
Abstract: A key feature differentiating artificial general intelligence (AGI) from traditional AI is that AGI can perform composite tasks that require a wide range of capabilities. Although embodied agents powered by multimodal large language models (MLLMs) offer rich perceptual and interactive capabilities, it remains largely unexplored whether they can solve composite tasks. In the current work, we designed a set of composite tasks inspired by common daily activities observed in early childhood development. Within a dynamic and simulated home environment, these tasks span three core domains: object understanding, spatial intelligence, and social activity. We evaluated 17 leading proprietary and open-source MLLMs on these tasks. The results consistently showed poor performance across all three domains, indicating a substantial gap between current capabilities and general intelligence requirements. Together, our tasks offer a preliminary framework for evaluating the general capabilities of embodied agents, marking an early but significant step toward the development of embodied MLLMs and their real-world deployment.

## 📝 요약

이 논문은 인공지능 일반화(AGI)와 전통적 AI의 차이를 탐구하며, AGI가 다양한 능력을 요구하는 복합 과제를 수행할 수 있는지를 조사합니다. 연구진은 초기 아동 발달에서 관찰되는 일상 활동을 바탕으로 한 복합 과제를 설계하고, 이를 동적 시뮬레이션 환경에서 수행했습니다. 17개의 주요 멀티모달 대형 언어 모델(MLLM)을 평가한 결과, 객체 이해, 공간 지능, 사회적 활동 등 세 가지 핵심 영역에서 모두 낮은 성능을 보였습니다. 이는 현재의 AI 능력과 일반 지능 요구 사이의 큰 격차를 나타냅니다. 이 연구는 구현된 에이전트의 일반적 능력을 평가하기 위한 초기 프레임워크를 제공하며, 실세계 적용을 위한 중요한 첫걸음을 제시합니다.

## 🎯 주요 포인트

- 1. 인공지능 일반 지능(AGI)은 다양한 능력을 요구하는 복합 작업을 수행할 수 있는 점에서 전통적인 AI와 차별화된다.
- 2. 다중 모달 대형 언어 모델(MLLMs)을 사용하는 구현된 에이전트의 복합 작업 해결 능력은 아직 충분히 탐구되지 않았다.
- 3. 본 연구에서는 유아 발달에서 관찰되는 일상 활동을 바탕으로 한 복합 작업 세트를 설계하였다.
- 4. 17개의 주요 MLLMs를 평가한 결과, 객체 이해, 공간 지능, 사회적 활동의 세 가지 핵심 영역에서 모두 낮은 성능을 보였다.
- 5. 본 연구의 작업은 구현된 MLLMs의 일반적 능력을 평가하기 위한 초기 프레임워크를 제공하며, 현실 세계에서의 적용을 위한 중요한 첫걸음을 내딛었다.


---

*Generated on 2025-09-23 22:59:47*