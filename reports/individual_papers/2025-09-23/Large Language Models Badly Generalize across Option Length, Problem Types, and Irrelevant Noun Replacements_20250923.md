---
keywords:
  - Large Language Model
  - Generalization Stress Test
  - Option Length Variation
  - Problem Type Variation
  - Irrelevant Noun Replacement
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2502.12459
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T00:46:53.725633",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Generalization Stress Test",
    "Option Length Variation",
    "Problem Type Variation",
    "Irrelevant Noun Replacement"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Generalization Stress Test": 0.7,
    "Option Length Variation": 0.78,
    "Problem Type Variation": 0.77,
    "Irrelevant Noun Replacement": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's focus on generalization issues.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Generalization Stress Test",
        "canonical": "Generalization Stress Test",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Introduces a novel method for evaluating LLMs' generalization.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      },
      {
        "surface": "option length",
        "canonical": "Option Length Variation",
        "aliases": [
          "option lengths"
        ],
        "category": "specific_connectable",
        "rationale": "Highlights a specific perturbation affecting LLM performance.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.75,
        "link_intent_score": 0.78
      },
      {
        "surface": "problem types",
        "canonical": "Problem Type Variation",
        "aliases": [
          "problem types"
        ],
        "category": "specific_connectable",
        "rationale": "Identifies a key factor in assessing LLM generalization.",
        "novelty_score": 0.6,
        "connectivity_score": 0.72,
        "specificity_score": 0.7,
        "link_intent_score": 0.77
      },
      {
        "surface": "irrelevant noun replacements",
        "canonical": "Irrelevant Noun Replacement",
        "aliases": [
          "noun replacements"
        ],
        "category": "specific_connectable",
        "rationale": "Demonstrates how superficial changes impact LLM accuracy.",
        "novelty_score": 0.68,
        "connectivity_score": 0.68,
        "specificity_score": 0.72,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "accuracy drops",
      "unexpected biases"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Generalization Stress Test",
      "resolved_canonical": "Generalization Stress Test",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "option length",
      "resolved_canonical": "Option Length Variation",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.75,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "problem types",
      "resolved_canonical": "Problem Type Variation",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.72,
        "specificity": 0.7,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "irrelevant noun replacements",
      "resolved_canonical": "Irrelevant Noun Replacement",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.68,
        "specificity": 0.72,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Large Language Models Badly Generalize across Option Length, Problem Types, and Irrelevant Noun Replacements

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2502.12459.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2502.12459](https://arxiv.org/abs/2502.12459)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/It Depends_ Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge_20250922|It Depends: Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge]] (88.5% similar)
- [[2025-09-22/Are LLMs Better Formalizers than Solvers on Complex Problems?_20250922|Are LLMs Better Formalizers than Solvers on Complex Problems?]] (86.5% similar)
- [[2025-09-19/Large Language Model probabilities cannot distinguish between possible and impossible language_20250919|Large Language Model probabilities cannot distinguish between possible and impossible language]] (86.4% similar)
- [[2025-09-22/Calibrating LLM Confidence by Probing Perturbed Representation Stability_20250922|Calibrating LLM Confidence by Probing Perturbed Representation Stability]] (86.1% similar)
- [[2025-09-22/A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages_20250922|A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages]] (86.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Option Length Variation|Option Length Variation]], [[keywords/Problem Type Variation|Problem Type Variation]], [[keywords/Irrelevant Noun Replacement|Irrelevant Noun Replacement]]
**âš¡ Unique Technical**: [[keywords/Generalization Stress Test|Generalization Stress Test]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2502.12459v3 Announce Type: replace-cross 
Abstract: In this paper, we propose a ``Generalization Stress Test" to assess Large Language Models' (LLMs) generalization ability under slight and controlled perturbations, including option length, problem types, and irrelevant noun replacements. We achieve novel and significant findings that, despite high benchmark scores, LLMs exhibit severe accuracy drops and unexpected biases (e.g., preference for longer distractors) when faced with these minor but content-preserving modifications. For example, Qwen 2.5 1.5B's MMLU score rises from 60 to 89 and drops from 89 to 36 when option lengths are changed without altering the question. Even GPT4o experiences a 25-point accuracy loss when problem types are changed, with a 6-point drop across all three modification categories. These analyses suggest that LLMs rely heavily on superficial cues rather than forming robust, abstract representations that generalize across formats, lexical variations, and irrelevant content shifts.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì—ì„œëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì¼ë°˜í™” ëŠ¥ë ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ "ì¼ë°˜í™” ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸"ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ í…ŒìŠ¤íŠ¸ëŠ” ì„ íƒì§€ ê¸¸ì´, ë¬¸ì œ ìœ í˜•, ë¬´ê´€í•œ ëª…ì‚¬ ëŒ€ì²´ì™€ ê°™ì€ ë¯¸ì„¸í•œ ë³€í™”ë¥¼ í†µí•´ LLMì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤. ì—°êµ¬ ê²°ê³¼, ë†’ì€ ë²¤ì¹˜ë§ˆí¬ ì ìˆ˜ì—ë„ ë¶ˆêµ¬í•˜ê³  LLMì€ ì´ëŸ¬í•œ ì‘ì€ ë³€í™”ì— ëŒ€í•´ ì‹¬ê°í•œ ì •í™•ë„ ì €í•˜ì™€ ì˜ˆê¸°ì¹˜ ì•Šì€ í¸í–¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, Qwen 2.5 1.5B ëª¨ë¸ì˜ MMLU ì ìˆ˜ëŠ” ì„ íƒì§€ ê¸¸ì´ë§Œ ë³€ê²½í–ˆì„ ë•Œ 60ì—ì„œ 89ë¡œ ìƒìŠ¹í–ˆë‹¤ê°€ 36ìœ¼ë¡œ ê¸‰ë½í–ˆìŠµë‹ˆë‹¤. ë˜í•œ GPT4oëŠ” ë¬¸ì œ ìœ í˜• ë³€ê²½ ì‹œ 25ì ì˜ ì •í™•ë„ ì†ì‹¤ì„ ê²ªì—ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ê²°ê³¼ëŠ” LLMì´ í˜•ì‹, ì–´íœ˜ ë³€í˜•, ë¬´ê´€í•œ ë‚´ìš© ë³€í™”ì— ëŒ€í•´ ê°•ë ¥í•˜ê³  ì¶”ìƒì ì¸ í‘œí˜„ì„ í˜•ì„±í•˜ê¸°ë³´ë‹¤ëŠ” í‘œë©´ì ì¸ ë‹¨ì„œì— í¬ê²Œ ì˜ì¡´í•˜ê³  ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. "ì¼ë°˜í™” ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸"ë¥¼ í†µí•´ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì¼ë°˜í™” ëŠ¥ë ¥ì„ í‰ê°€í•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤.
- 2. LLMì€ ë†’ì€ ë²¤ì¹˜ë§ˆí¬ ì ìˆ˜ì—ë„ ë¶ˆêµ¬í•˜ê³ , ì˜µì…˜ ê¸¸ì´, ë¬¸ì œ ìœ í˜•, ë¬´ê´€í•œ ëª…ì‚¬ ëŒ€ì²´ ë“±ì˜ ê²½ë¯¸í•œ ë³€í™”ì— ëŒ€í•´ ì‹¬ê°í•œ ì •í™•ë„ ì €í•˜ì™€ ì˜ˆê¸°ì¹˜ ì•Šì€ í¸í–¥ì„ ë³´ì…ë‹ˆë‹¤.
- 3. ì˜ˆë¥¼ ë“¤ì–´, Qwen 2.5 1.5B ëª¨ë¸ì˜ MMLU ì ìˆ˜ëŠ” ì˜µì…˜ ê¸¸ì´ ë³€í™”ì— ë”°ë¼ 60ì—ì„œ 89ë¡œ ìƒìŠ¹í•˜ê³ , ë‹¤ì‹œ 89ì—ì„œ 36ìœ¼ë¡œ í•˜ë½í•©ë‹ˆë‹¤.
- 4. GPT4o ëª¨ë¸ë„ ë¬¸ì œ ìœ í˜• ë³€ê²½ ì‹œ 25ì ì˜ ì •í™•ë„ ì†ì‹¤ì„ ê²½í—˜í•˜ë©°, ì„¸ ê°€ì§€ ìˆ˜ì • ë²”ì£¼ ëª¨ë‘ì—ì„œ 6ì ì˜ í•˜ë½ì„ ë³´ì…ë‹ˆë‹¤.
- 5. ì´ëŸ¬í•œ ë¶„ì„ì€ LLMì´ í˜•ì‹, ì–´íœ˜ ë³€í˜•, ë¬´ê´€í•œ ë‚´ìš© ë³€í™”ì— ê±¸ì³ ì¼ë°˜í™”ë˜ëŠ” ê²¬ê³ í•˜ê³  ì¶”ìƒì ì¸ í‘œí˜„ë³´ë‹¤ëŠ” í”¼ìƒì ì¸ ë‹¨ì„œì— í¬ê²Œ ì˜ì¡´í•œë‹¤ëŠ” ê²ƒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 00:46:53*