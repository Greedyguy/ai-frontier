---
keywords:
  - Large Language Model
  - Generalization Stress Test
  - Option Length Variation
  - Problem Type Variation
  - Irrelevant Noun Replacement
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2502.12459
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T00:46:53.725633",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Generalization Stress Test",
    "Option Length Variation",
    "Problem Type Variation",
    "Irrelevant Noun Replacement"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Generalization Stress Test": 0.7,
    "Option Length Variation": 0.78,
    "Problem Type Variation": 0.77,
    "Irrelevant Noun Replacement": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's focus on generalization issues.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Generalization Stress Test",
        "canonical": "Generalization Stress Test",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Introduces a novel method for evaluating LLMs' generalization.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      },
      {
        "surface": "option length",
        "canonical": "Option Length Variation",
        "aliases": [
          "option lengths"
        ],
        "category": "specific_connectable",
        "rationale": "Highlights a specific perturbation affecting LLM performance.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.75,
        "link_intent_score": 0.78
      },
      {
        "surface": "problem types",
        "canonical": "Problem Type Variation",
        "aliases": [
          "problem types"
        ],
        "category": "specific_connectable",
        "rationale": "Identifies a key factor in assessing LLM generalization.",
        "novelty_score": 0.6,
        "connectivity_score": 0.72,
        "specificity_score": 0.7,
        "link_intent_score": 0.77
      },
      {
        "surface": "irrelevant noun replacements",
        "canonical": "Irrelevant Noun Replacement",
        "aliases": [
          "noun replacements"
        ],
        "category": "specific_connectable",
        "rationale": "Demonstrates how superficial changes impact LLM accuracy.",
        "novelty_score": 0.68,
        "connectivity_score": 0.68,
        "specificity_score": 0.72,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "accuracy drops",
      "unexpected biases"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Generalization Stress Test",
      "resolved_canonical": "Generalization Stress Test",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "option length",
      "resolved_canonical": "Option Length Variation",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.75,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "problem types",
      "resolved_canonical": "Problem Type Variation",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.72,
        "specificity": 0.7,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "irrelevant noun replacements",
      "resolved_canonical": "Irrelevant Noun Replacement",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.68,
        "specificity": 0.72,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Large Language Models Badly Generalize across Option Length, Problem Types, and Irrelevant Noun Replacements

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2502.12459.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2502.12459](https://arxiv.org/abs/2502.12459)

## 🔗 유사한 논문
- [[2025-09-22/It Depends_ Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge_20250922|It Depends: Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge]] (88.5% similar)
- [[2025-09-22/Are LLMs Better Formalizers than Solvers on Complex Problems?_20250922|Are LLMs Better Formalizers than Solvers on Complex Problems?]] (86.5% similar)
- [[2025-09-19/Large Language Model probabilities cannot distinguish between possible and impossible language_20250919|Large Language Model probabilities cannot distinguish between possible and impossible language]] (86.4% similar)
- [[2025-09-22/Calibrating LLM Confidence by Probing Perturbed Representation Stability_20250922|Calibrating LLM Confidence by Probing Perturbed Representation Stability]] (86.1% similar)
- [[2025-09-22/A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages_20250922|A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages]] (86.0% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Option Length Variation|Option Length Variation]], [[keywords/Problem Type Variation|Problem Type Variation]], [[keywords/Irrelevant Noun Replacement|Irrelevant Noun Replacement]]
**⚡ Unique Technical**: [[keywords/Generalization Stress Test|Generalization Stress Test]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2502.12459v3 Announce Type: replace-cross 
Abstract: In this paper, we propose a ``Generalization Stress Test" to assess Large Language Models' (LLMs) generalization ability under slight and controlled perturbations, including option length, problem types, and irrelevant noun replacements. We achieve novel and significant findings that, despite high benchmark scores, LLMs exhibit severe accuracy drops and unexpected biases (e.g., preference for longer distractors) when faced with these minor but content-preserving modifications. For example, Qwen 2.5 1.5B's MMLU score rises from 60 to 89 and drops from 89 to 36 when option lengths are changed without altering the question. Even GPT4o experiences a 25-point accuracy loss when problem types are changed, with a 6-point drop across all three modification categories. These analyses suggest that LLMs rely heavily on superficial cues rather than forming robust, abstract representations that generalize across formats, lexical variations, and irrelevant content shifts.

## 📝 요약

이 논문에서는 대형 언어 모델(LLM)의 일반화 능력을 평가하기 위한 "일반화 스트레스 테스트"를 제안합니다. 이 테스트는 선택지 길이, 문제 유형, 무관한 명사 대체와 같은 미세한 변화를 통해 LLM의 성능을 평가합니다. 연구 결과, 높은 벤치마크 점수에도 불구하고 LLM은 이러한 작은 변화에 대해 심각한 정확도 저하와 예기치 않은 편향을 보였습니다. 예를 들어, Qwen 2.5 1.5B 모델의 MMLU 점수는 선택지 길이만 변경했을 때 60에서 89로 상승했다가 36으로 급락했습니다. 또한 GPT4o는 문제 유형 변경 시 25점의 정확도 손실을 겪었습니다. 이러한 결과는 LLM이 형식, 어휘 변형, 무관한 내용 변화에 대해 강력하고 추상적인 표현을 형성하기보다는 표면적인 단서에 크게 의존하고 있음을 시사합니다.

## 🎯 주요 포인트

- 1. "일반화 스트레스 테스트"를 통해 대형 언어 모델(LLM)의 일반화 능력을 평가하는 방법을 제안합니다.
- 2. LLM은 높은 벤치마크 점수에도 불구하고, 옵션 길이, 문제 유형, 무관한 명사 대체 등의 경미한 변화에 대해 심각한 정확도 저하와 예기치 않은 편향을 보입니다.
- 3. 예를 들어, Qwen 2.5 1.5B 모델의 MMLU 점수는 옵션 길이 변화에 따라 60에서 89로 상승하고, 다시 89에서 36으로 하락합니다.
- 4. GPT4o 모델도 문제 유형 변경 시 25점의 정확도 손실을 경험하며, 세 가지 수정 범주 모두에서 6점의 하락을 보입니다.
- 5. 이러한 분석은 LLM이 형식, 어휘 변형, 무관한 내용 변화에 걸쳐 일반화되는 견고하고 추상적인 표현보다는 피상적인 단서에 크게 의존한다는 것을 시사합니다.


---

*Generated on 2025-09-24 00:46:53*