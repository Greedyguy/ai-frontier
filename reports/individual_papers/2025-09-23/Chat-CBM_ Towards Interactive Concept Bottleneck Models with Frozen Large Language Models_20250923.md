---
keywords:
  - Concept Bottleneck Models
  - Large Language Model
  - Unsupervised Concept Bottleneck Models
  - Few-Shot Learning
category: cs.CV
publish_date: 2025-09-23
arxiv_id: 2509.17522
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T04:54:46.210806",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Concept Bottleneck Models",
    "Large Language Model",
    "Unsupervised Concept Bottleneck Models",
    "Few-Shot Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Concept Bottleneck Models": 0.8,
    "Large Language Model": 0.85,
    "Unsupervised Concept Bottleneck Models": 0.78,
    "Few-Shot Learning": 0.82
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Concept Bottleneck Models",
        "canonical": "Concept Bottleneck Models",
        "aliases": [
          "CBM"
        ],
        "category": "unique_technical",
        "rationale": "This is a central concept of the paper, representing a specific model type that enhances interpretability.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "These models are integral to the proposed method, enabling language-based reasoning over concepts.",
        "novelty_score": 0.4,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Unsupervised CBMs",
        "canonical": "Unsupervised Concept Bottleneck Models",
        "aliases": [
          "Unsupervised CBM"
        ],
        "category": "unique_technical",
        "rationale": "This variant of CBMs is highlighted for its challenges and the improvements offered by the proposed method.",
        "novelty_score": 0.68,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Few-Shot Capabilities",
        "canonical": "Few-Shot Learning",
        "aliases": [
          "Few-Shot"
        ],
        "category": "specific_connectable",
        "rationale": "The paper leverages few-shot learning capabilities of large language models for improved interventions.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.72,
        "link_intent_score": 0.82
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Concept Bottleneck Models",
      "resolved_canonical": "Concept Bottleneck Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Unsupervised CBMs",
      "resolved_canonical": "Unsupervised Concept Bottleneck Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Few-Shot Capabilities",
      "resolved_canonical": "Few-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.72,
        "link_intent": 0.82
      }
    }
  ]
}
-->

# Chat-CBM: Towards Interactive Concept Bottleneck Models with Frozen Large Language Models

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17522.pdf)
**Category**: cs.CV
**Published**: 2025-09-23
**ArXiv ID**: [2509.17522](https://arxiv.org/abs/2509.17522)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Bayesian Concept Bottleneck Models with LLM Priors_20250922|Bayesian Concept Bottleneck Models with LLM Priors]] (88.2% similar)
- [[2025-09-19/EnCoBo_ Energy-Guided Concept Bottlenecks for Interpretable Generation_20250919|EnCoBo: Energy-Guided Concept Bottlenecks for Interpretable Generation]] (85.4% similar)
- [[2025-09-23/MCP_ A Control-Theoretic Orchestration Framework for Synergistic Efficiency and Interpretability in Multimodal Large Language Models_20250923|MCP: A Control-Theoretic Orchestration Framework for Synergistic Efficiency and Interpretability in Multimodal Large Language Models]] (82.1% similar)
- [[2025-09-23/OptiChat_ Bridging Optimization Models and Practitioners with Large Language Models_20250923|OptiChat: Bridging Optimization Models and Practitioners with Large Language Models]] (81.6% similar)
- [[2025-09-23/WISE_ Weak-Supervision-Guided Step-by-Step Explanations for Multimodal LLMs in Image Classification_20250923|WISE: Weak-Supervision-Guided Step-by-Step Explanations for Multimodal LLMs in Image Classification]] (81.4% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Few-Shot Learning|Few-Shot Learning]]
**âš¡ Unique Technical**: [[keywords/Concept Bottleneck Models|Concept Bottleneck Models]], [[keywords/Unsupervised Concept Bottleneck Models|Unsupervised Concept Bottleneck Models]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17522v1 Announce Type: new 
Abstract: Concept Bottleneck Models (CBMs) provide inherent interpretability by first predicting a set of human-understandable concepts and then mapping them to labels through a simple classifier. While users can intervene in the concept space to improve predictions, traditional CBMs typically employ a fixed linear classifier over concept scores, which restricts interventions to manual value adjustments and prevents the incorporation of new concepts or domain knowledge at test time. These limitations are particularly severe in unsupervised CBMs, where concept activations are often noisy and densely activated, making user interventions ineffective. We introduce Chat-CBM, which replaces score-based classifiers with a language-based classifier that reasons directly over concept semantics. By grounding prediction in the semantic space of concepts, Chat-CBM preserves the interpretability of CBMs while enabling richer and more intuitive interventions, such as concept correction, addition or removal of concepts, incorporation of external knowledge, and high-level reasoning guidance. Leveraging the language understanding and few-shot capabilities of frozen large language models, Chat-CBM extends the intervention interface of CBMs beyond numerical editing and remains effective even in unsupervised settings. Experiments on nine datasets demonstrate that Chat-CBM achieves higher predictive performance and substantially improves user interactivity while maintaining the concept-based interpretability of CBMs.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì—ì„œëŠ” Chat-CBMì´ë¼ëŠ” ìƒˆë¡œìš´ ê°œë… ë³‘ëª© ëª¨ë¸ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ê°œë… ë³‘ëª© ëª¨ë¸ì€ ê°œë… ì ìˆ˜ì— ê¸°ë°˜í•œ ê³ ì •ëœ ì„ í˜• ë¶„ë¥˜ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìê°€ ê°œë… ê³µê°„ì—ì„œì˜ ê°œì…ì´ ì œí•œì ì´ì—ˆìŠµë‹ˆë‹¤. Chat-CBMì€ ì ìˆ˜ ê¸°ë°˜ ë¶„ë¥˜ê¸°ë¥¼ ì–¸ì–´ ê¸°ë°˜ ë¶„ë¥˜ê¸°ë¡œ ëŒ€ì²´í•˜ì—¬ ê°œë…ì˜ ì˜ë¯¸ì  ê³µê°„ì—ì„œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ê°œë… ìˆ˜ì •, ì¶”ê°€, ì œê±°, ì™¸ë¶€ ì§€ì‹ í†µí•© ë° ê³ ì°¨ì›ì  ì¶”ë¡  ì§€ì¹¨ ë“± ë” í’ë¶€í•˜ê³  ì§ê´€ì ì¸ ê°œì…ì´ ê°€ëŠ¥í•´ì§‘ë‹ˆë‹¤. íŠ¹íˆ, ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ ì–¸ì–´ ì´í•´ì™€ ì†Œìˆ˜ ìƒ· í•™ìŠµ ëŠ¥ë ¥ì„ í™œìš©í•˜ì—¬, Chat-CBMì€ ë¹„ì§€ë„ í•™ìŠµ í™˜ê²½ì—ì„œë„ íš¨ê³¼ì ì…ë‹ˆë‹¤. 9ê°œì˜ ë°ì´í„°ì…‹ ì‹¤í—˜ ê²°ê³¼, Chat-CBMì€ ì˜ˆì¸¡ ì„±ëŠ¥ì„ ë†’ì´ê³  ì‚¬ìš©ì ìƒí˜¸ì‘ìš©ì„ í¬ê²Œ ê°œì„ í•˜ë©´ì„œë„ ê°œë… ê¸°ë°˜ì˜ í•´ì„ ê°€ëŠ¥ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Concept Bottleneck Models(CBMs)ëŠ” ê°œë…ì„ ì˜ˆì¸¡í•˜ê³  ì´ë¥¼ ë¼ë²¨ë¡œ ë§¤í•‘í•˜ì—¬ í•´ì„ ê°€ëŠ¥ì„±ì„ ì œê³µí•©ë‹ˆë‹¤.
- 2. ê¸°ì¡´ CBMsëŠ” ê³ ì •ëœ ì„ í˜• ë¶„ë¥˜ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°œë… ì ìˆ˜ì— ê¸°ë°˜í•œ ìˆ˜ë™ ì¡°ì •ë§Œ ê°€ëŠ¥í•˜ë©°, ìƒˆë¡œìš´ ê°œë…ì´ë‚˜ ë„ë©”ì¸ ì§€ì‹ì„ í…ŒìŠ¤íŠ¸ ì‹œ ë°˜ì˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
- 3. Chat-CBMì€ ì ìˆ˜ ê¸°ë°˜ ë¶„ë¥˜ê¸°ë¥¼ ì–¸ì–´ ê¸°ë°˜ ë¶„ë¥˜ê¸°ë¡œ ëŒ€ì²´í•˜ì—¬ ê°œë… ì˜ë¯¸ë¥¼ ì§ì ‘ì ìœ¼ë¡œ í•´ì„í•˜ê³ , ê°œë… ìˆ˜ì •, ì¶”ê°€, ì œê±° ë° ì™¸ë¶€ ì§€ì‹ í†µí•©ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
- 4. Chat-CBMì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ ì–¸ì–´ ì´í•´ ë° ì†Œìˆ˜ì˜ ìƒ˜í”Œë¡œ í•™ìŠµí•˜ëŠ” ëŠ¥ë ¥ì„ í™œìš©í•˜ì—¬ CBMsì˜ ê°œì… ì¸í„°í˜ì´ìŠ¤ë¥¼ í™•ì¥í•˜ê³ , ë¹„ì§€ë„ í•™ìŠµ í™˜ê²½ì—ì„œë„ íš¨ê³¼ì ì…ë‹ˆë‹¤.
- 5. ì•„í™‰ ê°œì˜ ë°ì´í„°ì…‹ ì‹¤í—˜ì—ì„œ Chat-CBMì€ ì˜ˆì¸¡ ì„±ëŠ¥ì„ ë†’ì´ê³  ì‚¬ìš©ì ìƒí˜¸ì‘ìš©ì„ ê°œì„ í•˜ë©´ì„œ CBMsì˜ ê°œë… ê¸°ë°˜ í•´ì„ ê°€ëŠ¥ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 04:54:46*