---
keywords:
  - Hierarchical Dual-Adapter Contrastive Learning
  - Discourse Relation Classification
  - Large Language Model
  - Few-Shot Learning
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2509.16903
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:20:03.768004",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Hierarchical Dual-Adapter Contrastive Learning",
    "Discourse Relation Classification",
    "Large Language Model",
    "Few-Shot Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Hierarchical Dual-Adapter Contrastive Learning": 0.78,
    "Discourse Relation Classification": 0.82,
    "Large Language Model": 0.75,
    "Few-Shot Learning": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Hierarchical Dual-Adapter Contrastive learning",
        "canonical": "Hierarchical Dual-Adapter Contrastive Learning",
        "aliases": [
          "HiDAC"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel model introduced in the paper, offering a unique approach to discourse relation classification.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.88,
        "link_intent_score": 0.78
      },
      {
        "surface": "Discourse Relation Classification",
        "canonical": "Discourse Relation Classification",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Central to the paper's focus, it connects to broader discourse analysis topics.",
        "novelty_score": 0.55,
        "connectivity_score": 0.8,
        "specificity_score": 0.85,
        "link_intent_score": 0.82
      },
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "Key technology evaluated in the paper, relevant for linking to broader NLP and AI discussions.",
        "novelty_score": 0.4,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.75
      },
      {
        "surface": "Zero-shot and Few-shot settings",
        "canonical": "Few-Shot Learning",
        "aliases": [
          "Zero-Shot Learning"
        ],
        "category": "specific_connectable",
        "rationale": "These learning paradigms are significant for understanding model adaptability and performance.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "Task 3",
      "DISRPT 2025",
      "mBERT",
      "XLM-RoBERTa"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Hierarchical Dual-Adapter Contrastive learning",
      "resolved_canonical": "Hierarchical Dual-Adapter Contrastive Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.88,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Discourse Relation Classification",
      "resolved_canonical": "Discourse Relation Classification",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.8,
        "specificity": 0.85,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Zero-shot and Few-shot settings",
      "resolved_canonical": "Few-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# CLaC at DISRPT 2025: Hierarchical Adapters for Cross-Framework Multi-lingual Discourse Relation Classification

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16903.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2509.16903](https://arxiv.org/abs/2509.16903)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/CorefInst_ Leveraging LLMs for Multilingual Coreference Resolution_20250923|CorefInst: Leveraging LLMs for Multilingual Coreference Resolution]] (82.7% similar)
- [[2025-09-23/Dual-View Alignment Learning with Hierarchical-Prompt for Class-Imbalance Multi-Label Classification_20250923|Dual-View Alignment Learning with Hierarchical-Prompt for Class-Imbalance Multi-Label Classification]] (81.9% similar)
- [[2025-09-17/DSCC-HS_ A Dynamic Self-Reinforcing Framework for Hallucination Suppression in Large Language Models_20250917|DSCC-HS: A Dynamic Self-Reinforcing Framework for Hallucination Suppression in Large Language Models]] (81.3% similar)
- [[2025-09-23/PDTrim_ Targeted Pruning for Prefill-Decode Disaggregation in Inference_20250923|PDTrim: Targeted Pruning for Prefill-Decode Disaggregation in Inference]] (81.1% similar)
- [[2025-09-19/DetectAnyLLM_ Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models_20250919|DetectAnyLLM: Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models]] (81.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Discourse Relation Classification|Discourse Relation Classification]], [[keywords/Few-Shot Learning|Few-Shot Learning]]
**âš¡ Unique Technical**: [[keywords/Hierarchical Dual-Adapter Contrastive Learning|Hierarchical Dual-Adapter Contrastive Learning]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16903v1 Announce Type: new 
Abstract: We present our submission to Task 3 (Discourse Relation Classification) of the DISRPT 2025 shared task. Task 3 introduces a unified set of 17 discourse relation labels across 39 corpora in 16 languages and six discourse frameworks, posing significant multilingual and cross-formalism challenges. We first benchmark the task by fine-tuning multilingual BERT-based models (mBERT, XLM-RoBERTa-Base, and XLM-RoBERTa-Large) with two argument-ordering strategies and progressive unfreezing ratios to establish strong baselines. We then evaluate prompt-based large language models (namely Claude Opus 4.0) in zero-shot and few-shot settings to understand how LLMs respond to the newly proposed unified labels. Finally, we introduce HiDAC, a Hierarchical Dual-Adapter Contrastive learning model. Results show that while larger transformer models achieve higher accuracy, the improvements are modest, and that unfreezing the top 75% of encoder layers yields performance comparable to full fine-tuning while training far fewer parameters. Prompt-based models lag significantly behind fine-tuned transformers, and HiDAC achieves the highest overall accuracy (67.5%) while remaining more parameter-efficient than full fine-tuning.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ DISRPT 2025 ê³µìœ  ê³¼ì œì˜ Task 3ì¸ ë‹´í™” ê´€ê³„ ë¶„ë¥˜ì— ëŒ€í•œ ì—°êµ¬ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. 16ê°œ ì–¸ì–´ì™€ 6ê°œì˜ ë‹´í™” ì²´ê³„ë¥¼ í¬í•¨í•œ 39ê°œì˜ ì½”í¼ìŠ¤ì—ì„œ 17ê°œì˜ ë‹´í™” ê´€ê³„ ë ˆì´ë¸”ì„ í†µí•©í•˜ì—¬ ë‹¤ì–¸ì–´ ë° êµì°¨ í˜•ì‹ ë¬¸ì œë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ì—°êµ¬ì—ì„œëŠ” ë‹¤êµ­ì–´ BERT ê¸°ë°˜ ëª¨ë¸(mBERT, XLM-RoBERTa-Base, XLM-RoBERTa-Large)ì„ ë¯¸ì„¸ ì¡°ì •í•˜ì—¬ ê°•ë ¥í•œ ê¸°ì¤€ì„ ì„ ì„¤ì •í•˜ê³ , í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(Claude Opus 4.0)ì„ í‰ê°€í•˜ì—¬ ìƒˆë¡œìš´ ë ˆì´ë¸”ì— ëŒ€í•œ ë°˜ì‘ì„ ë¶„ì„í•©ë‹ˆë‹¤. ë˜í•œ, HiDACë¼ëŠ” ê³„ì¸µì  ì´ì¤‘ ì–´ëŒ‘í„° ëŒ€ì¡° í•™ìŠµ ëª¨ë¸ì„ ì†Œê°œí•©ë‹ˆë‹¤. ê²°ê³¼ì ìœ¼ë¡œ, ëŒ€í˜• íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì´ ë” ë†’ì€ ì •í™•ë„ë¥¼ ë³´ì´ì§€ë§Œ, ê°œì„  í­ì€ í¬ì§€ ì•Šìœ¼ë©°, ì¸ì½”ë” ì¸µì˜ 75%ë¥¼ í•´ì œí•˜ëŠ” ê²ƒì´ ì „ì²´ ë¯¸ì„¸ ì¡°ì •ê³¼ ìœ ì‚¬í•œ ì„±ëŠ¥ì„ ë³´ì´ë©´ì„œë„ ë” ì ì€ ë§¤ê°œë³€ìˆ˜ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ëª¨ë¸ì€ ë¯¸ì„¸ ì¡°ì •ëœ íŠ¸ëœìŠ¤í¬ë¨¸ë³´ë‹¤ ì„±ëŠ¥ì´ ë–¨ì–´ì§€ë©°, HiDACëŠ” ì „ì²´ ë¯¸ì„¸ ì¡°ì •ë³´ë‹¤ ë” íš¨ìœ¨ì ì¸ ë§¤ê°œë³€ìˆ˜ë¡œ ìµœê³  ì •í™•ë„(67.5%)ë¥¼ ë‹¬ì„±í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Task 3ì—ì„œëŠ” 16ê°œ ì–¸ì–´ì™€ 6ê°œì˜ ë‹´í™” í”„ë ˆì„ì›Œí¬ë¥¼ ì•„ìš°ë¥´ëŠ” 17ê°œì˜ í†µí•© ë‹´í™” ê´€ê³„ ë ˆì´ë¸”ì„ ë„ì…í•˜ì—¬ ë‹¤êµ­ì–´ ë° êµì°¨ í˜•ì‹ ë„ì „ ê³¼ì œë¥¼ ì œì‹œí•©ë‹ˆë‹¤.
- 2. mBERT, XLM-RoBERTa-Base, XLM-RoBERTa-Large ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ì—¬ ê°•ë ¥í•œ ê¸°ì¤€ì„ ì„ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.
- 3. Claude Opus 4.0ê³¼ ê°™ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì„ ì œë¡œìƒ· ë° í“¨ìƒ· ì„¤ì •ì—ì„œ í‰ê°€í•˜ì—¬ ìƒˆë¡œìš´ í†µí•© ë ˆì´ë¸”ì— ëŒ€í•œ ë°˜ì‘ì„ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.
- 4. HiDAC ëª¨ë¸ì€ ì „ì²´ ë¯¸ì„¸ ì¡°ì •ë³´ë‹¤ ë” ì ì€ ë§¤ê°œë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë©´ì„œë„ 67.5%ì˜ ìµœê³  ì •í™•ë„ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.
- 5. í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ëª¨ë¸ì€ ë¯¸ì„¸ ì¡°ì •ëœ íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì— ë¹„í•´ ì„±ëŠ¥ì´ ìƒë‹¹íˆ ë’¤ì²˜ì¡ŒìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 03:20:03*