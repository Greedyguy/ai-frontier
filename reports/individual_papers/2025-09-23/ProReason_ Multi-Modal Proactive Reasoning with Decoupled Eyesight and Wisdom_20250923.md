---
keywords:
  - Vision-Language Model
  - ProReason Framework
  - Decoupled Vision-Reasoning
  - Large Language Model
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2410.14138
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T00:40:11.157300",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Vision-Language Model",
    "ProReason Framework",
    "Decoupled Vision-Reasoning",
    "Large Language Model"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Vision-Language Model": 0.85,
    "ProReason Framework": 0.89,
    "Decoupled Vision-Reasoning": 0.82,
    "Large Language Model": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Vision-Language Models",
        "canonical": "Vision-Language Model",
        "aliases": [
          "LVLMs"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-Language Models are central to the paper's discussion on multi-modal reasoning, linking to trending research in multimodal AI.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.78,
        "link_intent_score": 0.85
      },
      {
        "surface": "ProReason",
        "canonical": "ProReason Framework",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "ProReason is a novel framework introduced in the paper, crucial for understanding its unique contribution to visual reasoning.",
        "novelty_score": 0.92,
        "connectivity_score": 0.65,
        "specificity_score": 0.91,
        "link_intent_score": 0.89
      },
      {
        "surface": "Decoupled Vision-Reasoning",
        "canonical": "Decoupled Vision-Reasoning",
        "aliases": [
          "Decoupled Eyesight and Wisdom"
        ],
        "category": "unique_technical",
        "rationale": "This concept is a core innovation in the paper, highlighting a new approach to integrating vision and reasoning processes.",
        "novelty_score": 0.78,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.82
      },
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are integral to the paper's framework, providing a bridge to existing knowledge in AI.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "multi-modal question",
      "visual descriptions",
      "performance gain"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Vision-Language Models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.78,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "ProReason",
      "resolved_canonical": "ProReason Framework",
      "decision": "linked",
      "scores": {
        "novelty": 0.92,
        "connectivity": 0.65,
        "specificity": 0.91,
        "link_intent": 0.89
      }
    },
    {
      "candidate_surface": "Decoupled Vision-Reasoning",
      "resolved_canonical": "Decoupled Vision-Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.78,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# ProReason: Multi-Modal Proactive Reasoning with Decoupled Eyesight and Wisdom

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2410.14138.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2410.14138](https://arxiv.org/abs/2410.14138)

## 🔗 유사한 논문
- [[2025-09-22/Perception-R1_ Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward_20250922|Perception-R1: Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward]] (88.3% similar)
- [[2025-09-22/Think, Verbalize, then Speak_ Bridging Complex Thoughts and Comprehensible Speech_20250922|Think, Verbalize, then Speak: Bridging Complex Thoughts and Comprehensible Speech]] (86.8% similar)
- [[2025-09-22/Temporal Reasoning with Large Language Models Augmented by Evolving Knowledge Graphs_20250922|Temporal Reasoning with Large Language Models Augmented by Evolving Knowledge Graphs]] (86.4% similar)
- [[2025-09-23/Reasoning Core_ A Scalable RL Environment for LLM Symbolic Reasoning_20250923|Reasoning Core: A Scalable RL Environment for LLM Symbolic Reasoning]] (86.1% similar)
- [[2025-09-19/WebCoT_ Enhancing Web Agent Reasoning by Reconstructing Chain-of-Thought in Reflection, Branching, and Rollback_20250919|WebCoT: Enhancing Web Agent Reasoning by Reconstructing Chain-of-Thought in Reflection, Branching, and Rollback]] (85.9% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**⚡ Unique Technical**: [[keywords/ProReason Framework|ProReason Framework]], [[keywords/Decoupled Vision-Reasoning|Decoupled Vision-Reasoning]]
**🚀 Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2410.14138v4 Announce Type: replace-cross 
Abstract: Large vision-language models (LVLMs) have witnessed significant progress on visual understanding tasks. However, they often prioritize language knowledge over image information on visual reasoning tasks, incurring performance degradation. To tackle this issue, we first identify the drawbacks of existing solutions (i.e., limited multi-modal reasoning capacities, and insufficient and irrelevant visual descriptions). We then decompose visual reasoning process into two stages: proactive visual perception (i.e., eyesight) and textual reasoning (i.e., wisdom), and introduce a novel visual reasoning framework named ProReason. This framework features decoupled vision-reasoning capabilities and multi-run proactive perception. Briefly, given a multi-modal question, ProReason iterates proactive information collection and reasoning until the answer can be concluded with necessary and sufficient visual descriptions. Notably, the disassociation of capabilities allows seamless integration of existing large language models (LLMs) to compensate for the reasoning deficits of LVLMs. Our extensive experiments demonstrate that ProReason outperforms existing multi-step reasoning frameworks on various benchmarks for both open-source and closed-source models, with the average performance gain reaching 13.2%. Besides, the integration of LLMs allows ProReason to produce high-quality visual reasoning data, which empowers ProReason-distilled models (i.e., ProReason-VL and ProReason-Q3) to achieve superior performance in downstream tasks. Our insights into existing solutions and the decoupled perspective for feasible integration of LLMs illuminate future research on visual reasoning techniques, especially LLM-assisted ones.

## 📝 요약

대형 비전-언어 모델(LVLM)은 시각적 이해 작업에서 큰 발전을 이루었지만, 시각적 추론 작업에서는 언어 지식을 우선시하여 성능 저하를 겪습니다. 이를 해결하기 위해, 기존 솔루션의 한계(제한된 다중 모달 추론 능력, 불충분하고 관련 없는 시각적 설명)를 식별하고, 시각적 추론 과정을 '적극적 시각 인식'과 '텍스트 추론'의 두 단계로 분해한 새로운 프레임워크 ProReason을 소개합니다. ProReason은 분리된 시각-추론 능력과 다중 실행 적극적 인식을 특징으로 하며, 기존 대형 언어 모델(LLM)을 통합하여 LVLM의 추론 결함을 보완합니다. 실험 결과, ProReason은 다양한 벤치마크에서 기존 다중 단계 추론 프레임워크보다 평균 13.2%의 성능 향상을 보였습니다. 또한, LLM 통합을 통해 고품질 시각 추론 데이터를 생성하여 ProReason-증류 모델이 하위 작업에서 뛰어난 성능을 발휘하도록 합니다. 이러한 연구는 LLM 지원 시각 추론 기술의 미래 연구에 대한 통찰을 제공합니다.

## 🎯 주요 포인트

- 1. 대형 비전-언어 모델(LVLM)은 시각적 이해 작업에서 상당한 진전을 보였으나, 시각적 추론 작업에서는 언어 지식을 우선시하여 성능 저하를 초래한다.
- 2. 기존 솔루션의 한계를 극복하기 위해 시각적 추론 과정을 '적극적 시각 인식'과 '텍스트 추론'의 두 단계로 분해한 새로운 프레임워크 ProReason을 제안한다.
- 3. ProReason은 시각-추론 능력을 분리하고, 다중 실행을 통한 적극적 인식을 특징으로 하며, 필요한 시각적 설명이 충분할 때까지 정보를 수집하고 추론을 반복한다.
- 4. ProReason은 기존의 다단계 추론 프레임워크를 능가하며, 평균 성능 향상이 13.2%에 이른다.
- 5. LLM의 통합은 ProReason이 고품질의 시각적 추론 데이터를 생성할 수 있게 하여, ProReason-증류 모델이 다운스트림 작업에서 우수한 성능을 발휘하도록 한다.


---

*Generated on 2025-09-24 00:40:11*