---
keywords:
  - Vision-Language Model
  - ProReason Framework
  - Decoupled Vision-Reasoning
  - Large Language Model
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2410.14138
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T00:40:11.157300",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Vision-Language Model",
    "ProReason Framework",
    "Decoupled Vision-Reasoning",
    "Large Language Model"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Vision-Language Model": 0.85,
    "ProReason Framework": 0.89,
    "Decoupled Vision-Reasoning": 0.82,
    "Large Language Model": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Vision-Language Models",
        "canonical": "Vision-Language Model",
        "aliases": [
          "LVLMs"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-Language Models are central to the paper's discussion on multi-modal reasoning, linking to trending research in multimodal AI.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.78,
        "link_intent_score": 0.85
      },
      {
        "surface": "ProReason",
        "canonical": "ProReason Framework",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "ProReason is a novel framework introduced in the paper, crucial for understanding its unique contribution to visual reasoning.",
        "novelty_score": 0.92,
        "connectivity_score": 0.65,
        "specificity_score": 0.91,
        "link_intent_score": 0.89
      },
      {
        "surface": "Decoupled Vision-Reasoning",
        "canonical": "Decoupled Vision-Reasoning",
        "aliases": [
          "Decoupled Eyesight and Wisdom"
        ],
        "category": "unique_technical",
        "rationale": "This concept is a core innovation in the paper, highlighting a new approach to integrating vision and reasoning processes.",
        "novelty_score": 0.78,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.82
      },
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are integral to the paper's framework, providing a bridge to existing knowledge in AI.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "multi-modal question",
      "visual descriptions",
      "performance gain"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Vision-Language Models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.78,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "ProReason",
      "resolved_canonical": "ProReason Framework",
      "decision": "linked",
      "scores": {
        "novelty": 0.92,
        "connectivity": 0.65,
        "specificity": 0.91,
        "link_intent": 0.89
      }
    },
    {
      "candidate_surface": "Decoupled Vision-Reasoning",
      "resolved_canonical": "Decoupled Vision-Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.78,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# ProReason: Multi-Modal Proactive Reasoning with Decoupled Eyesight and Wisdom

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2410.14138.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2410.14138](https://arxiv.org/abs/2410.14138)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Perception-R1_ Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward_20250922|Perception-R1: Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward]] (88.3% similar)
- [[2025-09-22/Think, Verbalize, then Speak_ Bridging Complex Thoughts and Comprehensible Speech_20250922|Think, Verbalize, then Speak: Bridging Complex Thoughts and Comprehensible Speech]] (86.8% similar)
- [[2025-09-22/Temporal Reasoning with Large Language Models Augmented by Evolving Knowledge Graphs_20250922|Temporal Reasoning with Large Language Models Augmented by Evolving Knowledge Graphs]] (86.4% similar)
- [[2025-09-23/Reasoning Core_ A Scalable RL Environment for LLM Symbolic Reasoning_20250923|Reasoning Core: A Scalable RL Environment for LLM Symbolic Reasoning]] (86.1% similar)
- [[2025-09-19/WebCoT_ Enhancing Web Agent Reasoning by Reconstructing Chain-of-Thought in Reflection, Branching, and Rollback_20250919|WebCoT: Enhancing Web Agent Reasoning by Reconstructing Chain-of-Thought in Reflection, Branching, and Rollback]] (85.9% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**âš¡ Unique Technical**: [[keywords/ProReason Framework|ProReason Framework]], [[keywords/Decoupled Vision-Reasoning|Decoupled Vision-Reasoning]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2410.14138v4 Announce Type: replace-cross 
Abstract: Large vision-language models (LVLMs) have witnessed significant progress on visual understanding tasks. However, they often prioritize language knowledge over image information on visual reasoning tasks, incurring performance degradation. To tackle this issue, we first identify the drawbacks of existing solutions (i.e., limited multi-modal reasoning capacities, and insufficient and irrelevant visual descriptions). We then decompose visual reasoning process into two stages: proactive visual perception (i.e., eyesight) and textual reasoning (i.e., wisdom), and introduce a novel visual reasoning framework named ProReason. This framework features decoupled vision-reasoning capabilities and multi-run proactive perception. Briefly, given a multi-modal question, ProReason iterates proactive information collection and reasoning until the answer can be concluded with necessary and sufficient visual descriptions. Notably, the disassociation of capabilities allows seamless integration of existing large language models (LLMs) to compensate for the reasoning deficits of LVLMs. Our extensive experiments demonstrate that ProReason outperforms existing multi-step reasoning frameworks on various benchmarks for both open-source and closed-source models, with the average performance gain reaching 13.2%. Besides, the integration of LLMs allows ProReason to produce high-quality visual reasoning data, which empowers ProReason-distilled models (i.e., ProReason-VL and ProReason-Q3) to achieve superior performance in downstream tasks. Our insights into existing solutions and the decoupled perspective for feasible integration of LLMs illuminate future research on visual reasoning techniques, especially LLM-assisted ones.

## ğŸ“ ìš”ì•½

ëŒ€í˜• ë¹„ì „-ì–¸ì–´ ëª¨ë¸(LVLM)ì€ ì‹œê°ì  ì´í•´ ì‘ì—…ì—ì„œ í° ë°œì „ì„ ì´ë£¨ì—ˆì§€ë§Œ, ì‹œê°ì  ì¶”ë¡  ì‘ì—…ì—ì„œëŠ” ì–¸ì–´ ì§€ì‹ì„ ìš°ì„ ì‹œí•˜ì—¬ ì„±ëŠ¥ ì €í•˜ë¥¼ ê²ªìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ê¸°ì¡´ ì†”ë£¨ì…˜ì˜ í•œê³„(ì œí•œëœ ë‹¤ì¤‘ ëª¨ë‹¬ ì¶”ë¡  ëŠ¥ë ¥, ë¶ˆì¶©ë¶„í•˜ê³  ê´€ë ¨ ì—†ëŠ” ì‹œê°ì  ì„¤ëª…)ë¥¼ ì‹ë³„í•˜ê³ , ì‹œê°ì  ì¶”ë¡  ê³¼ì •ì„ 'ì ê·¹ì  ì‹œê° ì¸ì‹'ê³¼ 'í…ìŠ¤íŠ¸ ì¶”ë¡ 'ì˜ ë‘ ë‹¨ê³„ë¡œ ë¶„í•´í•œ ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ ProReasonì„ ì†Œê°œí•©ë‹ˆë‹¤. ProReasonì€ ë¶„ë¦¬ëœ ì‹œê°-ì¶”ë¡  ëŠ¥ë ¥ê³¼ ë‹¤ì¤‘ ì‹¤í–‰ ì ê·¹ì  ì¸ì‹ì„ íŠ¹ì§•ìœ¼ë¡œ í•˜ë©°, ê¸°ì¡´ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ í†µí•©í•˜ì—¬ LVLMì˜ ì¶”ë¡  ê²°í•¨ì„ ë³´ì™„í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ProReasonì€ ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ê¸°ì¡´ ë‹¤ì¤‘ ë‹¨ê³„ ì¶”ë¡  í”„ë ˆì„ì›Œí¬ë³´ë‹¤ í‰ê·  13.2%ì˜ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ë˜í•œ, LLM í†µí•©ì„ í†µí•´ ê³ í’ˆì§ˆ ì‹œê° ì¶”ë¡  ë°ì´í„°ë¥¼ ìƒì„±í•˜ì—¬ ProReason-ì¦ë¥˜ ëª¨ë¸ì´ í•˜ìœ„ ì‘ì—…ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ë„ë¡ í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì—°êµ¬ëŠ” LLM ì§€ì› ì‹œê° ì¶”ë¡  ê¸°ìˆ ì˜ ë¯¸ë˜ ì—°êµ¬ì— ëŒ€í•œ í†µì°°ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ë¹„ì „-ì–¸ì–´ ëª¨ë¸(LVLM)ì€ ì‹œê°ì  ì´í•´ ì‘ì—…ì—ì„œ ìƒë‹¹í•œ ì§„ì „ì„ ë³´ì˜€ìœ¼ë‚˜, ì‹œê°ì  ì¶”ë¡  ì‘ì—…ì—ì„œëŠ” ì–¸ì–´ ì§€ì‹ì„ ìš°ì„ ì‹œí•˜ì—¬ ì„±ëŠ¥ ì €í•˜ë¥¼ ì´ˆë˜í•œë‹¤.
- 2. ê¸°ì¡´ ì†”ë£¨ì…˜ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ì‹œê°ì  ì¶”ë¡  ê³¼ì •ì„ 'ì ê·¹ì  ì‹œê° ì¸ì‹'ê³¼ 'í…ìŠ¤íŠ¸ ì¶”ë¡ 'ì˜ ë‘ ë‹¨ê³„ë¡œ ë¶„í•´í•œ ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ ProReasonì„ ì œì•ˆí•œë‹¤.
- 3. ProReasonì€ ì‹œê°-ì¶”ë¡  ëŠ¥ë ¥ì„ ë¶„ë¦¬í•˜ê³ , ë‹¤ì¤‘ ì‹¤í–‰ì„ í†µí•œ ì ê·¹ì  ì¸ì‹ì„ íŠ¹ì§•ìœ¼ë¡œ í•˜ë©°, í•„ìš”í•œ ì‹œê°ì  ì„¤ëª…ì´ ì¶©ë¶„í•  ë•Œê¹Œì§€ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³  ì¶”ë¡ ì„ ë°˜ë³µí•œë‹¤.
- 4. ProReasonì€ ê¸°ì¡´ì˜ ë‹¤ë‹¨ê³„ ì¶”ë¡  í”„ë ˆì„ì›Œí¬ë¥¼ ëŠ¥ê°€í•˜ë©°, í‰ê·  ì„±ëŠ¥ í–¥ìƒì´ 13.2%ì— ì´ë¥¸ë‹¤.
- 5. LLMì˜ í†µí•©ì€ ProReasonì´ ê³ í’ˆì§ˆì˜ ì‹œê°ì  ì¶”ë¡  ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ìˆê²Œ í•˜ì—¬, ProReason-ì¦ë¥˜ ëª¨ë¸ì´ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—…ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ë„ë¡ í•œë‹¤.


---

*Generated on 2025-09-24 00:40:11*