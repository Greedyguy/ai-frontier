---
keywords:
  - Large Language Model
  - Combinatorial Optimization
  - Reinforcement Learning
  - Supervised Fine-Tuning
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.16865
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T22:53:01.030976",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Combinatorial Optimization",
    "Reinforcement Learning",
    "Supervised Fine-Tuning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Combinatorial Optimization": 0.8,
    "Reinforcement Learning": 0.78,
    "Supervised Fine-Tuning": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Large Language Models"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's approach, linking to existing knowledge on LLMs.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Combinatorial Optimization",
        "canonical": "Combinatorial Optimization",
        "aliases": [
          "CO"
        ],
        "category": "unique_technical",
        "rationale": "The paper's focus is on solving combinatorial optimization problems, a distinct technical area.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Reinforcement Learning",
        "canonical": "Reinforcement Learning",
        "aliases": [
          "RL"
        ],
        "category": "specific_connectable",
        "rationale": "Used in the paper's methodology, connecting to reinforcement learning techniques.",
        "novelty_score": 0.4,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.78
      },
      {
        "surface": "Supervised Fine-Tuning",
        "canonical": "Supervised Fine-Tuning",
        "aliases": [
          "SFT"
        ],
        "category": "unique_technical",
        "rationale": "A specific training strategy discussed in the paper, relevant for linking training methodologies.",
        "novelty_score": 0.65,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "method",
      "evaluation",
      "solution"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Combinatorial Optimization",
      "resolved_canonical": "Combinatorial Optimization",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Reinforcement Learning",
      "resolved_canonical": "Reinforcement Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Supervised Fine-Tuning",
      "resolved_canonical": "Supervised Fine-Tuning",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Large Language Models as End-to-end Combinatorial Optimization Solvers

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16865.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.16865](https://arxiv.org/abs/2509.16865)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Are LLMs Better Formalizers than Solvers on Complex Problems?_20250922|Are LLMs Better Formalizers than Solvers on Complex Problems?]] (87.5% similar)
- [[2025-09-23/GPO_ Learning from Critical Steps to Improve LLM Reasoning_20250923|GPO: Learning from Critical Steps to Improve LLM Reasoning]] (85.8% similar)
- [[2025-09-22/Evaluating the Limitations of Local LLMs in Solving Complex Programming Challenges_20250922|Evaluating the Limitations of Local LLMs in Solving Complex Programming Challenges]] (85.4% similar)
- [[2025-09-19/Modular Machine Learning_ An Indispensable Path towards New-Generation Large Language Models_20250919|Modular Machine Learning: An Indispensable Path towards New-Generation Large Language Models]] (85.1% similar)
- [[2025-09-19/CodeLSI_ Leveraging Foundation Models for Automated Code Generation with Low-Rank Optimization and Domain-Specific Instruction Tuning_20250919|CodeLSI: Leveraging Foundation Models for Automated Code Generation with Low-Rank Optimization and Domain-Specific Instruction Tuning]] (84.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Reinforcement Learning|Reinforcement Learning]]
**âš¡ Unique Technical**: [[keywords/Combinatorial Optimization|Combinatorial Optimization]], [[keywords/Supervised Fine-Tuning|Supervised Fine-Tuning]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16865v1 Announce Type: new 
Abstract: Combinatorial optimization (CO) problems, central to decision-making scenarios like logistics and manufacturing, are traditionally solved using problem-specific algorithms requiring significant domain expertise. While large language models (LLMs) have shown promise in automating CO problem solving, existing approaches rely on intermediate steps such as code generation or solver invocation, limiting their generality and accessibility. This paper introduces a novel framework that empowers LLMs to serve as end-to-end CO solvers by directly mapping natural language problem descriptions to solutions. We propose a two-stage training strategy: supervised fine-tuning (SFT) imparts LLMs with solution generation patterns from domain-specific solvers, while a feasibility-and-optimality-aware reinforcement learning (FOARL) process explicitly mitigates constraint violations and refines solution quality. Evaluation across seven NP-hard CO problems shows that our method achieves a high feasibility rate and reduces the average optimality gap to 1.03-8.20% by tuning a 7B-parameter LLM, surpassing both general-purpose LLMs (e.g., GPT-4o), reasoning models (e.g., DeepSeek-R1), and domain-specific heuristics. Our method establishes a unified language-based pipeline for CO without extensive code execution or manual architectural adjustments for different problems, offering a general and language-driven alternative to traditional solver design while maintaining relative feasibility guarantees.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ í™œìš©í•˜ì—¬ ì¡°í•© ìµœì í™”(CO) ë¬¸ì œë¥¼ ìë™ìœ¼ë¡œ í•´ê²°í•˜ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ ë°©ë²•ë“¤ì€ ì½”ë“œ ìƒì„±ì´ë‚˜ ì†”ë²„ í˜¸ì¶œ ë“±ì˜ ì¤‘ê°„ ë‹¨ê³„ë¥¼ í•„ìš”ë¡œ í–ˆì§€ë§Œ, ì´ ì—°êµ¬ëŠ” ìì—°ì–´ ë¬¸ì œ ì„¤ëª…ì„ ì§ì ‘ ì†”ë£¨ì…˜ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ë°©ì‹ì„ ë„ì…í–ˆìŠµë‹ˆë‹¤. ë‘ ë‹¨ê³„ì˜ í›ˆë ¨ ì „ëµì„ ì‚¬ìš©í•˜ì—¬, ì²«ì§¸ë¡œ ì§€ë„ í•™ìŠµ(SFT)ì„ í†µí•´ LLMì´ ë„ë©”ì¸ë³„ ì†”ë²„ì˜ ì†”ë£¨ì…˜ ìƒì„± íŒ¨í„´ì„ í•™ìŠµí•˜ê³ , ë‘˜ì§¸ë¡œ ì œì•½ ì¡°ê±´ ìœ„ë°˜ì„ ì¤„ì´ê³  ì†”ë£¨ì…˜ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¤ëŠ” ê°•í™” í•™ìŠµ(FOARL)ì„ ì ìš©í–ˆìŠµë‹ˆë‹¤. 7ê°œì˜ NP-hard CO ë¬¸ì œì— ëŒ€í•œ í‰ê°€ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì€ ë†’ì€ ì‹¤í–‰ ê°€ëŠ¥ì„±ì„ ë³´ì´ë©° ìµœì ì„± ê²©ì°¨ë¥¼ 1.03-8.20%ë¡œ ì¤„ì˜€ìŠµë‹ˆë‹¤. ì´ëŠ” ê¸°ì¡´ì˜ ì¼ë°˜ ëª©ì  LLMì´ë‚˜ ë„ë©”ì¸ íŠ¹í™” íœ´ë¦¬ìŠ¤í‹±ì„ ëŠ¥ê°€í•˜ëŠ” ì„±ê³¼ë¡œ, ë‹¤ì–‘í•œ ë¬¸ì œì— ëŒ€í•œ í†µí•©ëœ ì–¸ì–´ ê¸°ë°˜ íŒŒì´í”„ë¼ì¸ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë³¸ ë…¼ë¬¸ì€ ìì—°ì–´ ë¬¸ì œ ì„¤ëª…ì„ ì§ì ‘ ì†”ë£¨ì…˜ìœ¼ë¡œ ë§¤í•‘í•˜ì—¬ LLMì„ ì¢…ë‹¨ ê°„ ì¡°í•© ìµœì í™” ë¬¸ì œ í•´ê²°ì‚¬ë¡œ í™œìš©í•˜ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤.
- 2. ì œì•ˆëœ ë‘ ë‹¨ê³„ì˜ í›ˆë ¨ ì „ëµì€ ê°ë…ëœ ë¯¸ì„¸ ì¡°ì •(SFT)ê³¼ ì œì•½ ìœ„ë°˜ì„ ì™„í™”í•˜ê³  ì†”ë£¨ì…˜ í’ˆì§ˆì„ ê°œì„ í•˜ëŠ” íƒ€ë‹¹ì„± ë° ìµœì ì„± ì¸ì‹ ê°•í™” í•™ìŠµ(FOARL) ê³¼ì •ì„ í¬í•¨í•©ë‹ˆë‹¤.
- 3. 7ê°œì˜ NP-ë‚œì´ë„ ì¡°í•© ìµœì í™” ë¬¸ì œì— ëŒ€í•œ í‰ê°€ì—ì„œ ì œì•ˆëœ ë°©ë²•ì€ ë†’ì€ íƒ€ë‹¹ì„± ë¹„ìœ¨ì„ ë‹¬ì„±í•˜ê³  í‰ê·  ìµœì ì„± ê²©ì°¨ë¥¼ 1.03-8.20%ë¡œ ì¤„ì˜€ìŠµë‹ˆë‹¤.
- 4. ë³¸ ë°©ë²•ì€ ì¼ë°˜ ëª©ì  LLM, ì¶”ë¡  ëª¨ë¸ ë° ë„ë©”ì¸ íŠ¹í™” íœ´ë¦¬ìŠ¤í‹±ì„ ëŠ¥ê°€í•˜ë©°, ë‹¤ì–‘í•œ ë¬¸ì œì— ëŒ€í•´ ì½”ë“œ ì‹¤í–‰ì´ë‚˜ ìˆ˜ë™ì ì¸ êµ¬ì¡° ì¡°ì • ì—†ì´ í†µí•©ëœ ì–¸ì–´ ê¸°ë°˜ íŒŒì´í”„ë¼ì¸ì„ ì œê³µí•©ë‹ˆë‹¤.
- 5. ì „í†µì ì¸ í•´ê²°ì‚¬ ì„¤ê³„ì— ëŒ€í•œ ì¼ë°˜ì ì´ê³  ì–¸ì–´ ì¤‘ì‹¬ì˜ ëŒ€ì•ˆì„ ì œì‹œí•˜ë©´ì„œ ìƒëŒ€ì  íƒ€ë‹¹ì„± ë³´ì¥ì„ ìœ ì§€í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-23 22:53:01*