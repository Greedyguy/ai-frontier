---
keywords:
  - SWE-Bench Pro
  - Long-Horizon Tasks
  - Large Language Model
  - Error Patterns in AI Models
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2509.16941
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:40:07.812642",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "SWE-Bench Pro",
    "Long-Horizon Tasks",
    "Large Language Model",
    "Error Patterns in AI Models"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "SWE-Bench Pro": 0.8,
    "Long-Horizon Tasks": 0.82,
    "Large Language Model": 0.78,
    "Error Patterns in AI Models": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "SWE-Bench Pro",
        "canonical": "SWE-Bench Pro",
        "aliases": [
          "SWE-BENCH PRO"
        ],
        "category": "unique_technical",
        "rationale": "Represents a new benchmark specifically designed for evaluating AI agents on complex software engineering tasks.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "Long-Horizon Tasks",
        "canonical": "Long-Horizon Tasks",
        "aliases": [
          "Extended Duration Tasks"
        ],
        "category": "specific_connectable",
        "rationale": "Highlights tasks that require extended time and complexity, relevant for evaluating AI capabilities in software engineering.",
        "novelty_score": 0.7,
        "connectivity_score": 0.75,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "Coding Models",
        "canonical": "Large Language Model",
        "aliases": [
          "AI Coding Models"
        ],
        "category": "broad_technical",
        "rationale": "Refers to AI models used for coding tasks, aligning with the broader category of large language models.",
        "novelty_score": 0.4,
        "connectivity_score": 0.85,
        "specificity_score": 0.6,
        "link_intent_score": 0.78
      },
      {
        "surface": "Error Patterns",
        "canonical": "Error Patterns in AI Models",
        "aliases": [
          "Failure Modes"
        ],
        "category": "specific_connectable",
        "rationale": "Understanding error patterns is crucial for improving AI model performance in complex tasks.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.72,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "benchmark",
      "problems",
      "repositories"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "SWE-Bench Pro",
      "resolved_canonical": "SWE-Bench Pro",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Long-Horizon Tasks",
      "resolved_canonical": "Long-Horizon Tasks",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.75,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Coding Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.85,
        "specificity": 0.6,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Error Patterns",
      "resolved_canonical": "Error Patterns in AI Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.72,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# SWE-Bench Pro: Can AI Agents Solve Long-Horizon Software Engineering Tasks?

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16941.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2509.16941](https://arxiv.org/abs/2509.16941)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-17/An Empirical Study on Failures in Automated Issue Solving_20250917|An Empirical Study on Failures in Automated Issue Solving]] (84.7% similar)
- [[2025-09-22/SeCodePLT_ A Unified Platform for Evaluating the Security of Code GenAI_20250922|SeCodePLT: A Unified Platform for Evaluating the Security of Code GenAI]] (82.5% similar)
- [[2025-09-19/SWE-QA_ Can Language Models Answer Repository-level Code Questions?_20250919|SWE-QA: Can Language Models Answer Repository-level Code Questions?]] (82.5% similar)
- [[2025-09-22/SWE-Effi_ Re-Evaluating Software AI Agent System Effectiveness Under Resource Constraints_20250922|SWE-Effi: Re-Evaluating Software AI Agent System Effectiveness Under Resource Constraints]] (82.0% similar)
- [[2025-09-19/SPICE_ An Automated SWE-Bench Labeling Pipeline for Issue Clarity, Test Coverage, and Effort Estimation_20250919|SPICE: An Automated SWE-Bench Labeling Pipeline for Issue Clarity, Test Coverage, and Effort Estimation]] (81.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Long-Horizon Tasks|Long-Horizon Tasks]], [[keywords/Error Patterns in AI Models|Error Patterns in AI Models]]
**âš¡ Unique Technical**: [[keywords/SWE-Bench Pro|SWE-Bench Pro]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16941v1 Announce Type: cross 
Abstract: We introduce SWE-Bench Pro, a substantially more challenging benchmark that builds upon the best practices of SWE-BENCH [25], but is explicitly designed to capture realistic, complex, enterprise-level problems beyond the scope of SWE-BENCH. SWE-BENCH PRO contains 1,865 problems sourced from a diverse set of 41 actively maintained repositories spanning business applications, B2B services, and developer tools. The benchmark is partitioned into a public set with open access to problems sourced from 11 repositories, a held-out set of 12 repositories and a commercial set of 18 proprietary repositories where we have formal partnership agreements with early-stage startups. Problems in the held-out and the commercial set are not publicly accessible, but we release results on the commercial set. Our benchmark features long-horizon tasks that may require hours to days for a professional software engineer to complete, often involving patches across multiple files and substantial code modifications. All tasks are human-verified and augmented with sufficient context to ensure resolvability. In our evaluation of widely used coding models, under a unified scaffold, we observe that their performance on SWE-Bench PRO remains below 25% (Pass@1), with GPT-5 achieving the highest score to date at 23.3%. To better understand these limitations, we cluster the failure modes observed in the collected agent trajectories for a clearer characterization of the error patterns exhibited by current models. Overall, SWE-BENCH PRO provides a contamination-resistant testbed that more faithfully captures the complexity and diversity of real-world software development, advancing the pursuit of truly autonomous software engineering agents at a professional level.

## ğŸ“ ìš”ì•½

SWE-Bench ProëŠ” ê¸°ì¡´ SWE-BENCHë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ì—¬ í˜„ì‹¤ì ì´ê³  ë³µì¡í•œ ê¸°ì—… ìˆ˜ì¤€ì˜ ë¬¸ì œë¥¼ ë‹¤ë£¨ëŠ” ë” ì–´ë ¤ìš´ ë²¤ì¹˜ë§ˆí¬ì…ë‹ˆë‹¤. ì´ ë²¤ì¹˜ë§ˆí¬ëŠ” 41ê°œì˜ ë‹¤ì–‘í•œ ì €ì¥ì†Œì—ì„œ ìˆ˜ì§‘ëœ 1,865ê°œì˜ ë¬¸ì œë¡œ êµ¬ì„±ë˜ë©°, ê³µê°œ ì„¸íŠ¸, ë¹„ê³µê°œ ì„¸íŠ¸, ìƒì—…ì  ì„¸íŠ¸ë¡œ ë‚˜ë‰©ë‹ˆë‹¤. ìƒì—…ì  ì„¸íŠ¸ëŠ” ì´ˆê¸° ìŠ¤íƒ€íŠ¸ì—…ê³¼ì˜ ê³µì‹ íŒŒíŠ¸ë„ˆì‹­ì„ í†µí•´ ì œê³µë©ë‹ˆë‹¤. ì´ ë²¤ì¹˜ë§ˆí¬ëŠ” ì—¬ëŸ¬ íŒŒì¼ì— ê±¸ì¹œ íŒ¨ì¹˜ì™€ ìƒë‹¹í•œ ì½”ë“œ ìˆ˜ì •ì´ í•„ìš”í•œ ì¥ê¸° ê³¼ì œë¥¼ í¬í•¨í•˜ë©°, ëª¨ë“  ê³¼ì œëŠ” í•´ê²° ê°€ëŠ¥í•˜ë„ë¡ ì¶©ë¶„í•œ ë§¥ë½ì´ ì œê³µë©ë‹ˆë‹¤. SWE-Bench Proì—ì„œ GPT-5ëŠ” 23.3%ì˜ ìµœê³  ì ìˆ˜ë¥¼ ê¸°ë¡í–ˆìœ¼ë©°, ì´ëŠ” í˜„ì¬ ëª¨ë¸ì˜ í•œê³„ë¥¼ ì´í•´í•˜ê¸° ìœ„í•œ ì˜¤ë¥˜ íŒ¨í„´ ë¶„ì„ì„ í†µí•´ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ë²¤ì¹˜ë§ˆí¬ëŠ” í˜„ì‹¤ ì„¸ê³„ì˜ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œì˜ ë³µì¡ì„±ê³¼ ë‹¤ì–‘ì„±ì„ ì˜ ë°˜ì˜í•˜ì—¬ ììœ¨ ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´ë§ ì—ì´ì „íŠ¸ ê°œë°œì„ ì´‰ì§„í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. SWE-Bench ProëŠ” ê¸°ì¡´ SWE-BENCHë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ì—¬ í˜„ì‹¤ì ì´ê³  ë³µì¡í•œ ê¸°ì—… ìˆ˜ì¤€ì˜ ë¬¸ì œë¥¼ ë‹¤ë£¨ê¸° ìœ„í•´ ì„¤ê³„ëœ ë”ìš± ë„ì „ì ì¸ ë²¤ì¹˜ë§ˆí¬ì…ë‹ˆë‹¤.
- 2. ì´ ë²¤ì¹˜ë§ˆí¬ëŠ” 41ê°œì˜ ë‹¤ì–‘í•œ ë¦¬í¬ì§€í† ë¦¬ì—ì„œ ìˆ˜ì§‘ëœ 1,865ê°œì˜ ë¬¸ì œë¥¼ í¬í•¨í•˜ë©°, ê³µê°œ ì„¸íŠ¸, ë¹„ê³µê°œ ì„¸íŠ¸, ìƒì—…ì  ì„¸íŠ¸ë¡œ êµ¬ë¶„ë©ë‹ˆë‹¤.
- 3. SWE-Bench Proì˜ ê³¼ì œëŠ” ì—¬ëŸ¬ íŒŒì¼ì— ê±¸ì¹œ íŒ¨ì¹˜ì™€ ìƒë‹¹í•œ ì½”ë“œ ìˆ˜ì •ì´ í•„ìš”í•œ ì¥ê¸° ê³¼ì œë¡œ, í•´ê²° ê°€ëŠ¥ì„±ì„ ë³´ì¥í•˜ê¸° ìœ„í•´ ì¶©ë¶„í•œ ë§¥ë½ì„ ì œê³µí•©ë‹ˆë‹¤.
- 4. SWE-Bench Proì—ì„œì˜ ì½”ë”© ëª¨ë¸ ì„±ëŠ¥ì€ 25% ë¯¸ë§Œ(Pass@1)ì´ë©°, GPT-5ê°€ í˜„ì¬ê¹Œì§€ ê°€ì¥ ë†’ì€ 23.3%ì˜ ì ìˆ˜ë¥¼ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤.
- 5. ì´ ë²¤ì¹˜ë§ˆí¬ëŠ” ì˜¤ì—¼ ì €í•­ì„±ì´ ë†’ì€ í…ŒìŠ¤íŠ¸ë² ë“œë¡œ, ì‹¤ì œ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œì˜ ë³µì¡ì„±ê³¼ ë‹¤ì–‘ì„±ì„ ì¶©ì‹¤íˆ ë°˜ì˜í•˜ì—¬ ììœ¨ ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´ë§ ì—ì´ì „íŠ¸ ê°œë°œì„ ì´‰ì§„í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 03:40:07*