---
keywords:
  - Neural Audio Codec
  - Transformer
  - CodecSep
  - CLAP-derived FiLM parameters
  - AudioSep
category: cs.LG
publish_date: 2025-09-23
arxiv_id: 2509.11717
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:09:44.870609",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Neural Audio Codec",
    "Transformer",
    "CodecSep",
    "CLAP-derived FiLM parameters",
    "AudioSep"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Neural Audio Codec": 0.78,
    "Transformer": 0.82,
    "CodecSep": 0.79,
    "CLAP-derived FiLM parameters": 0.68,
    "AudioSep": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Neural Audio Codec",
        "canonical": "Neural Audio Codec",
        "aliases": [
          "NAC"
        ],
        "category": "unique_technical",
        "rationale": "Represents a new class of models that optimize audio processing for edge devices.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Transformer masker",
        "canonical": "Transformer",
        "aliases": [
          "Transformer-based masker"
        ],
        "category": "broad_technical",
        "rationale": "Highlights the use of Transformer architecture in audio separation tasks.",
        "novelty_score": 0.4,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.82
      },
      {
        "surface": "CodecSep",
        "canonical": "CodecSep",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Introduces a novel model for efficient, universal source separation.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.79
      },
      {
        "surface": "CLAP-derived FiLM parameters",
        "canonical": "CLAP-derived FiLM parameters",
        "aliases": [
          "CLAP FiLM"
        ],
        "category": "unique_technical",
        "rationale": "Describes a specific modulation technique used in the model.",
        "novelty_score": 0.7,
        "connectivity_score": 0.5,
        "specificity_score": 0.75,
        "link_intent_score": 0.68
      },
      {
        "surface": "AudioSep",
        "canonical": "AudioSep",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Serves as a benchmark model for comparison in the study.",
        "novelty_score": 0.65,
        "connectivity_score": 0.55,
        "specificity_score": 0.7,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "text-guided",
      "compute-heavy",
      "open-domain benchmarks"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Neural Audio Codec",
      "resolved_canonical": "Neural Audio Codec",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Transformer masker",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "CodecSep",
      "resolved_canonical": "CodecSep",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "CLAP-derived FiLM parameters",
      "resolved_canonical": "CLAP-derived FiLM parameters",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.5,
        "specificity": 0.75,
        "link_intent": 0.68
      }
    },
    {
      "candidate_surface": "AudioSep",
      "resolved_canonical": "AudioSep",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.55,
        "specificity": 0.7,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# Neural Audio Codecs for Prompt-Driven Universal Source Separation

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.11717.pdf)
**Category**: cs.LG
**Published**: 2025-09-23
**ArXiv ID**: [2509.11717](https://arxiv.org/abs/2509.11717)

## 🔗 유사한 논문
- [[2025-09-22/FocalCodec-Stream_ Streaming Low-Bitrate Speech Coding via Causal Distillation_20250922|FocalCodec-Stream: Streaming Low-Bitrate Speech Coding via Causal Distillation]] (82.8% similar)
- [[2025-09-22/TISDiSS_ A Training-Time and Inference-Time Scalable Framework for Discriminative Source Separation_20250922|TISDiSS: A Training-Time and Inference-Time Scalable Framework for Discriminative Source Separation]] (80.9% similar)
- [[2025-09-19/Diffusion-Based Unsupervised Audio-Visual Speech Separation in Noisy Environments with Noise Prior_20250919|Diffusion-Based Unsupervised Audio-Visual Speech Separation in Noisy Environments with Noise Prior]] (80.0% similar)
- [[2025-09-23/QASTAnet_ A DNN-based Quality Metric for Spatial Audio_20250923|QASTAnet: A DNN-based Quality Metric for Spatial Audio]] (79.7% similar)
- [[2025-09-22/Comprehensive Evaluation of CNN-Based Audio Tagging Models on Resource-Constrained Devices_20250922|Comprehensive Evaluation of CNN-Based Audio Tagging Models on Resource-Constrained Devices]] (79.6% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Transformer|Transformer]]
**⚡ Unique Technical**: [[keywords/Neural Audio Codec|Neural Audio Codec]], [[keywords/CodecSep|CodecSep]], [[keywords/CLAP-derived FiLM parameters|CLAP-derived FiLM parameters]], [[keywords/AudioSep|AudioSep]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.11717v2 Announce Type: replace-cross 
Abstract: Text-guided source separation supports flexible audio editing across media and assistive applications, but existing models like AudioSep are too compute-heavy for edge deployment. Neural audio codec (NAC) models such as CodecFormer and SDCodec are compute-efficient but limited to fixed-class separation. We introduce CodecSep, the first NAC-based model for on-device universal, text-driven separation. CodecSep combines DAC compression with a Transformer masker modulated by CLAP-derived FiLM parameters. Across six open-domain benchmarks under matched training/prompt protocols, \textbf{CodecSep} surpasses \textbf{AudioSep} in separation fidelity (SI-SDR) while remaining competitive in perceptual quality (ViSQOL) and matching or exceeding fixed-stem baselines (TDANet, CodecFormer, SDCodec). In code-stream deployments, it needs just 1.35~GMACs end-to-end -- approximately $54\times$ less compute ($25\times$ architecture-only) than spectrogram-domain separators like AudioSep -- while remaining fully bitstream-compatible.

## 📝 요약

이 논문은 텍스트 기반 오디오 분리를 위한 새로운 모델인 CodecSep을 소개합니다. CodecSep은 Neural Audio Codec(NAC) 기반의 모델로, 장치 내에서 텍스트로 유도된 오디오 분리를 수행할 수 있습니다. 이 모델은 DAC 압축과 CLAP에서 유도된 FiLM 매개변수로 조정된 Transformer 마스커를 결합하여 작동합니다. CodecSep은 여섯 가지 오픈 도메인 벤치마크에서 기존의 AudioSep 모델보다 우수한 분리 충실도(SI-SDR)를 보여주며, 지각적 품질(ViSQOL)에서도 경쟁력을 유지합니다. 또한, 고정 클래스 기반 모델(TDANet, CodecFormer, SDCodec)과 비교하여 동등하거나 더 나은 성능을 보입니다. CodecSep은 코드 스트림 배포에서 1.35 GMACs만 필요로 하며, 이는 AudioSep과 같은 스펙트럼 도메인 분리기보다 약 54배 적은 계산량을 요구합니다.

## 🎯 주요 포인트

- 1. CodecSep은 최초의 NAC 기반 모델로, 텍스트 기반의 유연한 오디오 분리를 지원하며, 디바이스 상에서의 사용을 목표로 개발되었습니다.
- 2. CodecSep은 DAC 압축과 CLAP에서 유도된 FiLM 매개변수로 변조된 Transformer 마스크를 결합하여 작동합니다.
- 3. CodecSep은 여섯 개의 오픈 도메인 벤치마크에서 AudioSep을 능가하는 분리 충실도(SI-SDR)를 보여주며, 지각적 품질(ViSQOL)에서도 경쟁력을 유지합니다.
- 4. CodecSep은 코드 스트림 배포에서 단 1.35 GMACs의 연산만 필요로 하며, 이는 AudioSep과 같은 스펙트로그램 도메인 분리기보다 약 54배 적은 연산량을 요구합니다.


---

*Generated on 2025-09-24 03:09:44*