---
keywords:
  - Continual Multimodal Contrastive Learning
  - Multimodal Learning
  - Stability and Plasticity
  - Self-supervised Learning
category: cs.LG
publish_date: 2025-09-23
arxiv_id: 2503.14963
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T02:40:19.772647",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Continual Multimodal Contrastive Learning",
    "Multimodal Learning",
    "Stability and Plasticity",
    "Self-supervised Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Continual Multimodal Contrastive Learning": 0.88,
    "Multimodal Learning": 0.82,
    "Stability and Plasticity": 0.75,
    "Self-supervised Learning": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Continual Multimodal Contrastive Learning",
        "canonical": "Continual Multimodal Contrastive Learning",
        "aliases": [
          "CMCL"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel concept introduced in the paper, crucial for linking multimodal and continual learning research.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.88
      },
      {
        "surface": "Multimodal Contrastive Learning",
        "canonical": "Multimodal Learning",
        "aliases": [
          "MCL"
        ],
        "category": "specific_connectable",
        "rationale": "Connects to existing multimodal learning frameworks, enhancing cross-modal representation alignment.",
        "novelty_score": 0.55,
        "connectivity_score": 0.87,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "Stability and Plasticity",
        "canonical": "Stability and Plasticity",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Key principles in the paper's methodology, relevant for linking to cognitive and learning theories.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.75
      },
      {
        "surface": "Contrastive Learning",
        "canonical": "Self-supervised Learning",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "A core technique in the paper, linking to broader self-supervised learning strategies.",
        "novelty_score": 0.5,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Continual Multimodal Contrastive Learning",
      "resolved_canonical": "Continual Multimodal Contrastive Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "Multimodal Contrastive Learning",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.87,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Stability and Plasticity",
      "resolved_canonical": "Stability and Plasticity",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Contrastive Learning",
      "resolved_canonical": "Self-supervised Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# Continual Multimodal Contrastive Learning

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2503.14963.pdf)
**Category**: cs.LG
**Published**: 2025-09-23
**ArXiv ID**: [2503.14963](https://arxiv.org/abs/2503.14963)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Towards Robust Visual Continual Learning with Multi-Prototype Supervision_20250922|Towards Robust Visual Continual Learning with Multi-Prototype Supervision]] (86.5% similar)
- [[2025-09-22/Advances in Multimodal Adaptation and Generalization_ From Traditional Approaches to Foundation Models_20250922|Advances in Multimodal Adaptation and Generalization: From Traditional Approaches to Foundation Models]] (85.7% similar)
- [[2025-09-22/Global Pre-fixing, Local Adjusting_ A Simple yet Effective Contrastive Strategy for Continual Learning_20250922|Global Pre-fixing, Local Adjusting: A Simple yet Effective Contrastive Strategy for Continual Learning]] (85.3% similar)
- [[2025-09-22/Perception-R1_ Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward_20250922|Perception-R1: Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward]] (85.2% similar)
- [[2025-09-23/Can multimodal representation learning by alignment preserve modality-specific information?_20250923|Can multimodal representation learning by alignment preserve modality-specific information?]] (85.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]], [[keywords/Self-supervised Learning|Self-supervised Learning]]
**âš¡ Unique Technical**: [[keywords/Continual Multimodal Contrastive Learning|Continual Multimodal Contrastive Learning]], [[keywords/Stability and Plasticity|Stability and Plasticity]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2503.14963v3 Announce Type: replace 
Abstract: Multimodal Contrastive Learning (MCL) advances in aligning different modalities and generating multimodal representations in a joint space. By leveraging contrastive learning across diverse modalities, large-scale multimodal data enhances representational quality. However, a critical yet often overlooked challenge remains: multimodal data is rarely collected in a single process, and training from scratch is computationally expensive. Instead, emergent multimodal data can be used to optimize existing models gradually, i.e., models are trained on a sequence of modality pair data. We define this problem as Continual Multimodal Contrastive Learning (CMCL), an underexplored yet crucial research direction at the intersection of multimodal and continual learning. In this paper, we formulate CMCL through two specialized principles of stability and plasticity. We theoretically derive a novel optimization-based method, which projects updated gradients from dual sides onto subspaces where any gradient is prevented from interfering with the previously learned knowledge. Two upper bounds provide theoretical insights on both stability and plasticity in our solution. Beyond our theoretical contributions, we conduct experiments on multiple datasets by comparing our method against advanced continual learning baselines. The empirical results further support our claims and demonstrate the efficacy of our method. Our codes are available at https://github.com/Xiaohao-Liu/CMCL.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë‹¤ì–‘í•œ ëª¨ë‹¬ë¦¬í‹°ë¥¼ ì •ë ¬í•˜ê³  ë©€í‹°ëª¨ë‹¬ í‘œí˜„ì„ ìƒì„±í•˜ëŠ” ë©€í‹°ëª¨ë‹¬ ëŒ€ì¡° í•™ìŠµ(MCL)ì˜ ë°œì „ì„ ë‹¤ë£¹ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë©€í‹°ëª¨ë‹¬ ë°ì´í„°ë¥¼ í•œ ë²ˆì— ìˆ˜ì§‘í•˜ê¸° ì–´ë ¤ìš´ ì ê³¼ ì´ˆê¸°ë¶€í„° í•™ìŠµí•˜ëŠ” ë° ë“œëŠ” ë†’ì€ ê³„ì‚° ë¹„ìš©ì´ ë¬¸ì œë¡œ ì§€ì ë©ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ì ì§„ì ìœ¼ë¡œ ê¸°ì¡´ ëª¨ë¸ì„ ìµœì í™”í•˜ëŠ” ì—°ì† ë©€í‹°ëª¨ë‹¬ ëŒ€ì¡° í•™ìŠµ(CMCL)ì„ ì œì•ˆí•©ë‹ˆë‹¤. CMCLì€ ì•ˆì •ì„±ê³¼ ê°€ì†Œì„±ì´ë¼ëŠ” ë‘ ê°€ì§€ ì›ì¹™ì„ í†µí•´ ì´ë¡ ì ìœ¼ë¡œ ìƒˆë¡œìš´ ìµœì í™” ë°©ë²•ì„ ë„ì¶œí•˜ë©°, ì´ì „ì— í•™ìŠµëœ ì§€ì‹ì— ë°©í•´ê°€ ë˜ì§€ ì•Šë„ë¡ ì—…ë°ì´íŠ¸ëœ ê¸°ìš¸ê¸°ë¥¼ íˆ¬ì˜í•©ë‹ˆë‹¤. ì´ ë°©ë²•ì˜ ì•ˆì •ì„±ê³¼ ê°€ì†Œì„±ì— ëŒ€í•œ ì´ë¡ ì  í†µì°°ì„ ì œê³µí•˜ëŠ” ë‘ ê°œì˜ ìƒí•œì„ ì œì‹œí•˜ê³ , ì—¬ëŸ¬ ë°ì´í„°ì…‹ì—ì„œ ì‹¤í—˜ì„ í†µí•´ ê¸°ì¡´ ì—°ì† í•™ìŠµ ê¸°ë²•ê³¼ ë¹„êµí•˜ì—¬ ì œì•ˆëœ ë°©ë²•ì˜ íš¨ìœ¨ì„±ì„ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë‹¤ì¤‘ëª¨ë‹¬ ëŒ€ì¡° í•™ìŠµ(MCL)ì€ ë‹¤ì–‘í•œ ëª¨ë‹¬ë¦¬í‹°ë¥¼ ì •ë ¬í•˜ê³  ë‹¤ì¤‘ëª¨ë‹¬ í‘œí˜„ì„ ê³µë™ ê³µê°„ì—ì„œ ìƒì„±í•˜ëŠ” ë° ê¸°ì—¬í•œë‹¤.
- 2. ë‹¤ì¤‘ëª¨ë‹¬ ë°ì´í„°ë¥¼ í•œ ë²ˆì— ìˆ˜ì§‘í•˜ëŠ” ê²ƒì€ ë“œë¬¼ë©°, ì²˜ìŒë¶€í„° í•™ìŠµí•˜ëŠ” ê²ƒì€ ê³„ì‚° ë¹„ìš©ì´ ë§ì´ ë“ ë‹¤.
- 3. ì§€ì†ì  ë‹¤ì¤‘ëª¨ë‹¬ ëŒ€ì¡° í•™ìŠµ(CMCL)ì€ ë‹¤ì¤‘ëª¨ë‹¬ ë° ì§€ì† í•™ìŠµì˜ êµì°¨ì ì—ì„œ ì¤‘ìš”í•œ ì—°êµ¬ ë°©í–¥ìœ¼ë¡œ ì •ì˜ëœë‹¤.
- 4. CMCLì€ ì•ˆì •ì„±ê³¼ ê°€ì†Œì„±ì˜ ë‘ ê°€ì§€ ì›ì¹™ì„ í†µí•´ ì´ë¡ ì ìœ¼ë¡œ ìµœì í™” ê¸°ë°˜ ë°©ë²•ì„ ë„ì¶œí•œë‹¤.
- 5. ì‹¤í—˜ ê²°ê³¼ëŠ” ì´ë¡ ì  ê¸°ì—¬ë¥¼ ë’·ë°›ì¹¨í•˜ë©°, ì œì•ˆëœ ë°©ë²•ì˜ íš¨ëŠ¥ì„ ì…ì¦í•œë‹¤.


---

*Generated on 2025-09-24 02:40:19*