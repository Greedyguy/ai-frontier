---
keywords:
  - Deep Reinforcement Learning
  - Attention Mechanism
  - Dynamic Time Slot Assignment Problem
  - Scenario-based Planning
category: cs.LG
publish_date: 2025-09-23
arxiv_id: 2509.17870
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T01:58:44.170687",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Deep Reinforcement Learning",
    "Attention Mechanism",
    "Dynamic Time Slot Assignment Problem",
    "Scenario-based Planning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Deep Reinforcement Learning": 0.78,
    "Attention Mechanism": 0.81,
    "Dynamic Time Slot Assignment Problem": 0.79,
    "Scenario-based Planning": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Deep Reinforcement Learning",
        "canonical": "Deep Reinforcement Learning",
        "aliases": [
          "DRL"
        ],
        "category": "broad_technical",
        "rationale": "Deep Reinforcement Learning is a key methodology in the paper, linking it to broader machine learning contexts.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.78
      },
      {
        "surface": "Attention-based Deep Reinforcement Learning",
        "canonical": "Attention Mechanism",
        "aliases": [
          "Attention-based DRL"
        ],
        "category": "specific_connectable",
        "rationale": "The use of an attention mechanism within DRL is a specific technique that connects to existing research on attention models.",
        "novelty_score": 0.58,
        "connectivity_score": 0.85,
        "specificity_score": 0.82,
        "link_intent_score": 0.81
      },
      {
        "surface": "Dynamic Time Slot Assignment Problem",
        "canonical": "Dynamic Time Slot Assignment Problem",
        "aliases": [
          "DTSAP"
        ],
        "category": "unique_technical",
        "rationale": "This is a unique problem definition central to the paper, providing a specific context for application of the methodologies discussed.",
        "novelty_score": 0.72,
        "connectivity_score": 0.65,
        "specificity_score": 0.91,
        "link_intent_score": 0.79
      },
      {
        "surface": "Scenario-based Planning",
        "canonical": "Scenario-based Planning",
        "aliases": [
          "SBP"
        ],
        "category": "unique_technical",
        "rationale": "Scenario-based Planning is a distinct approach in the paper, offering a unique perspective on problem-solving strategies.",
        "novelty_score": 0.68,
        "connectivity_score": 0.72,
        "specificity_score": 0.78,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "maintenance scheduling",
      "after-sales service"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Deep Reinforcement Learning",
      "resolved_canonical": "Deep Reinforcement Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Attention-based Deep Reinforcement Learning",
      "resolved_canonical": "Attention Mechanism",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.85,
        "specificity": 0.82,
        "link_intent": 0.81
      }
    },
    {
      "candidate_surface": "Dynamic Time Slot Assignment Problem",
      "resolved_canonical": "Dynamic Time Slot Assignment Problem",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.65,
        "specificity": 0.91,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Scenario-based Planning",
      "resolved_canonical": "Scenario-based Planning",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.72,
        "specificity": 0.78,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Improving After-sales Service: Deep Reinforcement Learning for Dynamic Time Slot Assignment with Commitments and Customer Preferences

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17870.pdf)
**Category**: cs.LG
**Published**: 2025-09-23
**ArXiv ID**: [2509.17870](https://arxiv.org/abs/2509.17870)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Digital Twin-based Cooperative Autonomous Driving in Smart Intersections_ A Multi-Agent Reinforcement Learning Approach_20250919|Digital Twin-based Cooperative Autonomous Driving in Smart Intersections: A Multi-Agent Reinforcement Learning Approach]] (81.3% similar)
- [[2025-09-19/An Explainable AI Framework for Dynamic Resource Management in Vehicular Network Slicing_20250919|An Explainable AI Framework for Dynamic Resource Management in Vehicular Network Slicing]] (81.2% similar)
- [[2025-09-22/cadrille_ Multi-modal CAD Reconstruction with Online Reinforcement Learning_20250922|cadrille: Multi-modal CAD Reconstruction with Online Reinforcement Learning]] (80.9% similar)
- [[2025-09-22/Hierarchical Reinforcement Learning with Low-Level MPC for Multi-Agent Control_20250922|Hierarchical Reinforcement Learning with Low-Level MPC for Multi-Agent Control]] (80.3% similar)
- [[2025-09-18/SHaRe-RL_ Structured, Interactive Reinforcement Learning for Contact-Rich Industrial Assembly Tasks_20250918|SHaRe-RL: Structured, Interactive Reinforcement Learning for Contact-Rich Industrial Assembly Tasks]] (80.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Deep Reinforcement Learning|Deep Reinforcement Learning]]
**ğŸ”— Specific Connectable**: [[keywords/Attention Mechanism|Attention Mechanism]]
**âš¡ Unique Technical**: [[keywords/Dynamic Time Slot Assignment Problem|Dynamic Time Slot Assignment Problem]], [[keywords/Scenario-based Planning|Scenario-based Planning]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17870v1 Announce Type: new 
Abstract: Problem definition: For original equipment manufacturers (OEMs), high-tech maintenance is a strategic component in after-sales services, involving close coordination between customers and service engineers. Each customer suggests several time slots for their maintenance task, from which the OEM must select one. This decision needs to be made promptly to support customers' planning. At the end of each day, routes for service engineers are planned to fulfill the tasks scheduled for the following day. We study this hierarchical and sequential decision-making problem-the Dynamic Time Slot Assignment Problem with Commitments and Customer Preferences (DTSAP-CCP)-in this paper. Methodology/results: Two distinct approaches are proposed: 1) an attention-based deep reinforcement learning with rollout execution (ADRL-RE) and 2) a scenario-based planning approach (SBP). The ADRL-RE combines a well-trained attention-based neural network with a rollout framework for online trajectory simulation. To support the training, we develop a neural heuristic solver that provides rapid route planning solutions, enabling efficient learning in complex combinatorial settings. The SBP approach samples several scenarios to guide the time slot assignment. Numerical experiments demonstrate the superiority of ADRL-RE and the stability of SBP compared to both rule-based and rollout-based approaches. Furthermore, the strong practicality of ADRL-RE is verified in a case study of after-sales service for large medical equipment. Implications: This study provides OEMs with practical decision-support tools for dynamic maintenance scheduling, balancing customer preferences and operational efficiency. In particular, our ADRL-RE shows strong real-world potential, supporting timely and customer-aligned maintenance scheduling.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì›ë˜ ì¥ë¹„ ì œì¡°ì—…ì²´(OEM)ë¥¼ ìœ„í•œ ë™ì  ìœ ì§€ë³´ìˆ˜ ì¼ì • ê³„íš ë¬¸ì œ(DTSAP-CCP)ë¥¼ ë‹¤ë£¨ë©°, ê³ ê°ì˜ ì„ í˜¸ ì‹œê°„ëŒ€ì™€ ìš´ì˜ íš¨ìœ¨ì„±ì„ ê· í˜• ìˆê²Œ ê³ ë ¤í•˜ëŠ” ë°©ë²•ë¡ ì„ ì œì•ˆí•©ë‹ˆë‹¤. ë‘ ê°€ì§€ ì ‘ê·¼ë²•ì´ ì œì‹œë˜ì—ˆëŠ”ë°, ì²«ì§¸ëŠ” ì£¼ì˜ ê¸°ë°˜ ì‹¬ì¸µ ê°•í™” í•™ìŠµê³¼ ë¡¤ì•„ì›ƒ ì‹¤í–‰ì„ ê²°í•©í•œ ADRL-REì´ë©°, ë‘˜ì§¸ëŠ” ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ ê³„íš ì ‘ê·¼ë²•(SBP)ì…ë‹ˆë‹¤. ADRL-REëŠ” ì˜¨ë¼ì¸ ê²½ë¡œ ì‹œë®¬ë ˆì´ì…˜ì„ í†µí•´ íš¨ìœ¨ì ì¸ í•™ìŠµì„ ì§€ì›í•˜ê³ , SBPëŠ” ì—¬ëŸ¬ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìƒ˜í”Œë§í•˜ì—¬ ì‹œê°„ëŒ€ í• ë‹¹ì„ ì•ˆë‚´í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ADRL-REëŠ” ê¸°ì¡´ ë°©ë²•ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë©°, íŠ¹íˆ ëŒ€í˜• ì˜ë£Œ ì¥ë¹„ì˜ ì• í”„í„°ì„œë¹„ìŠ¤ ì‚¬ë¡€ ì—°êµ¬ì—ì„œ ê·¸ ì‹¤ìš©ì„±ì´ ì…ì¦ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” OEMì—ê²Œ ê³ ê° ë§ì¶¤í˜• ìœ ì§€ë³´ìˆ˜ ì¼ì • ê³„íšì„ ìœ„í•œ ì‹¤ì§ˆì ì¸ ì˜ì‚¬ê²°ì • ì§€ì› ë„êµ¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë³¸ ì—°êµ¬ëŠ” OEMì˜ ì• í”„í„°ì„œë¹„ìŠ¤ì—ì„œ ê³ ê° ì„ í˜¸ë„ì™€ ìš´ì˜ íš¨ìœ¨ì„±ì„ ê· í˜• ìˆê²Œ ê³ ë ¤í•œ ë™ì  ìœ ì§€ë³´ìˆ˜ ì¼ì • ê³„íšì„ ìœ„í•œ ì‹¤ì§ˆì ì¸ ì˜ì‚¬ê²°ì • ì§€ì› ë„êµ¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
- 2. ì£¼ì˜ ê¸°ë°˜ ì‹¬ì¸µ ê°•í™” í•™ìŠµê³¼ ë¡¤ì•„ì›ƒ ì‹¤í–‰(ADRL-RE) ë° ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ ê³„íš ì ‘ê·¼ë²•(SBP)ì´ë¼ëŠ” ë‘ ê°€ì§€ ë°©ë²•ë¡ ì„ ì œì•ˆí•©ë‹ˆë‹¤.
- 3. ADRL-REëŠ” ì£¼ì˜ ê¸°ë°˜ ì‹ ê²½ë§ê³¼ ë¡¤ì•„ì›ƒ í”„ë ˆì„ì›Œí¬ë¥¼ ê²°í•©í•˜ì—¬ ì˜¨ë¼ì¸ ê²½ë¡œ ì‹œë®¬ë ˆì´ì…˜ì„ ìˆ˜í–‰í•˜ë©°, ì‹ ê²½ íœ´ë¦¬ìŠ¤í‹± ì†”ë²„ë¥¼ ê°œë°œí•˜ì—¬ ë³µì¡í•œ ì¡°í•© ë¬¸ì œì—ì„œ íš¨ìœ¨ì ì¸ í•™ìŠµì„ ì§€ì›í•©ë‹ˆë‹¤.
- 4. ìˆ˜ì¹˜ ì‹¤í—˜ ê²°ê³¼, ADRL-REëŠ” ê·œì¹™ ê¸°ë°˜ ë° ë¡¤ì•„ì›ƒ ê¸°ë°˜ ì ‘ê·¼ë²•ì— ë¹„í•´ ìš°ìˆ˜ì„±ì„ ë³´ì˜€ìœ¼ë©°, SBPëŠ” ì•ˆì •ì„±ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.
- 5. ADRL-REì˜ ê°•ë ¥í•œ ì‹¤ìš©ì„±ì€ ëŒ€í˜• ì˜ë£Œ ì¥ë¹„ì˜ ì• í”„í„°ì„œë¹„ìŠ¤ ì‚¬ë¡€ ì—°êµ¬ì—ì„œ ê²€ì¦ë˜ì—ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 01:58:44*