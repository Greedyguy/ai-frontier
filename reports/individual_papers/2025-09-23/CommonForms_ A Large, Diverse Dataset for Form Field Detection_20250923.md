---
keywords:
  - Form Field Detection
  - Object Detection
  - CommonForms Dataset
  - FFDNet
  - High-Resolution Inputs
category: cs.LG
publish_date: 2025-09-23
arxiv_id: 2509.16506
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T02:09:43.838607",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Form Field Detection",
    "Object Detection",
    "CommonForms Dataset",
    "FFDNet",
    "High-Resolution Inputs"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Form Field Detection": 0.78,
    "Object Detection": 0.72,
    "CommonForms Dataset": 0.82,
    "FFDNet": 0.79,
    "High-Resolution Inputs": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "form field detection",
        "canonical": "Form Field Detection",
        "aliases": [
          "form detection",
          "field detection"
        ],
        "category": "unique_technical",
        "rationale": "This is a specific task central to the paper, providing a unique technical focus for linking.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "object detection",
        "canonical": "Object Detection",
        "aliases": [
          "object recognition"
        ],
        "category": "broad_technical",
        "rationale": "A well-known technique in computer vision, relevant for linking with other detection tasks.",
        "novelty_score": 0.45,
        "connectivity_score": 0.89,
        "specificity_score": 0.65,
        "link_intent_score": 0.72
      },
      {
        "surface": "CommonForms",
        "canonical": "CommonForms Dataset",
        "aliases": [
          "CommonForms"
        ],
        "category": "unique_technical",
        "rationale": "The dataset is a central contribution of the paper, offering a unique resource for linking.",
        "novelty_score": 0.8,
        "connectivity_score": 0.7,
        "specificity_score": 0.9,
        "link_intent_score": 0.82
      },
      {
        "surface": "FFDNet",
        "canonical": "FFDNet",
        "aliases": [
          "FFDNet-Small",
          "FFDNet-Large"
        ],
        "category": "unique_technical",
        "rationale": "These models are key contributions of the paper, relevant for linking with other form field detection models.",
        "novelty_score": 0.78,
        "connectivity_score": 0.66,
        "specificity_score": 0.88,
        "link_intent_score": 0.79
      },
      {
        "surface": "high-resolution inputs",
        "canonical": "High-Resolution Inputs",
        "aliases": [
          "high-res inputs"
        ],
        "category": "specific_connectable",
        "rationale": "This is a critical factor in the performance of detection models, relevant for linking with other image processing techniques.",
        "novelty_score": 0.6,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "web-scale dataset",
      "commercially available"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "form field detection",
      "resolved_canonical": "Form Field Detection",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "object detection",
      "resolved_canonical": "Object Detection",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.89,
        "specificity": 0.65,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "CommonForms",
      "resolved_canonical": "CommonForms Dataset",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.7,
        "specificity": 0.9,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "FFDNet",
      "resolved_canonical": "FFDNet",
      "decision": "linked",
      "scores": {
        "novelty": 0.78,
        "connectivity": 0.66,
        "specificity": 0.88,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "high-resolution inputs",
      "resolved_canonical": "High-Resolution Inputs",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# CommonForms: A Large, Diverse Dataset for Form Field Detection

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16506.pdf)
**Category**: cs.LG
**Published**: 2025-09-23
**ArXiv ID**: [2509.16506](https://arxiv.org/abs/2509.16506)

## 🔗 유사한 논문
- [[2025-09-22/Semantic Change Detection of Roads and Bridges_ A Fine-grained Dataset and Multimodal Frequency-driven Detector_20250922|Semantic Change Detection of Roads and Bridges: A Fine-grained Dataset and Multimodal Frequency-driven Detector]] (76.9% similar)
- [[2025-09-22/KatFishNet_ Detecting LLM-Generated Korean Text through Linguistic Feature Analysis_20250922|KatFishNet: Detecting LLM-Generated Korean Text through Linguistic Feature Analysis]] (76.9% similar)
- [[2025-09-22/FOVAL_ Calibration-Free and Subject-Invariant Fixation Depth Estimation Across Diverse Eye-Tracking Datasets_20250922|FOVAL: Calibration-Free and Subject-Invariant Fixation Depth Estimation Across Diverse Eye-Tracking Datasets]] (75.6% similar)
- [[2025-09-23/NUMINA_ A Natural Understanding Benchmark for Multi-dimensional Intelligence and Numerical Reasoning Abilities_20250923|NUMINA: A Natural Understanding Benchmark for Multi-dimensional Intelligence and Numerical Reasoning Abilities]] (75.5% similar)
- [[2025-09-22/ISP-AD_ A Large-Scale Real-World Dataset for Advancing Industrial Anomaly Detection with Synthetic and Real Defects_20250922|ISP-AD: A Large-Scale Real-World Dataset for Advancing Industrial Anomaly Detection with Synthetic and Real Defects]] (75.4% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Object Detection|Object Detection]]
**🔗 Specific Connectable**: [[keywords/High-Resolution Inputs|High-Resolution Inputs]]
**⚡ Unique Technical**: [[keywords/Form Field Detection|Form Field Detection]], [[keywords/CommonForms Dataset|CommonForms Dataset]], [[keywords/FFDNet|FFDNet]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.16506v1 Announce Type: cross 
Abstract: This paper introduces CommonForms, a web-scale dataset for form field detection. It casts the problem of form field detection as object detection: given an image of a page, predict the location and type (Text Input, Choice Button, Signature) of form fields. The dataset is constructed by filtering Common Crawl to find PDFs that have fillable elements. Starting with 8 million documents, the filtering process is used to arrive at a final dataset of roughly 55k documents that have over 450k pages. Analysis shows that the dataset contains a diverse mixture of languages and domains; one third of the pages are non-English, and among the 14 classified domains, no domain makes up more than 25% of the dataset.
  In addition, this paper presents a family of form field detectors, FFDNet-Small and FFDNet-Large, which attain a very high average precision on the CommonForms test set. Each model cost less than $500 to train. Ablation results show that high-resolution inputs are crucial for high-quality form field detection, and that the cleaning process improves data efficiency over using all PDFs that have fillable fields in Common Crawl. A qualitative analysis shows that they outperform a popular, commercially available PDF reader that can prepare forms. Unlike the most popular commercially available solutions, FFDNet can predict checkboxes in addition to text and signature fields. This is, to our knowledge, the first large scale dataset released for form field detection, as well as the first open source models. The dataset, models, and code will be released at https://github.com/jbarrow/commonforms

## 📝 요약

이 논문은 웹 규모의 양식 필드 감지를 위한 데이터셋인 CommonForms를 소개합니다. 양식 필드 감지를 객체 감지 문제로 접근하여 페이지 이미지에서 텍스트 입력, 선택 버튼, 서명 등의 필드 위치와 유형을 예측합니다. Common Crawl에서 필터링을 통해 작성된 이 데이터셋은 약 55,000개의 문서와 450,000개 이상의 페이지로 구성되어 있으며, 다양한 언어와 도메인을 포함합니다. 논문은 또한 FFDNet-Small과 FFDNet-Large라는 양식 필드 감지 모델을 제안하며, 이 모델들은 CommonForms 테스트 세트에서 높은 정밀도를 달성했습니다. 고해상도 입력이 양질의 감지에 중요하며, 데이터 정제 과정이 효율성을 높인다는 점을 발견했습니다. 이 모델들은 상용 PDF 리더보다 우수한 성능을 보이며, 텍스트와 서명 필드 외에 체크박스도 예측할 수 있습니다. 이는 양식 필드 감지를 위한 최초의 대규모 데이터셋과 오픈 소스 모델로, 관련 자료는 GitHub에서 공개될 예정입니다.

## 🎯 주요 포인트

- 1. CommonForms는 웹 규모의 양식 필드 감지를 위한 데이터셋으로, 페이지 이미지에서 양식 필드의 위치와 유형을 예측하는 객체 감지 문제로 정의됩니다.
- 2. 데이터셋은 Common Crawl에서 작성 가능 요소가 있는 PDF를 필터링하여 약 55,000개의 문서와 450,000개 이상의 페이지로 구성되었습니다.
- 3. FFDNet-Small과 FFDNet-Large라는 양식 필드 감지 모델은 CommonForms 테스트 세트에서 높은 평균 정밀도를 달성하며, 각 모델의 훈련 비용은 $500 미만입니다.
- 4. 고해상도 입력이 양질의 양식 필드 감지에 필수적이며, 데이터 정리 과정이 데이터 효율성을 향상시킵니다.
- 5. FFDNet은 텍스트 및 서명 필드 외에도 체크박스를 예측할 수 있으며, 이는 상업적으로 이용 가능한 솔루션과 비교하여 우수한 성능을 보입니다.


---

*Generated on 2025-09-24 02:09:43*