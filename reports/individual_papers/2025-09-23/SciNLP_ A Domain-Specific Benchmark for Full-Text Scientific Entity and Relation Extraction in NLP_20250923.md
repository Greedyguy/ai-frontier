---
keywords:
  - Natural Language Processing
  - Entity and Relation Extraction
  - Knowledge Graph
  - Full-Text Annotations
  - Supervised Models
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2509.07801
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T04:11:59.013229",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Natural Language Processing",
    "Entity and Relation Extraction",
    "Knowledge Graph",
    "Full-Text Annotations",
    "Supervised Models"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Natural Language Processing": 0.8,
    "Entity and Relation Extraction": 0.75,
    "Knowledge Graph": 0.78,
    "Full-Text Annotations": 0.7,
    "Supervised Models": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Natural Language Processing",
        "canonical": "Natural Language Processing",
        "aliases": [
          "NLP"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's domain, facilitating connections to a wide range of related research.",
        "novelty_score": 0.2,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.8
      },
      {
        "surface": "entity and relation extraction",
        "canonical": "Entity and Relation Extraction",
        "aliases": [
          "information extraction"
        ],
        "category": "specific_connectable",
        "rationale": "Key task in NLP, linking to various methodologies and applications in the field.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.75
      },
      {
        "surface": "knowledge graph",
        "canonical": "Knowledge Graph",
        "aliases": [
          "KG"
        ],
        "category": "specific_connectable",
        "rationale": "Important for understanding semantic relationships and enhancing downstream NLP applications.",
        "novelty_score": 0.4,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.78
      },
      {
        "surface": "full-text annotations",
        "canonical": "Full-Text Annotations",
        "aliases": [
          "complete text annotations"
        ],
        "category": "unique_technical",
        "rationale": "Unique aspect of the dataset, enabling comprehensive analysis and linking to annotation methodologies.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      },
      {
        "surface": "supervised models",
        "canonical": "Supervised Models",
        "aliases": [
          "supervised learning models"
        ],
        "category": "specific_connectable",
        "rationale": "Relevant for evaluating and comparing model performance on the dataset.",
        "novelty_score": 0.3,
        "connectivity_score": 0.82,
        "specificity_score": 0.7,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "structured information",
      "academic texts"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Natural Language Processing",
      "resolved_canonical": "Natural Language Processing",
      "decision": "linked",
      "scores": {
        "novelty": 0.2,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "entity and relation extraction",
      "resolved_canonical": "Entity and Relation Extraction",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "knowledge graph",
      "resolved_canonical": "Knowledge Graph",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "full-text annotations",
      "resolved_canonical": "Full-Text Annotations",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "supervised models",
      "resolved_canonical": "Supervised Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.82,
        "specificity": 0.7,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# SciNLP: A Domain-Specific Benchmark for Full-Text Scientific Entity and Relation Extraction in NLP

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.07801.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2509.07801](https://arxiv.org/abs/2509.07801)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/SciEvent_ Benchmarking Multi-domain Scientific Event Extraction_20250922|SciEvent: Benchmarking Multi-domain Scientific Event Extraction]] (83.8% similar)
- [[2025-09-22/A Benchmark for End-to-End Zero-Shot Biomedical Relation Extraction with LLMs_ Experiments with OpenAI Models_20250922|A Benchmark for End-to-End Zero-Shot Biomedical Relation Extraction with LLMs: Experiments with OpenAI Models]] (81.0% similar)
- [[2025-09-23/Automated Knowledge Graph Construction using Large Language Models and Sentence Complexity Modelling_20250923|Automated Knowledge Graph Construction using Large Language Models and Sentence Complexity Modelling]] (80.6% similar)
- [[2025-09-19/SNaRe_ Domain-aware Data Generation for Low-Resource Event Detection_20250919|SNaRe: Domain-aware Data Generation for Low-Resource Event Detection]] (80.0% similar)
- [[2025-09-22/DynamicNER_ A Dynamic, Multilingual, and Fine-Grained Dataset for LLM-based Named Entity Recognition_20250922|DynamicNER: A Dynamic, Multilingual, and Fine-Grained Dataset for LLM-based Named Entity Recognition]] (80.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Natural Language Processing|Natural Language Processing]]
**ğŸ”— Specific Connectable**: [[keywords/Entity and Relation Extraction|Entity and Relation Extraction]], [[keywords/Knowledge Graph|Knowledge Graph]], [[keywords/Supervised Models|Supervised Models]]
**âš¡ Unique Technical**: [[keywords/Full-Text Annotations|Full-Text Annotations]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.07801v3 Announce Type: replace 
Abstract: Structured information extraction from scientific literature is crucial for capturing core concepts and emerging trends in specialized fields. While existing datasets aid model development, most focus on specific publication sections due to domain complexity and the high cost of annotating scientific texts. To address this limitation, we introduce SciNLP--a specialized benchmark for full-text entity and relation extraction in the Natural Language Processing (NLP) domain. The dataset comprises 60 manually annotated full-text NLP publications, covering 7,072 entities and 1,826 relations. Compared to existing research, SciNLP is the first dataset providing full-text annotations of entities and their relationships in the NLP domain. To validate the effectiveness of SciNLP, we conducted comparative experiments with similar datasets and evaluated the performance of state-of-the-art supervised models on this dataset. Results reveal varying extraction capabilities of existing models across academic texts of different lengths. Cross-comparisons with existing datasets show that SciNLP achieves significant performance improvements on certain baseline models. Using models trained on SciNLP, we implemented automatic construction of a fine-grained knowledge graph for the NLP domain. Our KG has an average node degree of 3.2 per entity, indicating rich semantic topological information that enhances downstream applications. The dataset is publicly available at: https://github.com/AKADDC/SciNLP.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ê³¼í•™ ë¬¸í—Œì—ì„œ êµ¬ì¡°í™”ëœ ì •ë³´ ì¶”ì¶œì˜ ì¤‘ìš”ì„±ì„ ê°•ì¡°í•˜ë©°, NLP ë¶„ì•¼ì˜ ì „ì²´ í…ìŠ¤íŠ¸ ì—”í‹°í‹° ë° ê´€ê³„ ì¶”ì¶œì„ ìœ„í•œ SciNLPë¼ëŠ” ë²¤ì¹˜ë§ˆí¬ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. SciNLPëŠ” 60ê°œì˜ NLP ë…¼ë¬¸ì„ ìˆ˜ì‘ì—…ìœ¼ë¡œ ì£¼ì„ ì²˜ë¦¬í•˜ì—¬ 7,072ê°œì˜ ì—”í‹°í‹°ì™€ 1,826ê°œì˜ ê´€ê³„ë¥¼ í¬í•¨í•˜ê³  ìˆìœ¼ë©°, NLP ë¶„ì•¼ì—ì„œ ì „ì²´ í…ìŠ¤íŠ¸ ì£¼ì„ì„ ì œê³µí•˜ëŠ” ìµœì´ˆì˜ ë°ì´í„°ì…‹ì…ë‹ˆë‹¤. ë¹„êµ ì‹¤í—˜ì„ í†µí•´ SciNLPì˜ íš¨ê³¼ì„±ì„ ê²€ì¦í•˜ê³ , ìµœì‹  ê°ë… í•™ìŠµ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•œ ê²°ê³¼, ë‹¤ì–‘í•œ ê¸¸ì´ì˜ í•™ìˆ  í…ìŠ¤íŠ¸ì—ì„œ ëª¨ë¸ì˜ ì¶”ì¶œ ëŠ¥ë ¥ì´ ë‹¤ë¦„ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. SciNLPë¥¼ ì‚¬ìš©í•œ ëª¨ë¸ì€ íŠ¹ì • ê¸°ì¤€ ëª¨ë¸ì—ì„œ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì˜€ìœ¼ë©°, ì´ë¥¼ í†µí•´ ì„¸ë°€í•œ ì§€ì‹ ê·¸ë˜í”„ë¥¼ ìë™ ìƒì„±í•˜ì—¬ NLP ë¶„ì•¼ì˜ ì‘ìš©ì„ ê°•í™”í–ˆìŠµë‹ˆë‹¤. ë°ì´í„°ì…‹ì€ ê³µê°œì ìœ¼ë¡œ ì´ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. SciNLPëŠ” NLP ë¶„ì•¼ì—ì„œ ì „ì²´ í…ìŠ¤íŠ¸ì˜ ì—”í‹°í‹°ì™€ ê´€ê³„ ì¶”ì¶œì„ ìœ„í•œ ìµœì´ˆì˜ ë°ì´í„°ì…‹ìœ¼ë¡œ, 60ê°œì˜ ë…¼ë¬¸ì— ëŒ€í•´ ìˆ˜ì‘ì—…ìœ¼ë¡œ ì£¼ì„ì„ ë‹¬ì•˜ìŠµë‹ˆë‹¤.
- 2. SciNLP ë°ì´í„°ì…‹ì€ 7,072ê°œì˜ ì—”í‹°í‹°ì™€ 1,826ê°œì˜ ê´€ê³„ë¥¼ í¬í•¨í•˜ê³  ìˆìœ¼ë©°, ê¸°ì¡´ ë°ì´í„°ì…‹ê³¼ì˜ ë¹„êµ ì‹¤í—˜ì„ í†µí•´ ì„±ëŠ¥ì„ ê²€ì¦í–ˆìŠµë‹ˆë‹¤.
- 3. SciNLPë¥¼ í™œìš©í•œ ëª¨ë¸ì€ íŠ¹ì • ê¸°ì¤€ ëª¨ë¸ì—ì„œ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì—¬ì£¼ì—ˆìœ¼ë©°, ì´ë¥¼ í†µí•´ NLP ë¶„ì•¼ì— ëŒ€í•œ ì„¸ë°€í•œ ì§€ì‹ ê·¸ë˜í”„ë¥¼ ìë™ìœ¼ë¡œ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤.
- 4. êµ¬ì¶•ëœ ì§€ì‹ ê·¸ë˜í”„ëŠ” ì—”í‹°í‹°ë‹¹ í‰ê·  ë…¸ë“œ ì°¨ìˆ˜ê°€ 3.2ë¡œ, í’ë¶€í•œ ì˜ë¯¸ë¡ ì  ìœ„ìƒ ì •ë³´ë¥¼ ì œê³µí•˜ì—¬ í›„ì† ì‘ìš© í”„ë¡œê·¸ë¨ì„ ê°•í™”í•©ë‹ˆë‹¤.
- 5. SciNLP ë°ì´í„°ì…‹ì€ ê³µê°œì ìœ¼ë¡œ ì´ìš© ê°€ëŠ¥í•˜ë©°, ê´€ë ¨ ì •ë³´ëŠ” GitHubì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 04:11:59*