---
keywords:
  - Large Language Model
  - Contextual Robustness
  - Adaptive Distraction
  - Tree Search
  - Post-Training Optimization
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2502.01609
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:47:48.117236",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Contextual Robustness",
    "Adaptive Distraction",
    "Tree Search",
    "Post-Training Optimization"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Contextual Robustness": 0.8,
    "Adaptive Distraction": 0.78,
    "Tree Search": 0.77,
    "Post-Training Optimization": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "This is a central concept in the paper, linking it to the broader field of language models.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "contextual robustness",
        "canonical": "Contextual Robustness",
        "aliases": [
          "context robustness"
        ],
        "category": "unique_technical",
        "rationale": "This is a unique technical term introduced in the paper, crucial for understanding the model's performance under distraction.",
        "novelty_score": 0.75,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.8
      },
      {
        "surface": "adaptive distraction",
        "canonical": "Adaptive Distraction",
        "aliases": [
          "dynamic distraction"
        ],
        "category": "unique_technical",
        "rationale": "This term describes the novel method proposed in the paper, essential for linking to the methodology.",
        "novelty_score": 0.8,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "tree search",
        "canonical": "Tree Search",
        "aliases": [
          "automated tree search"
        ],
        "category": "specific_connectable",
        "rationale": "Tree search is a key technique used in the paper, linking it to algorithmic strategies.",
        "novelty_score": 0.5,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.77
      },
      {
        "surface": "post-training approaches",
        "canonical": "Post-Training Optimization",
        "aliases": [
          "post-training methods",
          "DPO"
        ],
        "category": "specific_connectable",
        "rationale": "This connects to strategies for improving model robustness, which is a significant focus of the paper.",
        "novelty_score": 0.55,
        "connectivity_score": 0.8,
        "specificity_score": 0.75,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "contextual robustness",
      "resolved_canonical": "Contextual Robustness",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "adaptive distraction",
      "resolved_canonical": "Adaptive Distraction",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "tree search",
      "resolved_canonical": "Tree Search",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "post-training approaches",
      "resolved_canonical": "Post-Training Optimization",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.8,
        "specificity": 0.75,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Adaptive Distraction: Probing LLM Contextual Robustness with Automated Tree Search

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2502.01609.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2502.01609](https://arxiv.org/abs/2502.01609)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/How Is LLM Reasoning Distracted by Irrelevant Context? An Analysis Using a Controlled Benchmark_20250923|How Is LLM Reasoning Distracted by Irrelevant Context? An Analysis Using a Controlled Benchmark]] (89.7% similar)
- [[2025-09-23/No Need for Explanations_ LLMs can implicitly learn from mistakes in-context_20250923|No Need for Explanations: LLMs can implicitly learn from mistakes in-context]] (87.0% similar)
- [[2025-09-22/From Judgment to Interference_ Early Stopping LLM Harmful Outputs via Streaming Content Monitoring_20250922|From Judgment to Interference: Early Stopping LLM Harmful Outputs via Streaming Content Monitoring]] (86.2% similar)
- [[2025-09-23/Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates_20250923|Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates]] (86.2% similar)
- [[2025-09-17/Simulating a Bias Mitigation Scenario in Large Language Models_20250917|Simulating a Bias Mitigation Scenario in Large Language Models]] (86.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Tree Search|Tree Search]], [[keywords/Post-Training Optimization|Post-Training Optimization]]
**âš¡ Unique Technical**: [[keywords/Contextual Robustness|Contextual Robustness]], [[keywords/Adaptive Distraction|Adaptive Distraction]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2502.01609v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) often struggle to maintain their original performance when faced with semantically coherent but task-irrelevant contextual information. Although prior studies have explored this issue using fixed-template or retrieval-based distractions, such static methods show limited effectiveness against contemporary models. To address this problem, we propose a dynamic distraction generation framework based on tree search, where the generation process is guided by model behavior. Without modifying the original question or answer, the method efficiently produces challenging adaptive distractions across multiple datasets, enabling systematic stress testing of LLMs' contextual robustness. Experiments on four benchmarks demonstrate that the generated distractions lead to an average performance drop of over 45\% for mainstream models. Further comparisons of mitigation strategies show that prompt-based optimization methods yield limited gains, whereas post-training approaches (e.g., DPO) significantly enhance the model's contextual robustness. The results indicate that these issues do not stem from knowledge deficits in LLMs, but from a fundamental inability to maintain consistent reasoning under contextual distraction, posing a major challenge to the reliability of LLMs in real-world applications. The code is publicly available at https://github.com/wyf23187/Adaptive_Distractions.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì´ ì˜ë¯¸ì ìœ¼ë¡œ ì¼ê´€ë˜ì§€ë§Œ ê³¼ì œì™€ ë¬´ê´€í•œ ë¬¸ë§¥ ì •ë³´ì— ì§ë©´í–ˆì„ ë•Œ ì„±ëŠ¥ì„ ìœ ì§€í•˜ê¸° ì–´ë ¤ìš´ ë¬¸ì œë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ëª¨ë¸ì˜ í–‰ë™ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ëŠ” íŠ¸ë¦¬ íƒìƒ‰ì„ í™œìš©í•œ ë™ì  ë°©í•´ ìš”ì†Œ ìƒì„± í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ì›ë˜ì˜ ì§ˆë¬¸ì´ë‚˜ ë‹µë³€ì„ ìˆ˜ì •í•˜ì§€ ì•Šê³ ë„ ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ì—ì„œ ì ì‘ì ì¸ ë°©í•´ ìš”ì†Œë¥¼ ìƒì„±í•˜ì—¬ LLMì˜ ë¬¸ë§¥ì  ê°•ì¸ì„±ì„ ì²´ê³„ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ìƒì„±ëœ ë°©í•´ ìš”ì†Œê°€ ì£¼ë¥˜ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê·  45% ì´ìƒ ê°ì†Œì‹œì¼°ìœ¼ë©°, í›„ì† í•™ìŠµ ë°©ë²•(DPO ë“±)ì´ ë¬¸ë§¥ì  ê°•ì¸ì„±ì„ í¬ê²Œ í–¥ìƒì‹œí‚´ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŠ” LLMì˜ ì§€ì‹ ë¶€ì¡±ì´ ì•„ë‹Œ, ë¬¸ë§¥ì  ë°©í•´ ìš”ì†Œ í•˜ì—ì„œ ì¼ê´€ëœ ì¶”ë¡ ì„ ìœ ì§€í•˜ëŠ” ë° ê·¼ë³¸ì ì¸ ì–´ë ¤ì›€ì´ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤. ì½”ë“œê°€ ê³µê°œë˜ì–´ ìˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ ì˜ë¯¸ì ìœ¼ë¡œ ì¼ê´€ë˜ì§€ë§Œ ì‘ì—…ê³¼ ë¬´ê´€í•œ ë§¥ë½ ì •ë³´ì— ì§ë©´í–ˆì„ ë•Œ ì›ë˜ ì„±ëŠ¥ì„ ìœ ì§€í•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªìŠµë‹ˆë‹¤.
- 2. ë³¸ ì—°êµ¬ëŠ” ëª¨ë¸ì˜ í–‰ë™ì— ì˜í•´ ìœ ë„ë˜ëŠ” íŠ¸ë¦¬ íƒìƒ‰ ê¸°ë°˜ì˜ ë™ì  ë°©í•´ ìš”ì†Œ ìƒì„± í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.
- 3. ìƒì„±ëœ ë°©í•´ ìš”ì†ŒëŠ” ì£¼ë¥˜ ëª¨ë¸ì˜ í‰ê·  ì„±ëŠ¥ì„ 45% ì´ìƒ ê°ì†Œì‹œì¼°ìœ¼ë©°, ì´ëŠ” LLMì˜ ë§¥ë½ì  ê°•ê±´ì„±ì„ ì²´ê³„ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.
- 4. í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ìµœì í™” ë°©ë²•ì€ ì œí•œëœ ì„±ê³¼ë¥¼ ë³´ì˜€ìœ¼ë‚˜, í›„ì† í›ˆë ¨ ì ‘ê·¼ë²•(DPO ë“±)ì€ ëª¨ë¸ì˜ ë§¥ë½ì  ê°•ê±´ì„±ì„ í¬ê²Œ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.
- 5. ì´ëŸ¬í•œ ë¬¸ì œëŠ” LLMì˜ ì§€ì‹ ê²°í•ì—ì„œ ê¸°ì¸í•œ ê²ƒì´ ì•„ë‹ˆë¼, ë§¥ë½ì  ë°©í•´ ìš”ì†Œ í•˜ì—ì„œ ì¼ê´€ëœ ì¶”ë¡ ì„ ìœ ì§€í•˜ì§€ ëª»í•˜ëŠ” ê·¼ë³¸ì ì¸ í•œê³„ì—ì„œ ë¹„ë¡¯ë©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 03:47:48*