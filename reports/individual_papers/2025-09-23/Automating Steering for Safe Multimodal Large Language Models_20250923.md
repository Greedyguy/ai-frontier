---
keywords:
  - Multimodal Learning
  - AutoSteer
  - Safety Awareness Score
  - Vision-Language Model
  - Attack Success Rate
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2507.13255
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T01:13:08.557857",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multimodal Learning",
    "AutoSteer",
    "Safety Awareness Score",
    "Vision-Language Model",
    "Attack Success Rate"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multimodal Learning": 0.79,
    "AutoSteer": 0.78,
    "Safety Awareness Score": 0.77,
    "Vision-Language Model": 0.75,
    "Attack Success Rate": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multimodal Large Language Models",
        "canonical": "Multimodal Learning",
        "aliases": [
          "MLLMs"
        ],
        "category": "specific_connectable",
        "rationale": "Connects to the trending concept of integrating multiple modalities in AI models.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.82,
        "link_intent_score": 0.79
      },
      {
        "surface": "AutoSteer",
        "canonical": "AutoSteer",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Represents a novel framework specifically designed for enhancing safety in MLLMs.",
        "novelty_score": 0.92,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.78
      },
      {
        "surface": "Safety Awareness Score",
        "canonical": "Safety Awareness Score",
        "aliases": [
          "SAS"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a new metric for evaluating safety in AI models, crucial for linking safety research.",
        "novelty_score": 0.87,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      },
      {
        "surface": "Vision-Language Model",
        "canonical": "Vision-Language Model",
        "aliases": [
          "Vision-Language"
        ],
        "category": "evolved_concepts",
        "rationale": "Highlights the integration of visual and textual data, a growing area in AI research.",
        "novelty_score": 0.6,
        "connectivity_score": 0.85,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      },
      {
        "surface": "Attack Success Rate",
        "canonical": "Attack Success Rate",
        "aliases": [
          "ASR"
        ],
        "category": "unique_technical",
        "rationale": "Measures the effectiveness of adversarial attacks, relevant for security-focused AI research.",
        "novelty_score": 0.7,
        "connectivity_score": 0.68,
        "specificity_score": 0.78,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "inference",
      "model",
      "safety"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multimodal Large Language Models",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.82,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "AutoSteer",
      "resolved_canonical": "AutoSteer",
      "decision": "linked",
      "scores": {
        "novelty": 0.92,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Safety Awareness Score",
      "resolved_canonical": "Safety Awareness Score",
      "decision": "linked",
      "scores": {
        "novelty": 0.87,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Vision-Language Model",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.85,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Attack Success Rate",
      "resolved_canonical": "Attack Success Rate",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.68,
        "specificity": 0.78,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# Automating Steering for Safe Multimodal Large Language Models

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2507.13255.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2507.13255](https://arxiv.org/abs/2507.13255)

## 🔗 유사한 논문
- [[2025-09-22/AdaSteer_ Your Aligned LLM is Inherently an Adaptive Jailbreak Defender_20250922|AdaSteer: Your Aligned LLM is Inherently an Adaptive Jailbreak Defender]] (89.5% similar)
- [[2025-09-22/Activation Space Interventions Can Be Transferred Between Large Language Models_20250922|Activation Space Interventions Can Be Transferred Between Large Language Models]] (86.6% similar)
- [[2025-09-22/Beyond Linear Steering_ Unified Multi-Attribute Control for Language Models_20250922|Beyond Linear Steering: Unified Multi-Attribute Control for Language Models]] (85.7% similar)
- [[2025-09-19/Enterprise AI Must Enforce Participant-Aware Access Control_20250919|Enterprise AI Must Enforce Participant-Aware Access Control]] (84.7% similar)
- [[2025-09-23/Large Language Models for Cyber Security_ A Systematic Literature Review_20250923|Large Language Models for Cyber Security: A Systematic Literature Review]] (84.5% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**⚡ Unique Technical**: [[keywords/AutoSteer|AutoSteer]], [[keywords/Safety Awareness Score|Safety Awareness Score]], [[keywords/Attack Success Rate|Attack Success Rate]]
**🚀 Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2507.13255v2 Announce Type: replace-cross 
Abstract: Recent progress in Multimodal Large Language Models (MLLMs) has unlocked powerful cross-modal reasoning abilities, but also raised new safety concerns, particularly when faced with adversarial multimodal inputs. To improve the safety of MLLMs during inference, we introduce a modular and adaptive inference-time intervention technology, AutoSteer, without requiring any fine-tuning of the underlying model. AutoSteer incorporates three core components: (1) a novel Safety Awareness Score (SAS) that automatically identifies the most safety-relevant distinctions among the model's internal layers; (2) an adaptive safety prober trained to estimate the likelihood of toxic outputs from intermediate representations; and (3) a lightweight Refusal Head that selectively intervenes to modulate generation when safety risks are detected. Experiments on LLaVA-OV and Chameleon across diverse safety-critical benchmarks demonstrate that AutoSteer significantly reduces the Attack Success Rate (ASR) for textual, visual, and cross-modal threats, while maintaining general abilities. These findings position AutoSteer as a practical, interpretable, and effective framework for safer deployment of multimodal AI systems.

## 📝 요약

최근 다중모달 대형 언어 모델(MLLMs)의 발전은 강력한 교차 모달 추론 능력을 가능하게 했지만, 적대적 다중모달 입력에 대한 새로운 안전성 문제도 제기했습니다. 이를 해결하기 위해, 우리는 모델의 미세 조정 없이도 추론 시 안전성을 향상시키는 AutoSteer라는 모듈형 적응형 개입 기술을 소개합니다. AutoSteer는 (1) 모델의 내부 층에서 안전성과 관련된 차이를 자동으로 식별하는 새로운 안전 인식 점수(SAS), (2) 중간 표현에서 유해한 출력 가능성을 추정하는 적응형 안전 탐지기, (3) 안전 위험이 감지될 때 생성 과정을 조절하는 경량 거부 헤드로 구성됩니다. 다양한 안전성 벤치마크에서의 실험 결과, AutoSteer는 텍스트, 시각 및 교차 모달 위협에 대한 공격 성공률(ASR)을 크게 줄이면서도 일반적인 능력을 유지함을 보여줍니다. 이러한 결과는 AutoSteer가 다중모달 AI 시스템의 안전한 배포를 위한 실용적이고 해석 가능한 효과적인 프레임워크임을 입증합니다.

## 🎯 주요 포인트

- 1. 최근 다중모달 대형 언어 모델(MLLMs)의 발전은 강력한 교차 모달 추론 능력을 제공하지만, 적대적 다중모달 입력에 대한 새로운 안전 문제를 제기합니다.
- 2. AutoSteer는 기본 모델의 미세 조정 없이 모듈형 및 적응형 추론 시간 개입 기술을 통해 MLLMs의 안전성을 향상시킵니다.
- 3. AutoSteer는 안전 인식 점수(SAS), 적응형 안전 탐침기, 경량 거부 헤드의 세 가지 핵심 구성 요소를 포함합니다.
- 4. AutoSteer는 다양한 안전 중요 벤치마크에서 텍스트, 시각 및 교차 모달 위협에 대한 공격 성공률(ASR)을 크게 줄입니다.
- 5. AutoSteer는 다중모달 AI 시스템의 안전한 배포를 위한 실용적이고 해석 가능하며 효과적인 프레임워크로 자리잡고 있습니다.


---

*Generated on 2025-09-24 01:13:08*