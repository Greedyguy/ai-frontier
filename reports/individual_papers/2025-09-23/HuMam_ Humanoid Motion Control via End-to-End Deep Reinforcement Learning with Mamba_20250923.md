---
keywords:
  - End-to-End Reinforcement Learning
  - Mamba Encoder
  - Proximal Policy Optimization
  - Humanoid Locomotion
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.18046
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T00:18:54.560130",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "End-to-End Reinforcement Learning",
    "Mamba Encoder",
    "Proximal Policy Optimization",
    "Humanoid Locomotion"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "End-to-End Reinforcement Learning": 0.78,
    "Mamba Encoder": 0.82,
    "Proximal Policy Optimization": 0.85,
    "Humanoid Locomotion": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "End-to-end reinforcement learning",
        "canonical": "End-to-End Reinforcement Learning",
        "aliases": [
          "E2E RL"
        ],
        "category": "broad_technical",
        "rationale": "This concept is central to the paper's approach and connects to broader discussions in machine learning.",
        "novelty_score": 0.45,
        "connectivity_score": 0.85,
        "specificity_score": 0.6,
        "link_intent_score": 0.78
      },
      {
        "surface": "Mamba encoder",
        "canonical": "Mamba Encoder",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "A unique component of the proposed framework, offering a novel approach to state fusion.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.82
      },
      {
        "surface": "Proximal Policy Optimization",
        "canonical": "Proximal Policy Optimization",
        "aliases": [
          "PPO"
        ],
        "category": "specific_connectable",
        "rationale": "A widely used algorithm in reinforcement learning, facilitating connections to similar works.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Humanoid locomotion",
        "canonical": "Humanoid Locomotion",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "A specific application area of the study, linking to research in robotics and biomechanics.",
        "novelty_score": 0.5,
        "connectivity_score": 0.75,
        "specificity_score": 0.78,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "training stability",
      "task performance",
      "energy saving"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "End-to-end reinforcement learning",
      "resolved_canonical": "End-to-End Reinforcement Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.85,
        "specificity": 0.6,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Mamba encoder",
      "resolved_canonical": "Mamba Encoder",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Proximal Policy Optimization",
      "resolved_canonical": "Proximal Policy Optimization",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Humanoid locomotion",
      "resolved_canonical": "Humanoid Locomotion",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.75,
        "specificity": 0.78,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# HuMam: Humanoid Motion Control via End-to-End Deep Reinforcement Learning with Mamba

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18046.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.18046](https://arxiv.org/abs/2509.18046)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/KungfuBot2_ Learning Versatile Motion Skills for Humanoid Whole-Body Control_20250923|KungfuBot2: Learning Versatile Motion Skills for Humanoid Whole-Body Control]] (85.2% similar)
- [[2025-09-18/Embracing Bulky Objects with Humanoid Robots_ Whole-Body Manipulation with Reinforcement Learning_20250918|Embracing Bulky Objects with Humanoid Robots: Whole-Body Manipulation with Reinforcement Learning]] (84.7% similar)
- [[2025-09-22/Hierarchical Reinforcement Learning with Low-Level MPC for Multi-Agent Control_20250922|Hierarchical Reinforcement Learning with Low-Level MPC for Multi-Agent Control]] (83.7% similar)
- [[2025-09-22/Implicit Kinodynamic Motion Retargeting for Human-to-humanoid Imitation Learning_20250922|Implicit Kinodynamic Motion Retargeting for Human-to-humanoid Imitation Learning]] (83.2% similar)
- [[2025-09-19/DreamControl_ Human-Inspired Whole-Body Humanoid Control for Scene Interaction via Guided Diffusion_20250919|DreamControl: Human-Inspired Whole-Body Humanoid Control for Scene Interaction via Guided Diffusion]] (82.9% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/End-to-End Reinforcement Learning|End-to-End Reinforcement Learning]]
**ğŸ”— Specific Connectable**: [[keywords/Proximal Policy Optimization|Proximal Policy Optimization]], [[keywords/Humanoid Locomotion|Humanoid Locomotion]]
**âš¡ Unique Technical**: [[keywords/Mamba Encoder|Mamba Encoder]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18046v1 Announce Type: cross 
Abstract: End-to-end reinforcement learning (RL) for humanoid locomotion is appealing for its compact perception-action mapping, yet practical policies often suffer from training instability, inefficient feature fusion, and high actuation cost. We present HuMam, a state-centric end-to-end RL framework that employs a single-layer Mamba encoder to fuse robot-centric states with oriented footstep targets and a continuous phase clock. The policy outputs joint position targets tracked by a low-level PD loop and is optimized with PPO. A concise six-term reward balances contact quality, swing smoothness, foot placement, posture, and body stability while implicitly promoting energy saving. On the JVRC-1 humanoid in mc-mujoco, HuMam consistently improves learning efficiency, training stability, and overall task performance over a strong feedforward baseline, while reducing power consumption and torque peaks. To our knowledge, this is the first end-to-end humanoid RL controller that adopts Mamba as the fusion backbone, demonstrating tangible gains in efficiency, stability, and control economy.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì—ì„œëŠ” íœ´ë¨¸ë…¸ì´ë“œ ë¡œë´‡ì˜ ë³´í–‰ì„ ìœ„í•œ ì¢…ë‹¨ê°„ ê°•í™”í•™ìŠµ(RL) í”„ë ˆì„ì›Œí¬ì¸ HuMamì„ ì œì•ˆí•©ë‹ˆë‹¤. HuMamì€ ë¡œë´‡ ì¤‘ì‹¬ ìƒíƒœì™€ ë°œê±¸ìŒ ëª©í‘œë¥¼ ë‹¨ì¼ ë ˆì´ì–´ Mamba ì¸ì½”ë”ë¡œ ìœµí•©í•˜ê³ , ì—°ì†ì ì¸ ìœ„ìƒ ì‹œê³„ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •ì±…ì„ ìµœì í™”í•©ë‹ˆë‹¤. ì •ì±…ì€ ê´€ì ˆ ìœ„ì¹˜ ëª©í‘œë¥¼ ì¶œë ¥í•˜ê³ , PPO ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ìµœì í™”ë©ë‹ˆë‹¤. ë³´ìƒì€ ì ‘ì´‰ í’ˆì§ˆ, ìŠ¤ìœ™ ë¶€ë“œëŸ¬ì›€, ë°œ ìœ„ì¹˜, ìì„¸, ì‹ ì²´ ì•ˆì •ì„±ì„ ê· í˜• ìˆê²Œ ê³ ë ¤í•˜ë©° ì—ë„ˆì§€ ì ˆì•½ì„ ì´‰ì§„í•©ë‹ˆë‹¤. HuMamì€ mc-mujocoì˜ JVRC-1 íœ´ë¨¸ë…¸ì´ë“œì—ì„œ í•™ìŠµ íš¨ìœ¨ì„±, ì•ˆì •ì„±, ê³¼ì œ ìˆ˜í–‰ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ê³ , ì „ë ¥ ì†Œë¹„ì™€ í† í¬ í”¼í¬ë¥¼ ì¤„ì…ë‹ˆë‹¤. Mambaë¥¼ ìœµí•© ë°±ë³¸ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ìµœì´ˆì˜ íœ´ë¨¸ë…¸ì´ë“œ RL ì»¨íŠ¸ë¡¤ëŸ¬ë¡œì„œ íš¨ìœ¨ì„±ê³¼ ì•ˆì •ì„±, ì œì–´ ê²½ì œì„±ì—ì„œ ì‹¤ì§ˆì ì¸ ê°œì„ ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. HuMamì€ ë¡œë´‡ ì¤‘ì‹¬ ìƒíƒœì™€ ë°œê±¸ìŒ ëª©í‘œë¥¼ ìœµí•©í•˜ëŠ” Mamba ì¸ì½”ë”ë¥¼ ì‚¬ìš©í•˜ì—¬ íš¨ìœ¨ì ì¸ í•™ìŠµê³¼ ì•ˆì •ì„±ì„ ì œê³µí•©ë‹ˆë‹¤.
- 2. ì •ì±…ì€ ì €ìˆ˜ì¤€ PD ë£¨í”„ê°€ ì¶”ì í•˜ëŠ” ê´€ì ˆ ìœ„ì¹˜ ëª©í‘œë¥¼ ì¶œë ¥í•˜ë©°, PPOë¡œ ìµœì í™”ë©ë‹ˆë‹¤.
- 3. ì—¬ì„¯ ê°€ì§€ ë³´ìƒ í•­ëª©ì€ ì ‘ì´‰ í’ˆì§ˆ, ìŠ¤ìœ™ ë¶€ë“œëŸ¬ì›€, ë°œ ìœ„ì¹˜, ìì„¸, ì‹ ì²´ ì•ˆì •ì„±ì„ ê· í˜• ìˆê²Œ ì¡°ì ˆí•˜ë©° ì—ë„ˆì§€ ì ˆì•½ì„ ì´‰ì§„í•©ë‹ˆë‹¤.
- 4. HuMamì€ mc-mujocoì˜ JVRC-1 íœ´ë¨¸ë…¸ì´ë“œì—ì„œ í•™ìŠµ íš¨ìœ¨ì„±, í›ˆë ¨ ì•ˆì •ì„±, ê³¼ì œ ì„±ëŠ¥ì„ ê°œì„ í•˜ê³  ì „ë ¥ ì†Œë¹„ì™€ í† í¬ í”¼í¬ë¥¼ ì¤„ì…ë‹ˆë‹¤.
- 5. Mambaë¥¼ ìœµí•© ë°±ë³¸ìœ¼ë¡œ ì±„íƒí•œ ìµœì´ˆì˜ íœ´ë¨¸ë…¸ì´ë“œ RL ì»¨íŠ¸ë¡¤ëŸ¬ë¡œ, íš¨ìœ¨ì„±, ì•ˆì •ì„±, ì œì–´ ê²½ì œì„±ì—ì„œ ì‹¤ì§ˆì ì¸ ì´ì ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.


---

*Generated on 2025-09-24 00:18:54*