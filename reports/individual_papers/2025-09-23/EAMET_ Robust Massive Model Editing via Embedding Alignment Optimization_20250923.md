---
keywords:
  - Large Language Model
  - Embedding Alignment
  - Model Editing
  - Transformer
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2505.11876
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:54:43.611958",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Embedding Alignment",
    "Model Editing",
    "Transformer"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Embedding Alignment": 0.78,
    "Model Editing": 0.8,
    "Transformer": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "large-scale language models"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's focus, linking to a widely discussed topic in NLP.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Embedding Alignment",
        "canonical": "Embedding Alignment",
        "aliases": [
          "embedding space alignment"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel approach to improve model editing reliability.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Model Editing",
        "canonical": "Model Editing",
        "aliases": [
          "knowledge update",
          "model update"
        ],
        "category": "specific_connectable",
        "rationale": "Key concept for modifying LLMs, relevant to ongoing research in model adaptability.",
        "novelty_score": 0.5,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Transformers",
        "canonical": "Transformer",
        "aliases": [
          "transformer models"
        ],
        "category": "broad_technical",
        "rationale": "Essential architecture for LLMs, facilitating connections across NLP research.",
        "novelty_score": 0.2,
        "connectivity_score": 0.85,
        "specificity_score": 0.6,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "robust",
      "efficacy",
      "metrics"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Embedding Alignment",
      "resolved_canonical": "Embedding Alignment",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Model Editing",
      "resolved_canonical": "Model Editing",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Transformers",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.2,
        "connectivity": 0.85,
        "specificity": 0.6,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# EAMET: Robust Massive Model Editing via Embedding Alignment Optimization

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2505.11876.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2505.11876](https://arxiv.org/abs/2505.11876)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/DualEdit_ Dual Editing for Knowledge Updating in Vision-Language Models_20250922|DualEdit: Dual Editing for Knowledge Updating in Vision-Language Models]] (86.5% similar)
- [[2025-09-23/WikiBigEdit_ Understanding the Limits of Lifelong Knowledge Editing in LLMs_20250923|WikiBigEdit: Understanding the Limits of Lifelong Knowledge Editing in LLMs]] (86.1% similar)
- [[2025-09-22/Temporal Reasoning with Large Language Models Augmented by Evolving Knowledge Graphs_20250922|Temporal Reasoning with Large Language Models Augmented by Evolving Knowledge Graphs]] (85.3% similar)
- [[2025-09-23/Diagnosing Model Editing via Knowledge Spectrum_20250923|Diagnosing Model Editing via Knowledge Spectrum]] (84.6% similar)
- [[2025-09-19/Middo_ Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning_20250919|Middo: Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning]] (83.9% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]], [[keywords/Transformer|Transformer]]
**ğŸ”— Specific Connectable**: [[keywords/Model Editing|Model Editing]]
**âš¡ Unique Technical**: [[keywords/Embedding Alignment|Embedding Alignment]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2505.11876v2 Announce Type: replace 
Abstract: Model editing techniques are essential for efficiently updating knowledge in large language models (LLMs). However, the effectiveness of existing approaches degrades in massive editing scenarios, particularly when evaluated with practical metrics. Their robustness is also limited in context-rich settings or when editing multiple facts of the same subject simultaneously. We attribute these failures to the embedding misalignment among knowledge items, which undermines editing reliability at scale. To address this, we propose EAMET (Embedding Alignment Model Editing in Transformers), which addresses this issue by aligning the space of key and residual embeddings. Extensive experiments across six LLMs and three datasets demonstrate that EAMET consistently outperforms existing methods, achieving about 90\% editing efficacy when editing 10k facts. Codes and datasets are publicly available at https://ybdai7.github.io/eamet-page/.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì—ì„œ ì§€ì‹ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ê¸° ìœ„í•œ ëª¨ë¸ í¸ì§‘ ê¸°ìˆ ì˜ í•œê³„ë¥¼ ì§€ì í•˜ê³ , ì´ë¥¼ ê°œì„ í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ë°©ë²•ë¡ ì¸ EAMETì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ ë°©ë²•ë“¤ì€ ëŒ€ê·œëª¨ í¸ì§‘ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ íš¨ê³¼ê°€ ë–¨ì–´ì§€ë©°, íŠ¹íˆ ì—¬ëŸ¬ ì‚¬ì‹¤ì„ ë™ì‹œì— í¸ì§‘í•  ë•Œì˜ ê°•ê±´ì„±ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ë¬¸ì œì˜ ì›ì¸ì€ ì§€ì‹ í•­ëª© ê°„ ì„ë² ë”© ë¶ˆì¼ì¹˜ì— ìˆë‹¤ê³  ë³´ê³ , EAMETì€ í‚¤ì™€ ì”ì—¬ ì„ë² ë”© ê³µê°„ì„ ì •ë ¬í•˜ì—¬ ì´ë¥¼ í•´ê²°í•©ë‹ˆë‹¤. ì—¬ì„¯ ê°œì˜ LLMê³¼ ì„¸ ê°œì˜ ë°ì´í„°ì…‹ì„ í™œìš©í•œ ì‹¤í—˜ ê²°ê³¼, EAMETì€ ê¸°ì¡´ ë°©ë²•ë“¤ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì´ë©°, 10,000ê°œì˜ ì‚¬ì‹¤ì„ í¸ì§‘í•  ë•Œ ì•½ 90%ì˜ í¸ì§‘ íš¨ìœ¨ì„±ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. ì½”ë“œì™€ ë°ì´í„°ì…‹ì€ ê³µê°œë˜ì–´ ìˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì—ì„œ ì§€ì‹ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ê¸° ìœ„í•´ ëª¨ë¸ í¸ì§‘ ê¸°ìˆ ì´ í•„ìˆ˜ì ì´ë‹¤.
- 2. ê¸°ì¡´ ë°©ë²•ë“¤ì€ ëŒ€ê·œëª¨ í¸ì§‘ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ íš¨ê³¼ê°€ ë–¨ì–´ì§€ë©°, íŠ¹íˆ ì‹¤ìš©ì ì¸ ì§€í‘œë¡œ í‰ê°€í•  ë•Œ ë”ìš± ê·¸ë ‡ë‹¤.
- 3. EAMETì€ í‚¤ ë° ì”ì—¬ ì„ë² ë”© ê³µê°„ì„ ì •ë ¬í•˜ì—¬ ì„ë² ë”© ë¶ˆì¼ì¹˜ë¥¼ í•´ê²°í•˜ê³ , ëŒ€ê·œëª¨ í¸ì§‘ì˜ ì‹ ë¢°ì„±ì„ ë†’ì¸ë‹¤.
- 4. EAMETì€ ì—¬ì„¯ ê°œì˜ LLMê³¼ ì„¸ ê°œì˜ ë°ì´í„°ì…‹ì— ê±¸ì¹œ ì‹¤í—˜ì—ì„œ ê¸°ì¡´ ë°©ë²•ì„ ëŠ¥ê°€í•˜ë©°, 10,000ê°œì˜ ì‚¬ì‹¤ì„ í¸ì§‘í•  ë•Œ ì•½ 90%ì˜ í¸ì§‘ íš¨ìœ¨ì„±ì„ ë‹¬ì„±í•œë‹¤.
- 5. EAMETì˜ ì½”ë“œì™€ ë°ì´í„°ì…‹ì€ ê³µê°œë˜ì–´ ìˆë‹¤.


---

*Generated on 2025-09-24 03:54:43*