---
keywords:
  - Large Language Model
  - Sequential-NIAH Benchmark
  - Needle Generation Pipelines
  - Long Context Information Extraction
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2504.04713
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:53:54.261713",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Sequential-NIAH Benchmark",
    "Needle Generation Pipelines",
    "Long Context Information Extraction"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Sequential-NIAH Benchmark": 0.78,
    "Needle Generation Pipelines": 0.7,
    "Long Context Information Extraction": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's focus on evaluating capabilities in processing long contexts.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Sequential-NIAH",
        "canonical": "Sequential-NIAH Benchmark",
        "aliases": [
          "NIAH"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a new benchmark specifically for evaluating LLMs, which is unique to this paper.",
        "novelty_score": 0.92,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Needle Generation Pipelines",
        "canonical": "Needle Generation Pipelines",
        "aliases": [
          "Needle Pipelines"
        ],
        "category": "unique_technical",
        "rationale": "Describes a specific method used within the benchmark, crucial for understanding its setup.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      },
      {
        "surface": "Long Contexts",
        "canonical": "Long Context Information Extraction",
        "aliases": [
          "Long Contexts"
        ],
        "category": "specific_connectable",
        "rationale": "Key challenge addressed by the benchmark, relevant for linking to broader LLM capabilities.",
        "novelty_score": 0.55,
        "connectivity_score": 0.78,
        "specificity_score": 0.68,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "benchmark",
      "evaluation model",
      "context lengths"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Sequential-NIAH",
      "resolved_canonical": "Sequential-NIAH Benchmark",
      "decision": "linked",
      "scores": {
        "novelty": 0.92,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Needle Generation Pipelines",
      "resolved_canonical": "Needle Generation Pipelines",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Long Contexts",
      "resolved_canonical": "Long Context Information Extraction",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.78,
        "specificity": 0.68,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# Sequential-NIAH: A Needle-In-A-Haystack Benchmark for Extracting Sequential Needles from Long Contexts

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2504.04713.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2504.04713](https://arxiv.org/abs/2504.04713)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/seqBench_ A Tunable Benchmark to Quantify Sequential Reasoning Limits of LLMs_20250923|seqBench: A Tunable Benchmark to Quantify Sequential Reasoning Limits of LLMs]] (86.2% similar)
- [[2025-09-23/Benchmarking Contextual and Paralinguistic Reasoning in Speech-LLMs_ A Case Study with In-the-Wild Data_20250923|Benchmarking Contextual and Paralinguistic Reasoning in Speech-LLMs: A Case Study with In-the-Wild Data]] (84.5% similar)
- [[2025-09-23/NUMINA_ A Natural Understanding Benchmark for Multi-dimensional Intelligence and Numerical Reasoning Abilities_20250923|NUMINA: A Natural Understanding Benchmark for Multi-dimensional Intelligence and Numerical Reasoning Abilities]] (84.3% similar)
- [[2025-09-23/From Easy to Hard_ The MIR Benchmark for Progressive Interleaved Multi-Image Reasoning_20250923|From Easy to Hard: The MIR Benchmark for Progressive Interleaved Multi-Image Reasoning]] (84.1% similar)
- [[2025-09-23/Evaluating CxG Generalisation in LLMs via Construction-Based NLI Fine Tuning_20250923|Evaluating CxG Generalisation in LLMs via Construction-Based NLI Fine Tuning]] (83.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Long Context Information Extraction|Long Context Information Extraction]]
**âš¡ Unique Technical**: [[keywords/Sequential-NIAH Benchmark|Sequential-NIAH Benchmark]], [[keywords/Needle Generation Pipelines|Needle Generation Pipelines]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2504.04713v3 Announce Type: replace 
Abstract: Evaluating the ability of large language models (LLMs) to process lengthy contexts is critical, especially for retrieving query-relevant information embedded within them. We introduce Sequential-NIAH, a benchmark specifically designed to evaluate the capability of LLMs to extract sequential information items (known as \emph{needles}) from long contexts. The benchmark includes three needle generation pipelines: synthetic-temporal, real-temporal, and real-logical orders, with context lengths ranging from 8K to 128K, which comprises 14,000 samples (2,000 for testing). To facilitate the evaluation of this benchmark, we trained an evaluation model that assesses the correctness of LLM responses by comparing their completeness and sequential consistency against the ground truth, which provides a more reliable evaluation metric than GPT-4 or Claude. We conducted experiments on six well-known LLMs, revealing that even the best-performing model achieved a maximum accuracy of only 63.50% on test set of this benchmark. Further analysis highlights the growing challenges posed by increasing the context length or the number of needles, underscoring substantial room for improvement of LLMs. Additionally, noise analysis validates the reliability and challenge of the benchmark, making Sequential-NIAH an important reference for advancing research on long text information extraction capabilities of LLMs.

## ğŸ“ ìš”ì•½

ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ê¸´ ë¬¸ë§¥ ì²˜ë¦¬ ëŠ¥ë ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•´ Sequential-NIAHë¼ëŠ” ë²¤ì¹˜ë§ˆí¬ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ì´ ë²¤ì¹˜ë§ˆí¬ëŠ” LLMì´ ê¸´ ë¬¸ë§¥ì—ì„œ ìˆœì°¨ì  ì •ë³´ í•­ëª©(ì´ë¥¸ë°” 'ë°”ëŠ˜')ì„ ì¶”ì¶œí•˜ëŠ” ëŠ¥ë ¥ì„ í‰ê°€í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ë²¤ì¹˜ë§ˆí¬ëŠ” í•©ì„±-ì‹œê°„ì , ì‹¤ì œ-ì‹œê°„ì , ì‹¤ì œ-ë…¼ë¦¬ì  ìˆœì„œì˜ ì„¸ ê°€ì§€ ë°”ëŠ˜ ìƒì„± íŒŒì´í”„ë¼ì¸ì„ í¬í•¨í•˜ë©°, ë¬¸ë§¥ ê¸¸ì´ëŠ” 8Kì—ì„œ 128Kê¹Œì§€ ë‹¤ì–‘í•˜ê³ , ì´ 14,000ê°œì˜ ìƒ˜í”Œ(í…ŒìŠ¤íŠ¸ìš© 2,000ê°œ)ì„ ì œê³µí•©ë‹ˆë‹¤. í‰ê°€ ëª¨ë¸ì„ í›ˆë ¨í•˜ì—¬ LLMì˜ ì‘ë‹µì„ ì •í™•ì„±, ì™„ì „ì„±, ìˆœì°¨ì  ì¼ê´€ì„±ì„ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•˜ì˜€ìœ¼ë©°, ì´ëŠ” GPT-4ë‚˜ Claudeë³´ë‹¤ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” í‰ê°€ ê¸°ì¤€ì„ ì œê³µí•©ë‹ˆë‹¤. ì—¬ì„¯ ê°œì˜ ìœ ëª…í•œ LLMì„ ëŒ€ìƒìœ¼ë¡œ ì‹¤í—˜í•œ ê²°ê³¼, ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë„ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ ìµœëŒ€ 63.50%ì˜ ì •í™•ë„ë¥¼ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤. ë¬¸ë§¥ ê¸¸ì´ ì¦ê°€ë‚˜ ë°”ëŠ˜ ìˆ˜ ì¦ê°€ì— ë”°ë¥¸ ë„ì „ ê³¼ì œë¥¼ ê°•ì¡°í•˜ë©°, LLMì˜ ê°œì„  ì—¬ì§€ê°€ í¼ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë…¸ì´ì¦ˆ ë¶„ì„ì„ í†µí•´ ë²¤ì¹˜ë§ˆí¬ì˜ ì‹ ë¢°ì„±ê³¼ ë„ì „ ê³¼ì œë¥¼ ê²€ì¦í•˜ì˜€ìœ¼ë©°, Sequential-NIAHëŠ” LLMì˜ ê¸´ í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ì¶œ ëŠ¥ë ¥ ì—°êµ¬ë¥¼ ë°œì „ì‹œí‚¤ëŠ” ì¤‘ìš”í•œ ì°¸ê³  ìë£Œê°€ ë©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Sequential-NIAHëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì´ ê¸´ ë¬¸ë§¥ì—ì„œ ìˆœì°¨ì  ì •ë³´ í•­ëª©ì„ ì¶”ì¶œí•˜ëŠ” ëŠ¥ë ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•´ ì„¤ê³„ëœ ë²¤ì¹˜ë§ˆí¬ì…ë‹ˆë‹¤.
- 2. ë²¤ì¹˜ë§ˆí¬ëŠ” í•©ì„±-ì‹œê°„ì , ì‹¤ì œ-ì‹œê°„ì , ì‹¤ì œ-ë…¼ë¦¬ì  ìˆœì„œì˜ ì„¸ ê°€ì§€ ë°”ëŠ˜ ìƒì„± íŒŒì´í”„ë¼ì¸ì„ í¬í•¨í•˜ë©°, ë¬¸ë§¥ ê¸¸ì´ëŠ” 8Kì—ì„œ 128Kê¹Œì§€ ë‹¤ì–‘í•©ë‹ˆë‹¤.
- 3. í‰ê°€ ëª¨ë¸ì€ LLMì˜ ì‘ë‹µì„ ì™„ì „ì„±ê³¼ ìˆœì°¨ì  ì¼ê´€ì„± ì¸¡ë©´ì—ì„œ ë¹„êµí•˜ì—¬ ì •í™•ì„±ì„ í‰ê°€í•˜ë©°, ì´ëŠ” GPT-4ë‚˜ Claudeë³´ë‹¤ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” í‰ê°€ ì²™ë„ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
- 4. ì‹¤í—˜ ê²°ê³¼, ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì€ ëª¨ë¸ë„ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ ìµœëŒ€ 63.50%ì˜ ì •í™•ë„ë¥¼ ê¸°ë¡í–ˆìœ¼ë©°, ë¬¸ë§¥ ê¸¸ì´ ì¦ê°€ë‚˜ ë°”ëŠ˜ ìˆ˜ ì¦ê°€ì— ë”°ë¥¸ ë„ì „ ê³¼ì œê°€ ë¶€ê°ë˜ì—ˆìŠµë‹ˆë‹¤.
- 5. Sequential-NIAHëŠ” LLMì˜ ê¸´ í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ì¶œ ëŠ¥ë ¥ ì—°êµ¬ë¥¼ ì§„ì „ì‹œí‚¤ê¸° ìœ„í•œ ì¤‘ìš”í•œ ì°¸ê³  ìë£Œë¡œ, ë…¸ì´ì¦ˆ ë¶„ì„ì„ í†µí•´ ë²¤ì¹˜ë§ˆí¬ì˜ ì‹ ë¢°ì„±ê³¼ ë„ì „ ê³¼ì œê°€ ê²€ì¦ë˜ì—ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 03:53:54*