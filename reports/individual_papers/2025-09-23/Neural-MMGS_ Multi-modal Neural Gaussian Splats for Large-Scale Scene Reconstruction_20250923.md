---
keywords:
  - Neural-MMGS
  - Multimodal Learning
  - LiDAR
  - Semantic Information
  - Neural Decoders
category: cs.CV
publish_date: 2025-09-23
arxiv_id: 2509.17762
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T05:02:24.555523",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Neural-MMGS",
    "Multimodal Learning",
    "LiDAR",
    "Semantic Information",
    "Neural Decoders"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Neural-MMGS": 0.8,
    "Multimodal Learning": 0.85,
    "LiDAR": 0.78,
    "Semantic Information": 0.77,
    "Neural Decoders": 0.65
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Neural-MMGS",
        "canonical": "Neural-MMGS",
        "aliases": [
          "Neural Multi-modal Gaussian Splats"
        ],
        "category": "unique_technical",
        "rationale": "Represents a novel framework for multimodal scene reconstruction, central to the paper's contribution.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "multimodal",
        "canonical": "Multimodal Learning",
        "aliases": [
          "multimodal"
        ],
        "category": "specific_connectable",
        "rationale": "Connects to the trend of integrating multiple data types for richer learning models.",
        "novelty_score": 0.5,
        "connectivity_score": 0.88,
        "specificity_score": 0.78,
        "link_intent_score": 0.85
      },
      {
        "surface": "LiDAR",
        "canonical": "LiDAR",
        "aliases": [
          "Light Detection and Ranging"
        ],
        "category": "specific_connectable",
        "rationale": "Key sensing modality used in the framework, essential for scene reconstruction.",
        "novelty_score": 0.55,
        "connectivity_score": 0.82,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "semantic information",
        "canonical": "Semantic Information",
        "aliases": [
          "semantics"
        ],
        "category": "specific_connectable",
        "rationale": "Provides high-level context crucial for enhancing scene reconstruction.",
        "novelty_score": 0.6,
        "connectivity_score": 0.79,
        "specificity_score": 0.75,
        "link_intent_score": 0.77
      },
      {
        "surface": "neural decoders",
        "canonical": "Neural Decoders",
        "aliases": [
          "decoders"
        ],
        "category": "broad_technical",
        "rationale": "Essential component for translating embeddings into usable parameters.",
        "novelty_score": 0.58,
        "connectivity_score": 0.7,
        "specificity_score": 0.72,
        "link_intent_score": 0.65
      }
    ],
    "ban_list_suggestions": [
      "framework",
      "approach",
      "method"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Neural-MMGS",
      "resolved_canonical": "Neural-MMGS",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "multimodal",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.88,
        "specificity": 0.78,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "LiDAR",
      "resolved_canonical": "LiDAR",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.82,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "semantic information",
      "resolved_canonical": "Semantic Information",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.79,
        "specificity": 0.75,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "neural decoders",
      "resolved_canonical": "Neural Decoders",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.7,
        "specificity": 0.72,
        "link_intent": 0.65
      }
    }
  ]
}
-->

# Neural-MMGS: Multi-modal Neural Gaussian Splats for Large-Scale Scene Reconstruction

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17762.pdf)
**Category**: cs.CV
**Published**: 2025-09-23
**ArXiv ID**: [2509.17762](https://arxiv.org/abs/2509.17762)

## 🔗 유사한 논문
- [[2025-09-22/MS-GS_ Multi-Appearance Sparse-View 3D Gaussian Splatting in the Wild_20250922|MS-GS: Multi-Appearance Sparse-View 3D Gaussian Splatting in the Wild]] (89.6% similar)
- [[2025-09-23/MedGS_ Gaussian Splatting for Multi-Modal 3D Medical Imaging_20250923|MedGS: Gaussian Splatting for Multi-Modal 3D Medical Imaging]] (87.0% similar)
- [[2025-09-23/HyRF_ Hybrid Radiance Fields for Memory-efficient and High-quality Novel View Synthesis_20250923|HyRF: Hybrid Radiance Fields for Memory-efficient and High-quality Novel View Synthesis]] (85.8% similar)
- [[2025-09-22/GS-Scale_ Unlocking Large-Scale 3D Gaussian Splatting Training via Host Offloading_20250922|GS-Scale: Unlocking Large-Scale 3D Gaussian Splatting Training via Host Offloading]] (84.4% similar)
- [[2025-09-23/3D Gaussian Flats_ Hybrid 2D/3D Photometric Scene Reconstruction_20250923|3D Gaussian Flats: Hybrid 2D/3D Photometric Scene Reconstruction]] (84.4% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Neural Decoders|Neural Decoders]]
**🔗 Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]], [[keywords/LiDAR|LiDAR]], [[keywords/Semantic Information|Semantic Information]]
**⚡ Unique Technical**: [[keywords/Neural-MMGS|Neural-MMGS]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.17762v1 Announce Type: new 
Abstract: This paper proposes Neural-MMGS, a novel neural 3DGS framework for multimodal large-scale scene reconstruction that fuses multiple sensing modalities in a per-gaussian compact, learnable embedding. While recent works focusing on large-scale scene reconstruction have incorporated LiDAR data to provide more accurate geometric constraints, we argue that LiDAR's rich physical properties remain underexplored. Similarly, semantic information has been used for object retrieval, but could provide valuable high-level context for scene reconstruction. Traditional approaches append these properties to Gaussians as separate parameters, increasing memory usage and limiting information exchange across modalities. Instead, our approach fuses all modalities -- image, LiDAR, and semantics -- into a compact, learnable embedding that implicitly encodes optical, physical, and semantic features in each Gaussian. We then train lightweight neural decoders to map these embeddings to Gaussian parameters, enabling the reconstruction of each sensing modality with lower memory overhead and improved scalability. We evaluate Neural-MMGS on the Oxford Spires and KITTI-360 datasets. On Oxford Spires, we achieve higher-quality reconstructions, while on KITTI-360, our method reaches competitive results with less storage consumption compared with current approaches in LiDAR-based novel-view synthesis.

## 📝 요약

이 논문은 Neural-MMGS라는 새로운 신경망 기반 3D 장면 재구성 프레임워크를 제안합니다. 이 프레임워크는 이미지, LiDAR, 의미론적 정보를 하나의 학습 가능한 임베딩으로 융합하여 대규모 장면을 재구성합니다. 기존 방법들은 LiDAR 데이터를 사용하여 기하학적 제약을 강화했지만, LiDAR의 물리적 특성을 충분히 활용하지 못했습니다. 또한, 의미론적 정보는 객체 검색에 사용되었으나 장면 재구성에 유용한 고수준의 문맥을 제공할 수 있습니다. Neural-MMGS는 이러한 정보를 개별 매개변수로 추가하는 대신, 모든 감지 모달리티를 하나의 임베딩에 융합하여 메모리 사용을 줄이고 확장성을 개선합니다. Oxford Spires와 KITTI-360 데이터셋을 통해 평가한 결과, Oxford Spires에서는 더 높은 품질의 재구성을, KITTI-360에서는 적은 저장 공간으로 경쟁력 있는 결과를 달성했습니다.

## 🎯 주요 포인트

- 1. Neural-MMGS는 이미지, LiDAR, 의미 정보를 통합하여 대규모 장면 재구성을 위한 새로운 신경 3DGS 프레임워크를 제안합니다.
- 2. 제안된 방법은 각 가우시안에 광학, 물리적, 의미적 특징을 암묵적으로 인코딩하는 컴팩트하고 학습 가능한 임베딩을 사용합니다.
- 3. 경량 신경 디코더를 훈련하여 임베딩을 가우시안 매개변수로 매핑함으로써 메모리 사용량을 줄이고 확장성을 개선합니다.
- 4. Oxford Spires 데이터셋에서는 더 높은 품질의 재구성을 달성했으며, KITTI-360 데이터셋에서는 저장 공간을 덜 소모하면서 경쟁력 있는 결과를 얻었습니다.


---

*Generated on 2025-09-24 05:02:24*