---
keywords:
  - Neural-MMGS
  - Multimodal Learning
  - LiDAR
  - Semantic Information
  - Neural Decoders
category: cs.CV
publish_date: 2025-09-23
arxiv_id: 2509.17762
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T05:02:24.555523",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Neural-MMGS",
    "Multimodal Learning",
    "LiDAR",
    "Semantic Information",
    "Neural Decoders"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Neural-MMGS": 0.8,
    "Multimodal Learning": 0.85,
    "LiDAR": 0.78,
    "Semantic Information": 0.77,
    "Neural Decoders": 0.65
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Neural-MMGS",
        "canonical": "Neural-MMGS",
        "aliases": [
          "Neural Multi-modal Gaussian Splats"
        ],
        "category": "unique_technical",
        "rationale": "Represents a novel framework for multimodal scene reconstruction, central to the paper's contribution.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "multimodal",
        "canonical": "Multimodal Learning",
        "aliases": [
          "multimodal"
        ],
        "category": "specific_connectable",
        "rationale": "Connects to the trend of integrating multiple data types for richer learning models.",
        "novelty_score": 0.5,
        "connectivity_score": 0.88,
        "specificity_score": 0.78,
        "link_intent_score": 0.85
      },
      {
        "surface": "LiDAR",
        "canonical": "LiDAR",
        "aliases": [
          "Light Detection and Ranging"
        ],
        "category": "specific_connectable",
        "rationale": "Key sensing modality used in the framework, essential for scene reconstruction.",
        "novelty_score": 0.55,
        "connectivity_score": 0.82,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "semantic information",
        "canonical": "Semantic Information",
        "aliases": [
          "semantics"
        ],
        "category": "specific_connectable",
        "rationale": "Provides high-level context crucial for enhancing scene reconstruction.",
        "novelty_score": 0.6,
        "connectivity_score": 0.79,
        "specificity_score": 0.75,
        "link_intent_score": 0.77
      },
      {
        "surface": "neural decoders",
        "canonical": "Neural Decoders",
        "aliases": [
          "decoders"
        ],
        "category": "broad_technical",
        "rationale": "Essential component for translating embeddings into usable parameters.",
        "novelty_score": 0.58,
        "connectivity_score": 0.7,
        "specificity_score": 0.72,
        "link_intent_score": 0.65
      }
    ],
    "ban_list_suggestions": [
      "framework",
      "approach",
      "method"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Neural-MMGS",
      "resolved_canonical": "Neural-MMGS",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "multimodal",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.88,
        "specificity": 0.78,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "LiDAR",
      "resolved_canonical": "LiDAR",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.82,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "semantic information",
      "resolved_canonical": "Semantic Information",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.79,
        "specificity": 0.75,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "neural decoders",
      "resolved_canonical": "Neural Decoders",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.7,
        "specificity": 0.72,
        "link_intent": 0.65
      }
    }
  ]
}
-->

# Neural-MMGS: Multi-modal Neural Gaussian Splats for Large-Scale Scene Reconstruction

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17762.pdf)
**Category**: cs.CV
**Published**: 2025-09-23
**ArXiv ID**: [2509.17762](https://arxiv.org/abs/2509.17762)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/MS-GS_ Multi-Appearance Sparse-View 3D Gaussian Splatting in the Wild_20250922|MS-GS: Multi-Appearance Sparse-View 3D Gaussian Splatting in the Wild]] (89.6% similar)
- [[2025-09-23/MedGS_ Gaussian Splatting for Multi-Modal 3D Medical Imaging_20250923|MedGS: Gaussian Splatting for Multi-Modal 3D Medical Imaging]] (87.0% similar)
- [[2025-09-23/HyRF_ Hybrid Radiance Fields for Memory-efficient and High-quality Novel View Synthesis_20250923|HyRF: Hybrid Radiance Fields for Memory-efficient and High-quality Novel View Synthesis]] (85.8% similar)
- [[2025-09-22/GS-Scale_ Unlocking Large-Scale 3D Gaussian Splatting Training via Host Offloading_20250922|GS-Scale: Unlocking Large-Scale 3D Gaussian Splatting Training via Host Offloading]] (84.4% similar)
- [[2025-09-23/3D Gaussian Flats_ Hybrid 2D/3D Photometric Scene Reconstruction_20250923|3D Gaussian Flats: Hybrid 2D/3D Photometric Scene Reconstruction]] (84.4% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Neural Decoders|Neural Decoders]]
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]], [[keywords/LiDAR|LiDAR]], [[keywords/Semantic Information|Semantic Information]]
**âš¡ Unique Technical**: [[keywords/Neural-MMGS|Neural-MMGS]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17762v1 Announce Type: new 
Abstract: This paper proposes Neural-MMGS, a novel neural 3DGS framework for multimodal large-scale scene reconstruction that fuses multiple sensing modalities in a per-gaussian compact, learnable embedding. While recent works focusing on large-scale scene reconstruction have incorporated LiDAR data to provide more accurate geometric constraints, we argue that LiDAR's rich physical properties remain underexplored. Similarly, semantic information has been used for object retrieval, but could provide valuable high-level context for scene reconstruction. Traditional approaches append these properties to Gaussians as separate parameters, increasing memory usage and limiting information exchange across modalities. Instead, our approach fuses all modalities -- image, LiDAR, and semantics -- into a compact, learnable embedding that implicitly encodes optical, physical, and semantic features in each Gaussian. We then train lightweight neural decoders to map these embeddings to Gaussian parameters, enabling the reconstruction of each sensing modality with lower memory overhead and improved scalability. We evaluate Neural-MMGS on the Oxford Spires and KITTI-360 datasets. On Oxford Spires, we achieve higher-quality reconstructions, while on KITTI-360, our method reaches competitive results with less storage consumption compared with current approaches in LiDAR-based novel-view synthesis.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ Neural-MMGSë¼ëŠ” ìƒˆë¡œìš´ ì‹ ê²½ë§ ê¸°ë°˜ 3D ì¥ë©´ ì¬êµ¬ì„± í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ì´ë¯¸ì§€, LiDAR, ì˜ë¯¸ë¡ ì  ì •ë³´ë¥¼ í•˜ë‚˜ì˜ í•™ìŠµ ê°€ëŠ¥í•œ ì„ë² ë”©ìœ¼ë¡œ ìœµí•©í•˜ì—¬ ëŒ€ê·œëª¨ ì¥ë©´ì„ ì¬êµ¬ì„±í•©ë‹ˆë‹¤. ê¸°ì¡´ ë°©ë²•ë“¤ì€ LiDAR ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°í•˜í•™ì  ì œì•½ì„ ê°•í™”í–ˆì§€ë§Œ, LiDARì˜ ë¬¼ë¦¬ì  íŠ¹ì„±ì„ ì¶©ë¶„íˆ í™œìš©í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, ì˜ë¯¸ë¡ ì  ì •ë³´ëŠ” ê°ì²´ ê²€ìƒ‰ì— ì‚¬ìš©ë˜ì—ˆìœ¼ë‚˜ ì¥ë©´ ì¬êµ¬ì„±ì— ìœ ìš©í•œ ê³ ìˆ˜ì¤€ì˜ ë¬¸ë§¥ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Neural-MMGSëŠ” ì´ëŸ¬í•œ ì •ë³´ë¥¼ ê°œë³„ ë§¤ê°œë³€ìˆ˜ë¡œ ì¶”ê°€í•˜ëŠ” ëŒ€ì‹ , ëª¨ë“  ê°ì§€ ëª¨ë‹¬ë¦¬í‹°ë¥¼ í•˜ë‚˜ì˜ ì„ë² ë”©ì— ìœµí•©í•˜ì—¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ì„ ì¤„ì´ê³  í™•ì¥ì„±ì„ ê°œì„ í•©ë‹ˆë‹¤. Oxford Spiresì™€ KITTI-360 ë°ì´í„°ì…‹ì„ í†µí•´ í‰ê°€í•œ ê²°ê³¼, Oxford Spiresì—ì„œëŠ” ë” ë†’ì€ í’ˆì§ˆì˜ ì¬êµ¬ì„±ì„, KITTI-360ì—ì„œëŠ” ì ì€ ì €ì¥ ê³µê°„ìœ¼ë¡œ ê²½ìŸë ¥ ìˆëŠ” ê²°ê³¼ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Neural-MMGSëŠ” ì´ë¯¸ì§€, LiDAR, ì˜ë¯¸ ì •ë³´ë¥¼ í†µí•©í•˜ì—¬ ëŒ€ê·œëª¨ ì¥ë©´ ì¬êµ¬ì„±ì„ ìœ„í•œ ìƒˆë¡œìš´ ì‹ ê²½ 3DGS í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.
- 2. ì œì•ˆëœ ë°©ë²•ì€ ê° ê°€ìš°ì‹œì•ˆì— ê´‘í•™, ë¬¼ë¦¬ì , ì˜ë¯¸ì  íŠ¹ì§•ì„ ì•”ë¬µì ìœ¼ë¡œ ì¸ì½”ë”©í•˜ëŠ” ì»´íŒ©íŠ¸í•˜ê³  í•™ìŠµ ê°€ëŠ¥í•œ ì„ë² ë”©ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
- 3. ê²½ëŸ‰ ì‹ ê²½ ë””ì½”ë”ë¥¼ í›ˆë ¨í•˜ì—¬ ì„ë² ë”©ì„ ê°€ìš°ì‹œì•ˆ ë§¤ê°œë³€ìˆ˜ë¡œ ë§¤í•‘í•¨ìœ¼ë¡œì¨ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì´ê³  í™•ì¥ì„±ì„ ê°œì„ í•©ë‹ˆë‹¤.
- 4. Oxford Spires ë°ì´í„°ì…‹ì—ì„œëŠ” ë” ë†’ì€ í’ˆì§ˆì˜ ì¬êµ¬ì„±ì„ ë‹¬ì„±í–ˆìœ¼ë©°, KITTI-360 ë°ì´í„°ì…‹ì—ì„œëŠ” ì €ì¥ ê³µê°„ì„ ëœ ì†Œëª¨í•˜ë©´ì„œ ê²½ìŸë ¥ ìˆëŠ” ê²°ê³¼ë¥¼ ì–»ì—ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 05:02:24*