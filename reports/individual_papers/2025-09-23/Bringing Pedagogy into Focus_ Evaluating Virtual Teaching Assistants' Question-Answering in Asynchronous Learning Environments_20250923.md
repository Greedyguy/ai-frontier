---
keywords:
  - Virtual Teaching Assistants
  - Asynchronous Learning Environments
  - Pedagogical Evaluation
  - Learning Sciences
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2509.17961
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:35:59.531794",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Virtual Teaching Assistants",
    "Asynchronous Learning Environments",
    "Pedagogical Evaluation",
    "Learning Sciences"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Virtual Teaching Assistants": 0.85,
    "Asynchronous Learning Environments": 0.82,
    "Pedagogical Evaluation": 0.8,
    "Learning Sciences": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Virtual Teaching Assistants",
        "canonical": "Virtual Teaching Assistants",
        "aliases": [
          "VTA",
          "Virtual TAs"
        ],
        "category": "unique_technical",
        "rationale": "Central to the paper's focus on improving pedagogical effectiveness in asynchronous learning environments.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.85
      },
      {
        "surface": "Asynchronous Learning Environments",
        "canonical": "Asynchronous Learning Environments",
        "aliases": [
          "ALE",
          "Asynchronous Education"
        ],
        "category": "unique_technical",
        "rationale": "Key context for deploying and evaluating Virtual Teaching Assistants.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "Pedagogical Evaluation",
        "canonical": "Pedagogical Evaluation",
        "aliases": [
          "Educational Assessment",
          "Teaching Evaluation"
        ],
        "category": "unique_technical",
        "rationale": "Focuses on the rigorous assessment of VTAs, which is crucial for educational impact.",
        "novelty_score": 0.68,
        "connectivity_score": 0.72,
        "specificity_score": 0.76,
        "link_intent_score": 0.8
      },
      {
        "surface": "Learning Sciences",
        "canonical": "Learning Sciences",
        "aliases": [
          "Educational Sciences",
          "Learning Theory"
        ],
        "category": "broad_technical",
        "rationale": "Provides a theoretical foundation for the evaluation framework proposed in the paper.",
        "novelty_score": 0.55,
        "connectivity_score": 0.78,
        "specificity_score": 0.7,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "evaluation framework",
      "forum discussions",
      "expert annotations"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Virtual Teaching Assistants",
      "resolved_canonical": "Virtual Teaching Assistants",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Asynchronous Learning Environments",
      "resolved_canonical": "Asynchronous Learning Environments",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Pedagogical Evaluation",
      "resolved_canonical": "Pedagogical Evaluation",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.72,
        "specificity": 0.76,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Learning Sciences",
      "resolved_canonical": "Learning Sciences",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.78,
        "specificity": 0.7,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Bringing Pedagogy into Focus: Evaluating Virtual Teaching Assistants' Question-Answering in Asynchronous Learning Environments

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17961.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2509.17961](https://arxiv.org/abs/2509.17961)

## 🔗 유사한 논문
- [[2025-09-23/Automated Procedural Analysis via Video-Language Models for AI-assisted Nursing Skills Assessment_20250923|Automated Procedural Analysis via Video-Language Models for AI-assisted Nursing Skills Assessment]] (83.1% similar)
- [[2025-09-23/ProtoVQA_ An Adaptable Prototypical Framework for Explainable Fine-Grained Visual Question Answering_20250923|ProtoVQA: An Adaptable Prototypical Framework for Explainable Fine-Grained Visual Question Answering]] (81.5% similar)
- [[2025-09-23/Comparative Analysis of STEM and non-STEM Teachers' Needs for Integrating AI into Educational Environments_20250923|Comparative Analysis of STEM and non-STEM Teachers' Needs for Integrating AI into Educational Environments]] (81.4% similar)
- [[2025-09-18/Calibrated Generative AI as Meta-Reviewer_ A Systemic Functional Linguistics Discourse Analysis of Reviews of Peer Reviews_20250918|Calibrated Generative AI as Meta-Reviewer: A Systemic Functional Linguistics Discourse Analysis of Reviews of Peer Reviews]] (80.9% similar)
- [[2025-09-22/Understanding AI Evaluation Patterns_ How Different GPT Models Assess Vision-Language Descriptions_20250922|Understanding AI Evaluation Patterns: How Different GPT Models Assess Vision-Language Descriptions]] (80.1% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Learning Sciences|Learning Sciences]]
**⚡ Unique Technical**: [[keywords/Virtual Teaching Assistants|Virtual Teaching Assistants]], [[keywords/Asynchronous Learning Environments|Asynchronous Learning Environments]], [[keywords/Pedagogical Evaluation|Pedagogical Evaluation]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.17961v1 Announce Type: new 
Abstract: Asynchronous learning environments (ALEs) are widely adopted for formal and informal learning, but timely and personalized support is often limited. In this context, Virtual Teaching Assistants (VTAs) can potentially reduce the workload of instructors, but rigorous and pedagogically sound evaluation is essential. Existing assessments often rely on surface-level metrics and lack sufficient grounding in educational theories, making it difficult to meaningfully compare the pedagogical effectiveness of different VTA systems. To bridge this gap, we propose an evaluation framework rooted in learning sciences and tailored to asynchronous forum discussions, a common VTA deployment context in ALE. We construct classifiers using expert annotations of VTA responses on a diverse set of forum posts. We evaluate the effectiveness of our classifiers, identifying approaches that improve accuracy as well as challenges that hinder generalization. Our work establishes a foundation for theory-driven evaluation of VTA systems, paving the way for more pedagogically effective AI in education.

## 📝 요약

비동기 학습 환경에서 가상 교육 조교(VTA)는 강사의 업무를 줄일 수 있지만, 교육 이론에 기반한 평가가 필요합니다. 기존 평가 방식은 표면적인 지표에 의존하여 VTA 시스템의 교육적 효과를 비교하기 어렵습니다. 이를 해결하기 위해, 우리는 학습 과학에 기반한 평가 프레임워크를 제안하고, 비동기 포럼 토론에 맞춘 VTA 응답을 전문가가 주석한 데이터를 활용해 분류기를 구축했습니다. 이 분류기의 정확성을 평가하고, 일반화에 방해가 되는 문제점을 식별했습니다. 이 연구는 교육에서 AI의 교육적 효과를 높이기 위한 이론 기반 평가의 기초를 마련합니다.

## 🎯 주요 포인트

- 1. 비동기 학습 환경에서 가상 조교(VTA)는 교수자의 업무 부담을 줄일 수 있지만, 엄격하고 교육학적으로 타당한 평가가 필요하다.
- 2. 기존 평가 방법은 표면적인 지표에 의존하며 교육 이론에 충분히 기반하지 않아, 다양한 VTA 시스템의 교육적 효과를 비교하기 어렵다.
- 3. 우리는 학습 과학에 기반을 둔 평가 프레임워크를 제안하며, 이는 비동기 포럼 토론에 맞춰져 있다.
- 4. 다양한 포럼 게시물에 대한 VTA 응답을 전문가가 주석 처리하여 분류기를 구축하고, 이들의 효과성을 평가한다.
- 5. 우리의 연구는 이론 기반의 VTA 시스템 평가의 기초를 마련하여 교육에서의 AI 활용을 더욱 교육학적으로 효과적으로 만드는 길을 열어준다.


---

*Generated on 2025-09-24 03:35:59*