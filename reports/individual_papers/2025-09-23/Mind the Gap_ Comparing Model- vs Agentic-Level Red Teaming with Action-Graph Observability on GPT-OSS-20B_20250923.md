---
keywords:
  - Agentic AI Systems
  - Red Teaming
  - AgentSeer
  - Tool-Calling Contexts
  - Iterative Attacks
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.17259
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T22:58:00.797592",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Agentic AI Systems",
    "Red Teaming",
    "AgentSeer",
    "Tool-Calling Contexts",
    "Iterative Attacks"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Agentic AI Systems": 0.78,
    "Red Teaming": 0.8,
    "AgentSeer": 0.77,
    "Tool-Calling Contexts": 0.75,
    "Iterative Attacks": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Agentic AI Systems",
        "canonical": "Agentic AI Systems",
        "aliases": [
          "Agentic Systems",
          "Agentic AI"
        ],
        "category": "unique_technical",
        "rationale": "Highlights a specific type of AI system with unique vulnerabilities, crucial for understanding agentic-level risks.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Red Teaming",
        "canonical": "Red Teaming",
        "aliases": [
          "Adversarial Testing",
          "Security Testing"
        ],
        "category": "specific_connectable",
        "rationale": "Connects to security and vulnerability assessment practices, relevant for understanding AI system robustness.",
        "novelty_score": 0.55,
        "connectivity_score": 0.82,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "AgentSeer",
        "canonical": "AgentSeer",
        "aliases": [
          "Agent Observability Framework"
        ],
        "category": "unique_technical",
        "rationale": "A specific framework used for deconstructing agentic systems, essential for detailed analysis of AI vulnerabilities.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.9,
        "link_intent_score": 0.77
      },
      {
        "surface": "Tool-Calling Contexts",
        "canonical": "Tool-Calling Contexts",
        "aliases": [
          "Tool Interaction Contexts"
        ],
        "category": "unique_technical",
        "rationale": "Identifies a specific context where agentic vulnerabilities are more pronounced, aiding in targeted security analysis.",
        "novelty_score": 0.7,
        "connectivity_score": 0.68,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      },
      {
        "surface": "Iterative Attacks",
        "canonical": "Iterative Attacks",
        "aliases": [
          "Repeated Attacks",
          "Cyclic Attacks"
        ],
        "category": "specific_connectable",
        "rationale": "Describes a method of attack that is crucial for understanding the dynamics of agentic vulnerabilities.",
        "novelty_score": 0.6,
        "connectivity_score": 0.78,
        "specificity_score": 0.72,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "model level",
      "vulnerability profiles",
      "standalone model"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Agentic AI Systems",
      "resolved_canonical": "Agentic AI Systems",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Red Teaming",
      "resolved_canonical": "Red Teaming",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.82,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "AgentSeer",
      "resolved_canonical": "AgentSeer",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.9,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Tool-Calling Contexts",
      "resolved_canonical": "Tool-Calling Contexts",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.68,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Iterative Attacks",
      "resolved_canonical": "Iterative Attacks",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.78,
        "specificity": 0.72,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Mind the Gap: Comparing Model- vs Agentic-Level Red Teaming with Action-Graph Observability on GPT-OSS-20B

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17259.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.17259](https://arxiv.org/abs/2509.17259)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/The Cybersecurity of a Humanoid Robot_20250918|The Cybersecurity of a Humanoid Robot]] (83.3% similar)
- [[2025-09-22/Activation Space Interventions Can Be Transferred Between Large Language Models_20250922|Activation Space Interventions Can Be Transferred Between Large Language Models]] (82.4% similar)
- [[2025-09-19/Sentinel Agents for Secure and Trustworthy Agentic AI in Multi-Agent Systems_20250919|Sentinel Agents for Secure and Trustworthy Agentic AI in Multi-Agent Systems]] (82.1% similar)
- [[2025-09-22/Understanding AI Evaluation Patterns_ How Different GPT Models Assess Vision-Language Descriptions_20250922|Understanding AI Evaluation Patterns: How Different GPT Models Assess Vision-Language Descriptions]] (82.0% similar)
- [[2025-09-18/Position_ AI Safety Must Embrace an Antifragile Perspective_20250918|Position: AI Safety Must Embrace an Antifragile Perspective]] (81.9% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Red Teaming|Red Teaming]], [[keywords/Iterative Attacks|Iterative Attacks]]
**âš¡ Unique Technical**: [[keywords/Agentic AI Systems|Agentic AI Systems]], [[keywords/AgentSeer|AgentSeer]], [[keywords/Tool-Calling Contexts|Tool-Calling Contexts]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17259v1 Announce Type: new 
Abstract: As the industry increasingly adopts agentic AI systems, understanding their unique vulnerabilities becomes critical. Prior research suggests that security flaws at the model level do not fully capture the risks present in agentic deployments, where models interact with tools and external environments. This paper investigates this gap by conducting a comparative red teaming analysis of GPT-OSS-20B, a 20-billion parameter open-source model. Using our observability framework AgentSeer to deconstruct agentic systems into granular actions and components, we apply iterative red teaming attacks with harmful objectives from HarmBench at two distinct levels: the standalone model and the model operating within an agentic loop. Our evaluation reveals fundamental differences between model level and agentic level vulnerability profiles. Critically, we discover the existence of agentic-only vulnerabilities, attack vectors that emerge exclusively within agentic execution contexts while remaining inert against standalone models. Agentic level iterative attacks successfully compromise objectives that completely failed at the model level, with tool-calling contexts showing 24\% higher vulnerability than non-tool contexts. Conversely, certain model-specific exploits work exclusively at the model level and fail when transferred to agentic contexts, demonstrating that standalone model vulnerabilities do not always generalize to deployed systems.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì—ì´ì „íŠ¸ ê¸°ë°˜ AI ì‹œìŠ¤í…œì˜ ê³ ìœ í•œ ì·¨ì•½ì„±ì„ ì´í•´í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤ëŠ” ì ì„ ê°•ì¡°í•©ë‹ˆë‹¤. ê¸°ì¡´ ì—°êµ¬ì—ì„œëŠ” ëª¨ë¸ ìˆ˜ì¤€ì˜ ë³´ì•ˆ ê²°í•¨ì´ ì—ì´ì „íŠ¸ ë°°í¬ì—ì„œì˜ ìœ„í—˜ì„ ì™„ì „íˆ ì„¤ëª…í•˜ì§€ ëª»í•œë‹¤ê³  ì§€ì í•©ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ì €ìë“¤ì€ 200ì–µ ê°œì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ê°€ì§„ ì˜¤í”ˆ ì†ŒìŠ¤ ëª¨ë¸ì¸ GPT-OSS-20Bë¥¼ ëŒ€ìƒìœ¼ë¡œ ë¹„êµì  ë ˆë“œ íŒ€ ë¶„ì„ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. AgentSeerë¼ëŠ” ê´€ì¸¡ í”„ë ˆì„ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ ì„¸ë¶„í™”ëœ í–‰ë™ê³¼ êµ¬ì„± ìš”ì†Œë¡œ ë¶„í•´í•˜ê³ , HarmBenchì˜ ìœ í•´í•œ ëª©í‘œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë°˜ë³µì ì¸ ë ˆë“œ íŒ€ ê³µê²©ì„ ëª¨ë¸ ë‹¨ë… ì‹¤í–‰ê³¼ ì—ì´ì „íŠ¸ ë£¨í”„ ë‚´ ì‹¤í–‰ ë‘ ê°€ì§€ ìˆ˜ì¤€ì—ì„œ ì ìš©í–ˆìŠµë‹ˆë‹¤. í‰ê°€ ê²°ê³¼, ëª¨ë¸ ìˆ˜ì¤€ê³¼ ì—ì´ì „íŠ¸ ìˆ˜ì¤€ì˜ ì·¨ì•½ì„± í”„ë¡œíŒŒì¼ ê°„ì— ê·¼ë³¸ì ì¸ ì°¨ì´ê°€ ìˆìŒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. íŠ¹íˆ, ì—ì´ì „íŠ¸ ì‹¤í–‰ í™˜ê²½ì—ì„œë§Œ ë‚˜íƒ€ë‚˜ëŠ” 'ì—ì´ì „íŠ¸ ì „ìš© ì·¨ì•½ì„±'ì´ ì¡´ì¬í•˜ë©°, ì´ëŠ” ë…ë¦½ ì‹¤í–‰ ëª¨ë¸ì—ì„œëŠ” ë“œëŸ¬ë‚˜ì§€ ì•ŠëŠ” ê³µê²© ë²¡í„°ì…ë‹ˆë‹¤. ë„êµ¬ í˜¸ì¶œ í™˜ê²½ì—ì„œëŠ” ë¹„ë„êµ¬ í™˜ê²½ë³´ë‹¤ 24% ë” ë†’ì€ ì·¨ì•½ì„±ì„ ë³´ì˜€ìœ¼ë©°, ì¼ë¶€ ëª¨ë¸ ì „ìš© ìµìŠ¤í”Œë¡œì‡ì€ ëª¨ë¸ ìˆ˜ì¤€ì—ì„œë§Œ ì‘ë™í•˜ê³  ì—ì´ì „íŠ¸ í™˜ê²½ì—ì„œëŠ” ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ë…ë¦½ ì‹¤í–‰ ëª¨ë¸ì˜ ì·¨ì•½ì„±ì´ ë°°í¬ ì‹œìŠ¤í…œì— í•­ìƒ ì¼ë°˜í™”ë˜ì§€ ì•ŠìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì—ì´ì „í‹± AI ì‹œìŠ¤í…œì˜ ê³ ìœ í•œ ì·¨ì•½ì„±ì„ ì´í•´í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•´ì§€ê³  ìˆìŠµë‹ˆë‹¤.
- 2. ëª¨ë¸ ìˆ˜ì¤€ì˜ ë³´ì•ˆ ê²°í•¨ì€ ì—ì´ì „í‹± ë°°í¬ì—ì„œì˜ ìœ„í—˜ì„ ì™„ì „íˆ í¬ì°©í•˜ì§€ ëª»í•©ë‹ˆë‹¤.
- 3. ì—ì´ì „í‹± ì‹œìŠ¤í…œì˜ ì·¨ì•½ì„±ì€ ëª¨ë¸ ìˆ˜ì¤€ê³¼ ì—ì´ì „í‹± ìˆ˜ì¤€ì—ì„œ ê·¼ë³¸ì ìœ¼ë¡œ ë‹¤ë¦…ë‹ˆë‹¤.
- 4. ì—ì´ì „í‹± ì‹¤í–‰ í™˜ê²½ì—ì„œë§Œ ë‚˜íƒ€ë‚˜ëŠ” ê³ ìœ í•œ ì·¨ì•½ì„±ì´ ì¡´ì¬í•©ë‹ˆë‹¤.
- 5. ë„êµ¬ í˜¸ì¶œ ë¬¸ë§¥ì—ì„œëŠ” ë¹„ë„êµ¬ ë¬¸ë§¥ë³´ë‹¤ 24% ë” ë†’ì€ ì·¨ì•½ì„±ì„ ë³´ì…ë‹ˆë‹¤.


---

*Generated on 2025-09-23 22:58:00*