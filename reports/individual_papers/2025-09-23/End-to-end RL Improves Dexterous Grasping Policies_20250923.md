---
keywords:
  - End-to-End Reinforcement Learning
  - Dexterous Grasping
  - Vision-Based Reinforcement Learning
  - Depth Distillation
category: cs.LG
publish_date: 2025-09-23
arxiv_id: 2509.16434
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T02:08:34.567355",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "End-to-End Reinforcement Learning",
    "Dexterous Grasping",
    "Vision-Based Reinforcement Learning",
    "Depth Distillation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "End-to-End Reinforcement Learning": 0.82,
    "Dexterous Grasping": 0.78,
    "Vision-Based Reinforcement Learning": 0.77,
    "Depth Distillation": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "end-to-end RL",
        "canonical": "End-to-End Reinforcement Learning",
        "aliases": [
          "end-to-end reinforcement learning"
        ],
        "category": "specific_connectable",
        "rationale": "End-to-end RL is a key concept in the paper, linking vision-based policies with reinforcement learning techniques.",
        "novelty_score": 0.65,
        "connectivity_score": 0.85,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "dexterous grasping",
        "canonical": "Dexterous Grasping",
        "aliases": [
          "dexterous manipulation"
        ],
        "category": "unique_technical",
        "rationale": "Dexterous grasping is a unique application area for robotics, central to the paper's focus.",
        "novelty_score": 0.72,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "vision-based RL",
        "canonical": "Vision-Based Reinforcement Learning",
        "aliases": [
          "vision-based reinforcement learning"
        ],
        "category": "specific_connectable",
        "rationale": "Vision-based RL is crucial for understanding the paper's approach to integrating visual data in RL.",
        "novelty_score": 0.6,
        "connectivity_score": 0.8,
        "specificity_score": 0.76,
        "link_intent_score": 0.77
      },
      {
        "surface": "depth distillation",
        "canonical": "Depth Distillation",
        "aliases": [
          "depth policy distillation"
        ],
        "category": "unique_technical",
        "rationale": "Depth distillation is a novel technique discussed in the paper, enhancing policy performance.",
        "novelty_score": 0.68,
        "connectivity_score": 0.72,
        "specificity_score": 0.82,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "simulator",
      "GPU"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "end-to-end RL",
      "resolved_canonical": "End-to-End Reinforcement Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.85,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "dexterous grasping",
      "resolved_canonical": "Dexterous Grasping",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "vision-based RL",
      "resolved_canonical": "Vision-Based Reinforcement Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.8,
        "specificity": 0.76,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "depth distillation",
      "resolved_canonical": "Depth Distillation",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.72,
        "specificity": 0.82,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# End-to-end RL Improves Dexterous Grasping Policies

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16434.pdf)
**Category**: cs.LG
**Published**: 2025-09-23
**ArXiv ID**: [2509.16434](https://arxiv.org/abs/2509.16434)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/Hybrid Diffusion Policies with Projective Geometric Algebra for Efficient Robot Manipulation Learning_20250918|Hybrid Diffusion Policies with Projective Geometric Algebra for Efficient Robot Manipulation Learning]] (83.9% similar)
- [[2025-09-19/Scalable Multi-Objective Robot Reinforcement Learning through Gradient Conflict Resolution_20250919|Scalable Multi-Objective Robot Reinforcement Learning through Gradient Conflict Resolution]] (83.7% similar)
- [[2025-09-22/GP3_ A 3D Geometry-Aware Policy with Multi-View Images for Robotic Manipulation_20250922|GP3: A 3D Geometry-Aware Policy with Multi-View Images for Robotic Manipulation]] (83.4% similar)
- [[2025-09-22/PVPO_ Pre-Estimated Value-Based Policy Optimization for Agentic Reasoning_20250922|PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic Reasoning]] (82.9% similar)
- [[2025-09-23/Latent Policy Steering with Embodiment-Agnostic Pretrained World Models_20250923|Latent Policy Steering with Embodiment-Agnostic Pretrained World Models]] (82.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/End-to-End Reinforcement Learning|End-to-End Reinforcement Learning]], [[keywords/Vision-Based Reinforcement Learning|Vision-Based Reinforcement Learning]]
**âš¡ Unique Technical**: [[keywords/Dexterous Grasping|Dexterous Grasping]], [[keywords/Depth Distillation|Depth Distillation]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16434v1 Announce Type: cross 
Abstract: This work explores techniques to scale up image-based end-to-end learning for dexterous grasping with an arm + hand system. Unlike state-based RL, vision-based RL is much more memory inefficient, resulting in relatively low batch sizes, which is not amenable for algorithms like PPO. Nevertheless, it is still an attractive method as unlike the more commonly used techniques which distill state-based policies into vision networks, end-to-end RL can allow for emergent active vision behaviors. We identify a key bottleneck in training these policies is the way most existing simulators scale to multiple GPUs using traditional data parallelism techniques. We propose a new method where we disaggregate the simulator and RL (both training and experience buffers) onto separate GPUs. On a node with four GPUs, we have the simulator running on three of them, and PPO running on the fourth. We are able to show that with the same number of GPUs, we can double the number of existing environments compared to the previous baseline of standard data parallelism. This allows us to train vision-based environments, end-to-end with depth, which were previously performing far worse with the baseline. We train and distill both depth and state-based policies into stereo RGB networks and show that depth distillation leads to better results, both in simulation and reality. This improvement is likely due to the observability gap between state and vision policies which does not exist when distilling depth policies into stereo RGB. We further show that the increased batch size brought about by disaggregated simulation also improves real world performance. When deploying in the real world, we improve upon the previous state-of-the-art vision-based results using our end-to-end policies.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” íŒ”ê³¼ ì† ì‹œìŠ¤í…œì„ í™œìš©í•œ ì´ë¯¸ì§€ ê¸°ë°˜ì˜ ì¢…ë‹¨ ê°„ í•™ìŠµì„ í™•ì¥í•˜ëŠ” ê¸°ìˆ ì„ íƒêµ¬í•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ìƒíƒœ ê¸°ë°˜ ê°•í™” í•™ìŠµê³¼ ë‹¬ë¦¬, ë¹„ì „ ê¸°ë°˜ ê°•í™” í•™ìŠµì€ ë©”ëª¨ë¦¬ íš¨ìœ¨ì´ ë‚®ì•„ ë°°ì¹˜ í¬ê¸°ê°€ ì‘ì•„ì§€ëŠ” ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì¢…ë‹¨ ê°„ í•™ìŠµì€ ëŠ¥ë™ì  ë¹„ì „ í–‰ë™ì„ ìœ ë„í•  ìˆ˜ ìˆì–´ ë§¤ë ¥ì ì…ë‹ˆë‹¤. ê¸°ì¡´ ì‹œë®¬ë ˆì´í„°ê°€ ì—¬ëŸ¬ GPUë¡œ í™•ì¥í•  ë•Œì˜ ë³‘ëª© í˜„ìƒì„ í•´ê²°í•˜ê¸° ìœ„í•´, ì‹œë®¬ë ˆì´í„°ì™€ ê°•í™” í•™ìŠµì„ ê°œë³„ GPUì— ë¶„ì‚°ì‹œí‚¤ëŠ” ìƒˆë¡œìš´ ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ë„¤ ê°œì˜ GPU ë…¸ë“œì—ì„œ ì„¸ ê°œëŠ” ì‹œë®¬ë ˆì´í„°, í•˜ë‚˜ëŠ” PPOë¥¼ ì‹¤í–‰í•˜ì—¬, ê¸°ì¡´ ë°ì´í„° ë³‘ë ¬ ì²˜ë¦¬ ë°©ì‹ë³´ë‹¤ ë‘ ë°° ë§ì€ í™˜ê²½ì„ ìƒì„±í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ê¹Šì´ ê¸°ë°˜ ì •ì±…ì„ ìŠ¤í…Œë ˆì˜¤ RGB ë„¤íŠ¸ì›Œí¬ë¡œ ì¦ë¥˜í•˜ì—¬ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, ë¶„ì‚°ëœ ì‹œë®¬ë ˆì´ì…˜ìœ¼ë¡œ ì¸í•œ ë°°ì¹˜ í¬ê¸° ì¦ê°€ê°€ ì‹¤ì œ í™˜ê²½ì—ì„œë„ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚´ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì´ë¯¸ì§€ ê¸°ë°˜ì˜ ì¢…ë‹¨ê°„ í•™ìŠµì„ í™•ì¥í•˜ì—¬ íŒ”ê³¼ ì† ì‹œìŠ¤í…œì„ ì´ìš©í•œ ì •êµí•œ ê·¸ë¦½ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ê¸°ìˆ ì„ íƒêµ¬í–ˆìŠµë‹ˆë‹¤.
- 2. ê¸°ì¡´ì˜ ë°ì´í„° ë³‘ë ¬ ì²˜ë¦¬ ê¸°ë²•ìœ¼ë¡œëŠ” ì—¬ëŸ¬ GPUì— ì‹œë®¬ë ˆì´í„°ë¥¼ í™•ì¥í•˜ëŠ” ë° í•œê³„ê°€ ìˆìŒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.
- 3. ì‹œë®¬ë ˆì´í„°ì™€ ê°•í™”í•™ìŠµì„ ë³„ë„ì˜ GPUì— ë¶„ì‚°í•˜ì—¬ ì‹¤í–‰í•˜ëŠ” ìƒˆë¡œìš´ ë°©ë²•ì„ ì œì•ˆí–ˆìŠµë‹ˆë‹¤.
- 4. ì œì•ˆëœ ë°©ë²•ìœ¼ë¡œ ê¸°ì¡´ì˜ ë°ì´í„° ë³‘ë ¬ ì²˜ë¦¬ ë°©ì‹ë³´ë‹¤ ë‘ ë°°ì˜ í™˜ê²½ì„ ë™ì¼í•œ GPU ìˆ˜ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.
- 5. ê¹Šì´ ê¸°ë°˜ ì •ì±…ì„ ìŠ¤í…Œë ˆì˜¤ RGB ë„¤íŠ¸ì›Œí¬ë¡œ ì¦ë¥˜í•˜ì—¬ ì‹œë®¬ë ˆì´ì…˜ ë° ì‹¤ì œ í™˜ê²½ì—ì„œ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 02:08:34*