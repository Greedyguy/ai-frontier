---
keywords:
  - Machine Learning
  - Neural Network
category: cs.LG
publish_date: 2025-09-23
arxiv_id: 2409.03555
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T02:34:09.433679",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Machine Learning",
    "Neural Network"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Machine Learning": 0.0,
    "Neural Network": 0.0
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Machine Learning",
      "resolved_canonical": "Machine Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.0,
        "connectivity": 0.0,
        "specificity": 0.0,
        "link_intent": 0.0
      }
    },
    {
      "candidate_surface": "Neural Network",
      "resolved_canonical": "Neural Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.0,
        "connectivity": 0.0,
        "specificity": 0.0,
        "link_intent": 0.0
      }
    }
  ]
}
-->

# Unified Framework for Pre-trained Neural Network Compression via Decomposition and Optimized Rank Selection

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2409.03555.pdf)
**Category**: cs.LG
**Published**: 2025-09-23
**ArXiv ID**: [2409.03555](https://arxiv.org/abs/2409.03555)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/Probabilistic and nonlinear compressive sensing_20250918|Probabilistic and nonlinear compressive sensing]] (83.2% similar)
- [[2025-09-23/Search-Optimized Quantization in Biomedical Ontology Alignment_20250923|Search-Optimized Quantization in Biomedical Ontology Alignment]] (83.2% similar)
- [[2025-09-23/Interpretability-Aware Pruning for Efficient Medical Image Analysis_20250923|Interpretability-Aware Pruning for Efficient Medical Image Analysis]] (83.0% similar)
- [[2025-09-22/KVCompose_ Efficient Structured KV Cache Compression with Composite Tokens_20250922|KVCompose: Efficient Structured KV Cache Compression with Composite Tokens]] (82.5% similar)
- [[2025-09-18/A Novel Compression Framework for YOLOv8_ Achieving Real-Time Aerial Object Detection on Edge Devices via Structured Pruning and Channel-Wise Distillation_20250918|A Novel Compression Framework for YOLOv8: Achieving Real-Time Aerial Object Detection on Edge Devices via Structured Pruning and Channel-Wise Distillation]] (82.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Machine Learning|Machine Learning]], [[keywords/Neural Network|Neural Network]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2409.03555v2 Announce Type: replace 
Abstract: Despite their high accuracy, complex neural networks demand significant computational resources, posing challenges for deployment on resource constrained devices such as mobile phones and embedded systems. Compression algorithms have been developed to address these challenges by reducing model size and computational demands while maintaining accuracy. Among these approaches, factorization methods based on tensor decomposition are theoretically sound and effective. However, they face difficulties in selecting the appropriate rank for decomposition. This paper tackles this issue by presenting a unified framework that simultaneously applies decomposition and rank selection, employing a composite compression loss within defined rank constraints. Our method includes an automatic rank search in a continuous space, efficiently identifying optimal rank configurations for the pre-trained model by eliminating the need for additional training data and reducing computational overhead in the search step. Combined with a subsequent fine-tuning step, our approach maintains the performance of highly compressed models on par with their original counterparts. Using various benchmark datasets and models, we demonstrate the efficacy of our method through a comprehensive analysis.

## ğŸ“ ìš”ì•½

ë³µì¡í•œ ì‹ ê²½ë§ì˜ ë†’ì€ ì •í™•ë„ì—ë„ ë¶ˆêµ¬í•˜ê³ , ìì› ì œì•½ì´ ìˆëŠ” ëª¨ë°”ì¼ ê¸°ê¸°ë‚˜ ì„ë² ë””ë“œ ì‹œìŠ¤í…œì— ë°°í¬í•˜ê¸°ì—ëŠ” ë§ì€ ê³„ì‚° ìì›ì´ í•„ìš”í•©ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ëª¨ë¸ í¬ê¸°ì™€ ê³„ì‚° ìš”êµ¬ë¥¼ ì¤„ì´ë©´ì„œ ì •í™•ì„±ì„ ìœ ì§€í•˜ëŠ” ì••ì¶• ì•Œê³ ë¦¬ì¦˜ì´ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤. íŠ¹íˆ í…ì„œ ë¶„í•´ ê¸°ë°˜ì˜ íŒ©í„°ë¼ì´ì œì´ì…˜ ë°©ë²•ì€ ì´ë¡ ì ìœ¼ë¡œ íƒ€ë‹¹í•˜ê³  íš¨ê³¼ì ì´ì§€ë§Œ, ì ì ˆí•œ ë¶„í•´ ë­í¬ë¥¼ ì„ íƒí•˜ëŠ” ë° ì–´ë ¤ì›€ì´ ìˆìŠµë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì€ ë¶„í•´ì™€ ë­í¬ ì„ íƒì„ ë™ì‹œì— ì ìš©í•˜ëŠ” í†µí•© í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•˜ì—¬ ì´ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤. ì œì•ˆëœ ë°©ë²•ì€ ì—°ì† ê³µê°„ì—ì„œ ìë™ìœ¼ë¡œ ë­í¬ë¥¼ íƒìƒ‰í•˜ì—¬ ì¶”ê°€ í›ˆë ¨ ë°ì´í„° ì—†ì´ ìµœì ì˜ ë­í¬ êµ¬ì„±ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì‹ë³„í•˜ê³ , íƒìƒ‰ ë‹¨ê³„ì˜ ê³„ì‚° ë¶€ë‹´ì„ ì¤„ì…ë‹ˆë‹¤. ì´í›„ì˜ ë¯¸ì„¸ ì¡°ì • ë‹¨ê³„ë¥¼ í†µí•´ ê³ ë„ë¡œ ì••ì¶•ëœ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì›ë³¸ ëª¨ë¸ê³¼ ë™ë“±í•˜ê²Œ ìœ ì§€í•©ë‹ˆë‹¤. ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ê³¼ ëª¨ë¸ì„ ì‚¬ìš©í•œ ì¢…í•© ë¶„ì„ì„ í†µí•´ ë³¸ ë°©ë²•ì˜ íš¨ëŠ¥ì„ ì…ì¦í•˜ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë³µì¡í•œ ì‹ ê²½ë§ì˜ ë†’ì€ ì •í™•ë„ì—ë„ ë¶ˆêµ¬í•˜ê³ , ìì› ì œí•œ ì¥ì¹˜ì—ì„œì˜ ë°°í¬ì— ì–´ë ¤ì›€ì´ ìˆë‹¤.
- 2. ëª¨ë¸ í¬ê¸°ì™€ ê³„ì‚° ìš”êµ¬ë¥¼ ì¤„ì´ë©´ì„œ ì •í™•ì„±ì„ ìœ ì§€í•˜ê¸° ìœ„í•´ ì••ì¶• ì•Œê³ ë¦¬ì¦˜ì´ ê°œë°œë˜ì—ˆë‹¤.
- 3. í…ì„œ ë¶„í•´ ê¸°ë°˜ì˜ ê³„ìˆ˜í™” ë°©ë²•ì€ ì´ë¡ ì ìœ¼ë¡œ íƒ€ë‹¹í•˜ê³  íš¨ê³¼ì ì´ì§€ë§Œ ì ì ˆí•œ ê³„ìˆ˜ë¥¼ ì„ íƒí•˜ëŠ” ë° ì–´ë ¤ì›€ì´ ìˆë‹¤.
- 4. ë³¸ ë…¼ë¬¸ì€ ê³„ìˆ˜ ì„ íƒê³¼ ë¶„í•´ë¥¼ ë™ì‹œì— ì ìš©í•˜ëŠ” í†µí•© í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•˜ì—¬ ì´ ë¬¸ì œë¥¼ í•´ê²°í•œë‹¤.
- 5. ì œì•ˆëœ ë°©ë²•ì€ ì¶”ê°€ í•™ìŠµ ë°ì´í„° ì—†ì´ë„ ìµœì ì˜ ê³„ìˆ˜ êµ¬ì„±ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì‹ë³„í•˜ë©°, ì„±ëŠ¥ì„ ìœ ì§€í•œë‹¤.


---

*Generated on 2025-09-24 02:34:09*