---
keywords:
  - Neural Network
  - Optimal Control
  - Neural Operator
  - DeepONet
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2506.04742
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T01:05:20.158672",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Neural Network",
    "Optimal Control",
    "Neural Operator",
    "DeepONet"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Neural Network": 0.78,
    "Optimal Control": 0.82,
    "Neural Operator": 0.79,
    "DeepONet": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Neural Networks",
        "canonical": "Neural Network",
        "aliases": [
          "NN",
          "Neural Nets"
        ],
        "category": "broad_technical",
        "rationale": "Neural networks are central to the paper's methodology and connect to a wide range of related topics.",
        "novelty_score": 0.45,
        "connectivity_score": 0.85,
        "specificity_score": 0.65,
        "link_intent_score": 0.78
      },
      {
        "surface": "Optimal Control Problems",
        "canonical": "Optimal Control",
        "aliases": [
          "Optimal Control Tasks"
        ],
        "category": "specific_connectable",
        "rationale": "The paper focuses on solving optimal control problems, making it a key concept for linking.",
        "novelty_score": 0.68,
        "connectivity_score": 0.72,
        "specificity_score": 0.8,
        "link_intent_score": 0.82
      },
      {
        "surface": "Neural Operator",
        "canonical": "Neural Operator",
        "aliases": [
          "Neural Operators"
        ],
        "category": "unique_technical",
        "rationale": "Neural operators are a novel approach discussed in the paper, relevant for linking to advanced computational techniques.",
        "novelty_score": 0.75,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.79
      },
      {
        "surface": "DeepONet",
        "canonical": "DeepONet",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "DeepONet is a specific neural operator architecture used in the study, important for technical specificity.",
        "novelty_score": 0.8,
        "connectivity_score": 0.65,
        "specificity_score": 0.88,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "training process",
      "cost function",
      "optimization routine"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Neural Networks",
      "resolved_canonical": "Neural Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.85,
        "specificity": 0.65,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Optimal Control Problems",
      "resolved_canonical": "Optimal Control",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.72,
        "specificity": 0.8,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Neural Operator",
      "resolved_canonical": "Neural Operator",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "DeepONet",
      "resolved_canonical": "DeepONet",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.65,
        "specificity": 0.88,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Were Residual Penalty and Neural Operators All We Needed for Solving Optimal Control Problems?

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2506.04742.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2506.04742](https://arxiv.org/abs/2506.04742)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/Data-Driven Distributed Optimization via Aggregative Tracking and Deep-Learning_20250918|Data-Driven Distributed Optimization via Aggregative Tracking and Deep-Learning]] (83.0% similar)
- [[2025-09-22/Gradient Alignment in Physics-informed Neural Networks_ A Second-Order Optimization Perspective_20250922|Gradient Alignment in Physics-informed Neural Networks: A Second-Order Optimization Perspective]] (81.8% similar)
- [[2025-09-17/A Variational Framework for Residual-Based Adaptivity in Neural PDE Solvers and Operator Learning_20250917|A Variational Framework for Residual-Based Adaptivity in Neural PDE Solvers and Operator Learning]] (81.6% similar)
- [[2025-09-22/Geometric Integration for Neural Control Variates_20250922|Geometric Integration for Neural Control Variates]] (81.6% similar)
- [[2025-09-22/Inverse Optimization Latent Variable Models for Learning Costs Applied to Route Problems_20250922|Inverse Optimization Latent Variable Models for Learning Costs Applied to Route Problems]] (81.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Neural Network|Neural Network]]
**ğŸ”— Specific Connectable**: [[keywords/Optimal Control|Optimal Control]]
**âš¡ Unique Technical**: [[keywords/Neural Operator|Neural Operator]], [[keywords/DeepONet|DeepONet]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2506.04742v2 Announce Type: replace-cross 
Abstract: Neural networks have been used to solve optimal control problems, typically by training neural networks using a combined loss function that considers data, differential equation residuals, and objective costs. We show that including cost functions in the training process is unnecessary, advocating for a simpler architecture and streamlined approach by decoupling the optimal control problem from the training process. Thus, our work shows that a simple neural operator architecture, such as DeepONet, coupled with an unconstrained optimization routine, can solve multiple optimal control problems with a single physics-informed training phase and a subsequent optimization phase. We achieve this by adding a penalty term based on the differential equation residual to the cost function and computing gradients with respect to the control using automatic differentiation through the trained neural operator within an iterative optimization routine. Our results show acceptable accuracy for practical applications and potential computational savings for more complex and higher-dimensional problems.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì—ì„œëŠ” ìµœì  ì œì–´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì‹ ê²½ë§ì„ ì‚¬ìš©í•˜ëŠ” ê¸°ì¡´ ë°©ë²•ì—ì„œ ë¹„ìš© í•¨ìˆ˜ë¥¼ í›ˆë ¨ ê³¼ì •ì— í¬í•¨í•  í•„ìš”ê°€ ì—†ìŒì„ ì œì•ˆí•©ë‹ˆë‹¤. ëŒ€ì‹ , ìµœì  ì œì–´ ë¬¸ì œë¥¼ í›ˆë ¨ ê³¼ì •ì—ì„œ ë¶„ë¦¬í•˜ì—¬ ê°„ë‹¨í•œ ì‹ ê²½ ì—°ì‚°ì êµ¬ì¡°ì™€ ë¹„ì œì•½ ìµœì í™” ì ˆì°¨ë¥¼ í†µí•´ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆìŒì„ ë³´ì…ë‹ˆë‹¤. DeepONetê³¼ ê°™ì€ ì‹ ê²½ ì—°ì‚°ìì™€ ë¬¼ë¦¬ ì •ë³´ë¥¼ í™œìš©í•œ í›ˆë ¨ ë‹¨ê³„ë¥¼ í†µí•´ ì—¬ëŸ¬ ìµœì  ì œì–´ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆìœ¼ë©°, ë¯¸ë¶„ ë°©ì •ì‹ ì”ì°¨ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ í˜ë„í‹° í•­ì„ ë¹„ìš© í•¨ìˆ˜ì— ì¶”ê°€í•˜ì—¬ ìë™ ë¯¸ë¶„ì„ í†µí•´ ì œì–´ì— ëŒ€í•œ ê¸°ìš¸ê¸°ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ì‹¤ìš©ì ì¸ ì •í™•ë„ë¥¼ ì œê³µí•˜ë©°, ë³µì¡í•˜ê³  ê³ ì°¨ì› ë¬¸ì œì—ì„œì˜ ê³„ì‚° ë¹„ìš© ì ˆê° ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ìµœì  ì œì–´ ë¬¸ì œ í•´ê²°ì— ìˆì–´ ë¹„ìš© í•¨ìˆ˜ë¥¼ í›ˆë ¨ ê³¼ì •ì— í¬í•¨ì‹œí‚¤ëŠ” ê²ƒì€ ë¶ˆí•„ìš”í•˜ë©°, ë‹¨ìˆœí•œ ì‹ ê²½ë§ êµ¬ì¡°ì™€ ì ‘ê·¼ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤.
- 2. DeepONetê³¼ ê°™ì€ ë‹¨ìˆœí•œ ì‹ ê²½ ì—°ì‚°ì êµ¬ì¡°ì™€ ë¹„ì œì•½ ìµœì í™” ë£¨í‹´ì„ ê²°í•©í•˜ì—¬ ì—¬ëŸ¬ ìµœì  ì œì–´ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- 3. í›ˆë ¨ëœ ì‹ ê²½ ì—°ì‚°ìë¥¼ í†µí•œ ìë™ ë¯¸ë¶„ì„ ì‚¬ìš©í•˜ì—¬ ì œì–´ì— ëŒ€í•œ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ê³„ì‚°í•˜ê³ , ë°˜ë³µ ìµœì í™” ë£¨í‹´ì„ í†µí•´ ìµœì í™”ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
- 4. ì œì•ˆëœ ë°©ë²•ì€ ì‹¤ì§ˆì ì¸ ì‘ìš©ì—ì„œ ìˆ˜ìš© ê°€ëŠ¥í•œ ì •í™•ë„ë¥¼ ë³´ì´ë©°, ë³µì¡í•˜ê³  ê³ ì°¨ì›ì ì¸ ë¬¸ì œì—ì„œì˜ ê³„ì‚° ë¹„ìš© ì ˆê°ì„ ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 01:05:20*