---
keywords:
  - Deep Learning
  - Generalized Laplace Approximation
  - Posterior Tempering
  - Aleatoric Uncertainty
category: cs.LG
publish_date: 2025-09-23
arxiv_id: 2405.13535
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T02:32:22.624464",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Deep Learning",
    "Generalized Laplace Approximation",
    "Posterior Tempering",
    "Aleatoric Uncertainty"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Deep Learning": 0.8,
    "Generalized Laplace Approximation": 0.78,
    "Posterior Tempering": 0.77,
    "Aleatoric Uncertainty": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Bayesian Deep Learning",
        "canonical": "Deep Learning",
        "aliases": [
          "Bayesian DL"
        ],
        "category": "broad_technical",
        "rationale": "Links to the broader field of deep learning, which is central to the paper's focus.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.8
      },
      {
        "surface": "Generalized Laplace Approximation",
        "canonical": "Generalized Laplace Approximation",
        "aliases": [
          "GLA"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel method that is central to the paper's contributions.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Posterior Tempering",
        "canonical": "Posterior Tempering",
        "aliases": [
          "Tempered Posterior"
        ],
        "category": "specific_connectable",
        "rationale": "A specific technique discussed in the paper that enhances understanding of Bayesian adjustments.",
        "novelty_score": 0.6,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      },
      {
        "surface": "Aleatoric Uncertainty",
        "canonical": "Aleatoric Uncertainty",
        "aliases": [
          "Data Uncertainty"
        ],
        "category": "specific_connectable",
        "rationale": "Key concept in understanding uncertainty reduction in Bayesian models.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.78,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "model misspecification",
      "joint probability",
      "regularized loss"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Bayesian Deep Learning",
      "resolved_canonical": "Deep Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Generalized Laplace Approximation",
      "resolved_canonical": "Generalized Laplace Approximation",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Posterior Tempering",
      "resolved_canonical": "Posterior Tempering",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Aleatoric Uncertainty",
      "resolved_canonical": "Aleatoric Uncertainty",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.78,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# Addressing the Inconsistency in Bayesian Deep Learning via Generalized Laplace Approximation

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2405.13535.pdf)
**Category**: cs.LG
**Published**: 2025-09-23
**ArXiv ID**: [2405.13535](https://arxiv.org/abs/2405.13535)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Policy Gradient Optimzation for Bayesian-Risk MDPs with General Convex Losses_20250922|Policy Gradient Optimzation for Bayesian-Risk MDPs with General Convex Losses]] (83.6% similar)
- [[2025-09-17/Online Bayesian Risk-Averse Reinforcement Learning_20250917|Online Bayesian Risk-Averse Reinforcement Learning]] (83.2% similar)
- [[2025-09-18/Post-Hoc Split-Point Self-Consistency Verification for Efficient, Unified Quantification of Aleatoric and Epistemic Uncertainty in Deep Learning_20250918|Post-Hoc Split-Point Self-Consistency Verification for Efficient, Unified Quantification of Aleatoric and Epistemic Uncertainty in Deep Learning]] (82.3% similar)
- [[2025-09-23/Enhancing Performance and Calibration in Quantile Hyperparameter Optimization_20250923|Enhancing Performance and Calibration in Quantile Hyperparameter Optimization]] (82.2% similar)
- [[2025-09-17/Physics-based deep kernel learning for parameter estimation in high dimensional PDEs_20250917|Physics-based deep kernel learning for parameter estimation in high dimensional PDEs]] (82.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Deep Learning|Deep Learning]]
**ğŸ”— Specific Connectable**: [[keywords/Posterior Tempering|Posterior Tempering]], [[keywords/Aleatoric Uncertainty|Aleatoric Uncertainty]]
**âš¡ Unique Technical**: [[keywords/Generalized Laplace Approximation|Generalized Laplace Approximation]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2405.13535v5 Announce Type: replace 
Abstract: In recent years, inconsistency in Bayesian deep learning has attracted significant attention. Tempered or generalized posterior distributions are frequently employed as direct and effective solutions. Nonetheless, the underlying mechanisms and the effectiveness of generalized posteriors remain active research topics. In this work, we interpret posterior tempering as a correction for model misspecification via adjustments to the joint probability, and as a recalibration of priors by reducing aleatoric uncertainty. We also introduce the generalized Laplace approximation, which requires only a simple modification to the Hessian calculation of the regularized loss and provides a flexible and scalable framework for high-quality posterior inference. We evaluate the proposed method on state-of-the-art neural networks and real-world datasets, demonstrating that the generalized Laplace approximation enhances predictive performance.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë² ì´ì§€ì•ˆ ë”¥ëŸ¬ë‹ì—ì„œ ë°œìƒí•˜ëŠ” ë¶ˆì¼ì¹˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ í›„í–‰ ë¶„í¬ì˜ ì¡°ì •ì„ í†µí•œ ëª¨ë¸ì˜ ì˜ëª»ëœ ëª…ì„¸ë¥¼ ìˆ˜ì •í•˜ê³ , ìš°ì„ ìˆœìœ„ë¥¼ ì¬ì¡°ì •í•˜ì—¬ ë¶ˆí™•ì‹¤ì„±ì„ ì¤„ì´ëŠ” ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. íŠ¹íˆ, ì¼ë°˜í™”ëœ ë¼í”Œë¼ìŠ¤ ê·¼ì‚¬ë¥¼ ë„ì…í•˜ì—¬ ì •ê·œí™”ëœ ì†ì‹¤ì˜ í—¤ì‹œì•ˆ ê³„ì‚°ì„ ê°„ë‹¨íˆ ìˆ˜ì •í•¨ìœ¼ë¡œì¨ ê³ í’ˆì§ˆì˜ í›„í–‰ ì¶”ë¡ ì„ ìœ„í•œ ìœ ì—°í•˜ê³  í™•ì¥ ê°€ëŠ¥í•œ í”„ë ˆì„ì›Œí¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì œì•ˆëœ ë°©ë²•ì€ ìµœì‹  ì‹ ê²½ë§ê³¼ ì‹¤ì œ ë°ì´í„°ì…‹ì—ì„œ ì˜ˆì¸¡ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë² ì´ì§€ì•ˆ ë”¥ëŸ¬ë‹ì˜ ë¶ˆì¼ì¹˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ í…œí¼ë§ëœ ë˜ëŠ” ì¼ë°˜í™”ëœ ì‚¬í›„ ë¶„í¬ê°€ ìì£¼ ì‚¬ìš©ëœë‹¤.
- 2. ë³¸ ì—°êµ¬ì—ì„œëŠ” ëª¨ë¸ì˜ ì˜ëª»ëœ ëª…ì„¸ë¥¼ ìˆ˜ì •í•˜ê³ , ì‚¬ì „ í™•ë¥ ì„ ì¬ì¡°ì •í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ ì‚¬í›„ í…œí¼ë§ì„ í•´ì„í•œë‹¤.
- 3. ì¼ë°˜í™”ëœ ë¼í”Œë¼ìŠ¤ ê·¼ì‚¬ë¥¼ ë„ì…í•˜ì—¬ ì •ê·œí™”ëœ ì†ì‹¤ì˜ í—¤ì‹œì•ˆ ê³„ì‚°ì„ ê°„ë‹¨íˆ ìˆ˜ì •í•¨ìœ¼ë¡œì¨ ê³ í’ˆì§ˆì˜ ì‚¬í›„ ì¶”ë¡ ì„ ìœ„í•œ ìœ ì—°í•˜ê³  í™•ì¥ ê°€ëŠ¥í•œ í”„ë ˆì„ì›Œí¬ë¥¼ ì œê³µí•œë‹¤.
- 4. ì œì•ˆëœ ë°©ë²•ì€ ìµœì‹  ì‹ ê²½ë§ê³¼ ì‹¤ì œ ë°ì´í„°ì…‹ì—ì„œ ì˜ˆì¸¡ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¨ë‹¤.


---

*Generated on 2025-09-24 02:32:22*