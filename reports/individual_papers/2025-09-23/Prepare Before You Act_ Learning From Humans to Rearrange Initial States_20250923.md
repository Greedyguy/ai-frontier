---
keywords:
  - Imitation Learning
  - ReSET Algorithm
  - Teleoperation Data
  - Diffusion Policies
  - Human Videos
category: cs.LG
publish_date: 2025-09-23
arxiv_id: 2509.18043
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T02:30:06.683387",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Imitation Learning",
    "ReSET Algorithm",
    "Teleoperation Data",
    "Diffusion Policies",
    "Human Videos"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Imitation Learning": 0.8,
    "ReSET Algorithm": 0.88,
    "Teleoperation Data": 0.78,
    "Diffusion Policies": 0.77,
    "Human Videos": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Imitation Learning",
        "canonical": "Imitation Learning",
        "aliases": [
          "IL"
        ],
        "category": "specific_connectable",
        "rationale": "Imitation Learning is central to the paper's approach and connects to a wide range of learning methods.",
        "novelty_score": 0.55,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "ReSET algorithm",
        "canonical": "ReSET Algorithm",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "ReSET is a novel algorithm introduced in the paper, crucial for understanding the proposed method.",
        "novelty_score": 0.9,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.88
      },
      {
        "surface": "Teleoperation data",
        "canonical": "Teleoperation Data",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Teleoperation data is a key component in training the algorithm, linking to data collection techniques.",
        "novelty_score": 0.6,
        "connectivity_score": 0.75,
        "specificity_score": 0.72,
        "link_intent_score": 0.78
      },
      {
        "surface": "Diffusion policies",
        "canonical": "Diffusion Policies",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Diffusion policies are compared against the proposed method, providing context for evaluation.",
        "novelty_score": 0.58,
        "connectivity_score": 0.7,
        "specificity_score": 0.68,
        "link_intent_score": 0.77
      },
      {
        "surface": "Human videos",
        "canonical": "Human Videos",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Human videos are used for action prediction, linking to human-robot interaction studies.",
        "novelty_score": 0.65,
        "connectivity_score": 0.78,
        "specificity_score": 0.71,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Imitation Learning",
      "resolved_canonical": "Imitation Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "ReSET algorithm",
      "resolved_canonical": "ReSET Algorithm",
      "decision": "linked",
      "scores": {
        "novelty": 0.9,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "Teleoperation data",
      "resolved_canonical": "Teleoperation Data",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.75,
        "specificity": 0.72,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Diffusion policies",
      "resolved_canonical": "Diffusion Policies",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.7,
        "specificity": 0.68,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Human videos",
      "resolved_canonical": "Human Videos",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.78,
        "specificity": 0.71,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Prepare Before You Act: Learning From Humans to Rearrange Initial States

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18043.pdf)
**Category**: cs.LG
**Published**: 2025-09-23
**ArXiv ID**: [2509.18043](https://arxiv.org/abs/2509.18043)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Latent Policy Steering with Embodiment-Agnostic Pretrained World Models_20250923|Latent Policy Steering with Embodiment-Agnostic Pretrained World Models]] (84.6% similar)
- [[2025-09-23/Look, Focus, Act_ Efficient and Robust Robot Learning via Human Gaze and Foveated Vision Transformers_20250923|Look, Focus, Act: Efficient and Robust Robot Learning via Human Gaze and Foveated Vision Transformers]] (82.6% similar)
- [[2025-09-18/Robot Control Stack_ A Lean Ecosystem for Robot Learning at Scale_20250918|Robot Control Stack: A Lean Ecosystem for Robot Learning at Scale]] (82.6% similar)
- [[2025-09-22/Uncertainty-Based Smooth Policy Regularisation for Reinforcement Learning with Few Demonstrations_20250922|Uncertainty-Based Smooth Policy Regularisation for Reinforcement Learning with Few Demonstrations]] (82.5% similar)
- [[2025-09-19/Learning Discrete Abstractions for Visual Rearrangement Tasks Using Vision-Guided Graph Coloring_20250919|Learning Discrete Abstractions for Visual Rearrangement Tasks Using Vision-Guided Graph Coloring]] (82.4% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Imitation Learning|Imitation Learning]], [[keywords/Teleoperation Data|Teleoperation Data]], [[keywords/Diffusion Policies|Diffusion Policies]], [[keywords/Human Videos|Human Videos]]
**âš¡ Unique Technical**: [[keywords/ReSET Algorithm|ReSET Algorithm]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18043v1 Announce Type: cross 
Abstract: Imitation learning (IL) has proven effective across a wide range of manipulation tasks. However, IL policies often struggle when faced with out-of-distribution observations; for instance, when the target object is in a previously unseen position or occluded by other objects. In these cases, extensive demonstrations are needed for current IL methods to reach robust and generalizable behaviors. But when humans are faced with these sorts of atypical initial states, we often rearrange the environment for more favorable task execution. For example, a person might rotate a coffee cup so that it is easier to grasp the handle, or push a box out of the way so they can directly grasp their target object. In this work we seek to equip robot learners with the same capability: enabling robots to prepare the environment before executing their given policy. We propose ReSET, an algorithm that takes initial states -- which are outside the policy's distribution -- and autonomously modifies object poses so that the restructured scene is similar to training data. Theoretically, we show that this two step process (rearranging the environment before rolling out the given policy) reduces the generalization gap. Practically, our ReSET algorithm combines action-agnostic human videos with task-agnostic teleoperation data to i) decide when to modify the scene, ii) predict what simplifying actions a human would take, and iii) map those predictions into robot action primitives. Comparisons with diffusion policies, VLAs, and other baselines show that using ReSET to prepare the environment enables more robust task execution with equal amounts of total training data. See videos at our project website: https://reset2025paper.github.io/

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë¡œë´‡ í•™ìŠµì—ì„œ í™˜ê²½ì„ ì‚¬ì „ì— ì¤€ë¹„í•˜ëŠ” ëŠ¥ë ¥ì„ ë¶€ì—¬í•˜ëŠ” ReSET ì•Œê³ ë¦¬ì¦˜ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ ëª¨ë°© í•™ìŠµì€ ê´€ì°°ì´ ë¶„í¬ ë°–ì— ìˆì„ ë•Œ ì–´ë ¤ì›€ì„ ê²ªì§€ë§Œ, ReSETì€ ì´ˆê¸° ìƒíƒœë¥¼ ì¡°ì •í•˜ì—¬ í›ˆë ¨ ë°ì´í„°ì™€ ìœ ì‚¬í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤. ì´ ê³¼ì •ì€ ì¼ë°˜í™” ê²©ì°¨ë¥¼ ì¤„ì´ë©°, ì¸ê°„ì˜ ë¹„ë””ì˜¤ì™€ ì›ê²© ì¡°ì‘ ë°ì´í„°ë¥¼ í™œìš©í•´ ì¥ë©´ ìˆ˜ì • ì‹œì ê³¼ ê°„ì†Œí™” í–‰ë™ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ReSETì€ í™˜ê²½ ì¤€ë¹„ë¥¼ í†µí•´ ë” ê°•ë ¥í•œ ì‘ì—… ìˆ˜í–‰ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëª¨ë°© í•™ìŠµ(IL)ì€ ë‹¤ì–‘í•œ ì¡°ì‘ ì‘ì—…ì—ì„œ íš¨ê³¼ì ì´ì§€ë§Œ, ë¶„í¬ ë°–ì˜ ê´€ì¸¡ì— ì§ë©´í–ˆì„ ë•Œ ì–´ë ¤ì›€ì„ ê²ªìŠµë‹ˆë‹¤.
- 2. ì¸ê°„ì€ ë¹„ì •ìƒì ì¸ ì´ˆê¸° ìƒíƒœì—ì„œ í™˜ê²½ì„ ì¬ë°°ì¹˜í•˜ì—¬ ì‘ì—…ì„ ë” ì‰½ê²Œ ìˆ˜í–‰í•˜ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤.
- 3. ReSET ì•Œê³ ë¦¬ì¦˜ì€ ë¡œë´‡ì´ ì •ì±… ì‹¤í–‰ ì „ì— í™˜ê²½ì„ ì¤€ë¹„í•  ìˆ˜ ìˆë„ë¡ í•˜ì—¬ ì¼ë°˜í™” ê²©ì°¨ë¥¼ ì¤„ì…ë‹ˆë‹¤.
- 4. ReSETì€ ì¸ê°„ì˜ ë¹„ë””ì˜¤ì™€ ì›ê²© ì¡°ì‘ ë°ì´í„°ë¥¼ ê²°í•©í•˜ì—¬ ì¥ë©´ ìˆ˜ì • ì‹œì ê³¼ ë‹¨ìˆœí™” í–‰ë™ì„ ì˜ˆì¸¡í•˜ê³  ì´ë¥¼ ë¡œë´‡ í–‰ë™ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
- 5. ReSETì„ ì‚¬ìš©í•˜ë©´ ë™ì¼í•œ ì–‘ì˜ í›ˆë ¨ ë°ì´í„°ë¡œ ë” ê²¬ê³ í•œ ì‘ì—… ìˆ˜í–‰ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 02:30:06*