---
keywords:
  - Multimodal Learning
  - Machine Unlearning
  - Prompt Decouple Loss
  - Safe Answer Refusal Rate
category: cs.CV
publish_date: 2025-09-23
arxiv_id: 2502.12520
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T05:17:07.230138",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multimodal Learning",
    "Machine Unlearning",
    "Prompt Decouple Loss",
    "Safe Answer Refusal Rate"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multimodal Learning": 0.82,
    "Machine Unlearning": 0.79,
    "Prompt Decouple Loss": 0.77,
    "Safe Answer Refusal Rate": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multimodal Large Language Models",
        "canonical": "Multimodal Learning",
        "aliases": [
          "MLLMs"
        ],
        "category": "specific_connectable",
        "rationale": "Multimodal Learning connects language and vision models, crucial for understanding the paper's focus on safety in these models.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "Machine Unlearning",
        "canonical": "Machine Unlearning",
        "aliases": [
          "MU"
        ],
        "category": "unique_technical",
        "rationale": "Machine Unlearning is a central theme of the paper, focusing on forgetting specific knowledge, which is a unique technical concept.",
        "novelty_score": 0.72,
        "connectivity_score": 0.65,
        "specificity_score": 0.81,
        "link_intent_score": 0.79
      },
      {
        "surface": "Prompt Decouple Loss",
        "canonical": "Prompt Decouple Loss",
        "aliases": [
          "PD Loss"
        ],
        "category": "unique_technical",
        "rationale": "Prompt Decouple Loss is a novel method introduced to mitigate over-forgetting, making it a unique technical contribution.",
        "novelty_score": 0.78,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      },
      {
        "surface": "Safe Answer Refusal Rate",
        "canonical": "Safe Answer Refusal Rate",
        "aliases": [
          "SARR"
        ],
        "category": "unique_technical",
        "rationale": "Safe Answer Refusal Rate is a new metric proposed in the paper, crucial for evaluating the effectiveness of the proposed methods.",
        "novelty_score": 0.75,
        "connectivity_score": 0.58,
        "specificity_score": 0.83,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "forget quality",
      "model utility",
      "over-forgetting"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multimodal Large Language Models",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Machine Unlearning",
      "resolved_canonical": "Machine Unlearning",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.65,
        "specificity": 0.81,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Prompt Decouple Loss",
      "resolved_canonical": "Prompt Decouple Loss",
      "decision": "linked",
      "scores": {
        "novelty": 0.78,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Safe Answer Refusal Rate",
      "resolved_canonical": "Safe Answer Refusal Rate",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.58,
        "specificity": 0.83,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# SafeEraser: Enhancing Safety in Multimodal Large Language Models through Multimodal Machine Unlearning

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2502.12520.pdf)
**Category**: cs.CV
**Published**: 2025-09-23
**ArXiv ID**: [2502.12520](https://arxiv.org/abs/2502.12520)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/SUA_ Stealthy Multimodal Large Language Model Unlearning Attack_20250923|SUA: Stealthy Multimodal Large Language Model Unlearning Attack]] (88.5% similar)
- [[2025-09-18/Reveal and Release_ Iterative LLM Unlearning with Self-generated Data_20250918|Reveal and Release: Iterative LLM Unlearning with Self-generated Data]] (86.7% similar)
- [[2025-09-22/Sparse-Autoencoder-Guided Internal Representation Unlearning for Large Language Models_20250922|Sparse-Autoencoder-Guided Internal Representation Unlearning for Large Language Models]] (86.3% similar)
- [[2025-09-22/Are Vision-Language Models Safe in the Wild? A Meme-Based Benchmark Study_20250922|Are Vision-Language Models Safe in the Wild? A Meme-Based Benchmark Study]] (85.7% similar)
- [[2025-09-17/Scrub It Out! Erasing Sensitive Memorization in Code Language Models via Machine Unlearning_20250917|Scrub It Out! Erasing Sensitive Memorization in Code Language Models via Machine Unlearning]] (85.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**âš¡ Unique Technical**: [[keywords/Machine Unlearning|Machine Unlearning]], [[keywords/Prompt Decouple Loss|Prompt Decouple Loss]], [[keywords/Safe Answer Refusal Rate|Safe Answer Refusal Rate]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2502.12520v3 Announce Type: replace 
Abstract: As Multimodal Large Language Models (MLLMs) develop, their potential security issues have become increasingly prominent. Machine Unlearning (MU), as an effective strategy for forgetting specific knowledge in training data, has been widely used in privacy protection. However, MU for safety in MLLM has yet to be fully explored. To address this issue, we propose SAFEERASER, a safety unlearning benchmark for MLLMs, consisting of 3,000 images and 28.8K VQA pairs. We comprehensively evaluate unlearning methods from two perspectives: forget quality and model utility. Our findings show that existing MU methods struggle to maintain model performance while implementing the forget operation and often suffer from over-forgetting. Hence, we introduce Prompt Decouple (PD) Loss to alleviate over-forgetting through decouple prompt during unlearning process. To quantitatively measure over-forgetting mitigated by PD Loss, we propose a new metric called Safe Answer Refusal Rate (SARR). Experimental results demonstrate that combining PD Loss with existing unlearning methods can effectively prevent over-forgetting and achieve a decrease of 79.5% in the SARR metric of LLaVA-7B and LLaVA-13B, while maintaining forget quality and model utility. Our code and dataset will be released upon acceptance. Warning: This paper contains examples of harmful language and images, and reader discretion is recommended.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë‹¤ì¤‘ ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(MLLM)ì˜ ì•ˆì „ì„± ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ SAFEERASERë¼ëŠ” ì•ˆì „í•œ í•™ìŠµ ì œê±° ë²¤ì¹˜ë§ˆí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. SAFEERASERëŠ” 3,000ê°œì˜ ì´ë¯¸ì§€ì™€ 28,800ê°œì˜ VQA ìŒìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, í•™ìŠµ ì œê±° ë°©ë²•ì„ ë§ê° í’ˆì§ˆê³¼ ëª¨ë¸ ìœ ìš©ì„± ì¸¡ë©´ì—ì„œ í‰ê°€í•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ í•™ìŠµ ì œê±° ë°©ë²•ì€ ëª¨ë¸ ì„±ëŠ¥ì„ ìœ ì§€í•˜ë©´ì„œ ë§ê° ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªê³ , ê³¼ë„í•œ ë§ê° ë¬¸ì œê°€ ë°œìƒí•©ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ Prompt Decouple (PD) Lossë¥¼ ë„ì…í•˜ì—¬ ë§ê° ê³¼ì •ì—ì„œ ê³¼ë„í•œ ë§ê°ì„ ì™„í™”í•©ë‹ˆë‹¤. Safe Answer Refusal Rate (SARR)ë¼ëŠ” ìƒˆë¡œìš´ ì§€í‘œë¥¼ ì œì•ˆí•˜ì—¬ PD Lossê°€ ê³¼ë„í•œ ë§ê°ì„ ì–¼ë§ˆë‚˜ ì™„í™”í•˜ëŠ”ì§€ ì¸¡ì •í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, PD Lossë¥¼ ê¸°ì¡´ ë°©ë²•ê³¼ ê²°í•©í•˜ë©´ ê³¼ë„í•œ ë§ê°ì„ íš¨ê³¼ì ìœ¼ë¡œ ë°©ì§€í•˜ê³ , LLaVA-7Bì™€ LLaVA-13Bì˜ SARR ì§€í‘œë¥¼ 79.5% ê°ì†Œì‹œí‚¤ë©´ì„œ ë§ê° í’ˆì§ˆê³¼ ëª¨ë¸ ìœ ìš©ì„±ì„ ìœ ì§€í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì½”ë“œì™€ ë°ì´í„°ì…‹ì€ ìŠ¹ì¸ í›„ ê³µê°œë  ì˜ˆì •ì…ë‹ˆë‹¤. ì£¼ì˜: ì´ ë…¼ë¬¸ì—ëŠ” ìœ í•´í•œ ì–¸ì–´ì™€ ì´ë¯¸ì§€ì˜ ì˜ˆê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë©€í‹°ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(MLLM)ì˜ ì•ˆì „ì„± ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ SAFEERASERë¼ëŠ” ì•ˆì „ì„± ì–¸ëŸ¬ë‹ ë²¤ì¹˜ë§ˆí¬ë¥¼ ì œì•ˆí–ˆìŠµë‹ˆë‹¤.
- 2. ê¸°ì¡´ì˜ ë¨¸ì‹  ì–¸ëŸ¬ë‹(MU) ë°©ë²•ì€ ëª¨ë¸ ì„±ëŠ¥ì„ ìœ ì§€í•˜ë©´ì„œ íŠ¹ì • ì§€ì‹ì„ ìŠê²Œ í•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªê³  ìˆìœ¼ë©°, ê³¼ë„í•œ ìŠìŒ í˜„ìƒì´ ë°œìƒí•©ë‹ˆë‹¤.
- 3. ê³¼ë„í•œ ìŠìŒì„ ì™„í™”í•˜ê¸° ìœ„í•´ í”„ë¡¬í”„íŠ¸ ë””ì»¤í”Œ(PD) ì†ì‹¤ì„ ë„ì…í•˜ì˜€ìœ¼ë©°, ì´ë¥¼ í†µí•´ ì•ˆì „í•œ ë‹µë³€ ê±°ë¶€ìœ¨(SARR)ì´ë¼ëŠ” ìƒˆë¡œìš´ ì§€í‘œë¥¼ ì œì•ˆí–ˆìŠµë‹ˆë‹¤.
- 4. ì‹¤í—˜ ê²°ê³¼, PD ì†ì‹¤ì„ ê¸°ì¡´ ì–¸ëŸ¬ë‹ ë°©ë²•ê³¼ ê²°í•©í•˜ë©´ ê³¼ë„í•œ ìŠìŒì„ íš¨ê³¼ì ìœ¼ë¡œ ë°©ì§€í•˜ê³ , LLaVA-7B ë° LLaVA-13B ëª¨ë¸ì—ì„œ SARR ì§€í‘œë¥¼ 79.5% ê°ì†Œì‹œí‚¬ ìˆ˜ ìˆìŒì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤.
- 5. ë³¸ ë…¼ë¬¸ì€ ìœ í•´í•œ ì–¸ì–´ì™€ ì´ë¯¸ì§€ì˜ ì˜ˆì‹œë¥¼ í¬í•¨í•˜ê³  ìˆìœ¼ë¯€ë¡œ ë…ìì˜ ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 05:17:07*