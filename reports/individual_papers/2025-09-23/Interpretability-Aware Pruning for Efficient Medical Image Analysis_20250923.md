---
keywords:
  - Deep Learning
  - Interpretability Techniques
  - Layer-wise Relevance Propagation
  - Medical Image Analysis
  - Interpretability-Guided Pruning
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2507.08330
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T01:12:23.037085",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Deep Learning",
    "Interpretability Techniques",
    "Layer-wise Relevance Propagation",
    "Medical Image Analysis",
    "Interpretability-Guided Pruning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Deep Learning": 0.85,
    "Interpretability Techniques": 0.78,
    "Layer-wise Relevance Propagation": 0.8,
    "Medical Image Analysis": 0.77,
    "Interpretability-Guided Pruning": 0.81
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Deep Learning",
        "canonical": "Deep Learning",
        "aliases": [
          "DL"
        ],
        "category": "broad_technical",
        "rationale": "Deep Learning is a foundational technology in medical image analysis, facilitating strong connections with other machine learning concepts.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Interpretability Techniques",
        "canonical": "Interpretability Techniques",
        "aliases": [
          "Model Interpretability"
        ],
        "category": "unique_technical",
        "rationale": "Interpretability is crucial for clinical adoption, providing a unique angle for linking with transparency and model analysis topics.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Layer-wise Relevance Propagation",
        "canonical": "Layer-wise Relevance Propagation",
        "aliases": [
          "LRP"
        ],
        "category": "specific_connectable",
        "rationale": "A specific interpretability method that can connect with other model analysis frameworks.",
        "novelty_score": 0.6,
        "connectivity_score": 0.75,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Medical Image Analysis",
        "canonical": "Medical Image Analysis",
        "aliases": [
          "Medical Imaging"
        ],
        "category": "specific_connectable",
        "rationale": "A key application area that links with healthcare and image processing domains.",
        "novelty_score": 0.5,
        "connectivity_score": 0.82,
        "specificity_score": 0.7,
        "link_intent_score": 0.77
      },
      {
        "surface": "Interpretability-Guided Pruning",
        "canonical": "Interpretability-Guided Pruning",
        "aliases": [
          "Pruning with Interpretability"
        ],
        "category": "unique_technical",
        "rationale": "A novel approach that combines model compression with transparency, offering a unique linking opportunity.",
        "novelty_score": 0.75,
        "connectivity_score": 0.7,
        "specificity_score": 0.9,
        "link_intent_score": 0.81
      }
    ],
    "ban_list_suggestions": [
      "model complexity",
      "predictive performance",
      "compression rates"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Deep Learning",
      "resolved_canonical": "Deep Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Interpretability Techniques",
      "resolved_canonical": "Interpretability Techniques",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Layer-wise Relevance Propagation",
      "resolved_canonical": "Layer-wise Relevance Propagation",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.75,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Medical Image Analysis",
      "resolved_canonical": "Medical Image Analysis",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.82,
        "specificity": 0.7,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Interpretability-Guided Pruning",
      "resolved_canonical": "Interpretability-Guided Pruning",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.7,
        "specificity": 0.9,
        "link_intent": 0.81
      }
    }
  ]
}
-->

# Interpretability-Aware Pruning for Efficient Medical Image Analysis

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2507.08330.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2507.08330](https://arxiv.org/abs/2507.08330)

## 🔗 유사한 논문
- [[2025-09-22/Temperature-Driven Robust Disease Detection in Brain and Gastrointestinal Disorders via Context-Aware Adaptive Knowledge Distillation_20250922|Temperature-Driven Robust Disease Detection in Brain and Gastrointestinal Disorders via Context-Aware Adaptive Knowledge Distillation]] (84.9% similar)
- [[2025-09-18/Locally Explaining Prediction Behavior via Gradual Interventions and Measuring Property Gradients_20250918|Locally Explaining Prediction Behavior via Gradual Interventions and Measuring Property Gradients]] (84.7% similar)
- [[2025-09-22/Data-Efficient Learning for Generalizable Surgical Video Understanding_20250922|Data-Efficient Learning for Generalizable Surgical Video Understanding]] (84.2% similar)
- [[2025-09-19/Fine-tuning Vision Language Models with Graph-based Knowledge for Explainable Medical Image Analysis_20250919|Fine-tuning Vision Language Models with Graph-based Knowledge for Explainable Medical Image Analysis]] (83.7% similar)
- [[2025-09-22/No Black Box Anymore_ Demystifying Clinical Predictive Modeling with Temporal-Feature Cross Attention Mechanism_20250922|No Black Box Anymore: Demystifying Clinical Predictive Modeling with Temporal-Feature Cross Attention Mechanism]] (82.7% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Deep Learning|Deep Learning]]
**🔗 Specific Connectable**: [[keywords/Layer-wise Relevance Propagation|Layer-wise Relevance Propagation]], [[keywords/Medical Image Analysis|Medical Image Analysis]]
**⚡ Unique Technical**: [[keywords/Interpretability Techniques|Interpretability Techniques]], [[keywords/Interpretability-Guided Pruning|Interpretability-Guided Pruning]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2507.08330v2 Announce Type: replace-cross 
Abstract: Deep learning has driven significant advances in medical image analysis, yet its adoption in clinical practice remains constrained by the large size and lack of transparency in modern models. Advances in interpretability techniques such as DL-Backtrace, Layer-wise Relevance Propagation, and Integrated Gradients make it possible to assess the contribution of individual components within neural networks trained on medical imaging tasks. In this work, we introduce an interpretability-guided pruning framework that reduces model complexity while preserving both predictive performance and transparency. By selectively retaining only the most relevant parts of each layer, our method enables targeted compression that maintains clinically meaningful representations. Experiments across multiple medical image classification benchmarks demonstrate that this approach achieves high compression rates with minimal loss in accuracy, paving the way for lightweight, interpretable models suited for real-world deployment in healthcare settings.

## 📝 요약

이 논문은 의료 영상 분석에서 딥러닝 모델의 복잡성을 줄이면서도 예측 성능과 투명성을 유지하는 해석 가능성 기반 가지치기 프레임워크를 제안합니다. DL-Backtrace, Layer-wise Relevance Propagation, Integrated Gradients와 같은 해석 기법을 활용하여 신경망의 각 구성 요소의 기여도를 평가하고, 각 층에서 가장 관련성이 높은 부분만 선택적으로 유지함으로써 모델을 압축합니다. 여러 의료 영상 분류 벤치마크 실험에서 높은 압축률과 최소한의 정확도 손실을 달성하여, 실제 의료 환경에 적합한 경량의 해석 가능한 모델 개발 가능성을 보여줍니다.

## 🎯 주요 포인트

- 1. 딥러닝은 의료 영상 분석에서 큰 발전을 이루었지만, 모델의 크기와 투명성 부족으로 임상 적용이 제한적이다.
- 2. DL-Backtrace, Layer-wise Relevance Propagation, Integrated Gradients와 같은 해석 가능성 기법의 발전으로 의료 영상 작업에 훈련된 신경망의 구성 요소 기여도를 평가할 수 있다.
- 3. 본 연구는 예측 성능과 투명성을 유지하면서 모델 복잡성을 줄이는 해석 가능성 기반 가지치기 프레임워크를 제안한다.
- 4. 각 층에서 가장 관련성이 높은 부분만 선택적으로 유지하여 임상적으로 의미 있는 표현을 유지하면서 모델 압축을 가능하게 한다.
- 5. 여러 의료 영상 분류 벤치마크 실험에서 높은 압축률과 최소한의 정확도 손실을 달성하여, 실제 의료 환경에 적합한 경량의 해석 가능한 모델 개발 가능성을 제시한다.


---

*Generated on 2025-09-24 01:12:23*