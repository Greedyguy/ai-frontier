---
keywords:
  - Class-Imbalanced Multi-Label Image Classification
  - Vision-Language Model
  - Hierarchical Prompt-Tuning
  - Semantic Consistency Loss
  - Few-Shot Learning
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.17747
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T00:07:34.058137",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Class-Imbalanced Multi-Label Image Classification",
    "Vision-Language Model",
    "Hierarchical Prompt-Tuning",
    "Semantic Consistency Loss",
    "Few-Shot Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Class-Imbalanced Multi-Label Image Classification": 0.78,
    "Vision-Language Model": 0.81,
    "Hierarchical Prompt-Tuning": 0.79,
    "Semantic Consistency Loss": 0.75,
    "Few-Shot Learning": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Class-Imbalanced Multi-Label Image Classification",
        "canonical": "Class-Imbalanced Multi-Label Image Classification",
        "aliases": [
          "CI-MLIC"
        ],
        "category": "unique_technical",
        "rationale": "This term is central to the paper's focus and represents a specific challenge in machine learning, making it a unique technical concept.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Vision-Language Pretrained Models",
        "canonical": "Vision-Language Model",
        "aliases": [
          "VLP Models"
        ],
        "category": "evolved_concepts",
        "rationale": "The use of vision-language models is a key aspect of the proposed method, linking it to current trends in multimodal learning.",
        "novelty_score": 0.58,
        "connectivity_score": 0.88,
        "specificity_score": 0.72,
        "link_intent_score": 0.81
      },
      {
        "surface": "Hierarchical Prompt-Tuning",
        "canonical": "Hierarchical Prompt-Tuning",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This novel technique is introduced in the paper and is crucial for adapting VLP models to specific tasks, offering a new avenue for exploration.",
        "novelty_score": 0.82,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.79
      },
      {
        "surface": "Semantic Consistency Loss",
        "canonical": "Semantic Consistency Loss",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This loss function is specifically designed to maintain general knowledge during prompt tuning, representing a unique contribution.",
        "novelty_score": 0.78,
        "connectivity_score": 0.67,
        "specificity_score": 0.77,
        "link_intent_score": 0.75
      },
      {
        "surface": "Few-Shot Learning",
        "canonical": "Few-Shot Learning",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Few-shot learning is a significant aspect of the paper's evaluation, connecting it to broader research in learning with limited data.",
        "novelty_score": 0.55,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "method",
      "approach",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Class-Imbalanced Multi-Label Image Classification",
      "resolved_canonical": "Class-Imbalanced Multi-Label Image Classification",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Vision-Language Pretrained Models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.88,
        "specificity": 0.72,
        "link_intent": 0.81
      }
    },
    {
      "candidate_surface": "Hierarchical Prompt-Tuning",
      "resolved_canonical": "Hierarchical Prompt-Tuning",
      "decision": "linked",
      "scores": {
        "novelty": 0.82,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Semantic Consistency Loss",
      "resolved_canonical": "Semantic Consistency Loss",
      "decision": "linked",
      "scores": {
        "novelty": 0.78,
        "connectivity": 0.67,
        "specificity": 0.77,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Few-Shot Learning",
      "resolved_canonical": "Few-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# Dual-View Alignment Learning with Hierarchical-Prompt for Class-Imbalance Multi-Label Classification

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17747.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.17747](https://arxiv.org/abs/2509.17747)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Multi-label Scene Classification for Autonomous Vehicles_ Acquiring and Accumulating Knowledge from Diverse Datasets_20250919|Multi-label Scene Classification for Autonomous Vehicles: Acquiring and Accumulating Knowledge from Diverse Datasets]] (83.5% similar)
- [[2025-09-22/Towards Robust Visual Continual Learning with Multi-Prototype Supervision_20250922|Towards Robust Visual Continual Learning with Multi-Prototype Supervision]] (83.3% similar)
- [[2025-09-19/Decoupled Proxy Alignment_ Mitigating Language Prior Conflict for Multimodal Alignment in MLLM_20250919|Decoupled Proxy Alignment: Mitigating Language Prior Conflict for Multimodal Alignment in MLLM]] (83.0% similar)
- [[2025-09-22/Perception-R1_ Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward_20250922|Perception-R1: Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward]] (82.7% similar)
- [[2025-09-23/Multimodal Medical Image Classification via Synergistic Learning Pre-training_20250923|Multimodal Medical Image Classification via Synergistic Learning Pre-training]] (82.7% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Few-Shot Learning|Few-Shot Learning]]
**âš¡ Unique Technical**: [[keywords/Class-Imbalanced Multi-Label Image Classification|Class-Imbalanced Multi-Label Image Classification]], [[keywords/Hierarchical Prompt-Tuning|Hierarchical Prompt-Tuning]], [[keywords/Semantic Consistency Loss|Semantic Consistency Loss]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17747v1 Announce Type: cross 
Abstract: Real-world datasets often exhibit class imbalance across multiple categories, manifesting as long-tailed distributions and few-shot scenarios. This is especially challenging in Class-Imbalanced Multi-Label Image Classification (CI-MLIC) tasks, where data imbalance and multi-object recognition present significant obstacles. To address these challenges, we propose a novel method termed Dual-View Alignment Learning with Hierarchical Prompt (HP-DVAL), which leverages multi-modal knowledge from vision-language pretrained (VLP) models to mitigate the class-imbalance problem in multi-label settings. Specifically, HP-DVAL employs dual-view alignment learning to transfer the powerful feature representation capabilities from VLP models by extracting complementary features for accurate image-text alignment. To better adapt VLP models for CI-MLIC tasks, we introduce a hierarchical prompt-tuning strategy that utilizes global and local prompts to learn task-specific and context-related prior knowledge. Additionally, we design a semantic consistency loss during prompt tuning to prevent learned prompts from deviating from general knowledge embedded in VLP models. The effectiveness of our approach is validated on two CI-MLIC benchmarks: MS-COCO and VOC2007. Extensive experimental results demonstrate the superiority of our method over SOTA approaches, achieving mAP improvements of 10.0\% and 5.2\% on the long-tailed multi-label image classification task, and 6.8\% and 2.9\% on the multi-label few-shot image classification task.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ í´ë˜ìŠ¤ ë¶ˆê· í˜•ì´ ìˆëŠ” ë‹¤ì¤‘ ë ˆì´ë¸” ì´ë¯¸ì§€ ë¶„ë¥˜(CI-MLIC) ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ìƒˆë¡œìš´ ë°©ë²•ì¸ ê³„ì¸µì  í”„ë¡¬í”„íŠ¸ë¥¼ í™œìš©í•œ ì´ì¤‘ ë·° ì •ë ¬ í•™ìŠµ(HP-DVAL)ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ë¹„ì „-ì–¸ì–´ ì‚¬ì „ í•™ìŠµ(VLP) ëª¨ë¸ì˜ ë‹¤ì¤‘ ëª¨ë‹¬ ì§€ì‹ì„ í™œìš©í•˜ì—¬ í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œë¥¼ ì™„í™”í•©ë‹ˆë‹¤. HP-DVALì€ VLP ëª¨ë¸ì˜ ê°•ë ¥í•œ íŠ¹ì§• í‘œí˜„ ëŠ¥ë ¥ì„ ì „ì´í•˜ì—¬ ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ì •ë ¬ì„ ì •í™•íˆ í•˜ê¸° ìœ„í•´ ë³´ì™„ì ì¸ íŠ¹ì§•ì„ ì¶”ì¶œí•©ë‹ˆë‹¤. ë˜í•œ, ê¸€ë¡œë²Œ ë° ë¡œì»¬ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ê³¼ì œë³„ ë° ë¬¸ë§¥ ê´€ë ¨ ì‚¬ì „ ì§€ì‹ì„ í•™ìŠµí•˜ëŠ” ê³„ì¸µì  í”„ë¡¬í”„íŠ¸ íŠœë‹ ì „ëµì„ ë„ì…í•˜ê³ , ì˜ë¯¸ì  ì¼ê´€ì„± ì†ì‹¤ì„ ì„¤ê³„í•˜ì—¬ í•™ìŠµëœ í”„ë¡¬í”„íŠ¸ê°€ VLP ëª¨ë¸ì— ë‚´ì¬ëœ ì¼ë°˜ ì§€ì‹ì—ì„œ ë²—ì–´ë‚˜ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤. MS-COCOì™€ VOC2007 ë²¤ì¹˜ë§ˆí¬ì—ì„œì˜ ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì´ ê¸°ì¡´ ìµœì²¨ë‹¨ ë°©ë²•ë“¤ë³´ë‹¤ ìš°ìˆ˜í•˜ë©°, ê¸´ ê¼¬ë¦¬ ë‹¤ì¤‘ ë ˆì´ë¸” ì´ë¯¸ì§€ ë¶„ë¥˜ì—ì„œ 10.0% ë° 5.2%, ë‹¤ì¤‘ ë ˆì´ë¸” ì†Œìˆ˜ ìƒ· ì´ë¯¸ì§€ ë¶„ë¥˜ì—ì„œ 6.8% ë° 2.9%ì˜ mAP í–¥ìƒì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. HP-DVALì€ ë¹„ì „-ì–¸ì–´ ì‚¬ì „ í•™ìŠµ ëª¨ë¸(VLP)ì„ í™œìš©í•˜ì—¬ í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ìƒˆë¡œìš´ ë°©ë²•ì…ë‹ˆë‹¤.
- 2. ë“€ì–¼ ë·° ì •ë ¬ í•™ìŠµì„ í†µí•´ VLP ëª¨ë¸ì˜ ê°•ë ¥í•œ íŠ¹ì§• í‘œí˜„ ëŠ¥ë ¥ì„ ì „ì´í•˜ì—¬ ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ì •ë ¬ì„ ì •í™•í•˜ê²Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.
- 3. ê³„ì¸µì  í”„ë¡¬í”„íŠ¸ íŠœë‹ ì „ëµì„ ë„ì…í•˜ì—¬ ê¸€ë¡œë²Œ ë° ë¡œì»¬ í”„ë¡¬í”„íŠ¸ë¥¼ í™œìš©í•´ ê³¼ì œ íŠ¹í™” ë° ë¬¸ë§¥ ê´€ë ¨ ì‚¬ì „ ì§€ì‹ì„ í•™ìŠµí•©ë‹ˆë‹¤.
- 4. í”„ë¡¬í”„íŠ¸ íŠœë‹ ì¤‘ í•™ìŠµëœ í”„ë¡¬í”„íŠ¸ê°€ VLP ëª¨ë¸ì— ë‚´ì¬ëœ ì¼ë°˜ ì§€ì‹ì—ì„œ ë²—ì–´ë‚˜ì§€ ì•Šë„ë¡ ì˜ë¯¸ ì¼ê´€ì„± ì†ì‹¤ì„ ì„¤ê³„í–ˆìŠµë‹ˆë‹¤.
- 5. MS-COCOì™€ VOC2007 ë²¤ì¹˜ë§ˆí¬ì—ì„œ HP-DVALì˜ ìš°ìˆ˜ì„±ì´ ì…ì¦ë˜ì—ˆìœ¼ë©°, SOTA ë°©ë²•ë“¤ë³´ë‹¤ mAPê°€ í¬ê²Œ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 00:07:34*