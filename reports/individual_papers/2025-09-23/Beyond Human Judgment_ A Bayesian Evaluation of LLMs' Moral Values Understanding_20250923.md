---
keywords:
  - Large Language Model
  - Bayesian Evaluation
  - Moral Dimensions
  - Aleatoric Uncertainty
  - Epistemic Uncertainty
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2508.13804
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T04:09:40.029660",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Bayesian Evaluation",
    "Moral Dimensions",
    "Aleatoric Uncertainty",
    "Epistemic Uncertainty"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Bayesian Evaluation": 0.78,
    "Moral Dimensions": 0.7,
    "Aleatoric Uncertainty": 0.72,
    "Epistemic Uncertainty": 0.71
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Central to the study, linking to a broad technical category.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Bayesian evaluation",
        "canonical": "Bayesian Evaluation",
        "aliases": [
          "Bayesian analysis"
        ],
        "category": "unique_technical",
        "rationale": "Highlights a unique methodological approach in the study.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "moral dimensions",
        "canonical": "Moral Dimensions",
        "aliases": [
          "ethical dimensions"
        ],
        "category": "unique_technical",
        "rationale": "Focuses on the specific aspect of moral understanding in AI.",
        "novelty_score": 0.65,
        "connectivity_score": 0.6,
        "specificity_score": 0.75,
        "link_intent_score": 0.7
      },
      {
        "surface": "aleatoric uncertainty",
        "canonical": "Aleatoric Uncertainty",
        "aliases": [
          "inherent uncertainty"
        ],
        "category": "unique_technical",
        "rationale": "Describes a specific type of uncertainty relevant to the study.",
        "novelty_score": 0.72,
        "connectivity_score": 0.55,
        "specificity_score": 0.78,
        "link_intent_score": 0.72
      },
      {
        "surface": "epistemic uncertainty",
        "canonical": "Epistemic Uncertainty",
        "aliases": [
          "model domain sensitivity"
        ],
        "category": "unique_technical",
        "rationale": "Addresses another type of uncertainty critical for model evaluation.",
        "novelty_score": 0.68,
        "connectivity_score": 0.58,
        "specificity_score": 0.76,
        "link_intent_score": 0.71
      }
    ],
    "ban_list_suggestions": [
      "GPU-optimized",
      "balanced accuracy"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Bayesian evaluation",
      "resolved_canonical": "Bayesian Evaluation",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "moral dimensions",
      "resolved_canonical": "Moral Dimensions",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.6,
        "specificity": 0.75,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "aleatoric uncertainty",
      "resolved_canonical": "Aleatoric Uncertainty",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.55,
        "specificity": 0.78,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "epistemic uncertainty",
      "resolved_canonical": "Epistemic Uncertainty",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.58,
        "specificity": 0.76,
        "link_intent": 0.71
      }
    }
  ]
}
-->

# Beyond Human Judgment: A Bayesian Evaluation of LLMs' Moral Values Understanding

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2508.13804.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2508.13804](https://arxiv.org/abs/2508.13804)

## 🔗 유사한 논문
- [[2025-09-23/Evaluating AI Alignment in Eleven LLMs through Output-Based Analysis and Human Benchmarking_20250923|Evaluating AI Alignment in Eleven LLMs through Output-Based Analysis and Human Benchmarking]] (86.3% similar)
- [[2025-09-18/Do LLMs Align Human Values Regarding Social Biases? Judging and Explaining Social Biases with LLMs_20250918|Do LLMs Align Human Values Regarding Social Biases? Judging and Explaining Social Biases with LLMs]] (86.0% similar)
- [[2025-09-23/AIPsychoBench_ Understanding the Psychometric Differences between LLMs and Humans_20250923|AIPsychoBench: Understanding the Psychometric Differences between LLMs and Humans]] (85.5% similar)
- [[2025-09-23/Breaking the Reviewer_ Assessing the Vulnerability of Large Language Models in Automated Peer Review Under Textual Adversarial Attacks_20250923|Breaking the Reviewer: Assessing the Vulnerability of Large Language Models in Automated Peer Review Under Textual Adversarial Attacks]] (85.4% similar)
- [[2025-09-19/Large Language Model probabilities cannot distinguish between possible and impossible language_20250919|Large Language Model probabilities cannot distinguish between possible and impossible language]] (85.2% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**⚡ Unique Technical**: [[keywords/Bayesian Evaluation|Bayesian Evaluation]], [[keywords/Moral Dimensions|Moral Dimensions]], [[keywords/Aleatoric Uncertainty|Aleatoric Uncertainty]], [[keywords/Epistemic Uncertainty|Epistemic Uncertainty]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2508.13804v2 Announce Type: replace 
Abstract: How do Large Language Models understand moral dimensions compared to humans?
  This first large-scale Bayesian evaluation of market-leading language models provides the answer. In contrast to prior work using deterministic ground truth (majority or inclusion rules), we model annotator disagreements to capture both aleatoric uncertainty (inherent human disagreement) and epistemic uncertainty (model domain sensitivity). We evaluated the best language models (Claude Sonnet 4, DeepSeek-V3, Llama 4 Maverick) across 250K+ annotations from nearly 700 annotators in 100K+ texts spanning social networks, news and forums.
  Our GPU-optimized Bayesian framework processed 1M+ model queries, revealing that AI models typically rank among the top 25\% of human annotators, performing much better than average balanced accuracy. Importantly, we find that AI produces far fewer false negatives than humans, highlighting their more sensitive moral detection capabilities.

## 📝 요약

이 논문은 대형 언어 모델이 도덕적 차원을 인간과 비교하여 어떻게 이해하는지를 대규모 베이지안 평가를 통해 분석합니다. 기존의 결정론적 접근과 달리, 이 연구는 주석자 간의 불일치를 모델링하여 인간의 내재적 불확실성과 모델의 도메인 민감성을 포착합니다. 100,000개 이상의 텍스트에 대한 250,000개 이상의 주석을 통해 최상의 언어 모델을 평가했으며, AI 모델이 인간 주석자 상위 25%에 속하는 성능을 보임을 발견했습니다. 특히 AI는 인간보다 더 적은 수의 거짓 음성을 생성하여 도덕적 감지 능력이 뛰어남을 보여줍니다.

## 🎯 주요 포인트

- 1. 본 연구는 대규모 베이지안 평가를 통해 대형 언어 모델이 인간과 비교하여 도덕적 차원을 어떻게 이해하는지를 분석합니다.
- 2. 기존의 결정론적 기준과 달리, 본 연구는 주석자 간의 불일치를 모델링하여 인간의 고유한 불확실성과 모델의 도메인 민감성을 포착합니다.
- 3. 100K+ 텍스트에 대한 250K+ 주석을 통해 최상의 언어 모델을 평가한 결과, AI 모델이 인간 주석자 상위 25%에 속하는 성능을 보이며 평균 균형 정확도보다 훨씬 뛰어나다는 것을 발견했습니다.
- 4. AI 모델은 인간보다 훨씬 적은 수의 거짓 부정을 생성하여 도덕적 감지 능력이 더 민감하다는 점을 강조합니다.


---

*Generated on 2025-09-24 04:09:40*