---
keywords:
  - Word2Vec Embeddings
  - Cosine Similarity
  - Stochastic Gradient Descent
  - Differentiable Stress Optimization
category: cs.LG
publish_date: 2025-09-23
arxiv_id: 2509.17333
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T02:22:23.623726",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Word2Vec Embeddings",
    "Cosine Similarity",
    "Stochastic Gradient Descent",
    "Differentiable Stress Optimization"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Word2Vec Embeddings": 0.78,
    "Cosine Similarity": 0.82,
    "Stochastic Gradient Descent": 0.8,
    "Differentiable Stress Optimization": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "word2vec-inspired embeddings",
        "canonical": "Word2Vec Embeddings",
        "aliases": [
          "word2vec embeddings",
          "word2vec"
        ],
        "category": "unique_technical",
        "rationale": "This technique is central to the proposed method, offering a novel application of word2vec in graph visualization.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "cosine dissimilarities",
        "canonical": "Cosine Similarity",
        "aliases": [
          "cosine distance",
          "cosine metric"
        ],
        "category": "specific_connectable",
        "rationale": "Cosine similarity is a key metric in the optimization process, linking to broader applications in machine learning.",
        "novelty_score": 0.6,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.82
      },
      {
        "surface": "stochastic gradient descent",
        "canonical": "Stochastic Gradient Descent",
        "aliases": [
          "SGD"
        ],
        "category": "broad_technical",
        "rationale": "SGD is a widely used optimization technique, relevant to many neural network training processes.",
        "novelty_score": 0.4,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.8
      },
      {
        "surface": "differentiable stress optimization",
        "canonical": "Differentiable Stress Optimization",
        "aliases": [
          "stress optimization"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel approach within the paper, enhancing the graph layout optimization process.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "method",
      "framework",
      "approach"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "word2vec-inspired embeddings",
      "resolved_canonical": "Word2Vec Embeddings",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "cosine dissimilarities",
      "resolved_canonical": "Cosine Similarity",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "stochastic gradient descent",
      "resolved_canonical": "Stochastic Gradient Descent",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "differentiable stress optimization",
      "resolved_canonical": "Differentiable Stress Optimization",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Word2VecGD: Neural Graph Drawing with Cosine-Stress Optimization

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17333.pdf)
**Category**: cs.LG
**Published**: 2025-09-23
**ArXiv ID**: [2509.17333](https://arxiv.org/abs/2509.17333)

## 🔗 유사한 논문
- [[2025-09-23/GraphWeave_ Interpretable and Robust Graph Generation via Random Walk Trajectories_20250923|GraphWeave: Interpretable and Robust Graph Generation via Random Walk Trajectories]] (84.1% similar)
- [[2025-09-22/Schreier-Coset Graph Propagation_20250922|Schreier-Coset Graph Propagation]] (83.1% similar)
- [[2025-09-23/Self-Supervised Discovery of Neural Circuits in Spatially Patterned Neural Responses with Graph Neural Networks_20250923|Self-Supervised Discovery of Neural Circuits in Spatially Patterned Neural Responses with Graph Neural Networks]] (81.7% similar)
- [[2025-09-18/GraphTorque_ Torque-Driven Rewiring Graph Neural Network_20250918|GraphTorque: Torque-Driven Rewiring Graph Neural Network]] (81.6% similar)
- [[2025-09-22/DiRW_ Path-Aware Digraph Learning for Heterophily_20250922|DiRW: Path-Aware Digraph Learning for Heterophily]] (81.4% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Stochastic Gradient Descent|Stochastic Gradient Descent]]
**🔗 Specific Connectable**: [[keywords/Cosine Similarity|Cosine Similarity]]
**⚡ Unique Technical**: [[keywords/Word2Vec Embeddings|Word2Vec Embeddings]], [[keywords/Differentiable Stress Optimization|Differentiable Stress Optimization]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.17333v1 Announce Type: cross 
Abstract: We propose a novel graph visualization method leveraging random walk-based embeddings to replace costly graph-theoretical distance computations. Using word2vec-inspired embeddings, our approach captures both structural and semantic relationships efficiently. Instead of relying on exact shortest-path distances, we optimize layouts using cosine dissimilarities, significantly reducing computational overhead. Our framework integrates differentiable stress optimization with stochastic gradient descent (SGD), supporting multi-criteria layout objectives. Experimental results demonstrate that our method produces high-quality, semantically meaningful layouts while efficiently scaling to large graphs. Code available at: https://github.com/mlyann/graphv_nn

## 📝 요약

이 논문은 랜덤 워크 기반 임베딩을 활용한 새로운 그래프 시각화 방법을 제안합니다. 이 방법은 그래프 이론적 거리 계산의 높은 비용을 대체하며, word2vec에서 영감을 받은 임베딩을 사용하여 구조적 및 의미적 관계를 효율적으로 포착합니다. 정확한 최단 경로 거리를 사용하는 대신, 코사인 비유사도를 활용하여 레이아웃을 최적화함으로써 계산 비용을 크게 줄였습니다. 이 프레임워크는 미분 가능한 스트레스 최적화와 확률적 경사 하강법(SGD)을 통합하여 다중 기준 레이아웃 목표를 지원합니다. 실험 결과, 이 방법은 대규모 그래프에서도 효율적으로 확장되며, 높은 품질의 의미 있는 레이아웃을 생성함을 보여줍니다. 코드는 https://github.com/mlyann/graphv_nn에서 제공됩니다.

## 🎯 주요 포인트

- 1. 본 연구는 랜덤 워크 기반 임베딩을 활용하여 그래프 이론적 거리 계산의 비용을 줄이는 새로운 그래프 시각화 방법을 제안합니다.
- 2. word2vec에서 영감을 받은 임베딩을 사용하여 구조적 및 의미적 관계를 효율적으로 포착합니다.
- 3. 정확한 최단 경로 거리를 사용하는 대신 코사인 비유사도를 최적화하여 계산 오버헤드를 크게 줄였습니다.
- 4. 차별 가능한 스트레스 최적화와 확률적 경사 하강법(SGD)을 통합하여 다중 기준 레이아웃 목표를 지원합니다.
- 5. 실험 결과, 제안된 방법이 대규모 그래프에 대해 효율적으로 확장되면서도 높은 품질의 의미 있는 레이아웃을 생성함을 보여줍니다.


---

*Generated on 2025-09-24 02:22:23*