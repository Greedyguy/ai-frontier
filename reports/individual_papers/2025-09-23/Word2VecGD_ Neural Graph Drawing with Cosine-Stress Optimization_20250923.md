---
keywords:
  - Word2Vec Embeddings
  - Cosine Similarity
  - Stochastic Gradient Descent
  - Differentiable Stress Optimization
category: cs.LG
publish_date: 2025-09-23
arxiv_id: 2509.17333
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T02:22:23.623726",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Word2Vec Embeddings",
    "Cosine Similarity",
    "Stochastic Gradient Descent",
    "Differentiable Stress Optimization"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Word2Vec Embeddings": 0.78,
    "Cosine Similarity": 0.82,
    "Stochastic Gradient Descent": 0.8,
    "Differentiable Stress Optimization": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "word2vec-inspired embeddings",
        "canonical": "Word2Vec Embeddings",
        "aliases": [
          "word2vec embeddings",
          "word2vec"
        ],
        "category": "unique_technical",
        "rationale": "This technique is central to the proposed method, offering a novel application of word2vec in graph visualization.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "cosine dissimilarities",
        "canonical": "Cosine Similarity",
        "aliases": [
          "cosine distance",
          "cosine metric"
        ],
        "category": "specific_connectable",
        "rationale": "Cosine similarity is a key metric in the optimization process, linking to broader applications in machine learning.",
        "novelty_score": 0.6,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.82
      },
      {
        "surface": "stochastic gradient descent",
        "canonical": "Stochastic Gradient Descent",
        "aliases": [
          "SGD"
        ],
        "category": "broad_technical",
        "rationale": "SGD is a widely used optimization technique, relevant to many neural network training processes.",
        "novelty_score": 0.4,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.8
      },
      {
        "surface": "differentiable stress optimization",
        "canonical": "Differentiable Stress Optimization",
        "aliases": [
          "stress optimization"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel approach within the paper, enhancing the graph layout optimization process.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "method",
      "framework",
      "approach"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "word2vec-inspired embeddings",
      "resolved_canonical": "Word2Vec Embeddings",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "cosine dissimilarities",
      "resolved_canonical": "Cosine Similarity",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "stochastic gradient descent",
      "resolved_canonical": "Stochastic Gradient Descent",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "differentiable stress optimization",
      "resolved_canonical": "Differentiable Stress Optimization",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Word2VecGD: Neural Graph Drawing with Cosine-Stress Optimization

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17333.pdf)
**Category**: cs.LG
**Published**: 2025-09-23
**ArXiv ID**: [2509.17333](https://arxiv.org/abs/2509.17333)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/GraphWeave_ Interpretable and Robust Graph Generation via Random Walk Trajectories_20250923|GraphWeave: Interpretable and Robust Graph Generation via Random Walk Trajectories]] (84.1% similar)
- [[2025-09-22/Schreier-Coset Graph Propagation_20250922|Schreier-Coset Graph Propagation]] (83.1% similar)
- [[2025-09-23/Self-Supervised Discovery of Neural Circuits in Spatially Patterned Neural Responses with Graph Neural Networks_20250923|Self-Supervised Discovery of Neural Circuits in Spatially Patterned Neural Responses with Graph Neural Networks]] (81.7% similar)
- [[2025-09-18/GraphTorque_ Torque-Driven Rewiring Graph Neural Network_20250918|GraphTorque: Torque-Driven Rewiring Graph Neural Network]] (81.6% similar)
- [[2025-09-22/DiRW_ Path-Aware Digraph Learning for Heterophily_20250922|DiRW: Path-Aware Digraph Learning for Heterophily]] (81.4% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Stochastic Gradient Descent|Stochastic Gradient Descent]]
**ğŸ”— Specific Connectable**: [[keywords/Cosine Similarity|Cosine Similarity]]
**âš¡ Unique Technical**: [[keywords/Word2Vec Embeddings|Word2Vec Embeddings]], [[keywords/Differentiable Stress Optimization|Differentiable Stress Optimization]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17333v1 Announce Type: cross 
Abstract: We propose a novel graph visualization method leveraging random walk-based embeddings to replace costly graph-theoretical distance computations. Using word2vec-inspired embeddings, our approach captures both structural and semantic relationships efficiently. Instead of relying on exact shortest-path distances, we optimize layouts using cosine dissimilarities, significantly reducing computational overhead. Our framework integrates differentiable stress optimization with stochastic gradient descent (SGD), supporting multi-criteria layout objectives. Experimental results demonstrate that our method produces high-quality, semantically meaningful layouts while efficiently scaling to large graphs. Code available at: https://github.com/mlyann/graphv_nn

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëœë¤ ì›Œí¬ ê¸°ë°˜ ì„ë² ë”©ì„ í™œìš©í•œ ìƒˆë¡œìš´ ê·¸ë˜í”„ ì‹œê°í™” ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ê·¸ë˜í”„ ì´ë¡ ì  ê±°ë¦¬ ê³„ì‚°ì˜ ë†’ì€ ë¹„ìš©ì„ ëŒ€ì²´í•˜ë©°, word2vecì—ì„œ ì˜ê°ì„ ë°›ì€ ì„ë² ë”©ì„ ì‚¬ìš©í•˜ì—¬ êµ¬ì¡°ì  ë° ì˜ë¯¸ì  ê´€ê³„ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ í¬ì°©í•©ë‹ˆë‹¤. ì •í™•í•œ ìµœë‹¨ ê²½ë¡œ ê±°ë¦¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ëŒ€ì‹ , ì½”ì‚¬ì¸ ë¹„ìœ ì‚¬ë„ë¥¼ í™œìš©í•˜ì—¬ ë ˆì´ì•„ì›ƒì„ ìµœì í™”í•¨ìœ¼ë¡œì¨ ê³„ì‚° ë¹„ìš©ì„ í¬ê²Œ ì¤„ì˜€ìŠµë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ë¯¸ë¶„ ê°€ëŠ¥í•œ ìŠ¤íŠ¸ë ˆìŠ¤ ìµœì í™”ì™€ í™•ë¥ ì  ê²½ì‚¬ í•˜ê°•ë²•(SGD)ì„ í†µí•©í•˜ì—¬ ë‹¤ì¤‘ ê¸°ì¤€ ë ˆì´ì•„ì›ƒ ëª©í‘œë¥¼ ì§€ì›í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì´ ë°©ë²•ì€ ëŒ€ê·œëª¨ ê·¸ë˜í”„ì—ì„œë„ íš¨ìœ¨ì ìœ¼ë¡œ í™•ì¥ë˜ë©°, ë†’ì€ í’ˆì§ˆì˜ ì˜ë¯¸ ìˆëŠ” ë ˆì´ì•„ì›ƒì„ ìƒì„±í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì½”ë“œëŠ” https://github.com/mlyann/graphv_nnì—ì„œ ì œê³µë©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë³¸ ì—°êµ¬ëŠ” ëœë¤ ì›Œí¬ ê¸°ë°˜ ì„ë² ë”©ì„ í™œìš©í•˜ì—¬ ê·¸ë˜í”„ ì´ë¡ ì  ê±°ë¦¬ ê³„ì‚°ì˜ ë¹„ìš©ì„ ì¤„ì´ëŠ” ìƒˆë¡œìš´ ê·¸ë˜í”„ ì‹œê°í™” ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤.
- 2. word2vecì—ì„œ ì˜ê°ì„ ë°›ì€ ì„ë² ë”©ì„ ì‚¬ìš©í•˜ì—¬ êµ¬ì¡°ì  ë° ì˜ë¯¸ì  ê´€ê³„ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ í¬ì°©í•©ë‹ˆë‹¤.
- 3. ì •í™•í•œ ìµœë‹¨ ê²½ë¡œ ê±°ë¦¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ëŒ€ì‹  ì½”ì‚¬ì¸ ë¹„ìœ ì‚¬ë„ë¥¼ ìµœì í™”í•˜ì—¬ ê³„ì‚° ì˜¤ë²„í—¤ë“œë¥¼ í¬ê²Œ ì¤„ì˜€ìŠµë‹ˆë‹¤.
- 4. ì°¨ë³„ ê°€ëŠ¥í•œ ìŠ¤íŠ¸ë ˆìŠ¤ ìµœì í™”ì™€ í™•ë¥ ì  ê²½ì‚¬ í•˜ê°•ë²•(SGD)ì„ í†µí•©í•˜ì—¬ ë‹¤ì¤‘ ê¸°ì¤€ ë ˆì´ì•„ì›ƒ ëª©í‘œë¥¼ ì§€ì›í•©ë‹ˆë‹¤.
- 5. ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì´ ëŒ€ê·œëª¨ ê·¸ë˜í”„ì— ëŒ€í•´ íš¨ìœ¨ì ìœ¼ë¡œ í™•ì¥ë˜ë©´ì„œë„ ë†’ì€ í’ˆì§ˆì˜ ì˜ë¯¸ ìˆëŠ” ë ˆì´ì•„ì›ƒì„ ìƒì„±í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.


---

*Generated on 2025-09-24 02:22:23*