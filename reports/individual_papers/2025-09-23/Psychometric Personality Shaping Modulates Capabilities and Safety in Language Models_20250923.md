---
keywords:
  - Large Language Model
  - Psychometric Personality Control
  - Big Five Personality Traits
  - AI Safety Evaluation
  - Dynamic Behavioral Control
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.16332
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T22:47:51.724959",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Psychometric Personality Control",
    "Big Five Personality Traits",
    "AI Safety Evaluation",
    "Dynamic Behavioral Control"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Psychometric Personality Control": 0.78,
    "Big Five Personality Traits": 0.8,
    "AI Safety Evaluation": 0.82,
    "Dynamic Behavioral Control": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Central to the study, linking to broader discussions on AI capabilities and safety.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Psychometric Personality Control",
        "canonical": "Psychometric Personality Control",
        "aliases": [
          "Personality Shaping"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel concept for controlling AI behavior, relevant for safety and alignment.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Big Five Framework",
        "canonical": "Big Five Personality Traits",
        "aliases": [
          "Big Five"
        ],
        "category": "specific_connectable",
        "rationale": "Provides a psychological basis for personality shaping in AI, useful for cross-disciplinary links.",
        "novelty_score": 0.55,
        "connectivity_score": 0.7,
        "specificity_score": 0.75,
        "link_intent_score": 0.8
      },
      {
        "surface": "Safety Evaluation",
        "canonical": "AI Safety Evaluation",
        "aliases": [
          "Safety Assessment"
        ],
        "category": "specific_connectable",
        "rationale": "Key aspect of the study, linking to broader AI safety research.",
        "novelty_score": 0.4,
        "connectivity_score": 0.85,
        "specificity_score": 0.65,
        "link_intent_score": 0.82
      },
      {
        "surface": "Dynamic Behavioral Control",
        "canonical": "Dynamic Behavioral Control",
        "aliases": [
          "Behavioral Steering"
        ],
        "category": "unique_technical",
        "rationale": "Emerging concept for real-time AI behavior management, relevant for deployment strategies.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.78,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "capabilities",
      "experiments",
      "metrics"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Psychometric Personality Control",
      "resolved_canonical": "Psychometric Personality Control",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Big Five Framework",
      "resolved_canonical": "Big Five Personality Traits",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.7,
        "specificity": 0.75,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Safety Evaluation",
      "resolved_canonical": "AI Safety Evaluation",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.85,
        "specificity": 0.65,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Dynamic Behavioral Control",
      "resolved_canonical": "Dynamic Behavioral Control",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.78,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Psychometric Personality Shaping Modulates Capabilities and Safety in Language Models

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16332.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.16332](https://arxiv.org/abs/2509.16332)

## 🔗 유사한 논문
- [[2025-09-22/Exploring the Impact of Personality Traits on LLM Bias and Toxicity_20250922|Exploring the Impact of Personality Traits on LLM Bias and Toxicity]] (90.3% similar)
- [[2025-09-18/Designing AI-Agents with Personalities_ A Psychometric Approach_20250918|Designing AI-Agents with Personalities: A Psychometric Approach]] (85.0% similar)
- [[2025-09-19/Adding LLMs to the psycholinguistic norming toolbox_ A practical guide to getting the most out of human ratings_20250919|Adding LLMs to the psycholinguistic norming toolbox: A practical guide to getting the most out of human ratings]] (84.3% similar)
- [[2025-09-22/Toxicity Red-Teaming_ Benchmarking LLM Safety in Singapore's Low-Resource Languages_20250922|Toxicity Red-Teaming: Benchmarking LLM Safety in Singapore's Low-Resource Languages]] (84.2% similar)
- [[2025-09-18/Do LLMs Align Human Values Regarding Social Biases? Judging and Explaining Social Biases with LLMs_20250918|Do LLMs Align Human Values Regarding Social Biases? Judging and Explaining Social Biases with LLMs]] (84.2% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Big Five Personality Traits|Big Five Personality Traits]], [[keywords/AI Safety Evaluation|AI Safety Evaluation]]
**⚡ Unique Technical**: [[keywords/Psychometric Personality Control|Psychometric Personality Control]], [[keywords/Dynamic Behavioral Control|Dynamic Behavioral Control]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.16332v1 Announce Type: new 
Abstract: Large Language Models increasingly mediate high-stakes interactions, intensifying research on their capabilities and safety. While recent work has shown that LLMs exhibit consistent and measurable synthetic personality traits, little is known about how modulating these traits affects model behavior. We address this gap by investigating how psychometric personality control grounded in the Big Five framework influences AI behavior in the context of capability and safety benchmarks. Our experiments reveal striking effects: for example, reducing conscientiousness leads to significant drops in safety-relevant metrics on benchmarks such as WMDP, TruthfulQA, ETHICS, and Sycophancy as well as reduction in general capabilities as measured by MMLU. These findings highlight personality shaping as a powerful and underexplored axis of model control that interacts with both safety and general competence. We discuss the implications for safety evaluation, alignment strategies, steering model behavior after deployment, and risks associated with possible exploitation of these findings. Our findings motivate a new line of research on personality-sensitive safety evaluations and dynamic behavioral control in LLMs.

## 📝 요약

이 논문은 대형 언어 모델(LLM)의 성격 특성을 조절하는 것이 모델의 행동에 미치는 영향을 연구합니다. Big Five 성격 이론을 기반으로 한 실험에서 성실성을 낮추면 안전 관련 지표와 일반적 능력이 크게 감소하는 것으로 나타났습니다. 이러한 결과는 성격 조절이 모델의 안전성과 능력에 중요한 영향을 미칠 수 있음을 시사합니다. 연구는 LLM의 안전 평가, 정렬 전략, 배포 후 행동 조정, 그리고 이러한 발견의 잠재적 악용 위험에 대한 새로운 연구 방향을 제안합니다.

## 🎯 주요 포인트

- 1. 대형 언어 모델(LLM)의 성격 특성을 조절하는 것이 모델의 행동에 미치는 영향을 연구하였다.
- 2. Big Five 성격 이론에 기반한 심리측정적 성격 조절이 AI의 능력 및 안전성 벤치마크에 미치는 영향을 분석하였다.
- 3. 실험 결과, 성실성을 낮추면 WMDP, TruthfulQA, ETHICS, Sycophancy 등 안전성 관련 지표와 MMLU로 측정한 일반 능력에서 큰 감소가 나타났다.
- 4. 성격 조절은 모델의 안전성과 일반적 능력에 영향을 미치는 강력하고 탐구되지 않은 제어 축임을 강조하였다.
- 5. 연구 결과는 성격에 민감한 안전성 평가와 LLM의 동적 행동 제어에 대한 새로운 연구 방향을 제시한다.


---

*Generated on 2025-09-23 22:47:51*