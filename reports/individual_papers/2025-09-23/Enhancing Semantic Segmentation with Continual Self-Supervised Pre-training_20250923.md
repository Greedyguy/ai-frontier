---
keywords:
  - Self-supervised Learning
  - Transformer
  - Semantic Segmentation
  - Continual Self-Supervised Pre-training
  - Global Local and Regional Enforcement
category: cs.CV
publish_date: 2025-09-23
arxiv_id: 2509.17816
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T05:04:19.607240",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Self-supervised Learning",
    "Transformer",
    "Semantic Segmentation",
    "Continual Self-Supervised Pre-training",
    "Global Local and Regional Enforcement"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Self-supervised Learning": 0.85,
    "Transformer": 0.8,
    "Semantic Segmentation": 0.82,
    "Continual Self-Supervised Pre-training": 0.78,
    "Global Local and Regional Enforcement": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Self-supervised Learning",
        "canonical": "Self-supervised Learning",
        "aliases": [
          "SSL"
        ],
        "category": "specific_connectable",
        "rationale": "Central to the paper's methodology, linking to a well-established concept in machine learning.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.8,
        "link_intent_score": 0.85
      },
      {
        "surface": "Vision Transformer",
        "canonical": "Transformer",
        "aliases": [
          "ViT"
        ],
        "category": "broad_technical",
        "rationale": "A key component in the model architecture, connecting to the broader concept of Transformers.",
        "novelty_score": 0.4,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Semantic Segmentation",
        "canonical": "Semantic Segmentation",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "The primary application focus of the paper, crucial for linking to related works in computer vision.",
        "novelty_score": 0.2,
        "connectivity_score": 0.85,
        "specificity_score": 0.9,
        "link_intent_score": 0.82
      },
      {
        "surface": "Continual Self-Supervised Pre-training",
        "canonical": "Continual Self-Supervised Pre-training",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "A novel approach introduced in the paper, enhancing the adaptability of models across domains.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "GLARE",
        "canonical": "Global Local and Regional Enforcement",
        "aliases": [
          "GLARE"
        ],
        "category": "unique_technical",
        "rationale": "A new method proposed in the paper, essential for understanding the specific contributions.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.88,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Self-supervised Learning",
      "resolved_canonical": "Self-supervised Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.8,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Vision Transformer",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Semantic Segmentation",
      "resolved_canonical": "Semantic Segmentation",
      "decision": "linked",
      "scores": {
        "novelty": 0.2,
        "connectivity": 0.85,
        "specificity": 0.9,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Continual Self-Supervised Pre-training",
      "resolved_canonical": "Continual Self-Supervised Pre-training",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "GLARE",
      "resolved_canonical": "Global Local and Regional Enforcement",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.88,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Enhancing Semantic Segmentation with Continual Self-Supervised Pre-training

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17816.pdf)
**Category**: cs.CV
**Published**: 2025-09-23
**ArXiv ID**: [2509.17816](https://arxiv.org/abs/2509.17816)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Which Direction to Choose? An Analysis on the Representation Power of Self-Supervised ViTs in Downstream Tasks_20250922|Which Direction to Choose? An Analysis on the Representation Power of Self-Supervised ViTs in Downstream Tasks]] (84.1% similar)
- [[2025-09-23/Leveraging Audio-Visual Data to Reduce the Multilingual Gap in Self-Supervised Speech Models_20250923|Leveraging Audio-Visual Data to Reduce the Multilingual Gap in Self-Supervised Speech Models]] (82.9% similar)
- [[2025-09-23/Visual Instruction Pretraining for Domain-Specific Foundation Models_20250923|Visual Instruction Pretraining for Domain-Specific Foundation Models]] (82.8% similar)
- [[2025-09-22/Minimal Semantic Sufficiency Meets Unsupervised Domain Generalization_20250922|Minimal Semantic Sufficiency Meets Unsupervised Domain Generalization]] (82.6% similar)
- [[2025-09-22/Global Pre-fixing, Local Adjusting_ A Simple yet Effective Contrastive Strategy for Continual Learning_20250922|Global Pre-fixing, Local Adjusting: A Simple yet Effective Contrastive Strategy for Continual Learning]] (82.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Transformer|Transformer]]
**ğŸ”— Specific Connectable**: [[keywords/Self-supervised Learning|Self-supervised Learning]], [[keywords/Semantic Segmentation|Semantic Segmentation]]
**âš¡ Unique Technical**: [[keywords/Continual Self-Supervised Pre-training|Continual Self-Supervised Pre-training]], [[keywords/Global Local and Regional Enforcement|Global Local and Regional Enforcement]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17816v1 Announce Type: new 
Abstract: Self-supervised learning (SSL) has emerged as a central paradigm for training foundation models by leveraging large-scale unlabeled datasets, often producing representations with strong generalization capabilities. These models are typically pre-trained on general-purpose datasets such as ImageNet and subsequently adapted to various downstream tasks through finetuning. While recent advances have explored parameter-efficient strategies for adapting pre-trained models, extending SSL pre-training itself to new domains - particularly under limited data regimes and for dense prediction tasks - remains underexplored. In this work, we address the problem of adapting vision foundation models to new domains in an unsupervised and data-efficient manner, specifically targeting downstream semantic segmentation. We propose GLARE (Global Local and Regional Enforcement), a novel continual self-supervised pre-training task designed to enhance downstream segmentation performance. GLARE introduces patch-level augmentations to encourage local consistency and incorporates a regional consistency constraint that leverages spatial semantics in the data. For efficient continual pre-training, we initialize Vision Transformers (ViTs) with weights from existing SSL models and update only lightweight adapter modules - specifically UniAdapter - while keeping the rest of the backbone frozen. Experiments across multiple semantic segmentation benchmarks on different domains demonstrate that GLARE consistently improves downstream performance with minimal computational and parameter overhead.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ìê°€ ì§€ë„ í•™ìŠµ(SSL)ì„ í†µí•´ ëŒ€ê·œëª¨ ë¹„ì§€ë„ ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬ ê°•ë ¥í•œ ì¼ë°˜í™” ëŠ¥ë ¥ì„ ê°€ì§„ ëª¨ë¸ì„ í›ˆë ¨í•˜ëŠ” ë°©ë²•ì„ íƒêµ¬í•©ë‹ˆë‹¤. íŠ¹íˆ, ìƒˆë¡œìš´ ë„ë©”ì¸ì—ì„œì˜ ë¹„ì§€ë„ ë° ë°ì´í„° íš¨ìœ¨ì ì¸ ë°©ì‹ìœ¼ë¡œ ë¹„ì „ ê¸°ë°˜ ëª¨ë¸ì„ ì ì‘ì‹œí‚¤ëŠ” ë¬¸ì œë¥¼ ë‹¤ë£¨ë©°, ì£¼ë¡œ í•˜ìœ„ ì‘ì—…ì¸ ì˜ë¯¸ë¡ ì  ë¶„í• ì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ GLARE(Global Local and Regional Enforcement)ë¼ëŠ” ìƒˆë¡œìš´ ì§€ì†ì  ìê°€ ì§€ë„ ì‚¬ì „ í›ˆë ¨ ì‘ì—…ì„ ì œì•ˆí•©ë‹ˆë‹¤. GLAREëŠ” íŒ¨ì¹˜ ìˆ˜ì¤€ì˜ ì¦ê°•ì„ ë„ì…í•˜ì—¬ ì§€ì—­ì  ì¼ê´€ì„±ì„ ê°•í™”í•˜ê³ , ë°ì´í„°ì˜ ê³µê°„ì  ì˜ë¯¸ë¡ ì„ í™œìš©í•œ ì§€ì—­ì  ì¼ê´€ì„± ì œì•½ì„ í¬í•¨í•©ë‹ˆë‹¤. íš¨ìœ¨ì ì¸ ì§€ì†ì  ì‚¬ì „ í›ˆë ¨ì„ ìœ„í•´, ê¸°ì¡´ SSL ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¡œ ì´ˆê¸°í™”ëœ Vision Transformers(ViTs)ë¥¼ ì‚¬ìš©í•˜ê³ , ë°±ë³¸ì„ ê³ ì •í•œ ì±„ ê°€ë²¼ìš´ ì–´ëŒ‘í„° ëª¨ë“ˆì¸ UniAdapterë§Œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤. ì—¬ëŸ¬ ì˜ë¯¸ë¡ ì  ë¶„í•  ë²¤ì¹˜ë§ˆí¬ ì‹¤í—˜ì—ì„œ GLAREëŠ” ìµœì†Œí•œì˜ ê³„ì‚° ë° íŒŒë¼ë¯¸í„° ì˜¤ë²„í—¤ë“œë¡œ ì¼ê´€ë˜ê²Œ ì„±ëŠ¥ì„ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ìê¸° ì§€ë„ í•™ìŠµ(SSL)ì€ ëŒ€ê·œëª¨ ë¹„ì§€ë„ ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬ ê°•ë ¥í•œ ì¼ë°˜í™” ëŠ¥ë ¥ì„ ê°€ì§„ í‘œí˜„ì„ ìƒì„±í•˜ëŠ” ì¤‘ì‹¬ íŒ¨ëŸ¬ë‹¤ì„ìœ¼ë¡œ ë¶€ìƒí–ˆìŠµë‹ˆë‹¤.
- 2. SSL ì‚¬ì „ í•™ìŠµì„ ìƒˆë¡œìš´ ë„ë©”ì¸ìœ¼ë¡œ í™•ì¥í•˜ëŠ” ê²ƒì€ ì œí•œëœ ë°ì´í„° í™˜ê²½ê³¼ ë°€ì§‘ ì˜ˆì¸¡ ì‘ì—…ì—ì„œ ì—¬ì „íˆ íƒêµ¬ë˜ì§€ ì•Šì€ ë¶„ì•¼ì…ë‹ˆë‹¤.
- 3. GLAREëŠ” ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì˜ë¯¸ë¡ ì  ë¶„í•  ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ì„¤ê³„ëœ ìƒˆë¡œìš´ ì§€ì†ì  ìê¸° ì§€ë„ ì‚¬ì „ í•™ìŠµ ì‘ì—…ì…ë‹ˆë‹¤.
- 4. GLAREëŠ” ì§€ì—­ ì¼ê´€ì„± ì œì•½ì„ ë„ì…í•˜ì—¬ ë°ì´í„°ì˜ ê³µê°„ì  ì˜ë¯¸ë¥¼ í™œìš©í•˜ê³ , íŒ¨ì¹˜ ìˆ˜ì¤€ì˜ ì¦ê°•ì„ í†µí•´ ì§€ì—­ì  ì¼ê´€ì„±ì„ ì´‰ì§„í•©ë‹ˆë‹¤.
- 5. ì‹¤í—˜ ê²°ê³¼, GLAREëŠ” ì—¬ëŸ¬ ë„ë©”ì¸ì˜ ì˜ë¯¸ë¡ ì  ë¶„í•  ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìµœì†Œí•œì˜ ê³„ì‚° ë° íŒŒë¼ë¯¸í„° ì˜¤ë²„í—¤ë“œë¡œ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì„±ëŠ¥ì„ ì§€ì†ì ìœ¼ë¡œ í–¥ìƒì‹œí‚µë‹ˆë‹¤.


---

*Generated on 2025-09-24 05:04:19*