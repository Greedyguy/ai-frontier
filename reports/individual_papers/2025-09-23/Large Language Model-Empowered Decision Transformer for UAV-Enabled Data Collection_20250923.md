---
keywords:
  - Large Language Model
  - UAV Trajectory Planning
  - Critic-Regularized Decision Transformer
  - Offline Reinforcement Learning
  - Energy Efficiency in Data Collection
category: cs.LG
publish_date: 2025-09-23
arxiv_id: 2509.13934
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:10:17.331011",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "UAV Trajectory Planning",
    "Critic-Regularized Decision Transformer",
    "Offline Reinforcement Learning",
    "Energy Efficiency in Data Collection"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "UAV Trajectory Planning": 0.78,
    "Critic-Regularized Decision Transformer": 0.82,
    "Offline Reinforcement Learning": 0.77,
    "Energy Efficiency in Data Collection": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Model",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are central to the proposed framework, linking to broader AI and NLP concepts.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "UAV Trajectory Planning",
        "canonical": "UAV Trajectory Planning",
        "aliases": [
          "Drone Path Optimization"
        ],
        "category": "unique_technical",
        "rationale": "This is a specific application area that connects UAV technology with optimization techniques.",
        "novelty_score": 0.72,
        "connectivity_score": 0.67,
        "specificity_score": 0.81,
        "link_intent_score": 0.78
      },
      {
        "surface": "Critic-Regularized Decision Transformer",
        "canonical": "Critic-Regularized Decision Transformer",
        "aliases": [
          "CRDT"
        ],
        "category": "unique_technical",
        "rationale": "The CRDT framework is a novel approach combining decision transformers with critic networks, enhancing policy learning.",
        "novelty_score": 0.83,
        "connectivity_score": 0.59,
        "specificity_score": 0.86,
        "link_intent_score": 0.82
      },
      {
        "surface": "Offline Reinforcement Learning",
        "canonical": "Offline Reinforcement Learning",
        "aliases": [
          "Offline RL"
        ],
        "category": "specific_connectable",
        "rationale": "Offline RL is crucial for safe and efficient UAV operations, linking to broader RL methodologies.",
        "novelty_score": 0.55,
        "connectivity_score": 0.79,
        "specificity_score": 0.72,
        "link_intent_score": 0.77
      },
      {
        "surface": "Energy Efficiency in Data Collection",
        "canonical": "Energy Efficiency in Data Collection",
        "aliases": [
          "Efficient Data Gathering"
        ],
        "category": "unique_technical",
        "rationale": "Energy efficiency is a key metric in UAV operations, relevant to sustainable IoT applications.",
        "novelty_score": 0.68,
        "connectivity_score": 0.65,
        "specificity_score": 0.78,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "experiment"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Model",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "UAV Trajectory Planning",
      "resolved_canonical": "UAV Trajectory Planning",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.67,
        "specificity": 0.81,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Critic-Regularized Decision Transformer",
      "resolved_canonical": "Critic-Regularized Decision Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.83,
        "connectivity": 0.59,
        "specificity": 0.86,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Offline Reinforcement Learning",
      "resolved_canonical": "Offline Reinforcement Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.79,
        "specificity": 0.72,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Energy Efficiency in Data Collection",
      "resolved_canonical": "Energy Efficiency in Data Collection",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.65,
        "specificity": 0.78,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Large Language Model-Empowered Decision Transformer for UAV-Enabled Data Collection

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.13934.pdf)
**Category**: cs.LG
**Published**: 2025-09-23
**ArXiv ID**: [2509.13934](https://arxiv.org/abs/2509.13934)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-17/Large Language Model-Empowered Decision Transformer for UAV-Enabled Data Collection_20250917|Large Language Model-Empowered Decision Transformer for UAV-Enabled Data Collection]] (99.2% similar)
- [[2025-09-18/Reinforcement Learning for Autonomous Point-to-Point UAV Navigation_20250918|Reinforcement Learning for Autonomous Point-to-Point UAV Navigation]] (85.5% similar)
- [[2025-09-18/Agentic UAVs_ LLM-Driven Autonomy with Integrated Tool-Calling and Cognitive Reasoning_20250918|Agentic UAVs: LLM-Driven Autonomy with Integrated Tool-Calling and Cognitive Reasoning]] (84.4% similar)
- [[2025-09-18/SPAR_ Scalable LLM-based PDDL Domain Generation for Aerial Robotics_20250918|SPAR: Scalable LLM-based PDDL Domain Generation for Aerial Robotics]] (82.9% similar)
- [[2025-09-23/Reinforcement Learning for Decision-Level Interception Prioritization in Drone Swarm Defense_20250923|Reinforcement Learning for Decision-Level Interception Prioritization in Drone Swarm Defense]] (82.7% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Offline Reinforcement Learning|Offline Reinforcement Learning]]
**âš¡ Unique Technical**: [[keywords/UAV Trajectory Planning|UAV Trajectory Planning]], [[keywords/Critic-Regularized Decision Transformer|Critic-Regularized Decision Transformer]], [[keywords/Energy Efficiency in Data Collection|Energy Efficiency in Data Collection]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.13934v2 Announce Type: replace-cross 
Abstract: The deployment of unmanned aerial vehicles (UAVs) for reliable and energy-efficient data collection from spatially distributed devices holds great promise in supporting diverse Internet of Things (IoT) applications. Nevertheless, the limited endurance and communication range of UAVs necessitate intelligent trajectory planning. While reinforcement learning (RL) has been extensively explored for UAV trajectory optimization, its interactive nature entails high costs and risks in real-world environments. Offline RL mitigates these issues but remains susceptible to unstable training and heavily rely on expert-quality datasets. To address these challenges, we formulate a joint UAV trajectory planning and resource allocation problem to maximize energy efficiency of data collection. The resource allocation subproblem is first transformed into an equivalent linear programming formulation and solved optimally with polynomial-time complexity. Then, we propose a large language model (LLM)-empowered critic-regularized decision transformer (DT) framework, termed LLM-CRDT, to learn effective UAV control policies. In LLM-CRDT, we incorporate critic networks to regularize the DT model training, thereby integrating the sequence modeling capabilities of DT with critic-based value guidance to enable learning effective policies from suboptimal datasets. Furthermore, to mitigate the data-hungry nature of transformer models, we employ a pre-trained LLM as the transformer backbone of the DT model and adopt a parameter-efficient fine-tuning strategy, i.e., LoRA, enabling rapid adaptation to UAV control tasks with small-scale dataset and low computational overhead. Extensive simulations demonstrate that LLM-CRDT outperforms benchmark online and offline RL methods, achieving up to 36.7\% higher energy efficiency than the current state-of-the-art DT approaches.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë¬´ì¸ í•­ê³µê¸°(UAV)ë¥¼ í™œìš©í•œ ì—ë„ˆì§€ íš¨ìœ¨ì ì¸ ë°ì´í„° ìˆ˜ì§‘ì„ ìœ„í•œ ê²½ë¡œ ê³„íš ë° ìì› í• ë‹¹ ë¬¸ì œë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. ê¸°ì¡´ ê°•í™” í•™ìŠµ(RL)ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´, ì €ìë“¤ì€ ìì› í• ë‹¹ ë¬¸ì œë¥¼ ì„ í˜• í”„ë¡œê·¸ë˜ë°ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ìµœì í™”í•˜ê³ , ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ í™œìš©í•œ ë¹„í‰ì-ì •ê·œí™” ê²°ì • ë³€í™˜ê¸°(LM-CRDT) í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ë¹„í‰ì ë„¤íŠ¸ì›Œí¬ë¥¼ í†µí•©í•˜ì—¬ ë¹„ìµœì  ë°ì´í„°ì…‹ì—ì„œë„ íš¨ê³¼ì ì¸ UAV ì œì–´ ì •ì±…ì„ í•™ìŠµí•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤. ë˜í•œ, ì‚¬ì „ í•™ìŠµëœ LLMì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ìš”êµ¬ëŸ‰ì„ ì¤„ì´ê³ , LoRA ê¸°ë²•ì„ í†µí•´ ì†Œê·œëª¨ ë°ì´í„°ì…‹ìœ¼ë¡œë„ ë¹ ë¥´ê²Œ ì ì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼, LLM-CRDTëŠ” ê¸°ì¡´ ë°©ë²•ë“¤ë³´ë‹¤ ìµœëŒ€ 36.7% ë†’ì€ ì—ë„ˆì§€ íš¨ìœ¨ì„±ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë¬´ì¸ í•­ê³µê¸°(UAV)ì˜ ì œí•œëœ ì§€ì† ì‹œê°„ê³¼ í†µì‹  ë²”ìœ„ë¥¼ ê³ ë ¤í•˜ì—¬ ì§€ëŠ¥ì ì¸ ê²½ë¡œ ê³„íšì´ í•„ìš”í•©ë‹ˆë‹¤.
- 2. ì˜¤í”„ë¼ì¸ ê°•í™” í•™ìŠµì€ ì‹¤ì œ í™˜ê²½ì—ì„œì˜ ë†’ì€ ë¹„ìš©ê³¼ ìœ„í—˜ì„ ì¤„ì¼ ìˆ˜ ìˆì§€ë§Œ, ë¶ˆì•ˆì •í•œ í›ˆë ¨ê³¼ ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ ë°ì´í„°ì…‹ì— ëŒ€í•œ ì˜ì¡´ì„±ì´ ë¬¸ì œì…ë‹ˆë‹¤.
- 3. UAV ê²½ë¡œ ê³„íš ë° ìì› í• ë‹¹ ë¬¸ì œë¥¼ ì—ë„ˆì§€ íš¨ìœ¨ì„±ì„ ê·¹ëŒ€í™”í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ìˆ˜ë¦½í•˜ê³ , ìì› í• ë‹¹ ë¬¸ì œë¥¼ ì„ í˜• í”„ë¡œê·¸ë˜ë°ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ìµœì  í•´ê²°í•©ë‹ˆë‹¤.
- 4. LLM-CRDT í”„ë ˆì„ì›Œí¬ëŠ” ë¹„íŒ ë„¤íŠ¸ì›Œí¬ë¥¼ í†µí•©í•˜ì—¬ DT ëª¨ë¸ í›ˆë ¨ì„ ì •ê·œí™”í•˜ê³ , ë¹„ìµœì  ë°ì´í„°ì…‹ì—ì„œ íš¨ê³¼ì ì¸ ì •ì±… í•™ìŠµì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
- 5. ì‚¬ì „ í›ˆë ¨ëœ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ DT ëª¨ë¸ì˜ ë°±ë³¸ìœ¼ë¡œ ì‚¬ìš©í•˜ê³ , LoRAë¥¼ í†µí•œ íŒŒë¼ë¯¸í„° íš¨ìœ¨ì  ë¯¸ì„¸ ì¡°ì •ì„ í†µí•´ ì†Œê·œëª¨ ë°ì´í„°ì…‹ìœ¼ë¡œë„ ë¹ ë¥¸ ì ì‘ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 03:10:17*