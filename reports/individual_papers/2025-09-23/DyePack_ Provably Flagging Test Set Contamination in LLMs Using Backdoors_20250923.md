---
keywords:
  - Large Language Model
  - Test Set Contamination
  - Backdoor Attack
  - False Positive Rate
  - Open Benchmark
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2505.23001
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T04:01:18.255331",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Test Set Contamination",
    "Backdoor Attack",
    "False Positive Rate",
    "Open Benchmark"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Test Set Contamination": 0.78,
    "Backdoor Attack": 0.82,
    "False Positive Rate": 0.77,
    "Open Benchmark": 0.74
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are central to the paper's focus on test set contamination and evaluation.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Test Set Contamination",
        "canonical": "Test Set Contamination",
        "aliases": [
          "Benchmark Contamination"
        ],
        "category": "unique_technical",
        "rationale": "Test Set Contamination is a unique challenge addressed by the DyePack framework.",
        "novelty_score": 0.75,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Backdoor Attacks",
        "canonical": "Backdoor Attack",
        "aliases": [
          "Backdoor Techniques"
        ],
        "category": "specific_connectable",
        "rationale": "Backdoor Attacks are a key method used in DyePack to identify contaminated models.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.85,
        "link_intent_score": 0.82
      },
      {
        "surface": "False Positive Rate",
        "canonical": "False Positive Rate",
        "aliases": [
          "FPR"
        ],
        "category": "specific_connectable",
        "rationale": "False Positive Rate is crucial for understanding the accuracy of the DyePack framework.",
        "novelty_score": 0.4,
        "connectivity_score": 0.65,
        "specificity_score": 0.7,
        "link_intent_score": 0.77
      },
      {
        "surface": "Open Benchmarks",
        "canonical": "Open Benchmark",
        "aliases": [
          "Public Benchmarks"
        ],
        "category": "specific_connectable",
        "rationale": "Open Benchmarks are essential for evaluating models and are susceptible to contamination.",
        "novelty_score": 0.5,
        "connectivity_score": 0.68,
        "specificity_score": 0.72,
        "link_intent_score": 0.74
      }
    ],
    "ban_list_suggestions": [
      "framework",
      "model",
      "evaluation"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Test Set Contamination",
      "resolved_canonical": "Test Set Contamination",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Backdoor Attacks",
      "resolved_canonical": "Backdoor Attack",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.85,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "False Positive Rate",
      "resolved_canonical": "False Positive Rate",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.65,
        "specificity": 0.7,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Open Benchmarks",
      "resolved_canonical": "Open Benchmark",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.68,
        "specificity": 0.72,
        "link_intent": 0.74
      }
    }
  ]
}
-->

# DyePack: Provably Flagging Test Set Contamination in LLMs Using Backdoors

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2505.23001.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2505.23001](https://arxiv.org/abs/2505.23001)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Rethinking Backdoor Detection Evaluation for Language Models_20250923|Rethinking Backdoor Detection Evaluation for Language Models]] (84.7% similar)
- [[2025-09-22/Backdoor Mitigation via Invertible Pruning Masks_20250922|Backdoor Mitigation via Invertible Pruning Masks]] (84.0% similar)
- [[2025-09-23/Both Text and Images Leaked! A Systematic Analysis of Data Contamination in Multimodal LLM_20250923|Both Text and Images Leaked! A Systematic Analysis of Data Contamination in Multimodal LLM]] (83.9% similar)
- [[2025-09-18/LNE-Blocking_ An Efficient Framework for Contamination Mitigation Evaluation on Large Language Models_20250918|LNE-Blocking: An Efficient Framework for Contamination Mitigation Evaluation on Large Language Models]] (83.9% similar)
- [[2025-09-23/Revisiting Backdoor Attacks on LLMs_ A Stealthy and Practical Poisoning Framework via Harmless Inputs_20250923|Revisiting Backdoor Attacks on LLMs: A Stealthy and Practical Poisoning Framework via Harmless Inputs]] (82.7% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Backdoor Attack|Backdoor Attack]], [[keywords/False Positive Rate|False Positive Rate]], [[keywords/Open Benchmark|Open Benchmark]]
**âš¡ Unique Technical**: [[keywords/Test Set Contamination|Test Set Contamination]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2505.23001v4 Announce Type: replace 
Abstract: Open benchmarks are essential for evaluating and advancing large language models, offering reproducibility and transparency. However, their accessibility makes them likely targets of test set contamination. In this work, we introduce DyePack, a framework that leverages backdoor attacks to identify models that used benchmark test sets during training, without requiring access to the loss, logits, or any internal details of the model. Like how banks mix dye packs with their money to mark robbers, DyePack mixes backdoor samples with the test data to flag models that trained on it. We propose a principled design incorporating multiple backdoors with stochastic targets, enabling exact false positive rate (FPR) computation when flagging every model. This provably prevents false accusations while providing strong evidence for every detected case of contamination. We evaluate DyePack on five models across three datasets, covering both multiple-choice and open-ended generation tasks. For multiple-choice questions, it successfully detects all contaminated models with guaranteed FPRs as low as 0.000073% on MMLU-Pro and 0.000017% on Big-Bench-Hard using eight backdoors. For open-ended generation tasks, it generalizes well and identifies all contaminated models on Alpaca with a guaranteed false positive rate of just 0.127% using six backdoors.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì—ì„œëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ í‰ê°€ë¥¼ ìœ„í•œ ì˜¤í”ˆ ë²¤ì¹˜ë§ˆí¬ì˜ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ì˜¤ì—¼ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ DyePackì´ë¼ëŠ” í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. DyePackì€ ëª¨ë¸ì˜ ë‚´ë¶€ ì •ë³´ ì—†ì´ ë°±ë„ì–´ ê³µê²©ì„ í™œìš©í•˜ì—¬ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¥¼ í•™ìŠµì— ì‚¬ìš©í•œ ëª¨ë¸ì„ ì‹ë³„í•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ì—¬ëŸ¬ ë°±ë„ì–´ì™€ í™•ë¥ ì  ëª©í‘œë¥¼ í†µí•©í•˜ì—¬ ëª¨ë“  ëª¨ë¸ì— ëŒ€í•œ ì •í™•í•œ ì˜¤íƒë¥ (FPR)ì„ ê³„ì‚°í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì˜ëª»ëœ ë¹„ë‚œì„ ë°©ì§€í•˜ë©´ì„œë„ ì˜¤ì—¼ëœ ì‚¬ë¡€ì— ëŒ€í•œ ê°•ë ¥í•œ ì¦ê±°ë¥¼ ì œê³µí•©ë‹ˆë‹¤. DyePackì€ ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ê³¼ ëª¨ë¸ì— ëŒ€í•´ í‰ê°€ë˜ì—ˆìœ¼ë©°, ë‹¤ì¤‘ ì„ íƒ ë¬¸ì œì—ì„œëŠ” ë§¤ìš° ë‚®ì€ ì˜¤íƒë¥ ë¡œ ëª¨ë“  ì˜¤ì—¼ëœ ëª¨ë¸ì„ ì„±ê³µì ìœ¼ë¡œ ê°ì§€í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, ê°œë°©í˜• ìƒì„± ì‘ì—…ì—ì„œë„ ë†’ì€ ì¼ë°˜í™” ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. DyePackì€ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¥¼ í›ˆë ¨ì— ì‚¬ìš©í•œ ëª¨ë¸ì„ ì‹ë³„í•˜ê¸° ìœ„í•´ ë°±ë„ì–´ ê³µê²©ì„ í™œìš©í•˜ëŠ” í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.
- 2. DyePackì€ ì†ì‹¤, ë¡œì§“ ë˜ëŠ” ëª¨ë¸ì˜ ë‚´ë¶€ ì„¸ë¶€ ì •ë³´ì— ëŒ€í•œ ì ‘ê·¼ ì—†ì´ë„ ì‘ë™í•©ë‹ˆë‹¤.
- 3. ì—¬ëŸ¬ ë°±ë„ì–´ì™€ í™•ë¥ ì  ëª©í‘œë¥¼ í¬í•¨í•œ ì„¤ê³„ë¥¼ í†µí•´ ì •í™•í•œ ì˜¤íƒë¥ (FPR) ê³„ì‚°ì´ ê°€ëŠ¥í•˜ë©°, ì´ëŠ” ì˜ëª»ëœ ë¹„ë‚œì„ ë°©ì§€í•©ë‹ˆë‹¤.
- 4. DyePackì€ MMLU-Proì™€ Big-Bench-Hardì—ì„œ ë§¤ìš° ë‚®ì€ ì˜¤íƒë¥ ë¡œ ëª¨ë“  ì˜¤ì—¼ëœ ëª¨ë¸ì„ ì„±ê³µì ìœ¼ë¡œ íƒì§€í•©ë‹ˆë‹¤.
- 5. Alpacaì—ì„œì˜ ê°œë°©í˜• ìƒì„± ì‘ì—…ì—ì„œë„ DyePackì€ ëª¨ë“  ì˜¤ì—¼ëœ ëª¨ë¸ì„ ì‹ë³„í•˜ë©°, ì˜¤íƒë¥ ì€ 0.127%ì— ë¶ˆê³¼í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 04:01:18*