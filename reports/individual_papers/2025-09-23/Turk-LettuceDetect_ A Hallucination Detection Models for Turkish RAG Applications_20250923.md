---
keywords:
  - Turk-LettuceDetect
  - Large Language Model
  - Retrieval Augmented Generation
  - ModernBERT
  - RAGTruth Benchmark
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.17671
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T00:05:53.689419",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Turk-LettuceDetect",
    "Large Language Model",
    "Retrieval Augmented Generation",
    "ModernBERT",
    "RAGTruth Benchmark"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Turk-LettuceDetect": 0.8,
    "Large Language Model": 0.85,
    "Retrieval Augmented Generation": 0.82,
    "ModernBERT": 0.75,
    "RAGTruth Benchmark": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Turk-LettuceDetect",
        "canonical": "Turk-LettuceDetect",
        "aliases": [
          "Turkish Hallucination Detection"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel model specifically for Turkish RAG applications, filling a gap in multilingual NLP.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "A fundamental concept in NLP, crucial for understanding the context of hallucination in language models.",
        "novelty_score": 0.4,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Retrieval-Augmented Generation",
        "canonical": "Retrieval Augmented Generation",
        "aliases": [
          "RAG"
        ],
        "category": "specific_connectable",
        "rationale": "Central to the paper's approach in addressing hallucination, providing a key link to recent advancements.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "ModernBERT",
        "canonical": "ModernBERT",
        "aliases": [
          "Turkish BERT"
        ],
        "category": "unique_technical",
        "rationale": "A specialized model variant tailored for Turkish, enhancing the paper's focus on language-specific solutions.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.75
      },
      {
        "surface": "RAGTruth benchmark dataset",
        "canonical": "RAGTruth Benchmark",
        "aliases": [
          "RAGTruth"
        ],
        "category": "unique_technical",
        "rationale": "Provides a critical dataset for evaluating hallucination detection, linking to empirical validation efforts.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "hallucination",
      "dataset",
      "model"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Turk-LettuceDetect",
      "resolved_canonical": "Turk-LettuceDetect",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Retrieval-Augmented Generation",
      "resolved_canonical": "Retrieval Augmented Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "ModernBERT",
      "resolved_canonical": "ModernBERT",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "RAGTruth benchmark dataset",
      "resolved_canonical": "RAGTruth Benchmark",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# Turk-LettuceDetect: A Hallucination Detection Models for Turkish RAG Applications

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17671.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.17671](https://arxiv.org/abs/2509.17671)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Do Retrieval Augmented Language Models Know When They Don't Know?_20250922|Do Retrieval Augmented Language Models Know When They Don't Know?]] (81.4% similar)
- [[2025-09-23/How Large Language Models are Designed to Hallucinate_20250923|How Large Language Models are Designed to Hallucinate]] (81.3% similar)
- [[2025-09-19/DetectAnyLLM_ Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models_20250919|DetectAnyLLM: Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models]] (81.3% similar)
- [[2025-09-22/Automatic Lexical Simplification for Turkish_20250922|Automatic Lexical Simplification for Turkish]] (81.0% similar)
- [[2025-09-22/KatFishNet_ Detecting LLM-Generated Korean Text through Linguistic Feature Analysis_20250922|KatFishNet: Detecting LLM-Generated Korean Text through Linguistic Feature Analysis]] (80.9% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Retrieval Augmented Generation|Retrieval Augmented Generation]]
**âš¡ Unique Technical**: [[keywords/Turk-LettuceDetect|Turk-LettuceDetect]], [[keywords/ModernBERT|ModernBERT]], [[keywords/RAGTruth Benchmark|RAGTruth Benchmark]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17671v1 Announce Type: cross 
Abstract: The widespread adoption of Large Language Models (LLMs) has been hindered by their tendency to hallucinate, generating plausible but factually incorrect information. While Retrieval-Augmented Generation (RAG) systems attempt to address this issue by grounding responses in external knowledge, hallucination remains a persistent challenge, particularly for morphologically complex, low-resource languages like Turkish. This paper introduces Turk-LettuceDetect, the first suite of hallucination detection models specifically designed for Turkish RAG applications. Building on the LettuceDetect framework, we formulate hallucination detection as a token-level classification task and fine-tune three distinct encoder architectures: a Turkish-specific ModernBERT, TurkEmbed4STS, and multilingual EuroBERT. These models were trained on a machine-translated version of the RAGTruth benchmark dataset containing 17,790 instances across question answering, data-to-text generation, and summarization tasks. Our experimental results show that the ModernBERT-based model achieves an F1-score of 0.7266 on the complete test set, with particularly strong performance on structured tasks. The models maintain computational efficiency while supporting long contexts up to 8,192 tokens, making them suitable for real-time deployment. Comparative analysis reveals that while state-of-the-art LLMs demonstrate high recall, they suffer from low precision due to over-generation of hallucinated content, underscoring the necessity of specialized detection mechanisms. By releasing our models and translated dataset, this work addresses a critical gap in multilingual NLP and establishes a foundation for developing more reliable and trustworthy AI applications for Turkish and other languages.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ í„°í‚¤ì–´ì™€ ê°™ì€ í˜•íƒœì ìœ¼ë¡œ ë³µì¡í•˜ê³  ìì›ì´ ë¶€ì¡±í•œ ì–¸ì–´ì—ì„œ ë°œìƒí•˜ëŠ” í™˜ê° ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ í„°í‚¤ì–´ RAG(Retrieval-Augmented Generation) ì‘ìš© í”„ë¡œê·¸ë¨ì— íŠ¹í™”ëœ í™˜ê° íƒì§€ ëª¨ë¸ì¸ Turk-LettuceDetectë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. LettuceDetect í”„ë ˆì„ì›Œí¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í™˜ê° íƒì§€ë¥¼ í† í° ìˆ˜ì¤€ì˜ ë¶„ë¥˜ ì‘ì—…ìœ¼ë¡œ ì •ì˜í•˜ê³ , í„°í‚¤ì–´ì— íŠ¹í™”ëœ ModernBERT, TurkEmbed4STS, ë‹¤êµ­ì–´ EuroBERT ë“± ì„¸ ê°€ì§€ ì¸ì½”ë” ì•„í‚¤í…ì²˜ë¥¼ ë¯¸ì„¸ ì¡°ì •í–ˆìŠµë‹ˆë‹¤. ì´ ëª¨ë¸ë“¤ì€ 17,790ê°œì˜ ì¸ìŠ¤í„´ìŠ¤ë¥¼ í¬í•¨í•œ RAGTruth ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì˜ ê¸°ê³„ ë²ˆì—­ ë²„ì „ìœ¼ë¡œ í›ˆë ¨ë˜ì—ˆìŠµë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ModernBERT ê¸°ë°˜ ëª¨ë¸ì´ ì „ì²´ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ F1 ì ìˆ˜ 0.7266ì„ ê¸°ë¡í•˜ë©° íŠ¹íˆ êµ¬ì¡°í™”ëœ ì‘ì—…ì—ì„œ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ëª¨ë¸ë“¤ì€ ìµœëŒ€ 8,192 í† í°ì˜ ê¸´ ë¬¸ë§¥ì„ ì§€ì›í•˜ë©´ì„œë„ ê³„ì‚° íš¨ìœ¨ì„±ì„ ìœ ì§€í•˜ì—¬ ì‹¤ì‹œê°„ ë°°í¬ì— ì í•©í•©ë‹ˆë‹¤. ë¹„êµ ë¶„ì„ ê²°ê³¼, ìµœì‹  LLMë“¤ì´ ë†’ì€ ì¬í˜„ìœ¨ì„ ë³´ì´ì§€ë§Œ í™˜ê°ëœ ì½˜í…ì¸ ì˜ ê³¼ì‰ ìƒì„±ìœ¼ë¡œ ì¸í•´ ë‚®ì€ ì •ë°€ë„ë¥¼ ë‚˜íƒ€ë‚´ì–´, íŠ¹í™”ëœ íƒì§€ ë©”ì»¤ë‹ˆì¦˜ì˜ í•„ìš”ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ë‹¤êµ­ì–´ NLPì˜ ì¤‘ìš”í•œ ê²©ì°¨ë¥¼ í•´ê²°í•˜ê³ , í„°í‚¤ì–´ ë° ë‹¤ë¥¸ ì–¸ì–´ë¥¼ ìœ„í•œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” AI ì‘ìš© í”„ë¡œê·¸ë¨ ê°œë°œì˜ ê¸°ì´ˆë¥¼ ë§ˆë ¨í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. í„°í‚¤ì–´ RAG ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìœ„í•œ ìµœì´ˆì˜ í™˜ê° íƒì§€ ëª¨ë¸ ëª¨ìŒì¸ Turk-LettuceDetectë¥¼ ì†Œê°œí•©ë‹ˆë‹¤.
- 2. í™˜ê° íƒì§€ë¥¼ í† í° ìˆ˜ì¤€ì˜ ë¶„ë¥˜ ì‘ì—…ìœ¼ë¡œ ì •ì˜í•˜ê³ , ì„¸ ê°€ì§€ ì¸ì½”ë” ì•„í‚¤í…ì²˜ë¥¼ ë¯¸ì„¸ ì¡°ì •í–ˆìŠµë‹ˆë‹¤: í„°í‚¤ì–´ ì „ìš© ModernBERT, TurkEmbed4STS, ë‹¤êµ­ì–´ EuroBERT.
- 3. ModernBERT ê¸°ë°˜ ëª¨ë¸ì€ ì „ì²´ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ F1 ì ìˆ˜ 0.7266ì„ ë‹¬ì„±í•˜ë©°, íŠ¹íˆ êµ¬ì¡°í™”ëœ ì‘ì—…ì—ì„œ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.
- 4. ëª¨ë¸ë“¤ì€ ìµœëŒ€ 8,192 í† í°ì˜ ê¸´ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì§€ì›í•˜ë©´ì„œë„ ê³„ì‚° íš¨ìœ¨ì„±ì„ ìœ ì§€í•˜ì—¬ ì‹¤ì‹œê°„ ë°°í¬ì— ì í•©í•©ë‹ˆë‹¤.
- 5. ì´ ì—°êµ¬ëŠ” ë‹¤êµ­ì–´ NLPì—ì„œ ì¤‘ìš”í•œ ê²©ì°¨ë¥¼ í•´ê²°í•˜ê³ , í„°í‚¤ì–´ ë° ê¸°íƒ€ ì–¸ì–´ë¥¼ ìœ„í•œ ë” ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” AI ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì˜ ê¸°ì´ˆë¥¼ ë§ˆë ¨í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 00:05:53*