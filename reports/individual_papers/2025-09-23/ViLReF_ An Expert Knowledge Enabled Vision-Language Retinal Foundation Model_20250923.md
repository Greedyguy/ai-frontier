---
keywords:
  - Vision-Language Model
  - Weighted Similarity Coupling Loss
  - Zero-Shot Learning
  - Batch Expansion Module
  - Dynamic Memory Queues
category: cs.CV
publish_date: 2025-09-23
arxiv_id: 2408.10894
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T05:15:02.726502",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Vision-Language Model",
    "Weighted Similarity Coupling Loss",
    "Zero-Shot Learning",
    "Batch Expansion Module",
    "Dynamic Memory Queues"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Vision-Language Model": 0.88,
    "Weighted Similarity Coupling Loss": 0.7,
    "Zero-Shot Learning": 0.85,
    "Batch Expansion Module": 0.72,
    "Dynamic Memory Queues": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Vision-Language Retinal Foundation Model",
        "canonical": "Vision-Language Model",
        "aliases": [
          "ViLReF"
        ],
        "category": "evolved_concepts",
        "rationale": "This connects to the broader concept of vision-language models, which is crucial for understanding the integration of visual and textual data.",
        "novelty_score": 0.7,
        "connectivity_score": 0.85,
        "specificity_score": 0.8,
        "link_intent_score": 0.88
      },
      {
        "surface": "Weighted Similarity Coupling Loss",
        "canonical": "Weighted Similarity Coupling Loss",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This is a unique loss function introduced in the paper, which is essential for understanding the model's training process.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.7
      },
      {
        "surface": "Zero-Shot Learning",
        "canonical": "Zero-Shot Learning",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Zero-shot learning is a key capability of the model, linking it to broader trends in machine learning.",
        "novelty_score": 0.6,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Batch Expansion Module",
        "canonical": "Batch Expansion Module",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This module is a novel component of the model architecture, important for understanding its data handling strategy.",
        "novelty_score": 0.65,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.72
      },
      {
        "surface": "Dynamic Memory Queues",
        "canonical": "Dynamic Memory Queues",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Dynamic memory queues are crucial for the model's ability to manage data efficiently during training.",
        "novelty_score": 0.68,
        "connectivity_score": 0.75,
        "specificity_score": 0.78,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "pre-training",
      "model's learning ability",
      "extensive experiments"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Vision-Language Retinal Foundation Model",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.85,
        "specificity": 0.8,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "Weighted Similarity Coupling Loss",
      "resolved_canonical": "Weighted Similarity Coupling Loss",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Zero-Shot Learning",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Batch Expansion Module",
      "resolved_canonical": "Batch Expansion Module",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "Dynamic Memory Queues",
      "resolved_canonical": "Dynamic Memory Queues",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.75,
        "specificity": 0.78,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# ViLReF: An Expert Knowledge Enabled Vision-Language Retinal Foundation Model

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2408.10894.pdf)
**Category**: cs.CV
**Published**: 2025-09-23
**ArXiv ID**: [2408.10894](https://arxiv.org/abs/2408.10894)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Vision Language Models Are Not (Yet) Spelling Correctors_20250923|Vision Language Models Are Not (Yet) Spelling Correctors]] (85.0% similar)
- [[2025-09-23/Visual Instruction Pretraining for Domain-Specific Foundation Models_20250923|Visual Instruction Pretraining for Domain-Specific Foundation Models]] (85.0% similar)
- [[2025-09-22/ViSpec_ Accelerating Vision-Language Models with Vision-Aware Speculative Decoding_20250922|ViSpec: Accelerating Vision-Language Models with Vision-Aware Speculative Decoding]] (84.1% similar)
- [[2025-09-23/Catching the Details_ Self-Distilled RoI Predictors for Fine-Grained MLLM Perception_20250923|Catching the Details: Self-Distilled RoI Predictors for Fine-Grained MLLM Perception]] (83.8% similar)
- [[2025-09-22/Quality-Driven Curation of Remote Sensing Vision-Language Data via Learned Scoring Models_20250922|Quality-Driven Curation of Remote Sensing Vision-Language Data via Learned Scoring Models]] (83.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Zero-Shot Learning|Zero-Shot Learning]]
**âš¡ Unique Technical**: [[keywords/Weighted Similarity Coupling Loss|Weighted Similarity Coupling Loss]], [[keywords/Batch Expansion Module|Batch Expansion Module]], [[keywords/Dynamic Memory Queues|Dynamic Memory Queues]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2408.10894v4 Announce Type: replace 
Abstract: Subtle semantic differences in retinal image and text data present great challenges for pre-training visual-language models. Moreover, false negative samples, i.e., image-text pairs having the same semantics but incorrectly regarded as negatives, disrupt the visual-language pre-training process and affect the model's learning ability. This work aims to develop a retinal foundation model, called ViLReF, by pre-training on a paired dataset comprising 451,956 retinal images and corresponding diagnostic text reports. In our vision-language pre-training strategy, we leverage expert knowledge to facilitate the extraction of labels and propose a novel constraint, the Weighted Similarity Coupling Loss, to adjust the speed of pushing sample pairs further apart dynamically within the feature space. Furthermore, we employ a batch expansion module with dynamic memory queues, maintained by momentum encoders, to supply extra samples and compensate for the vacancies caused by eliminating false negatives. Extensive experiments are conducted on multiple datasets for downstream classification and segmentation tasks. The experimental results demonstrate the powerful zero-shot and transfer learning capabilities of ViLReF, verifying the effectiveness of our pre-training strategy. Our ViLReF model is available at: https://github.com/T6Yang/ViLReF.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” ë§ë§‰ ì´ë¯¸ì§€ì™€ ì§„ë‹¨ í…ìŠ¤íŠ¸ ë³´ê³ ì„œë¡œ êµ¬ì„±ëœ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ ì‹œê°-ì–¸ì–´ ëª¨ë¸ì¸ ViLReFë¥¼ ì‚¬ì „ í›ˆë ¨í•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì£¼ìš” ê¸°ì—¬ëŠ” ì „ë¬¸ê°€ ì§€ì‹ì„ í™œìš©í•œ ë ˆì´ë¸” ì¶”ì¶œê³¼ 'ê°€ì¤‘ ìœ ì‚¬ì„± ê²°í•© ì†ì‹¤'ì´ë¼ëŠ” ìƒˆë¡œìš´ ì œì•½ ì¡°ê±´ì„ ë„ì…í•˜ì—¬ ìƒ˜í”Œ ìŒ ê°„ì˜ ê±°ë¦¬ë¥¼ ë™ì ìœ¼ë¡œ ì¡°ì ˆí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ë˜í•œ, ëª¨ë©˜í…€ ì¸ì½”ë”ë¡œ ìœ ì§€ë˜ëŠ” ë™ì  ë©”ëª¨ë¦¬ íë¥¼ ì‚¬ìš©í•˜ì—¬ ë°°ì¹˜ í™•ì¥ ëª¨ë“ˆì„ êµ¬í˜„, ì˜ëª»ëœ ë¶€ì • ìƒ˜í”Œì„ ì œê±°í•œ í›„ì˜ ê³µë°±ì„ ë³´ì™„í•©ë‹ˆë‹¤. ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ì— ëŒ€í•œ ì‹¤í—˜ ê²°ê³¼, ViLReFì˜ ê°•ë ¥í•œ ì œë¡œìƒ· ë° ì „ì´ í•™ìŠµ ëŠ¥ë ¥ì´ ì…ì¦ë˜ì—ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ViLReFëŠ” 451,956ê°œì˜ ë§ë§‰ ì´ë¯¸ì§€ì™€ ì§„ë‹¨ í…ìŠ¤íŠ¸ ë³´ê³ ì„œë¡œ êµ¬ì„±ëœ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ì „ í•™ìŠµëœ ë§ë§‰ ê¸°ì´ˆ ëª¨ë¸ì…ë‹ˆë‹¤.
- 2. ì‹œê°-ì–¸ì–´ ì‚¬ì „ í•™ìŠµ ê³¼ì •ì—ì„œ ì „ë¬¸ê°€ ì§€ì‹ì„ í™œìš©í•˜ì—¬ ë ˆì´ë¸” ì¶”ì¶œì„ ìš©ì´í•˜ê²Œ í•˜ê³ , Weighted Similarity Coupling Lossë¼ëŠ” ìƒˆë¡œìš´ ì œì•½ì„ ì œì•ˆí•©ë‹ˆë‹¤.
- 3. ë°°ì¹˜ í™•ì¥ ëª¨ë“ˆê³¼ ë™ì  ë©”ëª¨ë¦¬ íë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ëª»ëœ ìŒì„± ìƒ˜í”Œì„ ì œê±°í•¨ìœ¼ë¡œì¨ ë°œìƒí•˜ëŠ” ê³µë°±ì„ ë³´ì™„í•©ë‹ˆë‹¤.
- 4. ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ì—ì„œì˜ ì‹¤í—˜ ê²°ê³¼, ViLReFëŠ” ê°•ë ¥í•œ ì œë¡œìƒ· ë° ì „ì´ í•™ìŠµ ëŠ¥ë ¥ì„ ë³´ì—¬ì£¼ë©°, ì‚¬ì „ í•™ìŠµ ì „ëµì˜ íš¨ê³¼ì„±ì„ ì…ì¦í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 05:15:02*