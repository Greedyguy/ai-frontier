---
keywords:
  - Neural Processing Unit
  - Embedded Microcontroller
  - Energy Efficiency
  - ARM Cortex-M55
  - Real-time Edge Device
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.17533
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T00:00:45.382197",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Neural Processing Unit",
    "Embedded Microcontroller",
    "Energy Efficiency",
    "ARM Cortex-M55",
    "Real-time Edge Device"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Neural Processing Unit": 0.82,
    "Embedded Microcontroller": 0.78,
    "Energy Efficiency": 0.7,
    "ARM Cortex-M55": 0.75,
    "Real-time Edge Device": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Neural Processing Units",
        "canonical": "Neural Processing Unit",
        "aliases": [
          "NPU",
          "NPUs"
        ],
        "category": "unique_technical",
        "rationale": "NPUs are critical for enhancing energy efficiency in embedded ML, offering a unique technical focus.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.85,
        "link_intent_score": 0.82
      },
      {
        "surface": "Embedded Microcontrollers",
        "canonical": "Embedded Microcontroller",
        "aliases": [
          "MCU",
          "MCUs"
        ],
        "category": "unique_technical",
        "rationale": "Embedded microcontrollers are central to the study's context, providing a specific technical domain.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Energy Efficiency",
        "canonical": "Energy Efficiency",
        "aliases": [
          "Power Efficiency"
        ],
        "category": "broad_technical",
        "rationale": "Energy efficiency is a key concern in embedded ML, linking to broader sustainability goals.",
        "novelty_score": 0.5,
        "connectivity_score": 0.7,
        "specificity_score": 0.6,
        "link_intent_score": 0.7
      },
      {
        "surface": "ARM Cortex-M55",
        "canonical": "ARM Cortex-M55",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "The ARM Cortex-M55 is a specific hardware platform used in the study, crucial for replication and context.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.9,
        "link_intent_score": 0.75
      },
      {
        "surface": "Real-time Edge Devices",
        "canonical": "Real-time Edge Device",
        "aliases": [
          "Edge Devices"
        ],
        "category": "specific_connectable",
        "rationale": "Real-time edge devices are vital for understanding the deployment environment of embedded ML.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.75,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "methodology",
      "experimental results",
      "measurement"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Neural Processing Units",
      "resolved_canonical": "Neural Processing Unit",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.85,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Embedded Microcontrollers",
      "resolved_canonical": "Embedded Microcontroller",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Energy Efficiency",
      "resolved_canonical": "Energy Efficiency",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.7,
        "specificity": 0.6,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "ARM Cortex-M55",
      "resolved_canonical": "ARM Cortex-M55",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.9,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Real-time Edge Devices",
      "resolved_canonical": "Real-time Edge Device",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.75,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# Evaluating the Energy Efficiency of NPU-Accelerated Machine Learning Inference on Embedded Microcontrollers

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17533.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.17533](https://arxiv.org/abs/2509.17533)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/eIQ Neutron_ Redefining Edge-AI Inference with Integrated NPU and Compiler Innovations_20250919|eIQ Neutron: Redefining Edge-AI Inference with Integrated NPU and Compiler Innovations]] (87.4% similar)
- [[2025-09-19/MaRVIn_ A Cross-Layer Mixed-Precision RISC-V Framework for DNN Inference, from ISA Extension to Hardware Acceleration_20250919|MaRVIn: A Cross-Layer Mixed-Precision RISC-V Framework for DNN Inference, from ISA Extension to Hardware Acceleration]] (82.9% similar)
- [[2025-09-22/Hybrid unary-binary design for multiplier-less printed Machine Learning classifiers_20250922|Hybrid unary-binary design for multiplier-less printed Machine Learning classifiers]] (82.2% similar)
- [[2025-09-22/Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs_20250922|Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs]] (82.1% similar)
- [[2025-09-22/Comprehensive Evaluation of CNN-Based Audio Tagging Models on Resource-Constrained Devices_20250922|Comprehensive Evaluation of CNN-Based Audio Tagging Models on Resource-Constrained Devices]] (80.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Energy Efficiency|Energy Efficiency]]
**ğŸ”— Specific Connectable**: [[keywords/Real-time Edge Device|Real-time Edge Device]]
**âš¡ Unique Technical**: [[keywords/Neural Processing Unit|Neural Processing Unit]], [[keywords/Embedded Microcontroller|Embedded Microcontroller]], [[keywords/ARM Cortex-M55|ARM Cortex-M55]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17533v1 Announce Type: cross 
Abstract: The deployment of machine learning (ML) models on microcontrollers (MCUs) is constrained by strict energy, latency, and memory requirements, particularly in battery-operated and real-time edge devices. While software-level optimizations such as quantization and pruning reduce model size and computation, hardware acceleration has emerged as a decisive enabler for efficient embedded inference. This paper evaluates the impact of Neural Processing Units (NPUs) on MCU-based ML execution, using the ARM Cortex-M55 core combined with the Ethos-U55 NPU on the Alif Semiconductor Ensemble E7 development board as a representative platform. A rigorous measurement methodology was employed, incorporating per-inference net energy accounting via GPIO-triggered high-resolution digital multimeter synchronization and idle-state subtraction, ensuring accurate attribution of energy costs. Experimental results across six representative ML models -including MiniResNet, MobileNetV2, FD-MobileNet, MNIST, TinyYolo, and SSD-MobileNet- demonstrate substantial efficiency gains when inference is offloaded to the NPU. For moderate to large networks, latency improvements ranged from 7x to over 125x, with per-inference net energy reductions up to 143x. Notably, the NPU enabled execution of models unsupported on CPU-only paths, such as SSD-MobileNet, highlighting its functional as well as efficiency advantages. These findings establish NPUs as a cornerstone of energy-aware embedded AI, enabling real-time, power-constrained ML inference at the MCU level.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë§ˆì´í¬ë¡œì»¨íŠ¸ë¡¤ëŸ¬(MCU)ì—ì„œ ë¨¸ì‹ ëŸ¬ë‹(ML) ëª¨ë¸ì„ ì‹¤í–‰í•  ë•Œì˜ ì—ë„ˆì§€, ì§€ì—° ì‹œê°„, ë©”ëª¨ë¦¬ ì œì•½ì„ í•´ê²°í•˜ê¸° ìœ„í•´ í•˜ë“œì›¨ì–´ ê°€ì†ì˜ ì¤‘ìš”ì„±ì„ í‰ê°€í•©ë‹ˆë‹¤. ARM Cortex-M55 ì½”ì–´ì™€ Ethos-U55 NPUë¥¼ ì‚¬ìš©í•œ ì‹¤í—˜ì—ì„œ, NPUë¥¼ í™œìš©í•œ ê²½ìš° ML ëª¨ë¸ì˜ ì¶”ë¡  íš¨ìœ¨ì„±ì´ í¬ê²Œ í–¥ìƒë¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. MiniResNet, MobileNetV2 ë“± 6ê°œì˜ ëŒ€í‘œì ì¸ ML ëª¨ë¸ì„ ëŒ€ìƒìœ¼ë¡œ í•œ ì‹¤í—˜ ê²°ê³¼, NPUë¥¼ ì‚¬ìš©í•˜ë©´ ì§€ì—° ì‹œê°„ì´ ìµœëŒ€ 125ë°°, ì—ë„ˆì§€ëŠ” ìµœëŒ€ 143ë°° ì ˆê°ë˜ì—ˆìŠµë‹ˆë‹¤. íŠ¹íˆ, SSD-MobileNetê³¼ ê°™ì€ ëª¨ë¸ì€ CPUë§Œìœ¼ë¡œëŠ” ì‹¤í–‰í•  ìˆ˜ ì—†ì§€ë§Œ, NPUë¥¼ í†µí•´ ê°€ëŠ¥í•´ì¡ŒìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ê²°ê³¼ëŠ” NPUê°€ ì—ë„ˆì§€ íš¨ìœ¨ì ì¸ ì„ë² ë””ë“œ AI êµ¬í˜„ì— í•µì‹¬ì ì„ì„ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë§ˆì´í¬ë¡œì»¨íŠ¸ë¡¤ëŸ¬(MCU) ê¸°ë°˜ì˜ ë¨¸ì‹ ëŸ¬ë‹(ML) ì‹¤í–‰ì—ì„œ í•˜ë“œì›¨ì–´ ê°€ì†, íŠ¹íˆ ì‹ ê²½ì²˜ë¦¬ì¥ì¹˜(NPU)ì˜ í™œìš©ì´ íš¨ìœ¨ì ì¸ ì„ë² ë””ë“œ ì¶”ë¡ ì— ê²°ì •ì ì¸ ì—­í• ì„ í•œë‹¤.
- 2. ARM Cortex-M55 ì½”ì–´ì™€ Ethos-U55 NPUë¥¼ í™œìš©í•œ ì‹¤í—˜ì—ì„œ, NPUë¡œ ì¶”ë¡ ì„ ì˜¤í”„ë¡œë“œí•  ê²½ìš° ìƒë‹¹í•œ íš¨ìœ¨ì„± í–¥ìƒì´ ê´€ì°°ë˜ì—ˆë‹¤.
- 3. ì¤‘ê°„ì—ì„œ ëŒ€í˜• ë„¤íŠ¸ì›Œí¬ì˜ ê²½ìš°, ì§€ì—° ì‹œê°„ ê°œì„ ì€ 7ë°°ì—ì„œ 125ë°° ì´ìƒ, ì¶”ë¡ ë‹¹ ì—ë„ˆì§€ ì†Œë¹„ëŠ” ìµœëŒ€ 143ë°°ê¹Œì§€ ê°ì†Œí•˜ì˜€ë‹¤.
- 4. NPUëŠ” CPUë§Œìœ¼ë¡œëŠ” ì‹¤í–‰í•  ìˆ˜ ì—†ëŠ” ëª¨ë¸, ì˜ˆë¥¼ ë“¤ì–´ SSD-MobileNet, ì„ ì‹¤í–‰ ê°€ëŠ¥í•˜ê²Œ í•˜ì—¬ ê¸°ëŠ¥ì  ë° íš¨ìœ¨ì„± ì¸¡ë©´ì—ì„œ ì´ì ì„ ì œê³µí•œë‹¤.
- 5. ì´ëŸ¬í•œ ê²°ê³¼ëŠ” NPUê°€ ì—ë„ˆì§€ íš¨ìœ¨ì ì¸ ì„ë² ë””ë“œ AIì˜ í•µì‹¬ ìš”ì†Œì„ì„ ì…ì¦í•˜ë©°, ì‹¤ì‹œê°„ ì „ë ¥ ì œì•½ ML ì¶”ë¡ ì„ MCU ìˆ˜ì¤€ì—ì„œ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤.


---

*Generated on 2025-09-24 00:00:45*