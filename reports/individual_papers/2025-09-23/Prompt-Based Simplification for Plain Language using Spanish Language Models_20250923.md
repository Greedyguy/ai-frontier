---
keywords:
  - Zero-Shot Learning
  - Low-Rank Adaptation
  - Prompt Engineering
  - RigoChat-7B-v2
  - Semantic Similarity
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2509.17209
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:22:13.605867",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Zero-Shot Learning",
    "Low-Rank Adaptation",
    "Prompt Engineering",
    "RigoChat-7B-v2",
    "Semantic Similarity"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Zero-Shot Learning": 0.85,
    "Low-Rank Adaptation": 0.78,
    "Prompt Engineering": 0.8,
    "RigoChat-7B-v2": 0.77,
    "Semantic Similarity": 0.82
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Zero-Shot Configuration",
        "canonical": "Zero-Shot Learning",
        "aliases": [
          "Zero-Shot"
        ],
        "category": "specific_connectable",
        "rationale": "Zero-shot learning is a trending concept that enhances connectivity by linking to related learning paradigms.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Low-Rank Adaptation",
        "canonical": "Low-Rank Adaptation",
        "aliases": [
          "LoRA"
        ],
        "category": "unique_technical",
        "rationale": "Low-Rank Adaptation is a unique technique relevant to model optimization, offering new linkage opportunities.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Prompt Engineering",
        "canonical": "Prompt Engineering",
        "aliases": [
          "Prompt Design"
        ],
        "category": "specific_connectable",
        "rationale": "Prompt engineering is crucial for model performance and connects to broader NLP strategies.",
        "novelty_score": 0.55,
        "connectivity_score": 0.82,
        "specificity_score": 0.72,
        "link_intent_score": 0.8
      },
      {
        "surface": "RigoChat-7B-v2",
        "canonical": "RigoChat-7B-v2",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "RigoChat-7B-v2 is a specific model that can link to discussions on model architectures and applications.",
        "novelty_score": 0.68,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      },
      {
        "surface": "Semantic Similarity",
        "canonical": "Semantic Similarity",
        "aliases": [
          "SIM"
        ],
        "category": "broad_technical",
        "rationale": "Semantic similarity is a fundamental concept in NLP, linking to various evaluation metrics and tasks.",
        "novelty_score": 0.4,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.82
      }
    ],
    "ban_list_suggestions": [
      "Plain Language",
      "Training Data",
      "Readability Index"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Zero-Shot Configuration",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Low-Rank Adaptation",
      "resolved_canonical": "Low-Rank Adaptation",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Prompt Engineering",
      "resolved_canonical": "Prompt Engineering",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.82,
        "specificity": 0.72,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "RigoChat-7B-v2",
      "resolved_canonical": "RigoChat-7B-v2",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Semantic Similarity",
      "resolved_canonical": "Semantic Similarity",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.82
      }
    }
  ]
}
-->

# Prompt-Based Simplification for Plain Language using Spanish Language Models

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17209.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2509.17209](https://arxiv.org/abs/2509.17209)

## 🔗 유사한 논문
- [[2025-09-23/Prompt-with-Me_ in-IDE Structured Prompt Management for LLM-Driven Software Engineering_20250923|Prompt-with-Me: in-IDE Structured Prompt Management for LLM-Driven Software Engineering]] (80.6% similar)
- [[2025-09-22/A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages_20250922|A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages]] (79.6% similar)
- [[2025-09-23/CLaC at DISRPT 2025_ Hierarchical Adapters for Cross-Framework Multi-lingual Discourse Relation Classification_20250923|CLaC at DISRPT 2025: Hierarchical Adapters for Cross-Framework Multi-lingual Discourse Relation Classification]] (79.5% similar)
- [[2025-09-23/A State-Update Prompting Strategy for Efficient and Robust Multi-turn Dialogue_20250923|A State-Update Prompting Strategy for Efficient and Robust Multi-turn Dialogue]] (79.5% similar)
- [[2025-09-22/Enhancing LLM Language Adaption through Cross-lingual In-Context Pre-training_20250922|Enhancing LLM Language Adaption through Cross-lingual In-Context Pre-training]] (79.4% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Semantic Similarity|Semantic Similarity]]
**🔗 Specific Connectable**: [[keywords/Zero-Shot Learning|Zero-Shot Learning]], [[keywords/Prompt Engineering|Prompt Engineering]]
**⚡ Unique Technical**: [[keywords/Low-Rank Adaptation|Low-Rank Adaptation]], [[keywords/RigoChat-7B-v2|RigoChat-7B-v2]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.17209v1 Announce Type: new 
Abstract: This paper describes the participation of HULAT-UC3M in CLEARS 2025 Subtask 1: Adaptation of Text to Plain Language (PL) in Spanish. We explored strategies based on models trained on Spanish texts, including a zero-shot configuration using prompt engineering and a fine-tuned version with Low-Rank Adaptation (LoRA). Different strategies were evaluated on representative internal subsets of the training data, using the official task metrics, cosine similarity (SIM) and the Fern\'andez-Huerta readability index (FH) to guide the selection of the optimal model and prompt combination. The final system was selected for its balanced and consistent performance, combining normalization steps, the RigoChat-7B-v2 model, and a dedicated PL-oriented prompt. It ranked first in semantic similarity (SIM = 0.75), however, fourth in readability (FH = 69.72). We also discuss key challenges related to training data heterogeneity and the limitations of current evaluation metrics in capturing both linguistic clarity and content preservation.

## 📝 요약

이 논문은 HULAT-UC3M이 CLEARS 2025의 스페인어 평이한 언어 적응(Subtask 1)에 참여한 내용을 다룹니다. 스페인어 텍스트를 기반으로 한 모델들을 탐색했으며, 프롬프트 엔지니어링을 활용한 제로샷 구성과 LoRA를 사용한 미세 조정 버전을 포함했습니다. 다양한 전략을 평가하여 최적의 모델과 프롬프트 조합을 선택했습니다. 최종 시스템은 RigoChat-7B-v2 모델과 PL 지향 프롬프트를 결합하여 균형 잡힌 성능을 보였고, 의미 유사성에서 1위를 차지했으나 가독성에서는 4위를 기록했습니다. 또한, 훈련 데이터의 이질성과 현재 평가 지표의 한계에 대해 논의했습니다.

## 🎯 주요 포인트

- 1. HULAT-UC3M은 CLEARS 2025 Subtask 1에 참여하여 스페인어 텍스트를 쉬운 언어로 변환하는 전략을 탐구했습니다.
- 2. 제로샷 구성과 Low-Rank Adaptation(LoRA)을 활용한 미세 조정 버전을 포함한 다양한 모델을 평가했습니다.
- 3. 최종 시스템은 RigoChat-7B-v2 모델과 전용 쉬운 언어 지향 프롬프트를 결합하여 균형 잡힌 성능을 보여주었습니다.
- 4. 이 시스템은 의미 유사성에서 1위를 차지했으나 가독성에서는 4위를 기록했습니다.
- 5. 훈련 데이터의 이질성과 현재 평가 지표의 한계에 대한 주요 도전 과제를 논의했습니다.


---

*Generated on 2025-09-24 03:22:13*