---
keywords:
  - Zero-Shot Learning
  - Low-Rank Adaptation
  - Prompt Engineering
  - RigoChat-7B-v2
  - Semantic Similarity
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2509.17209
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:22:13.605867",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Zero-Shot Learning",
    "Low-Rank Adaptation",
    "Prompt Engineering",
    "RigoChat-7B-v2",
    "Semantic Similarity"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Zero-Shot Learning": 0.85,
    "Low-Rank Adaptation": 0.78,
    "Prompt Engineering": 0.8,
    "RigoChat-7B-v2": 0.77,
    "Semantic Similarity": 0.82
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Zero-Shot Configuration",
        "canonical": "Zero-Shot Learning",
        "aliases": [
          "Zero-Shot"
        ],
        "category": "specific_connectable",
        "rationale": "Zero-shot learning is a trending concept that enhances connectivity by linking to related learning paradigms.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Low-Rank Adaptation",
        "canonical": "Low-Rank Adaptation",
        "aliases": [
          "LoRA"
        ],
        "category": "unique_technical",
        "rationale": "Low-Rank Adaptation is a unique technique relevant to model optimization, offering new linkage opportunities.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Prompt Engineering",
        "canonical": "Prompt Engineering",
        "aliases": [
          "Prompt Design"
        ],
        "category": "specific_connectable",
        "rationale": "Prompt engineering is crucial for model performance and connects to broader NLP strategies.",
        "novelty_score": 0.55,
        "connectivity_score": 0.82,
        "specificity_score": 0.72,
        "link_intent_score": 0.8
      },
      {
        "surface": "RigoChat-7B-v2",
        "canonical": "RigoChat-7B-v2",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "RigoChat-7B-v2 is a specific model that can link to discussions on model architectures and applications.",
        "novelty_score": 0.68,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      },
      {
        "surface": "Semantic Similarity",
        "canonical": "Semantic Similarity",
        "aliases": [
          "SIM"
        ],
        "category": "broad_technical",
        "rationale": "Semantic similarity is a fundamental concept in NLP, linking to various evaluation metrics and tasks.",
        "novelty_score": 0.4,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.82
      }
    ],
    "ban_list_suggestions": [
      "Plain Language",
      "Training Data",
      "Readability Index"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Zero-Shot Configuration",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Low-Rank Adaptation",
      "resolved_canonical": "Low-Rank Adaptation",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Prompt Engineering",
      "resolved_canonical": "Prompt Engineering",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.82,
        "specificity": 0.72,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "RigoChat-7B-v2",
      "resolved_canonical": "RigoChat-7B-v2",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Semantic Similarity",
      "resolved_canonical": "Semantic Similarity",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.82
      }
    }
  ]
}
-->

# Prompt-Based Simplification for Plain Language using Spanish Language Models

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17209.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2509.17209](https://arxiv.org/abs/2509.17209)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Prompt-with-Me_ in-IDE Structured Prompt Management for LLM-Driven Software Engineering_20250923|Prompt-with-Me: in-IDE Structured Prompt Management for LLM-Driven Software Engineering]] (80.6% similar)
- [[2025-09-22/A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages_20250922|A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages]] (79.6% similar)
- [[2025-09-23/CLaC at DISRPT 2025_ Hierarchical Adapters for Cross-Framework Multi-lingual Discourse Relation Classification_20250923|CLaC at DISRPT 2025: Hierarchical Adapters for Cross-Framework Multi-lingual Discourse Relation Classification]] (79.5% similar)
- [[2025-09-23/A State-Update Prompting Strategy for Efficient and Robust Multi-turn Dialogue_20250923|A State-Update Prompting Strategy for Efficient and Robust Multi-turn Dialogue]] (79.5% similar)
- [[2025-09-22/Enhancing LLM Language Adaption through Cross-lingual In-Context Pre-training_20250922|Enhancing LLM Language Adaption through Cross-lingual In-Context Pre-training]] (79.4% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Semantic Similarity|Semantic Similarity]]
**ğŸ”— Specific Connectable**: [[keywords/Zero-Shot Learning|Zero-Shot Learning]], [[keywords/Prompt Engineering|Prompt Engineering]]
**âš¡ Unique Technical**: [[keywords/Low-Rank Adaptation|Low-Rank Adaptation]], [[keywords/RigoChat-7B-v2|RigoChat-7B-v2]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17209v1 Announce Type: new 
Abstract: This paper describes the participation of HULAT-UC3M in CLEARS 2025 Subtask 1: Adaptation of Text to Plain Language (PL) in Spanish. We explored strategies based on models trained on Spanish texts, including a zero-shot configuration using prompt engineering and a fine-tuned version with Low-Rank Adaptation (LoRA). Different strategies were evaluated on representative internal subsets of the training data, using the official task metrics, cosine similarity (SIM) and the Fern\'andez-Huerta readability index (FH) to guide the selection of the optimal model and prompt combination. The final system was selected for its balanced and consistent performance, combining normalization steps, the RigoChat-7B-v2 model, and a dedicated PL-oriented prompt. It ranked first in semantic similarity (SIM = 0.75), however, fourth in readability (FH = 69.72). We also discuss key challenges related to training data heterogeneity and the limitations of current evaluation metrics in capturing both linguistic clarity and content preservation.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ HULAT-UC3Mì´ CLEARS 2025ì˜ ìŠ¤í˜ì¸ì–´ í‰ì´í•œ ì–¸ì–´ ì ì‘(Subtask 1)ì— ì°¸ì—¬í•œ ë‚´ìš©ì„ ë‹¤ë£¹ë‹ˆë‹¤. ìŠ¤í˜ì¸ì–´ í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ëª¨ë¸ë“¤ì„ íƒìƒ‰í–ˆìœ¼ë©°, í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì„ í™œìš©í•œ ì œë¡œìƒ· êµ¬ì„±ê³¼ LoRAë¥¼ ì‚¬ìš©í•œ ë¯¸ì„¸ ì¡°ì • ë²„ì „ì„ í¬í•¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì–‘í•œ ì „ëµì„ í‰ê°€í•˜ì—¬ ìµœì ì˜ ëª¨ë¸ê³¼ í”„ë¡¬í”„íŠ¸ ì¡°í•©ì„ ì„ íƒí–ˆìŠµë‹ˆë‹¤. ìµœì¢… ì‹œìŠ¤í…œì€ RigoChat-7B-v2 ëª¨ë¸ê³¼ PL ì§€í–¥ í”„ë¡¬í”„íŠ¸ë¥¼ ê²°í•©í•˜ì—¬ ê· í˜• ì¡íŒ ì„±ëŠ¥ì„ ë³´ì˜€ê³ , ì˜ë¯¸ ìœ ì‚¬ì„±ì—ì„œ 1ìœ„ë¥¼ ì°¨ì§€í–ˆìœ¼ë‚˜ ê°€ë…ì„±ì—ì„œëŠ” 4ìœ„ë¥¼ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, í›ˆë ¨ ë°ì´í„°ì˜ ì´ì§ˆì„±ê³¼ í˜„ì¬ í‰ê°€ ì§€í‘œì˜ í•œê³„ì— ëŒ€í•´ ë…¼ì˜í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. HULAT-UC3Mì€ CLEARS 2025 Subtask 1ì— ì°¸ì—¬í•˜ì—¬ ìŠ¤í˜ì¸ì–´ í…ìŠ¤íŠ¸ë¥¼ ì‰¬ìš´ ì–¸ì–´ë¡œ ë³€í™˜í•˜ëŠ” ì „ëµì„ íƒêµ¬í–ˆìŠµë‹ˆë‹¤.
- 2. ì œë¡œìƒ· êµ¬ì„±ê³¼ Low-Rank Adaptation(LoRA)ì„ í™œìš©í•œ ë¯¸ì„¸ ì¡°ì • ë²„ì „ì„ í¬í•¨í•œ ë‹¤ì–‘í•œ ëª¨ë¸ì„ í‰ê°€í–ˆìŠµë‹ˆë‹¤.
- 3. ìµœì¢… ì‹œìŠ¤í…œì€ RigoChat-7B-v2 ëª¨ë¸ê³¼ ì „ìš© ì‰¬ìš´ ì–¸ì–´ ì§€í–¥ í”„ë¡¬í”„íŠ¸ë¥¼ ê²°í•©í•˜ì—¬ ê· í˜• ì¡íŒ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤.
- 4. ì´ ì‹œìŠ¤í…œì€ ì˜ë¯¸ ìœ ì‚¬ì„±ì—ì„œ 1ìœ„ë¥¼ ì°¨ì§€í–ˆìœ¼ë‚˜ ê°€ë…ì„±ì—ì„œëŠ” 4ìœ„ë¥¼ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤.
- 5. í›ˆë ¨ ë°ì´í„°ì˜ ì´ì§ˆì„±ê³¼ í˜„ì¬ í‰ê°€ ì§€í‘œì˜ í•œê³„ì— ëŒ€í•œ ì£¼ìš” ë„ì „ ê³¼ì œë¥¼ ë…¼ì˜í–ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 03:22:13*