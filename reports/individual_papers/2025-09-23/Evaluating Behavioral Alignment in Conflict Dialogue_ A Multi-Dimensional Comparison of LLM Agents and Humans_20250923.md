---
keywords:
  - Large Language Model
  - Five-Factor Model
  - Behavioral Alignment
  - Conflict Dialogue
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.16394
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T23:17:58.324014",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Five-Factor Model",
    "Behavioral Alignment",
    "Conflict Dialogue"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Five-Factor Model": 0.7,
    "Behavioral Alignment": 0.8,
    "Conflict Dialogue": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Language Model"
        ],
        "category": "broad_technical",
        "rationale": "Key technology in the study, linking to broader discussions on language models.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Five-Factor personality profile",
        "canonical": "Five-Factor Model",
        "aliases": [
          "Big Five",
          "OCEAN Model"
        ],
        "category": "unique_technical",
        "rationale": "Central to the study's methodology, linking personality psychology with AI behavior.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      },
      {
        "surface": "behavioral alignment",
        "canonical": "Behavioral Alignment",
        "aliases": [
          "Behavioral Matching",
          "Behavioral Consistency"
        ],
        "category": "unique_technical",
        "rationale": "Core concept of the paper, crucial for understanding LLM-human interaction.",
        "novelty_score": 0.7,
        "connectivity_score": 0.7,
        "specificity_score": 0.75,
        "link_intent_score": 0.8
      },
      {
        "surface": "conflict dialogue",
        "canonical": "Conflict Dialogue",
        "aliases": [
          "Adversarial Dialogue",
          "Dispute Resolution"
        ],
        "category": "unique_technical",
        "rationale": "Specific application context for LLMs, enhancing connections to dialogue systems.",
        "novelty_score": 0.65,
        "connectivity_score": 0.6,
        "specificity_score": 0.7,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "emotion",
      "style",
      "negotiation"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Five-Factor personality profile",
      "resolved_canonical": "Five-Factor Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "behavioral alignment",
      "resolved_canonical": "Behavioral Alignment",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.7,
        "specificity": 0.75,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "conflict dialogue",
      "resolved_canonical": "Conflict Dialogue",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.6,
        "specificity": 0.7,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Evaluating Behavioral Alignment in Conflict Dialogue: A Multi-Dimensional Comparison of LLM Agents and Humans

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16394.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.16394](https://arxiv.org/abs/2509.16394)

## 🔗 유사한 논문
- [[2025-09-22/Exploring the Impact of Personality Traits on LLM Bias and Toxicity_20250922|Exploring the Impact of Personality Traits on LLM Bias and Toxicity]] (87.0% similar)
- [[2025-09-18/Do LLMs Align Human Values Regarding Social Biases? Judging and Explaining Social Biases with LLMs_20250918|Do LLMs Align Human Values Regarding Social Biases? Judging and Explaining Social Biases with LLMs]] (86.8% similar)
- [[2025-09-22/It Depends_ Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge_20250922|It Depends: Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge]] (86.5% similar)
- [[2025-09-22/Can LLMs Judge Debates? Evaluating Non-Linear Reasoning via Argumentation Theory Semantics_20250922|Can LLMs Judge Debates? Evaluating Non-Linear Reasoning via Argumentation Theory Semantics]] (85.8% similar)
- [[2025-09-23/Psychometric Personality Shaping Modulates Capabilities and Safety in Language Models_20250923|Psychometric Personality Shaping Modulates Capabilities and Safety in Language Models]] (85.6% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**⚡ Unique Technical**: [[keywords/Five-Factor Model|Five-Factor Model]], [[keywords/Behavioral Alignment|Behavioral Alignment]], [[keywords/Conflict Dialogue|Conflict Dialogue]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.16394v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) are increasingly deployed in socially complex, interaction-driven tasks, yet their ability to mirror human behavior in emotionally and strategically complex contexts remains underexplored. This study assesses the behavioral alignment of personality-prompted LLMs in adversarial dispute resolution by simulating multi-turn conflict dialogues that incorporate negotiation. Each LLM is guided by a matched Five-Factor personality profile to control for individual variation and enhance realism. We evaluate alignment across three dimensions: linguistic style, emotional expression (e.g., anger dynamics), and strategic behavior. GPT-4.1 achieves the closest alignment with humans in linguistic style and emotional dynamics, while Claude-3.7-Sonnet best reflects strategic behavior. Nonetheless, substantial alignment gaps persist. Our findings establish a benchmark for alignment between LLMs and humans in socially complex interactions, underscoring both the promise and the limitations of personality conditioning in dialogue modeling.

## 📝 요약

이 연구는 대형 언어 모델(LLM)이 감정적, 전략적으로 복잡한 상황에서 인간 행동을 모방하는 능력을 평가합니다. 연구는 성격 프로파일을 기반으로 한 LLM을 사용하여 협상 요소가 포함된 다중 회전 갈등 대화를 시뮬레이션합니다. GPT-4.1은 언어 스타일과 감정 표현에서 인간과 가장 유사한 반면, Claude-3.7-Sonnet은 전략적 행동에서 더 나은 성과를 보입니다. 그러나 여전히 상당한 차이가 존재합니다. 이 연구는 LLM과 인간 간의 상호작용 정렬의 기준점을 제시하며, 대화 모델링에서 성격 조건의 가능성과 한계를 강조합니다.

## 🎯 주요 포인트

- 1. 대형 언어 모델(LLM)의 감정적, 전략적 복잡성을 반영한 인간 행동 모방 능력은 아직 충분히 탐구되지 않았다.
- 2. 본 연구는 대립적 분쟁 해결에서 성격 기반 LLM의 행동적 정렬을 평가하기 위해 협상을 포함한 다중 회전 갈등 대화를 시뮬레이션한다.
- 3. 각 LLM은 개인 차이를 통제하고 현실성을 높이기 위해 일치된 5요인 성격 프로파일에 의해 안내된다.
- 4. GPT-4.1은 언어 스타일과 감정 역학에서 인간과 가장 가까운 정렬을 달성했으며, Claude-3.7-Sonnet은 전략적 행동을 가장 잘 반영했다.
- 5. 연구 결과는 LLM과 인간 간의 사회적 복잡한 상호작용에서의 정렬 기준을 설정하며, 대화 모델링에서 성격 조건화의 가능성과 한계를 강조한다.


---

*Generated on 2025-09-23 23:17:58*