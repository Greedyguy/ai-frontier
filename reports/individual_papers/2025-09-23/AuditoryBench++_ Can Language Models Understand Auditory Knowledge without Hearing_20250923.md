---
keywords:
  - AuditoryBench++
  - Auditory Imagination Reasoning
  - Multimodal Learning
  - Auditory Commonsense
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.17641
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T00:04:12.696292",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "AuditoryBench++",
    "Auditory Imagination Reasoning",
    "Multimodal Learning",
    "Auditory Commonsense"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "AuditoryBench++": 0.78,
    "Auditory Imagination Reasoning": 0.77,
    "Multimodal Learning": 0.79,
    "Auditory Commonsense": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "AuditoryBench++",
        "canonical": "AuditoryBench++",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "AuditoryBench++ is a unique benchmark specifically designed for evaluating auditory knowledge in text-only settings, making it a novel concept in the field.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.78
      },
      {
        "surface": "auditory imagination reasoning",
        "canonical": "Auditory Imagination Reasoning",
        "aliases": [
          "AIR-CoT"
        ],
        "category": "unique_technical",
        "rationale": "This method introduces a novel approach to integrate auditory information during inference, which is crucial for linking auditory concepts in language models.",
        "novelty_score": 0.8,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      },
      {
        "surface": "Multimodal LLMs",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal Large Language Models"
        ],
        "category": "specific_connectable",
        "rationale": "Multimodal LLMs are increasingly relevant for integrating auditory and textual data, providing strong connectivity with existing multimodal research.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.8,
        "link_intent_score": 0.79
      },
      {
        "surface": "auditory commonsense",
        "canonical": "Auditory Commonsense",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Auditory commonsense is a specific concept that highlights the intuitive understanding of auditory properties, which is underexplored in language models.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.82,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "auditory properties",
      "auditory knowledge",
      "benchmark"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "AuditoryBench++",
      "resolved_canonical": "AuditoryBench++",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "auditory imagination reasoning",
      "resolved_canonical": "Auditory Imagination Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Multimodal LLMs",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.8,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "auditory commonsense",
      "resolved_canonical": "Auditory Commonsense",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.82,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# AuditoryBench++: Can Language Models Understand Auditory Knowledge without Hearing?

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17641.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.17641](https://arxiv.org/abs/2509.17641)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Benchmarking Contextual and Paralinguistic Reasoning in Speech-LLMs_ A Case Study with In-the-Wild Data_20250923|Benchmarking Contextual and Paralinguistic Reasoning in Speech-LLMs: A Case Study with In-the-Wild Data]] (86.4% similar)
- [[2025-09-22/SightSound-R1_ Cross-Modal Reasoning Distillation from Vision to Audio Language Models_20250922|SightSound-R1: Cross-Modal Reasoning Distillation from Vision to Audio Language Models]] (84.5% similar)
- [[2025-09-22/Can Large Language Models Infer Causal Relationships from Real-World Text?_20250922|Can Large Language Models Infer Causal Relationships from Real-World Text?]] (84.3% similar)
- [[2025-09-22/Benchmark of stylistic variation in LLM-generated texts_20250922|Benchmark of stylistic variation in LLM-generated texts]] (84.1% similar)
- [[2025-09-23/EngiBench_ A Benchmark for Evaluating Large Language Models on Engineering Problem Solving_20250923|EngiBench: A Benchmark for Evaluating Large Language Models on Engineering Problem Solving]] (84.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**âš¡ Unique Technical**: [[keywords/AuditoryBench++|AuditoryBench++]], [[keywords/Auditory Imagination Reasoning|Auditory Imagination Reasoning]], [[keywords/Auditory Commonsense|Auditory Commonsense]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17641v1 Announce Type: cross 
Abstract: Even without directly hearing sounds, humans can effortlessly reason about auditory properties, such as pitch, loudness, or sound-source associations, drawing on auditory commonsense. In contrast, language models often lack this capability, limiting their effectiveness in multimodal interactions. As an initial step to address this gap, we present AuditoryBench++, a comprehensive benchmark for evaluating auditory knowledge and reasoning in text-only settings. The benchmark encompasses tasks that range from basic auditory comparisons to contextually grounded reasoning, enabling fine-grained analysis of how models process and integrate auditory concepts. In addition, we introduce AIR-CoT, a novel auditory imagination reasoning method that generates and integrates auditory information during inference through span detection with special tokens and knowledge injection. Extensive experiments with recent LLMs and Multimodal LLMs demonstrate that AIR-CoT generally outperforms both the off-the-shelf models and those augmented with auditory knowledge. The project page is available at https://auditorybenchpp.github.io.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì¸ê°„ì´ ì†Œë¦¬ ì—†ì´ë„ ì²­ê°ì  íŠ¹ì„±ì„ ì¶”ë¡ í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ì–¸ì–´ ëª¨ë¸ì´ ê°–ì¶”ì§€ ëª»í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ AuditoryBench++ë¼ëŠ” ë²¤ì¹˜ë§ˆí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ë²¤ì¹˜ë§ˆí¬ëŠ” í…ìŠ¤íŠ¸ ê¸°ë°˜ í™˜ê²½ì—ì„œ ì²­ê° ì§€ì‹ê³¼ ì¶”ë¡  ëŠ¥ë ¥ì„ í‰ê°€í•˜ë©°, ê¸°ë³¸ì ì¸ ì²­ê° ë¹„êµë¶€í„° ë§¥ë½ì— ê¸°ë°˜í•œ ì¶”ë¡ ê¹Œì§€ ë‹¤ì–‘í•œ ê³¼ì œë¥¼ í¬í•¨í•©ë‹ˆë‹¤. ë˜í•œ, AIR-CoTë¼ëŠ” ìƒˆë¡œìš´ ì²­ê° ìƒìƒ ì¶”ë¡  ë°©ë²•ì„ ë„ì…í•˜ì—¬ íŠ¹ìˆ˜ í† í°ê³¼ ì§€ì‹ ì£¼ì…ì„ í†µí•´ ì¶”ë¡  ì‹œ ì²­ê° ì •ë³´ë¥¼ ìƒì„±í•˜ê³  í†µí•©í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, AIR-CoTëŠ” ê¸°ì¡´ ëª¨ë¸ê³¼ ì²­ê° ì§€ì‹ì´ ë³´ê°•ëœ ëª¨ë¸ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì¸ê°„ì€ ì§ì ‘ ì†Œë¦¬ë¥¼ ë“£ì§€ ì•Šê³ ë„ ì²­ê°ì  ìƒì‹ì„ í†µí•´ ìŒë†’ì´, ìŒëŸ‰, ì†Œë¦¬ì˜ ì¶œì²˜ ë“±ì„ ì¶”ë¡ í•  ìˆ˜ ìˆì§€ë§Œ, ì–¸ì–´ ëª¨ë¸ì€ ì´ëŸ¬í•œ ëŠ¥ë ¥ì´ ë¶€ì¡±í•˜ë‹¤.
- 2. AuditoryBench++ëŠ” í…ìŠ¤íŠ¸ ê¸°ë°˜ í™˜ê²½ì—ì„œ ì²­ê°ì  ì§€ì‹ê³¼ ì¶”ë¡ ì„ í‰ê°€í•˜ê¸° ìœ„í•œ í¬ê´„ì ì¸ ë²¤ì¹˜ë§ˆí¬ë¡œ, ê¸°ë³¸ì ì¸ ì²­ê° ë¹„êµë¶€í„° ë§¥ë½ì  ì¶”ë¡ ê¹Œì§€ ë‹¤ì–‘í•œ ê³¼ì œë¥¼ í¬í•¨í•œë‹¤.
- 3. AIR-CoTëŠ” ì¶”ë¡  ì¤‘ì— íŠ¹ë³„í•œ í† í°ê³¼ ì§€ì‹ ì£¼ì…ì„ í†µí•´ ì²­ê° ì •ë³´ë¥¼ ìƒì„±í•˜ê³  í†µí•©í•˜ëŠ” ìƒˆë¡œìš´ ì²­ê° ìƒìƒ ì¶”ë¡  ë°©ë²•ì´ë‹¤.
- 4. ìµœì‹  ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM) ë° ë‹¤ì¤‘ ëª¨ë‹¬ LLMì„ ì‚¬ìš©í•œ ì‹¤í—˜ ê²°ê³¼, AIR-CoTê°€ ê¸°ë³¸ ëª¨ë¸ê³¼ ì²­ê° ì§€ì‹ì´ ì¶”ê°€ëœ ëª¨ë¸ë³´ë‹¤ ì¼ë°˜ì ìœ¼ë¡œ ë” ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤.


---

*Generated on 2025-09-24 00:04:12*