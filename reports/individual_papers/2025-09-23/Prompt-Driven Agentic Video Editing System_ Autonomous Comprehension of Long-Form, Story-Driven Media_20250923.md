---
keywords:
  - Semantic Indexing
  - Prompt-Driven Editing
  - Multimodal Learning
  - Cross-Granularity Fusion
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.16811
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T22:52:08.850892",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Semantic Indexing",
    "Prompt-Driven Editing",
    "Multimodal Learning",
    "Cross-Granularity Fusion"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Semantic Indexing": 0.78,
    "Prompt-Driven Editing": 0.79,
    "Multimodal Learning": 0.82,
    "Cross-Granularity Fusion": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "semantic indexing pipeline",
        "canonical": "Semantic Indexing",
        "aliases": [
          "indexing pipeline",
          "semantic pipeline"
        ],
        "category": "unique_technical",
        "rationale": "Semantic indexing is a novel approach in the context of video editing, providing a new method for narrative comprehension.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.82,
        "link_intent_score": 0.78
      },
      {
        "surface": "prompt-driven editing",
        "canonical": "Prompt-Driven Editing",
        "aliases": [
          "prompt-based editing",
          "prompt editing"
        ],
        "category": "unique_technical",
        "rationale": "This concept introduces a new paradigm in video editing that leverages prompts for content restructuring.",
        "novelty_score": 0.8,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.79
      },
      {
        "surface": "multimodal editing",
        "canonical": "Multimodal Learning",
        "aliases": [
          "multimodal video editing"
        ],
        "category": "specific_connectable",
        "rationale": "Multimodal learning is crucial for understanding and editing video content that involves various data types.",
        "novelty_score": 0.65,
        "connectivity_score": 0.88,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "cross-granularity fusion",
        "canonical": "Cross-Granularity Fusion",
        "aliases": [
          "granularity fusion",
          "cross-level fusion"
        ],
        "category": "unique_technical",
        "rationale": "This technique enhances narrative coherence by integrating information across different levels of detail.",
        "novelty_score": 0.7,
        "connectivity_score": 0.72,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "semantic indexing pipeline",
      "resolved_canonical": "Semantic Indexing",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.82,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "prompt-driven editing",
      "resolved_canonical": "Prompt-Driven Editing",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "multimodal editing",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.88,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "cross-granularity fusion",
      "resolved_canonical": "Cross-Granularity Fusion",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.72,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Prompt-Driven Agentic Video Editing System: Autonomous Comprehension of Long-Form, Story-Driven Media

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16811.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.16811](https://arxiv.org/abs/2509.16811)

## 🔗 유사한 논문
- [[2025-09-18/Vistoria_ A Multimodal System to Support Fictional Story Writing through Instrumental Text-Image Co-Editing_20250918|Vistoria: A Multimodal System to Support Fictional Story Writing through Instrumental Text-Image Co-Editing]] (82.0% similar)
- [[2025-09-18/EdiVal-Agent_ An Object-Centric Framework for Automated, Scalable, Fine-Grained Evaluation of Multi-Turn Editing_20250918|EdiVal-Agent: An Object-Centric Framework for Automated, Scalable, Fine-Grained Evaluation of Multi-Turn Editing]] (81.0% similar)
- [[2025-09-22/ChronoForge-RL_ Chronological Forging through Reinforcement Learning for Enhanced Video Understanding_20250922|ChronoForge-RL: Chronological Forging through Reinforcement Learning for Enhanced Video Understanding]] (80.3% similar)
- [[2025-09-18/Identity-Preserving Text-to-Video Generation Guided by Simple yet Effective Spatial-Temporal Decoupled Representations_20250918|Identity-Preserving Text-to-Video Generation Guided by Simple yet Effective Spatial-Temporal Decoupled Representations]] (79.6% similar)
- [[2025-09-19/WorldForge_ Unlocking Emergent 3D/4D Generation in Video Diffusion Model via Training-Free Guidance_20250919|WorldForge: Unlocking Emergent 3D/4D Generation in Video Diffusion Model via Training-Free Guidance]] (79.4% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**⚡ Unique Technical**: [[keywords/Semantic Indexing|Semantic Indexing]], [[keywords/Prompt-Driven Editing|Prompt-Driven Editing]], [[keywords/Cross-Granularity Fusion|Cross-Granularity Fusion]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.16811v1 Announce Type: new 
Abstract: Creators struggle to edit long-form, narrative-rich videos not because of UI complexity, but due to the cognitive demands of searching, storyboarding, and sequencing hours of footage. Existing transcript- or embedding-based methods fall short for creative workflows, as models struggle to track characters, infer motivations, and connect dispersed events. We present a prompt-driven, modular editing system that helps creators restructure multi-hour content through free-form prompts rather than timelines. At its core is a semantic indexing pipeline that builds a global narrative via temporal segmentation, guided memory compression, and cross-granularity fusion, producing interpretable traces of plot, dialogue, emotion, and context. Users receive cinematic edits while optionally refining transparent intermediate outputs. Evaluated on 400+ videos with expert ratings, QA, and preference studies, our system scales prompt-driven editing, preserves narrative coherence, and balances automation with creator control.

## 📝 요약

이 논문은 창작자들이 긴 형식의 내러티브 비디오를 편집할 때 겪는 인지적 부담을 해결하기 위해 제안된 새로운 편집 시스템을 소개합니다. 기존의 전사 또는 임베딩 기반 방법은 캐릭터 추적, 동기 추론, 분산된 사건 연결에 한계가 있습니다. 제안된 시스템은 자유로운 형태의 프롬프트를 통해 다시간 콘텐츠를 재구성할 수 있도록 돕습니다. 핵심은 시간적 세분화, 메모리 압축, 다중 세분화 융합을 통한 전반적인 내러티브 구축을 위한 의미론적 인덱싱 파이프라인입니다. 이 시스템은 플롯, 대화, 감정, 맥락의 해석 가능한 흔적을 생성하여 사용자에게 영화적인 편집을 제공합니다. 400개 이상의 비디오를 대상으로 한 전문가 평가 및 선호도 연구에서 이 시스템은 프롬프트 기반 편집의 확장성, 내러티브 일관성 유지, 자동화와 창작자 통제의 균형을 입증했습니다.

## 🎯 주요 포인트

- 1. 창작자들은 UI 복잡성보다는 장시간의 영상에서 필요한 장면을 찾고, 스토리보드를 구성하며, 시퀀스를 조정하는 인지적 부담 때문에 긴 내러티브 영상 편집에 어려움을 겪습니다.
- 2. 기존의 텍스트 전사나 임베딩 기반 방법은 캐릭터 추적, 동기 추론, 분산된 사건 연결에 어려움을 겪어 창의적 워크플로우에 적합하지 않습니다.
- 3. 제안된 시스템은 자유로운 프롬프트를 통해 다시간 콘텐츠를 재구성할 수 있는 모듈식 편집 시스템으로, 시간적 세분화, 메모리 압축, 다중 세분화 융합을 통해 글로벌 내러티브를 구축합니다.
- 4. 사용자는 투명한 중간 결과를 선택적으로 수정하면서 시네마틱 편집을 받을 수 있으며, 시스템은 프롬프트 기반 편집을 확장하고 내러티브 일관성을 유지하며 자동화와 창작자 통제 간의 균형을 맞춥니다.
- 5. 400개 이상의 비디오에 대한 전문가 평가, QA, 선호도 연구를 통해 시스템의 효과가 검증되었습니다.


---

*Generated on 2025-09-23 22:52:08*