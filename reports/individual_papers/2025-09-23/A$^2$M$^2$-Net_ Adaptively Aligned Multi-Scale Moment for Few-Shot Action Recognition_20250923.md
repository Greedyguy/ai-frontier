---
keywords:
  - Few-Shot Learning
  - Temporal Misalignment
  - Multi-Scale Moment
  - Adaptive Alignment
  - Video Dynamics
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.17638
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T00:03:53.542398",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Few-Shot Learning",
    "Temporal Misalignment",
    "Multi-Scale Moment",
    "Adaptive Alignment",
    "Video Dynamics"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Few-Shot Learning": 0.85,
    "Temporal Misalignment": 0.72,
    "Multi-Scale Moment": 0.7,
    "Adaptive Alignment": 0.75,
    "Video Dynamics": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Few-Shot Action Recognition",
        "canonical": "Few-Shot Learning",
        "aliases": [
          "FSAR"
        ],
        "category": "specific_connectable",
        "rationale": "Connects to the broader concept of Few-Shot Learning, which is a trending topic and relevant to the paper's focus.",
        "novelty_score": 0.55,
        "connectivity_score": 0.89,
        "specificity_score": 0.78,
        "link_intent_score": 0.85
      },
      {
        "surface": "Temporal Misalignment",
        "canonical": "Temporal Misalignment",
        "aliases": [
          "Time Misalignment"
        ],
        "category": "unique_technical",
        "rationale": "Addresses a specific challenge in video dynamics, which is crucial for understanding the paper's contribution.",
        "novelty_score": 0.68,
        "connectivity_score": 0.65,
        "specificity_score": 0.82,
        "link_intent_score": 0.72
      },
      {
        "surface": "Multi-Scale Moment",
        "canonical": "Multi-Scale Moment",
        "aliases": [
          "M^2"
        ],
        "category": "unique_technical",
        "rationale": "Represents a novel approach in the paper, highlighting its distinct methodology.",
        "novelty_score": 0.71,
        "connectivity_score": 0.6,
        "specificity_score": 0.79,
        "link_intent_score": 0.7
      },
      {
        "surface": "Adaptive Alignment",
        "canonical": "Adaptive Alignment",
        "aliases": [
          "A^2"
        ],
        "category": "unique_technical",
        "rationale": "Key component of the proposed method, crucial for understanding the adaptive nature of the model.",
        "novelty_score": 0.65,
        "connectivity_score": 0.67,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      },
      {
        "surface": "Video Dynamics",
        "canonical": "Video Dynamics",
        "aliases": [
          "Video Motion"
        ],
        "category": "specific_connectable",
        "rationale": "Essential for linking to research focused on video analysis and dynamics.",
        "novelty_score": 0.5,
        "connectivity_score": 0.78,
        "specificity_score": 0.7,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Few-Shot Action Recognition",
      "resolved_canonical": "Few-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.89,
        "specificity": 0.78,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Temporal Misalignment",
      "resolved_canonical": "Temporal Misalignment",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.65,
        "specificity": 0.82,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "Multi-Scale Moment",
      "resolved_canonical": "Multi-Scale Moment",
      "decision": "linked",
      "scores": {
        "novelty": 0.71,
        "connectivity": 0.6,
        "specificity": 0.79,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Adaptive Alignment",
      "resolved_canonical": "Adaptive Alignment",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.67,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Video Dynamics",
      "resolved_canonical": "Video Dynamics",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.78,
        "specificity": 0.7,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# A$^2$M$^2$-Net: Adaptively Aligned Multi-Scale Moment for Few-Shot Action Recognition

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17638.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.17638](https://arxiv.org/abs/2509.17638)

## 🔗 유사한 논문
- [[2025-09-18/LSTC-MDA_ A Unified Framework for Long-Short Term Temporal Convolution and Mixed Data Augmentation in Skeleton-Based Action Recognition_20250918|LSTC-MDA: A Unified Framework for Long-Short Term Temporal Convolution and Mixed Data Augmentation in Skeleton-Based Action Recognition]] (81.1% similar)
- [[2025-09-18/VSE-MOT_ Multi-Object Tracking in Low-Quality Video Scenes Guided by Visual Semantic Enhancement_20250918|VSE-MOT: Multi-Object Tracking in Low-Quality Video Scenes Guided by Visual Semantic Enhancement]] (80.7% similar)
- [[2025-09-22/Cross-Resolution SAR Target Detection Using Structural Hierarchy Adaptation and Reliable Adjacency Alignment_20250922|Cross-Resolution SAR Target Detection Using Structural Hierarchy Adaptation and Reliable Adjacency Alignment]] (80.0% similar)
- [[2025-09-22/(SP)$^2$-Net_ A Neural Spatial Spectrum Method for DOA Estimation_20250922|(SP)$^2$-Net: A Neural Spatial Spectrum Method for DOA Estimation]] (79.7% similar)
- [[2025-09-22/SAMPO_Scale-wise Autoregression with Motion PrOmpt for generative world models_20250922|SAMPO:Scale-wise Autoregression with Motion PrOmpt for generative world models]] (79.4% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Few-Shot Learning|Few-Shot Learning]], [[keywords/Video Dynamics|Video Dynamics]]
**⚡ Unique Technical**: [[keywords/Temporal Misalignment|Temporal Misalignment]], [[keywords/Multi-Scale Moment|Multi-Scale Moment]], [[keywords/Adaptive Alignment|Adaptive Alignment]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.17638v1 Announce Type: cross 
Abstract: Thanks to capability to alleviate the cost of large-scale annotation, few-shot action recognition (FSAR) has attracted increased attention of researchers in recent years. Existing FSAR approaches typically neglect the role of individual motion pattern in comparison, and under-explore the feature statistics for video dynamics. Thereby, they struggle to handle the challenging temporal misalignment in video dynamics, particularly by using 2D backbones. To overcome these limitations, this work proposes an adaptively aligned multi-scale second-order moment network, namely A$^2$M$^2$-Net, to describe the latent video dynamics with a collection of powerful representation candidates and adaptively align them in an instance-guided manner. To this end, our A$^2$M$^2$-Net involves two core components, namely, adaptive alignment (A$^2$ module) for matching, and multi-scale second-order moment (M$^2$ block) for strong representation. Specifically, M$^2$ block develops a collection of semantic second-order descriptors at multiple spatio-temporal scales. Furthermore, A$^2$ module aims to adaptively select informative candidate descriptors while considering the individual motion pattern. By such means, our A$^2$M$^2$-Net is able to handle the challenging temporal misalignment problem by establishing an adaptive alignment protocol for strong representation. Notably, our proposed method generalizes well to various few-shot settings and diverse metrics. The experiments are conducted on five widely used FSAR benchmarks, and the results show our A$^2$M$^2$-Net achieves very competitive performance compared to state-of-the-arts, demonstrating its effectiveness and generalization.

## 📝 요약

이 논문은 소수 샷 행동 인식(FSAR)의 한계를 극복하기 위해 A$^2$M$^2$-Net이라는 네트워크를 제안합니다. 기존 FSAR 방법론이 개별 움직임 패턴과 비디오 동역학의 특징 통계를 충분히 활용하지 못하는 문제를 해결하고자, 이 네트워크는 적응적으로 정렬된 다중 스케일의 2차 모멘트 네트워크를 사용합니다. A$^2$M$^2$-Net은 적응적 정렬(A$^2$ 모듈)과 강력한 표현을 위한 다중 스케일 2차 모멘트(M$^2$ 블록)로 구성됩니다. 실험 결과, 이 네트워크는 다양한 FSAR 벤치마크에서 경쟁력 있는 성능을 보이며, 뛰어난 일반화 능력을 입증했습니다.

## 🎯 주요 포인트

- 1. 소수 샷 행동 인식(FSAR)의 비용 절감 능력 덕분에 최근 연구자들의 관심이 증가하고 있습니다.
- 2. 기존 FSAR 접근법은 개별 동작 패턴의 비교 역할을 간과하고, 비디오 동적 특성을 충분히 탐구하지 못합니다.
- 3. A$^2$M$^2$-Net은 적응적으로 정렬된 다중 스케일 이차 모멘트 네트워크로, 강력한 표현 후보를 수집하고 인스턴스 기반으로 정렬하여 잠재적인 비디오 동적 특성을 설명합니다.
- 4. A$^2$M$^2$-Net은 적응형 정렬(A$^2$ 모듈)과 다중 스케일 이차 모멘트(M$^2$ 블록)라는 두 가지 핵심 구성 요소를 포함합니다.
- 5. 실험 결과, A$^2$M$^2$-Net은 다섯 개의 널리 사용되는 FSAR 벤치마크에서 매우 경쟁력 있는 성능을 보여주며, 다양한 소수 샷 설정과 메트릭에 잘 일반화됩니다.


---

*Generated on 2025-09-24 00:03:53*