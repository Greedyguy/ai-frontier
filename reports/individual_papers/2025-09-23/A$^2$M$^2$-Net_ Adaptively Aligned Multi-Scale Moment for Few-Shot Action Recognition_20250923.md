---
keywords:
  - Few-Shot Learning
  - Temporal Misalignment
  - Multi-Scale Moment
  - Adaptive Alignment
  - Video Dynamics
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.17638
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T00:03:53.542398",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Few-Shot Learning",
    "Temporal Misalignment",
    "Multi-Scale Moment",
    "Adaptive Alignment",
    "Video Dynamics"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Few-Shot Learning": 0.85,
    "Temporal Misalignment": 0.72,
    "Multi-Scale Moment": 0.7,
    "Adaptive Alignment": 0.75,
    "Video Dynamics": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Few-Shot Action Recognition",
        "canonical": "Few-Shot Learning",
        "aliases": [
          "FSAR"
        ],
        "category": "specific_connectable",
        "rationale": "Connects to the broader concept of Few-Shot Learning, which is a trending topic and relevant to the paper's focus.",
        "novelty_score": 0.55,
        "connectivity_score": 0.89,
        "specificity_score": 0.78,
        "link_intent_score": 0.85
      },
      {
        "surface": "Temporal Misalignment",
        "canonical": "Temporal Misalignment",
        "aliases": [
          "Time Misalignment"
        ],
        "category": "unique_technical",
        "rationale": "Addresses a specific challenge in video dynamics, which is crucial for understanding the paper's contribution.",
        "novelty_score": 0.68,
        "connectivity_score": 0.65,
        "specificity_score": 0.82,
        "link_intent_score": 0.72
      },
      {
        "surface": "Multi-Scale Moment",
        "canonical": "Multi-Scale Moment",
        "aliases": [
          "M^2"
        ],
        "category": "unique_technical",
        "rationale": "Represents a novel approach in the paper, highlighting its distinct methodology.",
        "novelty_score": 0.71,
        "connectivity_score": 0.6,
        "specificity_score": 0.79,
        "link_intent_score": 0.7
      },
      {
        "surface": "Adaptive Alignment",
        "canonical": "Adaptive Alignment",
        "aliases": [
          "A^2"
        ],
        "category": "unique_technical",
        "rationale": "Key component of the proposed method, crucial for understanding the adaptive nature of the model.",
        "novelty_score": 0.65,
        "connectivity_score": 0.67,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      },
      {
        "surface": "Video Dynamics",
        "canonical": "Video Dynamics",
        "aliases": [
          "Video Motion"
        ],
        "category": "specific_connectable",
        "rationale": "Essential for linking to research focused on video analysis and dynamics.",
        "novelty_score": 0.5,
        "connectivity_score": 0.78,
        "specificity_score": 0.7,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Few-Shot Action Recognition",
      "resolved_canonical": "Few-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.89,
        "specificity": 0.78,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Temporal Misalignment",
      "resolved_canonical": "Temporal Misalignment",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.65,
        "specificity": 0.82,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "Multi-Scale Moment",
      "resolved_canonical": "Multi-Scale Moment",
      "decision": "linked",
      "scores": {
        "novelty": 0.71,
        "connectivity": 0.6,
        "specificity": 0.79,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Adaptive Alignment",
      "resolved_canonical": "Adaptive Alignment",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.67,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Video Dynamics",
      "resolved_canonical": "Video Dynamics",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.78,
        "specificity": 0.7,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# A$^2$M$^2$-Net: Adaptively Aligned Multi-Scale Moment for Few-Shot Action Recognition

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17638.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.17638](https://arxiv.org/abs/2509.17638)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/LSTC-MDA_ A Unified Framework for Long-Short Term Temporal Convolution and Mixed Data Augmentation in Skeleton-Based Action Recognition_20250918|LSTC-MDA: A Unified Framework for Long-Short Term Temporal Convolution and Mixed Data Augmentation in Skeleton-Based Action Recognition]] (81.1% similar)
- [[2025-09-18/VSE-MOT_ Multi-Object Tracking in Low-Quality Video Scenes Guided by Visual Semantic Enhancement_20250918|VSE-MOT: Multi-Object Tracking in Low-Quality Video Scenes Guided by Visual Semantic Enhancement]] (80.7% similar)
- [[2025-09-22/Cross-Resolution SAR Target Detection Using Structural Hierarchy Adaptation and Reliable Adjacency Alignment_20250922|Cross-Resolution SAR Target Detection Using Structural Hierarchy Adaptation and Reliable Adjacency Alignment]] (80.0% similar)
- [[2025-09-22/(SP)$^2$-Net_ A Neural Spatial Spectrum Method for DOA Estimation_20250922|(SP)$^2$-Net: A Neural Spatial Spectrum Method for DOA Estimation]] (79.7% similar)
- [[2025-09-22/SAMPO_Scale-wise Autoregression with Motion PrOmpt for generative world models_20250922|SAMPO:Scale-wise Autoregression with Motion PrOmpt for generative world models]] (79.4% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Few-Shot Learning|Few-Shot Learning]], [[keywords/Video Dynamics|Video Dynamics]]
**âš¡ Unique Technical**: [[keywords/Temporal Misalignment|Temporal Misalignment]], [[keywords/Multi-Scale Moment|Multi-Scale Moment]], [[keywords/Adaptive Alignment|Adaptive Alignment]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17638v1 Announce Type: cross 
Abstract: Thanks to capability to alleviate the cost of large-scale annotation, few-shot action recognition (FSAR) has attracted increased attention of researchers in recent years. Existing FSAR approaches typically neglect the role of individual motion pattern in comparison, and under-explore the feature statistics for video dynamics. Thereby, they struggle to handle the challenging temporal misalignment in video dynamics, particularly by using 2D backbones. To overcome these limitations, this work proposes an adaptively aligned multi-scale second-order moment network, namely A$^2$M$^2$-Net, to describe the latent video dynamics with a collection of powerful representation candidates and adaptively align them in an instance-guided manner. To this end, our A$^2$M$^2$-Net involves two core components, namely, adaptive alignment (A$^2$ module) for matching, and multi-scale second-order moment (M$^2$ block) for strong representation. Specifically, M$^2$ block develops a collection of semantic second-order descriptors at multiple spatio-temporal scales. Furthermore, A$^2$ module aims to adaptively select informative candidate descriptors while considering the individual motion pattern. By such means, our A$^2$M$^2$-Net is able to handle the challenging temporal misalignment problem by establishing an adaptive alignment protocol for strong representation. Notably, our proposed method generalizes well to various few-shot settings and diverse metrics. The experiments are conducted on five widely used FSAR benchmarks, and the results show our A$^2$M$^2$-Net achieves very competitive performance compared to state-of-the-arts, demonstrating its effectiveness and generalization.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì†Œìˆ˜ ìƒ· í–‰ë™ ì¸ì‹(FSAR)ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ A$^2$M$^2$-Netì´ë¼ëŠ” ë„¤íŠ¸ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ FSAR ë°©ë²•ë¡ ì´ ê°œë³„ ì›€ì§ì„ íŒ¨í„´ê³¼ ë¹„ë””ì˜¤ ë™ì—­í•™ì˜ íŠ¹ì§• í†µê³„ë¥¼ ì¶©ë¶„íˆ í™œìš©í•˜ì§€ ëª»í•˜ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê³ ì, ì´ ë„¤íŠ¸ì›Œí¬ëŠ” ì ì‘ì ìœ¼ë¡œ ì •ë ¬ëœ ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ì˜ 2ì°¨ ëª¨ë©˜íŠ¸ ë„¤íŠ¸ì›Œí¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. A$^2$M$^2$-Netì€ ì ì‘ì  ì •ë ¬(A$^2$ ëª¨ë“ˆ)ê³¼ ê°•ë ¥í•œ í‘œí˜„ì„ ìœ„í•œ ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ 2ì°¨ ëª¨ë©˜íŠ¸(M$^2$ ë¸”ë¡)ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì´ ë„¤íŠ¸ì›Œí¬ëŠ” ë‹¤ì–‘í•œ FSAR ë²¤ì¹˜ë§ˆí¬ì—ì„œ ê²½ìŸë ¥ ìˆëŠ” ì„±ëŠ¥ì„ ë³´ì´ë©°, ë›°ì–´ë‚œ ì¼ë°˜í™” ëŠ¥ë ¥ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì†Œìˆ˜ ìƒ· í–‰ë™ ì¸ì‹(FSAR)ì˜ ë¹„ìš© ì ˆê° ëŠ¥ë ¥ ë•ë¶„ì— ìµœê·¼ ì—°êµ¬ìë“¤ì˜ ê´€ì‹¬ì´ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤.
- 2. ê¸°ì¡´ FSAR ì ‘ê·¼ë²•ì€ ê°œë³„ ë™ì‘ íŒ¨í„´ì˜ ë¹„êµ ì—­í• ì„ ê°„ê³¼í•˜ê³ , ë¹„ë””ì˜¤ ë™ì  íŠ¹ì„±ì„ ì¶©ë¶„íˆ íƒêµ¬í•˜ì§€ ëª»í•©ë‹ˆë‹¤.
- 3. A$^2$M$^2$-Netì€ ì ì‘ì ìœ¼ë¡œ ì •ë ¬ëœ ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ì´ì°¨ ëª¨ë©˜íŠ¸ ë„¤íŠ¸ì›Œí¬ë¡œ, ê°•ë ¥í•œ í‘œí˜„ í›„ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³  ì¸ìŠ¤í„´ìŠ¤ ê¸°ë°˜ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ì ì¬ì ì¸ ë¹„ë””ì˜¤ ë™ì  íŠ¹ì„±ì„ ì„¤ëª…í•©ë‹ˆë‹¤.
- 4. A$^2$M$^2$-Netì€ ì ì‘í˜• ì •ë ¬(A$^2$ ëª¨ë“ˆ)ê³¼ ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ì´ì°¨ ëª¨ë©˜íŠ¸(M$^2$ ë¸”ë¡)ë¼ëŠ” ë‘ ê°€ì§€ í•µì‹¬ êµ¬ì„± ìš”ì†Œë¥¼ í¬í•¨í•©ë‹ˆë‹¤.
- 5. ì‹¤í—˜ ê²°ê³¼, A$^2$M$^2$-Netì€ ë‹¤ì„¯ ê°œì˜ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” FSAR ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë§¤ìš° ê²½ìŸë ¥ ìˆëŠ” ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ë©°, ë‹¤ì–‘í•œ ì†Œìˆ˜ ìƒ· ì„¤ì •ê³¼ ë©”íŠ¸ë¦­ì— ì˜ ì¼ë°˜í™”ë©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 00:03:53*