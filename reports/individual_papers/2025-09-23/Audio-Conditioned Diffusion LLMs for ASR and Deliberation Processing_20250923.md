---
keywords:
  - Diffusion-based Large Language Models
  - Automatic Speech Recognition
  - Whisper-LLaMA
  - Audio-conditioned Embeddings
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.16622
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T23:29:07.589726",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Diffusion-based Large Language Models",
    "Automatic Speech Recognition",
    "Whisper-LLaMA",
    "Audio-conditioned Embeddings"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Diffusion-based Large Language Models": 0.78,
    "Automatic Speech Recognition": 0.82,
    "Whisper-LLaMA": 0.7,
    "Audio-conditioned Embeddings": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Diffusion-based Large Language Models",
        "canonical": "Diffusion-based Large Language Models",
        "aliases": [
          "DLLMs",
          "Diffusion LLMs"
        ],
        "category": "unique_technical",
        "rationale": "This represents a novel approach in language models, distinct from autoregressive models, and is central to the paper's contributions.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.88,
        "link_intent_score": 0.78
      },
      {
        "surface": "Automatic Speech Recognition",
        "canonical": "Automatic Speech Recognition",
        "aliases": [
          "ASR"
        ],
        "category": "broad_technical",
        "rationale": "ASR is a fundamental application area for language models, providing a key context for linking related research.",
        "novelty_score": 0.45,
        "connectivity_score": 0.92,
        "specificity_score": 0.7,
        "link_intent_score": 0.82
      },
      {
        "surface": "Whisper-LLaMA",
        "canonical": "Whisper-LLaMA",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This specific model is a focal point of the study, making it crucial for understanding the paper's experimental setup.",
        "novelty_score": 0.75,
        "connectivity_score": 0.55,
        "specificity_score": 0.85,
        "link_intent_score": 0.7
      },
      {
        "surface": "Audio-conditioned Embeddings",
        "canonical": "Audio-conditioned Embeddings",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "These embeddings are critical for improving ASR accuracy, highlighting the importance of multimodal approaches.",
        "novelty_score": 0.68,
        "connectivity_score": 0.78,
        "specificity_score": 0.82,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "empirical study",
      "baseline",
      "accuracy"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Diffusion-based Large Language Models",
      "resolved_canonical": "Diffusion-based Large Language Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.88,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Automatic Speech Recognition",
      "resolved_canonical": "Automatic Speech Recognition",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.92,
        "specificity": 0.7,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Whisper-LLaMA",
      "resolved_canonical": "Whisper-LLaMA",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.55,
        "specificity": 0.85,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Audio-conditioned Embeddings",
      "resolved_canonical": "Audio-conditioned Embeddings",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.78,
        "specificity": 0.82,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Audio-Conditioned Diffusion LLMs for ASR and Deliberation Processing

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16622.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.16622](https://arxiv.org/abs/2509.16622)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Discrete Diffusion in Large Language and Multimodal Models_ A Survey_20250922|Discrete Diffusion in Large Language and Multimodal Models: A Survey]] (85.2% similar)
- [[2025-09-22/Exploring Fine-Tuning of Large Audio Language Models for Spoken Language Understanding under Limited Speech data_20250922|Exploring Fine-Tuning of Large Audio Language Models for Spoken Language Understanding under Limited Speech data]] (82.7% similar)
- [[2025-09-19/DetectAnyLLM_ Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models_20250919|DetectAnyLLM: Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models]] (82.3% similar)
- [[2025-09-22/LESS_ Large Language Model Enhanced Semi-Supervised Learning for Speech Foundational Models Using in-the-wild Data_20250922|LESS: Large Language Model Enhanced Semi-Supervised Learning for Speech Foundational Models Using in-the-wild Data]] (82.2% similar)
- [[2025-09-22/It Depends_ Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge_20250922|It Depends: Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge]] (82.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Automatic Speech Recognition|Automatic Speech Recognition]]
**ğŸ”— Specific Connectable**: [[keywords/Audio-conditioned Embeddings|Audio-conditioned Embeddings]]
**âš¡ Unique Technical**: [[keywords/Diffusion-based Large Language Models|Diffusion-based Large Language Models]], [[keywords/Whisper-LLaMA|Whisper-LLaMA]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16622v1 Announce Type: cross 
Abstract: Diffusion-based large language models (DLLMs) have recently attracted growing interest as an alternative to autoregressive decoders. In this work, we present an empirical study on using the diffusion-based large language model LLaDA for automatic speech recognition (ASR). We first investigate its use as an external deliberation-based processing module for Whisper-LLaMA transcripts. By leveraging the bidirectional attention and denoising capabilities of LLaDA, we explore random masking, low-confidence masking, and semi-autoregressive strategies, showing that Whisper-LLaDA substantially reduces WER compared with the baseline. On LibriSpeech, the best cascade system achieves 2.25%/4.94% WER on test-clean/test-other, representing a 12.3% relative improvement over the Whisper-LLaMA baseline on the test-other split. In contrast, a plain-text LLaDA without acoustic features fails to improve accuracy, highlighting the importance of audio-conditioned embeddings. We further evaluate Whisper-LLaDA as a standalone decoder for ASR with diffusion-based and semi-autoregressive decoding. Most experimental configurations achieve faster inference than the Whisper-LLaMA baseline, although recognition accuracy is slightly lower. These findings offer an empirical view of diffusion-based LLMs for ASR and point to promising directions for improvements.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” í™•ì‚° ê¸°ë°˜ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(DLLM)ì¸ LLaDAë¥¼ ìë™ ìŒì„± ì¸ì‹(ASR)ì— í™œìš©í•œ ì‹¤ì¦ì  ì—°êµ¬ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. LLaDAì˜ ì–‘ë°©í–¥ ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ê³¼ ì¡ìŒ ì œê±° ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ Whisper-LLaMAì˜ ì„±ëŠ¥ì„ ê°œì„ í•˜ê³ ì í–ˆìŠµë‹ˆë‹¤. ëœë¤ ë§ˆìŠ¤í‚¹, ì €ì‹ ë¢°ë„ ë§ˆìŠ¤í‚¹, ë°˜ìê¸°íšŒê·€ ì „ëµì„ í†µí•´ WER(ë‹¨ì–´ ì˜¤ë¥˜ìœ¨)ì„ í¬ê²Œ ì¤„ì˜€ìœ¼ë©°, LibriSpeech ë°ì´í„°ì…‹ì—ì„œ 12.3%ì˜ ìƒëŒ€ì  ê°œì„ ì„ ì´ë£¨ì—ˆìŠµë‹ˆë‹¤. ë˜í•œ, LLaDAë¥¼ ë…ë¦½ì ì¸ ë””ì½”ë”ë¡œ ì‚¬ìš©í–ˆì„ ë•Œ, ì¸ì‹ ì†ë„ëŠ” ë¹¨ë¼ì¡Œì§€ë§Œ ì •í™•ë„ëŠ” ì•½ê°„ ë‚®ì•˜ìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ASRì— ëŒ€í•œ í™•ì‚° ê¸°ë°˜ LLMì˜ ê°€ëŠ¥ì„±ì„ ì œì‹œí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. í™•ì‚° ê¸°ë°˜ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(DLLMs)ì€ ìë™ íšŒê·€ ë””ì½”ë”ì˜ ëŒ€ì•ˆìœ¼ë¡œ ì£¼ëª©ë°›ê³  ìˆë‹¤.
- 2. LLaDA ëª¨ë¸ì„ í™œìš©í•˜ì—¬ Whisper-LLaMA ì„±ëŠ¥ì„ ê°œì„ í•˜ê³  WERì„ í¬ê²Œ ì¤„ì˜€ë‹¤.
- 3. LibriSpeech ë°ì´í„°ì…‹ì—ì„œ Whisper-LLaDAëŠ” test-clean/test-otherì—ì„œ ê°ê° 2.25%/4.94%ì˜ WERì„ ê¸°ë¡í•˜ë©°, test-otherì—ì„œ 12.3%ì˜ ìƒëŒ€ì  ê°œì„ ì„ ë³´ì˜€ë‹¤.
- 4. ì˜¤ë””ì˜¤ ì¡°ê±´ ì„ë² ë”©ì˜ ì¤‘ìš”ì„±ì´ ê°•ì¡°ë˜ë©°, ìŒí–¥ íŠ¹ì§•ì´ ì—†ëŠ” LLaDAëŠ” ì •í™•ë„ í–¥ìƒì— ì‹¤íŒ¨í–ˆë‹¤.
- 5. Whisper-LLaDAëŠ” í™•ì‚° ê¸°ë°˜ ë° ë°˜ìë™ íšŒê·€ ë””ì½”ë”©ì„ í†µí•´ ë…ë¦½ì ì¸ ë””ì½”ë”ë¡œì„œ ë¹ ë¥¸ ì¶”ë¡  ì†ë„ë¥¼ ë³´ì˜€ìœ¼ë‚˜, ì¸ì‹ ì •í™•ë„ëŠ” ì•½ê°„ ë‚®ì•˜ë‹¤.


---

*Generated on 2025-09-23 23:29:07*