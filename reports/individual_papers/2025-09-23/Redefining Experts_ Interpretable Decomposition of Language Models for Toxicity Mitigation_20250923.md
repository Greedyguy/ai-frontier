---
keywords:
  - Large Language Model
  - EigenShift
  - Toxicity Mitigation
  - Neuron Activation
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2509.16660
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:15:56.895735",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "EigenShift",
    "Toxicity Mitigation",
    "Neuron Activation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "EigenShift": 0.78,
    "Toxicity Mitigation": 0.81,
    "Neuron Activation": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's focus on toxicity mitigation, linking to broader discussions on language models.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "EigenShift",
        "canonical": "EigenShift",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Introduces a novel technique specific to the paper, offering unique insights into model intervention.",
        "novelty_score": 0.92,
        "connectivity_score": 0.55,
        "specificity_score": 0.89,
        "link_intent_score": 0.78
      },
      {
        "surface": "Toxicity Mitigation",
        "canonical": "Toxicity Mitigation",
        "aliases": [
          "Toxicity Reduction"
        ],
        "category": "specific_connectable",
        "rationale": "Key theme of the paper, relevant to ongoing research in AI safety.",
        "novelty_score": 0.58,
        "connectivity_score": 0.73,
        "specificity_score": 0.82,
        "link_intent_score": 0.81
      },
      {
        "surface": "Neuron Activations",
        "canonical": "Neuron Activation",
        "aliases": [
          "Neural Activation"
        ],
        "category": "specific_connectable",
        "rationale": "Discusses a technical aspect of model behavior, useful for linking to neural network studies.",
        "novelty_score": 0.6,
        "connectivity_score": 0.7,
        "specificity_score": 0.78,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "EigenShift",
      "resolved_canonical": "EigenShift",
      "decision": "linked",
      "scores": {
        "novelty": 0.92,
        "connectivity": 0.55,
        "specificity": 0.89,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Toxicity Mitigation",
      "resolved_canonical": "Toxicity Mitigation",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.73,
        "specificity": 0.82,
        "link_intent": 0.81
      }
    },
    {
      "candidate_surface": "Neuron Activations",
      "resolved_canonical": "Neuron Activation",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.7,
        "specificity": 0.78,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Redefining Experts: Interpretable Decomposition of Language Models for Toxicity Mitigation

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16660.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2509.16660](https://arxiv.org/abs/2509.16660)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Activation Space Interventions Can Be Transferred Between Large Language Models_20250922|Activation Space Interventions Can Be Transferred Between Large Language Models]] (84.0% similar)
- [[2025-09-19/Translate, then Detect_ Leveraging Machine Translation for Cross-Lingual Toxicity Classification_20250919|Translate, then Detect: Leveraging Machine Translation for Cross-Lingual Toxicity Classification]] (83.1% similar)
- [[2025-09-23/Jailbreak-Tuning_ Models Efficiently Learn Jailbreak Susceptibility_20250923|Jailbreak-Tuning: Models Efficiently Learn Jailbreak Susceptibility]] (82.5% similar)
- [[2025-09-22/Exploring the Impact of Personality Traits on LLM Bias and Toxicity_20250922|Exploring the Impact of Personality Traits on LLM Bias and Toxicity]] (82.0% similar)
- [[2025-09-22/Red Teaming Multimodal Language Models_ Evaluating Harm Across Prompt Modalities and Models_20250922|Red Teaming Multimodal Language Models: Evaluating Harm Across Prompt Modalities and Models]] (81.9% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Toxicity Mitigation|Toxicity Mitigation]], [[keywords/Neuron Activation|Neuron Activation]]
**âš¡ Unique Technical**: [[keywords/EigenShift|EigenShift]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16660v1 Announce Type: new 
Abstract: Large Language Models have demonstrated impressive fluency across diverse tasks, yet their tendency to produce toxic content remains a critical challenge for AI safety and public trust. Existing toxicity mitigation approaches primarily manipulate individual neuron activations, but these methods suffer from instability, context dependence, and often compromise the model's core language abilities. To address these shortcomings, we investigate three key questions: the stability of neuron-level toxicity indicators, the advantages of structural (layer-wise) representations, and the interpretability of mechanisms driving toxic generation. Through extensive experiments on Jigsaw and ToxiCN datasets, we show that aggregated layer-wise features provide more robust signals than single neurons. Moreover, we observe conceptual limitations in prior works that conflate toxicity detection experts and generation experts within neuron-based interventions. To mitigate this, we propose a novel principled intervention technique, EigenShift, based on eigen-decomposition of the language model's final output layer. This method selectively targets generation-aligned components, enabling precise toxicity suppression without impairing linguistic competence. Our method requires no additional training or fine-tuning, incurs minimal computational cost, and is grounded in rigorous theoretical analysis.

## ğŸ“ ìš”ì•½

ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì€ ë‹¤ì–‘í•œ ì‘ì—…ì—ì„œ ë›°ì–´ë‚œ ìœ ì°½ì„±ì„ ë³´ì´ì§€ë§Œ, ìœ í•´í•œ ì½˜í…ì¸ ë¥¼ ìƒì„±í•˜ëŠ” ê²½í–¥ì€ AI ì•ˆì „ì„±ê³¼ ëŒ€ì¤‘ì˜ ì‹ ë¢°ì— ì¤‘ìš”í•œ ë„ì „ ê³¼ì œë¡œ ë‚¨ì•„ ìˆìŠµë‹ˆë‹¤. ê¸°ì¡´ì˜ ìœ í•´ì„± ì™„í™” ë°©ë²•ì€ ì£¼ë¡œ ê°œë³„ ë‰´ëŸ° í™œì„±í™”ë¥¼ ì¡°ì‘í•˜ì§€ë§Œ, ì´ëŸ¬í•œ ë°©ë²•ì€ ë¶ˆì•ˆì •í•˜ê³  ë§¥ë½ì— ì˜ì¡´í•˜ë©° ëª¨ë¸ì˜ í•µì‹¬ ì–¸ì–´ ëŠ¥ë ¥ì„ ì†ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ëŠ” ë‰´ëŸ° ìˆ˜ì¤€ì˜ ìœ í•´ì„± ì§€í‘œì˜ ì•ˆì •ì„±, ê³„ì¸µì  í‘œí˜„ì˜ ì¥ì , ìœ í•´ ìƒì„± ë©”ì»¤ë‹ˆì¦˜ì˜ í•´ì„ ê°€ëŠ¥ì„±ì„ ì¡°ì‚¬í•©ë‹ˆë‹¤. Jigsawì™€ ToxiCN ë°ì´í„°ì…‹ì„ í†µí•´, ê³„ì¸µì  íŠ¹ì§•ì´ ë‹¨ì¼ ë‰´ëŸ°ë³´ë‹¤ ë” ê°•ë ¥í•œ ì‹ í˜¸ë¥¼ ì œê³µí•¨ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤. ë˜í•œ, ê¸°ì¡´ ì—°êµ¬ì˜ ê°œë…ì  í•œê³„ë¥¼ ì§€ì í•˜ë©°, ìƒˆë¡œìš´ ê°œì… ê¸°ë²•ì¸ EigenShiftë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ì–¸ì–´ ëª¨ë¸ì˜ ìµœì¢… ì¶œë ¥ ê³„ì¸µì˜ ê³ ìœ ê°’ ë¶„í•´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ì—¬, ìƒì„±ì— ë§ì¶°ì§„ ìš”ì†Œë¥¼ ì„ íƒì ìœ¼ë¡œ ì¡°ì •í•¨ìœ¼ë¡œì¨ ì–¸ì–´ ëŠ¥ë ¥ì„ ì†ìƒì‹œí‚¤ì§€ ì•Šê³  ìœ í•´ì„±ì„ ì–µì œí•©ë‹ˆë‹¤. ì¶”ê°€ì ì¸ í›ˆë ¨ì´ë‚˜ ë¯¸ì„¸ ì¡°ì •ì´ í•„ìš” ì—†ìœ¼ë©°, ìµœì†Œí•œì˜ ê³„ì‚° ë¹„ìš©ìœ¼ë¡œ ì´ë¡ ì  ë¶„ì„ì— ê¸°ë°˜ì„ ë‘ê³  ìˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ ë…ì„± ì½˜í…ì¸  ìƒì„± ë¬¸ì œëŠ” AI ì•ˆì „ì„±ê³¼ ëŒ€ì¤‘ì˜ ì‹ ë¢°ì— ì¤‘ìš”í•œ ë„ì „ ê³¼ì œë¡œ ë‚¨ì•„ ìˆë‹¤.
- 2. ê¸°ì¡´ì˜ ë…ì„± ì™„í™” ë°©ë²•ì€ ê°œë³„ ë‰´ëŸ° í™œì„±í™”ë¥¼ ì¡°ì‘í•˜ì§€ë§Œ, ì´ëŠ” ë¶ˆì•ˆì •ì„±ê³¼ ë¬¸ë§¥ ì˜ì¡´ì„± ë¬¸ì œë¥¼ ê²ªëŠ”ë‹¤.
- 3. ì—°êµ¬ëŠ” ë‰´ëŸ° ìˆ˜ì¤€ì˜ ë…ì„± ì§€í‘œì˜ ì•ˆì •ì„±, ì¸µë³„ êµ¬ì¡°ì  í‘œí˜„ì˜ ì¥ì , ë…ì„± ìƒì„± ë©”ì»¤ë‹ˆì¦˜ì˜ í•´ì„ ê°€ëŠ¥ì„±ì„ ì¡°ì‚¬í•œë‹¤.
- 4. ì‹¤í—˜ ê²°ê³¼, ì¸µë³„ íŠ¹ì§•ì˜ ì§‘ê³„ê°€ ë‹¨ì¼ ë‰´ëŸ°ë³´ë‹¤ ë” ê°•ë ¥í•œ ì‹ í˜¸ë¥¼ ì œê³µí•¨ì„ ë³´ì—¬ì¤€ë‹¤.
- 5. ì œì•ˆëœ EigenShift ê¸°ë²•ì€ ì–¸ì–´ ëª¨ë¸ì˜ ìµœì¢… ì¶œë ¥ì¸µì˜ ê³ ìœ  ë¶„í•´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ì—¬, ì–¸ì–´ ëŠ¥ë ¥ì„ ì†ìƒì‹œí‚¤ì§€ ì•Šê³  ë…ì„±ì„ ì–µì œí•œë‹¤.


---

*Generated on 2025-09-24 03:15:56*