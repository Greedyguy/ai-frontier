---
keywords:
  - Graph Neural Network
  - Over-smoothing in GNNs
  - Local Contribution Score
  - Feature Fusion in GNNs
category: cs.LG
publish_date: 2025-09-23
arxiv_id: 2504.15920
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T02:41:16.866915",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Graph Neural Network",
    "Over-smoothing in GNNs",
    "Local Contribution Score",
    "Feature Fusion in GNNs"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Graph Neural Network": 0.85,
    "Over-smoothing in GNNs": 0.78,
    "Local Contribution Score": 0.8,
    "Feature Fusion in GNNs": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Graph Neural Networks",
        "canonical": "Graph Neural Network",
        "aliases": [
          "GNN",
          "Graph Neural Networks"
        ],
        "category": "specific_connectable",
        "rationale": "Graph Neural Networks are central to the paper's methodology and connect well with existing literature on graph-based learning.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.8,
        "link_intent_score": 0.85
      },
      {
        "surface": "over-smoothing",
        "canonical": "Over-smoothing in GNNs",
        "aliases": [
          "over-smoothing problem",
          "node representation smoothing"
        ],
        "category": "unique_technical",
        "rationale": "Over-smoothing is a specific challenge in GNNs that the paper addresses, making it a unique technical concept.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Local Contribution Score",
        "canonical": "Local Contribution Score",
        "aliases": [
          "LCS",
          "local score"
        ],
        "category": "unique_technical",
        "rationale": "The Local Contribution Score is a novel mechanism introduced in the paper, offering a unique approach to feature selection in GNNs.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.88,
        "link_intent_score": 0.8
      },
      {
        "surface": "feature fusion strategy",
        "canonical": "Feature Fusion in GNNs",
        "aliases": [
          "fusion strategy",
          "feature fusion"
        ],
        "category": "specific_connectable",
        "rationale": "Feature fusion is a key technique in the paper, enhancing the connectivity with other works on feature integration in GNNs.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "scalability",
      "efficiency",
      "computational overhead"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Graph Neural Networks",
      "resolved_canonical": "Graph Neural Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.8,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "over-smoothing",
      "resolved_canonical": "Over-smoothing in GNNs",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Local Contribution Score",
      "resolved_canonical": "Local Contribution Score",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.88,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "feature fusion strategy",
      "resolved_canonical": "Feature Fusion in GNNs",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# ScaleGNN: Towards Scalable Graph Neural Networks via Adaptive High-order Neighboring Feature Fusion

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2504.15920.pdf)
**Category**: cs.LG
**Published**: 2025-09-23
**ArXiv ID**: [2504.15920](https://arxiv.org/abs/2504.15920)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Schreier-Coset Graph Propagation_20250922|Schreier-Coset Graph Propagation]] (87.5% similar)
- [[2025-09-22/GIN-Graph_ A Generative Interpretation Network for Model-Level Explanation of Graph Neural Networks_20250922|GIN-Graph: A Generative Interpretation Network for Model-Level Explanation of Graph Neural Networks]] (85.1% similar)
- [[2025-09-19/Brain-HGCN_ A Hyperbolic Graph Convolutional Network for Brain Functional Network Analysis_20250919|Brain-HGCN: A Hyperbolic Graph Convolutional Network for Brain Functional Network Analysis]] (84.3% similar)
- [[2025-09-23/A Scalable Multi-Robot Framework for Decentralized and Asynchronous Perception-Action-Communication Loops_20250923|A Scalable Multi-Robot Framework for Decentralized and Asynchronous Perception-Action-Communication Loops]] (84.2% similar)
- [[2025-09-18/GraphTorque_ Torque-Driven Rewiring Graph Neural Network_20250918|GraphTorque: Torque-Driven Rewiring Graph Neural Network]] (83.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Graph Neural Network|Graph Neural Network]], [[keywords/Feature Fusion in GNNs|Feature Fusion in GNNs]]
**âš¡ Unique Technical**: [[keywords/Over-smoothing in GNNs|Over-smoothing in GNNs]], [[keywords/Local Contribution Score|Local Contribution Score]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2504.15920v5 Announce Type: replace 
Abstract: Graph Neural Networks (GNNs) have demonstrated impressive performance across diverse graph-based tasks by leveraging message passing to capture complex node relationships. However, when applied to large-scale real-world graphs, GNNs face two major challenges: First, it becomes increasingly difficult to ensure both scalability and efficiency, as the repeated aggregation of large neighborhoods leads to significant computational overhead; Second, the over-smoothing problem arises, where excessive or deep propagation makes node representations indistinguishable, severely hindering model expressiveness. To tackle these issues, we propose ScaleGNN, a novel framework that adaptively fuses multi-hop node features for both scalable and effective graph learning. First, we construct per-hop pure neighbor matrices that capture only the exclusive structural information at each hop, avoiding the redundancy of conventional aggregation. Then, an enhanced feature fusion strategy significantly balances low-order and high-order information, preserving both local detail and global correlations without incurring excessive complexity. To further reduce redundancy and over-smoothing, we introduce a Local Contribution Score (LCS)-based masking mechanism to filter out less relevant high-order neighbors, ensuring that only the most meaningful information is aggregated. In addition, learnable sparse constraints selectively integrate multi-hop valuable features, emphasizing the most informative high-order neighbors. Extensive experiments on real-world datasets demonstrate that ScaleGNN consistently outperforms state-of-the-art GNNs in both predictive accuracy and computational efficiency, highlighting its practical value for large-scale graph learning.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì—ì„œëŠ” ëŒ€ê·œëª¨ ê·¸ë˜í”„ í•™ìŠµì˜ íš¨ìœ¨ì„±ê³¼ í™•ì¥ì„±ì„ ê°œì„ í•˜ê¸° ìœ„í•´ ScaleGNNì´ë¼ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ ê·¸ë˜í”„ ì‹ ê²½ë§(GNN)ì´ ëŒ€ê·œëª¨ ê·¸ë˜í”„ì—ì„œ í™•ì¥ì„±ê³¼ ê³¼ë„í•œ ìŠ¤ë¬´ë”© ë¬¸ì œë¥¼ ê²ªëŠ”ë‹¤ëŠ” ì ì„ í•´ê²°í•˜ê³ ì, ScaleGNNì€ ë©€í‹° í™‰ ë…¸ë“œ íŠ¹ì§•ì„ ì ì‘ì ìœ¼ë¡œ ìœµí•©í•©ë‹ˆë‹¤. ê° í™‰ì˜ êµ¬ì¡°ì  ì •ë³´ë¥¼ í¬ì°©í•˜ëŠ” ìˆœìˆ˜ ì´ì›ƒ í–‰ë ¬ì„ êµ¬ì„±í•˜ì—¬ ì¤‘ë³µì„ í”¼í•˜ê³ , í–¥ìƒëœ íŠ¹ì§• ìœµí•© ì „ëµì„ í†µí•´ ì €ì°¨ ë° ê³ ì°¨ ì •ë³´ë¥¼ ê· í˜• ìˆê²Œ ê²°í•©í•©ë‹ˆë‹¤. ë˜í•œ, ë¡œì»¬ ê¸°ì—¬ ì ìˆ˜(LCS) ê¸°ë°˜ì˜ ë§ˆìŠ¤í‚¹ ë©”ì»¤ë‹ˆì¦˜ê³¼ í•™ìŠµ ê°€ëŠ¥í•œ í¬ì†Œ ì œì•½ì„ ë„ì…í•˜ì—¬, ì¤‘ìš”í•˜ì§€ ì•Šì€ ê³ ì°¨ ì´ì›ƒì„ í•„í„°ë§í•˜ê³  ìœ ìš©í•œ ì •ë³´ë¥¼ ê°•ì¡°í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ScaleGNNì€ ì˜ˆì¸¡ ì •í™•ë„ì™€ ê³„ì‚° íš¨ìœ¨ì„±ì—ì„œ ê¸°ì¡´ GNNì„ ëŠ¥ê°€í•˜ë©°, ëŒ€ê·œëª¨ ê·¸ë˜í”„ í•™ìŠµì— ì‹¤ì§ˆì ì¸ ê°€ì¹˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. GNNì€ ëŒ€ê·œëª¨ ê·¸ë˜í”„ì—ì„œ í™•ì¥ì„±ê³¼ íš¨ìœ¨ì„±ì„ ë™ì‹œì— í™•ë³´í•˜ê¸° ì–´ë ¤ìš´ ë¬¸ì œì— ì§ë©´í•©ë‹ˆë‹¤.
- 2. ê³¼ë„í•œ ì „íŒŒë¡œ ì¸í•´ ë…¸ë“œ í‘œí˜„ì´ êµ¬ë³„ë˜ì§€ ì•ŠëŠ” ê³¼ë„í•œ í‰í™œí™” ë¬¸ì œê°€ ë°œìƒí•©ë‹ˆë‹¤.
- 3. ScaleGNNì€ ë©€í‹° í™‰ ë…¸ë“œ íŠ¹ì§•ì„ ì ì‘ì ìœ¼ë¡œ ìœµí•©í•˜ì—¬ í™•ì¥ ê°€ëŠ¥í•˜ê³  íš¨ê³¼ì ì¸ ê·¸ë˜í”„ í•™ìŠµì„ ì œê³µí•©ë‹ˆë‹¤.
- 4. LCS ê¸°ë°˜ ë§ˆìŠ¤í‚¹ ë©”ì»¤ë‹ˆì¦˜ì„ ë„ì…í•˜ì—¬ ëœ ê´€ë ¨ ìˆëŠ” ê³ ì°¨ ì´ì›ƒì„ í•„í„°ë§í•˜ê³  ê°€ì¥ ì˜ë¯¸ ìˆëŠ” ì •ë³´ë¥¼ ì§‘ê³„í•©ë‹ˆë‹¤.
- 5. ScaleGNNì€ ì˜ˆì¸¡ ì •í™•ë„ì™€ ê³„ì‚° íš¨ìœ¨ì„± ë©´ì—ì„œ ìµœì²¨ë‹¨ GNNë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.


---

*Generated on 2025-09-24 02:41:16*