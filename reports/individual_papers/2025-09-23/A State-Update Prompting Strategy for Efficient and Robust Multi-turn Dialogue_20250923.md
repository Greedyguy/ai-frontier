---
keywords:
  - Large Language Model
  - State-Update Dialogue Strategy
  - Multi-hop Question Answering
  - HotpotQA
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.17766
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T00:08:42.188793",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "State-Update Dialogue Strategy",
    "Multi-hop Question Answering",
    "HotpotQA"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "State-Update Dialogue Strategy": 0.8,
    "Multi-hop Question Answering": 0.82,
    "HotpotQA": 0.88
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Connects to existing discussions on the challenges and advancements in language models.",
        "novelty_score": 0.2,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "State-Update Multi-turn Dialogue Strategy",
        "canonical": "State-Update Dialogue Strategy",
        "aliases": [
          "State Reconstruction",
          "History Remind"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel approach specific to multi-turn dialogue management.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Multi-hop QA datasets",
        "canonical": "Multi-hop Question Answering",
        "aliases": [
          "Multi-hop QA"
        ],
        "category": "specific_connectable",
        "rationale": "Links to datasets and methodologies in question answering research.",
        "novelty_score": 0.45,
        "connectivity_score": 0.78,
        "specificity_score": 0.7,
        "link_intent_score": 0.82
      },
      {
        "surface": "HotpotQA dataset",
        "canonical": "HotpotQA",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "A well-known dataset that provides context for evaluating the proposed strategy.",
        "novelty_score": 0.3,
        "connectivity_score": 0.85,
        "specificity_score": 0.75,
        "link_intent_score": 0.88
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "efficiency"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.2,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "State-Update Multi-turn Dialogue Strategy",
      "resolved_canonical": "State-Update Dialogue Strategy",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Multi-hop QA datasets",
      "resolved_canonical": "Multi-hop Question Answering",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.78,
        "specificity": 0.7,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "HotpotQA dataset",
      "resolved_canonical": "HotpotQA",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.85,
        "specificity": 0.75,
        "link_intent": 0.88
      }
    }
  ]
}
-->

# A State-Update Prompting Strategy for Efficient and Robust Multi-turn Dialogue

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17766.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.17766](https://arxiv.org/abs/2509.17766)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Single- vs. Dual-Prompt Dialogue Generation with LLMs for Job Interviews in Human Resources_20250919|Single- vs. Dual-Prompt Dialogue Generation with LLMs for Job Interviews in Human Resources]] (86.5% similar)
- [[2025-09-23/Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates_20250923|Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates]] (85.5% similar)
- [[2025-09-19/Controlling Language Difficulty in Dialogues with Linguistic Features_20250919|Controlling Language Difficulty in Dialogues with Linguistic Features]] (85.4% similar)
- [[2025-09-22/It Depends_ Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge_20250922|It Depends: Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge]] (85.1% similar)
- [[2025-09-19/(P)rior(D)yna(F)low_ A Priori Dynamic Workflow Construction via Multi-Agent Collaboration_20250919|(P)rior(D)yna(F)low: A Priori Dynamic Workflow Construction via Multi-Agent Collaboration]] (84.7% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Multi-hop Question Answering|Multi-hop Question Answering]], [[keywords/HotpotQA|HotpotQA]]
**âš¡ Unique Technical**: [[keywords/State-Update Dialogue Strategy|State-Update Dialogue Strategy]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17766v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) struggle with information forgetting and inefficiency in long-horizon, multi-turn dialogues. To address this, we propose a training-free prompt engineering method, the State-Update Multi-turn Dialogue Strategy. It utilizes "State Reconstruction" and "History Remind" mechanisms to effectively manage dialogue history. Our strategy shows strong performance across multiple multi-hop QA datasets. For instance, on the HotpotQA dataset, it improves the core information filtering score by 32.6%, leading to a 14.1% increase in the downstream QA score, while also reducing inference time by 73.1% and token consumption by 59.4%. Ablation studies confirm the pivotal roles of both components. Our work offers an effective solution for optimizing LLMs in long-range interactions, providing new insights for developing more robust Agents.

## ğŸ“ ìš”ì•½

ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ ê¸´ ëŒ€í™”ì—ì„œ ì •ë³´ ë§ê°ê³¼ ë¹„íš¨ìœ¨ì„± ë¬¸ì œë¥¼ ê²ªìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ìš°ë¦¬ëŠ” í›ˆë ¨ì´ í•„ìš” ì—†ëŠ” í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ë°©ë²•ì¸ 'ìƒíƒœ ì—…ë°ì´íŠ¸ ë‹¤ì¤‘ í„´ ëŒ€í™” ì „ëµ'ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ì „ëµì€ 'ìƒíƒœ ì¬êµ¬ì„±'ê³¼ 'ì—­ì‚¬ ìƒê¸°' ë©”ì»¤ë‹ˆì¦˜ì„ í™œìš©í•˜ì—¬ ëŒ€í™” ê¸°ë¡ì„ íš¨ê³¼ì ìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì „ëµì€ ì—¬ëŸ¬ ë‹¤ì¤‘ í™‰ ì§ˆì˜ì‘ë‹µ(QA) ë°ì´í„°ì…‹ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë©°, íŠ¹íˆ HotpotQA ë°ì´í„°ì…‹ì—ì„œ í•µì‹¬ ì •ë³´ í•„í„°ë§ ì ìˆ˜ë¥¼ 32.6% í–¥ìƒì‹œí‚¤ê³ , QA ì ìˆ˜ë¥¼ 14.1% ì¦ê°€ì‹œì¼°ìœ¼ë©°, ì¶”ë¡  ì‹œê°„ì„ 73.1%, í† í° ì†Œë¹„ë¥¼ 59.4% ì¤„ì˜€ìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” LLMì˜ ì¥ê¸° ìƒí˜¸ì‘ìš© ìµœì í™”ì— íš¨ê³¼ì ì¸ í•´ê²°ì±…ì„ ì œê³µí•˜ë©°, ë” ê°•ë ¥í•œ ì—ì´ì „íŠ¸ ê°œë°œì— ìƒˆë¡œìš´ í†µì°°ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì€ ì¥ê¸° ë‹¤ì¤‘ í„´ ëŒ€í™”ì—ì„œ ì •ë³´ ë§ê°ê³¼ ë¹„íš¨ìœ¨ì„± ë¬¸ì œë¥¼ ê²ªëŠ”ë‹¤.
- 2. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” í›ˆë ¨ì´ í•„ìš” ì—†ëŠ” í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ë°©ë²•ì¸ ìƒíƒœ ì—…ë°ì´íŠ¸ ë‹¤ì¤‘ í„´ ëŒ€í™” ì „ëµì„ ì œì•ˆí•œë‹¤.
- 3. ì´ ì „ëµì€ "ìƒíƒœ ì¬êµ¬ì„±"ê³¼ "ì—­ì‚¬ ìƒê¸°" ë©”ì»¤ë‹ˆì¦˜ì„ í™œìš©í•˜ì—¬ ëŒ€í™” ê¸°ë¡ì„ íš¨ê³¼ì ìœ¼ë¡œ ê´€ë¦¬í•œë‹¤.
- 4. HotpotQA ë°ì´í„°ì…‹ì—ì„œ í•µì‹¬ ì •ë³´ í•„í„°ë§ ì ìˆ˜ë¥¼ 32.6% í–¥ìƒì‹œí‚¤ê³ , ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ QA ì ìˆ˜ë¥¼ 14.1% ì¦ê°€ì‹œì¼°ìœ¼ë©°, ì¶”ë¡  ì‹œê°„ì€ 73.1%, í† í° ì†Œë¹„ëŠ” 59.4% ê°ì†Œì‹œì¼°ë‹¤.
- 5. ì—°êµ¬ ê²°ê³¼ëŠ” LLMì˜ ì¥ê±°ë¦¬ ìƒí˜¸ì‘ìš© ìµœì í™”ë¥¼ ìœ„í•œ íš¨ê³¼ì ì¸ ì†”ë£¨ì…˜ì„ ì œê³µí•˜ë©°, ë” ê²¬ê³ í•œ ì—ì´ì „íŠ¸ ê°œë°œì— ëŒ€í•œ ìƒˆë¡œìš´ í†µì°°ì„ ì œì‹œí•œë‹¤.


---

*Generated on 2025-09-24 00:08:42*