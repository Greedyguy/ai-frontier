---
keywords:
  - Audio Editing
  - Diffusion Models
  - Neural Editing
  - Virtual Consistency
category: cs.LG
publish_date: 2025-09-23
arxiv_id: 2509.17219
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T02:20:46.468594",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Audio Editing",
    "Diffusion Models",
    "Neural Editing",
    "Virtual Consistency"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Audio Editing": 0.75,
    "Diffusion Models": 0.8,
    "Neural Editing": 0.7,
    "Virtual Consistency": 0.65
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "audio editing",
        "canonical": "Audio Editing",
        "aliases": [
          "sound editing",
          "audio manipulation"
        ],
        "category": "unique_technical",
        "rationale": "Audio Editing is central to the paper's contribution and offers unique insights into the field.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      },
      {
        "surface": "diffusion models",
        "canonical": "Diffusion Models",
        "aliases": [
          "diffusion processes"
        ],
        "category": "specific_connectable",
        "rationale": "Diffusion Models are a key component of the proposed system, linking to broader machine learning concepts.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "neural editing",
        "canonical": "Neural Editing",
        "aliases": [
          "neural-based editing"
        ],
        "category": "unique_technical",
        "rationale": "Neural Editing is a distinct approach discussed in the paper, relevant for linking to neural network applications.",
        "novelty_score": 0.65,
        "connectivity_score": 0.65,
        "specificity_score": 0.75,
        "link_intent_score": 0.7
      },
      {
        "surface": "virtual consistency",
        "canonical": "Virtual Consistency",
        "aliases": [
          "virtual coherence"
        ],
        "category": "unique_technical",
        "rationale": "Virtual Consistency is a novel concept introduced by the authors, crucial for understanding their method.",
        "novelty_score": 0.8,
        "connectivity_score": 0.5,
        "specificity_score": 0.85,
        "link_intent_score": 0.65
      }
    ],
    "ban_list_suggestions": [
      "inversion procedures",
      "sampling process",
      "user study"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "audio editing",
      "resolved_canonical": "Audio Editing",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "diffusion models",
      "resolved_canonical": "Diffusion Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "neural editing",
      "resolved_canonical": "Neural Editing",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.65,
        "specificity": 0.75,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "virtual consistency",
      "resolved_canonical": "Virtual Consistency",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.5,
        "specificity": 0.85,
        "link_intent": 0.65
      }
    }
  ]
}
-->

# Virtual Consistency for Audio Editing

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17219.pdf)
**Category**: cs.LG
**Published**: 2025-09-23
**ArXiv ID**: [2509.17219](https://arxiv.org/abs/2509.17219)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-17/RFM-Editing_ Rectified Flow Matching for Text-guided Audio Editing_20250917|RFM-Editing: Rectified Flow Matching for Text-guided Audio Editing]] (87.4% similar)
- [[2025-09-19/Mitigating data replication in text-to-audio generative diffusion models through anti-memorization guidance_20250919|Mitigating data replication in text-to-audio generative diffusion models through anti-memorization guidance]] (81.1% similar)
- [[2025-09-23/Audio-Guided Dynamic Modality Fusion with Stereo-Aware Attention for Audio-Visual Navigation_20250923|Audio-Guided Dynamic Modality Fusion with Stereo-Aware Attention for Audio-Visual Navigation]] (80.8% similar)
- [[2025-09-23/Audio Contrastive-based Fine-tuning_ Decoupling Representation Learning and Classification_20250923|Audio Contrastive-based Fine-tuning: Decoupling Representation Learning and Classification]] (80.5% similar)
- [[2025-09-23/Prompt-Driven Agentic Video Editing System_ Autonomous Comprehension of Long-Form, Story-Driven Media_20250923|Prompt-Driven Agentic Video Editing System: Autonomous Comprehension of Long-Form, Story-Driven Media]] (80.4% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Diffusion Models|Diffusion Models]]
**âš¡ Unique Technical**: [[keywords/Audio Editing|Audio Editing]], [[keywords/Neural Editing|Neural Editing]], [[keywords/Virtual Consistency|Virtual Consistency]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17219v1 Announce Type: cross 
Abstract: Free-form, text-based audio editing remains a persistent challenge, despite progress in inversion-based neural methods. Current approaches rely on slow inversion procedures, limiting their practicality. We present a virtual-consistency based audio editing system that bypasses inversion by adapting the sampling process of diffusion models. Our pipeline is model-agnostic, requiring no fine-tuning or architectural changes, and achieves substantial speed-ups over recent neural editing baselines. Crucially, it achieves this efficiency without compromising quality, as demonstrated by quantitative benchmarks and a user study involving 16 participants.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ììœ í˜• í…ìŠ¤íŠ¸ ê¸°ë°˜ ì˜¤ë””ì˜¤ í¸ì§‘ì˜ íš¨ìœ¨ì„±ì„ ê°œì„ í•œ ì—°êµ¬ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. ê¸°ì¡´ ë°©ë²•ë“¤ì€ ëŠë¦° ì—­ë³€í™˜ ì ˆì°¨ì— ì˜ì¡´í•˜ì—¬ ì‹¤ìš©ì„±ì´ ë–¨ì–´ì¡ŒìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” ì—­ë³€í™˜ì„ ìš°íšŒí•˜ê³  í™•ì‚° ëª¨ë¸ì˜ ìƒ˜í”Œë§ ê³¼ì •ì„ ì¡°ì •í•˜ëŠ” ê°€ìƒ ì¼ê´€ì„± ê¸°ë°˜ ì˜¤ë””ì˜¤ í¸ì§‘ ì‹œìŠ¤í…œì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œì€ ëª¨ë¸ì— êµ¬ì• ë°›ì§€ ì•Šìœ¼ë©°, ë¯¸ì„¸ ì¡°ì •ì´ë‚˜ êµ¬ì¡°ì  ë³€ê²½ ì—†ì´ë„ ìµœê·¼ì˜ ì‹ ê²½ë§ í¸ì§‘ ê¸°ì¤€ë³´ë‹¤ ì†ë„ê°€ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤. ì¤‘ìš”í•œ ì ì€, ì´ëŸ¬í•œ íš¨ìœ¨ì„±ì„ í’ˆì§ˆ ì €í•˜ ì—†ì´ ë‹¬ì„±í–ˆë‹¤ëŠ” ê²ƒì´ë©°, ì´ëŠ” ì •ëŸ‰ì  ë²¤ì¹˜ë§ˆí¬ì™€ 16ëª…ì˜ ì°¸ê°€ìë¥¼ ëŒ€ìƒìœ¼ë¡œ í•œ ì‚¬ìš©ì ì—°êµ¬ë¥¼ í†µí•´ ì…ì¦ë˜ì—ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë³¸ ì—°êµ¬ëŠ” ììœ í˜• í…ìŠ¤íŠ¸ ê¸°ë°˜ ì˜¤ë””ì˜¤ í¸ì§‘ì˜ ì–´ë ¤ì›€ì„ í•´ê²°í•˜ê¸° ìœ„í•´ ê°€ìƒ ì¼ê´€ì„± ê¸°ë°˜ ì˜¤ë””ì˜¤ í¸ì§‘ ì‹œìŠ¤í…œì„ ì œì•ˆí•©ë‹ˆë‹¤.
- 2. ì œì•ˆëœ ì‹œìŠ¤í…œì€ í™•ì‚° ëª¨ë¸ì˜ ìƒ˜í”Œë§ ê³¼ì •ì„ ì¡°ì •í•˜ì—¬ ì—­ë³€í™˜ì„ ìš°íšŒí•˜ë©°, ì´ëŠ” ê¸°ì¡´ì˜ ëŠë¦° ì—­ë³€í™˜ ì ˆì°¨ë¥¼ ëŒ€ì²´í•©ë‹ˆë‹¤.
- 3. ì´ íŒŒì´í”„ë¼ì¸ì€ ëª¨ë¸ì— êµ¬ì• ë°›ì§€ ì•Šìœ¼ë©°, ë¯¸ì„¸ ì¡°ì •ì´ë‚˜ êµ¬ì¡°ì  ë³€ê²½ ì—†ì´ë„ ìµœê·¼ ì‹ ê²½ë§ í¸ì§‘ ê¸°ì¤€ë³´ë‹¤ ìƒë‹¹íˆ ë¹ ë¥¸ ì†ë„ë¥¼ ë‹¬ì„±í•©ë‹ˆë‹¤.
- 4. ì œì•ˆëœ ë°©ë²•ì€ íš¨ìœ¨ì„±ì„ ë†’ì´ë©´ì„œë„ í’ˆì§ˆì„ ì €í•˜ì‹œí‚¤ì§€ ì•Šìœ¼ë©°, ì´ëŠ” ì •ëŸ‰ì  ë²¤ì¹˜ë§ˆí¬ì™€ 16ëª…ì˜ ì°¸ê°€ìë¥¼ ëŒ€ìƒìœ¼ë¡œ í•œ ì‚¬ìš©ì ì—°êµ¬ë¥¼ í†µí•´ ì…ì¦ë˜ì—ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 02:20:46*