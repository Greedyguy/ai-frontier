---
keywords:
  - Explainability
  - Artificial Intelligence
  - Liability in Healthcare
  - Defensive Medicine
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.17334
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T23:52:30.735880",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Explainability",
    "Artificial Intelligence",
    "Liability in Healthcare",
    "Defensive Medicine"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Explainability": 0.85,
    "Artificial Intelligence": 0.7,
    "Liability in Healthcare": 0.8,
    "Defensive Medicine": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Explainability",
        "canonical": "Explainability",
        "aliases": [
          "Interpretability"
        ],
        "category": "unique_technical",
        "rationale": "Explainability is crucial for understanding AI decisions in healthcare, impacting liability and behavior.",
        "novelty_score": 0.7,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.85
      },
      {
        "surface": "Artificial Intelligence System",
        "canonical": "Artificial Intelligence",
        "aliases": [
          "AI",
          "AIS"
        ],
        "category": "broad_technical",
        "rationale": "AI systems are central to the discussion of liability and explainability in healthcare.",
        "novelty_score": 0.55,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.7
      },
      {
        "surface": "Liability Rules",
        "canonical": "Liability in Healthcare",
        "aliases": [
          "Legal Responsibility"
        ],
        "category": "unique_technical",
        "rationale": "Liability rules are a key factor in how explainability affects healthcare practices.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Defensive Medicine",
        "canonical": "Defensive Medicine",
        "aliases": [
          "Risk-averse Practice"
        ],
        "category": "unique_technical",
        "rationale": "Defensive medicine is a potential outcome of liability and explainability issues in healthcare.",
        "novelty_score": 0.6,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "Oracle",
      "AI Colleague"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Explainability",
      "resolved_canonical": "Explainability",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Artificial Intelligence System",
      "resolved_canonical": "Artificial Intelligence",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Liability Rules",
      "resolved_canonical": "Liability in Healthcare",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Defensive Medicine",
      "resolved_canonical": "Defensive Medicine",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Explainability matters: The effect of liability rules on the healthcare sector

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17334.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.17334](https://arxiv.org/abs/2509.17334)

## 🔗 유사한 논문
- [[2025-09-22/Who is Responsible When AI Fails? Mapping Causes, Entities, and Consequences of AI Privacy and Ethical Incidents_20250922|Who is Responsible When AI Fails? Mapping Causes, Entities, and Consequences of AI Privacy and Ethical Incidents]] (81.8% similar)
- [[2025-09-18/From Sea to System_ Exploring User-Centered Explainable AI for Maritime Decision Support_20250918|From Sea to System: Exploring User-Centered Explainable AI for Maritime Decision Support]] (81.6% similar)
- [[2025-09-18/Blockchain-Enabled Explainable AI for Trusted Healthcare Systems_20250918|Blockchain-Enabled Explainable AI for Trusted Healthcare Systems]] (80.9% similar)
- [[2025-09-23/"I think this is fair''_ Uncovering the Complexities of Stakeholder Decision-Making in AI Fairness Assessment_20250923|"I think this is fair'': Uncovering the Complexities of Stakeholder Decision-Making in AI Fairness Assessment]] (79.6% similar)
- [[2025-09-22/Algorithmic Fairness_ Not a Purely Technical but Socio-Technical Property_20250922|Algorithmic Fairness: Not a Purely Technical but Socio-Technical Property]] (79.0% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Artificial Intelligence|Artificial Intelligence]]
**⚡ Unique Technical**: [[keywords/Explainability|Explainability]], [[keywords/Liability in Healthcare|Liability in Healthcare]], [[keywords/Defensive Medicine|Defensive Medicine]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.17334v1 Announce Type: cross 
Abstract: Explainability, the capability of an artificial intelligence system (AIS) to explain its outcomes in a manner that is comprehensible to human beings at an acceptable level, has been deemed essential for critical sectors, such as healthcare. Is it really the case? In this perspective, we consider two extreme cases, ``Oracle'' (without explainability) versus ``AI Colleague'' (with explainability) for a thorough analysis. We discuss how the level of automation and explainability of AIS can affect the determination of liability among the medical practitioner/facility and manufacturer of AIS. We argue that explainability plays a crucial role in setting a responsibility framework in healthcare, from a legal standpoint, to shape the behavior of all involved parties and mitigate the risk of potential defensive medicine practices.

## 📝 요약

이 논문은 인공지능 시스템(AIS)의 설명 가능성이 의료 분야에서 중요한 역할을 한다고 주장합니다. 저자들은 설명 가능성이 없는 '오라클'과 설명 가능성이 있는 'AI 동료'라는 두 가지 극단적인 사례를 분석하여, AIS의 자동화 수준과 설명 가능성이 의료 종사자 및 AIS 제조업체의 책임 결정에 미치는 영향을 논의합니다. 설명 가능성은 법적 관점에서 책임 체계를 설정하고, 관련 당사자들의 행동을 조정하며, 방어적 의료 관행의 위험을 줄이는 데 중요한 역할을 한다고 주장합니다.

## 🎯 주요 포인트

- 1. 설명 가능성은 인공지능 시스템(AIS)이 인간에게 이해할 수 있는 수준으로 결과를 설명할 수 있는 능력으로, 특히 의료 분야에서 필수적이라고 여겨진다.
- 2. 설명 가능성이 없는 '오라클'과 설명 가능성이 있는 'AI 동료'라는 두 극단적인 사례를 통해 AIS의 자동화 및 설명 가능성이 책임 결정에 미치는 영향을 분석한다.
- 3. 설명 가능성은 의료 분야에서 법적 관점에서 책임 체계를 설정하는 데 중요한 역할을 하며, 관련 당사자들의 행동을 형성하고 방어적 의료 관행의 위험을 줄이는 데 기여한다.


---

*Generated on 2025-09-23 23:52:30*