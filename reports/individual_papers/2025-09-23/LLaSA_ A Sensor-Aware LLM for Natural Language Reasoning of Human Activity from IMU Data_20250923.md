---
keywords:
  - Sensor-Aware Language Model
  - Inertial Measurement Unit Data
  - Open Sensor Question Answering
  - Causal Reasoning
  - Sensor Caption Dataset
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2406.14498
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:42:51.899758",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Sensor-Aware Language Model",
    "Inertial Measurement Unit Data",
    "Open Sensor Question Answering",
    "Causal Reasoning",
    "Sensor Caption Dataset"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Sensor-Aware Language Model": 0.82,
    "Inertial Measurement Unit Data": 0.75,
    "Open Sensor Question Answering": 0.79,
    "Causal Reasoning": 0.78,
    "Sensor Caption Dataset": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "LLaSA",
        "canonical": "Sensor-Aware Language Model",
        "aliases": [
          "Large Language and Sensor Assistant"
        ],
        "category": "unique_technical",
        "rationale": "LLaSA represents a novel integration of language models with sensor data, offering unique insights into sensor reasoning.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.88,
        "link_intent_score": 0.82
      },
      {
        "surface": "IMU data",
        "canonical": "Inertial Measurement Unit Data",
        "aliases": [
          "IMU"
        ],
        "category": "specific_connectable",
        "rationale": "IMU data is central to the paper's focus on human activity recognition, providing a key data source for sensor-aware models.",
        "novelty_score": 0.55,
        "connectivity_score": 0.78,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      },
      {
        "surface": "OpenSQA",
        "canonical": "Open Sensor Question Answering",
        "aliases": [
          "OpenSQA dataset"
        ],
        "category": "unique_technical",
        "rationale": "OpenSQA is a specialized dataset designed for causal reasoning, enhancing the model's explanatory capabilities.",
        "novelty_score": 0.72,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.79
      },
      {
        "surface": "causal and explanatory reasoning",
        "canonical": "Causal Reasoning",
        "aliases": [
          "explanatory reasoning"
        ],
        "category": "specific_connectable",
        "rationale": "Causal reasoning is a critical component of the model's ability to interpret sensor data beyond mere activity recognition.",
        "novelty_score": 0.6,
        "connectivity_score": 0.82,
        "specificity_score": 0.77,
        "link_intent_score": 0.78
      },
      {
        "surface": "SensorCap",
        "canonical": "Sensor Caption Dataset",
        "aliases": [
          "SensorCap dataset"
        ],
        "category": "unique_technical",
        "rationale": "SensorCap provides a large-scale resource for training models on sensor data, crucial for developing sensor-aware language models.",
        "novelty_score": 0.7,
        "connectivity_score": 0.68,
        "specificity_score": 0.84,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "wearable systems",
      "benchmark tasks"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "LLaSA",
      "resolved_canonical": "Sensor-Aware Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.88,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "IMU data",
      "resolved_canonical": "Inertial Measurement Unit Data",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.78,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "OpenSQA",
      "resolved_canonical": "Open Sensor Question Answering",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "causal and explanatory reasoning",
      "resolved_canonical": "Causal Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.82,
        "specificity": 0.77,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "SensorCap",
      "resolved_canonical": "Sensor Caption Dataset",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.68,
        "specificity": 0.84,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# LLaSA: A Sensor-Aware LLM for Natural Language Reasoning of Human Activity from IMU Data

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2406.14498.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2406.14498](https://arxiv.org/abs/2406.14498)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Question Answering with LLMs and Learning from Answer Sets_20250923|Question Answering with LLMs and Learning from Answer Sets]] (84.1% similar)
- [[2025-09-19/Large Multi-modal Models Can Interpret Features in Large Multi-modal Models_20250919|Large Multi-modal Models Can Interpret Features in Large Multi-modal Models]] (83.6% similar)
- [[2025-09-23/UR$^2$_ Unify RAG and Reasoning through Reinforcement Learning_20250923|UR$^2$: Unify RAG and Reasoning through Reinforcement Learning]] (82.6% similar)
- [[2025-09-19/SWE-QA_ Can Language Models Answer Repository-level Code Questions?_20250919|SWE-QA: Can Language Models Answer Repository-level Code Questions?]] (82.4% similar)
- [[2025-09-22/Quantifying Self-Awareness of Knowledge in Large Language Models_20250922|Quantifying Self-Awareness of Knowledge in Large Language Models]] (82.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Inertial Measurement Unit Data|Inertial Measurement Unit Data]], [[keywords/Causal Reasoning|Causal Reasoning]]
**âš¡ Unique Technical**: [[keywords/Sensor-Aware Language Model|Sensor-Aware Language Model]], [[keywords/Open Sensor Question Answering|Open Sensor Question Answering]], [[keywords/Sensor Caption Dataset|Sensor Caption Dataset]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2406.14498v4 Announce Type: replace 
Abstract: Wearable systems can recognize activities from IMU data but often fail to explain their underlying causes or contextual significance. To address this limitation, we introduce two large-scale resources: SensorCap, comprising 35,960 IMU--caption pairs, and OpenSQA, with 199,701 question--answer pairs designed for causal and explanatory reasoning. OpenSQA includes a curated tuning split (Tune-OpenSQA) optimized for scientific accuracy, narrative clarity, and diagnostic insight. Leveraging these datasets, we develop LLaSA (Large Language and Sensor Assistant), a family of compact sensor-aware language models (7B and 13B) that generate interpretable, context-rich responses to open-ended questions grounded in raw IMU data. LLaSA outperforms commercial LLMs, including GPT-3.5 and GPT-4o-mini, on benchmark and real-world tasks, demonstrating the effectiveness of domain supervision and model alignment for sensor reasoning. Our code repository and datasets can be found at https://github.com/BASHLab/LLaSA.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì›¨ì–´ëŸ¬ë¸” ì‹œìŠ¤í…œì˜ IMU ë°ì´í„°ë¥¼ í™œìš©í•œ í™œë™ ì¸ì‹ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ë‘ ê°€ì§€ ëŒ€ê·œëª¨ ìì›ì¸ SensorCapê³¼ OpenSQAë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. SensorCapì€ 35,960ê°œì˜ IMU-ìº¡ì…˜ ìŒìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, OpenSQAëŠ” 199,701ê°œì˜ ì§ˆë¬¸-ë‹µë³€ ìŒì„ í¬í•¨í•˜ì—¬ ì¸ê³¼ì  ë° ì„¤ëª…ì  ì¶”ë¡ ì„ ë•ìŠµë‹ˆë‹¤. ì´ ë°ì´í„°ë¥¼ í™œìš©í•´ ê°œë°œëœ LLaSAëŠ” 7B ë° 13B í¬ê¸°ì˜ ì„¼ì„œ ì¸ì‹ ì–¸ì–´ ëª¨ë¸ë¡œ, IMU ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•´ì„ ê°€ëŠ¥í•˜ê³  ë§¥ë½ì´ í’ë¶€í•œ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤. LLaSAëŠ” GPT-3.5 ë° GPT-4o-mini ë“± ìƒì—…ì  LLMì„ ëŠ¥ê°€í•˜ë©°, ì„¼ì„œ ì¶”ë¡ ì— ìˆì–´ ë„ë©”ì¸ ê°ë…ê³¼ ëª¨ë¸ ì •ë ¬ì˜ íš¨ê³¼ë¥¼ ì…ì¦í•©ë‹ˆë‹¤. ì½”ë“œì™€ ë°ì´í„°ì…‹ì€ GitHubì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. IMU ë°ì´í„°ë¥¼ í™œìš©í•œ í™œë™ ì¸ì‹ ì‹œìŠ¤í…œì€ ì›ì¸ì´ë‚˜ ë§¥ë½ì  ì¤‘ìš”ì„±ì„ ì„¤ëª…í•˜ëŠ” ë° í•œê³„ê°€ ìˆë‹¤.
- 2. SensorCapê³¼ OpenSQAë¼ëŠ” ë‘ ê°€ì§€ ëŒ€ê·œëª¨ ìì›ì„ ì†Œê°œí•˜ì—¬ ì´ëŸ¬í•œ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³ ì í•œë‹¤.
- 3. LLaSAëŠ” ì›ì‹œ IMU ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•´ì„ ê°€ëŠ¥í•˜ê³  ë§¥ë½ì´ í’ë¶€í•œ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì„¼ì„œ ì¸ì‹ ì–¸ì–´ ëª¨ë¸ì´ë‹¤.
- 4. LLaSAëŠ” GPT-3.5 ë° GPT-4o-minië¥¼ í¬í•¨í•œ ìƒìš© LLMì„ ëŠ¥ê°€í•˜ëŠ” ì„±ëŠ¥ì„ ë³´ì¸ë‹¤.
- 5. ì—°êµ¬ì˜ ì½”ë“œì™€ ë°ì´í„°ì…‹ì€ https://github.com/BASHLab/LLaSAì—ì„œ í™•ì¸í•  ìˆ˜ ìˆë‹¤.


---

*Generated on 2025-09-24 03:42:51*