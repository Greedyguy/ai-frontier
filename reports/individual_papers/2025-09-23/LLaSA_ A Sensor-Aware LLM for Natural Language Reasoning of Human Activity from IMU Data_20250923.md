---
keywords:
  - Sensor-Aware Language Model
  - Inertial Measurement Unit Data
  - Open Sensor Question Answering
  - Causal Reasoning
  - Sensor Caption Dataset
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2406.14498
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:42:51.899758",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Sensor-Aware Language Model",
    "Inertial Measurement Unit Data",
    "Open Sensor Question Answering",
    "Causal Reasoning",
    "Sensor Caption Dataset"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Sensor-Aware Language Model": 0.82,
    "Inertial Measurement Unit Data": 0.75,
    "Open Sensor Question Answering": 0.79,
    "Causal Reasoning": 0.78,
    "Sensor Caption Dataset": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "LLaSA",
        "canonical": "Sensor-Aware Language Model",
        "aliases": [
          "Large Language and Sensor Assistant"
        ],
        "category": "unique_technical",
        "rationale": "LLaSA represents a novel integration of language models with sensor data, offering unique insights into sensor reasoning.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.88,
        "link_intent_score": 0.82
      },
      {
        "surface": "IMU data",
        "canonical": "Inertial Measurement Unit Data",
        "aliases": [
          "IMU"
        ],
        "category": "specific_connectable",
        "rationale": "IMU data is central to the paper's focus on human activity recognition, providing a key data source for sensor-aware models.",
        "novelty_score": 0.55,
        "connectivity_score": 0.78,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      },
      {
        "surface": "OpenSQA",
        "canonical": "Open Sensor Question Answering",
        "aliases": [
          "OpenSQA dataset"
        ],
        "category": "unique_technical",
        "rationale": "OpenSQA is a specialized dataset designed for causal reasoning, enhancing the model's explanatory capabilities.",
        "novelty_score": 0.72,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.79
      },
      {
        "surface": "causal and explanatory reasoning",
        "canonical": "Causal Reasoning",
        "aliases": [
          "explanatory reasoning"
        ],
        "category": "specific_connectable",
        "rationale": "Causal reasoning is a critical component of the model's ability to interpret sensor data beyond mere activity recognition.",
        "novelty_score": 0.6,
        "connectivity_score": 0.82,
        "specificity_score": 0.77,
        "link_intent_score": 0.78
      },
      {
        "surface": "SensorCap",
        "canonical": "Sensor Caption Dataset",
        "aliases": [
          "SensorCap dataset"
        ],
        "category": "unique_technical",
        "rationale": "SensorCap provides a large-scale resource for training models on sensor data, crucial for developing sensor-aware language models.",
        "novelty_score": 0.7,
        "connectivity_score": 0.68,
        "specificity_score": 0.84,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "wearable systems",
      "benchmark tasks"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "LLaSA",
      "resolved_canonical": "Sensor-Aware Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.88,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "IMU data",
      "resolved_canonical": "Inertial Measurement Unit Data",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.78,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "OpenSQA",
      "resolved_canonical": "Open Sensor Question Answering",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "causal and explanatory reasoning",
      "resolved_canonical": "Causal Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.82,
        "specificity": 0.77,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "SensorCap",
      "resolved_canonical": "Sensor Caption Dataset",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.68,
        "specificity": 0.84,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# LLaSA: A Sensor-Aware LLM for Natural Language Reasoning of Human Activity from IMU Data

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2406.14498.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2406.14498](https://arxiv.org/abs/2406.14498)

## 🔗 유사한 논문
- [[2025-09-23/Question Answering with LLMs and Learning from Answer Sets_20250923|Question Answering with LLMs and Learning from Answer Sets]] (84.1% similar)
- [[2025-09-19/Large Multi-modal Models Can Interpret Features in Large Multi-modal Models_20250919|Large Multi-modal Models Can Interpret Features in Large Multi-modal Models]] (83.6% similar)
- [[2025-09-23/UR$^2$_ Unify RAG and Reasoning through Reinforcement Learning_20250923|UR$^2$: Unify RAG and Reasoning through Reinforcement Learning]] (82.6% similar)
- [[2025-09-19/SWE-QA_ Can Language Models Answer Repository-level Code Questions?_20250919|SWE-QA: Can Language Models Answer Repository-level Code Questions?]] (82.4% similar)
- [[2025-09-22/Quantifying Self-Awareness of Knowledge in Large Language Models_20250922|Quantifying Self-Awareness of Knowledge in Large Language Models]] (82.2% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Inertial Measurement Unit Data|Inertial Measurement Unit Data]], [[keywords/Causal Reasoning|Causal Reasoning]]
**⚡ Unique Technical**: [[keywords/Sensor-Aware Language Model|Sensor-Aware Language Model]], [[keywords/Open Sensor Question Answering|Open Sensor Question Answering]], [[keywords/Sensor Caption Dataset|Sensor Caption Dataset]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2406.14498v4 Announce Type: replace 
Abstract: Wearable systems can recognize activities from IMU data but often fail to explain their underlying causes or contextual significance. To address this limitation, we introduce two large-scale resources: SensorCap, comprising 35,960 IMU--caption pairs, and OpenSQA, with 199,701 question--answer pairs designed for causal and explanatory reasoning. OpenSQA includes a curated tuning split (Tune-OpenSQA) optimized for scientific accuracy, narrative clarity, and diagnostic insight. Leveraging these datasets, we develop LLaSA (Large Language and Sensor Assistant), a family of compact sensor-aware language models (7B and 13B) that generate interpretable, context-rich responses to open-ended questions grounded in raw IMU data. LLaSA outperforms commercial LLMs, including GPT-3.5 and GPT-4o-mini, on benchmark and real-world tasks, demonstrating the effectiveness of domain supervision and model alignment for sensor reasoning. Our code repository and datasets can be found at https://github.com/BASHLab/LLaSA.

## 📝 요약

이 논문은 웨어러블 시스템의 IMU 데이터를 활용한 활동 인식의 한계를 극복하기 위해 두 가지 대규모 자원인 SensorCap과 OpenSQA를 소개합니다. SensorCap은 35,960개의 IMU-캡션 쌍으로 구성되어 있으며, OpenSQA는 199,701개의 질문-답변 쌍을 포함하여 인과적 및 설명적 추론을 돕습니다. 이 데이터를 활용해 개발된 LLaSA는 7B 및 13B 크기의 센서 인식 언어 모델로, IMU 데이터를 기반으로 해석 가능하고 맥락이 풍부한 응답을 생성합니다. LLaSA는 GPT-3.5 및 GPT-4o-mini 등 상업적 LLM을 능가하며, 센서 추론에 있어 도메인 감독과 모델 정렬의 효과를 입증합니다. 코드와 데이터셋은 GitHub에서 확인할 수 있습니다.

## 🎯 주요 포인트

- 1. IMU 데이터를 활용한 활동 인식 시스템은 원인이나 맥락적 중요성을 설명하는 데 한계가 있다.
- 2. SensorCap과 OpenSQA라는 두 가지 대규모 자원을 소개하여 이러한 한계를 극복하고자 한다.
- 3. LLaSA는 원시 IMU 데이터를 바탕으로 해석 가능하고 맥락이 풍부한 응답을 생성하는 센서 인식 언어 모델이다.
- 4. LLaSA는 GPT-3.5 및 GPT-4o-mini를 포함한 상용 LLM을 능가하는 성능을 보인다.
- 5. 연구의 코드와 데이터셋은 https://github.com/BASHLab/LLaSA에서 확인할 수 있다.


---

*Generated on 2025-09-24 03:42:51*