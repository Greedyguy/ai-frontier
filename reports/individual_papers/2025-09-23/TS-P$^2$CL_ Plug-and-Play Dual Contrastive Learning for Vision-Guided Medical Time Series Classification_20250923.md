---
keywords:
  - Medical Time Series Classification
  - Vision-Guided Paradigm
  - Self-supervised Learning
  - Multimodal Learning
  - Domain-Invariant Features
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.17802
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T00:10:20.184927",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Medical Time Series Classification",
    "Vision-Guided Paradigm",
    "Self-supervised Learning",
    "Multimodal Learning",
    "Domain-Invariant Features"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Medical Time Series Classification": 0.78,
    "Vision-Guided Paradigm": 0.77,
    "Self-supervised Learning": 0.8,
    "Multimodal Learning": 0.82,
    "Domain-Invariant Features": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Medical Time Series Classification",
        "canonical": "Medical Time Series Classification",
        "aliases": [
          "MedTS Classification"
        ],
        "category": "unique_technical",
        "rationale": "This is a specific task within healthcare analytics, crucial for linking to domain-specific research.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Vision-Guided Paradigm",
        "canonical": "Vision-Guided Paradigm",
        "aliases": [
          "Vision-Guided Approach"
        ],
        "category": "unique_technical",
        "rationale": "This represents a novel approach that bridges vision models with time series data, enhancing interdisciplinary links.",
        "novelty_score": 0.82,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      },
      {
        "surface": "Dual Contrastive Learning",
        "canonical": "Self-supervised Learning",
        "aliases": [
          "Dual Contrastive Learning"
        ],
        "category": "specific_connectable",
        "rationale": "This method aligns with self-supervised learning techniques, enabling connections to broader machine learning frameworks.",
        "novelty_score": 0.68,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Cross-Modal Alignment",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Cross-Modal Alignment"
        ],
        "category": "specific_connectable",
        "rationale": "This concept is key in multimodal learning, facilitating connections across different data modalities.",
        "novelty_score": 0.7,
        "connectivity_score": 0.88,
        "specificity_score": 0.75,
        "link_intent_score": 0.82
      },
      {
        "surface": "Domain-Invariant Features",
        "canonical": "Domain-Invariant Features",
        "aliases": [
          "Domain-Invariant Representations"
        ],
        "category": "unique_technical",
        "rationale": "This concept is critical for transfer learning and cross-domain applications, linking to robust feature learning.",
        "novelty_score": 0.78,
        "connectivity_score": 0.72,
        "specificity_score": 0.82,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Medical Time Series Classification",
      "resolved_canonical": "Medical Time Series Classification",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Vision-Guided Paradigm",
      "resolved_canonical": "Vision-Guided Paradigm",
      "decision": "linked",
      "scores": {
        "novelty": 0.82,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Dual Contrastive Learning",
      "resolved_canonical": "Self-supervised Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Cross-Modal Alignment",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.88,
        "specificity": 0.75,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Domain-Invariant Features",
      "resolved_canonical": "Domain-Invariant Features",
      "decision": "linked",
      "scores": {
        "novelty": 0.78,
        "connectivity": 0.72,
        "specificity": 0.82,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# TS-P$^2$CL: Plug-and-Play Dual Contrastive Learning for Vision-Guided Medical Time Series Classification

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17802.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.17802](https://arxiv.org/abs/2509.17802)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Channel-Imposed Fusion_ A Simple yet Effective Method for Medical Time Series Classification_20250922|Channel-Imposed Fusion: A Simple yet Effective Method for Medical Time Series Classification]] (83.9% similar)
- [[2025-09-22/RegionMed-CLIP_ A Region-Aware Multimodal Contrastive Learning Pre-trained Model for Medical Image Understanding_20250922|RegionMed-CLIP: A Region-Aware Multimodal Contrastive Learning Pre-trained Model for Medical Image Understanding]] (83.8% similar)
- [[2025-09-23/Multimodal Medical Image Classification via Synergistic Learning Pre-training_20250923|Multimodal Medical Image Classification via Synergistic Learning Pre-training]] (82.6% similar)
- [[2025-09-18/Taylor-Series Expanded Kolmogorov-Arnold Network for Medical Imaging Classification_20250918|Taylor-Series Expanded Kolmogorov-Arnold Network for Medical Imaging Classification]] (82.1% similar)
- [[2025-09-22/CLIPTTA_ Robust Contrastive Vision-Language Test-Time Adaptation_20250922|CLIPTTA: Robust Contrastive Vision-Language Test-Time Adaptation]] (82.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Self-supervised Learning|Self-supervised Learning]], [[keywords/Multimodal Learning|Multimodal Learning]]
**âš¡ Unique Technical**: [[keywords/Medical Time Series Classification|Medical Time Series Classification]], [[keywords/Vision-Guided Paradigm|Vision-Guided Paradigm]], [[keywords/Domain-Invariant Features|Domain-Invariant Features]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17802v1 Announce Type: cross 
Abstract: Medical time series (MedTS) classification is pivotal for intelligent healthcare, yet its efficacy is severely limited by poor cross-subject generation due to the profound cross-individual heterogeneity. Despite advances in architectural innovations and transfer learning techniques, current methods remain constrained by modality-specific inductive biases that limit their ability to learn universally invariant representations. To overcome this, we propose TS-P$^2$CL, a novel plug-and-play framework that leverages the universal pattern recognition capabilities of pre-trained vision models. We introduce a vision-guided paradigm that transforms 1D physiological signals into 2D pseudo-images, establishing a bridge to the visual domain. This transformation enables implicit access to rich semantic priors learned from natural images. Within this unified space, we employ a dual-contrastive learning strategy: intra-modal consistency enforces temporal coherence, while cross-modal alignment aligns time-series dynamics with visual semantics, thereby mitigating individual-specific biases and learning robust, domain-invariant features. Extensive experiments on six MedTS datasets demonstrate that TS-P$^2$CL consistently outperforms fourteen methods in both subject-dependent and subject-independent settings.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì˜ë£Œ ì‹œê³„ì—´(MedTS) ë¶„ë¥˜ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ TS-P$^2$CLì´ë¼ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ ë°©ë²•ë“¤ì´ ê°œë³„ì  í¸í–¥ìœ¼ë¡œ ì¸í•´ ë³´í¸ì ì¸ í‘œí˜„ í•™ìŠµì— í•œê³„ê°€ ìˆëŠ” ë°˜ë©´, TS-P$^2$CLì€ ì‚¬ì „ í•™ìŠµëœ ë¹„ì „ ëª¨ë¸ì˜ íŒ¨í„´ ì¸ì‹ ëŠ¥ë ¥ì„ í™œìš©í•©ë‹ˆë‹¤. 1D ìƒë¦¬ ì‹ í˜¸ë¥¼ 2D ê°€ìƒ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ì—¬ ì‹œê°ì  ë„ë©”ì¸ê³¼ ì—°ê²°í•˜ê³ , ì´ í†µí•©ëœ ê³µê°„ì—ì„œ ì´ì¤‘ ëŒ€ì¡° í•™ìŠµ ì „ëµì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ëŠ” ì‹œê³„ì—´ì˜ ì‹œê°„ì  ì¼ê´€ì„±ì„ ìœ ì§€í•˜ê³ , ì‹œê°ì  ì˜ë¯¸ì™€ì˜ ì •ë ¬ì„ í†µí•´ ê°œë³„ì  í¸í–¥ì„ ì¤„ì´ë©° ê°•ë ¥í•œ ë„ë©”ì¸ ë¶ˆë³€ íŠ¹ì§•ì„ í•™ìŠµí•©ë‹ˆë‹¤. ì—¬ì„¯ ê°œì˜ MedTS ë°ì´í„°ì…‹ ì‹¤í—˜ ê²°ê³¼, TS-P$^2$CLì€ ì£¼ì œ ì˜ì¡´ ë° ë…ë¦½ ì„¤ì • ëª¨ë‘ì—ì„œ 14ê°€ì§€ ë°©ë²•ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì˜ë£Œ ì‹œê³„ì—´ ë¶„ë¥˜ëŠ” ê°œë³„ì  ì´ì§ˆì„±ìœ¼ë¡œ ì¸í•´ êµì°¨ ì£¼ì²´ ìƒì„±ì´ ì–´ë ¤ì›Œ ê·¸ íš¨ìœ¨ì„±ì´ ì œí•œë©ë‹ˆë‹¤.
- 2. TS-P$^2$CLì€ ì‚¬ì „ í•™ìŠµëœ ë¹„ì „ ëª¨ë¸ì˜ íŒ¨í„´ ì¸ì‹ ëŠ¥ë ¥ì„ í™œìš©í•˜ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.
- 3. 1D ìƒë¦¬ ì‹ í˜¸ë¥¼ 2D ì˜ì‚¬ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ì—¬ ì‹œê°ì  ë„ë©”ì¸ê³¼ì˜ ì—°ê²°ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.
- 4. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ì‹œê°„ì  ì¼ê´€ì„±ì„ ìœ ì§€í•˜ê³  ì‹œê³„ì—´ ì—­í•™ì„ ì‹œê°ì  ì˜ë¯¸ì™€ ì •ë ¬í•˜ì—¬ ê°œì¸ë³„ í¸í–¥ì„ ì™„í™”í•©ë‹ˆë‹¤.
- 5. ì—¬ì„¯ ê°œì˜ MedTS ë°ì´í„°ì…‹ì— ëŒ€í•œ ì‹¤í—˜ì—ì„œ TS-P$^2$CLì€ ì£¼ì²´ ì˜ì¡´ ë° ë…ë¦½ ì„¤ì • ëª¨ë‘ì—ì„œ 14ê°œ ë°©ë²•ì„ ëŠ¥ê°€í–ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 00:10:20*