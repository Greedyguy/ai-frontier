---
keywords:
  - Medical Time Series Classification
  - Vision-Guided Paradigm
  - Self-supervised Learning
  - Multimodal Learning
  - Domain-Invariant Features
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.17802
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T00:10:20.184927",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Medical Time Series Classification",
    "Vision-Guided Paradigm",
    "Self-supervised Learning",
    "Multimodal Learning",
    "Domain-Invariant Features"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Medical Time Series Classification": 0.78,
    "Vision-Guided Paradigm": 0.77,
    "Self-supervised Learning": 0.8,
    "Multimodal Learning": 0.82,
    "Domain-Invariant Features": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Medical Time Series Classification",
        "canonical": "Medical Time Series Classification",
        "aliases": [
          "MedTS Classification"
        ],
        "category": "unique_technical",
        "rationale": "This is a specific task within healthcare analytics, crucial for linking to domain-specific research.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Vision-Guided Paradigm",
        "canonical": "Vision-Guided Paradigm",
        "aliases": [
          "Vision-Guided Approach"
        ],
        "category": "unique_technical",
        "rationale": "This represents a novel approach that bridges vision models with time series data, enhancing interdisciplinary links.",
        "novelty_score": 0.82,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      },
      {
        "surface": "Dual Contrastive Learning",
        "canonical": "Self-supervised Learning",
        "aliases": [
          "Dual Contrastive Learning"
        ],
        "category": "specific_connectable",
        "rationale": "This method aligns with self-supervised learning techniques, enabling connections to broader machine learning frameworks.",
        "novelty_score": 0.68,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Cross-Modal Alignment",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Cross-Modal Alignment"
        ],
        "category": "specific_connectable",
        "rationale": "This concept is key in multimodal learning, facilitating connections across different data modalities.",
        "novelty_score": 0.7,
        "connectivity_score": 0.88,
        "specificity_score": 0.75,
        "link_intent_score": 0.82
      },
      {
        "surface": "Domain-Invariant Features",
        "canonical": "Domain-Invariant Features",
        "aliases": [
          "Domain-Invariant Representations"
        ],
        "category": "unique_technical",
        "rationale": "This concept is critical for transfer learning and cross-domain applications, linking to robust feature learning.",
        "novelty_score": 0.78,
        "connectivity_score": 0.72,
        "specificity_score": 0.82,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Medical Time Series Classification",
      "resolved_canonical": "Medical Time Series Classification",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Vision-Guided Paradigm",
      "resolved_canonical": "Vision-Guided Paradigm",
      "decision": "linked",
      "scores": {
        "novelty": 0.82,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Dual Contrastive Learning",
      "resolved_canonical": "Self-supervised Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Cross-Modal Alignment",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.88,
        "specificity": 0.75,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Domain-Invariant Features",
      "resolved_canonical": "Domain-Invariant Features",
      "decision": "linked",
      "scores": {
        "novelty": 0.78,
        "connectivity": 0.72,
        "specificity": 0.82,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# TS-P$^2$CL: Plug-and-Play Dual Contrastive Learning for Vision-Guided Medical Time Series Classification

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17802.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.17802](https://arxiv.org/abs/2509.17802)

## 🔗 유사한 논문
- [[2025-09-22/Channel-Imposed Fusion_ A Simple yet Effective Method for Medical Time Series Classification_20250922|Channel-Imposed Fusion: A Simple yet Effective Method for Medical Time Series Classification]] (83.9% similar)
- [[2025-09-22/RegionMed-CLIP_ A Region-Aware Multimodal Contrastive Learning Pre-trained Model for Medical Image Understanding_20250922|RegionMed-CLIP: A Region-Aware Multimodal Contrastive Learning Pre-trained Model for Medical Image Understanding]] (83.8% similar)
- [[2025-09-23/Multimodal Medical Image Classification via Synergistic Learning Pre-training_20250923|Multimodal Medical Image Classification via Synergistic Learning Pre-training]] (82.6% similar)
- [[2025-09-18/Taylor-Series Expanded Kolmogorov-Arnold Network for Medical Imaging Classification_20250918|Taylor-Series Expanded Kolmogorov-Arnold Network for Medical Imaging Classification]] (82.1% similar)
- [[2025-09-22/CLIPTTA_ Robust Contrastive Vision-Language Test-Time Adaptation_20250922|CLIPTTA: Robust Contrastive Vision-Language Test-Time Adaptation]] (82.0% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Self-supervised Learning|Self-supervised Learning]], [[keywords/Multimodal Learning|Multimodal Learning]]
**⚡ Unique Technical**: [[keywords/Medical Time Series Classification|Medical Time Series Classification]], [[keywords/Vision-Guided Paradigm|Vision-Guided Paradigm]], [[keywords/Domain-Invariant Features|Domain-Invariant Features]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.17802v1 Announce Type: cross 
Abstract: Medical time series (MedTS) classification is pivotal for intelligent healthcare, yet its efficacy is severely limited by poor cross-subject generation due to the profound cross-individual heterogeneity. Despite advances in architectural innovations and transfer learning techniques, current methods remain constrained by modality-specific inductive biases that limit their ability to learn universally invariant representations. To overcome this, we propose TS-P$^2$CL, a novel plug-and-play framework that leverages the universal pattern recognition capabilities of pre-trained vision models. We introduce a vision-guided paradigm that transforms 1D physiological signals into 2D pseudo-images, establishing a bridge to the visual domain. This transformation enables implicit access to rich semantic priors learned from natural images. Within this unified space, we employ a dual-contrastive learning strategy: intra-modal consistency enforces temporal coherence, while cross-modal alignment aligns time-series dynamics with visual semantics, thereby mitigating individual-specific biases and learning robust, domain-invariant features. Extensive experiments on six MedTS datasets demonstrate that TS-P$^2$CL consistently outperforms fourteen methods in both subject-dependent and subject-independent settings.

## 📝 요약

이 논문은 의료 시계열(MedTS) 분류의 한계를 극복하기 위해 TS-P$^2$CL이라는 새로운 프레임워크를 제안합니다. 기존 방법들이 개별적 편향으로 인해 보편적인 표현 학습에 한계가 있는 반면, TS-P$^2$CL은 사전 학습된 비전 모델의 패턴 인식 능력을 활용합니다. 1D 생리 신호를 2D 가상 이미지로 변환하여 시각적 도메인과 연결하고, 이 통합된 공간에서 이중 대조 학습 전략을 사용합니다. 이는 시계열의 시간적 일관성을 유지하고, 시각적 의미와의 정렬을 통해 개별적 편향을 줄이며 강력한 도메인 불변 특징을 학습합니다. 여섯 개의 MedTS 데이터셋 실험 결과, TS-P$^2$CL은 주제 의존 및 독립 설정 모두에서 14가지 방법보다 우수한 성능을 보였습니다.

## 🎯 주요 포인트

- 1. 의료 시계열 분류는 개별적 이질성으로 인해 교차 주체 생성이 어려워 그 효율성이 제한됩니다.
- 2. TS-P$^2$CL은 사전 학습된 비전 모델의 패턴 인식 능력을 활용하는 새로운 프레임워크입니다.
- 3. 1D 생리 신호를 2D 의사 이미지로 변환하여 시각적 도메인과의 연결을 구축합니다.
- 4. 이 프레임워크는 시간적 일관성을 유지하고 시계열 역학을 시각적 의미와 정렬하여 개인별 편향을 완화합니다.
- 5. 여섯 개의 MedTS 데이터셋에 대한 실험에서 TS-P$^2$CL은 주체 의존 및 독립 설정 모두에서 14개 방법을 능가했습니다.


---

*Generated on 2025-09-24 00:10:20*