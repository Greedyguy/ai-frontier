---
keywords:
  - Perception-Aware Reinforcement Learning
  - Autonomous Inspection
  - Machine Learning
  - Target Visibility
category: cs.CV
publish_date: 2025-09-23
arxiv_id: 2509.17877
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T05:12:51.091759",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Perception-Aware Reinforcement Learning",
    "Autonomous Inspection",
    "Machine Learning",
    "Target Visibility"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Perception-Aware Reinforcement Learning": 0.78,
    "Autonomous Inspection": 0.77,
    "Machine Learning": 0.7,
    "Target Visibility": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Perception-Aware Reinforcement Learning",
        "canonical": "Perception-Aware Reinforcement Learning",
        "aliases": [
          "Perception-Driven Reinforcement Learning"
        ],
        "category": "unique_technical",
        "rationale": "This concept integrates perception into reinforcement learning, which is central to the paper's approach and novel in its application to robotic inspection.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Autonomous Inspection",
        "canonical": "Autonomous Inspection",
        "aliases": [
          "Automated Inspection"
        ],
        "category": "unique_technical",
        "rationale": "This term encapsulates the primary application domain of the research, linking it to broader robotics and automation contexts.",
        "novelty_score": 0.65,
        "connectivity_score": 0.72,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      },
      {
        "surface": "Reinforcement Learning",
        "canonical": "Machine Learning",
        "aliases": [
          "RL"
        ],
        "category": "broad_technical",
        "rationale": "Reinforcement learning is a fundamental machine learning approach used in the paper, connecting it to a broad range of AI research.",
        "novelty_score": 0.4,
        "connectivity_score": 0.85,
        "specificity_score": 0.6,
        "link_intent_score": 0.7
      },
      {
        "surface": "Target Visibility",
        "canonical": "Target Visibility",
        "aliases": [
          "Visibility of Target"
        ],
        "category": "unique_technical",
        "rationale": "This is a key concept in the paper's methodology, focusing on the visibility aspect of inspection tasks.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.78,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "navigation tasks",
      "real-world environments",
      "simulation"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Perception-Aware Reinforcement Learning",
      "resolved_canonical": "Perception-Aware Reinforcement Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Autonomous Inspection",
      "resolved_canonical": "Autonomous Inspection",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.72,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Reinforcement Learning",
      "resolved_canonical": "Machine Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.85,
        "specificity": 0.6,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Target Visibility",
      "resolved_canonical": "Target Visibility",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.78,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Sight Over Site: Perception-Aware Reinforcement Learning for Efficient Robotic Inspection

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17877.pdf)
**Category**: cs.CV
**Published**: 2025-09-23
**ArXiv ID**: [2509.17877](https://arxiv.org/abs/2509.17877)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Semantic Exploration and Dense Mapping of Complex Environments using Ground Robot with Panoramic LiDAR-Camera Fusion_20250919|Semantic Exploration and Dense Mapping of Complex Environments using Ground Robot with Panoramic LiDAR-Camera Fusion]] (85.4% similar)
- [[2025-09-22/Dynamic Neural Curiosity Enhances Learning Flexibility for Autonomous Goal Discovery_20250922|Dynamic Neural Curiosity Enhances Learning Flexibility for Autonomous Goal Discovery]] (84.6% similar)
- [[2025-09-19/Learning Discrete Abstractions for Visual Rearrangement Tasks Using Vision-Guided Graph Coloring_20250919|Learning Discrete Abstractions for Visual Rearrangement Tasks Using Vision-Guided Graph Coloring]] (84.1% similar)
- [[2025-09-18/Reinforcement Learning for Autonomous Point-to-Point UAV Navigation_20250918|Reinforcement Learning for Autonomous Point-to-Point UAV Navigation]] (83.3% similar)
- [[2025-09-19/Digital Twin-based Cooperative Autonomous Driving in Smart Intersections_ A Multi-Agent Reinforcement Learning Approach_20250919|Digital Twin-based Cooperative Autonomous Driving in Smart Intersections: A Multi-Agent Reinforcement Learning Approach]] (83.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Machine Learning|Machine Learning]]
**âš¡ Unique Technical**: [[keywords/Perception-Aware Reinforcement Learning|Perception-Aware Reinforcement Learning]], [[keywords/Autonomous Inspection|Autonomous Inspection]], [[keywords/Target Visibility|Target Visibility]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17877v1 Announce Type: cross 
Abstract: Autonomous inspection is a central problem in robotics, with applications ranging from industrial monitoring to search-and-rescue. Traditionally, inspection has often been reduced to navigation tasks, where the objective is to reach a predefined location while avoiding obstacles. However, this formulation captures only part of the real inspection problem. In real-world environments, the inspection targets may become visible well before their exact coordinates are reached, making further movement both redundant and inefficient. What matters more for inspection is not simply arriving at the target's position, but positioning the robot at a viewpoint from which the target becomes observable. In this work, we revisit inspection from a perception-aware perspective. We propose an end-to-end reinforcement learning framework that explicitly incorporates target visibility as the primary objective, enabling the robot to find the shortest trajectory that guarantees visual contact with the target without relying on a map. The learned policy leverages both perceptual and proprioceptive sensing and is trained entirely in simulation, before being deployed to a real-world robot. We further develop an algorithm to compute ground-truth shortest inspection paths, which provides a reference for evaluation. Through extensive experiments, we show that our method outperforms existing classical and learning-based navigation approaches, yielding more efficient inspection trajectories in both simulated and real-world settings. The project is avialable at https://sight-over-site.github.io/

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ììœ¨ ë¡œë´‡ì˜ ê²€ì‚¬ ë¬¸ì œë¥¼ ìƒˆë¡œìš´ ì‹œê°ì—ì„œ ì ‘ê·¼í•˜ì—¬, ëª©í‘œë¬¼ì˜ ê°€ì‹œì„±ì„ ìµœìš°ì„ ìœ¼ë¡œ ê³ ë ¤í•˜ëŠ” ê°•í™” í•™ìŠµ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì „í†µì ì¸ íƒìƒ‰ ë°©ì‹ì€ ëª©í‘œ ì§€ì ì— ë„ë‹¬í•˜ëŠ” ê²ƒì„ ì¤‘ì‹œí•˜ì§€ë§Œ, ì´ ì—°êµ¬ëŠ” ëª©í‘œë¬¼ì´ ë³´ì´ëŠ” ìµœì ì˜ ìœ„ì¹˜ë¥¼ ì°¾ëŠ” ê²ƒì´ ë” ì¤‘ìš”í•˜ë‹¤ê³  ì£¼ì¥í•©ë‹ˆë‹¤. ì œì•ˆëœ ë°©ë²•ì€ ì§€ë„ ì—†ì´ë„ ëª©í‘œë¬¼ê³¼ì˜ ì‹œê°ì  ì ‘ì´‰ì„ ë³´ì¥í•˜ëŠ” ìµœë‹¨ ê²½ë¡œë¥¼ ì°¾ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½ì—ì„œ í•™ìŠµëœ ì •ì±…ì„ ì‹¤ì œ ë¡œë´‡ì— ì ìš©í•˜ì˜€ê³ , ì‹¤í—˜ ê²°ê³¼ ê¸°ì¡´ì˜ íƒìƒ‰ ë°©ë²•ë“¤ë³´ë‹¤ ë” íš¨ìœ¨ì ì¸ ê²½ë¡œë¥¼ ì œê³µí•¨ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ììœ¨ ê²€ì‚¬ ë¬¸ì œëŠ” ì „í†µì ìœ¼ë¡œ ëª©í‘œ ì§€ì ì— ë„ë‹¬í•˜ëŠ” ë‚´ë¹„ê²Œì´ì…˜ ë¬¸ì œë¡œ ê°„ì£¼ë˜ì—ˆìœ¼ë‚˜, ì‹¤ì œë¡œëŠ” ëª©í‘œë¥¼ ê´€ì°°í•  ìˆ˜ ìˆëŠ” ìœ„ì¹˜ì— ë¡œë´‡ì„ ë°°ì¹˜í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤.
- 2. ë³¸ ì—°êµ¬ëŠ” ëª©í‘œ ê°€ì‹œì„±ì„ ì£¼ìš” ëª©í‘œë¡œ í•˜ëŠ” ê°•í™” í•™ìŠµ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•˜ì—¬, ì§€ë„ ì—†ì´ë„ ëª©í‘œë¥¼ ì‹œê°ì ìœ¼ë¡œ ê´€ì°°í•  ìˆ˜ ìˆëŠ” ìµœë‹¨ ê²½ë¡œë¥¼ ì°¾ë„ë¡ í•œë‹¤.
- 3. ì œì•ˆëœ ì •ì±…ì€ ì§€ê° ë° ê³ ìœ  ê°ê°ì„ í™œìš©í•˜ë©°, ì‹œë®¬ë ˆì´ì…˜ì—ì„œ í›ˆë ¨ëœ í›„ ì‹¤ì œ ë¡œë´‡ì— ì ìš©ëœë‹¤.
- 4. ë³¸ ì—°êµ¬ëŠ” ìµœë‹¨ ê²€ì‚¬ ê²½ë¡œë¥¼ ê³„ì‚°í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì„ ê°œë°œí•˜ì—¬ í‰ê°€ ê¸°ì¤€ì„ ì œê³µí•œë‹¤.
- 5. ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì€ ê¸°ì¡´ì˜ ë‚´ë¹„ê²Œì´ì…˜ ì ‘ê·¼ ë°©ì‹ì„ ëŠ¥ê°€í•˜ì—¬ ë” íš¨ìœ¨ì ì¸ ê²€ì‚¬ ê²½ë¡œë¥¼ ì œê³µí•œë‹¤.


---

*Generated on 2025-09-24 05:12:51*