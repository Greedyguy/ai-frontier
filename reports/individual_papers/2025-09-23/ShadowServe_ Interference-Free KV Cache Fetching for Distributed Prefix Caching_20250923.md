---
keywords:
  - Distributed Prefix Caching
  - Key-Value Cache
  - Smart Network Interface Card
  - Large Language Model Serving
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.16857
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T23:35:50.155996",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Distributed Prefix Caching",
    "Key-Value Cache",
    "Smart Network Interface Card",
    "Large Language Model Serving"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Distributed Prefix Caching": 0.78,
    "Key-Value Cache": 0.8,
    "Smart Network Interface Card": 0.77,
    "Large Language Model Serving": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Distributed prefix caching",
        "canonical": "Distributed Prefix Caching",
        "aliases": [
          "Prefix Caching",
          "Distributed Caching"
        ],
        "category": "unique_technical",
        "rationale": "This term is central to the paper's contribution and represents a unique approach to optimizing LLM serving.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "KV cache",
        "canonical": "Key-Value Cache",
        "aliases": [
          "KV Cache",
          "Key-Value Store"
        ],
        "category": "specific_connectable",
        "rationale": "Key-Value caching is a specific technique that can be linked to broader caching strategies in distributed systems.",
        "novelty_score": 0.6,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "SmartNIC",
        "canonical": "Smart Network Interface Card",
        "aliases": [
          "SmartNIC",
          "Programmable NIC"
        ],
        "category": "specific_connectable",
        "rationale": "SmartNICs are increasingly relevant in optimizing data plane operations, providing strong connectivity to network optimization topics.",
        "novelty_score": 0.65,
        "connectivity_score": 0.78,
        "specificity_score": 0.75,
        "link_intent_score": 0.77
      },
      {
        "surface": "LLM serving",
        "canonical": "Large Language Model Serving",
        "aliases": [
          "LLM Deployment",
          "Language Model Serving"
        ],
        "category": "broad_technical",
        "rationale": "Serving large language models is a broad technical concept that connects to various deployment strategies.",
        "novelty_score": 0.55,
        "connectivity_score": 0.82,
        "specificity_score": 0.65,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "compression",
      "decompression",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Distributed prefix caching",
      "resolved_canonical": "Distributed Prefix Caching",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "KV cache",
      "resolved_canonical": "Key-Value Cache",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "SmartNIC",
      "resolved_canonical": "Smart Network Interface Card",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.78,
        "specificity": 0.75,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "LLM serving",
      "resolved_canonical": "Large Language Model Serving",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.82,
        "specificity": 0.65,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# ShadowServe: Interference-Free KV Cache Fetching for Distributed Prefix Caching

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16857.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.16857](https://arxiv.org/abs/2509.16857)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Taming Serverless Cold Starts Through OS Co-Design_20250919|Taming Serverless Cold Starts Through OS Co-Design]] (80.3% similar)
- [[2025-09-19/{\lambda}Scale_ Enabling Fast Scaling for Serverless Large Language Model Inference_20250919|{\lambda}Scale: Enabling Fast Scaling for Serverless Large Language Model Inference]] (79.4% similar)
- [[2025-09-22/KVCompose_ Efficient Structured KV Cache Compression with Composite Tokens_20250922|KVCompose: Efficient Structured KV Cache Compression with Composite Tokens]] (79.1% similar)
- [[2025-09-22/ForestColl_ Throughput-Optimal Collective Communications on Heterogeneous Network Fabrics_20250922|ForestColl: Throughput-Optimal Collective Communications on Heterogeneous Network Fabrics]] (78.9% similar)
- [[2025-09-19/MaRVIn_ A Cross-Layer Mixed-Precision RISC-V Framework for DNN Inference, from ISA Extension to Hardware Acceleration_20250919|MaRVIn: A Cross-Layer Mixed-Precision RISC-V Framework for DNN Inference, from ISA Extension to Hardware Acceleration]] (78.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model Serving|Large Language Model Serving]]
**ğŸ”— Specific Connectable**: [[keywords/Key-Value Cache|Key-Value Cache]], [[keywords/Smart Network Interface Card|Smart Network Interface Card]]
**âš¡ Unique Technical**: [[keywords/Distributed Prefix Caching|Distributed Prefix Caching]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16857v1 Announce Type: cross 
Abstract: Distributed prefix caching accelerates long-context LLM serving by reusing KV cache entries for common context prefixes. However, KV cache fetches can become a bottleneck when network bandwidth is limited. Compression mitigates the bandwidth issue, but can degrade overall performance when decompression interferes with model computation.
  We present ShadowServe, the first SmartNIC-accelerated, interference-free prefix caching system for LLM serving. ShadowServe separates a control plane on the host and a data plane fully offloaded to the SmartNIC, which eliminates interference to both host GPU and CPU. To overcome the SmartNIC's limited compute and memory resources, we design a chunked pipeline that parallelizes data plane operations across the SmartNIC's compute resources, and a minimal-copy memory management scheme that reduces memory pressure on the SmartNIC. Compared to state-of-the-art solutions, ShadowServe achieves up to 2.2x lower loaded time-per-output-token (TPOT), and reduces time-to-first-token (TTFT) by up to 1.38x in low-bandwidth scenarios (<= 20 Gbps), translating to up to 1.35x higher throughput.

## ğŸ“ ìš”ì•½

ShadowServeëŠ” LLM ì„œë¹„ìŠ¤ì—ì„œ ê¸´ ë§¥ë½ì„ ê°€ì†í™”í•˜ê¸° ìœ„í•œ SmartNIC ê¸°ë°˜ì˜ ê°„ì„­ ì—†ëŠ” ì ‘ë‘ì‚¬ ìºì‹± ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë¶„ì‚° ì ‘ë‘ì‚¬ ìºì‹±ì€ ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­í­ì´ ì œí•œë  ë•Œ ë³‘ëª© í˜„ìƒì´ ë°œìƒí•  ìˆ˜ ìˆìœ¼ë©°, ì••ì¶•ì€ ëŒ€ì—­í­ ë¬¸ì œë¥¼ ì™„í™”í•˜ì§€ë§Œ ëª¨ë¸ ê³„ì‚°ì— ê°„ì„­ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ShadowServeëŠ” í˜¸ìŠ¤íŠ¸ì˜ ì œì–´ í‰ë©´ê³¼ SmartNICì— ì™„ì „íˆ ì˜¤í”„ë¡œë“œëœ ë°ì´í„° í‰ë©´ì„ ë¶„ë¦¬í•˜ì—¬ ì´ëŸ¬í•œ ê°„ì„­ì„ ì œê±°í•©ë‹ˆë‹¤. SmartNICì˜ ì œí•œëœ ìì›ì„ ê·¹ë³µí•˜ê¸° ìœ„í•´ ë°ì´í„° í‰ë©´ ì‘ì—…ì„ ë³‘ë ¬í™”í•˜ëŠ” ì²­í¬ íŒŒì´í”„ë¼ì¸ê³¼ ë©”ëª¨ë¦¬ ì••ë°•ì„ ì¤„ì´ëŠ” ìµœì†Œ ë³µì‚¬ ë©”ëª¨ë¦¬ ê´€ë¦¬ ë°©ì‹ì„ ì„¤ê³„í–ˆìŠµë‹ˆë‹¤. ShadowServeëŠ” ìµœì‹  ì†”ë£¨ì…˜ ëŒ€ë¹„ ì¶œë ¥ í† í°ë‹¹ ì‹œê°„(TPOT)ì„ ìµœëŒ€ 2.2ë°°, ì²« ë²ˆì§¸ í† í°ê¹Œì§€ì˜ ì‹œê°„(TTFT)ì„ ìµœëŒ€ 1.38ë°° ë‹¨ì¶•í•˜ì—¬ ìµœëŒ€ 1.35ë°° ë†’ì€ ì²˜ë¦¬ëŸ‰ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ShadowServeëŠ” SmartNICì„ í™œìš©í•˜ì—¬ LLM ì„œë¹„ìŠ¤ì—ì„œ ê°„ì„­ ì—†ëŠ” ì ‘ë‘ì‚¬ ìºì‹± ì‹œìŠ¤í…œì„ êµ¬í˜„í•©ë‹ˆë‹¤.
- 2. ShadowServeëŠ” í˜¸ìŠ¤íŠ¸ì˜ ì œì–´ í‰ë©´ê³¼ SmartNICì— ì™„ì „íˆ ì˜¤í”„ë¡œë“œëœ ë°ì´í„° í‰ë©´ì„ ë¶„ë¦¬í•˜ì—¬ GPU ë° CPU ê°„ì„­ì„ ì œê±°í•©ë‹ˆë‹¤.
- 3. ì œí•œëœ SmartNICì˜ ê³„ì‚° ë° ë©”ëª¨ë¦¬ ìì›ì„ ê·¹ë³µí•˜ê¸° ìœ„í•´ ë°ì´í„° í‰ë©´ ì‘ì—…ì„ ë³‘ë ¬í™”í•˜ëŠ” ì²­í¬ íŒŒì´í”„ë¼ì¸ê³¼ ìµœì†Œ ë³µì‚¬ ë©”ëª¨ë¦¬ ê´€ë¦¬ ë°©ì‹ì„ ì„¤ê³„í–ˆìŠµë‹ˆë‹¤.
- 4. ShadowServeëŠ” ìµœì‹  ì†”ë£¨ì…˜ê³¼ ë¹„êµí•˜ì—¬ ìµœëŒ€ 2.2ë°° ë‚®ì€ ì¶œë ¥ í† í°ë‹¹ ë¡œë“œ ì‹œê°„ì„ ë‹¬ì„±í•˜ê³ , ì €ëŒ€ì—­í­ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì²« ë²ˆì§¸ í† í°ê¹Œì§€ì˜ ì‹œê°„ì„ ìµœëŒ€ 1.38ë°° ë‹¨ì¶•í•©ë‹ˆë‹¤.
- 5. ì´ëŸ¬í•œ ê°œì„ ì€ ìµœëŒ€ 1.35ë°° ë†’ì€ ì²˜ë¦¬ëŸ‰ìœ¼ë¡œ ì´ì–´ì§‘ë‹ˆë‹¤.


---

*Generated on 2025-09-23 23:35:50*