---
keywords:
  - Audio-Reasoner
  - Multimodal Learning
  - Audio Modality
  - CoTA Dataset
  - Chain of Thought Process
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2503.02318
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T00:49:30.890692",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Audio-Reasoner",
    "Multimodal Learning",
    "Audio Modality",
    "CoTA Dataset",
    "Chain of Thought Process"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Audio-Reasoner": 0.78,
    "Multimodal Learning": 0.82,
    "Audio Modality": 0.75,
    "CoTA Dataset": 0.77,
    "Chain of Thought Process": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Audio-Reasoner",
        "canonical": "Audio-Reasoner",
        "aliases": [
          "Audio Reasoner"
        ],
        "category": "unique_technical",
        "rationale": "As a novel model specifically designed for audio reasoning, it represents a unique contribution to the field.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.78
      },
      {
        "surface": "multimodal reasoning",
        "canonical": "Multimodal Learning",
        "aliases": [
          "multimodal reasoning"
        ],
        "category": "specific_connectable",
        "rationale": "Links to existing work on integrating multiple data modalities, enhancing connectivity with related research.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.82
      },
      {
        "surface": "audio modality",
        "canonical": "Audio Modality",
        "aliases": [
          "audio data",
          "audio input"
        ],
        "category": "unique_technical",
        "rationale": "Focuses on a specific data type that is central to the paper's contributions.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.75
      },
      {
        "surface": "CoTA",
        "canonical": "CoTA Dataset",
        "aliases": [
          "CoTA"
        ],
        "category": "unique_technical",
        "rationale": "Represents a specific dataset introduced in the paper, crucial for replicating and understanding the research.",
        "novelty_score": 0.8,
        "connectivity_score": 0.55,
        "specificity_score": 0.88,
        "link_intent_score": 0.77
      },
      {
        "surface": "structured CoT process",
        "canonical": "Chain of Thought Process",
        "aliases": [
          "CoT process",
          "structured CoT"
        ],
        "category": "specific_connectable",
        "rationale": "Connects to methodologies in reasoning and problem-solving, relevant to the paper's approach.",
        "novelty_score": 0.65,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Audio-Reasoner",
      "resolved_canonical": "Audio-Reasoner",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "multimodal reasoning",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "audio modality",
      "resolved_canonical": "Audio Modality",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "CoTA",
      "resolved_canonical": "CoTA Dataset",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.55,
        "specificity": 0.88,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "structured CoT process",
      "resolved_canonical": "Chain of Thought Process",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Audio-Reasoner: Improving Reasoning Capability in Large Audio Language Models

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2503.02318.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2503.02318](https://arxiv.org/abs/2503.02318)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/SightSound-R1_ Cross-Modal Reasoning Distillation from Vision to Audio Language Models_20250922|SightSound-R1: Cross-Modal Reasoning Distillation from Vision to Audio Language Models]] (86.3% similar)
- [[2025-09-23/AuditoryBench++_ Can Language Models Understand Auditory Knowledge without Hearing?_20250923|AuditoryBench++: Can Language Models Understand Auditory Knowledge without Hearing?]] (86.1% similar)
- [[2025-09-18/Omni-CLST_ Error-aware Curriculum Learning with guided Selective chain-of-Thought for audio question answering_20250918|Omni-CLST: Error-aware Curriculum Learning with guided Selective chain-of-Thought for audio question answering]] (86.1% similar)
- [[2025-09-18/Spatial Audio Motion Understanding and Reasoning_20250918|Spatial Audio Motion Understanding and Reasoning]] (85.1% similar)
- [[2025-09-23/LTA-thinker_ Latent Thought-Augmented Training Framework for Large Language Models on Complex Reasoning_20250923|LTA-thinker: Latent Thought-Augmented Training Framework for Large Language Models on Complex Reasoning]] (83.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]], [[keywords/Chain of Thought Process|Chain of Thought Process]]
**âš¡ Unique Technical**: [[keywords/Audio-Reasoner|Audio-Reasoner]], [[keywords/Audio Modality|Audio Modality]], [[keywords/CoTA Dataset|CoTA Dataset]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2503.02318v2 Announce Type: replace-cross 
Abstract: Recent advancements in multimodal reasoning have largely overlooked the audio modality. We introduce Audio-Reasoner, a large-scale audio language model for deep reasoning in audio tasks. We meticulously curated a large-scale and diverse multi-task audio dataset with simple annotations. Then, we leverage closed-source models to conduct secondary labeling, QA generation, along with structured COT process. These datasets together form a high-quality reasoning dataset with 1.2 million reasoning-rich samples, which we name CoTA. Following inference scaling principles, we train Audio-Reasoner on CoTA, enabling it to achieve great logical capabilities in audio reasoning. Experiments show state-of-the-art performance across key benchmarks, including MMAU-mini (+25.42%), AIR-Bench chat/foundation(+14.57%/+10.13%), and MELD (+8.01%). Our findings stress the core of structured CoT training in advancing audio reasoning.

## ğŸ“ ìš”ì•½

ìµœê·¼ ë©€í‹°ëª¨ë‹¬ ì¶”ë¡  ì—°êµ¬ì—ì„œ ì˜¤ë””ì˜¤ ëª¨ë‹¬ë¦¬í‹°ê°€ ì£¼ëª©ë°›ì§€ ëª»í•œ ì ì„ ê°œì„ í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ì˜¤ë””ì˜¤ íƒœìŠ¤í¬ì—ì„œ ì‹¬ì¸µ ì¶”ë¡ ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ëŒ€ê·œëª¨ ì˜¤ë””ì˜¤ ì–¸ì–´ ëª¨ë¸ì¸ Audio-Reasonerë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ê°„ë‹¨í•œ ì£¼ì„ìœ¼ë¡œ êµ¬ì„±ëœ ëŒ€ê·œëª¨ ë©€í‹°íƒœìŠ¤í¬ ì˜¤ë””ì˜¤ ë°ì´í„°ì…‹ì„ ì‹ ì¤‘í•˜ê²Œ êµ¬ì¶•í•˜ê³ , ë¹„ê³µê°œ ëª¨ë¸ì„ í™œìš©í•´ 2ì°¨ ë ˆì´ë¸”ë§, QA ìƒì„±, êµ¬ì¡°í™”ëœ CoT í”„ë¡œì„¸ìŠ¤ë¥¼ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ ìƒì„±ëœ CoTA ë°ì´í„°ì…‹ì€ 120ë§Œ ê°œì˜ ì¶”ë¡  ìƒ˜í”Œì„ í¬í•¨í•˜ë©°, Audio-ReasonerëŠ” ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµí•˜ì—¬ ì˜¤ë””ì˜¤ ì¶”ë¡ ì—ì„œ ë›°ì–´ë‚œ ë…¼ë¦¬ì  ëŠ¥ë ¥ì„ ë°œíœ˜í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, MMAU-mini, AIR-Bench, MELD ë“± ì£¼ìš” ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤. ì—°êµ¬ëŠ” êµ¬ì¡°í™”ëœ CoT í›ˆë ¨ì´ ì˜¤ë””ì˜¤ ì¶”ë¡  ë°œì „ì— í•µì‹¬ì„ì„ ê°•ì¡°í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ìµœê·¼ ë©€í‹°ëª¨ë‹¬ ì¶”ë¡  ì—°êµ¬ì—ì„œ ì˜¤ë””ì˜¤ ëª¨ë‹¬ë¦¬í‹°ê°€ ê°„ê³¼ë˜ê³  ìˆëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ Audio-Reasonerë¼ëŠ” ëŒ€ê·œëª¨ ì˜¤ë””ì˜¤ ì–¸ì–´ ëª¨ë¸ì„ ì†Œê°œí•©ë‹ˆë‹¤.
- 2. ê°„ë‹¨í•œ ì£¼ì„ì´ í¬í•¨ëœ ëŒ€ê·œëª¨ ë©€í‹°íƒœìŠ¤í¬ ì˜¤ë””ì˜¤ ë°ì´í„°ì…‹ì„ ì‹ ì¤‘í•˜ê²Œ êµ¬ì„±í•˜ê³ , ë¹„ê³µê°œ ëª¨ë¸ì„ í™œìš©í•˜ì—¬ 2ì°¨ ë ˆì´ë¸”ë§ ë° QA ìƒì„±, êµ¬ì¡°í™”ëœ COT í”„ë¡œì„¸ìŠ¤ë¥¼ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.
- 3. CoTAë¼ëŠ” ì´ë¦„ì˜ ê³ í’ˆì§ˆ ì¶”ë¡  ë°ì´í„°ì…‹ì„ êµ¬ì¶•í•˜ì—¬ Audio-Reasonerë¥¼ í›ˆë ¨ì‹œí‚´ìœ¼ë¡œì¨ ì˜¤ë””ì˜¤ ì¶”ë¡ ì—ì„œ ë›°ì–´ë‚œ ë…¼ë¦¬ì  ëŠ¥ë ¥ì„ ë°œíœ˜í•  ìˆ˜ ìˆê²Œ í–ˆìŠµë‹ˆë‹¤.
- 4. ì‹¤í—˜ ê²°ê³¼, MMAU-mini, AIR-Bench chat/foundation, MELD ë“± ì£¼ìš” ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.
- 5. êµ¬ì¡°í™”ëœ CoT í›ˆë ¨ì´ ì˜¤ë””ì˜¤ ì¶”ë¡  ë°œì „ì— í•µì‹¬ì ì´ë¼ëŠ” ì ì„ ê°•ì¡°í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 00:49:30*