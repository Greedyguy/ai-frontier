---
keywords:
  - Large Language Model
  - Boolean Satisfiability
  - Logical Reasoning
  - SATBench
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2505.14615
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T00:25:56.200732",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Boolean Satisfiability",
    "Logical Reasoning",
    "SATBench"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Boolean Satisfiability": 0.78,
    "Logical Reasoning": 0.8,
    "SATBench": 0.82
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Links to the broader context of AI and NLP research, connecting with existing work on language models.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Boolean Satisfiability",
        "canonical": "Boolean Satisfiability",
        "aliases": [
          "SAT problems"
        ],
        "category": "unique_technical",
        "rationale": "Central to the paper's methodology, providing a unique angle on logical reasoning in AI.",
        "novelty_score": 0.75,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Logical Reasoning",
        "canonical": "Logical Reasoning",
        "aliases": [
          "Logical Puzzles"
        ],
        "category": "specific_connectable",
        "rationale": "Connects with research on reasoning capabilities of AI, a key aspect of the study.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "SATBench",
        "canonical": "SATBench",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Represents a novel benchmark introduced by the paper, crucial for linking related research efforts.",
        "novelty_score": 0.85,
        "connectivity_score": 0.6,
        "specificity_score": 0.9,
        "link_intent_score": 0.82
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Boolean Satisfiability",
      "resolved_canonical": "Boolean Satisfiability",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Logical Reasoning",
      "resolved_canonical": "Logical Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "SATBench",
      "resolved_canonical": "SATBench",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.6,
        "specificity": 0.9,
        "link_intent": 0.82
      }
    }
  ]
}
-->

# SATBench: Benchmarking LLMs' Logical Reasoning via Automated Puzzle Generation from SAT Formulas

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2505.14615.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2505.14615](https://arxiv.org/abs/2505.14615)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/seqBench_ A Tunable Benchmark to Quantify Sequential Reasoning Limits of LLMs_20250923|seqBench: A Tunable Benchmark to Quantify Sequential Reasoning Limits of LLMs]] (88.8% similar)
- [[2025-09-23/EngiBench_ A Benchmark for Evaluating Large Language Models on Engineering Problem Solving_20250923|EngiBench: A Benchmark for Evaluating Large Language Models on Engineering Problem Solving]] (86.5% similar)
- [[2025-09-22/Are LLMs Better Formalizers than Solvers on Complex Problems?_20250922|Are LLMs Better Formalizers than Solvers on Complex Problems?]] (86.3% similar)
- [[2025-09-22/DivLogicEval_ A Framework for Benchmarking Logical Reasoning Evaluation in Large Language Models_20250922|DivLogicEval: A Framework for Benchmarking Logical Reasoning Evaluation in Large Language Models]] (86.0% similar)
- [[2025-09-23/On LLM-Based Scientific Inductive Reasoning Beyond Equations_20250923|On LLM-Based Scientific Inductive Reasoning Beyond Equations]] (85.7% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Logical Reasoning|Logical Reasoning]]
**âš¡ Unique Technical**: [[keywords/Boolean Satisfiability|Boolean Satisfiability]], [[keywords/SATBench|SATBench]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2505.14615v2 Announce Type: replace 
Abstract: We introduce SATBench, a benchmark for evaluating the logical reasoning capabilities of large language models (LLMs) through logical puzzles derived from Boolean satisfiability (SAT) problems. Unlike prior work that focuses on inference rule-based reasoning, which often involves deducing conclusions from a set of premises, our approach leverages the search-based nature of SAT problems, where the objective is to find a solution that fulfills a specified set of logical constraints. Each instance in SATBench is generated from a SAT formula, then translated into a puzzle using LLMs. The generation process is fully automated and allows for adjustable difficulty by varying the number of clauses. All 2100 puzzles are validated through both LLM-based and solver-based consistency checks, with human validation on a subset. Experimental results show that even the strongest model, o4-mini, achieves only 65.0% accuracy on hard UNSAT problems, close to the random baseline of 50%. Our error analysis reveals systematic failures such as satisfiability bias, context inconsistency, and condition omission, highlighting limitations of current LLMs in search-based logical reasoning. Our code and data are publicly available at https://github.com/Anjiang-Wei/SATBench

## ğŸ“ ìš”ì•½

SATBenchëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ë…¼ë¦¬ì  ì¶”ë¡  ëŠ¥ë ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ë²¤ì¹˜ë§ˆí¬ë¡œ, ë¶€ìš¸ ë§Œì¡±ë„(SAT) ë¬¸ì œì—ì„œ íŒŒìƒëœ ë…¼ë¦¬ í¼ì¦ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ê¸°ì¡´ ì—°êµ¬ì™€ ë‹¬ë¦¬, SATBenchëŠ” ë…¼ë¦¬ì  ì œì•½ì„ ì¶©ì¡±í•˜ëŠ” í•´ë¥¼ ì°¾ëŠ” SAT ë¬¸ì œì˜ íƒìƒ‰ ê¸°ë°˜ íŠ¹ì„±ì„ í™œìš©í•©ë‹ˆë‹¤. í¼ì¦ì€ SAT ê³µì‹ì„ LLMì„ í†µí•´ ìë™ ìƒì„±í•˜ë©°, ë‚œì´ë„ ì¡°ì ˆì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. 2100ê°œì˜ í¼ì¦ì€ LLM ë° ì†”ë²„ ê¸°ë°˜ì˜ ì¼ê´€ì„± ê²€ì¦ì„ ê±°ì³¤ê³ , ì¼ë¶€ëŠ” ì¸ê°„ ê²€ì¦ë„ ìˆ˜í–‰ë˜ì—ˆìŠµë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ê°€ì¥ ê°•ë ¥í•œ ëª¨ë¸ì¸ o4-minië„ ì–´ë ¤ìš´ UNSAT ë¬¸ì œì—ì„œ 65.0%ì˜ ì •í™•ë„ë¥¼ ê¸°ë¡í•´, ë¬´ì‘ìœ„ ê¸°ì¤€ì¸ 50%ì— ê·¼ì ‘í–ˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜ ë¶„ì„ì„ í†µí•´ í˜„ì¬ LLMì˜ íƒìƒ‰ ê¸°ë°˜ ë…¼ë¦¬ ì¶”ë¡ ì˜ í•œê³„ë¥¼ ë“œëŸ¬ë‚´ëŠ” ì²´ê³„ì  ì‹¤íŒ¨ë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ì½”ë“œì™€ ë°ì´í„°ëŠ” ê³µê°œë˜ì–´ ìˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. SATBenchëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ë…¼ë¦¬ì  ì¶”ë¡  ëŠ¥ë ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•´ SAT ë¬¸ì œì—ì„œ íŒŒìƒëœ ë…¼ë¦¬ í¼ì¦ì„ ì‚¬ìš©í•˜ëŠ” ë²¤ì¹˜ë§ˆí¬ì…ë‹ˆë‹¤.
- 2. SATBenchëŠ” ì™„ì „ ìë™í™”ëœ ìƒì„± ê³¼ì •ì„ í†µí•´ ë‚œì´ë„ë¥¼ ì¡°ì ˆí•  ìˆ˜ ìˆìœ¼ë©°, LLM ë° ì†”ë²„ ê¸°ë°˜ì˜ ì¼ê´€ì„± ê²€ì‚¬ë¥¼ í†µí•´ ê²€ì¦ë˜ì—ˆìŠµë‹ˆë‹¤.
- 3. ì‹¤í—˜ ê²°ê³¼, ê°€ì¥ ê°•ë ¥í•œ ëª¨ë¸ì¸ o4-miniì¡°ì°¨ë„ ì–´ë ¤ìš´ UNSAT ë¬¸ì œì—ì„œ 65.0%ì˜ ì •í™•ë„ë¥¼ ê¸°ë¡í•˜ì—¬ ë¬´ì‘ìœ„ ê¸°ì¤€ì¸ 50%ì— ê·¼ì ‘í•œ ì„±ê³¼ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.
- 4. ì˜¤ë¥˜ ë¶„ì„ ê²°ê³¼, í˜„ì¬ LLMì˜ í•œê³„ë¡œì„œ ë§Œì¡± ê°€ëŠ¥ì„± í¸í–¥, ë¬¸ë§¥ ë¶ˆì¼ì¹˜, ì¡°ê±´ ëˆ„ë½ ë“±ì˜ ì²´ê³„ì ì¸ ì‹¤íŒ¨ê°€ ë“œëŸ¬ë‚¬ìŠµë‹ˆë‹¤.
- 5. SATBenchì˜ ì½”ë“œì™€ ë°ì´í„°ëŠ” ê³µê°œë˜ì–´ ìˆìœ¼ë©°, ì—°êµ¬ìë“¤ì´ LLMì˜ ë…¼ë¦¬ì  ì¶”ë¡  ëŠ¥ë ¥ì„ ë”ìš± ë°œì „ì‹œí‚¬ ìˆ˜ ìˆëŠ” ê¸°íšŒë¥¼ ì œê³µí•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 00:25:56*