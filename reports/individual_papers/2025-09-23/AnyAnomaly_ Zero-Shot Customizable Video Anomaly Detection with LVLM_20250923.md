---
keywords:
  - Zero-Shot Learning
  - Vision-Language Model
  - Video Anomaly Detection
  - Context-Aware Visual Question Answering
category: cs.CV
publish_date: 2025-09-23
arxiv_id: 2503.04504
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T05:18:25.258062",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Zero-Shot Learning",
    "Vision-Language Model",
    "Video Anomaly Detection",
    "Context-Aware Visual Question Answering"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Zero-Shot Learning": 0.78,
    "Vision-Language Model": 0.82,
    "Video Anomaly Detection": 0.77,
    "Context-Aware Visual Question Answering": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Zero-Shot",
        "canonical": "Zero-Shot Learning",
        "aliases": [
          "Zero-Shot"
        ],
        "category": "specific_connectable",
        "rationale": "Zero-Shot Learning is crucial for understanding the model's ability to generalize without retraining, a key aspect of the paper.",
        "novelty_score": 0.55,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.78
      },
      {
        "surface": "Vision-Language Model",
        "canonical": "Vision-Language Model",
        "aliases": [
          "LVLM"
        ],
        "category": "evolved_concepts",
        "rationale": "The use of a Vision-Language Model is central to the AnyAnomaly approach, linking it to recent advancements in multimodal AI.",
        "novelty_score": 0.6,
        "connectivity_score": 0.88,
        "specificity_score": 0.75,
        "link_intent_score": 0.82
      },
      {
        "surface": "Video Anomaly Detection",
        "canonical": "Video Anomaly Detection",
        "aliases": [
          "VAD"
        ],
        "category": "unique_technical",
        "rationale": "Video Anomaly Detection is the primary application of the study, providing a unique context for the proposed model.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      },
      {
        "surface": "Context-Aware Visual Question Answering",
        "canonical": "Context-Aware Visual Question Answering",
        "aliases": [
          "C-VQA"
        ],
        "category": "unique_technical",
        "rationale": "This technique is a novel aspect of the model's implementation, enhancing its adaptability and customization.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "model",
      "performance",
      "method"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Zero-Shot",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Vision-Language Model",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.88,
        "specificity": 0.75,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Video Anomaly Detection",
      "resolved_canonical": "Video Anomaly Detection",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Context-Aware Visual Question Answering",
      "resolved_canonical": "Context-Aware Visual Question Answering",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# AnyAnomaly: Zero-Shot Customizable Video Anomaly Detection with LVLM

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2503.04504.pdf)
**Category**: cs.CV
**Published**: 2025-09-23
**ArXiv ID**: [2503.04504](https://arxiv.org/abs/2503.04504)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/AD-DINOv3_ Enhancing DINOv3 for Zero-Shot Anomaly Detection with Anomaly-Aware Calibration_20250918|AD-DINOv3: Enhancing DINOv3 for Zero-Shot Anomaly Detection with Anomaly-Aware Calibration]] (82.9% similar)
- [[2025-09-23/From Benchmarks to Reality_ Advancing Visual Anomaly Detection by the VAND 3.0 Challenge_20250923|From Benchmarks to Reality: Advancing Visual Anomaly Detection by the VAND 3.0 Challenge]] (82.4% similar)
- [[2025-09-23/VCE_ Safe Autoregressive Image Generation via Visual Contrast Exploitation_20250923|VCE: Safe Autoregressive Image Generation via Visual Contrast Exploitation]] (80.8% similar)
- [[2025-09-23/When Big Models Train Small Ones_ Label-Free Model Parity Alignment for Efficient Visual Question Answering using Small VLMs_20250923|When Big Models Train Small Ones: Label-Free Model Parity Alignment for Efficient Visual Question Answering using Small VLMs]] (80.7% similar)
- [[2025-09-23/ADVEDM_Fine-grained Adversarial Attack against VLM-based Embodied Agents_20250923|ADVEDM:Fine-grained Adversarial Attack against VLM-based Embodied Agents]] (80.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Zero-Shot Learning|Zero-Shot Learning]]
**âš¡ Unique Technical**: [[keywords/Video Anomaly Detection|Video Anomaly Detection]], [[keywords/Context-Aware Visual Question Answering|Context-Aware Visual Question Answering]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2503.04504v3 Announce Type: replace 
Abstract: Video anomaly detection (VAD) is crucial for video analysis and surveillance in computer vision. However, existing VAD models rely on learned normal patterns, which makes them difficult to apply to diverse environments. Consequently, users should retrain models or develop separate AI models for new environments, which requires expertise in machine learning, high-performance hardware, and extensive data collection, limiting the practical usability of VAD. To address these challenges, this study proposes customizable video anomaly detection (C-VAD) technique and the AnyAnomaly model. C-VAD considers user-defined text as an abnormal event and detects frames containing a specified event in a video. We effectively implemented AnyAnomaly using a context-aware visual question answering without fine-tuning the large vision language model. To validate the effectiveness of the proposed model, we constructed C-VAD datasets and demonstrated the superiority of AnyAnomaly. Furthermore, our approach showed competitive results on VAD benchmarks, achieving state-of-the-art performance on UBnormal and UCF-Crime and surpassing other methods in generalization across all datasets. Our code is available online at github.com/SkiddieAhn/Paper-AnyAnomaly.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” ë‹¤ì–‘í•œ í™˜ê²½ì— ì ìš©í•˜ê¸° ì–´ë ¤ìš´ ê¸°ì¡´ ì˜ìƒ ì´ìƒ íƒì§€(VAD) ëª¨ë¸ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ì‚¬ìš©ì ì •ì˜ ê°€ëŠ¥í•œ ì˜ìƒ ì´ìƒ íƒì§€(C-VAD) ê¸°ìˆ ê³¼ AnyAnomaly ëª¨ë¸ì„ ì œì•ˆí•©ë‹ˆë‹¤. C-VADëŠ” ì‚¬ìš©ìê°€ ì •ì˜í•œ í…ìŠ¤íŠ¸ë¥¼ ì´ìƒ ì´ë²¤íŠ¸ë¡œ ê°„ì£¼í•˜ì—¬ í•´ë‹¹ ì´ë²¤íŠ¸ê°€ í¬í•¨ëœ í”„ë ˆì„ì„ íƒì§€í•©ë‹ˆë‹¤. AnyAnomalyëŠ” ëŒ€í˜• ë¹„ì „ ì–¸ì–´ ëª¨ë¸ì˜ ë¯¸ì„¸ ì¡°ì • ì—†ì´ ë¬¸ë§¥ ì¸ì‹ ì‹œê°ì  ì§ˆë¬¸ ì‘ë‹µì„ í™œìš©í•˜ì—¬ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤. ì œì•ˆëœ ëª¨ë¸ì˜ íš¨ê³¼ë¥¼ ê²€ì¦í•˜ê¸° ìœ„í•´ C-VAD ë°ì´í„°ì…‹ì„ êµ¬ì¶•í•˜ê³ , UBnormal ë° UCF-Crime ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ë©° ëª¨ë“  ë°ì´í„°ì…‹ì—ì„œ ì¼ë°˜í™” ëŠ¥ë ¥ì—ì„œ ê²½ìŸë ¥ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤. ì½”ë“œì™€ ë°ì´í„°ëŠ” ì˜¨ë¼ì¸ì—ì„œ ì œê³µë©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ê¸°ì¡´ì˜ ë¹„ë””ì˜¤ ì´ìƒ íƒì§€(VAD) ëª¨ë¸ì€ í•™ìŠµëœ ì •ìƒ íŒ¨í„´ì— ì˜ì¡´í•˜ì—¬ ë‹¤ì–‘í•œ í™˜ê²½ì— ì ìš©í•˜ê¸° ì–´ë µë‹¤.
- 2. ì‚¬ìš©ìê°€ ì •ì˜í•œ í…ìŠ¤íŠ¸ë¥¼ ë¹„ì •ìƒ ì´ë²¤íŠ¸ë¡œ ê°„ì£¼í•˜ì—¬ íŠ¹ì • ì´ë²¤íŠ¸ê°€ í¬í•¨ëœ í”„ë ˆì„ì„ íƒì§€í•˜ëŠ” ë§ì¶¤í˜• ë¹„ë””ì˜¤ ì´ìƒ íƒì§€(C-VAD) ê¸°ë²•ì„ ì œì•ˆí•œë‹¤.
- 3. AnyAnomaly ëª¨ë¸ì€ ëŒ€í˜• ë¹„ì „ ì–¸ì–´ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ì§€ ì•Šê³  ë§¥ë½ ì¸ì‹ ì‹œê°ì  ì§ˆë¬¸ ì‘ë‹µì„ í†µí•´ íš¨ê³¼ì ìœ¼ë¡œ êµ¬í˜„ë˜ì—ˆë‹¤.
- 4. ì œì•ˆëœ ëª¨ë¸ì˜ íš¨ê³¼ì„±ì„ ê²€ì¦í•˜ê¸° ìœ„í•´ C-VAD ë°ì´í„°ì…‹ì„ êµ¬ì¶•í•˜ê³  AnyAnomalyì˜ ìš°ìˆ˜ì„±ì„ ì…ì¦í•˜ì˜€ë‹¤.
- 5. AnyAnomalyëŠ” UBnormal ë° UCF-Crimeì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ê³ , ëª¨ë“  ë°ì´í„°ì…‹ì—ì„œ ì¼ë°˜í™” ì¸¡ë©´ì—ì„œ ë‹¤ë¥¸ ë°©ë²•ë“¤ì„ ëŠ¥ê°€í•˜ì˜€ë‹¤.


---

*Generated on 2025-09-24 05:18:25*