---
keywords:
  - Large Language Model
  - Psychometric Properties
  - AIPsychoBench
  - Role-Playing Prompt
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.16530
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T23:23:55.510553",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Psychometric Properties",
    "AIPsychoBench",
    "Role-Playing Prompt"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Psychometric Properties": 0.78,
    "AIPsychoBench": 0.82,
    "Role-Playing Prompt": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Large Language Models"
        ],
        "category": "broad_technical",
        "rationale": "LLMs are central to the paper's focus on psychometrics and are a key concept in NLP.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "psychometric properties",
        "canonical": "Psychometric Properties",
        "aliases": [
          "psychometrics",
          "psychometric measures"
        ],
        "category": "unique_technical",
        "rationale": "This term is crucial for linking discussions on cognitive assessments between humans and LLMs.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "AIPsychoBench",
        "canonical": "AIPsychoBench",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "As a new benchmark introduced in the paper, it is essential for understanding LLM psychometrics.",
        "novelty_score": 0.95,
        "connectivity_score": 0.55,
        "specificity_score": 0.9,
        "link_intent_score": 0.82
      },
      {
        "surface": "role-playing prompt",
        "canonical": "Role-Playing Prompt",
        "aliases": [
          "role-play prompt"
        ],
        "category": "specific_connectable",
        "rationale": "This technique is pivotal for improving response rates in LLM assessments.",
        "novelty_score": 0.68,
        "connectivity_score": 0.7,
        "specificity_score": 0.75,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "human scales",
      "traditional jailbreak prompts"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "psychometric properties",
      "resolved_canonical": "Psychometric Properties",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "AIPsychoBench",
      "resolved_canonical": "AIPsychoBench",
      "decision": "linked",
      "scores": {
        "novelty": 0.95,
        "connectivity": 0.55,
        "specificity": 0.9,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "role-playing prompt",
      "resolved_canonical": "Role-Playing Prompt",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.7,
        "specificity": 0.75,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# AIPsychoBench: Understanding the Psychometric Differences between LLMs and Humans

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16530.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.16530](https://arxiv.org/abs/2509.16530)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Adding LLMs to the psycholinguistic norming toolbox_ A practical guide to getting the most out of human ratings_20250919|Adding LLMs to the psycholinguistic norming toolbox: A practical guide to getting the most out of human ratings]] (89.4% similar)
- [[2025-09-22/Benchmark of stylistic variation in LLM-generated texts_20250922|Benchmark of stylistic variation in LLM-generated texts]] (86.7% similar)
- [[2025-09-23/EngiBench_ A Benchmark for Evaluating Large Language Models on Engineering Problem Solving_20250923|EngiBench: A Benchmark for Evaluating Large Language Models on Engineering Problem Solving]] (86.5% similar)
- [[2025-09-22/DivLogicEval_ A Framework for Benchmarking Logical Reasoning Evaluation in Large Language Models_20250922|DivLogicEval: A Framework for Benchmarking Logical Reasoning Evaluation in Large Language Models]] (86.4% similar)
- [[2025-09-19/Rationality Check! Benchmarking the Rationality of Large Language Models_20250919|Rationality Check! Benchmarking the Rationality of Large Language Models]] (86.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Role-Playing Prompt|Role-Playing Prompt]]
**âš¡ Unique Technical**: [[keywords/Psychometric Properties|Psychometric Properties]], [[keywords/AIPsychoBench|AIPsychoBench]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16530v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) with hundreds of billions of parameters have exhibited human-like intelligence by learning from vast amounts of internet-scale data. However, the uninterpretability of large-scale neural networks raises concerns about the reliability of LLM. Studies have attempted to assess the psychometric properties of LLMs by borrowing concepts from human psychology to enhance their interpretability, but they fail to account for the fundamental differences between LLMs and humans. This results in high rejection rates when human scales are reused directly. Furthermore, these scales do not support the measurement of LLM psychological property variations in different languages. This paper introduces AIPsychoBench, a specialized benchmark tailored to assess the psychological properties of LLM. It uses a lightweight role-playing prompt to bypass LLM alignment, improving the average effective response rate from 70.12% to 90.40%. Meanwhile, the average biases are only 3.3% (positive) and 2.1% (negative), which are significantly lower than the biases of 9.8% and 6.9%, respectively, caused by traditional jailbreak prompts. Furthermore, among the total of 112 psychometric subcategories, the score deviations for seven languages compared to English ranged from 5% to 20.2% in 43 subcategories, providing the first comprehensive evidence of the linguistic impact on the psychometrics of LLM.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì‹¬ë¦¬ì  ì†ì„±ì„ í‰ê°€í•˜ê¸° ìœ„í•´ AIPsychoBenchë¼ëŠ” ë²¤ì¹˜ë§ˆí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ì¸ê°„ ì‹¬ë¦¬í•™ ê°œë…ì„ ì°¨ìš©í•œ ì—°êµ¬ë“¤ì€ LLMê³¼ ì¸ê°„ì˜ ê·¼ë³¸ì  ì°¨ì´ë¥¼ ê°„ê³¼í•˜ì—¬ ë†’ì€ ê±°ë¶€ìœ¨ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. AIPsychoBenchëŠ” ê²½ëŸ‰í™”ëœ ì—­í•  ìˆ˜í–‰ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ LLMì˜ ì •ë ¬ ë¬¸ì œë¥¼ ìš°íšŒí•˜ë©°, í‰ê·  ìœ íš¨ ì‘ë‹µë¥ ì„ 70.12%ì—ì„œ 90.40%ë¡œ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤. ë˜í•œ, ì „í†µì  ë°©ë²•ë³´ë‹¤ í¸í–¥ì´ í¬ê²Œ ê°ì†Œí–ˆìŠµë‹ˆë‹¤. 7ê°œ ì–¸ì–´ì˜ ì‹¬ë¦¬ì¸¡ì • ì ìˆ˜ í¸ì°¨ë¥¼ ë¶„ì„í•˜ì—¬ LLMì˜ ì‹¬ë¦¬ì¸¡ì •ì— ë¯¸ì¹˜ëŠ” ì–¸ì–´ì  ì˜í–¥ì„ ì²˜ìŒìœ¼ë¡œ í¬ê´„ì ìœ¼ë¡œ ì¦ëª…í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ í•´ì„ ê°€ëŠ¥ì„±ì„ ë†’ì´ê¸° ìœ„í•´ ì¸ê°„ ì‹¬ë¦¬í•™ ê°œë…ì„ ì°¨ìš©í•œ ì—°êµ¬ë“¤ì´ ìˆì§€ë§Œ, LLMê³¼ ì¸ê°„ì˜ ê·¼ë³¸ì ì¸ ì°¨ì´ë¥¼ ê°„ê³¼í•˜ì—¬ ë†’ì€ ê±°ë¶€ìœ¨ì„ ì´ˆë˜í•œë‹¤.
- 2. ê¸°ì¡´ì˜ ì¸ê°„ ì‹¬ë¦¬ ì²™ë„ëŠ” LLMì˜ ì‹¬ë¦¬ì  íŠ¹ì„± ë³€í™”ë¥¼ ë‹¤ì–‘í•œ ì–¸ì–´ì—ì„œ ì¸¡ì •í•˜ëŠ” ë° í•œê³„ê°€ ìˆë‹¤.
- 3. AIPsychoBenchëŠ” LLMì˜ ì‹¬ë¦¬ì  íŠ¹ì„±ì„ í‰ê°€í•˜ê¸° ìœ„í•œ íŠ¹í™”ëœ ë²¤ì¹˜ë§ˆí¬ë¡œ, ê²½ëŸ‰ì˜ ë¡¤í”Œë ˆì‰ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ LLM ì •ë ¬ ë¬¸ì œë¥¼ ìš°íšŒí•˜ê³  í‰ê·  ìœ íš¨ ì‘ë‹µë¥ ì„ 70.12%ì—ì„œ 90.40%ë¡œ í–¥ìƒì‹œí‚¨ë‹¤.
- 4. AIPsychoBenchëŠ” ì „í†µì ì¸ íƒˆì˜¥ í”„ë¡¬í”„íŠ¸ì— ë¹„í•´ í¸í–¥ì´ í¬ê²Œ ì¤„ì–´ë“¤ì–´, ê¸ì •ì  í¸í–¥ 3.3%ì™€ ë¶€ì •ì  í¸í–¥ 2.1%ë¥¼ ê¸°ë¡í•œë‹¤.
- 5. 112ê°œì˜ ì‹¬ë¦¬ ì¸¡ì • í•˜ìœ„ ë²”ì£¼ ì¤‘ 43ê°œì—ì„œ ì˜ì–´ì™€ ë¹„êµí–ˆì„ ë•Œ 7ê°œ ì–¸ì–´ì˜ ì ìˆ˜ í¸ì°¨ê°€ 5%ì—ì„œ 20.2% ë²”ìœ„ë¡œ ë‚˜íƒ€ë‚˜, LLMì˜ ì‹¬ë¦¬ ì¸¡ì •ì— ëŒ€í•œ ì–¸ì–´ì  ì˜í–¥ì— ëŒ€í•œ í¬ê´„ì ì¸ ì¦ê±°ë¥¼ ì œê³µí•œë‹¤.


---

*Generated on 2025-09-23 23:23:55*