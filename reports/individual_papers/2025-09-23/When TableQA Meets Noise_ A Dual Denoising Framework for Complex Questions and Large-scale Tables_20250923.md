---
keywords:
  - Table Question Answering
  - Large Language Model
  - Relevance Filtering
  - Table Pruning
  - Evidence-based Question Denoising
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2509.17680
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:31:45.399130",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Table Question Answering",
    "Large Language Model",
    "Relevance Filtering",
    "Table Pruning",
    "Evidence-based Question Denoising"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Table Question Answering": 0.78,
    "Large Language Model": 0.8,
    "Relevance Filtering": 0.75,
    "Table Pruning": 0.77,
    "Evidence-based Question Denoising": 0.74
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Table Question Answering",
        "canonical": "Table Question Answering",
        "aliases": [
          "TableQA"
        ],
        "category": "unique_technical",
        "rationale": "Table Question Answering is a specific task in NLP that involves reasoning over structured data, which is central to the paper's contributions.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are crucial for reasoning capabilities, which are a key focus of the paper.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Relevance Filtering",
        "canonical": "Relevance Filtering",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Relevance Filtering is a novel approach introduced in the paper to improve reasoning by identifying essential information.",
        "novelty_score": 0.68,
        "connectivity_score": 0.6,
        "specificity_score": 0.82,
        "link_intent_score": 0.75
      },
      {
        "surface": "Table Pruning",
        "canonical": "Table Pruning",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Table Pruning is a specific method proposed to manage large-scale tables, enhancing the paper's contribution to TableQA.",
        "novelty_score": 0.7,
        "connectivity_score": 0.62,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      },
      {
        "surface": "Evidence-based Question Denoising",
        "canonical": "Evidence-based Question Denoising",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This technique is a key innovation of the paper, focusing on decomposing and filtering questions for better reasoning.",
        "novelty_score": 0.72,
        "connectivity_score": 0.58,
        "specificity_score": 0.83,
        "link_intent_score": 0.74
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance",
      "framework",
      "approach"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Table Question Answering",
      "resolved_canonical": "Table Question Answering",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Relevance Filtering",
      "resolved_canonical": "Relevance Filtering",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.6,
        "specificity": 0.82,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Table Pruning",
      "resolved_canonical": "Table Pruning",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.62,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Evidence-based Question Denoising",
      "resolved_canonical": "Evidence-based Question Denoising",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.58,
        "specificity": 0.83,
        "link_intent": 0.74
      }
    }
  ]
}
-->

# When TableQA Meets Noise: A Dual Denoising Framework for Complex Questions and Large-scale Tables

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17680.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2509.17680](https://arxiv.org/abs/2509.17680)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Can GRPO Boost Complex Multimodal Table Understanding?_20250923|Can GRPO Boost Complex Multimodal Table Understanding?]] (82.1% similar)
- [[2025-09-19/TableDART_ Dynamic Adaptive Multi-Modal Routing for Table Understanding_20250919|TableDART: Dynamic Adaptive Multi-Modal Routing for Table Understanding]] (81.3% similar)
- [[2025-09-23/Improving Deep Tabular Learning_20250923|Improving Deep Tabular Learning]] (79.7% similar)
- [[2025-09-23/Beyond Prompting_ An Efficient Embedding Framework for Open-Domain Question Answering_20250923|Beyond Prompting: An Efficient Embedding Framework for Open-Domain Question Answering]] (79.7% similar)
- [[2025-09-23/Table2LaTeX-RL_ High-Fidelity LaTeX Code Generation from Table Images via Reinforced Multimodal Language Models_20250923|Table2LaTeX-RL: High-Fidelity LaTeX Code Generation from Table Images via Reinforced Multimodal Language Models]] (79.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**âš¡ Unique Technical**: [[keywords/Table Question Answering|Table Question Answering]], [[keywords/Relevance Filtering|Relevance Filtering]], [[keywords/Table Pruning|Table Pruning]], [[keywords/Evidence-based Question Denoising|Evidence-based Question Denoising]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17680v1 Announce Type: new 
Abstract: Table question answering (TableQA) is a fundamental task in natural language processing (NLP). The strong reasoning capabilities of large language models (LLMs) have brought significant advances in this field. However, as real-world applications involve increasingly complex questions and larger tables, substantial noisy data is introduced, which severely degrades reasoning performance. To address this challenge, we focus on improving two core capabilities: Relevance Filtering, which identifies and retains information truly relevant to reasoning, and Table Pruning, which reduces table size while preserving essential content. Based on these principles, we propose EnoTab, a dual denoising framework for complex questions and large-scale tables. Specifically, we first perform Evidence-based Question Denoising by decomposing the question into minimal semantic units and filtering out those irrelevant to answer reasoning based on consistency and usability criteria. Then, we propose Evidence Tree-guided Table Denoising, which constructs an explicit and transparent table pruning path to remove irrelevant data step by step. At each pruning step, we observe the intermediate state of the table and apply a post-order node rollback mechanism to handle abnormal table states, ultimately producing a highly reliable sub-table for final answer reasoning. Finally, extensive experiments show that EnoTab achieves outstanding performance on TableQA tasks with complex questions and large-scale tables, confirming its effectiveness.

## ğŸ“ ìš”ì•½

TableQAëŠ” ìì—°ì–´ ì²˜ë¦¬ì˜ ì¤‘ìš”í•œ ê³¼ì œë¡œ, ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ê°•ë ¥í•œ ì¶”ë¡  ëŠ¥ë ¥ ë•ë¶„ì— í° ë°œì „ì„ ì´ë£¨ì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë³µì¡í•œ ì§ˆë¬¸ê³¼ ëŒ€ê·œëª¨ í…Œì´ë¸”ì´ í¬í•¨ëœ ì‹¤ì œ ì‘ìš©ì—ì„œëŠ” ë§ì€ ì¡ìŒ ë°ì´í„°ê°€ ë°œìƒí•´ ì„±ëŠ¥ì´ ì €í•˜ë©ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ê´€ë ¨ì„± í•„í„°ë§ê³¼ í…Œì´ë¸” ê°€ì§€ì¹˜ê¸°ë¼ëŠ” ë‘ ê°€ì§€ í•µì‹¬ ëŠ¥ë ¥ì„ ê°œì„ í•˜ê³ ì í•©ë‹ˆë‹¤. ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ë³µì¡í•œ ì§ˆë¬¸ê³¼ ëŒ€ê·œëª¨ í…Œì´ë¸”ì— ëŒ€í•œ ì´ì¤‘ ë…¸ì´ì¦ˆ ì œê±° í”„ë ˆì„ì›Œí¬ì¸ EnoTabì„ ì œì•ˆí•©ë‹ˆë‹¤. ë¨¼ì €, ì§ˆë¬¸ì„ ìµœì†Œ ì˜ë¯¸ ë‹¨ìœ„ë¡œ ë¶„í•´í•˜ê³  ë¶ˆí•„ìš”í•œ ë¶€ë¶„ì„ ì œê±°í•˜ëŠ” ì¦ê±° ê¸°ë°˜ ì§ˆë¬¸ ë…¸ì´ì¦ˆ ì œê±°ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì´í›„, ëª…ì‹œì  í…Œì´ë¸” ê°€ì§€ì¹˜ê¸° ê²½ë¡œë¥¼ êµ¬ì¶•í•˜ì—¬ ë¶ˆí•„ìš”í•œ ë°ì´í„°ë¥¼ ë‹¨ê³„ì ìœ¼ë¡œ ì œê±°í•˜ëŠ” ì¦ê±° íŠ¸ë¦¬ ê¸°ë°˜ í…Œì´ë¸” ë…¸ì´ì¦ˆ ì œê±°ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, EnoTabì€ ë³µì¡í•œ ì§ˆë¬¸ê³¼ ëŒ€ê·œëª¨ í…Œì´ë¸”ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì—¬ ê·¸ íš¨ê³¼ì„±ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. TableQAëŠ” ìì—°ì–´ ì²˜ë¦¬ ë¶„ì•¼ì—ì„œ ì¤‘ìš”í•œ ê³¼ì œë¡œ, ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ ê°•ë ¥í•œ ì¶”ë¡  ëŠ¥ë ¥ì´ ì´ ë¶„ì•¼ì˜ ë°œì „ì„ ì´ëŒê³  ìˆìŠµë‹ˆë‹¤.
- 2. ì‹¤ì œ ì‘ìš©ì—ì„œëŠ” ë³µì¡í•œ ì§ˆë¬¸ê³¼ ëŒ€ê·œëª¨ í…Œì´ë¸”ë¡œ ì¸í•´ ë§ì€ ì¡ìŒ ë°ì´í„°ê°€ ë°œìƒí•˜ì—¬ ì¶”ë¡  ì„±ëŠ¥ì´ ì €í•˜ë©ë‹ˆë‹¤.
- 3. EnoTabì€ ë³µì¡í•œ ì§ˆë¬¸ê³¼ ëŒ€ê·œëª¨ í…Œì´ë¸”ì„ ìœ„í•œ ì´ì¤‘ ì¡ìŒ ì œê±° í”„ë ˆì„ì›Œí¬ë¡œ, ê´€ë ¨ì„± í•„í„°ë§ê³¼ í…Œì´ë¸” ê°€ì§€ì¹˜ê¸°ë¥¼ í†µí•´ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
- 4. ì¦ê±° ê¸°ë°˜ ì§ˆë¬¸ ì¡ìŒ ì œê±°ì™€ ì¦ê±° íŠ¸ë¦¬ ê¸°ë°˜ í…Œì´ë¸” ì¡ìŒ ì œê±°ë¥¼ í†µí•´ ë¶ˆí•„ìš”í•œ ë°ì´í„°ë¥¼ ë‹¨ê³„ì ìœ¼ë¡œ ì œê±°í•˜ì—¬ ì‹ ë¢°ì„± ë†’ì€ ì„œë¸Œ í…Œì´ë¸”ì„ ìƒì„±í•©ë‹ˆë‹¤.
- 5. ê´‘ë²”ìœ„í•œ ì‹¤í—˜ ê²°ê³¼, EnoTabì€ ë³µì¡í•œ ì§ˆë¬¸ê³¼ ëŒ€ê·œëª¨ í…Œì´ë¸”ì„ í¬í•¨í•œ TableQA ì‘ì—…ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 03:31:45*