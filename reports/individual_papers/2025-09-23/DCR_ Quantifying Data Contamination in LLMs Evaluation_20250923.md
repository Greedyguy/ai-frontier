---
keywords:
  - Large Language Model
  - Data Contamination Risk
  - Benchmark Data Contamination
  - Fuzzy Inference System
  - Sentiment Analysis
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2507.11405
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T04:07:37.429513",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Data Contamination Risk",
    "Benchmark Data Contamination",
    "Fuzzy Inference System",
    "Sentiment Analysis"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Data Contamination Risk": 0.8,
    "Benchmark Data Contamination": 0.78,
    "Fuzzy Inference System": 0.77,
    "Sentiment Analysis": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "This is a foundational concept in the paper, linking it to broader discussions in AI and NLP.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Data Contamination Risk",
        "canonical": "Data Contamination Risk",
        "aliases": [
          "DCR"
        ],
        "category": "unique_technical",
        "rationale": "A unique framework introduced in the paper, crucial for understanding the study's contribution.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Benchmark Data Contamination",
        "canonical": "Benchmark Data Contamination",
        "aliases": [
          "BDC"
        ],
        "category": "unique_technical",
        "rationale": "Central to the paper's focus, it highlights a specific issue in LLM evaluation.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Fuzzy Inference System",
        "canonical": "Fuzzy Inference System",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "An important method used in the paper, linking to broader discussions on inference techniques.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.77
      },
      {
        "surface": "Sentiment Analysis",
        "canonical": "Sentiment Analysis",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "One of the tasks used to validate the framework, connecting to a common NLP application.",
        "novelty_score": 0.4,
        "connectivity_score": 0.8,
        "specificity_score": 0.65,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "evaluation data",
      "performance metrics"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Data Contamination Risk",
      "resolved_canonical": "Data Contamination Risk",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Benchmark Data Contamination",
      "resolved_canonical": "Benchmark Data Contamination",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Fuzzy Inference System",
      "resolved_canonical": "Fuzzy Inference System",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Sentiment Analysis",
      "resolved_canonical": "Sentiment Analysis",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.8,
        "specificity": 0.65,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# DCR: Quantifying Data Contamination in LLMs Evaluation

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2507.11405.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2507.11405](https://arxiv.org/abs/2507.11405)

## 🔗 유사한 논문
- [[2025-09-23/Both Text and Images Leaked! A Systematic Analysis of Data Contamination in Multimodal LLM_20250923|Both Text and Images Leaked! A Systematic Analysis of Data Contamination in Multimodal LLM]] (88.1% similar)
- [[2025-09-18/LNE-Blocking_ An Efficient Framework for Contamination Mitigation Evaluation on Large Language Models_20250918|LNE-Blocking: An Efficient Framework for Contamination Mitigation Evaluation on Large Language Models]] (87.8% similar)
- [[2025-09-22/Calibrating LLM Confidence by Probing Perturbed Representation Stability_20250922|Calibrating LLM Confidence by Probing Perturbed Representation Stability]] (86.4% similar)
- [[2025-09-23/D-REX_ A Benchmark for Detecting Deceptive Reasoning in Large Language Models_20250923|D-REX: A Benchmark for Detecting Deceptive Reasoning in Large Language Models]] (86.3% similar)
- [[2025-09-23/From Scores to Steps_ Diagnosing and Improving LLM Performance in Evidence-Based Medical Calculations_20250923|From Scores to Steps: Diagnosing and Improving LLM Performance in Evidence-Based Medical Calculations]] (85.6% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Fuzzy Inference System|Fuzzy Inference System]], [[keywords/Sentiment Analysis|Sentiment Analysis]]
**⚡ Unique Technical**: [[keywords/Data Contamination Risk|Data Contamination Risk]], [[keywords/Benchmark Data Contamination|Benchmark Data Contamination]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2507.11405v2 Announce Type: replace 
Abstract: The rapid advancement of large language models (LLMs) has heightened concerns about benchmark data contamination (BDC), where models inadvertently memorize evaluation data during the training process, inflating performance metrics, and undermining genuine generalization assessment. This paper introduces the Data Contamination Risk (DCR) framework, a lightweight, interpretable pipeline designed to detect and quantify BDC risk across four granular levels: semantic, informational, data, and label. By synthesizing contamination scores via a fuzzy inference system, DCR produces a unified DCR Factor that adjusts raw accuracy to reflect contamination-aware performance. Validated on 9 LLMs (0.5B-72B) across sentiment analysis, fake news detection, and arithmetic reasoning tasks, the DCR framework reliably diagnoses contamination severity and with accuracy adjusted using the DCR Factor to within 4% average error across the three benchmarks compared to the uncontaminated baseline. Emphasizing computational efficiency and transparency, DCR provides a practical tool for integrating contamination assessment into routine evaluations, fostering fairer comparisons and enhancing the credibility of LLM benchmarking practices.

## 📝 요약

이 논문은 대형 언어 모델(LLM)의 훈련 과정에서 평가 데이터가 의도치 않게 학습되는 벤치마크 데이터 오염(BDC) 문제를 다룹니다. 이를 해결하기 위해 데이터 오염 위험(DCR) 프레임워크를 제안하며, 이는 의미적, 정보적, 데이터, 레이블의 네 가지 수준에서 BDC 위험을 탐지하고 정량화합니다. DCR은 퍼지 추론 시스템을 통해 오염 점수를 통합하여, 오염을 고려한 성능을 반영하는 DCR 팩터를 생성합니다. 9개의 LLM을 대상으로 감정 분석, 가짜 뉴스 탐지, 산술 추론 과제를 통해 검증한 결과, DCR은 오염 심각도를 신뢰성 있게 진단하고, 오염되지 않은 기준과 비교했을 때 평균 4% 이내의 오차로 정확도를 조정합니다. DCR은 계산 효율성과 투명성을 강조하며, LLM 벤치마킹의 신뢰성을 높이는 실용적인 도구를 제공합니다.

## 🎯 주요 포인트

- 1. 대형 언어 모델(LLM)의 발전으로 인해 벤치마크 데이터 오염(BDC)에 대한 우려가 증가하고 있습니다.
- 2. 본 논문은 BDC 위험을 탐지하고 정량화하기 위한 Data Contamination Risk (DCR) 프레임워크를 소개합니다.
- 3. DCR은 의미적, 정보적, 데이터, 레이블의 네 가지 세부 수준에서 오염 위험을 평가합니다.
- 4. DCR 프레임워크는 9개의 LLM에 대해 검증되었으며, 오염 인식 성능을 반영하기 위해 정확도를 조정합니다.
- 5. DCR은 계산 효율성과 투명성을 강조하며, LLM 벤치마킹의 신뢰성을 높이는 실용적인 도구를 제공합니다.


---

*Generated on 2025-09-24 04:07:37*