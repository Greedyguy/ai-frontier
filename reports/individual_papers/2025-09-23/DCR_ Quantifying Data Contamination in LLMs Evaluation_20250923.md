---
keywords:
  - Large Language Model
  - Data Contamination Risk
  - Benchmark Data Contamination
  - Fuzzy Inference System
  - Sentiment Analysis
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2507.11405
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T04:07:37.429513",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Data Contamination Risk",
    "Benchmark Data Contamination",
    "Fuzzy Inference System",
    "Sentiment Analysis"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Data Contamination Risk": 0.8,
    "Benchmark Data Contamination": 0.78,
    "Fuzzy Inference System": 0.77,
    "Sentiment Analysis": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "This is a foundational concept in the paper, linking it to broader discussions in AI and NLP.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Data Contamination Risk",
        "canonical": "Data Contamination Risk",
        "aliases": [
          "DCR"
        ],
        "category": "unique_technical",
        "rationale": "A unique framework introduced in the paper, crucial for understanding the study's contribution.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Benchmark Data Contamination",
        "canonical": "Benchmark Data Contamination",
        "aliases": [
          "BDC"
        ],
        "category": "unique_technical",
        "rationale": "Central to the paper's focus, it highlights a specific issue in LLM evaluation.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Fuzzy Inference System",
        "canonical": "Fuzzy Inference System",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "An important method used in the paper, linking to broader discussions on inference techniques.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.77
      },
      {
        "surface": "Sentiment Analysis",
        "canonical": "Sentiment Analysis",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "One of the tasks used to validate the framework, connecting to a common NLP application.",
        "novelty_score": 0.4,
        "connectivity_score": 0.8,
        "specificity_score": 0.65,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "evaluation data",
      "performance metrics"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Data Contamination Risk",
      "resolved_canonical": "Data Contamination Risk",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Benchmark Data Contamination",
      "resolved_canonical": "Benchmark Data Contamination",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Fuzzy Inference System",
      "resolved_canonical": "Fuzzy Inference System",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Sentiment Analysis",
      "resolved_canonical": "Sentiment Analysis",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.8,
        "specificity": 0.65,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# DCR: Quantifying Data Contamination in LLMs Evaluation

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2507.11405.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2507.11405](https://arxiv.org/abs/2507.11405)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Both Text and Images Leaked! A Systematic Analysis of Data Contamination in Multimodal LLM_20250923|Both Text and Images Leaked! A Systematic Analysis of Data Contamination in Multimodal LLM]] (88.1% similar)
- [[2025-09-18/LNE-Blocking_ An Efficient Framework for Contamination Mitigation Evaluation on Large Language Models_20250918|LNE-Blocking: An Efficient Framework for Contamination Mitigation Evaluation on Large Language Models]] (87.8% similar)
- [[2025-09-22/Calibrating LLM Confidence by Probing Perturbed Representation Stability_20250922|Calibrating LLM Confidence by Probing Perturbed Representation Stability]] (86.4% similar)
- [[2025-09-23/D-REX_ A Benchmark for Detecting Deceptive Reasoning in Large Language Models_20250923|D-REX: A Benchmark for Detecting Deceptive Reasoning in Large Language Models]] (86.3% similar)
- [[2025-09-23/From Scores to Steps_ Diagnosing and Improving LLM Performance in Evidence-Based Medical Calculations_20250923|From Scores to Steps: Diagnosing and Improving LLM Performance in Evidence-Based Medical Calculations]] (85.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Fuzzy Inference System|Fuzzy Inference System]], [[keywords/Sentiment Analysis|Sentiment Analysis]]
**âš¡ Unique Technical**: [[keywords/Data Contamination Risk|Data Contamination Risk]], [[keywords/Benchmark Data Contamination|Benchmark Data Contamination]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2507.11405v2 Announce Type: replace 
Abstract: The rapid advancement of large language models (LLMs) has heightened concerns about benchmark data contamination (BDC), where models inadvertently memorize evaluation data during the training process, inflating performance metrics, and undermining genuine generalization assessment. This paper introduces the Data Contamination Risk (DCR) framework, a lightweight, interpretable pipeline designed to detect and quantify BDC risk across four granular levels: semantic, informational, data, and label. By synthesizing contamination scores via a fuzzy inference system, DCR produces a unified DCR Factor that adjusts raw accuracy to reflect contamination-aware performance. Validated on 9 LLMs (0.5B-72B) across sentiment analysis, fake news detection, and arithmetic reasoning tasks, the DCR framework reliably diagnoses contamination severity and with accuracy adjusted using the DCR Factor to within 4% average error across the three benchmarks compared to the uncontaminated baseline. Emphasizing computational efficiency and transparency, DCR provides a practical tool for integrating contamination assessment into routine evaluations, fostering fairer comparisons and enhancing the credibility of LLM benchmarking practices.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ í›ˆë ¨ ê³¼ì •ì—ì„œ í‰ê°€ ë°ì´í„°ê°€ ì˜ë„ì¹˜ ì•Šê²Œ í•™ìŠµë˜ëŠ” ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° ì˜¤ì—¼(BDC) ë¬¸ì œë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë°ì´í„° ì˜¤ì—¼ ìœ„í—˜(DCR) í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•˜ë©°, ì´ëŠ” ì˜ë¯¸ì , ì •ë³´ì , ë°ì´í„°, ë ˆì´ë¸”ì˜ ë„¤ ê°€ì§€ ìˆ˜ì¤€ì—ì„œ BDC ìœ„í—˜ì„ íƒì§€í•˜ê³  ì •ëŸ‰í™”í•©ë‹ˆë‹¤. DCRì€ í¼ì§€ ì¶”ë¡  ì‹œìŠ¤í…œì„ í†µí•´ ì˜¤ì—¼ ì ìˆ˜ë¥¼ í†µí•©í•˜ì—¬, ì˜¤ì—¼ì„ ê³ ë ¤í•œ ì„±ëŠ¥ì„ ë°˜ì˜í•˜ëŠ” DCR íŒ©í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. 9ê°œì˜ LLMì„ ëŒ€ìƒìœ¼ë¡œ ê°ì • ë¶„ì„, ê°€ì§œ ë‰´ìŠ¤ íƒì§€, ì‚°ìˆ  ì¶”ë¡  ê³¼ì œë¥¼ í†µí•´ ê²€ì¦í•œ ê²°ê³¼, DCRì€ ì˜¤ì—¼ ì‹¬ê°ë„ë¥¼ ì‹ ë¢°ì„± ìˆê²Œ ì§„ë‹¨í•˜ê³ , ì˜¤ì—¼ë˜ì§€ ì•Šì€ ê¸°ì¤€ê³¼ ë¹„êµí–ˆì„ ë•Œ í‰ê·  4% ì´ë‚´ì˜ ì˜¤ì°¨ë¡œ ì •í™•ë„ë¥¼ ì¡°ì •í•©ë‹ˆë‹¤. DCRì€ ê³„ì‚° íš¨ìœ¨ì„±ê³¼ íˆ¬ëª…ì„±ì„ ê°•ì¡°í•˜ë©°, LLM ë²¤ì¹˜ë§ˆí‚¹ì˜ ì‹ ë¢°ì„±ì„ ë†’ì´ëŠ” ì‹¤ìš©ì ì¸ ë„êµ¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ë°œì „ìœ¼ë¡œ ì¸í•´ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° ì˜¤ì—¼(BDC)ì— ëŒ€í•œ ìš°ë ¤ê°€ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤.
- 2. ë³¸ ë…¼ë¬¸ì€ BDC ìœ„í—˜ì„ íƒì§€í•˜ê³  ì •ëŸ‰í™”í•˜ê¸° ìœ„í•œ Data Contamination Risk (DCR) í”„ë ˆì„ì›Œí¬ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤.
- 3. DCRì€ ì˜ë¯¸ì , ì •ë³´ì , ë°ì´í„°, ë ˆì´ë¸”ì˜ ë„¤ ê°€ì§€ ì„¸ë¶€ ìˆ˜ì¤€ì—ì„œ ì˜¤ì—¼ ìœ„í—˜ì„ í‰ê°€í•©ë‹ˆë‹¤.
- 4. DCR í”„ë ˆì„ì›Œí¬ëŠ” 9ê°œì˜ LLMì— ëŒ€í•´ ê²€ì¦ë˜ì—ˆìœ¼ë©°, ì˜¤ì—¼ ì¸ì‹ ì„±ëŠ¥ì„ ë°˜ì˜í•˜ê¸° ìœ„í•´ ì •í™•ë„ë¥¼ ì¡°ì •í•©ë‹ˆë‹¤.
- 5. DCRì€ ê³„ì‚° íš¨ìœ¨ì„±ê³¼ íˆ¬ëª…ì„±ì„ ê°•ì¡°í•˜ë©°, LLM ë²¤ì¹˜ë§ˆí‚¹ì˜ ì‹ ë¢°ì„±ì„ ë†’ì´ëŠ” ì‹¤ìš©ì ì¸ ë„êµ¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 04:07:37*