---
keywords:
  - Visuomotor Policies
  - World Model
  - Latent Policy Steering
  - Optic Flow
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2507.13340
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T01:13:25.548281",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Visuomotor Policies",
    "World Model",
    "Latent Policy Steering",
    "Optic Flow"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Visuomotor Policies": 0.8,
    "World Model": 0.82,
    "Latent Policy Steering": 0.78,
    "Optic Flow": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "visuomotor policies",
        "canonical": "Visuomotor Policies",
        "aliases": [
          "visual motor policies"
        ],
        "category": "unique_technical",
        "rationale": "This term is central to the paper's focus on improving robot learning and is specific to the intersection of vision and motor control.",
        "novelty_score": 0.65,
        "connectivity_score": 0.72,
        "specificity_score": 0.78,
        "link_intent_score": 0.8
      },
      {
        "surface": "World Model",
        "canonical": "World Model",
        "aliases": [
          "WM"
        ],
        "category": "specific_connectable",
        "rationale": "World Models are key to the paper's methodology, providing a framework for policy improvement across different embodiments.",
        "novelty_score": 0.55,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.82
      },
      {
        "surface": "Latent Policy Steering",
        "canonical": "Latent Policy Steering",
        "aliases": [
          "LPS"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel method introduced in the paper, crucial for enhancing policy performance in the described experiments.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "optic flow",
        "canonical": "Optic Flow",
        "aliases": [
          "optical flow"
        ],
        "category": "specific_connectable",
        "rationale": "Optic flow is used as an embodiment-agnostic action representation, making it a pivotal concept for cross-embodiment learning.",
        "novelty_score": 0.5,
        "connectivity_score": 0.77,
        "specificity_score": 0.73,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "robot data",
      "training demonstrations"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "visuomotor policies",
      "resolved_canonical": "Visuomotor Policies",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.72,
        "specificity": 0.78,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "World Model",
      "resolved_canonical": "World Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Latent Policy Steering",
      "resolved_canonical": "Latent Policy Steering",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "optic flow",
      "resolved_canonical": "Optic Flow",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.77,
        "specificity": 0.73,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Latent Policy Steering with Embodiment-Agnostic Pretrained World Models

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2507.13340.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2507.13340](https://arxiv.org/abs/2507.13340)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/Self-Improving Embodied Foundation Models_20250918|Self-Improving Embodied Foundation Models]] (84.2% similar)
- [[2025-09-18/PRISM-DP_ Spatial Pose-based Observations for Diffusion-Policies via Segmentation, Mesh Generation, and Pose Tracking_20250918|PRISM-DP: Spatial Pose-based Observations for Diffusion-Policies via Segmentation, Mesh Generation, and Pose Tracking]] (83.8% similar)
- [[2025-09-18/Embracing Bulky Objects with Humanoid Robots_ Whole-Body Manipulation with Reinforcement Learning_20250918|Embracing Bulky Objects with Humanoid Robots: Whole-Body Manipulation with Reinforcement Learning]] (83.6% similar)
- [[2025-09-19/ActivePusher_ Active Learning and Planning with Residual Physics for Nonprehensile Manipulation_20250919|ActivePusher: Active Learning and Planning with Residual Physics for Nonprehensile Manipulation]] (83.3% similar)
- [[2025-09-23/Robot Learning with Sparsity and Scarcity_20250923|Robot Learning with Sparsity and Scarcity]] (83.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/World Model|World Model]], [[keywords/Optic Flow|Optic Flow]]
**âš¡ Unique Technical**: [[keywords/Visuomotor Policies|Visuomotor Policies]], [[keywords/Latent Policy Steering|Latent Policy Steering]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2507.13340v2 Announce Type: replace-cross 
Abstract: Learning visuomotor policies via imitation has proven effective across a wide range of robotic domains. However, the performance of these policies is heavily dependent on the number of training demonstrations, which requires expensive data collection in the real world. In this work, we aim to reduce data collection efforts when learning visuomotor robot policies by leveraging existing or cost-effective data from a wide range of embodiments, such as public robot datasets and the datasets of humans playing with objects (human data from play). Our approach leverages two key insights. First, we use optic flow as an embodiment-agnostic action representation to train a World Model (WM) across multi-embodiment datasets, and finetune it on a small amount of robot data from the target embodiment. Second, we develop a method, Latent Policy Steering (LPS), to improve the output of a behavior-cloned policy by searching in the latent space of the WM for better action sequences. In real world experiments, we observe significant improvements in the performance of policies trained with a small amount of data (over 50% relative improvement with 30 demonstrations and over 20% relative improvement with 50 demonstrations) by combining the policy with a WM pretrained on two thousand episodes sampled from the existing Open X-embodiment dataset across different robots or a cost-effective human dataset from play.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë¡œë´‡ì˜ ì‹œê°-ìš´ë™ ì •ì±… í•™ìŠµ ì‹œ ë°ì´í„° ìˆ˜ì§‘ ë¹„ìš©ì„ ì¤„ì´ê¸° ìœ„í•œ ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë¡œë´‡ ë°ì´í„°ì…‹ê³¼ ì¸ê°„ì˜ ë†€ì´ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ë°ì´í„° ìˆ˜ì§‘ì„ ìµœì†Œí™”í•˜ê³ ì í•©ë‹ˆë‹¤. ì£¼ìš” ê¸°ì—¬ëŠ” ë‘ ê°€ì§€ì…ë‹ˆë‹¤. ì²«ì§¸, ë‹¤ì–‘í•œ êµ¬í˜„ì²´ì˜ ë°ì´í„°ì…‹ì„ í™œìš©í•´ ì„¸ê³„ ëª¨ë¸(WM)ì„ í›ˆë ¨í•˜ê³ , ëª©í‘œ ë¡œë´‡ ë°ì´í„°ë¡œ ë¯¸ì„¸ ì¡°ì •í•©ë‹ˆë‹¤. ë‘˜ì§¸, ì ì¬ ê³µê°„ì—ì„œ ë” ë‚˜ì€ í–‰ë™ ì‹œí€€ìŠ¤ë¥¼ íƒìƒ‰í•˜ëŠ” ì ì¬ ì •ì±… ì¡°ì •(LPS) ë°©ë²•ì„ ê°œë°œí–ˆìŠµë‹ˆë‹¤. ì‹¤ì œ ì‹¤í—˜ì—ì„œ, 30ê°œì˜ ì‹œì—°ìœ¼ë¡œ 50% ì´ìƒ, 50ê°œì˜ ì‹œì—°ìœ¼ë¡œ 20% ì´ìƒì˜ ì„±ëŠ¥ í–¥ìƒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì‹œê°-ìš´ë™ ì •ì±… í•™ìŠµì€ ë‹¤ì–‘í•œ ë¡œë´‡ ë¶„ì•¼ì—ì„œ íš¨ê³¼ì ì´ì§€ë§Œ, ë§ì€ í›ˆë ¨ ì‹œì—°ì´ í•„ìš”í•˜ì—¬ ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ ë¹„ìš©ì´ ë†’ìŠµë‹ˆë‹¤.
- 2. ë³¸ ì—°êµ¬ëŠ” ê³µê³µ ë¡œë´‡ ë°ì´í„°ì…‹ê³¼ ì¸ê°„ì˜ ë†€ì´ ë°ì´í„°ì…‹ ê°™ì€ ê¸°ì¡´ ë˜ëŠ” ì €ë¹„ìš© ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ë°ì´í„° ìˆ˜ì§‘ ë…¸ë ¥ì„ ì¤„ì´ê³ ì í•©ë‹ˆë‹¤.
- 3. ê´‘ë¥˜(optic flow)ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ì–‘í•œ êµ¬í˜„ ë°ì´í„°ì…‹ì—ì„œ ì„¸ê³„ ëª¨ë¸(WM)ì„ í›ˆë ¨í•˜ê³ , ëª©í‘œ êµ¬í˜„ì˜ ì†ŒëŸ‰ ë¡œë´‡ ë°ì´í„°ë¡œ ë¯¸ì„¸ ì¡°ì •í•©ë‹ˆë‹¤.
- 4. ì ì¬ ì •ì±… ì¡°ì •(LPS) ë°©ë²•ì„ ê°œë°œí•˜ì—¬ í–‰ë™ ë³µì œ ì •ì±…ì˜ ì¶œë ¥ì„ ê°œì„ í•˜ê³ , WMì˜ ì ì¬ ê³µê°„ì—ì„œ ë” ë‚˜ì€ í–‰ë™ ì‹œí€€ìŠ¤ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
- 5. ì‹¤ì œ ì‹¤í—˜ì—ì„œ, ê¸°ì¡´ ë°ì´í„°ì…‹ì„ í™œìš©í•œ WM ì‚¬ì „ í›ˆë ¨ì„ í†µí•´ ì ì€ ì–‘ì˜ ë°ì´í„°ë¡œ í›ˆë ¨ëœ ì •ì±…ì˜ ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 01:13:25*