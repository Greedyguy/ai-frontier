---
keywords:
  - Neural Network
  - Concept Bottleneck Model
  - Spatially-Aware Concept Bottleneck Model
  - Zero-Shot Learning
category: cs.CV
publish_date: 2025-09-23
arxiv_id: 2502.20134
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T05:18:06.408771",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Neural Network",
    "Concept Bottleneck Model",
    "Spatially-Aware Concept Bottleneck Model",
    "Zero-Shot Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Neural Network": 0.85,
    "Concept Bottleneck Model": 0.8,
    "Spatially-Aware Concept Bottleneck Model": 0.78,
    "Zero-Shot Learning": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Deep Neural Networks",
        "canonical": "Neural Network",
        "aliases": [
          "DNN",
          "Deep Learning Models"
        ],
        "category": "broad_technical",
        "rationale": "Neural networks are central to the paper's methodology and connect to a wide range of related research.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Concept Bottleneck Models",
        "canonical": "Concept Bottleneck Model",
        "aliases": [
          "CBM",
          "Concept Bottleneck"
        ],
        "category": "unique_technical",
        "rationale": "This is a core innovation of the paper, offering a new approach to model interpretability.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Spatially-Aware Concept Bottleneck Model",
        "canonical": "Spatially-Aware Concept Bottleneck Model",
        "aliases": [
          "SALF-CBM"
        ],
        "category": "unique_technical",
        "rationale": "This specific model is a novel contribution that enhances interpretability in neural networks.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.9,
        "link_intent_score": 0.78
      },
      {
        "surface": "Zero-Shot Segmentation",
        "canonical": "Zero-Shot Learning",
        "aliases": [
          "Zero-Shot Segmentation Task"
        ],
        "category": "specific_connectable",
        "rationale": "The paper demonstrates improved performance in zero-shot tasks, linking to broader zero-shot learning research.",
        "novelty_score": 0.5,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "task",
      "model"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Deep Neural Networks",
      "resolved_canonical": "Neural Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Concept Bottleneck Models",
      "resolved_canonical": "Concept Bottleneck Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Spatially-Aware Concept Bottleneck Model",
      "resolved_canonical": "Spatially-Aware Concept Bottleneck Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.9,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Zero-Shot Segmentation",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Show and Tell: Visually Explainable Deep Neural Nets via Spatially-Aware Concept Bottleneck Models

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2502.20134.pdf)
**Category**: cs.CV
**Published**: 2025-09-23
**ArXiv ID**: [2502.20134](https://arxiv.org/abs/2502.20134)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Chat-CBM_ Towards Interactive Concept Bottleneck Models with Frozen Large Language Models_20250923|Chat-CBM: Towards Interactive Concept Bottleneck Models with Frozen Large Language Models]] (85.0% similar)
- [[2025-09-22/Bayesian Concept Bottleneck Models with LLM Priors_20250922|Bayesian Concept Bottleneck Models with LLM Priors]] (84.4% similar)
- [[2025-09-23/V-CECE_ Visual Counterfactual Explanations via Conceptual Edits_20250923|V-CECE: Visual Counterfactual Explanations via Conceptual Edits]] (83.1% similar)
- [[2025-09-22/Multi-Modal Interpretability for Enhanced Localization in Vision-Language Models_20250922|Multi-Modal Interpretability for Enhanced Localization in Vision-Language Models]] (82.7% similar)
- [[2025-09-23/WISE_ Weak-Supervision-Guided Step-by-Step Explanations for Multimodal LLMs in Image Classification_20250923|WISE: Weak-Supervision-Guided Step-by-Step Explanations for Multimodal LLMs in Image Classification]] (82.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Neural Network|Neural Network]]
**ğŸ”— Specific Connectable**: [[keywords/Zero-Shot Learning|Zero-Shot Learning]]
**âš¡ Unique Technical**: [[keywords/Concept Bottleneck Model|Concept Bottleneck Model]], [[keywords/Spatially-Aware Concept Bottleneck Model|Spatially-Aware Concept Bottleneck Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2502.20134v4 Announce Type: replace 
Abstract: Modern deep neural networks have now reached human-level performance across a variety of tasks. However, unlike humans they lack the ability to explain their decisions by showing where and telling what concepts guided them. In this work, we present a unified framework for transforming any vision neural network into a spatially and conceptually interpretable model. We introduce a spatially-aware concept bottleneck layer that projects "black-box" features of pre-trained backbone models into interpretable concept maps, without requiring human labels. By training a classification layer over this bottleneck, we obtain a self-explaining model that articulates which concepts most influenced its prediction, along with heatmaps that ground them in the input image. Accordingly, we name this method "Spatially-Aware and Label-Free Concept Bottleneck Model" (SALF-CBM). Our results show that the proposed SALF-CBM: (1) Outperforms non-spatial CBM methods, as well as the original backbone, on a variety of classification tasks; (2) Produces high-quality spatial explanations, outperforming widely used heatmap-based methods on a zero-shot segmentation task; (3) Facilitates model exploration and debugging, enabling users to query specific image regions and refine the model's decisions by locally editing its concept maps.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” ëª¨ë“  ë¹„ì „ ì‹ ê²½ë§ì„ ê³µê°„ì  ë° ê°œë…ì ìœ¼ë¡œ í•´ì„ ê°€ëŠ¥í•œ ëª¨ë¸ë¡œ ë³€í™˜í•˜ëŠ” í†µí•© í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì—°êµ¬ì—ì„œëŠ” ì¸ê°„ì˜ ë ˆì´ë¸” ì—†ì´ë„ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì˜ "ë¸”ë™ë°•ìŠ¤" íŠ¹ì§•ì„ í•´ì„ ê°€ëŠ¥í•œ ê°œë… ë§µìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê³µê°„ ì¸ì‹ ê°œë… ë³‘ëª©ì¸µì„ ë„ì…í–ˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì˜ˆì¸¡ì— ê°€ì¥ í° ì˜í–¥ì„ ë¯¸ì¹œ ê°œë…ì„ ì„¤ëª…í•˜ê³  ì…ë ¥ ì´ë¯¸ì§€ì— ì´ë¥¼ ì‹œê°ì ìœ¼ë¡œ í‘œí˜„í•˜ëŠ” ìê¸° ì„¤ëª… ëª¨ë¸ì„ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤. ì œì•ˆëœ ë°©ë²•ì¸ SALF-CBMì€ ë‹¤ì–‘í•œ ë¶„ë¥˜ ì‘ì—…ì—ì„œ ê¸°ì¡´ ë°©ë²•ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë©°, ê³ í’ˆì§ˆì˜ ê³µê°„ì  ì„¤ëª…ì„ ì œê³µí•˜ì—¬ ëª¨ë¸ íƒìƒ‰ ë° ë””ë²„ê¹…ì„ ìš©ì´í•˜ê²Œ í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. SALF-CBMì€ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì˜ "ë¸”ë™ë°•ìŠ¤" íŠ¹ì§•ì„ í•´ì„ ê°€ëŠ¥í•œ ê°œë… ì§€ë„ì— íˆ¬ì˜í•˜ì—¬ ê³µê°„ì  ë° ê°œë…ì ìœ¼ë¡œ í•´ì„ ê°€ëŠ¥í•œ ëª¨ë¸ì„ ì œê³µí•©ë‹ˆë‹¤.
- 2. ì´ ëª¨ë¸ì€ ì¸ê°„ì˜ ë ˆì´ë¸” ì—†ì´ë„ ê³µê°„ì ìœ¼ë¡œ ì¸ì‹ ê°€ëŠ¥í•œ ê°œë… ë³‘ëª© ë ˆì´ì–´ë¥¼ ë„ì…í•˜ì—¬ ëª¨ë¸ì˜ ì˜ˆì¸¡ì— ê°€ì¥ í° ì˜í–¥ì„ ë¯¸ì¹œ ê°œë…ì„ ì„¤ëª…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- 3. SALF-CBMì€ ë‹¤ì–‘í•œ ë¶„ë¥˜ ì‘ì—…ì—ì„œ ë¹„ê³µê°„ì  CBM ë°©ë²• ë° ì›ë˜ ë°±ë³¸ ëª¨ë¸ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.
- 4. ì œì•ˆëœ ëª¨ë¸ì€ ì œë¡œìƒ· ë¶„í•  ì‘ì—…ì—ì„œ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” íˆíŠ¸ë§µ ê¸°ë°˜ ë°©ë²•ë³´ë‹¤ ë›°ì–´ë‚œ ê³ í’ˆì§ˆì˜ ê³µê°„ì  ì„¤ëª…ì„ ìƒì„±í•©ë‹ˆë‹¤.
- 5. ì‚¬ìš©ìëŠ” íŠ¹ì • ì´ë¯¸ì§€ ì˜ì—­ì„ ì¿¼ë¦¬í•˜ê³  ê°œë… ì§€ë„ë¥¼ ë¡œì»¬ë¡œ í¸ì§‘í•˜ì—¬ ëª¨ë¸ì˜ ê²°ì •ì„ ê°œì„ í•  ìˆ˜ ìˆì–´ ëª¨ë¸ íƒìƒ‰ ë° ë””ë²„ê¹…ì„ ìš©ì´í•˜ê²Œ í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 05:18:06*