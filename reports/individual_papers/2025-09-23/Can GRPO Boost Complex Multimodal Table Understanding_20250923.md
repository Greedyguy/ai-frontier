---
keywords:
  - Group Relative Policy Optimization
  - Multimodal Learning
  - Table-R1
  - Vision-Language Model
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2509.16889
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:19:42.066721",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Group Relative Policy Optimization",
    "Multimodal Learning",
    "Table-R1",
    "Vision-Language Model"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Group Relative Policy Optimization": 0.8,
    "Multimodal Learning": 0.85,
    "Table-R1": 0.75,
    "Vision-Language Model": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Group Relative Policy Optimization",
        "canonical": "Group Relative Policy Optimization",
        "aliases": [
          "GRPO"
        ],
        "category": "unique_technical",
        "rationale": "GRPO is central to the paper's proposed method and is not widely recognized, making it a unique technical term.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Multimodal Table Understanding",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal Table Understanding"
        ],
        "category": "specific_connectable",
        "rationale": "Multimodal learning is a key aspect of the paper's focus, linking it to broader multimodal research.",
        "novelty_score": 0.55,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Table-R1",
        "canonical": "Table-R1",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Table-R1 is a novel framework introduced in the paper, representing a unique contribution to the field.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.9,
        "link_intent_score": 0.75
      },
      {
        "surface": "Vision-Language Model",
        "canonical": "Vision-Language Model",
        "aliases": [
          "Vision-Language"
        ],
        "category": "evolved_concepts",
        "rationale": "The paper's context involves vision-language models, which are a trending area of research.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "supervised finetuning",
      "reinforcement learning",
      "table reasoning performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Group Relative Policy Optimization",
      "resolved_canonical": "Group Relative Policy Optimization",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Multimodal Table Understanding",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Table-R1",
      "resolved_canonical": "Table-R1",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.9,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Vision-Language Model",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# Can GRPO Boost Complex Multimodal Table Understanding?

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16889.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2509.16889](https://arxiv.org/abs/2509.16889)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/TableDART_ Dynamic Adaptive Multi-Modal Routing for Table Understanding_20250919|TableDART: Dynamic Adaptive Multi-Modal Routing for Table Understanding]] (85.4% similar)
- [[2025-09-23/Table2LaTeX-RL_ High-Fidelity LaTeX Code Generation from Table Images via Reinforced Multimodal Language Models_20250923|Table2LaTeX-RL: High-Fidelity LaTeX Code Generation from Table Images via Reinforced Multimodal Language Models]] (83.9% similar)
- [[2025-09-23/Improving Deep Tabular Learning_20250923|Improving Deep Tabular Learning]] (82.5% similar)
- [[2025-09-18/TDRM_ Smooth Reward Models with Temporal Difference for LLM RL and Inference_20250918|TDRM: Smooth Reward Models with Temporal Difference for LLM RL and Inference]] (81.1% similar)
- [[2025-09-22/ChronoForge-RL_ Chronological Forging through Reinforcement Learning for Enhanced Video Understanding_20250922|ChronoForge-RL: Chronological Forging through Reinforcement Learning for Enhanced Video Understanding]] (81.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**âš¡ Unique Technical**: [[keywords/Group Relative Policy Optimization|Group Relative Policy Optimization]], [[keywords/Table-R1|Table-R1]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16889v1 Announce Type: new 
Abstract: Existing table understanding methods face challenges due to complex table structures and intricate logical reasoning. While supervised finetuning (SFT) dominates existing research, reinforcement learning (RL), such as Group Relative Policy Optimization (GRPO), has shown promise but struggled with low initial policy accuracy and coarse rewards in tabular contexts. In this paper, we introduce Table-R1, a three-stage RL framework that enhances multimodal table understanding through: (1) Warm-up that prompts initial perception and reasoning capabilities, (2) Perception Alignment GRPO (PA-GRPO), which employs continuous Tree-Edit-Distance Similarity (TEDS) rewards for recognizing table structures and contents, and (3) Hint-Completion GRPO (HC-GRPO), which utilizes fine-grained rewards of residual steps based on the hint-guided question. Extensive experiments demonstrate that Table-R1 can boost the model's table reasoning performance obviously on both held-in and held-out datasets, outperforming SFT and GRPO largely. Notably, Qwen2-VL-7B with Table-R1 surpasses larger specific table understanding models (e.g., Table-LLaVA 13B), even achieving comparable performance to the closed-source model GPT-4o on held-in datasets, demonstrating the efficacy of each stage of Table-R1 in overcoming initialization bottlenecks and reward sparsity, thereby advancing robust multimodal table understanding.

## ğŸ“ ìš”ì•½

ê¸°ì¡´ì˜ í…Œì´ë¸” ì´í•´ ë°©ë²•ì€ ë³µì¡í•œ í…Œì´ë¸” êµ¬ì¡°ì™€ ë…¼ë¦¬ì  ì¶”ë¡ ì˜ ì–´ë ¤ì›€ ë•Œë¬¸ì— í•œê³„ë¥¼ ê²ªê³  ìˆìŠµë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ Table-R1ì´ë¼ëŠ” 3ë‹¨ê³„ ê°•í™” í•™ìŠµ(RL) í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì²«ì§¸, ì´ˆê¸° ì¸ì‹ ë° ì¶”ë¡  ëŠ¥ë ¥ì„ ì´‰ì§„í•˜ëŠ” 'ì›Œë°ì—…' ë‹¨ê³„, ë‘˜ì§¸, í…Œì´ë¸” êµ¬ì¡°ì™€ ë‚´ìš©ì„ ì¸ì‹í•˜ê¸° ìœ„í•œ ì—°ì†ì  Tree-Edit-Distance Similarity(TEDS) ë³´ìƒì„ ì‚¬ìš©í•˜ëŠ” 'Perception Alignment GRPO(PA-GRPO)', ì…‹ì§¸, íŒíŠ¸ ê¸°ë°˜ ì§ˆë¬¸ì— ë”°ë¥¸ ì„¸ë¶€ì ì¸ ë³´ìƒì„ í™œìš©í•˜ëŠ” 'Hint-Completion GRPO(HC-GRPO)'ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, Table-R1ì€ ê¸°ì¡´ì˜ ê°ë… í•™ìŠµ(SFT) ë° GRPOë¥¼ í¬ê²Œ ëŠ¥ê°€í•˜ë©°, íŠ¹íˆ Qwen2-VL-7B ëª¨ë¸ì´ Table-R1ì„ í†µí•´ ë” í° í…Œì´ë¸” ì´í•´ ëª¨ë¸ì„ ë›°ì–´ë„˜ëŠ” ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ì´ëŠ” ì´ˆê¸°í™” ë¬¸ì œì™€ ë³´ìƒ í¬ì†Œì„±ì„ ê·¹ë³µí•˜ì—¬ ê°•ë ¥í•œ ë‹¤ì¤‘ ëª¨ë‹¬ í…Œì´ë¸” ì´í•´ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Table-R1ì€ ë³µì¡í•œ í…Œì´ë¸” êµ¬ì¡°ì™€ ë…¼ë¦¬ì  ì¶”ë¡ ì„ ê°œì„ í•˜ê¸° ìœ„í•´ ì„¸ ë‹¨ê³„ì˜ ê°•í™” í•™ìŠµ í”„ë ˆì„ì›Œí¬ë¥¼ ë„ì…í•©ë‹ˆë‹¤.
- 2. PA-GRPOëŠ” ì—°ì†ì ì¸ Tree-Edit-Distance Similarity (TEDS) ë³´ìƒì„ í™œìš©í•˜ì—¬ í…Œì´ë¸” êµ¬ì¡°ì™€ ë‚´ìš©ì„ ì¸ì‹í•©ë‹ˆë‹¤.
- 3. HC-GRPOëŠ” íŒíŠ¸ ê¸°ë°˜ ì§ˆë¬¸ì— ë”°ë¼ ì”ì—¬ ë‹¨ê³„ì˜ ì„¸ë°€í•œ ë³´ìƒì„ í™œìš©í•©ë‹ˆë‹¤.
- 4. Table-R1ì€ SFTì™€ ê¸°ì¡´ GRPOë¥¼ ëŠ¥ê°€í•˜ë©°, íŠ¹íˆ Qwen2-VL-7B ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
- 5. Table-R1ì€ ì´ˆê¸°í™” ë³‘ëª© í˜„ìƒê³¼ ë³´ìƒ í¬ì†Œì„±ì„ ê·¹ë³µí•˜ì—¬ ê°•ë ¥í•œ ë©€í‹°ëª¨ë‹¬ í…Œì´ë¸” ì´í•´ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 03:19:42*