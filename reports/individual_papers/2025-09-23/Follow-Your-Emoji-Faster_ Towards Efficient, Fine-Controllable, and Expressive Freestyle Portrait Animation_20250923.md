---
keywords:
  - Diffusion Model
  - Facial Landmarks
  - Expression-Aware Landmarks
  - Fine-Grained Facial Loss
  - Progressive Generation
category: cs.CV
publish_date: 2025-09-23
arxiv_id: 2509.16630
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T04:28:40.238319",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Diffusion Model",
    "Facial Landmarks",
    "Expression-Aware Landmarks",
    "Fine-Grained Facial Loss",
    "Progressive Generation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Diffusion Model": 0.78,
    "Facial Landmarks": 0.81,
    "Expression-Aware Landmarks": 0.79,
    "Fine-Grained Facial Loss": 0.77,
    "Progressive Generation": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "diffusion-based framework",
        "canonical": "Diffusion Model",
        "aliases": [
          "diffusion framework",
          "diffusion-based model"
        ],
        "category": "broad_technical",
        "rationale": "Diffusion models are a key component in generative modeling, linking to broader machine learning discussions.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.78
      },
      {
        "surface": "facial landmarks",
        "canonical": "Facial Landmarks",
        "aliases": [
          "face landmarks",
          "landmark points"
        ],
        "category": "specific_connectable",
        "rationale": "Facial landmarks are essential for animation and recognition tasks, providing a bridge to computer vision topics.",
        "novelty_score": 0.45,
        "connectivity_score": 0.85,
        "specificity_score": 0.72,
        "link_intent_score": 0.81
      },
      {
        "surface": "expression-aware landmarks",
        "canonical": "Expression-Aware Landmarks",
        "aliases": [
          "emotion landmarks",
          "expression landmarks"
        ],
        "category": "unique_technical",
        "rationale": "This concept is unique to the paper, enhancing the understanding of emotion representation in animations.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.82,
        "link_intent_score": 0.79
      },
      {
        "surface": "fine-grained facial loss",
        "canonical": "Fine-Grained Facial Loss",
        "aliases": [
          "detailed facial loss",
          "facial loss function"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel loss function for better expression capture, relevant to deep learning optimization.",
        "novelty_score": 0.68,
        "connectivity_score": 0.72,
        "specificity_score": 0.78,
        "link_intent_score": 0.77
      },
      {
        "surface": "progressive generation strategy",
        "canonical": "Progressive Generation",
        "aliases": [
          "progressive animation",
          "stepwise generation"
        ],
        "category": "specific_connectable",
        "rationale": "This strategy is crucial for achieving stable animations, linking to iterative improvement methods.",
        "novelty_score": 0.58,
        "connectivity_score": 0.79,
        "specificity_score": 0.7,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "efficiency"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "diffusion-based framework",
      "resolved_canonical": "Diffusion Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "facial landmarks",
      "resolved_canonical": "Facial Landmarks",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.85,
        "specificity": 0.72,
        "link_intent": 0.81
      }
    },
    {
      "candidate_surface": "expression-aware landmarks",
      "resolved_canonical": "Expression-Aware Landmarks",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.82,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "fine-grained facial loss",
      "resolved_canonical": "Fine-Grained Facial Loss",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.72,
        "specificity": 0.78,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "progressive generation strategy",
      "resolved_canonical": "Progressive Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.79,
        "specificity": 0.7,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Follow-Your-Emoji-Faster: Towards Efficient, Fine-Controllable, and Expressive Freestyle Portrait Animation

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16630.pdf)
**Category**: cs.CV
**Published**: 2025-09-23
**ArXiv ID**: [2509.16630](https://arxiv.org/abs/2509.16630)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Controllable Localized Face Anonymization Via Diffusion Inpainting_20250919|Controllable Localized Face Anonymization Via Diffusion Inpainting]] (83.2% similar)
- [[2025-09-22/FLOAT_ Generative Motion Latent Flow Matching for Audio-driven Talking Portrait_20250922|FLOAT: Generative Motion Latent Flow Matching for Audio-driven Talking Portrait]] (83.2% similar)
- [[2025-09-22/Lynx_ Towards High-Fidelity Personalized Video Generation_20250922|Lynx: Towards High-Fidelity Personalized Video Generation]] (80.8% similar)
- [[2025-09-22/Tiny is not small enough_ High-quality, low-resource facial animation models through hybrid knowledge distillation_20250922|Tiny is not small enough: High-quality, low-resource facial animation models through hybrid knowledge distillation]] (80.7% similar)
- [[2025-09-22/RespoDiff_ Dual-Module Bottleneck Transformation for Responsible & Faithful T2I Generation_20250922|RespoDiff: Dual-Module Bottleneck Transformation for Responsible & Faithful T2I Generation]] (80.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Diffusion Model|Diffusion Model]]
**ğŸ”— Specific Connectable**: [[keywords/Facial Landmarks|Facial Landmarks]], [[keywords/Progressive Generation|Progressive Generation]]
**âš¡ Unique Technical**: [[keywords/Expression-Aware Landmarks|Expression-Aware Landmarks]], [[keywords/Fine-Grained Facial Loss|Fine-Grained Facial Loss]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16630v1 Announce Type: new 
Abstract: We present Follow-Your-Emoji-Faster, an efficient diffusion-based framework for freestyle portrait animation driven by facial landmarks. The main challenges in this task are preserving the identity of the reference portrait, accurately transferring target expressions, and maintaining long-term temporal consistency while ensuring generation efficiency. To address identity preservation and accurate expression retargeting, we enhance Stable Diffusion with two key components: a expression-aware landmarks as explicit motion signals, which improve motion alignment, support exaggerated expressions, and reduce identity leakage; and a fine-grained facial loss that leverages both expression and facial masks to better capture subtle expressions and faithfully preserve the reference appearance. With these components, our model supports controllable and expressive animation across diverse portrait types, including real faces, cartoons, sculptures, and animals. However, diffusion-based frameworks typically struggle to efficiently generate long-term stable animation results, which remains a core challenge in this task. To address this, we propose a progressive generation strategy for stable long-term animation, and introduce a Taylor-interpolated cache, achieving a 2.6X lossless acceleration. These two strategies ensure that our method produces high-quality results efficiently, making it user-friendly and accessible. Finally, we introduce EmojiBench++, a more comprehensive benchmark comprising diverse portraits, driving videos, and landmark sequences. Extensive evaluations on EmojiBench++ demonstrate that Follow-Your-Emoji-Faster achieves superior performance in both animation quality and controllability. The code, training dataset and benchmark will be found in https://follow-your-emoji.github.io/.

## ğŸ“ ìš”ì•½

Follow-Your-Emoji-FasterëŠ” ì–¼êµ´ ëœë“œë§ˆí¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì´ˆìƒí™” ì• ë‹ˆë©”ì´ì…˜ í”„ë ˆì„ì›Œí¬ë¡œ, ì •ì²´ì„± ìœ ì§€, í‘œì • ì „ì´, ì¥ê¸°ì  ì¼ê´€ì„±ì„ í•´ê²°í•©ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ í‘œí˜„ ì¸ì‹ ëœë“œë§ˆí¬ì™€ ì„¸ë°€í•œ ì–¼êµ´ ì†ì‹¤ì„ í†µí•´ ëª¨ì…˜ ì •ë ¬ê³¼ ì •ì²´ì„± ìœ ì¶œ ê°ì†Œë¥¼ ê°œì„ í•˜ë©°, ë‹¤ì–‘í•œ ì´ˆìƒí™” ìœ í˜•ì— ëŒ€í•´ í‘œí˜„ë ¥ ìˆëŠ” ì• ë‹ˆë©”ì´ì…˜ì„ ì§€ì›í•©ë‹ˆë‹¤. ë˜í•œ, ì¥ê¸°ì  ì•ˆì •ì„±ì„ ìœ„í•œ ì ì§„ì  ìƒì„± ì „ëµê³¼ í…Œì¼ëŸ¬ ë³´ê°„ ìºì‹œë¥¼ ë„ì…í•˜ì—¬ 2.6ë°°ì˜ ê°€ì†ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. EmojiBench++ ë²¤ì¹˜ë§ˆí¬ í‰ê°€ì—ì„œ ë†’ì€ í’ˆì§ˆê³¼ ì œì–´ì„±ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Follow-Your-Emoji-FasterëŠ” ì–¼êµ´ ëœë“œë§ˆí¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ììœ ë¡œìš´ ì´ˆìƒí™” ì• ë‹ˆë©”ì´ì…˜ì„ ìœ„í•œ íš¨ìœ¨ì ì¸ í™•ì‚° ê¸°ë°˜ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.
- 2. ì´ ëª¨ë¸ì€ í‘œí˜„ ì¸ì‹ ëœë“œë§ˆí¬ì™€ ì„¸ë°€í•œ ì–¼êµ´ ì†ì‹¤ì„ í†µí•´ ì°¸ì¡° ì´ˆìƒì˜ ì •ì²´ì„±ì„ ë³´ì¡´í•˜ê³  ëª©í‘œ í‘œí˜„ì„ ì •í™•í•˜ê²Œ ì „ë‹¬í•©ë‹ˆë‹¤.
- 3. ì¥ê¸°ì ì¸ ì•ˆì •ì ì¸ ì• ë‹ˆë©”ì´ì…˜ ìƒì„±ì„ ìœ„í•´ ì ì§„ì  ìƒì„± ì „ëµê³¼ í…Œì¼ëŸ¬ ë³´ê°„ ìºì‹œë¥¼ ë„ì…í•˜ì—¬ 2.6ë°°ì˜ ë¬´ì†ì‹¤ ê°€ì†ì„ ë‹¬ì„±í•©ë‹ˆë‹¤.
- 4. EmojiBench++ë¼ëŠ” í¬ê´„ì ì¸ ë²¤ì¹˜ë§ˆí¬ë¥¼ í†µí•´ ë‹¤ì–‘í•œ ì´ˆìƒí™”ì™€ êµ¬ë™ ë¹„ë””ì˜¤, ëœë“œë§ˆí¬ ì‹œí€€ìŠ¤ë¥¼ í‰ê°€í•˜ë©°, ë›°ì–´ë‚œ ì• ë‹ˆë©”ì´ì…˜ í’ˆì§ˆê³¼ ì œì–´ ê°€ëŠ¥ì„±ì„ ì…ì¦í•©ë‹ˆë‹¤.
- 5. ì´ ì—°êµ¬ì˜ ì½”ë“œ, í•™ìŠµ ë°ì´í„°ì…‹ ë° ë²¤ì¹˜ë§ˆí¬ëŠ” https://follow-your-emoji.github.io/ì—ì„œ ì œê³µë©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 04:28:40*