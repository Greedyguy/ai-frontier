---
keywords:
  - Machine Translation
  - Large Language Model
  - Specification-Aware Translation
  - Investor Relations Texts
  - Human Evaluation
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2509.17559
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:29:57.565511",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Machine Translation",
    "Large Language Model",
    "Specification-Aware Translation",
    "Investor Relations Texts",
    "Human Evaluation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Machine Translation": 0.78,
    "Large Language Model": 0.8,
    "Specification-Aware Translation": 0.85,
    "Investor Relations Texts": 0.7,
    "Human Evaluation": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Machine Translation",
        "canonical": "Machine Translation",
        "aliases": [
          "MT"
        ],
        "category": "broad_technical",
        "rationale": "Machine Translation is a core concept in the paper, linking it to broader NLP discussions.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.78
      },
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "The paper discusses LLMs extensively, connecting it to ongoing research in NLP and AI.",
        "novelty_score": 0.4,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Specification-Aware Translation",
        "canonical": "Specification-Aware Translation",
        "aliases": [
          "specification-driven translation"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel approach introduced in the paper, highlighting its unique contribution to MT.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.85
      },
      {
        "surface": "Investor Relations Texts",
        "canonical": "Investor Relations Texts",
        "aliases": [
          "IR texts"
        ],
        "category": "unique_technical",
        "rationale": "Specific domain application that can link to financial communication studies.",
        "novelty_score": 0.65,
        "connectivity_score": 0.55,
        "specificity_score": 0.78,
        "link_intent_score": 0.7
      },
      {
        "surface": "Human Evaluation",
        "canonical": "Human Evaluation",
        "aliases": [
          "expert evaluation"
        ],
        "category": "specific_connectable",
        "rationale": "Human evaluation is crucial for assessing translation quality, connecting to broader evaluation methodologies.",
        "novelty_score": 0.5,
        "connectivity_score": 0.75,
        "specificity_score": 0.68,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "translation types",
      "automatic metric",
      "user preference rankings"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Machine Translation",
      "resolved_canonical": "Machine Translation",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Specification-Aware Translation",
      "resolved_canonical": "Specification-Aware Translation",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Investor Relations Texts",
      "resolved_canonical": "Investor Relations Texts",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.55,
        "specificity": 0.78,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Human Evaluation",
      "resolved_canonical": "Human Evaluation",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.75,
        "specificity": 0.68,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# Specification-Aware Machine Translation and Evaluation for Purpose Alignment

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17559.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2509.17559](https://arxiv.org/abs/2509.17559)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/Audio-Based Crowd-Sourced Evaluation of Machine Translation Quality_20250918|Audio-Based Crowd-Sourced Evaluation of Machine Translation Quality]] (84.4% similar)
- [[2025-09-22/Translationese-index_ Using Likelihood Ratios for Graded and Generalizable Measurement of Translationese_20250922|Translationese-index: Using Likelihood Ratios for Graded and Generalizable Measurement of Translationese]] (82.2% similar)
- [[2025-09-23/Extending Automatic Machine Translation Evaluation to Book-Length Documents_20250923|Extending Automatic Machine Translation Evaluation to Book-Length Documents]] (81.8% similar)
- [[2025-09-17/Long-context Reference-based MT Quality Estimation_20250917|Long-context Reference-based MT Quality Estimation]] (80.9% similar)
- [[2025-09-22/MT-RewardTree_ A Comprehensive Framework for Advancing LLM-Based Machine Translation via Reward Modeling_20250922|MT-RewardTree: A Comprehensive Framework for Advancing LLM-Based Machine Translation via Reward Modeling]] (80.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Machine Translation|Machine Translation]], [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Human Evaluation|Human Evaluation]]
**âš¡ Unique Technical**: [[keywords/Specification-Aware Translation|Specification-Aware Translation]], [[keywords/Investor Relations Texts|Investor Relations Texts]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17559v1 Announce Type: new 
Abstract: In professional settings, translation is guided by communicative goals and client needs, often formalized as specifications. While existing evaluation frameworks acknowledge the importance of such specifications, these specifications are often treated only implicitly in machine translation (MT) research. Drawing on translation studies, we provide a theoretical rationale for why specifications matter in professional translation, as well as a practical guide to implementing specification-aware MT and evaluation. Building on this foundation, we apply our framework to the translation of investor relations texts from 33 publicly listed companies. In our experiment, we compare five translation types, including official human translations and prompt-based outputs from large language models (LLMs), using expert error analysis, user preference rankings, and an automatic metric. The results show that LLM translations guided by specifications consistently outperformed official human translations in human evaluations, highlighting a gap between perceived and expected quality. These findings demonstrate that integrating specifications into MT workflows, with human oversight, can improve translation quality in ways aligned with professional practice.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë²ˆì—­ ì‘ì—…ì—ì„œ ì˜ì‚¬ì†Œí†µ ëª©í‘œì™€ ê³ ê° ìš”êµ¬ ì‚¬í•­ì„ ë°˜ì˜í•œ ëª…ì„¸ì˜ ì¤‘ìš”ì„±ì„ ê°•ì¡°í•˜ë©°, ì´ë¥¼ ê¸°ê³„ ë²ˆì—­(MT) ì—°êµ¬ì— í†µí•©í•˜ëŠ” ë°©ë²•ë¡ ì„ ì œì‹œí•©ë‹ˆë‹¤. ì—°êµ¬ëŠ” 33ê°œ ìƒì¥ ê¸°ì—…ì˜ íˆ¬ìì ê´€ê³„ í…ìŠ¤íŠ¸ ë²ˆì—­ì— ì´ í”„ë ˆì„ì›Œí¬ë¥¼ ì ìš©í•˜ì—¬, ê³µì‹ ì¸ê°„ ë²ˆì—­ê³¼ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ëª…ì„¸ ê¸°ë°˜ ë²ˆì—­ì„ ë¹„êµí–ˆìŠµë‹ˆë‹¤. ì „ë¬¸ê°€ ì˜¤ë¥˜ ë¶„ì„, ì‚¬ìš©ì ì„ í˜¸ë„ í‰ê°€, ìë™ ì§€í‘œë¥¼ í†µí•´ í‰ê°€í•œ ê²°ê³¼, ëª…ì„¸ë¥¼ ë°˜ì˜í•œ LLM ë²ˆì—­ì´ ì¸ê°„ ë²ˆì—­ë³´ë‹¤ ì¼ê´€ë˜ê²Œ ìš°ìˆ˜í•˜ë‹¤ëŠ” ì ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ëª…ì„¸ í†µí•©ì´ ë²ˆì—­ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì „ë¬¸ ë²ˆì—­ì—ì„œ ëª…ì„¸ëŠ” ì˜ì‚¬ì†Œí†µ ëª©í‘œì™€ ê³ ê°ì˜ ìš”êµ¬ì— ë”°ë¼ ë²ˆì—­ì„ ì•ˆë‚´í•˜ëŠ” ì¤‘ìš”í•œ ìš”ì†Œì´ë‹¤.
- 2. ê¸°ê³„ ë²ˆì—­ ì—°êµ¬ì—ì„œëŠ” ëª…ì„¸ì˜ ì¤‘ìš”ì„±ì´ ì¸ì •ë˜ì§€ë§Œ, ì¢…ì¢… ì•”ë¬µì ìœ¼ë¡œë§Œ ë‹¤ë¤„ì§„ë‹¤.
- 3. ëª…ì„¸ë¥¼ ê³ ë ¤í•œ ê¸°ê³„ ë²ˆì—­ ë° í‰ê°€ì˜ êµ¬í˜„ì„ ìœ„í•œ ì´ë¡ ì  ê·¼ê±°ì™€ ì‹¤ìš©ì  ê°€ì´ë“œë¥¼ ì œê³µí•œë‹¤.
- 4. íˆ¬ìì ê´€ê³„ í…ìŠ¤íŠ¸ ë²ˆì—­ ì‹¤í—˜ì—ì„œ ëª…ì„¸ì— ë”°ë¼ ë²ˆì—­ëœ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ë²ˆì—­ì´ ê³µì‹ ì¸ê°„ ë²ˆì—­ë³´ë‹¤ ìš°ìˆ˜í•œ ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ë‹¤.
- 5. ëª…ì„¸ë¥¼ ê¸°ê³„ ë²ˆì—­ ì›Œí¬í”Œë¡œì— í†µí•©í•˜ë©´ ë²ˆì—­ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìœ¼ë©°, ì´ëŠ” ì „ë¬¸ ë²ˆì—­ ê´€í–‰ê³¼ ì¼ì¹˜í•œë‹¤.


---

*Generated on 2025-09-24 03:29:57*