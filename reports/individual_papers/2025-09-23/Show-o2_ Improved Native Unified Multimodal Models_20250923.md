---
keywords:
  - Multimodal Learning
  - Autoregressive Models
  - Flow Matching
  - 3D Causal Variational Autoencoder
  - Spatio-Temporal Fusion
category: cs.CV
publish_date: 2025-09-23
arxiv_id: 2506.15564
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T05:24:43.550480",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multimodal Learning",
    "Autoregressive Models",
    "Flow Matching",
    "3D Causal Variational Autoencoder",
    "Spatio-Temporal Fusion"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multimodal Learning": 0.85,
    "Autoregressive Models": 0.78,
    "Flow Matching": 0.8,
    "3D Causal Variational Autoencoder": 0.77,
    "Spatio-Temporal Fusion": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "multimodal models",
        "canonical": "Multimodal Learning",
        "aliases": [
          "multimodal systems",
          "multimodal architectures"
        ],
        "category": "specific_connectable",
        "rationale": "Multimodal Learning is a trending area that connects different data types, enhancing the understanding and generation of diverse modalities.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "autoregressive modeling",
        "canonical": "Autoregressive Models",
        "aliases": [
          "AR models",
          "autoregressive techniques"
        ],
        "category": "unique_technical",
        "rationale": "Autoregressive Models are crucial for sequence prediction tasks, linking to broader concepts in machine learning.",
        "novelty_score": 0.65,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "flow matching",
        "canonical": "Flow Matching",
        "aliases": [
          "flow alignment",
          "flow-based matching"
        ],
        "category": "unique_technical",
        "rationale": "Flow Matching is a specific technique that enhances model performance in multimodal tasks.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "3D causal variational autoencoder",
        "canonical": "3D Causal Variational Autoencoder",
        "aliases": [
          "3D CVAE",
          "causal VAE"
        ],
        "category": "unique_technical",
        "rationale": "This specific model architecture is novel and relevant for linking advanced generative model discussions.",
        "novelty_score": 0.75,
        "connectivity_score": 0.55,
        "specificity_score": 0.9,
        "link_intent_score": 0.77
      },
      {
        "surface": "spatial-temporal fusion",
        "canonical": "Spatio-Temporal Fusion",
        "aliases": [
          "space-time fusion",
          "spatial-temporal integration"
        ],
        "category": "unique_technical",
        "rationale": "Spatio-Temporal Fusion is essential for integrating data across time and space, relevant for video and dynamic image analysis.",
        "novelty_score": 0.68,
        "connectivity_score": 0.65,
        "specificity_score": 0.82,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "experiment"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "multimodal models",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "autoregressive modeling",
      "resolved_canonical": "Autoregressive Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "flow matching",
      "resolved_canonical": "Flow Matching",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "3D causal variational autoencoder",
      "resolved_canonical": "3D Causal Variational Autoencoder",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.55,
        "specificity": 0.9,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "spatial-temporal fusion",
      "resolved_canonical": "Spatio-Temporal Fusion",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.65,
        "specificity": 0.82,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Show-o2: Improved Native Unified Multimodal Models

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2506.15564.pdf)
**Category**: cs.CV
**Published**: 2025-09-23
**ArXiv ID**: [2506.15564](https://arxiv.org/abs/2506.15564)

## 🔗 유사한 논문
- [[2025-09-19/UnifiedVisual_ A Framework for Constructing Unified Vision-Language Datasets_20250919|UnifiedVisual: A Framework for Constructing Unified Vision-Language Datasets]] (82.5% similar)
- [[2025-09-22/Combo_ Co-speech holistic 3D human motion generation and efficient customizable adaptation in harmony_20250922|Combo: Co-speech holistic 3D human motion generation and efficient customizable adaptation in harmony]] (82.3% similar)
- [[2025-09-19/Hybrid Autoregressive-Diffusion Model for Real-Time Sign Language Production_20250919|Hybrid Autoregressive-Diffusion Model for Real-Time Sign Language Production]] (81.6% similar)
- [[2025-09-22/MANZANO_ A Simple and Scalable Unified Multimodal Model with a Hybrid Vision Tokenizer_20250922|MANZANO: A Simple and Scalable Unified Multimodal Model with a Hybrid Vision Tokenizer]] (81.4% similar)
- [[2025-09-22/OSPO_ Object-centric Self-improving Preference Optimization for Text-to-Image Generation_20250922|OSPO: Object-centric Self-improving Preference Optimization for Text-to-Image Generation]] (81.3% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**⚡ Unique Technical**: [[keywords/Autoregressive Models|Autoregressive Models]], [[keywords/Flow Matching|Flow Matching]], [[keywords/3D Causal Variational Autoencoder|3D Causal Variational Autoencoder]], [[keywords/Spatio-Temporal Fusion|Spatio-Temporal Fusion]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2506.15564v3 Announce Type: replace 
Abstract: This paper presents improved native unified multimodal models, \emph{i.e.,} Show-o2, that leverage autoregressive modeling and flow matching. Built upon a 3D causal variational autoencoder space, unified visual representations are constructed through a dual-path of spatial (-temporal) fusion, enabling scalability across image and video modalities while ensuring effective multimodal understanding and generation. Based on a language model, autoregressive modeling and flow matching are natively applied to the language head and flow head, respectively, to facilitate text token prediction and image/video generation. A two-stage training recipe is designed to effectively learn and scale to larger models. The resulting Show-o2 models demonstrate versatility in handling a wide range of multimodal understanding and generation tasks across diverse modalities, including text, images, and videos. Code and models are released at https://github.com/showlab/Show-o.

## 📝 요약

이 논문은 Show-o2라는 개선된 통합 멀티모달 모델을 소개합니다. 이 모델은 3D 인과 변분 오토인코더 공간을 기반으로 하여, 공간(-시간) 융합의 이중 경로를 통해 통합된 시각 표현을 구축합니다. 이를 통해 이미지와 비디오 모달리티 전반에 걸쳐 확장 가능하며, 효과적인 멀티모달 이해와 생성을 보장합니다. 언어 모델을 기반으로, 오토회귀 모델링과 흐름 매칭이 각각 언어 헤드와 흐름 헤드에 적용되어 텍스트 토큰 예측과 이미지/비디오 생성을 지원합니다. 두 단계의 학습 방법을 통해 더 큰 모델로 확장할 수 있도록 설계되었습니다. 결과적으로 Show-o2 모델은 텍스트, 이미지, 비디오 등 다양한 모달리티에서 멀티모달 이해와 생성 작업을 효과적으로 처리할 수 있는 다재다능함을 보여줍니다. 코드와 모델은 https://github.com/showlab/Show-o에서 제공됩니다.

## 🎯 주요 포인트

- 1. Show-o2 모델은 자율회귀 모델링과 흐름 매칭을 활용하여 개선된 통합 멀티모달 모델을 제시합니다.
- 2. 3D 인과 변분 오토인코더 공간을 기반으로 이미지와 비디오 모달리티 전반에 걸쳐 확장 가능한 통합 시각 표현을 구축합니다.
- 3. 언어 모델을 기반으로 언어 헤드와 흐름 헤드에 각각 자율회귀 모델링과 흐름 매칭을 적용하여 텍스트 토큰 예측과 이미지/비디오 생성을 지원합니다.
- 4. 두 단계의 학습 레시피를 통해 더 큰 모델로 효과적으로 학습하고 확장할 수 있습니다.
- 5. Show-o2 모델은 다양한 모달리티의 멀티모달 이해 및 생성 작업을 처리하는 데 있어 높은 유연성을 보여줍니다.


---

*Generated on 2025-09-24 05:24:43*