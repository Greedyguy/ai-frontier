---
keywords:
  - Large Language Model
  - Deductive Reasoning
  - Chain-of-Thought Prompting
  - Context Size
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2505.15712
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:56:46.253656",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Deductive Reasoning",
    "Chain-of-Thought Prompting",
    "Context Size"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Deductive Reasoning": 0.8,
    "Chain-of-Thought Prompting": 0.82,
    "Context Size": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Large Language Models"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's focus on evaluating deductive reasoning capabilities.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "deductive reasoning",
        "canonical": "Deductive Reasoning",
        "aliases": [
          "deductive logic"
        ],
        "category": "unique_technical",
        "rationale": "Key concept for understanding the evaluation framework presented in the paper.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Chain-of-Thought prompting",
        "canonical": "Chain-of-Thought Prompting",
        "aliases": [
          "CoT prompting"
        ],
        "category": "specific_connectable",
        "rationale": "Relevant for linking strategies used to enhance reasoning in LLMs.",
        "novelty_score": 0.68,
        "connectivity_score": 0.78,
        "specificity_score": 0.72,
        "link_intent_score": 0.82
      },
      {
        "surface": "context size",
        "canonical": "Context Size",
        "aliases": [
          "narrative context size"
        ],
        "category": "unique_technical",
        "rationale": "Important for understanding the factors affecting model performance.",
        "novelty_score": 0.6,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "framework",
      "dataset",
      "testimonies",
      "evidences"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "deductive reasoning",
      "resolved_canonical": "Deductive Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Chain-of-Thought prompting",
      "resolved_canonical": "Chain-of-Thought Prompting",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.78,
        "specificity": 0.72,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "context size",
      "resolved_canonical": "Context Size",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# TurnaboutLLM: A Deductive Reasoning Benchmark from Detective Games

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2505.15712.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2505.15712](https://arxiv.org/abs/2505.15712)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/InMind_ Evaluating LLMs in Capturing and Applying Individual Human Reasoning Styles_20250923|InMind: Evaluating LLMs in Capturing and Applying Individual Human Reasoning Styles]] (87.5% similar)
- [[2025-09-23/LLMsPark_ A Benchmark for Evaluating Large Language Models in Strategic Gaming Contexts_20250923|LLMsPark: A Benchmark for Evaluating Large Language Models in Strategic Gaming Contexts]] (87.4% similar)
- [[2025-09-23/D-REX_ A Benchmark for Detecting Deceptive Reasoning in Large Language Models_20250923|D-REX: A Benchmark for Detecting Deceptive Reasoning in Large Language Models]] (86.8% similar)
- [[2025-09-22/Can LLMs Judge Debates? Evaluating Non-Linear Reasoning via Argumentation Theory Semantics_20250922|Can LLMs Judge Debates? Evaluating Non-Linear Reasoning via Argumentation Theory Semantics]] (86.6% similar)
- [[2025-09-22/DivLogicEval_ A Framework for Benchmarking Logical Reasoning Evaluation in Large Language Models_20250922|DivLogicEval: A Framework for Benchmarking Logical Reasoning Evaluation in Large Language Models]] (86.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Chain-of-Thought Prompting|Chain-of-Thought Prompting]]
**âš¡ Unique Technical**: [[keywords/Deductive Reasoning|Deductive Reasoning]], [[keywords/Context Size|Context Size]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2505.15712v2 Announce Type: replace 
Abstract: This paper introduces TurnaboutLLM, a novel framework and dataset for evaluating the deductive reasoning abilities of Large Language Models (LLMs) by leveraging the interactive gameplay of detective games Ace Attorney and Danganronpa. The framework tasks LLMs with identifying contradictions between testimonies and evidences within long narrative contexts, a challenging task due to the large answer space and diverse reasoning types presented by its questions. We evaluate twelve state-of-the-art LLMs on the dataset, hinting at limitations of popular strategies for enhancing deductive reasoning such as extensive thinking and Chain-of-Thought prompting. The results also suggest varying effects of context size, the number of reasoning step and answer space size on model performance. Overall, TurnaboutLLM presents a substantial challenge for LLMs' deductive reasoning abilities in complex, narrative-rich environments.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì—°ì—­ì  ì¶”ë¡  ëŠ¥ë ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ì™€ ë°ì´í„°ì…‹ì¸ TurnaboutLLMì„ ì†Œê°œí•©ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” 'Ace Attorney'ì™€ 'Danganronpa' ê°™ì€ íƒì • ê²Œì„ì˜ ìƒí˜¸ì‘ìš©ì„ í™œìš©í•˜ì—¬, LLMì´ ê¸´ ì„œì‚¬ì  ë§¥ë½ì—ì„œ ì¦ì–¸ê³¼ ì¦ê±° ê°„ì˜ ëª¨ìˆœì„ ì‹ë³„í•˜ë„ë¡ í•©ë‹ˆë‹¤. 12ê°œì˜ ìµœì‹  LLMì„ í‰ê°€í•œ ê²°ê³¼, ì—°ì—­ì  ì¶”ë¡ ì„ ê°•í™”í•˜ê¸° ìœ„í•œ ì¼ë°˜ì ì¸ ì „ëµì¸ ì‹¬ì¸µ ì‚¬ê³ ì™€ ì—°ì‡„ì  ì‚¬ê³  ìœ ë„ë²•ì˜ í•œê³„ë¥¼ ì‹œì‚¬í•©ë‹ˆë‹¤. ë˜í•œ, ë§¥ë½ì˜ í¬ê¸°, ì¶”ë¡  ë‹¨ê³„ ìˆ˜, ë‹µë³€ ê³µê°„ í¬ê¸°ê°€ ëª¨ë¸ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ë‹¤ì–‘í•œ ì˜í–¥ì„ ì œì‹œí•©ë‹ˆë‹¤. TurnaboutLLMì€ ë³µì¡í•˜ê³  ì„œì‚¬ì ì¸ í™˜ê²½ì—ì„œ LLMì˜ ì—°ì—­ì  ì¶”ë¡  ëŠ¥ë ¥ì— ìƒë‹¹í•œ ë„ì „ ê³¼ì œë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. TurnaboutLLMì€ Ace Attorneyì™€ Danganronpa ê²Œì„ì„ í™œìš©í•˜ì—¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì—°ì—­ì  ì¶”ë¡  ëŠ¥ë ¥ì„ í‰ê°€í•˜ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ì™€ ë°ì´í„°ì…‹ì„ ì†Œê°œí•©ë‹ˆë‹¤.
- 2. ì´ í”„ë ˆì„ì›Œí¬ëŠ” LLMì´ ê¸´ ì„œì‚¬ì  ë§¥ë½ ë‚´ì—ì„œ ì¦ì–¸ê³¼ ì¦ê±° ì‚¬ì´ì˜ ëª¨ìˆœì„ ì‹ë³„í•˜ë„ë¡ ìš”êµ¬í•˜ë©°, ì´ëŠ” ë‹¤ì–‘í•œ ì¶”ë¡  ìœ í˜•ê³¼ í° ë‹µë³€ ê³µê°„ ë•Œë¬¸ì— ë„ì „ì ì¸ ê³¼ì œì…ë‹ˆë‹¤.
- 3. 12ê°œì˜ ìµœì²¨ë‹¨ LLMì„ ë°ì´í„°ì…‹ì—ì„œ í‰ê°€í•œ ê²°ê³¼, ê´‘ë²”ìœ„í•œ ì‚¬ê³ ì™€ Chain-of-Thought í”„ë¡¬í”„íŠ¸ì™€ ê°™ì€ ì—°ì—­ì  ì¶”ë¡  ê°•í™” ì „ëµì˜ í•œê³„ë¥¼ ì•”ì‹œí•©ë‹ˆë‹¤.
- 4. ì—°êµ¬ ê²°ê³¼ëŠ” ë§¥ë½ í¬ê¸°, ì¶”ë¡  ë‹¨ê³„ ìˆ˜ ë° ë‹µë³€ ê³µê°„ í¬ê¸°ê°€ ëª¨ë¸ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ë‹¤ì–‘í•œ ì˜í–¥ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.
- 5. ì „ë°˜ì ìœ¼ë¡œ TurnaboutLLMì€ ë³µì¡í•˜ê³  ì„œì‚¬ì ì¸ í™˜ê²½ì—ì„œ LLMì˜ ì—°ì—­ì  ì¶”ë¡  ëŠ¥ë ¥ì— ìƒë‹¹í•œ ë„ì „ì„ ì œì‹œí•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 03:56:46*