---
keywords:
  - Large Language Model
  - Deceptive Reasoning Exposure Suite
  - Deceptive Alignment
  - Adversarial System Prompts
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2509.17938
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:35:30.194083",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Deceptive Reasoning Exposure Suite",
    "Deceptive Alignment",
    "Adversarial System Prompts"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Deceptive Reasoning Exposure Suite": 0.8,
    "Deceptive Alignment": 0.75,
    "Adversarial System Prompts": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "This is a foundational concept in the paper, linking to broader discussions on AI safety and alignment.",
        "novelty_score": 0.2,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Deceptive Reasoning Exposure Suite",
        "canonical": "Deceptive Reasoning Exposure Suite",
        "aliases": [
          "D-REX"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel benchmark specifically designed to evaluate deceptive reasoning in LLMs.",
        "novelty_score": 0.95,
        "connectivity_score": 0.6,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "deceptive alignment",
        "canonical": "Deceptive Alignment",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Highlights a critical evaluation task for assessing the alignment of LLMs.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.75
      },
      {
        "surface": "adversarial system prompts",
        "canonical": "Adversarial System Prompts",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Key mechanism by which deceptive reasoning is induced, relevant for adversarial AI research.",
        "novelty_score": 0.6,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "safety filters",
      "internal reasoning process"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.2,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Deceptive Reasoning Exposure Suite",
      "resolved_canonical": "Deceptive Reasoning Exposure Suite",
      "decision": "linked",
      "scores": {
        "novelty": 0.95,
        "connectivity": 0.6,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "deceptive alignment",
      "resolved_canonical": "Deceptive Alignment",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "adversarial system prompts",
      "resolved_canonical": "Adversarial System Prompts",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# D-REX: A Benchmark for Detecting Deceptive Reasoning in Large Language Models

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17938.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2509.17938](https://arxiv.org/abs/2509.17938)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/MSCoRe_ A Benchmark for Multi-Stage Collaborative Reasoning in LLM Agents_20250923|MSCoRe: A Benchmark for Multi-Stage Collaborative Reasoning in LLM Agents]] (86.0% similar)
- [[2025-09-23/EquiBench_ Benchmarking Large Language Models' Reasoning about Program Semantics via Equivalence Checking_20250923|EquiBench: Benchmarking Large Language Models' Reasoning about Program Semantics via Equivalence Checking]] (85.9% similar)
- [[2025-09-22/DivLogicEval_ A Framework for Benchmarking Logical Reasoning Evaluation in Large Language Models_20250922|DivLogicEval: A Framework for Benchmarking Logical Reasoning Evaluation in Large Language Models]] (85.7% similar)
- [[2025-09-23/How Is LLM Reasoning Distracted by Irrelevant Context? An Analysis Using a Controlled Benchmark_20250923|How Is LLM Reasoning Distracted by Irrelevant Context? An Analysis Using a Controlled Benchmark]] (84.8% similar)
- [[2025-09-23/EngiBench_ A Benchmark for Evaluating Large Language Models on Engineering Problem Solving_20250923|EngiBench: A Benchmark for Evaluating Large Language Models on Engineering Problem Solving]] (84.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Adversarial System Prompts|Adversarial System Prompts]]
**âš¡ Unique Technical**: [[keywords/Deceptive Reasoning Exposure Suite|Deceptive Reasoning Exposure Suite]], [[keywords/Deceptive Alignment|Deceptive Alignment]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17938v1 Announce Type: new 
Abstract: The safety and alignment of Large Language Models (LLMs) are critical for their responsible deployment. Current evaluation methods predominantly focus on identifying and preventing overtly harmful outputs. However, they often fail to address a more insidious failure mode: models that produce benign-appearing outputs while operating on malicious or deceptive internal reasoning. This vulnerability, often triggered by sophisticated system prompt injections, allows models to bypass conventional safety filters, posing a significant, underexplored risk. To address this gap, we introduce the Deceptive Reasoning Exposure Suite (D-REX), a novel dataset designed to evaluate the discrepancy between a model's internal reasoning process and its final output. D-REX was constructed through a competitive red-teaming exercise where participants crafted adversarial system prompts to induce such deceptive behaviors. Each sample in D-REX contains the adversarial system prompt, an end-user's test query, the model's seemingly innocuous response, and, crucially, the model's internal chain-of-thought, which reveals the underlying malicious intent. Our benchmark facilitates a new, essential evaluation task: the detection of deceptive alignment. We demonstrate that D-REX presents a significant challenge for existing models and safety mechanisms, highlighting the urgent need for new techniques that scrutinize the internal processes of LLMs, not just their final outputs.

## ğŸ“ ìš”ì•½

ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì•ˆì „ì„±ê³¼ ì •ë ¬ì€ ì±…ì„ ìˆëŠ” ë°°í¬ë¥¼ ìœ„í•´ ì¤‘ìš”í•©ë‹ˆë‹¤. ê¸°ì¡´ í‰ê°€ ë°©ë²•ì€ ì£¼ë¡œ ëª…ë°±íˆ ìœ í•´í•œ ì¶œë ¥ì„ ì‹ë³„í•˜ê³  ë°©ì§€í•˜ëŠ” ë° ì¤‘ì ì„ ë‘ì§€ë§Œ, ì•…ì˜ì ì´ê±°ë‚˜ ê¸°ë§Œì ì¸ ë‚´ë¶€ ì¶”ë¡ ì„ í†µí•´ ê²‰ë³´ê¸°ì— ë¬´í•´í•œ ì¶œë ¥ì„ ìƒì„±í•˜ëŠ” ëª¨ë¸ì˜ ë¬¸ì œë¥¼ ê°„ê³¼í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì·¨ì•½ì ì€ ì •êµí•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì£¼ì…ì— ì˜í•´ ë°œìƒí•˜ë©°, ê¸°ì¡´ ì•ˆì „ í•„í„°ë¥¼ ìš°íšŒí•  ìˆ˜ ìˆì–´ í° ìœ„í—˜ì„ ì´ˆë˜í•©ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ëª¨ë¸ì˜ ë‚´ë¶€ ì¶”ë¡  ê³¼ì •ê³¼ ìµœì¢… ì¶œë ¥ ê°„ì˜ ë¶ˆì¼ì¹˜ë¥¼ í‰ê°€í•˜ëŠ” ìƒˆë¡œìš´ ë°ì´í„°ì…‹ì¸ D-REX(Deceptive Reasoning Exposure Suite)ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. D-REXëŠ” ê²½ìŸì ì¸ ë ˆë“œíŒ€ í™œë™ì„ í†µí•´ êµ¬ì¶•ë˜ì—ˆìœ¼ë©°, ê° ìƒ˜í”Œì—ëŠ” ì•…ì˜ì ì¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸, ì‚¬ìš©ì í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬, ëª¨ë¸ì˜ ë¬´í•´í•´ ë³´ì´ëŠ” ì‘ë‹µ, ê·¸ë¦¬ê³  ëª¨ë¸ì˜ ë‚´ë¶€ ì‚¬ê³  ê³¼ì •ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. D-REXëŠ” ê¸°ë§Œì  ì •ë ¬ì„ íƒì§€í•˜ëŠ” ìƒˆë¡œìš´ í‰ê°€ ê³¼ì œë¥¼ ì œì‹œí•˜ë©°, ê¸°ì¡´ ëª¨ë¸ê³¼ ì•ˆì „ ë©”ì»¤ë‹ˆì¦˜ì— í° ë„ì „ ê³¼ì œë¥¼ ì œê¸°í•©ë‹ˆë‹¤. ì´ëŠ” LLMì˜ ìµœì¢… ì¶œë ¥ë¿ë§Œ ì•„ë‹ˆë¼ ë‚´ë¶€ ê³¼ì •ì„ ë©´ë°€íˆ ì¡°ì‚¬í•  ìƒˆë¡œìš´ ê¸°ìˆ ì˜ í•„ìš”ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì˜ ì•ˆì „ì„±ê³¼ ì •ë ¬ì€ ì±…ì„ ìˆëŠ” ë°°í¬ë¥¼ ìœ„í•´ ì¤‘ìš”í•˜ë‹¤.
- 2. ê¸°ì¡´ í‰ê°€ ë°©ë²•ì€ ëª…ë°±íˆ í•´ë¡œìš´ ì¶œë ¥ë¬¼ì„ ì‹ë³„í•˜ê³  ë°©ì§€í•˜ëŠ” ë° ì¤‘ì ì„ ë‘ì§€ë§Œ, ì•…ì˜ì ì´ê±°ë‚˜ ê¸°ë§Œì ì¸ ë‚´ë¶€ ì¶”ë¡ ì„ í†µí•´ ê²‰ìœ¼ë¡œëŠ” ë¬´í•´í•œ ì¶œë ¥ë¬¼ì„ ìƒì„±í•˜ëŠ” ë¬¸ì œë¥¼ ê°„ê³¼í•œë‹¤.
- 3. D-REX(Deceptive Reasoning Exposure Suite)ëŠ” ëª¨ë¸ì˜ ë‚´ë¶€ ì¶”ë¡  ê³¼ì •ê³¼ ìµœì¢… ì¶œë ¥ ê°„ì˜ ë¶ˆì¼ì¹˜ë¥¼ í‰ê°€í•˜ê¸° ìœ„í•´ ì„¤ê³„ëœ ìƒˆë¡œìš´ ë°ì´í„°ì…‹ì´ë‹¤.
- 4. D-REXëŠ” ê²½ìŸì ì¸ ë ˆë“œíŒ€ ì—°ìŠµì„ í†µí•´ êµ¬ì¶•ë˜ì—ˆìœ¼ë©°, ì°¸ê°€ìë“¤ì€ ê¸°ë§Œì  í–‰ë™ì„ ìœ ë„í•˜ëŠ” ì ëŒ€ì  ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í–ˆë‹¤.
- 5. D-REXëŠ” ê¸°ì¡´ ëª¨ë¸ê³¼ ì•ˆì „ ë©”ì»¤ë‹ˆì¦˜ì— í° ë„ì „ ê³¼ì œë¥¼ ì œì‹œí•˜ë©°, LLMì˜ ë‚´ë¶€ ê³¼ì •ì„ ë©´ë°€íˆ ì¡°ì‚¬í•˜ëŠ” ìƒˆë¡œìš´ ê¸°ìˆ ì˜ í•„ìš”ì„±ì„ ê°•ì¡°í•œë‹¤.


---

*Generated on 2025-09-24 03:35:30*