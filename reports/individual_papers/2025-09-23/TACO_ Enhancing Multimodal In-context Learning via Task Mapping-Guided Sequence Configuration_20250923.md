---
keywords:
  - Multimodal Learning
  - Vision-Language Model
  - Task Mapping
  - Attention Mechanism
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2505.17098
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:57:33.843551",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multimodal Learning",
    "Vision-Language Model",
    "Task Mapping",
    "Attention Mechanism"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multimodal Learning": 0.78,
    "Vision-Language Model": 0.8,
    "Task Mapping": 0.85,
    "Attention Mechanism": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multimodal In-Context Learning",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal ICL"
        ],
        "category": "specific_connectable",
        "rationale": "This term connects to the broader concept of integrating multiple modalities, which is crucial for understanding the paper's focus.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.72,
        "link_intent_score": 0.78
      },
      {
        "surface": "Vision-Language Models",
        "canonical": "Vision-Language Model",
        "aliases": [
          "LVLMs"
        ],
        "category": "evolved_concepts",
        "rationale": "This represents a key area of research that bridges vision and language, central to the paper's methodology.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Task Mapping",
        "canonical": "Task Mapping",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Introduces a novel perspective for interpreting and improving multimodal ICL, which is a core contribution of the paper.",
        "novelty_score": 0.75,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.85
      },
      {
        "surface": "Task-Aware Attention",
        "canonical": "Attention Mechanism",
        "aliases": [
          "Task-Aware Attention"
        ],
        "category": "specific_connectable",
        "rationale": "This is a specialized form of attention mechanism that enhances the model's ability to configure sequences based on tasks.",
        "novelty_score": 0.6,
        "connectivity_score": 0.82,
        "specificity_score": 0.78,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "ICL sequences",
      "autoregressive decoding",
      "demonstrations"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multimodal In-Context Learning",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.72,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Vision-Language Models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Task Mapping",
      "resolved_canonical": "Task Mapping",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Task-Aware Attention",
      "resolved_canonical": "Attention Mechanism",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.82,
        "specificity": 0.78,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# TACO: Enhancing Multimodal In-context Learning via Task Mapping-Guided Sequence Configuration

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2505.17098.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2505.17098](https://arxiv.org/abs/2505.17098)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Process-Supervised Reinforcement Learning for Interactive Multimodal Tool-Use Agents_20250919|Process-Supervised Reinforcement Learning for Interactive Multimodal Tool-Use Agents]] (83.7% similar)
- [[2025-09-22/CLIPTTA_ Robust Contrastive Vision-Language Test-Time Adaptation_20250922|CLIPTTA: Robust Contrastive Vision-Language Test-Time Adaptation]] (83.5% similar)
- [[2025-09-23/LTA-thinker_ Latent Thought-Augmented Training Framework for Large Language Models on Complex Reasoning_20250923|LTA-thinker: Latent Thought-Augmented Training Framework for Large Language Models on Complex Reasoning]] (83.3% similar)
- [[2025-09-22/Cache-of-Thought_ Master-Apprentice Framework for Cost-Effective Vision Language Model Reasoning_20250922|Cache-of-Thought: Master-Apprentice Framework for Cost-Effective Vision Language Model Reasoning]] (83.2% similar)
- [[2025-09-18/TICL_ Text-Embedding KNN For Speech In-Context Learning Unlocks Speech Recognition Abilities of Large Multimodal Models_20250918|TICL: Text-Embedding KNN For Speech In-Context Learning Unlocks Speech Recognition Abilities of Large Multimodal Models]] (82.9% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]], [[keywords/Attention Mechanism|Attention Mechanism]]
**âš¡ Unique Technical**: [[keywords/Task Mapping|Task Mapping]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2505.17098v2 Announce Type: replace 
Abstract: Multimodal in-context learning (ICL) has emerged as a key mechanism for harnessing the capabilities of large vision-language models (LVLMs). However, its effectiveness remains highly sensitive to the quality of input ICL sequences, particularly for tasks involving complex reasoning or open-ended generation. A major limitation is our limited understanding of how LVLMs actually exploit these sequences during inference. To bridge this gap, we systematically interpret multimodal ICL through the lens of task mapping, which reveals how local and global relationships within and among demonstrations guide model reasoning. Building on this insight, we present TACO, a lightweight transformer-based model equipped with task-aware attention that dynamically configures ICL sequences. By injecting task-mapping signals into the autoregressive decoding process, TACO creates a bidirectional synergy between sequence construction and task reasoning. Experiments on five LVLMs and nine datasets demonstrate that TACO consistently surpasses baselines across diverse ICL tasks. These results position task mapping as a novel and valuable perspective for interpreting and improving multimodal ICL.

## ğŸ“ ìš”ì•½

ë©€í‹°ëª¨ë‹¬ ì¸ì»¨í…ìŠ¤íŠ¸ í•™ìŠµ(ICL)ì€ ëŒ€í˜• ë¹„ì „-ì–¸ì–´ ëª¨ë¸(LVLM)ì˜ ì ì¬ë ¥ì„ í™œìš©í•˜ëŠ” í•µì‹¬ ë©”ì»¤ë‹ˆì¦˜ìœ¼ë¡œ ë¶€ìƒí–ˆì§€ë§Œ, ì…ë ¥ ICL ì‹œí€€ìŠ¤ì˜ í’ˆì§ˆì— í¬ê²Œ ì¢Œìš°ë©ë‹ˆë‹¤. ë³¸ ì—°êµ¬ëŠ” LVLMì´ ì‹œí€€ìŠ¤ë¥¼ í™œìš©í•˜ëŠ” ë°©ì‹ì„ ì´í•´í•˜ê¸° ìœ„í•´ ê³¼ì œ ë§¤í•‘(task mapping)ì„ í†µí•´ ë©€í‹°ëª¨ë‹¬ ICLì„ í•´ì„í–ˆìŠµë‹ˆë‹¤. ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ê³¼ì œ ì¸ì‹ ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì„ ê°–ì¶˜ ê²½ëŸ‰ íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ TACOë¥¼ ì œì•ˆí•˜ì—¬ ì‹œí€€ìŠ¤ êµ¬ì„±ê³¼ ê³¼ì œ ì¶”ë¡  ê°„ì˜ ìƒí˜¸ì‘ìš©ì„ ê°•í™”í–ˆìŠµë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, TACOëŠ” ë‹¤ì–‘í•œ ICL ê³¼ì œì—ì„œ ê¸°ì¡´ ëª¨ë¸ì„ ëŠ¥ê°€í–ˆìœ¼ë©°, ê³¼ì œ ë§¤í•‘ì´ ë©€í‹°ëª¨ë‹¬ ICL í•´ì„ ë° ê°œì„ ì— ìœ ìš©í•œ ê´€ì ì„ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë©€í‹°ëª¨ë‹¬ ì¸ì»¨í…ìŠ¤íŠ¸ í•™ìŠµ(ICL)ì€ ëŒ€í˜• ë¹„ì „-ì–¸ì–´ ëª¨ë¸(LVLM)ì˜ ê¸°ëŠ¥ì„ í™œìš©í•˜ëŠ” í•µì‹¬ ë©”ì»¤ë‹ˆì¦˜ìœ¼ë¡œ ë¶€ìƒí•˜ê³  ìˆë‹¤.
- 2. ICLì˜ íš¨ê³¼ëŠ” ì…ë ¥ ICL ì‹œí€€ìŠ¤ì˜ í’ˆì§ˆì— ë§¤ìš° ë¯¼ê°í•˜ë©°, íŠ¹íˆ ë³µì¡í•œ ì¶”ë¡ ì´ë‚˜ ê°œë°©í˜• ìƒì„± ì‘ì—…ì—ì„œ ê·¸ëŸ¬í•˜ë‹¤.
- 3. TACOëŠ” ì‘ì—… ì¸ì‹ ì£¼ì˜ë¥¼ ê°–ì¶˜ ê²½ëŸ‰ íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ ëª¨ë¸ë¡œ, ICL ì‹œí€€ìŠ¤ë¥¼ ë™ì ìœ¼ë¡œ êµ¬ì„±í•˜ì—¬ ì‹œí€€ìŠ¤ êµ¬ì„±ê³¼ ì‘ì—… ì¶”ë¡  ê°„ì˜ ì–‘ë°©í–¥ ì‹œë„ˆì§€ë¥¼ ì°½ì¶œí•œë‹¤.
- 4. TACOëŠ” ë‹¤ì„¯ ê°œì˜ LVLMê³¼ ì•„í™‰ ê°œì˜ ë°ì´í„°ì…‹ ì‹¤í—˜ì—ì„œ ë‹¤ì–‘í•œ ICL ì‘ì—…ì— ëŒ€í•´ ì¼ê´€ë˜ê²Œ ê¸°ì¡´ ëª¨ë¸ì„ ëŠ¥ê°€í•œë‹¤.
- 5. ì‘ì—… ë§¤í•‘ì€ ë©€í‹°ëª¨ë‹¬ ICLì„ í•´ì„í•˜ê³  ê°œì„ í•˜ëŠ” ë° ìˆì–´ ìƒˆë¡œìš´ ê°€ì¹˜ ìˆëŠ” ê´€ì ìœ¼ë¡œ ìë¦¬ ì¡ê³  ìˆë‹¤.


---

*Generated on 2025-09-24 03:57:33*