---
keywords:
  - Large Language Model
  - CodeGym
  - Reinforcement Learning
  - Out-of-distribution Generalization
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.17325
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T23:52:12.824510",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "CodeGym",
    "Reinforcement Learning",
    "Out-of-distribution Generalization"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "CodeGym": 0.8,
    "Reinforcement Learning": 0.78,
    "Out-of-distribution Generalization": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Tool-augmented large language models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM agents",
          "Tool-augmented LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Connects to existing knowledge on large language models, emphasizing their tool-augmented capabilities.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "CodeGym",
        "canonical": "CodeGym",
        "aliases": [
          "CodeGym framework"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel framework for training LLM agents, crucial for understanding the paper's contribution.",
        "novelty_score": 0.92,
        "connectivity_score": 0.7,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "Reinforcement Learning",
        "canonical": "Reinforcement Learning",
        "aliases": [
          "RL"
        ],
        "category": "specific_connectable",
        "rationale": "A core method used in the paper, linking to a broad area of machine learning research.",
        "novelty_score": 0.3,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.78
      },
      {
        "surface": "Out-of-distribution generalizability",
        "canonical": "Out-of-distribution Generalization",
        "aliases": [
          "OOD generalization"
        ],
        "category": "specific_connectable",
        "rationale": "Key concept for evaluating the model's performance beyond training data.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "static trajectories",
      "supervised fine-tuning"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Tool-augmented large language models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "CodeGym",
      "resolved_canonical": "CodeGym",
      "decision": "linked",
      "scores": {
        "novelty": 0.92,
        "connectivity": 0.7,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Reinforcement Learning",
      "resolved_canonical": "Reinforcement Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Out-of-distribution generalizability",
      "resolved_canonical": "Out-of-distribution Generalization",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Generalizable End-to-End Tool-Use RL with Synthetic CodeGym

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17325.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.17325](https://arxiv.org/abs/2509.17325)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Process-Supervised Reinforcement Learning for Interactive Multimodal Tool-Use Agents_20250919|Process-Supervised Reinforcement Learning for Interactive Multimodal Tool-Use Agents]] (86.5% similar)
- [[2025-09-23/Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates_20250923|Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates]] (85.2% similar)
- [[2025-09-18/LLM-I_ LLMs are Naturally Interleaved Multimodal Creators_20250918|LLM-I: LLMs are Naturally Interleaved Multimodal Creators]] (84.9% similar)
- [[2025-09-19/LEED_ A Highly Efficient and Scalable LLM-Empowered Expert Demonstrations Framework for Multi-Agent Reinforcement Learning_20250919|LEED: A Highly Efficient and Scalable LLM-Empowered Expert Demonstrations Framework for Multi-Agent Reinforcement Learning]] (84.8% similar)
- [[2025-09-23/Generalizability of Large Language Model-Based Agents_ A Comprehensive Survey_20250923|Generalizability of Large Language Model-Based Agents: A Comprehensive Survey]] (84.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Reinforcement Learning|Reinforcement Learning]], [[keywords/Out-of-distribution Generalization|Out-of-distribution Generalization]]
**âš¡ Unique Technical**: [[keywords/CodeGym|CodeGym]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17325v1 Announce Type: cross 
Abstract: Tool-augmented large language models (LLMs), hereafter LLM agents, leverage external tools to solve diverse tasks and interface with the real world. However, current training practices largely rely on supervised fine-tuning (SFT) over static trajectories or reinforcement learning (RL) on narrow tasks, and generalize poorly beyond development settings, leading to brittleness with new tools and unseen workflows. Because code execution reflects many structures of real-world workflows, coding problems provide a natural basis for building agent training environments. Motivated by this, we introduce CodeGym, a scalable framework that synthesizes diverse, verifiable, and controllable multi-turn tool-use environments for agent RL, enabling LLM agents to explore and master various workflows actively. CodeGym rewrites static coding problems into interactive environments by extracting atomic functions or logic into callable tools, yielding verifiable tasks that span various tool-execution workflows. Models of varying sizes and chain-of-thought configurations, trained in CodeGym, exhibit consistent out-of-distribution generalizability; for example, Qwen2.5-32B-Instruct achieves an absolute accuracy gain of 8.7 points on the OOD benchmark $\tau$-Bench. These results highlight CodeGym as a step toward scalable general-purpose RL environments that align with real-world agent workflows.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì™¸ë¶€ ë„êµ¬ë¥¼ í™œìš©í•˜ì—¬ ë‹¤ì–‘í•œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë„êµ¬ í™•ì¥í˜• ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM) ì—ì´ì „íŠ¸ì˜ í›ˆë ¨ í™˜ê²½ì„ ê°œì„ í•˜ê¸° ìœ„í•´ CodeGymì´ë¼ëŠ” í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ í›ˆë ¨ ë°©ì‹ì€ ì •ì  ê²½ë¡œì— ëŒ€í•œ ì§€ë„ í•™ìŠµì´ë‚˜ ì¢ì€ ì‘ì—…ì— ëŒ€í•œ ê°•í™” í•™ìŠµì— ì˜ì¡´í•˜ì—¬ ìƒˆë¡œìš´ ë„êµ¬ì™€ ë¯¸ì§€ì˜ ì‘ì—… íë¦„ì— ì·¨ì•½í•©ë‹ˆë‹¤. CodeGymì€ ë‹¤ì–‘í•œ ë„êµ¬ ì‚¬ìš© í™˜ê²½ì„ ìƒì„±í•˜ì—¬ ì—ì´ì „íŠ¸ê°€ ë‹¤ì–‘í•œ ì‘ì—… íë¦„ì„ íƒìƒ‰í•˜ê³  ìˆ™ë‹¬í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ì •ì  ì½”ë”© ë¬¸ì œë¥¼ ìƒí˜¸ì‘ìš© í™˜ê²½ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ê²€ì¦ ê°€ëŠ¥í•œ ì‘ì—…ì„ ì œê³µí•©ë‹ˆë‹¤. CodeGymì—ì„œ í›ˆë ¨ëœ ëª¨ë¸ë“¤ì€ ê°œë°œ í™˜ê²½ì„ ë„˜ì–´ì„œëŠ” ì¼ë°˜í™” ëŠ¥ë ¥ì„ ë³´ì˜€ìœ¼ë©°, ì˜ˆë¥¼ ë“¤ì–´ Qwen2.5-32B-Instruct ëª¨ë¸ì€ OOD ë²¤ì¹˜ë§ˆí¬ì—ì„œ 8.7ì ì˜ ì ˆëŒ€ ì •í™•ë„ í–¥ìƒì„ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” CodeGymì´ í˜„ì‹¤ ì„¸ê³„ì˜ ì—ì´ì „íŠ¸ ì‘ì—… íë¦„ì— ë§ì¶˜ í™•ì¥ ê°€ëŠ¥í•œ ë²”ìš© ê°•í™” í•™ìŠµ í™˜ê²½ìœ¼ë¡œ ë°œì „í•  ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. LLM ì—ì´ì „íŠ¸ëŠ” ì™¸ë¶€ ë„êµ¬ë¥¼ í™œìš©í•˜ì—¬ ë‹¤ì–‘í•œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê³  ì‹¤ì œ ì„¸ê³„ì™€ ìƒí˜¸ì‘ìš©í•©ë‹ˆë‹¤.
- 2. ê¸°ì¡´ì˜ í›ˆë ¨ ë°©ì‹ì€ ìƒˆë¡œìš´ ë„êµ¬ì™€ ë³´ì§€ ëª»í•œ ì›Œí¬í”Œë¡œìš°ì— ëŒ€í•œ ì¼ë°˜í™”ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.
- 3. CodeGymì€ ë‹¤ì–‘í•œ ë„êµ¬ ì‚¬ìš© í™˜ê²½ì„ ì œê³µí•˜ì—¬ ì—ì´ì „íŠ¸ê°€ ë‹¤ì–‘í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ íƒìƒ‰í•˜ê³  ìˆ™ë‹¬í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
- 4. CodeGymì—ì„œ í›ˆë ¨ëœ ëª¨ë¸ì€ ì¼ê´€ëœ ë¶„í¬ ì™¸ ì¼ë°˜í™” ì„±ëŠ¥ì„ ë³´ì´ë©°, Qwen2.5-32B-Instruct ëª¨ë¸ì€ OOD ë²¤ì¹˜ë§ˆí¬ì—ì„œ 8.7ì ì˜ ì ˆëŒ€ ì •í™•ë„ í–¥ìƒì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.
- 5. CodeGymì€ í˜„ì‹¤ ì„¸ê³„ì˜ ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°ì— ë§ì¶˜ í™•ì¥ ê°€ëŠ¥í•œ ë²”ìš© RL í™˜ê²½ìœ¼ë¡œì˜ ë°œì „ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.


---

*Generated on 2025-09-23 23:52:12*