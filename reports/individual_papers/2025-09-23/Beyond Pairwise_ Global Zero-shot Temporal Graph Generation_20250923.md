---
keywords:
  - Temporal Relation Extraction
  - Zero-Shot Learning
  - Large Language Model
  - Temporal Graph Generation
  - Temporal Constraint Optimization
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2502.11114
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:48:25.538789",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Temporal Relation Extraction",
    "Zero-Shot Learning",
    "Large Language Model",
    "Temporal Graph Generation",
    "Temporal Constraint Optimization"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Temporal Relation Extraction": 0.8,
    "Zero-Shot Learning": 0.9,
    "Large Language Model": 0.85,
    "Temporal Graph Generation": 0.75,
    "Temporal Constraint Optimization": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Temporal Relation Extraction",
        "canonical": "Temporal Relation Extraction",
        "aliases": [
          "TRE"
        ],
        "category": "unique_technical",
        "rationale": "This is a specific task in NLP that directly relates to the paper's contribution and is essential for linking related research.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "Zero-shot Method",
        "canonical": "Zero-Shot Learning",
        "aliases": [
          "Zero-shot Approach"
        ],
        "category": "specific_connectable",
        "rationale": "Zero-shot learning is a trending concept that connects to various machine learning techniques and applications.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.9
      },
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "LLMs are a foundational technology in NLP and connect to a wide range of research topics.",
        "novelty_score": 0.4,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Temporal Graph Generation",
        "canonical": "Temporal Graph Generation",
        "aliases": [
          "Temporal Graph Construction"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel concept introduced by the paper, crucial for understanding its contributions.",
        "novelty_score": 0.8,
        "connectivity_score": 0.5,
        "specificity_score": 0.85,
        "link_intent_score": 0.75
      },
      {
        "surface": "Temporal Constraint Optimization",
        "canonical": "Temporal Constraint Optimization",
        "aliases": [
          "Temporal Optimization"
        ],
        "category": "unique_technical",
        "rationale": "This technique is a key part of the proposed method, linking it to optimization research.",
        "novelty_score": 0.65,
        "connectivity_score": 0.55,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "method",
      "approach",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Temporal Relation Extraction",
      "resolved_canonical": "Temporal Relation Extraction",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Zero-shot Method",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.9
      }
    },
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Temporal Graph Generation",
      "resolved_canonical": "Temporal Graph Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.5,
        "specificity": 0.85,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Temporal Constraint Optimization",
      "resolved_canonical": "Temporal Constraint Optimization",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.55,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# Beyond Pairwise: Global Zero-shot Temporal Graph Generation

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2502.11114.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2502.11114](https://arxiv.org/abs/2502.11114)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/A Benchmark for End-to-End Zero-Shot Biomedical Relation Extraction with LLMs_ Experiments with OpenAI Models_20250922|A Benchmark for End-to-End Zero-Shot Biomedical Relation Extraction with LLMs: Experiments with OpenAI Models]] (80.8% similar)
- [[2025-09-22/Temporal Reasoning with Large Language Models Augmented by Evolving Knowledge Graphs_20250922|Temporal Reasoning with Large Language Models Augmented by Evolving Knowledge Graphs]] (80.3% similar)
- [[2025-09-23/Full-History Graphs with Edge-Type Decoupled Networks for Temporal Reasoning_20250923|Full-History Graphs with Edge-Type Decoupled Networks for Temporal Reasoning]] (79.4% similar)
- [[2025-09-22/Structured Information for Improving Spatial Relationships in Text-to-Image Generation_20250922|Structured Information for Improving Spatial Relationships in Text-to-Image Generation]] (79.1% similar)
- [[2025-09-22/BBScoreV2_ Learning Time-Evolution and Latent Alignment from Stochastic Representation_20250922|BBScoreV2: Learning Time-Evolution and Latent Alignment from Stochastic Representation]] (78.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Zero-Shot Learning|Zero-Shot Learning]]
**âš¡ Unique Technical**: [[keywords/Temporal Relation Extraction|Temporal Relation Extraction]], [[keywords/Temporal Graph Generation|Temporal Graph Generation]], [[keywords/Temporal Constraint Optimization|Temporal Constraint Optimization]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2502.11114v3 Announce Type: replace 
Abstract: Temporal relation extraction (TRE) is a fundamental task in natural language processing (NLP) that involves identifying the temporal relationships between events in a document. Despite the advances in large language models (LLMs), their application to TRE remains limited. Most existing approaches rely on pairwise classification, where event pairs are classified in isolation, leading to computational inefficiency and a lack of global consistency in the resulting temporal graph. In this work, we propose a novel zero-shot method for TRE that generates a document's complete temporal graph in a single step, followed by temporal constraint optimization to refine predictions and enforce temporal consistency across relations. Additionally, we introduce OmniTemp, a new dataset with complete annotations for all pairs of targeted events within a document. Through experiments and analyses, we demonstrate that our method outperforms existing zero-shot approaches and offers a competitive alternative to supervised TRE models.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ìì—°ì–´ ì²˜ë¦¬ì—ì„œ ë¬¸ì„œ ë‚´ ì‚¬ê±´ ê°„ì˜ ì‹œê°„ì  ê´€ê³„ë¥¼ ì¶”ì¶œí•˜ëŠ” ì‘ì—…ì¸ ì‹œê°„ ê´€ê³„ ì¶”ì¶œ(TRE)ì— ëŒ€í•œ ì—°êµ¬ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë°©ë²•ë“¤ì€ ì‚¬ê±´ ìŒì„ ê°œë³„ì ìœ¼ë¡œ ë¶„ë¥˜í•˜ì—¬ ë¹„íš¨ìœ¨ì ì´ê³  ì „ì²´ì ì¸ ì¼ê´€ì„±ì´ ë¶€ì¡±í•œ ë¬¸ì œë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” ë¬¸ì„œì˜ ì „ì²´ ì‹œê°„ ê·¸ë˜í”„ë¥¼ í•œ ë²ˆì— ìƒì„±í•˜ê³ , ì‹œê°„ ì œì•½ ìµœì í™”ë¥¼ í†µí•´ ì˜ˆì¸¡ì„ ê°œì„ í•˜ê³  ê´€ê³„ ê°„ì˜ ì‹œê°„ì  ì¼ê´€ì„±ì„ ìœ ì§€í•˜ëŠ” ìƒˆë¡œìš´ ì œë¡œìƒ· ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ë˜í•œ, ëª¨ë“  ì‚¬ê±´ ìŒì— ëŒ€í•œ ì™„ì „í•œ ì£¼ì„ì„ í¬í•¨í•œ ìƒˆë¡œìš´ ë°ì´í„°ì…‹ì¸ OmniTempë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì´ ê¸°ì¡´ ì œë¡œìƒ· ì ‘ê·¼ë²•ì„ ëŠ¥ê°€í•˜ë©°, ì§€ë„ í•™ìŠµ ëª¨ë¸ì— ëŒ€í•œ ê²½ìŸë ¥ ìˆëŠ” ëŒ€ì•ˆì„ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì‹œê°„ ê´€ê³„ ì¶”ì¶œ(TRE)ì€ ë¬¸ì„œ ë‚´ ì‚¬ê±´ ê°„ì˜ ì‹œê°„ì  ê´€ê³„ë¥¼ ì‹ë³„í•˜ëŠ” ìì—°ì–´ ì²˜ë¦¬(NLP)ì˜ ê¸°ë³¸ ì‘ì—…ì´ë‹¤.
- 2. ê¸°ì¡´ ë°©ë²•ë“¤ì€ ì‚¬ê±´ ìŒì„ ê°œë³„ì ìœ¼ë¡œ ë¶„ë¥˜í•˜ì—¬ ê³„ì‚° ë¹„íš¨ìœ¨ì„±ê³¼ ì‹œê°„ ê·¸ë˜í”„ì˜ ì „ì—­ì  ì¼ê´€ì„± ë¶€ì¡± ë¬¸ì œë¥¼ ê°€ì§„ë‹¤.
- 3. ë³¸ ì—°êµ¬ì—ì„œëŠ” ë¬¸ì„œì˜ ì „ì²´ ì‹œê°„ ê·¸ë˜í”„ë¥¼ í•œ ë²ˆì— ìƒì„±í•˜ê³ , ì‹œê°„ ì œì•½ ìµœì í™”ë¥¼ í†µí•´ ì˜ˆì¸¡ì„ ê°œì„ í•˜ëŠ” ìƒˆë¡œìš´ ì œë¡œìƒ· ë°©ë²•ì„ ì œì•ˆí•œë‹¤.
- 4. ìƒˆë¡œìš´ ë°ì´í„°ì…‹ OmniTempë¥¼ ë„ì…í•˜ì—¬ ë¬¸ì„œ ë‚´ ëª¨ë“  ì‚¬ê±´ ìŒì— ëŒ€í•œ ì™„ì „í•œ ì£¼ì„ì„ ì œê³µí•œë‹¤.
- 5. ì‹¤í—˜ê³¼ ë¶„ì„ì„ í†µí•´ ì œì•ˆëœ ë°©ë²•ì´ ê¸°ì¡´ ì œë¡œìƒ· ì ‘ê·¼ë²•ì„ ëŠ¥ê°€í•˜ë©°, ê°ë… í•™ìŠµ TRE ëª¨ë¸ì— ëŒ€í•œ ê²½ìŸë ¥ ìˆëŠ” ëŒ€ì•ˆì„ì„ ì…ì¦í•œë‹¤.


---

*Generated on 2025-09-24 03:48:25*