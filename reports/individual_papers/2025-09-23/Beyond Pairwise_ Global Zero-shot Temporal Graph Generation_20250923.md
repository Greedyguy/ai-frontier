---
keywords:
  - Temporal Relation Extraction
  - Zero-Shot Learning
  - Large Language Model
  - Temporal Graph Generation
  - Temporal Constraint Optimization
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2502.11114
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:48:25.538789",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Temporal Relation Extraction",
    "Zero-Shot Learning",
    "Large Language Model",
    "Temporal Graph Generation",
    "Temporal Constraint Optimization"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Temporal Relation Extraction": 0.8,
    "Zero-Shot Learning": 0.9,
    "Large Language Model": 0.85,
    "Temporal Graph Generation": 0.75,
    "Temporal Constraint Optimization": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Temporal Relation Extraction",
        "canonical": "Temporal Relation Extraction",
        "aliases": [
          "TRE"
        ],
        "category": "unique_technical",
        "rationale": "This is a specific task in NLP that directly relates to the paper's contribution and is essential for linking related research.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "Zero-shot Method",
        "canonical": "Zero-Shot Learning",
        "aliases": [
          "Zero-shot Approach"
        ],
        "category": "specific_connectable",
        "rationale": "Zero-shot learning is a trending concept that connects to various machine learning techniques and applications.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.9
      },
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "LLMs are a foundational technology in NLP and connect to a wide range of research topics.",
        "novelty_score": 0.4,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Temporal Graph Generation",
        "canonical": "Temporal Graph Generation",
        "aliases": [
          "Temporal Graph Construction"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel concept introduced by the paper, crucial for understanding its contributions.",
        "novelty_score": 0.8,
        "connectivity_score": 0.5,
        "specificity_score": 0.85,
        "link_intent_score": 0.75
      },
      {
        "surface": "Temporal Constraint Optimization",
        "canonical": "Temporal Constraint Optimization",
        "aliases": [
          "Temporal Optimization"
        ],
        "category": "unique_technical",
        "rationale": "This technique is a key part of the proposed method, linking it to optimization research.",
        "novelty_score": 0.65,
        "connectivity_score": 0.55,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "method",
      "approach",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Temporal Relation Extraction",
      "resolved_canonical": "Temporal Relation Extraction",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Zero-shot Method",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.9
      }
    },
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Temporal Graph Generation",
      "resolved_canonical": "Temporal Graph Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.5,
        "specificity": 0.85,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Temporal Constraint Optimization",
      "resolved_canonical": "Temporal Constraint Optimization",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.55,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# Beyond Pairwise: Global Zero-shot Temporal Graph Generation

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2502.11114.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2502.11114](https://arxiv.org/abs/2502.11114)

## 🔗 유사한 논문
- [[2025-09-22/A Benchmark for End-to-End Zero-Shot Biomedical Relation Extraction with LLMs_ Experiments with OpenAI Models_20250922|A Benchmark for End-to-End Zero-Shot Biomedical Relation Extraction with LLMs: Experiments with OpenAI Models]] (80.8% similar)
- [[2025-09-22/Temporal Reasoning with Large Language Models Augmented by Evolving Knowledge Graphs_20250922|Temporal Reasoning with Large Language Models Augmented by Evolving Knowledge Graphs]] (80.3% similar)
- [[2025-09-23/Full-History Graphs with Edge-Type Decoupled Networks for Temporal Reasoning_20250923|Full-History Graphs with Edge-Type Decoupled Networks for Temporal Reasoning]] (79.4% similar)
- [[2025-09-22/Structured Information for Improving Spatial Relationships in Text-to-Image Generation_20250922|Structured Information for Improving Spatial Relationships in Text-to-Image Generation]] (79.1% similar)
- [[2025-09-22/BBScoreV2_ Learning Time-Evolution and Latent Alignment from Stochastic Representation_20250922|BBScoreV2: Learning Time-Evolution and Latent Alignment from Stochastic Representation]] (78.6% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Zero-Shot Learning|Zero-Shot Learning]]
**⚡ Unique Technical**: [[keywords/Temporal Relation Extraction|Temporal Relation Extraction]], [[keywords/Temporal Graph Generation|Temporal Graph Generation]], [[keywords/Temporal Constraint Optimization|Temporal Constraint Optimization]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2502.11114v3 Announce Type: replace 
Abstract: Temporal relation extraction (TRE) is a fundamental task in natural language processing (NLP) that involves identifying the temporal relationships between events in a document. Despite the advances in large language models (LLMs), their application to TRE remains limited. Most existing approaches rely on pairwise classification, where event pairs are classified in isolation, leading to computational inefficiency and a lack of global consistency in the resulting temporal graph. In this work, we propose a novel zero-shot method for TRE that generates a document's complete temporal graph in a single step, followed by temporal constraint optimization to refine predictions and enforce temporal consistency across relations. Additionally, we introduce OmniTemp, a new dataset with complete annotations for all pairs of targeted events within a document. Through experiments and analyses, we demonstrate that our method outperforms existing zero-shot approaches and offers a competitive alternative to supervised TRE models.

## 📝 요약

이 논문은 자연어 처리에서 문서 내 사건 간의 시간적 관계를 추출하는 작업인 시간 관계 추출(TRE)에 대한 연구를 다룹니다. 기존의 방법들은 사건 쌍을 개별적으로 분류하여 비효율적이고 전체적인 일관성이 부족한 문제를 가지고 있습니다. 본 연구에서는 문서의 전체 시간 그래프를 한 번에 생성하고, 시간 제약 최적화를 통해 예측을 개선하고 관계 간의 시간적 일관성을 유지하는 새로운 제로샷 방법을 제안합니다. 또한, 모든 사건 쌍에 대한 완전한 주석을 포함한 새로운 데이터셋인 OmniTemp를 소개합니다. 실험 결과, 제안된 방법이 기존 제로샷 접근법을 능가하며, 지도 학습 모델에 대한 경쟁력 있는 대안임을 보여줍니다.

## 🎯 주요 포인트

- 1. 시간 관계 추출(TRE)은 문서 내 사건 간의 시간적 관계를 식별하는 자연어 처리(NLP)의 기본 작업이다.
- 2. 기존 방법들은 사건 쌍을 개별적으로 분류하여 계산 비효율성과 시간 그래프의 전역적 일관성 부족 문제를 가진다.
- 3. 본 연구에서는 문서의 전체 시간 그래프를 한 번에 생성하고, 시간 제약 최적화를 통해 예측을 개선하는 새로운 제로샷 방법을 제안한다.
- 4. 새로운 데이터셋 OmniTemp를 도입하여 문서 내 모든 사건 쌍에 대한 완전한 주석을 제공한다.
- 5. 실험과 분석을 통해 제안된 방법이 기존 제로샷 접근법을 능가하며, 감독 학습 TRE 모델에 대한 경쟁력 있는 대안임을 입증한다.


---

*Generated on 2025-09-24 03:48:25*