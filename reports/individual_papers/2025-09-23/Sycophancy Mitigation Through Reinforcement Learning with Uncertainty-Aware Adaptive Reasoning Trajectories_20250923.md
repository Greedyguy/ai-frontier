---
keywords:
  - Large Language Model
  - Reinforcement Learning
  - Uncertainty-Aware Adaptive Monte Carlo Tree Search
  - Reasoning Optimization
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.16742
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T22:51:29.942686",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Reinforcement Learning",
    "Uncertainty-Aware Adaptive Monte Carlo Tree Search",
    "Reasoning Optimization"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Reinforcement Learning": 0.8,
    "Uncertainty-Aware Adaptive Monte Carlo Tree Search": 0.78,
    "Reasoning Optimization": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "large-scale language models"
        ],
        "category": "broad_technical",
        "rationale": "Connecting to the broader field of language models enhances understanding of the sycophancy issue in AI.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.5,
        "link_intent_score": 0.85
      },
      {
        "surface": "Reinforcement Learning",
        "canonical": "Reinforcement Learning",
        "aliases": [
          "RL"
        ],
        "category": "broad_technical",
        "rationale": "Reinforcement learning is central to the proposed sycophancy mitigation strategy.",
        "novelty_score": 0.4,
        "connectivity_score": 0.88,
        "specificity_score": 0.6,
        "link_intent_score": 0.8
      },
      {
        "surface": "Uncertainty-Aware Adaptive Monte Carlo Tree Search",
        "canonical": "Uncertainty-Aware Adaptive Monte Carlo Tree Search",
        "aliases": [
          "UA-MCTS"
        ],
        "category": "unique_technical",
        "rationale": "This novel technique is pivotal in the adaptive reasoning framework proposed in the paper.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Reasoning Optimization Problem",
        "canonical": "Reasoning Optimization",
        "aliases": [
          "optimization of reasoning"
        ],
        "category": "unique_technical",
        "rationale": "Reframing sycophancy as a reasoning optimization problem is a novel approach in the paper.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "sycophancy",
      "SMART"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.5,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Reinforcement Learning",
      "resolved_canonical": "Reinforcement Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.88,
        "specificity": 0.6,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Uncertainty-Aware Adaptive Monte Carlo Tree Search",
      "resolved_canonical": "Uncertainty-Aware Adaptive Monte Carlo Tree Search",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Reasoning Optimization Problem",
      "resolved_canonical": "Reasoning Optimization",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Sycophancy Mitigation Through Reinforcement Learning with Uncertainty-Aware Adaptive Reasoning Trajectories

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16742.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.16742](https://arxiv.org/abs/2509.16742)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Internalizing Self-Consistency in Language Models_ Multi-Agent Consensus Alignment_20250919|Internalizing Self-Consistency in Language Models: Multi-Agent Consensus Alignment]] (85.3% similar)
- [[2025-09-22/Search and Refine During Think_ Facilitating Knowledge Refinement for Improved Retrieval-Augmented Reasoning_20250922|Search and Refine During Think: Facilitating Knowledge Refinement for Improved Retrieval-Augmented Reasoning]] (84.7% similar)
- [[2025-09-22/Pointing to a Llama and Call it a Camel_ On the Sycophancy of Multimodal Large Language Models_20250922|Pointing to a Llama and Call it a Camel: On the Sycophancy of Multimodal Large Language Models]] (83.4% similar)
- [[2025-09-19/Enhancing Logical Reasoning in Language Models via Symbolically-Guided Monte Carlo Process Supervision_20250919|Enhancing Logical Reasoning in Language Models via Symbolically-Guided Monte Carlo Process Supervision]] (83.1% similar)
- [[2025-09-19/SMART_ Simulated Students Aligned with Item Response Theory for Question Difficulty Prediction_20250919|SMART: Simulated Students Aligned with Item Response Theory for Question Difficulty Prediction]] (82.7% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]], [[keywords/Reinforcement Learning|Reinforcement Learning]]
**âš¡ Unique Technical**: [[keywords/Uncertainty-Aware Adaptive Monte Carlo Tree Search|Uncertainty-Aware Adaptive Monte Carlo Tree Search]], [[keywords/Reasoning Optimization|Reasoning Optimization]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16742v1 Announce Type: new 
Abstract: Despite the remarkable capabilities of large language models, current training paradigms inadvertently foster \textit{sycophancy}, i.e., the tendency of a model to agree with or reinforce user-provided information even when it's factually incorrect. To address this challenge, we introduce \textbf{SMART} (Sycophancy Mitigation through Adaptive Reasoning Trajectories), which reframes sycophancy as a \textit{reasoning optimization problem} rather than an output alignment issue. SMART is a two-stage framework comprising: (1) Uncertainty-Aware Adaptive Monte Carlo Tree Search (UA-MCTS), which dynamically adjusts model exploration based on state-level uncertainty to collect high-quality, diverse reasoning trajectories alongside both stepwise progress and final outcome rewards; and (2) progress-based reinforcement learning, which fine-tunes the model using the collected trajectories and reward signals to reinforce effective reasoning patterns. Through extensive experiments, we show that SMART significantly reduces sycophantic behavior while preserving strong performance on out-of-distribution inputs and maintaining general capabilities. These results underscore the importance of optimizing internal reasoning mechanisms to build more truthful and aligned AI assistants.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ ë¬¸ì œì ì¸ 'ì•„ì²¨'ì„ í•´ê²°í•˜ê¸° ìœ„í•´ SMARTë¼ëŠ” ìƒˆë¡œìš´ ì ‘ê·¼ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì•„ì²¨ì€ ëª¨ë¸ì´ ì‚¬ìš©ì ì œê³µ ì •ë³´ì— ë¬´ì¡°ê±´ ë™ì˜í•˜ëŠ” ê²½í–¥ì„ ë§í•©ë‹ˆë‹¤. SMARTëŠ” ì´ë¥¼ ì¶œë ¥ ì •ë ¬ ë¬¸ì œê°€ ì•„ë‹Œ ì¶”ë¡  ìµœì í™” ë¬¸ì œë¡œ ì¬êµ¬ì„±í•©ë‹ˆë‹¤. ë‘ ë‹¨ê³„ë¡œ êµ¬ì„±ëœ SMARTëŠ” (1) ìƒíƒœ ë¶ˆí™•ì‹¤ì„±ì— ê¸°ë°˜í•´ ëª¨ë¸ íƒìƒ‰ì„ ì¡°ì •í•˜ëŠ” ë¶ˆí™•ì‹¤ì„± ì¸ì‹ ì ì‘í˜• ëª¬í…Œì¹´ë¥¼ë¡œ íŠ¸ë¦¬ íƒìƒ‰(UA-MCTS)ê³¼ (2) ìˆ˜ì§‘ëœ ê²½ë¡œì™€ ë³´ìƒ ì‹ í˜¸ë¥¼ í†µí•´ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ëŠ” ì§„í–‰ ê¸°ë°˜ ê°•í™” í•™ìŠµì„ í¬í•¨í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, SMARTëŠ” ì•„ì²¨ í–‰ë™ì„ í¬ê²Œ ì¤„ì´ë©´ì„œë„ ëª¨ë¸ì˜ ì¼ë°˜ì ì¸ ì„±ëŠ¥ì„ ìœ ì§€í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŠ” AI ë¹„ì„œì˜ ì§„ì‹¤ì„±ê³¼ ì •ë ¬ì„±ì„ ë†’ì´ê¸° ìœ„í•´ ë‚´ë¶€ ì¶”ë¡  ë©”ì»¤ë‹ˆì¦˜ ìµœì í™”ê°€ ì¤‘ìš”í•¨ì„ ê°•ì¡°í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ ì•„ì²¨ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ SMARTë¼ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¥¼ ë„ì…í–ˆìŠµë‹ˆë‹¤.
- 2. SMARTëŠ” ì•„ì²¨ì„ ì¶œë ¥ ì •ë ¬ ë¬¸ì œê°€ ì•„ë‹Œ ì¶”ë¡  ìµœì í™” ë¬¸ì œë¡œ ì¬êµ¬ì„±í•©ë‹ˆë‹¤.
- 3. UA-MCTSëŠ” ìƒíƒœ ë¶ˆí™•ì‹¤ì„±ì— ë”°ë¼ ëª¨ë¸ íƒìƒ‰ì„ ë™ì ìœ¼ë¡œ ì¡°ì •í•˜ì—¬ ë‹¤ì–‘í•œ ì¶”ë¡  ê²½ë¡œë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
- 4. ì§„í–‰ ê¸°ë°˜ ê°•í™” í•™ìŠµì„ í†µí•´ ìˆ˜ì§‘ëœ ê²½ë¡œì™€ ë³´ìƒ ì‹ í˜¸ë¥¼ ì‚¬ìš©í•˜ì—¬ íš¨ê³¼ì ì¸ ì¶”ë¡  íŒ¨í„´ì„ ê°•í™”í•©ë‹ˆë‹¤.
- 5. SMARTëŠ” ì•„ì²¨ í–‰ë™ì„ í¬ê²Œ ì¤„ì´ë©´ì„œë„ ëª¨ë¸ì˜ ì¼ë°˜ì ì¸ ì„±ëŠ¥ì„ ìœ ì§€í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-23 22:51:29*