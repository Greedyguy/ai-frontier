---
keywords:
  - VQToken
  - Extreme Short Token Reduction
  - Token Information Density
  - Video Large Language Models
  - Vector Quantization
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2503.16980
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T00:51:25.712776",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "VQToken",
    "Extreme Short Token Reduction",
    "Token Information Density",
    "Video Large Language Models",
    "Vector Quantization"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "VQToken": 0.8,
    "Extreme Short Token Reduction": 0.75,
    "Token Information Density": 0.7,
    "Video Large Language Models": 0.78,
    "Vector Quantization": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "VQToken",
        "canonical": "VQToken",
        "aliases": [
          "Neural Discrete Token Representation"
        ],
        "category": "unique_technical",
        "rationale": "VQToken represents a novel approach to token representation, crucial for linking innovations in video LLMs.",
        "novelty_score": 0.85,
        "connectivity_score": 0.7,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "Extreme Short Token Reduction",
        "canonical": "Extreme Short Token Reduction",
        "aliases": [
          "Token Reduction"
        ],
        "category": "unique_technical",
        "rationale": "This task is central to the paper's contribution and links to efforts in optimizing token usage in LLMs.",
        "novelty_score": 0.8,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.75
      },
      {
        "surface": "Token Information Density",
        "canonical": "Token Information Density",
        "aliases": [
          "TokDense"
        ],
        "category": "unique_technical",
        "rationale": "TokDense is a new metric introduced in the paper, relevant for evaluating token efficiency.",
        "novelty_score": 0.78,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      },
      {
        "surface": "Video Large Language Models",
        "canonical": "Video Large Language Models",
        "aliases": [
          "Video LLMs"
        ],
        "category": "evolved_concepts",
        "rationale": "This concept represents an evolution in LLMs, integrating video data, and is crucial for cross-modal research.",
        "novelty_score": 0.7,
        "connectivity_score": 0.85,
        "specificity_score": 0.75,
        "link_intent_score": 0.78
      },
      {
        "surface": "Vector Quantization",
        "canonical": "Vector Quantization",
        "aliases": [
          "VQ"
        ],
        "category": "specific_connectable",
        "rationale": "Vector Quantization is a key technique used in the paper, linking to broader applications in data compression.",
        "novelty_score": 0.65,
        "connectivity_score": 0.8,
        "specificity_score": 0.7,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "approach"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "VQToken",
      "resolved_canonical": "VQToken",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.7,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Extreme Short Token Reduction",
      "resolved_canonical": "Extreme Short Token Reduction",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Token Information Density",
      "resolved_canonical": "Token Information Density",
      "decision": "linked",
      "scores": {
        "novelty": 0.78,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Video Large Language Models",
      "resolved_canonical": "Video Large Language Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.85,
        "specificity": 0.75,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Vector Quantization",
      "resolved_canonical": "Vector Quantization",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.8,
        "specificity": 0.7,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# VQToken: Neural Discrete Token Representation Learning for Extreme Token Reduction in Video Large Language Models

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2503.16980.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2503.16980](https://arxiv.org/abs/2503.16980)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Training-Free Pyramid Token Pruning for Efficient Large Vision-Language Models via Region, Token, and Instruction-Guided Importance_20250922|Training-Free Pyramid Token Pruning for Efficient Large Vision-Language Models via Region, Token, and Instruction-Guided Importance]] (84.5% similar)
- [[2025-09-17/Dense Video Understanding with Gated Residual Tokenization_20250917|Dense Video Understanding with Gated Residual Tokenization]] (84.3% similar)
- [[2025-09-22/KVCompose_ Efficient Structured KV Cache Compression with Composite Tokens_20250922|KVCompose: Efficient Structured KV Cache Compression with Composite Tokens]] (83.8% similar)
- [[2025-09-17/Where Do Tokens Go? Understanding Pruning Behaviors in STEP at High Resolutions_20250917|Where Do Tokens Go? Understanding Pruning Behaviors in STEP at High Resolutions]] (83.7% similar)
- [[2025-09-23/PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models_20250923|PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models]] (83.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Vector Quantization|Vector Quantization]]
**âš¡ Unique Technical**: [[keywords/VQToken|VQToken]], [[keywords/Extreme Short Token Reduction|Extreme Short Token Reduction]], [[keywords/Token Information Density|Token Information Density]]
**ğŸš€ Evolved Concepts**: [[keywords/Video Large Language Models|Video Large Language Models]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2503.16980v5 Announce Type: replace-cross 
Abstract: Token-based video representation has emerged as a promising approach for enabling large language models (LLMs) to interpret video content. However, existing token reduction techniques, such as pruning and merging, often disrupt essential positional embeddings and rely on continuous visual tokens sampled from nearby pixels with similar spatial-temporal locations. By removing only a small fraction of tokens, these methods still produce relatively lengthy continuous sequences, which falls short of the extreme compression required to balance computational efficiency and token count in video LLMs. In this paper, we introduce the novel task of Extreme Short Token Reduction, which aims to represent entire videos using a minimal set of discrete tokens. We propose VQToken, a neural discrete token representation framework that (i) applies adaptive vector quantization to continuous ViT embeddings to learn a compact codebook and (ii) preserves spatial-temporal positions via a token hash function by assigning each grid-level token to its nearest codebook entry. On the Extreme Short Token Reduction task, our VQToken compresses sequences to just 0.07 percent of their original length while incurring only a 0.66 percent drop in accuracy on the NextQA-MC benchmark. It also achieves comparable performance on ActNet-QA, Long Video Bench, and VideoMME. We further introduce the Token Information Density (TokDense) metric and formalize fixed-length and adaptive-length subtasks, achieving state-of-the-art results in both settings. Our approach dramatically lowers theoretical complexity, increases information density, drastically reduces token counts, and enables efficient video LLMs in resource-constrained environments.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë¹„ë””ì˜¤ ì½˜í…ì¸  í•´ì„ì„ ìœ„í•œ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì— ì í•©í•œ ê·¹ë‹¨ì ì¸ í† í° ì¶•ì†Œ ê¸°ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ í† í° ì¶•ì†Œ ë°©ë²•ì€ ìœ„ì¹˜ ì„ë² ë”©ì„ ë°©í•´í•˜ê³ , ìœ ì‚¬í•œ ìœ„ì¹˜ì˜ ì—°ì†ì ì¸ ë¹„ì£¼ì–¼ í† í°ì— ì˜ì¡´í•˜ì—¬ ê¸´ ì‹œí€€ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” VQTokenì´ë¼ëŠ” ì‹ ê²½ë§ ê¸°ë°˜ì˜ ì´ì‚° í† í° í‘œí˜„ í”„ë ˆì„ì›Œí¬ë¥¼ ì†Œê°œí•˜ì—¬, ì ì‘í˜• ë²¡í„° ì–‘ìí™”ë¥¼ í†µí•´ ì••ì¶•ëœ ì½”ë“œë¶ì„ í•™ìŠµí•˜ê³ , í† í° í•´ì‹œ í•¨ìˆ˜ë¥¼ í†µí•´ ê³µê°„-ì‹œê°„ì  ìœ„ì¹˜ë¥¼ ë³´ì¡´í•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ NextQA-MC ë²¤ì¹˜ë§ˆí¬ì—ì„œ ì •í™•ë„ 0.66% ê°ì†Œë§Œìœ¼ë¡œ ì›ë˜ ê¸¸ì´ì˜ 0.07%ë¡œ ì‹œí€€ìŠ¤ë¥¼ ì••ì¶•í•˜ë©°, ActNet-QA ë“±ì—ì„œë„ ìœ ì‚¬í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤. ë˜í•œ, ìƒˆë¡œìš´ í† í° ì •ë³´ ë°€ë„(TokDense) ì§€í‘œë¥¼ ë„ì…í•˜ì—¬ ê³ ì • ë° ì ì‘ ê¸¸ì´ì˜ í•˜ìœ„ ê³¼ì œì—ì„œ ìµœì²¨ë‹¨ ê²°ê³¼ë¥¼ ë‹¬ì„±í•©ë‹ˆë‹¤. ì´ ì ‘ê·¼ë²•ì€ ì´ë¡ ì  ë³µì¡ì„±ì„ ë‚®ì¶”ê³ , ì •ë³´ ë°€ë„ë¥¼ ë†’ì´ë©°, ìì› ì œí•œ í™˜ê²½ì—ì„œ íš¨ìœ¨ì ì¸ ë¹„ë””ì˜¤ LLMì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë³¸ ì—°êµ¬ëŠ” ë¹„ë””ì˜¤ LLMsì˜ íš¨ìœ¨ì„±ì„ ë†’ì´ê¸° ìœ„í•´ ê·¹ë‹¨ì ì¸ í† í° ì••ì¶•ì„ ëª©í‘œë¡œ í•˜ëŠ” Extreme Short Token Reduction ì‘ì—…ì„ ì œì•ˆí•©ë‹ˆë‹¤.
- 2. VQTokenì€ ì ì‘í˜• ë²¡í„° ì–‘ìí™”ë¥¼ ì‚¬ìš©í•˜ì—¬ ì—°ì†ì ì¸ ViT ì„ë² ë”©ì„ ì••ì¶• ì½”ë“œë¶ìœ¼ë¡œ í•™ìŠµí•˜ê³ , í† í° í•´ì‹œ í•¨ìˆ˜ë¥¼ í†µí•´ ê³µê°„-ì‹œê°„ì  ìœ„ì¹˜ë¥¼ ë³´ì¡´í•©ë‹ˆë‹¤.
- 3. VQTokenì€ NextQA-MC ë²¤ì¹˜ë§ˆí¬ì—ì„œ ì›ë˜ ê¸¸ì´ì˜ 0.07%ë¡œ ì‹œí€€ìŠ¤ë¥¼ ì••ì¶•í•˜ë©´ì„œë„ ì •í™•ë„ëŠ” 0.66%ë§Œ ê°ì†Œì‹œí‚µë‹ˆë‹¤.
- 4. TokDenseë¼ëŠ” ìƒˆë¡œìš´ í† í° ì •ë³´ ë°€ë„ ì§€í‘œë¥¼ ë„ì…í•˜ê³ , ê³ ì • ê¸¸ì´ ë° ì ì‘í˜• ê¸¸ì´ì˜ í•˜ìœ„ ì‘ì—…ì—ì„œ ìµœì²¨ë‹¨ ê²°ê³¼ë¥¼ ë‹¬ì„±í•©ë‹ˆë‹¤.
- 5. ì œì•ˆëœ ë°©ë²•ì€ ì´ë¡ ì  ë³µì¡ì„±ì„ í¬ê²Œ ë‚®ì¶”ê³ , ì •ë³´ ë°€ë„ë¥¼ ë†’ì´ë©°, í† í° ìˆ˜ë¥¼ ê¸‰ê²©íˆ ì¤„ì—¬ ìì› ì œì•½ í™˜ê²½ì—ì„œ íš¨ìœ¨ì ì¸ ë¹„ë””ì˜¤ LLMsë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 00:51:25*