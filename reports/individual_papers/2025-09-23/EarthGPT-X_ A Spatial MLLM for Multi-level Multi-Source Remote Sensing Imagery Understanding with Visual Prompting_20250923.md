---
keywords:
  - Large Language Model
  - Remote Sensing
  - Visual Prompting
  - Cross-domain Fusion
  - Spatial Reasoning
category: cs.CV
publish_date: 2025-09-23
arxiv_id: 2504.12795
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T05:20:53.250832",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Remote Sensing",
    "Visual Prompting",
    "Cross-domain Fusion",
    "Spatial Reasoning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Remote Sensing": 0.78,
    "Visual Prompting": 0.8,
    "Cross-domain Fusion": 0.72,
    "Spatial Reasoning": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multi-modal Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "MLLM",
          "Multimodal LLM"
        ],
        "category": "broad_technical",
        "rationale": "Connects to existing knowledge on large language models and their application across modalities.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Remote Sensing Imagery",
        "canonical": "Remote Sensing",
        "aliases": [
          "RS Imagery",
          "Remote Sensing Data"
        ],
        "category": "specific_connectable",
        "rationale": "Facilitates connections to studies and technologies focused on remote sensing data.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Visual Prompting",
        "canonical": "Visual Prompting",
        "aliases": [
          "Visual Prompts",
          "Prompting"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel approach in the context of remote sensing and language models.",
        "novelty_score": 0.7,
        "connectivity_score": 0.75,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Cross-domain Fusion Training",
        "canonical": "Cross-domain Fusion",
        "aliases": [
          "Fusion Training",
          "Cross-domain Training"
        ],
        "category": "unique_technical",
        "rationale": "Highlights a specific training strategy relevant to multi-modal and multi-task learning.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.78,
        "link_intent_score": 0.72
      },
      {
        "surface": "Hierarchical Spatial Reasoning",
        "canonical": "Spatial Reasoning",
        "aliases": [
          "Hierarchical Reasoning",
          "Spatial Analysis"
        ],
        "category": "specific_connectable",
        "rationale": "Links to concepts in spatial analysis and reasoning, crucial for interpreting remote sensing data.",
        "novelty_score": 0.6,
        "connectivity_score": 0.82,
        "specificity_score": 0.77,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multi-modal Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Remote Sensing Imagery",
      "resolved_canonical": "Remote Sensing",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Visual Prompting",
      "resolved_canonical": "Visual Prompting",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.75,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Cross-domain Fusion Training",
      "resolved_canonical": "Cross-domain Fusion",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.78,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "Hierarchical Spatial Reasoning",
      "resolved_canonical": "Spatial Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.82,
        "specificity": 0.77,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# EarthGPT-X: A Spatial MLLM for Multi-level Multi-Source Remote Sensing Imagery Understanding with Visual Prompting

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2504.12795.pdf)
**Category**: cs.CV
**Published**: 2025-09-23
**ArXiv ID**: [2504.12795](https://arxiv.org/abs/2504.12795)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/See&Trek_ Training-Free Spatial Prompting for Multimodal Large Language Model_20250922|See&Trek: Training-Free Spatial Prompting for Multimodal Large Language Model]] (84.9% similar)
- [[2025-09-23/Open Vision Reasoner_ Transferring Linguistic Cognitive Behavior for Visual Reasoning_20250923|Open Vision Reasoner: Transferring Linguistic Cognitive Behavior for Visual Reasoning]] (83.7% similar)
- [[2025-09-23/GeoPQA_ Bridging the Visual Perception Gap in MLLMs for Geometric Reasoning_20250923|GeoPQA: Bridging the Visual Perception Gap in MLLMs for Geometric Reasoning]] (83.7% similar)
- [[2025-09-22/Perception-R1_ Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward_20250922|Perception-R1: Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward]] (83.2% similar)
- [[2025-09-23/ProReason_ Multi-Modal Proactive Reasoning with Decoupled Eyesight and Wisdom_20250923|ProReason: Multi-Modal Proactive Reasoning with Decoupled Eyesight and Wisdom]] (83.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Remote Sensing|Remote Sensing]], [[keywords/Spatial Reasoning|Spatial Reasoning]]
**âš¡ Unique Technical**: [[keywords/Visual Prompting|Visual Prompting]], [[keywords/Cross-domain Fusion|Cross-domain Fusion]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2504.12795v2 Announce Type: replace 
Abstract: Recent advances in natural-domain multi-modal large language models (MLLMs) have demonstrated effective spatial reasoning through visual and textual prompting. However, their direct transfer to remote sensing (RS) is hindered by heterogeneous sensing physics, diverse modalities, and unique spatial scales. Existing RS MLLMs are mainly limited to optical imagery and plain language interaction, preventing flexible and scalable real-world applications. In this article, EarthGPT-X is proposed, the first flexible spatial MLLM that unifies multi-source RS imagery comprehension and accomplishes both coarse-grained and fine-grained visual tasks under diverse visual prompts in a single framework. Distinct from prior models, EarthGPT-X introduces: 1) a dual-prompt mechanism combining text instructions with various visual prompts (i.e., point, box, and free-form) to mimic the versatility of referring in human life; 2) a comprehensive multi-source multi-level prompting dataset, the model advances beyond holistic image understanding to support hierarchical spatial reasoning, including scene-level understanding and fine-grained object attributes and relational analysis; 3) a cross-domain one-stage fusion training strategy, enabling efficient and consistent alignment across modalities and tasks. Extensive experiments demonstrate that EarthGPT-X substantially outperforms prior nature and RS MLLMs, establishing the first framework capable of multi-source, multi-task, and multi-level interpretation using visual prompting in RS scenarios.

## ğŸ“ ìš”ì•½

ìµœê·¼ ìì—° ë¶„ì•¼ì˜ ë‹¤ì¤‘ ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(MLLMs)ì€ ì‹œê°ì  ë° í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¥¼ í†µí•´ íš¨ê³¼ì ì¸ ê³µê°„ ì¶”ë¡ ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì›ê²© íƒì‚¬(RS) ë¶„ì•¼ë¡œì˜ ì§ì ‘ì ì¸ ì „í™˜ì€ ë‹¤ì–‘í•œ ê°ì§€ ë¬¼ë¦¬í•™, ëª¨ë‹¬ë¦¬í‹°, ê³µê°„ ê·œëª¨ë¡œ ì¸í•´ ì–´ë ¤ì›€ì„ ê²ªê³  ìˆìŠµë‹ˆë‹¤. ê¸°ì¡´ RS MLLMsëŠ” ì£¼ë¡œ ê´‘í•™ ì´ë¯¸ì§€ì™€ ë‹¨ìˆœí•œ ì–¸ì–´ ìƒí˜¸ì‘ìš©ì— ì œí•œë˜ì–´ ìˆì–´ ìœ ì—°í•˜ê³  í™•ì¥ ê°€ëŠ¥í•œ ì‹¤ì œ ì‘ìš©ì— í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì œì•ˆëœ EarthGPT-XëŠ” ë‹¤ì¤‘ ì†ŒìŠ¤ RS ì´ë¯¸ì§€ ì´í•´ë¥¼ í†µí•©í•˜ê³  ë‹¤ì–‘í•œ ì‹œê°ì  í”„ë¡¬í”„íŠ¸ í•˜ì—ì„œ ëŒ€ê·œëª¨ ë° ì„¸ë¶€ ì‹œê° ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ìµœì´ˆì˜ ìœ ì—°í•œ ê³µê°„ MLLMì…ë‹ˆë‹¤. EarthGPT-XëŠ” í…ìŠ¤íŠ¸ ì§€ì‹œì™€ ë‹¤ì–‘í•œ ì‹œê°ì  í”„ë¡¬í”„íŠ¸ë¥¼ ê²°í•©í•œ ì´ì¤‘ í”„ë¡¬í”„íŠ¸ ë©”ì»¤ë‹ˆì¦˜, í¬ê´„ì ì¸ ë‹¤ì¤‘ ì†ŒìŠ¤ ë‹¤ì¤‘ ë ˆë²¨ í”„ë¡¬í”„íŠ¸ ë°ì´í„°ì…‹, í¬ë¡œìŠ¤ ë„ë©”ì¸ ì›ìŠ¤í…Œì´ì§€ ìœµí•© í›ˆë ¨ ì „ëµì„ ë„ì…í•˜ì—¬ ë‹¤ì–‘í•œ ëª¨ë‹¬ë¦¬í‹°ì™€ ì‘ì—… ê°„ì˜ íš¨ìœ¨ì ì´ê³  ì¼ê´€ëœ ì •ë ¬ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, EarthGPT-XëŠ” ê¸°ì¡´ì˜ ìì—° ë° RS MLLMsë¥¼ ëŠ¥ê°€í•˜ë©°, RS ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì‹œê°ì  í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•œ ë‹¤ì¤‘ ì†ŒìŠ¤, ë‹¤ì¤‘ ì‘ì—…, ë‹¤ì¤‘ ë ˆë²¨ í•´ì„ì´ ê°€ëŠ¥í•œ ìµœì´ˆì˜ í”„ë ˆì„ì›Œí¬ë¥¼ í™•ë¦½í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. EarthGPT-XëŠ” ë‹¤ì–‘í•œ ì‹œê°ì  í”„ë¡¬í”„íŠ¸ë¥¼ í™œìš©í•˜ì—¬ ë‹¤ì¤‘ ì†ŒìŠ¤ ì›ê²© ê°ì§€ ì´ë¯¸ì§€ë¥¼ ì´í•´í•˜ê³ , ë‹¤ì–‘í•œ ì‹œê°ì  ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ìœ ì—°í•œ ê³µê°„ MLLMì…ë‹ˆë‹¤.
- 2. ì´ ëª¨ë¸ì€ í…ìŠ¤íŠ¸ ì§€ì‹œì™€ ë‹¤ì–‘í•œ ì‹œê°ì  í”„ë¡¬í”„íŠ¸(ì , ë°•ìŠ¤, ììœ í˜•)ë¥¼ ê²°í•©í•œ ì´ì¤‘ í”„ë¡¬í”„íŠ¸ ë©”ì»¤ë‹ˆì¦˜ì„ ë„ì…í•˜ì—¬ ì¸ê°„ì˜ ì°¸ì¡° ë‹¤ë³€ì„±ì„ ëª¨ë°©í•©ë‹ˆë‹¤.
- 3. í¬ê´„ì ì¸ ë‹¤ì¤‘ ì†ŒìŠ¤ ë‹¤ì¤‘ ë ˆë²¨ í”„ë¡¬í”„íŠ¸ ë°ì´í„°ì…‹ì„ í†µí•´ ì¥ë©´ ìˆ˜ì¤€ì˜ ì´í•´ì™€ ì„¸ë¶€ ê°ì²´ ì†ì„± ë° ê´€ê³„ ë¶„ì„ì„ ì§€ì›í•˜ëŠ” ê³„ì¸µì  ê³µê°„ ì¶”ë¡ ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
- 4. í¬ë¡œìŠ¤ ë„ë©”ì¸ ì›ìŠ¤í…Œì´ì§€ ìœµí•© í›ˆë ¨ ì „ëµì„ í†µí•´ ëª¨ë‹¬ë¦¬í‹°ì™€ ì‘ì—… ê°„ì˜ íš¨ìœ¨ì ì´ê³  ì¼ê´€ëœ ì •ë ¬ì„ ì‹¤í˜„í•©ë‹ˆë‹¤.
- 5. ì‹¤í—˜ ê²°ê³¼, EarthGPT-XëŠ” ê¸°ì¡´ì˜ ìì—° ë° ì›ê²© ê°ì§€ MLLMì„ ëŠ¥ê°€í•˜ë©°, ì›ê²© ê°ì§€ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì‹œê°ì  í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ëŠ” ë‹¤ì¤‘ ì†ŒìŠ¤, ë‹¤ì¤‘ ì‘ì—…, ë‹¤ì¤‘ ë ˆë²¨ í•´ì„ì´ ê°€ëŠ¥í•œ ì²« ë²ˆì§¸ í”„ë ˆì„ì›Œí¬ë¥¼ í™•ë¦½í–ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 05:20:53*