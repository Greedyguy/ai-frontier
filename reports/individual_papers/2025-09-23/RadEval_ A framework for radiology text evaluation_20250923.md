---
keywords:
  - Radiology Text Evaluation
  - Large Language Model
  - Zero-Shot Learning
  - Clinical Concept-Based Evaluation
  - Multimodal Learning
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2509.18030
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:36:34.200438",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Radiology Text Evaluation",
    "Large Language Model",
    "Zero-Shot Learning",
    "Clinical Concept-Based Evaluation",
    "Multimodal Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Radiology Text Evaluation": 0.78,
    "Large Language Model": 0.8,
    "Zero-Shot Learning": 0.82,
    "Clinical Concept-Based Evaluation": 0.75,
    "Multimodal Learning": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Radiology Text Evaluation",
        "canonical": "Radiology Text Evaluation",
        "aliases": [
          "RadEval"
        ],
        "category": "unique_technical",
        "rationale": "This is a unique framework specifically designed for evaluating radiology texts, which is central to the paper.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Large Language Model",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are integral to the evaluation framework discussed in the paper.",
        "novelty_score": 0.4,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Zero-Shot Retrieval",
        "canonical": "Zero-Shot Learning",
        "aliases": [
          "Zero-Shot"
        ],
        "category": "specific_connectable",
        "rationale": "Zero-shot retrieval is a key feature of the framework, enhancing its applicability in radiology.",
        "novelty_score": 0.68,
        "connectivity_score": 0.75,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "Clinical Concept-Based Scores",
        "canonical": "Clinical Concept-Based Evaluation",
        "aliases": [
          "Clinical Scores"
        ],
        "category": "unique_technical",
        "rationale": "These scores are critical for evaluating radiology texts in a clinically relevant manner.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      },
      {
        "surface": "Multimodal Imaging",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal"
        ],
        "category": "specific_connectable",
        "rationale": "The extension of the framework to support multiple imaging modalities highlights its versatility.",
        "novelty_score": 0.65,
        "connectivity_score": 0.72,
        "specificity_score": 0.77,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "experiment"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Radiology Text Evaluation",
      "resolved_canonical": "Radiology Text Evaluation",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Large Language Model",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Zero-Shot Retrieval",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.75,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Clinical Concept-Based Scores",
      "resolved_canonical": "Clinical Concept-Based Evaluation",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Multimodal Imaging",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.72,
        "specificity": 0.77,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# RadEval: A framework for radiology text evaluation

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18030.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2509.18030](https://arxiv.org/abs/2509.18030)

## 🔗 유사한 논문
- [[2025-09-22/CLEAR_ A Clinically-Grounded Tabular Framework for Radiology Report Evaluation_20250922|CLEAR: A Clinically-Grounded Tabular Framework for Radiology Report Evaluation]] (84.6% similar)
- [[2025-09-23/Medical AI Consensus_ A Multi-Agent Framework for Radiology Report Generation and Evaluation_20250923|Medical AI Consensus: A Multi-Agent Framework for Radiology Report Generation and Evaluation]] (83.6% similar)
- [[2025-09-23/HARE_ an entity and relation centric evaluation framework for histopathology reports_20250923|HARE: an entity and relation centric evaluation framework for histopathology reports]] (82.6% similar)
- [[2025-09-18/Limitations of Public Chest Radiography Datasets for Artificial Intelligence_ Label Quality, Domain Shift, Bias and Evaluation Challenges_20250918|Limitations of Public Chest Radiography Datasets for Artificial Intelligence: Label Quality, Domain Shift, Bias and Evaluation Challenges]] (81.5% similar)
- [[2025-09-19/MedVAL_ Toward Expert-Level Medical Text Validation with Language Models_20250919|MedVAL: Toward Expert-Level Medical Text Validation with Language Models]] (81.2% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Zero-Shot Learning|Zero-Shot Learning]], [[keywords/Multimodal Learning|Multimodal Learning]]
**⚡ Unique Technical**: [[keywords/Radiology Text Evaluation|Radiology Text Evaluation]], [[keywords/Clinical Concept-Based Evaluation|Clinical Concept-Based Evaluation]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.18030v1 Announce Type: new 
Abstract: We introduce RadEval, a unified, open-source framework for evaluating radiology texts. RadEval consolidates a diverse range of metrics, from classic n-gram overlap (BLEU, ROUGE) and contextual measures (BERTScore) to clinical concept-based scores (F1CheXbert, F1RadGraph, RaTEScore, SRR-BERT, TemporalEntityF1) and advanced LLM-based evaluators (GREEN). We refine and standardize implementations, extend GREEN to support multiple imaging modalities with a more lightweight model, and pretrain a domain-specific radiology encoder, demonstrating strong zero-shot retrieval performance. We also release a richly annotated expert dataset with over 450 clinically significant error labels and show how different metrics correlate with radiologist judgment. Finally, RadEval provides statistical testing tools and baseline model evaluations across multiple publicly available datasets, facilitating reproducibility and robust benchmarking in radiology report generation.

## 📝 요약

RadEval은 방사선학 텍스트 평가를 위한 통합 오픈소스 프레임워크로, 다양한 평가 지표를 통합합니다. 이 프레임워크는 BLEU, ROUGE 같은 고전적 n-그램 중복 지표부터 BERTScore와 같은 문맥적 측정, F1CheXbert, F1RadGraph 등 임상 개념 기반 점수, 그리고 GREEN 같은 고급 LLM 기반 평가자를 포함합니다. RadEval은 다양한 이미징 모달리티를 지원하도록 GREEN을 확장하고, 도메인 특화 방사선학 인코더를 사전 학습하여 강력한 제로샷 검색 성능을 입증했습니다. 또한, 450개 이상의 임상적으로 중요한 오류 레이블이 포함된 전문가 주석 데이터셋을 공개하고, 다양한 지표가 방사선 전문의의 판단과 어떻게 상관관계가 있는지를 보여줍니다. RadEval은 통계 테스트 도구와 여러 공개 데이터셋에 대한 기준 모델 평가를 제공하여 방사선 보고서 생성의 재현성과 견고한 벤치마킹을 촉진합니다.

## 🎯 주요 포인트

- 1. RadEval은 방사선학 텍스트 평가를 위한 통합 오픈소스 프레임워크로, 다양한 평가 지표를 통합합니다.
- 2. RadEval은 n-gram 중복, 문맥적 측정, 임상 개념 기반 점수, 고급 LLM 기반 평가자를 포함한 다양한 평가 방법을 제공합니다.
- 3. GREEN을 여러 영상 모달리티를 지원하도록 확장하고, 도메인 특화 방사선학 인코더를 사전 훈련하여 강력한 제로샷 검색 성능을 입증합니다.
- 4. 450개 이상의 임상적으로 중요한 오류 레이블이 포함된 전문가 주석 데이터셋을 공개하고, 다양한 지표가 방사선 전문의의 판단과 어떻게 상관관계가 있는지 보여줍니다.
- 5. RadEval은 통계적 테스트 도구와 여러 공개 데이터셋에 대한 기준 모델 평가를 제공하여 방사선 보고서 생성의 재현성과 견고한 벤치마킹을 촉진합니다.


---

*Generated on 2025-09-24 03:36:34*