---
keywords:
  - Radiology Text Evaluation
  - Large Language Model
  - Zero-Shot Learning
  - Clinical Concept-Based Evaluation
  - Multimodal Learning
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2509.18030
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:36:34.200438",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Radiology Text Evaluation",
    "Large Language Model",
    "Zero-Shot Learning",
    "Clinical Concept-Based Evaluation",
    "Multimodal Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Radiology Text Evaluation": 0.78,
    "Large Language Model": 0.8,
    "Zero-Shot Learning": 0.82,
    "Clinical Concept-Based Evaluation": 0.75,
    "Multimodal Learning": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Radiology Text Evaluation",
        "canonical": "Radiology Text Evaluation",
        "aliases": [
          "RadEval"
        ],
        "category": "unique_technical",
        "rationale": "This is a unique framework specifically designed for evaluating radiology texts, which is central to the paper.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Large Language Model",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are integral to the evaluation framework discussed in the paper.",
        "novelty_score": 0.4,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Zero-Shot Retrieval",
        "canonical": "Zero-Shot Learning",
        "aliases": [
          "Zero-Shot"
        ],
        "category": "specific_connectable",
        "rationale": "Zero-shot retrieval is a key feature of the framework, enhancing its applicability in radiology.",
        "novelty_score": 0.68,
        "connectivity_score": 0.75,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "Clinical Concept-Based Scores",
        "canonical": "Clinical Concept-Based Evaluation",
        "aliases": [
          "Clinical Scores"
        ],
        "category": "unique_technical",
        "rationale": "These scores are critical for evaluating radiology texts in a clinically relevant manner.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      },
      {
        "surface": "Multimodal Imaging",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal"
        ],
        "category": "specific_connectable",
        "rationale": "The extension of the framework to support multiple imaging modalities highlights its versatility.",
        "novelty_score": 0.65,
        "connectivity_score": 0.72,
        "specificity_score": 0.77,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "experiment"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Radiology Text Evaluation",
      "resolved_canonical": "Radiology Text Evaluation",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Large Language Model",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Zero-Shot Retrieval",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.75,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Clinical Concept-Based Scores",
      "resolved_canonical": "Clinical Concept-Based Evaluation",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Multimodal Imaging",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.72,
        "specificity": 0.77,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# RadEval: A framework for radiology text evaluation

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18030.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2509.18030](https://arxiv.org/abs/2509.18030)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/CLEAR_ A Clinically-Grounded Tabular Framework for Radiology Report Evaluation_20250922|CLEAR: A Clinically-Grounded Tabular Framework for Radiology Report Evaluation]] (84.6% similar)
- [[2025-09-23/Medical AI Consensus_ A Multi-Agent Framework for Radiology Report Generation and Evaluation_20250923|Medical AI Consensus: A Multi-Agent Framework for Radiology Report Generation and Evaluation]] (83.6% similar)
- [[2025-09-23/HARE_ an entity and relation centric evaluation framework for histopathology reports_20250923|HARE: an entity and relation centric evaluation framework for histopathology reports]] (82.6% similar)
- [[2025-09-18/Limitations of Public Chest Radiography Datasets for Artificial Intelligence_ Label Quality, Domain Shift, Bias and Evaluation Challenges_20250918|Limitations of Public Chest Radiography Datasets for Artificial Intelligence: Label Quality, Domain Shift, Bias and Evaluation Challenges]] (81.5% similar)
- [[2025-09-19/MedVAL_ Toward Expert-Level Medical Text Validation with Language Models_20250919|MedVAL: Toward Expert-Level Medical Text Validation with Language Models]] (81.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Zero-Shot Learning|Zero-Shot Learning]], [[keywords/Multimodal Learning|Multimodal Learning]]
**âš¡ Unique Technical**: [[keywords/Radiology Text Evaluation|Radiology Text Evaluation]], [[keywords/Clinical Concept-Based Evaluation|Clinical Concept-Based Evaluation]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18030v1 Announce Type: new 
Abstract: We introduce RadEval, a unified, open-source framework for evaluating radiology texts. RadEval consolidates a diverse range of metrics, from classic n-gram overlap (BLEU, ROUGE) and contextual measures (BERTScore) to clinical concept-based scores (F1CheXbert, F1RadGraph, RaTEScore, SRR-BERT, TemporalEntityF1) and advanced LLM-based evaluators (GREEN). We refine and standardize implementations, extend GREEN to support multiple imaging modalities with a more lightweight model, and pretrain a domain-specific radiology encoder, demonstrating strong zero-shot retrieval performance. We also release a richly annotated expert dataset with over 450 clinically significant error labels and show how different metrics correlate with radiologist judgment. Finally, RadEval provides statistical testing tools and baseline model evaluations across multiple publicly available datasets, facilitating reproducibility and robust benchmarking in radiology report generation.

## ğŸ“ ìš”ì•½

RadEvalì€ ë°©ì‚¬ì„ í•™ í…ìŠ¤íŠ¸ í‰ê°€ë¥¼ ìœ„í•œ í†µí•© ì˜¤í”ˆì†ŒìŠ¤ í”„ë ˆì„ì›Œí¬ë¡œ, ë‹¤ì–‘í•œ í‰ê°€ ì§€í‘œë¥¼ í†µí•©í•©ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” BLEU, ROUGE ê°™ì€ ê³ ì „ì  n-ê·¸ë¨ ì¤‘ë³µ ì§€í‘œë¶€í„° BERTScoreì™€ ê°™ì€ ë¬¸ë§¥ì  ì¸¡ì •, F1CheXbert, F1RadGraph ë“± ì„ìƒ ê°œë… ê¸°ë°˜ ì ìˆ˜, ê·¸ë¦¬ê³  GREEN ê°™ì€ ê³ ê¸‰ LLM ê¸°ë°˜ í‰ê°€ìë¥¼ í¬í•¨í•©ë‹ˆë‹¤. RadEvalì€ ë‹¤ì–‘í•œ ì´ë¯¸ì§• ëª¨ë‹¬ë¦¬í‹°ë¥¼ ì§€ì›í•˜ë„ë¡ GREENì„ í™•ì¥í•˜ê³ , ë„ë©”ì¸ íŠ¹í™” ë°©ì‚¬ì„ í•™ ì¸ì½”ë”ë¥¼ ì‚¬ì „ í•™ìŠµí•˜ì—¬ ê°•ë ¥í•œ ì œë¡œìƒ· ê²€ìƒ‰ ì„±ëŠ¥ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, 450ê°œ ì´ìƒì˜ ì„ìƒì ìœ¼ë¡œ ì¤‘ìš”í•œ ì˜¤ë¥˜ ë ˆì´ë¸”ì´ í¬í•¨ëœ ì „ë¬¸ê°€ ì£¼ì„ ë°ì´í„°ì…‹ì„ ê³µê°œí•˜ê³ , ë‹¤ì–‘í•œ ì§€í‘œê°€ ë°©ì‚¬ì„  ì „ë¬¸ì˜ì˜ íŒë‹¨ê³¼ ì–´ë–»ê²Œ ìƒê´€ê´€ê³„ê°€ ìˆëŠ”ì§€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. RadEvalì€ í†µê³„ í…ŒìŠ¤íŠ¸ ë„êµ¬ì™€ ì—¬ëŸ¬ ê³µê°œ ë°ì´í„°ì…‹ì— ëŒ€í•œ ê¸°ì¤€ ëª¨ë¸ í‰ê°€ë¥¼ ì œê³µí•˜ì—¬ ë°©ì‚¬ì„  ë³´ê³ ì„œ ìƒì„±ì˜ ì¬í˜„ì„±ê³¼ ê²¬ê³ í•œ ë²¤ì¹˜ë§ˆí‚¹ì„ ì´‰ì§„í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. RadEvalì€ ë°©ì‚¬ì„ í•™ í…ìŠ¤íŠ¸ í‰ê°€ë¥¼ ìœ„í•œ í†µí•© ì˜¤í”ˆì†ŒìŠ¤ í”„ë ˆì„ì›Œí¬ë¡œ, ë‹¤ì–‘í•œ í‰ê°€ ì§€í‘œë¥¼ í†µí•©í•©ë‹ˆë‹¤.
- 2. RadEvalì€ n-gram ì¤‘ë³µ, ë¬¸ë§¥ì  ì¸¡ì •, ì„ìƒ ê°œë… ê¸°ë°˜ ì ìˆ˜, ê³ ê¸‰ LLM ê¸°ë°˜ í‰ê°€ìë¥¼ í¬í•¨í•œ ë‹¤ì–‘í•œ í‰ê°€ ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤.
- 3. GREENì„ ì—¬ëŸ¬ ì˜ìƒ ëª¨ë‹¬ë¦¬í‹°ë¥¼ ì§€ì›í•˜ë„ë¡ í™•ì¥í•˜ê³ , ë„ë©”ì¸ íŠ¹í™” ë°©ì‚¬ì„ í•™ ì¸ì½”ë”ë¥¼ ì‚¬ì „ í›ˆë ¨í•˜ì—¬ ê°•ë ¥í•œ ì œë¡œìƒ· ê²€ìƒ‰ ì„±ëŠ¥ì„ ì…ì¦í•©ë‹ˆë‹¤.
- 4. 450ê°œ ì´ìƒì˜ ì„ìƒì ìœ¼ë¡œ ì¤‘ìš”í•œ ì˜¤ë¥˜ ë ˆì´ë¸”ì´ í¬í•¨ëœ ì „ë¬¸ê°€ ì£¼ì„ ë°ì´í„°ì…‹ì„ ê³µê°œí•˜ê³ , ë‹¤ì–‘í•œ ì§€í‘œê°€ ë°©ì‚¬ì„  ì „ë¬¸ì˜ì˜ íŒë‹¨ê³¼ ì–´ë–»ê²Œ ìƒê´€ê´€ê³„ê°€ ìˆëŠ”ì§€ ë³´ì—¬ì¤ë‹ˆë‹¤.
- 5. RadEvalì€ í†µê³„ì  í…ŒìŠ¤íŠ¸ ë„êµ¬ì™€ ì—¬ëŸ¬ ê³µê°œ ë°ì´í„°ì…‹ì— ëŒ€í•œ ê¸°ì¤€ ëª¨ë¸ í‰ê°€ë¥¼ ì œê³µí•˜ì—¬ ë°©ì‚¬ì„  ë³´ê³ ì„œ ìƒì„±ì˜ ì¬í˜„ì„±ê³¼ ê²¬ê³ í•œ ë²¤ì¹˜ë§ˆí‚¹ì„ ì´‰ì§„í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 03:36:34*