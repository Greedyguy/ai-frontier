---
keywords:
  - Zero-Shot Learning
  - Multimodal Learning
  - Interactive Retrieval
  - Vision-Language Model
category: cs.CV
publish_date: 2025-09-23
arxiv_id: 2509.16674
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T04:31:09.070064",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Zero-Shot Learning",
    "Multimodal Learning",
    "Interactive Retrieval",
    "Vision-Language Model"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Zero-Shot Learning": 0.85,
    "Multimodal Learning": 0.8,
    "Interactive Retrieval": 0.78,
    "Vision-Language Model": 0.82
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Zero-Shot",
        "canonical": "Zero-Shot Learning",
        "aliases": [
          "Zero-Shot"
        ],
        "category": "specific_connectable",
        "rationale": "Zero-Shot Learning is crucial for understanding the framework's ability to generalize without prior examples, linking it to broader machine learning concepts.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Multimodal",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal"
        ],
        "category": "specific_connectable",
        "rationale": "Multimodal Learning is central to the framework's ability to process and integrate different types of data, enhancing connectivity with related research.",
        "novelty_score": 0.5,
        "connectivity_score": 0.82,
        "specificity_score": 0.68,
        "link_intent_score": 0.8
      },
      {
        "surface": "Interactive Retrieval",
        "canonical": "Interactive Retrieval",
        "aliases": [
          "Interactive Search"
        ],
        "category": "unique_technical",
        "rationale": "Interactive Retrieval is a unique aspect of the framework, emphasizing user engagement and adaptability in search processes.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.75,
        "link_intent_score": 0.78
      },
      {
        "surface": "Vision-Language",
        "canonical": "Vision-Language Model",
        "aliases": [
          "Vision-Language"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-Language Models are integral to the framework's ability to interpret and relate visual and textual data, linking it to advanced AI research.",
        "novelty_score": 0.6,
        "connectivity_score": 0.85,
        "specificity_score": 0.72,
        "link_intent_score": 0.82
      }
    ],
    "ban_list_suggestions": [
      "Text-based Pedestrian Retrieval",
      "Feature Contrastive Decoding",
      "Incremental Semantic Mining",
      "Query-aware Hierarchical Retrieval"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Zero-Shot",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Multimodal",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.82,
        "specificity": 0.68,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Interactive Retrieval",
      "resolved_canonical": "Interactive Retrieval",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.75,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Vision-Language",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.85,
        "specificity": 0.72,
        "link_intent": 0.82
      }
    }
  ]
}
-->

# FitPro: A Zero-Shot Framework for Interactive Text-based Pedestrian Retrieval in Open World

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16674.pdf)
**Category**: cs.CV
**Published**: 2025-09-23
**ArXiv ID**: [2509.16674](https://arxiv.org/abs/2509.16674)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Handle Object Navigation as Weighted Traveling Repairman Problem_20250919|Handle Object Navigation as Weighted Traveling Repairman Problem]] (80.9% similar)
- [[2025-09-23/Optimal Transport for Handwritten Text Recognition in a Low-Resource Regime_20250923|Optimal Transport for Handwritten Text Recognition in a Low-Resource Regime]] (80.8% similar)
- [[2025-09-23/ProReason_ Multi-Modal Proactive Reasoning with Decoupled Eyesight and Wisdom_20250923|ProReason: Multi-Modal Proactive Reasoning with Decoupled Eyesight and Wisdom]] (80.0% similar)
- [[2025-09-22/MMAPG_ A Training-Free Framework for Multimodal Multi-hop Question Answering via Adaptive Planning Graphs_20250922|MMAPG: A Training-Free Framework for Multimodal Multi-hop Question Answering via Adaptive Planning Graphs]] (79.6% similar)
- [[2025-09-23/KRAST_ Knowledge-Augmented Robotic Action Recognition with Structured Text for Vision-Language Models_20250923|KRAST: Knowledge-Augmented Robotic Action Recognition with Structured Text for Vision-Language Models]] (79.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Zero-Shot Learning|Zero-Shot Learning]], [[keywords/Multimodal Learning|Multimodal Learning]]
**âš¡ Unique Technical**: [[keywords/Interactive Retrieval|Interactive Retrieval]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16674v1 Announce Type: new 
Abstract: Text-based Pedestrian Retrieval (TPR) aims to retrieve specific target pedestrians in visual scenes according to natural language descriptions. Although existing methods have achieved progress under constrained settings, interactive retrieval in the open-world scenario still suffers from limited model generalization and insufficient semantic understanding. To address these challenges, we propose FitPro, an open-world interactive zero-shot TPR framework with enhanced semantic comprehension and cross-scene adaptability. FitPro has three innovative components: Feature Contrastive Decoding (FCD), Incremental Semantic Mining (ISM), and Query-aware Hierarchical Retrieval (QHR). The FCD integrates prompt-guided contrastive decoding to generate high-quality structured pedestrian descriptions from denoised images, effectively alleviating semantic drift in zero-shot scenarios. The ISM constructs holistic pedestrian representations from multi-view observations to achieve global semantic modeling in multi-turn interactions,thereby improving robustness against viewpoint shifts and fine-grained variations in descriptions. The QHR dynamically optimizes the retrieval pipeline according to query types, enabling efficient adaptation to multi-modal and multi-view inputs. Extensive experiments on five public datasets and two evaluation protocols demonstrate that FitPro significantly overcomes the generalization limitations and semantic modeling constraints of existing methods in interactive retrieval, paving the way for practical deployment. The code and data will be released at https://github.com/ lilo4096/FitPro-Interactive-Person-Retrieval.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ìì—°ì–´ ì„¤ëª…ì„ ê¸°ë°˜ìœ¼ë¡œ íŠ¹ì • ë³´í–‰ìë¥¼ ì‹œê° ì¥ë©´ì—ì„œ ê²€ìƒ‰í•˜ëŠ” í…ìŠ¤íŠ¸ ê¸°ë°˜ ë³´í–‰ì ê²€ìƒ‰(TPR)ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ FitProë¼ëŠ” í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. FitProëŠ” ê°œë°©í˜• ì„¸ê³„ì—ì„œì˜ ìƒí˜¸ì‘ìš©ì  ì œë¡œìƒ· TPRì„ ëª©í‘œë¡œ í•˜ë©°, í–¥ìƒëœ ì˜ë¯¸ ì´í•´ì™€ ì¥ë©´ ê°„ ì ì‘ì„±ì„ ì œê³µí•©ë‹ˆë‹¤. ì£¼ìš” êµ¬ì„± ìš”ì†Œë¡œëŠ” íŠ¹ì§• ëŒ€ì¡° ë””ì½”ë”©(FCD), ì ì§„ì  ì˜ë¯¸ ì±„êµ´(ISM), ì¿¼ë¦¬ ì¸ì‹ ê³„ì¸µì  ê²€ìƒ‰(QHR)ì´ ìˆìŠµë‹ˆë‹¤. FCDëŠ” í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ëŒ€ì¡° ë””ì½”ë”©ì„ í†µí•´ ê³ í’ˆì§ˆì˜ ë³´í–‰ì ì„¤ëª…ì„ ìƒì„±í•˜ì—¬ ì˜ë¯¸ ë“œë¦¬í”„íŠ¸ë¥¼ ì™„í™”í•©ë‹ˆë‹¤. ISMì€ ë‹¤ì¤‘ ê´€ì°°ì„ í†µí•´ ë³´í–‰ì í‘œí˜„ì„ êµ¬ì¶•í•˜ì—¬ ê²¬ê³ ì„±ì„ ë†’ì…ë‹ˆë‹¤. QHRì€ ì¿¼ë¦¬ ìœ í˜•ì— ë”°ë¼ ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸ì„ ìµœì í™”í•˜ì—¬ ë‹¤ì¤‘ ëª¨ë‹¬ ì…ë ¥ì— íš¨ìœ¨ì ìœ¼ë¡œ ì ì‘í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, FitProëŠ” ê¸°ì¡´ ë°©ë²•ì˜ ì¼ë°˜í™” í•œê³„ì™€ ì˜ë¯¸ ëª¨ë¸ë§ ì œì•½ì„ ê·¹ë³µí•˜ì—¬ ì‹¤ìš©ì  í™œìš© ê°€ëŠ¥ì„±ì„ ì œì‹œí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. FitProëŠ” ìì—°ì–´ ì„¤ëª…ì„ ê¸°ë°˜ìœ¼ë¡œ íŠ¹ì • ë³´í–‰ìë¥¼ ì‹œê°ì  ì¥ë©´ì—ì„œ ê²€ìƒ‰í•˜ëŠ” í…ìŠ¤íŠ¸ ê¸°ë°˜ ë³´í–‰ì ê²€ìƒ‰(TPR)ì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.
- 2. FitProëŠ” ì œë¡œìƒ· ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì˜ë¯¸ì  ë“œë¦¬í”„íŠ¸ë¥¼ ì™„í™”í•˜ê¸° ìœ„í•´ í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ëŒ€ì¡° ë””ì½”ë”©ì„ í†µí•©í•œ ê¸°ëŠ¥ ëŒ€ì¡° ë””ì½”ë”©(FCD)ì„ ë„ì…í•©ë‹ˆë‹¤.
- 3. ì¦ë¶„ì  ì˜ë¯¸ ë§ˆì´ë‹(ISM)ì€ ë‹¤ì¤‘ ê´€ì°°ì„ í†µí•´ ì „ì²´ì ì¸ ë³´í–‰ì í‘œí˜„ì„ êµ¬ì¶•í•˜ì—¬ ë‹¤ì¤‘ í„´ ìƒí˜¸ì‘ìš©ì—ì„œ ì „ì—­ ì˜ë¯¸ ëª¨ë¸ë§ì„ ë‹¬ì„±í•©ë‹ˆë‹¤.
- 4. FitProì˜ ì¿¼ë¦¬ ì¸ì‹ ê³„ì¸µì  ê²€ìƒ‰(QHR)ì€ ì¿¼ë¦¬ ìœ í˜•ì— ë”°ë¼ ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸ì„ ë™ì ìœ¼ë¡œ ìµœì í™”í•˜ì—¬ íš¨ìœ¨ì ì¸ ì ì‘ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
- 5. FitProëŠ” ë‹¤ì„¯ ê°œì˜ ê³µê°œ ë°ì´í„°ì…‹ê³¼ ë‘ ê°œì˜ í‰ê°€ í”„ë¡œí† ì½œì—ì„œ ê¸°ì¡´ ë°©ë²•ì˜ ì¼ë°˜í™” í•œê³„ì™€ ì˜ë¯¸ ëª¨ë¸ë§ ì œì•½ì„ ê·¹ë³µí•˜ëŠ” ë° ì„±ê³µí–ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 04:31:09*