---
keywords:
  - Large Language Model
  - Low-Resource Machine Translation
  - SynOPUS Repository
  - Document-Level Synthetic Corpus
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2505.14423
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:56:22.170860",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Low-Resource Machine Translation",
    "SynOPUS Repository",
    "Document-Level Synthetic Corpus"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Low-Resource Machine Translation": 0.78,
    "SynOPUS Repository": 0.8,
    "Document-Level Synthetic Corpus": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "LLM-generated synthetic data",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "synthetic data from LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Links to existing discussions on the use of Large Language Models in data generation.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "low-resource Machine Translation",
        "canonical": "Low-Resource Machine Translation",
        "aliases": [
          "low-resource MT"
        ],
        "category": "unique_technical",
        "rationale": "Focuses on a niche area within Machine Translation, enhancing connectivity with related research.",
        "novelty_score": 0.65,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "SynOPUS",
        "canonical": "SynOPUS Repository",
        "aliases": [
          "SynOPUS"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a new resource for synthetic parallel datasets, relevant for future dataset discussions.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "document-level synthetic corpus",
        "canonical": "Document-Level Synthetic Corpus",
        "aliases": [
          "synthetic corpus"
        ],
        "category": "specific_connectable",
        "rationale": "Provides a detailed focus on corpus-level data generation, useful for corpus-based studies.",
        "novelty_score": 0.6,
        "connectivity_score": 0.7,
        "specificity_score": 0.75,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "improving",
      "evaluation",
      "training regimes",
      "effect",
      "utility"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "LLM-generated synthetic data",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "low-resource Machine Translation",
      "resolved_canonical": "Low-Resource Machine Translation",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "SynOPUS",
      "resolved_canonical": "SynOPUS Repository",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "document-level synthetic corpus",
      "resolved_canonical": "Document-Level Synthetic Corpus",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.7,
        "specificity": 0.75,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Scaling Low-Resource MT via Synthetic Data Generation with LLMs

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2505.14423.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2505.14423](https://arxiv.org/abs/2505.14423)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages_20250922|A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages]] (88.5% similar)
- [[2025-09-22/SyGra_ A Unified Graph-Based Framework for Scalable Generation, Quality Tagging, and Management of Synthetic Data_20250922|SyGra: A Unified Graph-Based Framework for Scalable Generation, Quality Tagging, and Management of Synthetic Data]] (84.9% similar)
- [[2025-09-22/LiteLong_ Resource-Efficient Long-Context Data Synthesis for LLMs_20250922|LiteLong: Resource-Efficient Long-Context Data Synthesis for LLMs]] (83.3% similar)
- [[2025-09-22/Frustratingly Easy Data Augmentation for Low-Resource ASR_20250922|Frustratingly Easy Data Augmentation for Low-Resource ASR]] (83.1% similar)
- [[2025-09-23/XL-Suite_ Cross-Lingual Synthetic Training and Evaluation Data for Open-Ended Generation_20250923|XL-Suite: Cross-Lingual Synthetic Training and Evaluation Data for Open-Ended Generation]] (83.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Document-Level Synthetic Corpus|Document-Level Synthetic Corpus]]
**âš¡ Unique Technical**: [[keywords/Low-Resource Machine Translation|Low-Resource Machine Translation]], [[keywords/SynOPUS Repository|SynOPUS Repository]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2505.14423v2 Announce Type: replace 
Abstract: We investigate the potential of LLM-generated synthetic data for improving low-resource Machine Translation (MT). Focusing on seven diverse target languages, we construct a document-level synthetic corpus from English Europarl, and extend it via pivoting to 147 additional language pairs. Automatic and human evaluation confirm its overall high quality. We study its practical application by (i) identifying effective training regimes, (ii) comparing our data with the HPLT dataset, (iii) studying the effect of varying training data size, and (iiii) testing its utility beyond English-centric MT. Finally, we introduce SynOPUS, a public repository for synthetic parallel datasets. Our findings show that LLM-generated synthetic data, even when noisy, can substantially improve MT performance for low-resource languages.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ LLMì´ ìƒì„±í•œ í•©ì„± ë°ì´í„°ê°€ ì €ìì› ê¸°ê³„ ë²ˆì—­(MT)ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆëŠ” ê°€ëŠ¥ì„±ì„ ì¡°ì‚¬í•©ë‹ˆë‹¤. ì˜ì–´ Europarlì—ì„œ ë¬¸ì„œ ìˆ˜ì¤€ì˜ í•©ì„± ì½”í¼ìŠ¤ë¥¼ ìƒì„±í•˜ê³ , ì´ë¥¼ í”¼ë²— ê¸°ë²•ì„ í†µí•´ 147ê°œì˜ ì¶”ê°€ ì–¸ì–´ ìŒìœ¼ë¡œ í™•ì¥í–ˆìŠµë‹ˆë‹¤. ìë™ ë° ì¸ê°„ í‰ê°€ë¥¼ í†µí•´ ë°ì´í„°ì˜ ì „ë°˜ì ì¸ ë†’ì€ í’ˆì§ˆì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. íš¨ê³¼ì ì¸ í›ˆë ¨ ë°©ë²• ì‹ë³„, HPLT ë°ì´í„°ì…‹ê³¼ì˜ ë¹„êµ, í›ˆë ¨ ë°ì´í„° í¬ê¸° ë³€í™”ì˜ ì˜í–¥, ì˜ì–´ ì¤‘ì‹¬ì´ ì•„ë‹Œ MTì—ì„œì˜ ìœ ìš©ì„±ì„ í…ŒìŠ¤íŠ¸í–ˆìŠµë‹ˆë‹¤. ìµœì¢…ì ìœ¼ë¡œ í•©ì„± ë³‘ë ¬ ë°ì´í„°ì…‹ì„ ìœ„í•œ ê³µê°œ ì €ì¥ì†Œì¸ SynOPUSë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ì—°êµ¬ ê²°ê³¼, LLMì´ ìƒì„±í•œ í•©ì„± ë°ì´í„°ëŠ” ë…¸ì´ì¦ˆê°€ ìˆë”ë¼ë„ ì €ìì› ì–¸ì–´ì˜ MT ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. LLMì´ ìƒì„±í•œ í•©ì„± ë°ì´í„°ëŠ” ì €ìì› ê¸°ê³„ ë²ˆì—­ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆë‹¤.
- 2. ì˜ì–´ Europarlë¡œë¶€í„° ë¬¸ì„œ ìˆ˜ì¤€ì˜ í•©ì„± ì½”í¼ìŠ¤ë¥¼ êµ¬ì¶•í•˜ê³ , ì´ë¥¼ í”¼ë²—í•˜ì—¬ 147ê°œì˜ ì¶”ê°€ ì–¸ì–´ ìŒìœ¼ë¡œ í™•ì¥í•˜ì˜€ë‹¤.
- 3. ìë™ ë° ì¸ê°„ í‰ê°€ë¥¼ í†µí•´ í•©ì„± ë°ì´í„°ì˜ ì „ë°˜ì ì¸ ë†’ì€ í’ˆì§ˆì„ í™•ì¸í•˜ì˜€ë‹¤.
- 4. ë‹¤ì–‘í•œ í›ˆë ¨ ë°ì´í„° í¬ê¸°ì˜ íš¨ê³¼ë¥¼ ì—°êµ¬í•˜ê³ , ì˜ì–´ ì¤‘ì‹¬ì˜ ê¸°ê³„ ë²ˆì—­ì„ ë„˜ì–´ì„œ í•©ì„± ë°ì´í„°ì˜ ìœ ìš©ì„±ì„ í…ŒìŠ¤íŠ¸í•˜ì˜€ë‹¤.
- 5. SynOPUSë¼ëŠ” í•©ì„± ë³‘ë ¬ ë°ì´í„°ì…‹ì˜ ê³µê°œ ì €ì¥ì†Œë¥¼ ì†Œê°œí•˜ì˜€ë‹¤.


---

*Generated on 2025-09-24 03:56:22*