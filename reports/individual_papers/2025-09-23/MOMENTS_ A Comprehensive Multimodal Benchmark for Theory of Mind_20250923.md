---
keywords:
  - Theory of Mind
  - Multimodal Mental States
  - Multimodal Learning
  - Vision-Language Model
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2507.04415
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T04:06:51.111525",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Theory of Mind",
    "Multimodal Mental States",
    "Multimodal Learning",
    "Vision-Language Model"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Theory of Mind": 0.78,
    "Multimodal Mental States": 0.79,
    "Multimodal Learning": 0.81,
    "Vision-Language Model": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Theory of Mind",
        "canonical": "Theory of Mind",
        "aliases": [
          "ToM"
        ],
        "category": "unique_technical",
        "rationale": "Theory of Mind is a central concept in understanding social intelligence and is crucial for linking multimodal AI research.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Multimodal Mental States",
        "canonical": "Multimodal Mental States",
        "aliases": [
          "MoMentS"
        ],
        "category": "unique_technical",
        "rationale": "This is a specific benchmark introduced in the paper, providing a unique dataset for evaluating Theory of Mind in AI.",
        "novelty_score": 0.82,
        "connectivity_score": 0.65,
        "specificity_score": 0.88,
        "link_intent_score": 0.79
      },
      {
        "surface": "Multimodal",
        "canonical": "Multimodal Learning",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Multimodal learning is essential for integrating various data types, which is a key challenge highlighted in the paper.",
        "novelty_score": 0.55,
        "connectivity_score": 0.87,
        "specificity_score": 0.72,
        "link_intent_score": 0.81
      },
      {
        "surface": "Vision-Language",
        "canonical": "Vision-Language Model",
        "aliases": [],
        "category": "evolved_concepts",
        "rationale": "Vision-language models are crucial for understanding and integrating visual and textual data, as discussed in the paper.",
        "novelty_score": 0.6,
        "connectivity_score": 0.83,
        "specificity_score": 0.78,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "benchmark",
      "performance",
      "questions"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Theory of Mind",
      "resolved_canonical": "Theory of Mind",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Multimodal Mental States",
      "resolved_canonical": "Multimodal Mental States",
      "decision": "linked",
      "scores": {
        "novelty": 0.82,
        "connectivity": 0.65,
        "specificity": 0.88,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Multimodal",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.87,
        "specificity": 0.72,
        "link_intent": 0.81
      }
    },
    {
      "candidate_surface": "Vision-Language",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.83,
        "specificity": 0.78,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# MOMENTS: A Comprehensive Multimodal Benchmark for Theory of Mind

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2507.04415.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2507.04415](https://arxiv.org/abs/2507.04415)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/TactfulToM_ Do LLMs Have the Theory of Mind Ability to Understand White Lies?_20250923|TactfulToM: Do LLMs Have the Theory of Mind Ability to Understand White Lies?]] (85.0% similar)
- [[2025-09-23/AuditoryBench++_ Can Language Models Understand Auditory Knowledge without Hearing?_20250923|AuditoryBench++: Can Language Models Understand Auditory Knowledge without Hearing?]] (84.5% similar)
- [[2025-09-19/OnlineMate_ An LLM-Based Multi-Agent Companion System for Cognitive Support in Online Learning_20250919|OnlineMate: An LLM-Based Multi-Agent Companion System for Cognitive Support in Online Learning]] (84.0% similar)
- [[2025-09-23/Evaluating Multimodal Large Language Models with Daily Composite Tasks in Home Environments_20250923|Evaluating Multimodal Large Language Models with Daily Composite Tasks in Home Environments]] (82.9% similar)
- [[2025-09-22/How Good are Foundation Models in Step-by-Step Embodied Reasoning?_20250922|How Good are Foundation Models in Step-by-Step Embodied Reasoning?]] (82.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**âš¡ Unique Technical**: [[keywords/Theory of Mind|Theory of Mind]], [[keywords/Multimodal Mental States|Multimodal Mental States]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2507.04415v2 Announce Type: replace 
Abstract: Understanding Theory of Mind is essential for building socially intelligent multimodal agents capable of perceiving and interpreting human behavior. We introduce MoMentS (Multimodal Mental States), a comprehensive benchmark designed to assess the ToM capabilities of multimodal large language models (LLMs) through realistic, narrative-rich scenarios presented in short films. MoMentS includes over 2,300 multiple-choice questions spanning seven distinct ToM categories. The benchmark features long video context windows and realistic social interactions that provide deeper insight into characters' mental states. We evaluate several MLLMs and find that although vision generally improves performance, models still struggle to integrate it effectively. For audio, models that process dialogues as audio do not consistently outperform transcript-based inputs. Our findings highlight the need to improve multimodal integration and point to open challenges that must be addressed to advance AI's social understanding.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì‚¬íšŒì ìœ¼ë¡œ ì§€ëŠ¥ì ì¸ ë©€í‹°ëª¨ë‹¬ ì—ì´ì „íŠ¸ë¥¼ êµ¬ì¶•í•˜ê¸° ìœ„í•´ í•„ìˆ˜ì ì¸ ë§ˆìŒ ì´ë¡ (ToM)ì˜ ì´í•´ë¥¼ í‰ê°€í•˜ëŠ” MoMentSë¼ëŠ” ë²¤ì¹˜ë§ˆí¬ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. MoMentSëŠ” ì§§ì€ ì˜í™”ì— ë“±ì¥í•˜ëŠ” í˜„ì‹¤ì ì´ê³  ì„œì‚¬ì ì¸ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ í†µí•´ ë©€í‹°ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì˜ ToM ëŠ¥ë ¥ì„ í‰ê°€í•˜ë©°, 7ê°€ì§€ ToM ë²”ì£¼ì— ê±¸ì³ 2,300ê°œ ì´ìƒì˜ ê°ê´€ì‹ ì§ˆë¬¸ì„ í¬í•¨í•©ë‹ˆë‹¤. ì—°êµ¬ ê²°ê³¼, ì‹œê° ì •ë³´ê°€ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ì§€ë§Œ íš¨ê³¼ì ìœ¼ë¡œ í†µí•©í•˜ëŠ” ë° ì–´ë ¤ì›€ì´ ìˆìœ¼ë©°, ì˜¤ë””ì˜¤ ëŒ€í™”ì˜ ê²½ìš° í…ìŠ¤íŠ¸ ê¸°ë°˜ ì…ë ¥ë³´ë‹¤ ì¼ê´€ëœ ìš°ìœ„ë¥¼ ë³´ì´ì§€ ì•ŠëŠ”ë‹¤ëŠ” ì ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ë©€í‹°ëª¨ë‹¬ í†µí•©ì˜ ê°œì„  í•„ìš”ì„±ê³¼ AIì˜ ì‚¬íšŒì  ì´í•´ë¥¼ ë°œì „ì‹œí‚¤ê¸° ìœ„í•œ ê³¼ì œë¥¼ ê°•ì¡°í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. MoMentSëŠ” ì¸ê°„ í–‰ë™ì„ ì¸ì‹í•˜ê³  í•´ì„í•  ìˆ˜ ìˆëŠ” ì‚¬íšŒì ìœ¼ë¡œ ì§€ëŠ¥ì ì¸ ë©€í‹°ëª¨ë‹¬ ì—ì´ì „íŠ¸ë¥¼ êµ¬ì¶•í•˜ê¸° ìœ„í•œ Theory of Mind í‰ê°€ë¥¼ ìœ„í•œ ë²¤ì¹˜ë§ˆí¬ì…ë‹ˆë‹¤.
- 2. MoMentSëŠ” 7ê°œì˜ ToM ì¹´í…Œê³ ë¦¬ì— ê±¸ì³ 2,300ê°œ ì´ìƒì˜ ê°ê´€ì‹ ì§ˆë¬¸ì„ í¬í•¨í•˜ê³  ìˆìœ¼ë©°, í˜„ì‹¤ì ì¸ ì‚¬íšŒì  ìƒí˜¸ì‘ìš©ì„ í†µí•´ ìºë¦­í„°ì˜ ì •ì‹  ìƒíƒœì— ëŒ€í•œ ê¹Šì€ í†µì°°ì„ ì œê³µí•©ë‹ˆë‹¤.
- 3. ë¹„ì „ ëª¨ë‹¬ë¦¬í‹°ëŠ” ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ì§€ë§Œ, ëª¨ë¸ë“¤ì´ ì´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í†µí•©í•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªê³  ìˆìŠµë‹ˆë‹¤.
- 4. ì˜¤ë””ì˜¤ ëª¨ë‹¬ë¦¬í‹°ì˜ ê²½ìš°, ëŒ€í™”ë¥¼ ì˜¤ë””ì˜¤ë¡œ ì²˜ë¦¬í•˜ëŠ” ëª¨ë¸ì´ í…ìŠ¤íŠ¸ ê¸°ë°˜ ì…ë ¥ë³´ë‹¤ ì¼ê´€ë˜ê²Œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì´ì§€ëŠ” ì•ŠìŠµë‹ˆë‹¤.
- 5. ì—°êµ¬ ê²°ê³¼ëŠ” ë©€í‹°ëª¨ë‹¬ í†µí•©ì˜ ê°œì„  í•„ìš”ì„±ì„ ê°•ì¡°í•˜ë©°, AIì˜ ì‚¬íšŒì  ì´í•´ë¥¼ ë°œì „ì‹œí‚¤ê¸° ìœ„í•´ í•´ê²°í•´ì•¼ í•  ê³¼ì œë¥¼ ì œì‹œí•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 04:06:51*