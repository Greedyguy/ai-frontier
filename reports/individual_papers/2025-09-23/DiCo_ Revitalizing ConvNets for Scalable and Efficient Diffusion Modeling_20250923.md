---
keywords:
  - Diffusion Transformer
  - Neural Network
  - Attention Mechanism
  - Diffusion ConvNet
  - Text-to-Image Generation
category: cs.CV
publish_date: 2025-09-23
arxiv_id: 2505.11196
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T05:22:16.812231",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Diffusion Transformer",
    "Neural Network",
    "Attention Mechanism",
    "Diffusion ConvNet",
    "Text-to-Image Generation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Diffusion Transformer": 0.78,
    "Neural Network": 0.82,
    "Attention Mechanism": 0.8,
    "Diffusion ConvNet": 0.85,
    "Text-to-Image Generation": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Diffusion Transformer",
        "canonical": "Diffusion Transformer",
        "aliases": [
          "DiT"
        ],
        "category": "unique_technical",
        "rationale": "Represents a specific model discussed in the paper, highlighting its importance in diffusion modeling.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Convolutional Neural Network",
        "canonical": "Neural Network",
        "aliases": [
          "ConvNet"
        ],
        "category": "broad_technical",
        "rationale": "ConvNets are revisited as a core component, linking to broader neural network discussions.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.82
      },
      {
        "surface": "Channel Attention Mechanism",
        "canonical": "Attention Mechanism",
        "aliases": [
          "Channel Attention"
        ],
        "category": "specific_connectable",
        "rationale": "Enhances feature diversity, connecting to discussions on attention mechanisms.",
        "novelty_score": 0.6,
        "connectivity_score": 0.85,
        "specificity_score": 0.78,
        "link_intent_score": 0.8
      },
      {
        "surface": "Diffusion ConvNet",
        "canonical": "Diffusion ConvNet",
        "aliases": [
          "DiCo"
        ],
        "category": "unique_technical",
        "rationale": "A novel model proposed in the paper, central to its contributions.",
        "novelty_score": 0.8,
        "connectivity_score": 0.7,
        "specificity_score": 0.88,
        "link_intent_score": 0.85
      },
      {
        "surface": "Text-to-Image Generation",
        "canonical": "Text-to-Image Generation",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Highlights the application potential of the discussed models in multimodal generation tasks.",
        "novelty_score": 0.65,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "performance",
      "method",
      "experiment"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Diffusion Transformer",
      "resolved_canonical": "Diffusion Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Convolutional Neural Network",
      "resolved_canonical": "Neural Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Channel Attention Mechanism",
      "resolved_canonical": "Attention Mechanism",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.85,
        "specificity": 0.78,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Diffusion ConvNet",
      "resolved_canonical": "Diffusion ConvNet",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.7,
        "specificity": 0.88,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Text-to-Image Generation",
      "resolved_canonical": "Text-to-Image Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# DiCo: Revitalizing ConvNets for Scalable and Efficient Diffusion Modeling

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2505.11196.pdf)
**Category**: cs.CV
**Published**: 2025-09-23
**ArXiv ID**: [2505.11196](https://arxiv.org/abs/2505.11196)

## 🔗 유사한 논문
- [[2025-09-23/AlignedGen_ Aligning Style Across Generated Images_20250923|AlignedGen: Aligning Style Across Generated Images]] (85.4% similar)
- [[2025-09-23/Optimizing Inference in Transformer-Based Models_ A Multi-Method Benchmark_20250923|Optimizing Inference in Transformer-Based Models: A Multi-Method Benchmark]] (85.4% similar)
- [[2025-09-17/BWCache_ Accelerating Video Diffusion Transformers through Block-Wise Caching_20250917|BWCache: Accelerating Video Diffusion Transformers through Block-Wise Caching]] (84.0% similar)
- [[2025-09-22/LowDiff_ Efficient Diffusion Sampling with Low-Resolution Condition_20250922|LowDiff: Efficient Diffusion Sampling with Low-Resolution Condition]] (83.7% similar)
- [[2025-09-22/Diffusion-Based Cross-Modal Feature Extraction for Multi-Label Classification_20250922|Diffusion-Based Cross-Modal Feature Extraction for Multi-Label Classification]] (83.5% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Neural Network|Neural Network]]
**🔗 Specific Connectable**: [[keywords/Attention Mechanism|Attention Mechanism]], [[keywords/Text-to-Image Generation|Text-to-Image Generation]]
**⚡ Unique Technical**: [[keywords/Diffusion Transformer|Diffusion Transformer]], [[keywords/Diffusion ConvNet|Diffusion ConvNet]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2505.11196v2 Announce Type: replace 
Abstract: Diffusion Transformer (DiT), a promising diffusion model for visual generation, demonstrates impressive performance but incurs significant computational overhead. Intriguingly, analysis of pre-trained DiT models reveals that global self-attention is often redundant, predominantly capturing local patterns-highlighting the potential for more efficient alternatives. In this paper, we revisit convolution as an alternative building block for constructing efficient and expressive diffusion models. However, naively replacing self-attention with convolution typically results in degraded performance. Our investigations attribute this performance gap to the higher channel redundancy in ConvNets compared to Transformers. To resolve this, we introduce a compact channel attention mechanism that promotes the activation of more diverse channels, thereby enhancing feature diversity. This leads to Diffusion ConvNet (DiCo), a family of diffusion models built entirely from standard ConvNet modules, offering strong generative performance with significant efficiency gains. On class-conditional ImageNet generation benchmarks, DiCo-XL achieves an FID of 2.05 at 256x256 resolution and 2.53 at 512x512, with a 2.7x and 3.1x speedup over DiT-XL/2, respectively. Furthermore, experimental results on MS-COCO demonstrate that the purely convolutional DiCo exhibits strong potential for text-to-image generation. Code: https://github.com/shallowdream204/DiCo.

## 📝 요약

Diffusion Transformer (DiT)는 뛰어난 성능의 시각 생성 모델이지만, 높은 계산 비용이 문제입니다. 연구 결과, DiT의 글로벌 셀프 어텐션은 주로 지역 패턴을 포착하는 데 불필요하며, 더 효율적인 대안이 가능함을 시사합니다. 본 논문에서는 효율적이고 표현력 있는 확산 모델을 구축하기 위해 컨볼루션을 대안으로 재검토합니다. 셀프 어텐션을 컨볼루션으로 단순히 대체하면 성능 저하가 발생하는데, 이는 ConvNet의 채널 중복도가 Transformer보다 높기 때문입니다. 이를 해결하기 위해 다양한 채널의 활성화를 촉진하는 컴팩트 채널 어텐션 메커니즘을 도입하여 기능 다양성을 높였습니다. 결과적으로, 표준 ConvNet 모듈로만 구성된 Diffusion ConvNet (DiCo) 모델을 제안하며, 이는 효율성을 크게 향상시키면서도 강력한 생성 성능을 제공합니다. ImageNet 생성 벤치마크에서 DiCo-XL은 256x256 해상도에서 FID 2.05, 512x512 해상도에서 2.53을 기록하며, DiT-XL/2 대비 각각 2.7배, 3.1배의 속도 향상을 보였습니다. MS-COCO 실험 결과, 순수 컨볼루션 기반 DiCo는 텍스트-이미지 생성에서도 강력한 잠재력을 보였습니다.

## 🎯 주요 포인트

- 1. DiT 모델의 글로벌 셀프 어텐션은 종종 불필요하며, 주로 지역 패턴을 포착하는 데 집중되어 있음.
- 2. 셀프 어텐션을 컨볼루션으로 대체하면 성능 저하가 발생하며, 이는 ConvNet의 채널 중복성이 원인임.
- 3. 다양한 채널 활성화를 촉진하는 컴팩트 채널 어텐션 메커니즘을 도입하여 성능 격차를 해소함.
- 4. DiCo 모델은 표준 ConvNet 모듈로만 구성되어 효율성을 크게 향상시키면서도 강력한 생성 성능을 제공함.
- 5. DiCo-XL은 ImageNet 및 MS-COCO 벤치마크에서 DiT-XL/2 대비 최대 3.1배의 속도 향상을 보이며, 우수한 이미지 생성 성능을 입증함.


---

*Generated on 2025-09-24 05:22:16*