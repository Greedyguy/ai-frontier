---
keywords:
  - Phoneme-Aware Speech Encoder
  - Phoneme-Viseme Alignment
  - Self-supervised Learning
  - NeRF
  - 3DGS
category: cs.CV
publish_date: 2025-09-23
arxiv_id: 2504.05803
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T05:34:43.842973",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Phoneme-Aware Speech Encoder",
    "Phoneme-Viseme Alignment",
    "Self-supervised Learning",
    "NeRF",
    "3DGS"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Phoneme-Aware Speech Encoder": 0.82,
    "Phoneme-Viseme Alignment": 0.8,
    "Self-supervised Learning": 0.78,
    "NeRF": 0.77,
    "3DGS": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Phoneme-Aware Speech Encoder",
        "canonical": "Phoneme-Aware Speech Encoder",
        "aliases": [
          "PASE"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel approach to improve phoneme-viseme alignment, crucial for talking head synthesis.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.88,
        "link_intent_score": 0.82
      },
      {
        "surface": "Phoneme-Viseme Alignment",
        "canonical": "Phoneme-Viseme Alignment",
        "aliases": [
          "Phoneme-Viseme Correspondence"
        ],
        "category": "unique_technical",
        "rationale": "Central to the paper's contribution, addressing ambiguity in speech-driven synthesis.",
        "novelty_score": 0.78,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Contrastive Learning",
        "canonical": "Self-supervised Learning",
        "aliases": [
          "Contrastive Learning"
        ],
        "category": "specific_connectable",
        "rationale": "Enhances alignment by leveraging discriminative learning techniques.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.78
      },
      {
        "surface": "NeRF",
        "canonical": "NeRF",
        "aliases": [
          "Neural Radiance Fields"
        ],
        "category": "specific_connectable",
        "rationale": "Relevant for discussing state-of-the-art rendering models in the context of the paper.",
        "novelty_score": 0.65,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      },
      {
        "surface": "3DGS",
        "canonical": "3DGS",
        "aliases": [
          "3D Geometry Synthesis"
        ],
        "category": "unique_technical",
        "rationale": "Highlights the specific rendering model used to demonstrate the encoder's effectiveness.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.78,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "general acoustic features",
      "ground truth videos"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Phoneme-Aware Speech Encoder",
      "resolved_canonical": "Phoneme-Aware Speech Encoder",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.88,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Phoneme-Viseme Alignment",
      "resolved_canonical": "Phoneme-Viseme Alignment",
      "decision": "linked",
      "scores": {
        "novelty": 0.78,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Contrastive Learning",
      "resolved_canonical": "Self-supervised Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "NeRF",
      "resolved_canonical": "NeRF",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "3DGS",
      "resolved_canonical": "3DGS",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.78,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Revisiting Speech-Lip Alignment: A Phoneme-Aware Speech Encoder for Robust Talking Head Synthesis

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2504.05803.pdf)
**Category**: cs.CV
**Published**: 2025-09-23
**ArXiv ID**: [2504.05803](https://arxiv.org/abs/2504.05803)

## 🔗 유사한 논문
- [[2025-09-22/P2VA_ Converting Persona Descriptions into Voice Attributes for Fair and Controllable Text-to-Speech_20250922|P2VA: Converting Persona Descriptions into Voice Attributes for Fair and Controllable Text-to-Speech]] (83.4% similar)
- [[2025-09-22/GLip_ A Global-Local Integrated Progressive Framework for Robust Visual Speech Recognition_20250922|GLip: A Global-Local Integrated Progressive Framework for Robust Visual Speech Recognition]] (83.3% similar)
- [[2025-09-22/AS-ASR_ A Lightweight Framework for Aphasia-Specific Automatic Speech Recognition_20250922|AS-ASR: A Lightweight Framework for Aphasia-Specific Automatic Speech Recognition]] (83.3% similar)
- [[2025-09-19/Hybrid Autoregressive-Diffusion Model for Real-Time Sign Language Production_20250919|Hybrid Autoregressive-Diffusion Model for Real-Time Sign Language Production]] (83.2% similar)
- [[2025-09-23/PGSTalker_ Real-Time Audio-Driven Talking Head Generation via 3D Gaussian Splatting with Pixel-Aware Density Control_20250923|PGSTalker: Real-Time Audio-Driven Talking Head Generation via 3D Gaussian Splatting with Pixel-Aware Density Control]] (83.1% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Self-supervised Learning|Self-supervised Learning]], [[keywords/NeRF|NeRF]]
**⚡ Unique Technical**: [[keywords/Phoneme-Aware Speech Encoder|Phoneme-Aware Speech Encoder]], [[keywords/Phoneme-Viseme Alignment|Phoneme-Viseme Alignment]], [[keywords/3DGS|3DGS]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2504.05803v2 Announce Type: replace-cross 
Abstract: Speech-driven talking head synthesis tasks commonly use general acoustic features as guided speech features. However, we discovered that these features suffer from phoneme-viseme alignment ambiguity, which refers to the uncertainty and imprecision in matching phonemes with visemes. To overcome this limitation, we propose a phoneme-aware speech encoder (PASE) that explicitly enforces accurate phoneme-viseme correspondence. PASE first captures fine-grained speech and visual features, then introduces a prediction-reconstruction task to improve robustness under noise and modality absence. Furthermore, a phoneme-level alignment module guided by phoneme embeddings and contrastive learning ensures discriminative audio and visual alignment. Experimental results show that PASE achieves state-of-the-art performance in both NeRF and 3DGS rendering models. Its lip sync accuracy improves by 13.7% and 14.2% compared to the acoustic feature, producing results close to the ground truth videos.

## 📝 요약

이 논문은 음성 기반의 말하는 얼굴 합성에서 발생하는 음소-비젬 정렬 모호성을 해결하기 위해 음소 인식 음성 인코더(PASE)를 제안합니다. PASE는 세밀한 음성 및 시각적 특징을 포착하고, 예측-재구성 작업을 통해 잡음 및 모달리티 부재 상황에서도 강건성을 향상시킵니다. 또한, 음소 임베딩과 대조 학습을 활용한 음소 수준 정렬 모듈을 도입하여 차별적인 음성 및 시각 정렬을 보장합니다. 실험 결과, PASE는 NeRF 및 3DGS 렌더링 모델에서 최첨단 성능을 달성했으며, 입술 동기화 정확도가 기존 음향 특징 대비 각각 13.7% 및 14.2% 향상되어 실제 영상에 가까운 결과를 제공합니다.

## 🎯 주요 포인트

- 1. 일반적인 음성 특징을 사용하는 기존 방법의 한계를 극복하기 위해, 정확한 음소-비셈 대응을 강제하는 음소 인식 음성 인코더(PASE)를 제안합니다.
- 2. PASE는 세밀한 음성 및 시각적 특징을 포착하고, 예측-재구성 작업을 도입하여 잡음 및 모달리티 부재 상황에서의 강인성을 향상시킵니다.
- 3. 음소 임베딩과 대조 학습을 활용한 음소 수준 정렬 모듈은 차별적인 오디오 및 비주얼 정렬을 보장합니다.
- 4. 실험 결과, PASE는 NeRF 및 3DGS 렌더링 모델에서 최첨단 성능을 달성하며, 입술 동기화 정확도가 기존 음향 특징 대비 각각 13.7% 및 14.2% 향상되었습니다.
- 5. PASE는 실제 비디오에 가까운 결과를 생성합니다.


---

*Generated on 2025-09-24 05:34:43*