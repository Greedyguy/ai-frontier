---
keywords:
  - Object Hallucination
  - Vision-Language Model
  - GLSim
  - Multimodal Learning
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2508.19972
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T01:23:07.528746",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Object Hallucination",
    "Vision-Language Model",
    "GLSim",
    "Multimodal Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Object Hallucination": 0.8,
    "Vision-Language Model": 0.85,
    "GLSim": 0.78,
    "Multimodal Learning": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Object Hallucination",
        "canonical": "Object Hallucination",
        "aliases": [
          "Object-level Hallucination"
        ],
        "category": "unique_technical",
        "rationale": "It is a specific challenge addressed by the paper, crucial for linking discussions on model reliability.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "Vision-Language Models",
        "canonical": "Vision-Language Model",
        "aliases": [
          "LVLMs"
        ],
        "category": "evolved_concepts",
        "rationale": "Central to the paper's focus, linking advancements in multimodal AI research.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.75,
        "link_intent_score": 0.85
      },
      {
        "surface": "GLSim",
        "canonical": "GLSim",
        "aliases": [
          "Global-Local Similarity"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel framework specific to the paper, enhancing discussions on detection methods.",
        "novelty_score": 0.9,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Multimodal",
        "canonical": "Multimodal Learning",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Relevant for linking to broader discussions on integrating multiple data modalities.",
        "novelty_score": 0.5,
        "connectivity_score": 0.82,
        "specificity_score": 0.7,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Object Hallucination",
      "resolved_canonical": "Object Hallucination",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Vision-Language Models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.75,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "GLSim",
      "resolved_canonical": "GLSim",
      "decision": "linked",
      "scores": {
        "novelty": 0.9,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Multimodal",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.82,
        "specificity": 0.7,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# GLSim: Detecting Object Hallucinations in LVLMs via Global-Local Similarity

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2508.19972.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2508.19972](https://arxiv.org/abs/2508.19972)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Mitigating Hallucinations in Large Vision-Language Models via Entity-Centric Multimodal Preference Optimization_20250923|Mitigating Hallucinations in Large Vision-Language Models via Entity-Centric Multimodal Preference Optimization]] (84.9% similar)
- [[2025-09-22/ORIC_ Benchmarking Object Recognition in Incongruous Context for Large Vision-Language Models_20250922|ORIC: Benchmarking Object Recognition in Incongruous Context for Large Vision-Language Models]] (84.4% similar)
- [[2025-09-22/ORCA_ Agentic Reasoning For Hallucination and Adversarial Robustness in Vision-Language Models_20250922|ORCA: Agentic Reasoning For Hallucination and Adversarial Robustness in Vision-Language Models]] (83.9% similar)
- [[2025-09-17/DSCC-HS_ A Dynamic Self-Reinforcing Framework for Hallucination Suppression in Large Language Models_20250917|DSCC-HS: A Dynamic Self-Reinforcing Framework for Hallucination Suppression in Large Language Models]] (82.7% similar)
- [[2025-09-23/ChartHal_ A Fine-grained Framework Evaluating Hallucination of Large Vision Language Models in Chart Understanding_20250923|ChartHal: A Fine-grained Framework Evaluating Hallucination of Large Vision Language Models in Chart Understanding]] (81.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**âš¡ Unique Technical**: [[keywords/Object Hallucination|Object Hallucination]], [[keywords/GLSim|GLSim]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2508.19972v2 Announce Type: replace-cross 
Abstract: Object hallucination in large vision-language models presents a significant challenge to their safe deployment in real-world applications. Recent works have proposed object-level hallucination scores to estimate the likelihood of object hallucination; however, these methods typically adopt either a global or local perspective in isolation, which may limit detection reliability. In this paper, we introduce GLSim, a novel training-free object hallucination detection framework that leverages complementary global and local embedding similarity signals between image and text modalities, enabling more accurate and reliable hallucination detection in diverse scenarios. We comprehensively benchmark existing object hallucination detection methods and demonstrate that GLSim achieves superior detection performance, outperforming competitive baselines by a significant margin.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€ê·œëª¨ ì‹œê°-ì–¸ì–´ ëª¨ë¸ì—ì„œ ë°œìƒí•˜ëŠ” ê°ì²´ í™˜ê° ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ì ‘ê·¼ë²•ì¸ GLSimì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ê°ì²´ í™˜ê° ì ìˆ˜ëŠ” ì£¼ë¡œ ì „ì—­ì  ë˜ëŠ” êµ­ì†Œì  ê´€ì  ì¤‘ í•˜ë‚˜ë§Œì„ ì‚¬ìš©í•˜ì—¬ í™˜ê°ì„ ê°ì§€í•˜ëŠ” ë° í•œê³„ê°€ ìˆì—ˆìŠµë‹ˆë‹¤. GLSimì€ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ê°„ì˜ ì „ì—­ ë° êµ­ì†Œ ì„ë² ë”© ìœ ì‚¬ì„±ì„ í™œìš©í•˜ì—¬ ë³´ë‹¤ ì •í™•í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” í™˜ê° ê°ì§€ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ GLSimì˜ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ì…ì¦í•˜ë©°, ê¸°ì¡´ ë°©ë²•ë“¤ë³´ë‹¤ ë›°ì–´ë‚œ í™˜ê° ê°ì§€ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€ê·œëª¨ ë¹„ì „-ì–¸ì–´ ëª¨ë¸ì—ì„œ ê°ì²´ í™˜ê° ë¬¸ì œëŠ” ì‹¤ì œ ì‘ìš©ì—ì„œì˜ ì•ˆì „í•œ ë°°í¬ì— ì¤‘ìš”í•œ ë„ì „ ê³¼ì œì…ë‹ˆë‹¤.
- 2. ê¸°ì¡´ ì—°êµ¬ë“¤ì€ ê°ì²´ í™˜ê° ê°€ëŠ¥ì„±ì„ ì¶”ì •í•˜ê¸° ìœ„í•´ ê°ì²´ ìˆ˜ì¤€ì˜ í™˜ê° ì ìˆ˜ë¥¼ ì œì•ˆí–ˆìœ¼ë‚˜, ì£¼ë¡œ ì „ì—­ ë˜ëŠ” êµ­ë¶€ì  ê´€ì ì„ ë‹¨ë…ìœ¼ë¡œ ì±„íƒí•˜ì—¬ íƒì§€ ì‹ ë¢°ì„±ì„ ì œí•œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- 3. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ëª¨ë‹¬ë¦¬í‹° ê°„ì˜ ì „ì—­ ë° êµ­ë¶€ ì„ë² ë”© ìœ ì‚¬ì„± ì‹ í˜¸ë¥¼ í™œìš©í•˜ì—¬ ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ë” ì •í™•í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” í™˜ê° íƒì§€ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” GLSimì´ë¼ëŠ” ìƒˆë¡œìš´ í›ˆë ¨ ë¶ˆí•„ìš” ê°ì²´ í™˜ê° íƒì§€ í”„ë ˆì„ì›Œí¬ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤.
- 4. ê¸°ì¡´ ê°ì²´ í™˜ê° íƒì§€ ë°©ë²•ì„ ì¢…í•©ì ìœ¼ë¡œ ë²¤ì¹˜ë§ˆí‚¹í•œ ê²°ê³¼, GLSimì´ ê²½ìŸì ì¸ ê¸°ì¤€ì„ ì„ ìƒë‹¹í•œ ì°¨ì´ë¡œ ëŠ¥ê°€í•˜ëŠ” ìš°ìˆ˜í•œ íƒì§€ ì„±ëŠ¥ì„ ë‹¬ì„±í•¨ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 01:23:07*