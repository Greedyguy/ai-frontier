---
keywords:
  - Multimodal Learning
  - Attention Mechanism
  - Self-supervised Learning
  - Vocal Tract Segmentation
category: cs.CV
publish_date: 2025-09-23
arxiv_id: 2509.13767
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T05:32:00.193901",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multimodal Learning",
    "Attention Mechanism",
    "Self-supervised Learning",
    "Vocal Tract Segmentation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multimodal Learning": 0.85,
    "Attention Mechanism": 0.82,
    "Self-supervised Learning": 0.79,
    "Vocal Tract Segmentation": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multimodal framework",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal integration"
        ],
        "category": "specific_connectable",
        "rationale": "Links to recent advancements in integrating multiple data types for enhanced learning.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Cross-attention fusion",
        "canonical": "Attention Mechanism",
        "aliases": [
          "Cross-attention"
        ],
        "category": "specific_connectable",
        "rationale": "Connects to attention-based models which are central to modern neural network architectures.",
        "novelty_score": 0.6,
        "connectivity_score": 0.9,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "Contrastive learning objective",
        "canonical": "Self-supervised Learning",
        "aliases": [
          "Contrastive learning"
        ],
        "category": "specific_connectable",
        "rationale": "Highlights a key technique in self-supervised learning that enhances model robustness.",
        "novelty_score": 0.65,
        "connectivity_score": 0.85,
        "specificity_score": 0.8,
        "link_intent_score": 0.79
      },
      {
        "surface": "Vocal tract segmentation",
        "canonical": "Vocal Tract Segmentation",
        "aliases": [
          "Articulatory structure segmentation"
        ],
        "category": "unique_technical",
        "rationale": "Specific to the domain of speech and MRI analysis, offering unique insights.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.9,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "experiment"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multimodal framework",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Cross-attention fusion",
      "resolved_canonical": "Attention Mechanism",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.9,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Contrastive learning objective",
      "resolved_canonical": "Self-supervised Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.85,
        "specificity": 0.8,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Vocal tract segmentation",
      "resolved_canonical": "Vocal Tract Segmentation",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.9,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# VocSegMRI: Multimodal Learning for Precise Vocal Tract Segmentation in Real-time MRI

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.13767.pdf)
**Category**: cs.CV
**Published**: 2025-09-23
**ArXiv ID**: [2509.13767](https://arxiv.org/abs/2509.13767)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/UniMRSeg_ Unified Modality-Relax Segmentation via Hierarchical Self-Supervised Compensation_20250922|UniMRSeg: Unified Modality-Relax Segmentation via Hierarchical Self-Supervised Compensation]] (86.2% similar)
- [[2025-09-23/Multimodal Medical Image Classification via Synergistic Learning Pre-training_20250923|Multimodal Medical Image Classification via Synergistic Learning Pre-training]] (84.8% similar)
- [[2025-09-23/Unified Multimodal Coherent Field_ Synchronous Semantic-Spatial-Vision Fusion for Brain Tumor Segmentation_20250923|Unified Multimodal Coherent Field: Synchronous Semantic-Spatial-Vision Fusion for Brain Tumor Segmentation]] (82.8% similar)
- [[2025-09-22/SLaM-DiMM_ Shared Latent Modeling for Diffusion Based Missing Modality Synthesis in MRI_20250922|SLaM-DiMM: Shared Latent Modeling for Diffusion Based Missing Modality Synthesis in MRI]] (82.7% similar)
- [[2025-09-22/Enhancing Sa2VA for Referent Video Object Segmentation_ 2nd Solution for 7th LSVOS RVOS Track_20250922|Enhancing Sa2VA for Referent Video Object Segmentation: 2nd Solution for 7th LSVOS RVOS Track]] (82.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]], [[keywords/Attention Mechanism|Attention Mechanism]], [[keywords/Self-supervised Learning|Self-supervised Learning]]
**âš¡ Unique Technical**: [[keywords/Vocal Tract Segmentation|Vocal Tract Segmentation]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.13767v2 Announce Type: replace 
Abstract: Accurately segmenting articulatory structures in real-time magnetic resonance imaging (rtMRI) remains challenging, as most existing methods rely almost entirely on visual cues. Yet synchronized acoustic and phonological signals provide complementary context that can enrich visual information and improve precision. In this paper, we introduce VocSegMRI, a multimodal framework that integrates video, audio, and phonological inputs through cross-attention fusion for dynamic feature alignment. To further enhance cross-modal representation, we incorporate a contrastive learning objective that improves segmentation performance even when the audio modality is unavailable at inference. Evaluated on a sub-set of USC-75 rtMRI dataset, our approach achieves state-of-the-art performance, with a Dice score of 0.95 and a 95th percentile Hausdorff Distance (HD_95) of 4.20 mm, outperforming both unimodal and multimodal baselines. Ablation studies confirm the contributions of cross-attention and contrastive learning to segmentation precision and robustness. These results highlight the value of integrative multimodal modeling for accurate vocal tract analysis.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì—ì„œëŠ” ì‹¤ì‹œê°„ ìê¸°ê³µëª…ì˜ìƒ(rtMRI)ì—ì„œ ì¡°ìŒ êµ¬ì¡°ë¥¼ ì •í™•íˆ ë¶„í• í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ë‹¤ì¤‘ ëª¨ë‹¬ í”„ë ˆì„ì›Œí¬ì¸ VocSegMRIë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ë¹„ë””ì˜¤, ì˜¤ë””ì˜¤, ìŒìš´ ì…ë ¥ì„ êµì°¨ ì£¼ì˜ ìœµí•©ì„ í†µí•´ í†µí•©í•˜ì—¬ ë™ì  íŠ¹ì§• ì •ë ¬ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ë˜í•œ, ëŒ€ì¡° í•™ìŠµ ëª©í‘œë¥¼ ë„ì…í•˜ì—¬ ì˜¤ë””ì˜¤ ëª¨ë‹¬ë¦¬í‹°ê°€ ì—†ëŠ” ê²½ìš°ì—ë„ ë¶„í•  ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. USC-75 rtMRI ë°ì´í„°ì…‹ì˜ ì¼ë¶€ë¥¼ ì‚¬ìš©í•œ í‰ê°€ì—ì„œ Dice ì ìˆ˜ 0.95ì™€ 95ë²ˆì§¸ ë°±ë¶„ìœ„ìˆ˜ í•˜ìš°ìŠ¤ë„ë¥´í”„ ê±°ë¦¬(HD_95) 4.20 mmë¥¼ ê¸°ë¡í•˜ë©° ê¸°ì¡´ ë°©ë²•ë“¤ì„ ëŠ¥ê°€í–ˆìŠµë‹ˆë‹¤. ì—°êµ¬ ê²°ê³¼ëŠ” êµì°¨ ì£¼ì˜ì™€ ëŒ€ì¡° í•™ìŠµì´ ë¶„í• ì˜ ì •ë°€ì„±ê³¼ ê²¬ê³ ì„±ì— ê¸°ì—¬í•¨ì„ í™•ì¸í•˜ë©°, ì •í™•í•œ ì„±ëŒ€ ë¶„ì„ì„ ìœ„í•œ í†µí•©ì  ë‹¤ì¤‘ ëª¨ë‹¬ ëª¨ë¸ë§ì˜ ê°€ì¹˜ë¥¼ ê°•ì¡°í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. VocSegMRIëŠ” ë¹„ë””ì˜¤, ì˜¤ë””ì˜¤, ìŒìš´ ì…ë ¥ì„ í†µí•©í•˜ì—¬ êµì°¨ ì£¼ì˜ ìœµí•©ì„ í†µí•´ ë™ì  íŠ¹ì§• ì •ë ¬ì„ ìˆ˜í–‰í•˜ëŠ” ë‹¤ì¤‘ ëª¨ë‹¬ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.
- 2. ëŒ€ì¡° í•™ìŠµ ëª©í‘œë¥¼ ë„ì…í•˜ì—¬ ì˜¤ë””ì˜¤ ëª¨ë‹¬ë¦¬í‹°ê°€ ë¶ˆê°€ëŠ¥í•œ ê²½ìš°ì—ë„ ë¶„í•  ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
- 3. USC-75 rtMRI ë°ì´í„°ì…‹ì˜ í•˜ìœ„ ì§‘í•©ì—ì„œ í‰ê°€í•œ ê²°ê³¼, Dice ì ìˆ˜ 0.95ì™€ HD_95 4.20 mmë¡œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.
- 4. êµì°¨ ì£¼ì˜ì™€ ëŒ€ì¡° í•™ìŠµì´ ë¶„í•  ì •ë°€ë„ì™€ ê°•ê±´ì„±ì— ê¸°ì—¬í•¨ì„ ì…ì¦í•˜ëŠ” ì†Œê±° ì—°êµ¬ê°€ ìˆ˜í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.
- 5. í†µí•©ì  ë‹¤ì¤‘ ëª¨ë‹¬ ëª¨ë¸ë§ì´ ì •í™•í•œ ë°œì„± ê¸°ê´€ ë¶„ì„ì— ê°€ì¹˜ê°€ ìˆìŒì„ ê°•ì¡°í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 05:32:00*