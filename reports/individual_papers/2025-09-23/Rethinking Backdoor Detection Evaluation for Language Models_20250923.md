---
keywords:
  - Backdoor Attack
  - Large Language Model
  - Backdoor Detection
  - Trigger Inversion
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2409.00399
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:44:08.131727",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Backdoor Attack",
    "Large Language Model",
    "Backdoor Detection",
    "Trigger Inversion"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Backdoor Attack": 0.9,
    "Large Language Model": 0.85,
    "Backdoor Detection": 0.88,
    "Trigger Inversion": 0.82
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Backdoor Attacks",
        "canonical": "Backdoor Attack",
        "aliases": [
          "Backdoor Insertion",
          "Malicious Trigger"
        ],
        "category": "unique_technical",
        "rationale": "This term is central to the paper's focus on security risks in language models and is not commonly found in the existing vocabulary.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.88,
        "link_intent_score": 0.9
      },
      {
        "surface": "Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Language Model"
        ],
        "category": "broad_technical",
        "rationale": "This is a foundational concept in the paper, linking it to broader discussions on language models.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Backdoor Detection",
        "canonical": "Backdoor Detection",
        "aliases": [
          "Backdoor Identification",
          "Malicious Trigger Detection"
        ],
        "category": "unique_technical",
        "rationale": "The paper evaluates the effectiveness of detection methods, making this a key technical term.",
        "novelty_score": 0.75,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.88
      },
      {
        "surface": "Trigger Inversion",
        "canonical": "Trigger Inversion",
        "aliases": [
          "Reverse Trigger",
          "Inversion Method"
        ],
        "category": "specific_connectable",
        "rationale": "This method is specifically discussed as a technique for detecting backdoors, providing a connection point for related research.",
        "novelty_score": 0.65,
        "connectivity_score": 0.78,
        "specificity_score": 0.8,
        "link_intent_score": 0.82
      }
    ],
    "ban_list_suggestions": [
      "model",
      "method",
      "benchmark"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Backdoor Attacks",
      "resolved_canonical": "Backdoor Attack",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.88,
        "link_intent": 0.9
      }
    },
    {
      "candidate_surface": "Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Backdoor Detection",
      "resolved_canonical": "Backdoor Detection",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "Trigger Inversion",
      "resolved_canonical": "Trigger Inversion",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.78,
        "specificity": 0.8,
        "link_intent": 0.82
      }
    }
  ]
}
-->

# Rethinking Backdoor Detection Evaluation for Language Models

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2409.00399.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2409.00399](https://arxiv.org/abs/2409.00399)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Backdoor Mitigation via Invertible Pruning Masks_20250922|Backdoor Mitigation via Invertible Pruning Masks]] (88.9% similar)
- [[2025-09-23/Jailbreak-Tuning_ Models Efficiently Learn Jailbreak Susceptibility_20250923|Jailbreak-Tuning: Models Efficiently Learn Jailbreak Susceptibility]] (85.5% similar)
- [[2025-09-23/Test-Time Multimodal Backdoor Detection by Contrastive Prompting_20250923|Test-Time Multimodal Backdoor Detection by Contrastive Prompting]] (85.3% similar)
- [[2025-09-22/Inverting Trojans in LLMs_20250922|Inverting Trojans in LLMs]] (85.2% similar)
- [[2025-09-22/Activation Space Interventions Can Be Transferred Between Large Language Models_20250922|Activation Space Interventions Can Be Transferred Between Large Language Models]] (84.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Trigger Inversion|Trigger Inversion]]
**âš¡ Unique Technical**: [[keywords/Backdoor Attack|Backdoor Attack]], [[keywords/Backdoor Detection|Backdoor Detection]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2409.00399v2 Announce Type: replace 
Abstract: Backdoor attacks, in which a model behaves maliciously when given an attacker-specified trigger, pose a major security risk for practitioners who depend on publicly released language models. As a countermeasure, backdoor detection methods aim to detect whether a released model contains a backdoor. While existing backdoor detection methods have high accuracy in detecting backdoored models on standard benchmarks, it is unclear whether they can robustly identify backdoors in the wild. In this paper, we examine the robustness of backdoor detectors by manipulating different factors during backdoor planting. We find that the success of existing methods based on trigger inversion or meta classifiers highly depends on how intensely the model is trained on poisoned data. Specifically, backdoors planted with more aggressive or more conservative training are significantly more difficult to detect than the default ones. Our results highlight a lack of robustness of existing backdoor detectors and the limitations in current benchmark construction.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ê³µê°œëœ ì–¸ì–´ ëª¨ë¸ì— ëŒ€í•œ ë°±ë„ì–´ ê³µê²©ì˜ ìœ„í—˜ì„±ì„ ë‹¤ë£¨ë©°, ë°±ë„ì–´ íƒì§€ ë°©ë²•ì˜ ê²¬ê³ ì„±ì„ í‰ê°€í•©ë‹ˆë‹¤. ê¸°ì¡´ íƒì§€ ë°©ë²•ì€ í‘œì¤€ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë†’ì€ ì •í™•ë„ë¥¼ ë³´ì´ì§€ë§Œ, ì‹¤ì œ í™˜ê²½ì—ì„œì˜ ê²¬ê³ ì„±ì€ ë¶ˆí™•ì‹¤í•©ë‹ˆë‹¤. ì—°êµ¬ ê²°ê³¼, íŠ¸ë¦¬ê±° ë°˜ì „ì´ë‚˜ ë©”íƒ€ ë¶„ë¥˜ê¸°ì— ê¸°ë°˜í•œ ê¸°ì¡´ ë°©ë²•ì˜ ì„±ê³µ ì—¬ë¶€ëŠ” ëª¨ë¸ì´ ì˜¤ì—¼ëœ ë°ì´í„°ë¡œ ì–¼ë§ˆë‚˜ ê°•í•˜ê²Œ í›ˆë ¨ë˜ì—ˆëŠ”ì§€ì— í¬ê²Œ ì¢Œìš°ë©ë‹ˆë‹¤. íŠ¹íˆ, ë” ê³µê²©ì ì´ê±°ë‚˜ ë³´ìˆ˜ì ìœ¼ë¡œ í›ˆë ¨ëœ ë°±ë„ì–´ëŠ” íƒì§€ê°€ ì–´ë µìŠµë‹ˆë‹¤. ì´ëŠ” í˜„ì¬ ë°±ë„ì–´ íƒì§€ê¸°ì˜ ê²¬ê³ ì„± ë¶€ì¡±ê³¼ ë²¤ì¹˜ë§ˆí¬ êµ¬ì„±ì˜ í•œê³„ë¥¼ ê°•ì¡°í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë°±ë„ì–´ ê³µê²©ì€ ê³µê²©ìê°€ ì§€ì •í•œ íŠ¸ë¦¬ê±°ì— ì˜í•´ ëª¨ë¸ì´ ì•…ì˜ì ìœ¼ë¡œ ì‘ë™í•˜ê²Œ í•˜ì—¬ ë³´ì•ˆ ìœ„í—˜ì„ ì´ˆë˜í•œë‹¤.
- 2. ë°±ë„ì–´ íƒì§€ ë°©ë²•ì€ ê³µê°œëœ ëª¨ë¸ì— ë°±ë„ì–´ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ë¥¼ ê°ì§€í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•œë‹¤.
- 3. ê¸°ì¡´ ë°±ë„ì–´ íƒì§€ ë°©ë²•ì€ í‘œì¤€ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë†’ì€ ì •í™•ë„ë¥¼ ë³´ì´ì§€ë§Œ, ì‹¤ì œ í™˜ê²½ì—ì„œì˜ ê²¬ê³ ì„±ì€ ë¶ˆí™•ì‹¤í•˜ë‹¤.
- 4. ë°±ë„ì–´ íƒì§€ê¸°ì˜ ê²¬ê³ ì„±ì„ í‰ê°€í•œ ê²°ê³¼, íŠ¸ë¦¬ê±° ë°˜ì „ì´ë‚˜ ë©”íƒ€ ë¶„ë¥˜ê¸°ì— ê¸°ë°˜í•œ ë°©ë²•ì˜ ì„±ê³µì€ ëª¨ë¸ì´ ì˜¤ì—¼ëœ ë°ì´í„°ë¡œ ì–¼ë§ˆë‚˜ ê°•í•˜ê²Œ í›ˆë ¨ë˜ì—ˆëŠ”ì§€ì— í¬ê²Œ ì˜ì¡´í•œë‹¤.
- 5. ê³µê²©ì ì¸ ë˜ëŠ” ë³´ìˆ˜ì ì¸ í›ˆë ¨ìœ¼ë¡œ ì‹¬ì–´ì§„ ë°±ë„ì–´ëŠ” ê¸°ë³¸ì ì¸ ë°±ë„ì–´ë³´ë‹¤ íƒì§€í•˜ê¸° ì–´ë µë‹¤ëŠ” í•œê³„ê°€ ë“œëŸ¬ë‚¬ë‹¤.


---

*Generated on 2025-09-24 03:44:08*