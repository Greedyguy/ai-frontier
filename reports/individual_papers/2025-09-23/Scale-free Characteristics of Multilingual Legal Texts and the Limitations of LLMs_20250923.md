---
keywords:
  - Large Language Model
  - Legal Texts
  - Vocabulary Growth
  - Word-Frequency Fluctuation
  - AI-generated Text
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2509.17367
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:23:23.532739",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Legal Texts",
    "Vocabulary Growth",
    "Word-Frequency Fluctuation",
    "AI-generated Text"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Legal Texts": 0.78,
    "Vocabulary Growth": 0.77,
    "Word-Frequency Fluctuation": 0.74,
    "AI-generated Text": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Links to discussions on the limitations and capabilities of large language models in handling domain-specific texts.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Legal Texts",
        "canonical": "Legal Texts",
        "aliases": [
          "Legal Documents",
          "Statutory Codes"
        ],
        "category": "unique_technical",
        "rationale": "Highlights the specific domain of legal documents, which is crucial for understanding the study's focus on text complexity.",
        "novelty_score": 0.7,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Vocabulary Growth",
        "canonical": "Vocabulary Growth",
        "aliases": [
          "Heaps' Exponent"
        ],
        "category": "unique_technical",
        "rationale": "Key metric for analyzing text complexity, relevant for linking to linguistic studies.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.72,
        "link_intent_score": 0.77
      },
      {
        "surface": "Word-Frequency Fluctuation",
        "canonical": "Word-Frequency Fluctuation",
        "aliases": [
          "Taylor's Exponent"
        ],
        "category": "unique_technical",
        "rationale": "Essential for understanding text complexity, providing a basis for comparison across domains.",
        "novelty_score": 0.68,
        "connectivity_score": 0.67,
        "specificity_score": 0.75,
        "link_intent_score": 0.74
      },
      {
        "surface": "AI-generated Text",
        "canonical": "AI-generated Text",
        "aliases": [
          "GPT Text"
        ],
        "category": "specific_connectable",
        "rationale": "Relevant for linking discussions on AI's role in text generation and its comparison with human-generated texts.",
        "novelty_score": 0.55,
        "connectivity_score": 0.8,
        "specificity_score": 0.7,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "text complexity",
      "general texts"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Legal Texts",
      "resolved_canonical": "Legal Texts",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Vocabulary Growth",
      "resolved_canonical": "Vocabulary Growth",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.72,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Word-Frequency Fluctuation",
      "resolved_canonical": "Word-Frequency Fluctuation",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.67,
        "specificity": 0.75,
        "link_intent": 0.74
      }
    },
    {
      "candidate_surface": "AI-generated Text",
      "resolved_canonical": "AI-generated Text",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.8,
        "specificity": 0.7,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Scale-free Characteristics of Multilingual Legal Texts and the Limitations of LLMs

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17367.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2509.17367](https://arxiv.org/abs/2509.17367)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Benchmark of stylistic variation in LLM-generated texts_20250922|Benchmark of stylistic variation in LLM-generated texts]] (81.4% similar)
- [[2025-09-22/A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages_20250922|A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages]] (81.3% similar)
- [[2025-09-18/An LLM Agentic Approach for Legal-Critical Software_ A Case Study for Tax Prep Software_20250918|An LLM Agentic Approach for Legal-Critical Software: A Case Study for Tax Prep Software]] (81.0% similar)
- [[2025-09-22/DNA-DetectLLM_ Unveiling AI-Generated Text via a DNA-Inspired Mutation-Repair Paradigm_20250922|DNA-DetectLLM: Unveiling AI-Generated Text via a DNA-Inspired Mutation-Repair Paradigm]] (80.6% similar)
- [[2025-09-19/When Content is Goliath and Algorithm is David_ The Style and Semantic Effects of Generative Search Engine_20250919|When Content is Goliath and Algorithm is David: The Style and Semantic Effects of Generative Search Engine]] (80.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/AI-generated Text|AI-generated Text]]
**âš¡ Unique Technical**: [[keywords/Legal Texts|Legal Texts]], [[keywords/Vocabulary Growth|Vocabulary Growth]], [[keywords/Word-Frequency Fluctuation|Word-Frequency Fluctuation]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17367v1 Announce Type: new 
Abstract: We present a comparative analysis of text complexity across domains using scale-free metrics. We quantify linguistic complexity via Heaps' exponent $\beta$ (vocabulary growth), Taylor's exponent $\alpha$ (word-frequency fluctuation scaling), compression rate $r$ (redundancy), and entropy. Our corpora span three domains: legal documents (statutes, cases, deeds) as a specialized domain, general natural language texts (literature, Wikipedia), and AI-generated (GPT) text. We find that legal texts exhibit slower vocabulary growth (lower $\beta$) and higher term consistency (higher $\alpha$) than general texts. Within legal domain, statutory codes have the lowest $\beta$ and highest $\alpha$, reflecting strict drafting conventions, while cases and deeds show higher $\beta$ and lower $\alpha$. In contrast, GPT-generated text shows the statistics more aligning with general language patterns. These results demonstrate that legal texts exhibit domain-specific structures and complexities, which current generative models do not fully replicate.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë„ë©”ì¸ë³„ í…ìŠ¤íŠ¸ ë³µì¡ì„±ì„ ë¹„êµ ë¶„ì„í•˜ë©°, Heaps ì§€ìˆ˜, Taylor ì§€ìˆ˜, ì••ì¶•ë¥ , ì—”íŠ¸ë¡œí”¼ë¥¼ ì‚¬ìš©í•˜ì—¬ ì–¸ì–´ì  ë³µì¡ì„±ì„ ì •ëŸ‰í™”í•©ë‹ˆë‹¤. ë²•ë¥  ë¬¸ì„œ, ì¼ë°˜ ìì—°ì–´ í…ìŠ¤íŠ¸, AI ìƒì„± í…ìŠ¤íŠ¸ë¥¼ ëŒ€ìƒìœ¼ë¡œ ì—°êµ¬í•œ ê²°ê³¼, ë²•ë¥  ë¬¸ì„œëŠ” ì¼ë°˜ í…ìŠ¤íŠ¸ì— ë¹„í•´ ì–´íœ˜ ì„±ì¥ ì†ë„ê°€ ëŠë¦¬ê³  ìš©ì–´ ì¼ê´€ì„±ì´ ë†’ì•˜ìŠµë‹ˆë‹¤. íŠ¹íˆ ë²•ë¥  ë¬¸ì„œ ì¤‘ì—ì„œë„ ë²•ë ¹ì€ ê°€ì¥ ë‚®ì€ ì–´íœ˜ ì„±ì¥ê³¼ ë†’ì€ ìš©ì–´ ì¼ê´€ì„±ì„ ë³´ì˜€ìœ¼ë©°, ì´ëŠ” ì—„ê²©í•œ ì‘ì„± ê·œì¹™ì„ ë°˜ì˜í•©ë‹ˆë‹¤. ë°˜ë©´, AIê°€ ìƒì„±í•œ í…ìŠ¤íŠ¸ëŠ” ì¼ë°˜ ì–¸ì–´ íŒ¨í„´ê³¼ ìœ ì‚¬í•œ í†µê³„ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ê²°ê³¼ëŠ” ë²•ë¥  ë¬¸ì„œê°€ ë„ë©”ì¸ íŠ¹ìœ ì˜ êµ¬ì¡°ì™€ ë³µì¡ì„±ì„ ê°€ì§€ê³  ìˆìœ¼ë©°, í˜„ì¬ì˜ ìƒì„± ëª¨ë¸ì´ ì´ë¥¼ ì™„ì „íˆ ì¬í˜„í•˜ì§€ ëª»í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë²•ë¥  í…ìŠ¤íŠ¸ëŠ” ì¼ë°˜ í…ìŠ¤íŠ¸ì— ë¹„í•´ ì–´íœ˜ ì„±ì¥ ì†ë„ê°€ ëŠë¦¬ê³  ìš©ì–´ ì¼ê´€ì„±ì´ ë†’ë‹¤.
- 2. ë²•ë¥  ë„ë©”ì¸ ë‚´ì—ì„œ ë²•ë ¹ì€ ê°€ì¥ ë‚®ì€ ì–´íœ˜ ì„±ì¥ ì§€ìˆ˜($\beta$)ì™€ ê°€ì¥ ë†’ì€ ìš©ì–´ ì¼ê´€ì„± ì§€ìˆ˜($\alpha$)ë¥¼ ë³´ì¸ë‹¤.
- 3. GPT ìƒì„± í…ìŠ¤íŠ¸ëŠ” ì¼ë°˜ ì–¸ì–´ íŒ¨í„´ê³¼ ë” ìœ ì‚¬í•œ í†µê³„ì  íŠ¹ì„±ì„ ë³´ì¸ë‹¤.
- 4. ë²•ë¥  í…ìŠ¤íŠ¸ëŠ” ë„ë©”ì¸ íŠ¹ìœ ì˜ êµ¬ì¡°ì™€ ë³µì¡ì„±ì„ ê°€ì§€ë©°, ì´ëŠ” í˜„ì¬ì˜ ìƒì„± ëª¨ë¸ë“¤ì´ ì™„ì „íˆ ì¬í˜„í•˜ì§€ ëª»í•œë‹¤.


---

*Generated on 2025-09-24 03:23:23*