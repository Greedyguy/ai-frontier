---
keywords:
  - Large Language Model
  - SEGALE
  - Document-Level Evaluation
  - Sentence Segmentation and Alignment
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2509.17249
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:22:35.687664",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "SEGALE",
    "Document-Level Evaluation",
    "Sentence Segmentation and Alignment"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "SEGALE": 0.8,
    "Document-Level Evaluation": 0.78,
    "Sentence Segmentation and Alignment": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are central to the paper's discussion on translation and evaluation, providing a strong link to existing research in NLP.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "SEGALE",
        "canonical": "SEGALE",
        "aliases": [
          "Sentence Segmentation and Alignment Evaluation"
        ],
        "category": "unique_technical",
        "rationale": "SEGALE is a novel evaluation scheme introduced in the paper, offering a unique link to document-level translation evaluation.",
        "novelty_score": 0.85,
        "connectivity_score": 0.6,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "document-level evaluation",
        "canonical": "Document-Level Evaluation",
        "aliases": [
          "long-document evaluation"
        ],
        "category": "specific_connectable",
        "rationale": "Document-level evaluation is a key concept in extending translation assessments beyond sentence-level, crucial for linking to broader translation evaluation methodologies.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.78
      },
      {
        "surface": "sentence segmentation and alignment",
        "canonical": "Sentence Segmentation and Alignment",
        "aliases": [
          "sentence alignment"
        ],
        "category": "specific_connectable",
        "rationale": "This technique is essential for the proposed evaluation scheme, connecting to methods in text processing and alignment.",
        "novelty_score": 0.5,
        "connectivity_score": 0.72,
        "specificity_score": 0.68,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "evaluation methodologies",
      "translation performance",
      "experiments"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "SEGALE",
      "resolved_canonical": "SEGALE",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.6,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "document-level evaluation",
      "resolved_canonical": "Document-Level Evaluation",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "sentence segmentation and alignment",
      "resolved_canonical": "Sentence Segmentation and Alignment",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.72,
        "specificity": 0.68,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Extending Automatic Machine Translation Evaluation to Book-Length Documents

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17249.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2509.17249](https://arxiv.org/abs/2509.17249)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Breaking the Reviewer_ Assessing the Vulnerability of Large Language Models in Automated Peer Review Under Textual Adversarial Attacks_20250923|Breaking the Reviewer: Assessing the Vulnerability of Large Language Models in Automated Peer Review Under Textual Adversarial Attacks]] (81.4% similar)
- [[2025-09-23/GALLa_ Graph Aligned Large Language Models for Improved Source Code Understanding_20250923|GALLa: Graph Aligned Large Language Models for Improved Source Code Understanding]] (81.4% similar)
- [[2025-09-23/EquiBench_ Benchmarking Large Language Models' Reasoning about Program Semantics via Equivalence Checking_20250923|EquiBench: Benchmarking Large Language Models' Reasoning about Program Semantics via Equivalence Checking]] (81.1% similar)
- [[2025-09-19/CLEAR_ A Comprehensive Linguistic Evaluation of Argument Rewriting by Large Language Models_20250919|CLEAR: A Comprehensive Linguistic Evaluation of Argument Rewriting by Large Language Models]] (80.9% similar)
- [[2025-09-22/A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages_20250922|A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages]] (80.9% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Document-Level Evaluation|Document-Level Evaluation]], [[keywords/Sentence Segmentation and Alignment|Sentence Segmentation and Alignment]]
**âš¡ Unique Technical**: [[keywords/SEGALE|SEGALE]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17249v1 Announce Type: new 
Abstract: Despite Large Language Models (LLMs) demonstrating superior translation performance and long-context capabilities, evaluation methodologies remain constrained to sentence-level assessment due to dataset limitations, token number restrictions in metrics, and rigid sentence boundary requirements. We introduce SEGALE, an evaluation scheme that extends existing automatic metrics to long-document translation by treating documents as continuous text and applying sentence segmentation and alignment methods. Our approach enables previously unattainable document-level evaluation, handling translations of arbitrary length generated with document-level prompts while accounting for under-/over-translations and varied sentence boundaries. Experiments show our scheme significantly outperforms existing long-form document evaluation schemes, while being comparable to evaluations performed with groundtruth sentence alignments. Additionally, we apply our scheme to book-length texts and newly demonstrate that many open-weight LLMs fail to effectively translate documents at their reported maximum context lengths.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ë²ˆì—­ ì„±ëŠ¥ í‰ê°€ë¥¼ ë¬¸ì„œ ìˆ˜ì¤€ìœ¼ë¡œ í™•ì¥í•˜ëŠ” SEGALEë¼ëŠ” í‰ê°€ ë°©ì‹ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë¬¸ì¥ ë‹¨ìœ„ í‰ê°€ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ë¬¸ì„œë¥¼ ì—°ì†ì ì¸ í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬í•˜ê³  ë¬¸ì¥ ë¶„í•  ë° ì •ë ¬ ë°©ë²•ì„ ì ìš©í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë¬¸ì„œ ê¸¸ì´ì— ìƒê´€ì—†ì´ ë²ˆì—­ í‰ê°€ê°€ ê°€ëŠ¥í•˜ë©°, ê³¼ì†Œ/ê³¼ëŒ€ ë²ˆì—­ ë° ë‹¤ì–‘í•œ ë¬¸ì¥ ê²½ê³„ë¥¼ ê³ ë ¤í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, SEGALEëŠ” ê¸°ì¡´ì˜ ì¥ë¬¸ ë¬¸ì„œ í‰ê°€ ë°©ì‹ë³´ë‹¤ ìš°ìˆ˜í•˜ë©°, ì‹¤ì œ ë¬¸ì¥ ì •ë ¬ì„ ì‚¬ìš©í•œ í‰ê°€ì™€ ìœ ì‚¬í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤. ë˜í•œ, ì±… ê¸¸ì´ì˜ í…ìŠ¤íŠ¸ì— ì ìš©í•˜ì—¬ ë§ì€ ê³µê°œ LLMì´ ìµœëŒ€ ë¬¸ë§¥ ê¸¸ì´ì—ì„œ íš¨ê³¼ì ìœ¼ë¡œ ë²ˆì—­í•˜ì§€ ëª»í•¨ì„ ìƒˆë¡­ê²Œ ì…ì¦í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. SEGALEëŠ” ê¸°ì¡´ ìë™ í‰ê°€ ì§€í‘œë¥¼ í™•ì¥í•˜ì—¬ ë¬¸ì„œë¥¼ ì—°ì†ì ì¸ í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬í•˜ê³  ë¬¸ì¥ ë¶„í•  ë° ì •ë ¬ ë°©ë²•ì„ ì ìš©í•˜ì—¬ ì¥ë¬¸ ë²ˆì—­ í‰ê°€ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
- 2. ì´ ì ‘ê·¼ë²•ì€ ë¬¸ì„œ ìˆ˜ì¤€ì˜ í”„ë¡¬í”„íŠ¸ë¡œ ìƒì„±ëœ ì„ì˜ ê¸¸ì´ì˜ ë²ˆì—­ì„ ì²˜ë¦¬í•˜ë©°, ëˆ„ë½/ê³¼ì‰ ë²ˆì—­ ë° ë‹¤ì–‘í•œ ë¬¸ì¥ ê²½ê³„ë¥¼ ê³ ë ¤í•©ë‹ˆë‹¤.
- 3. ì‹¤í—˜ ê²°ê³¼, SEGALEëŠ” ê¸°ì¡´ì˜ ì¥ë¬¸ ë¬¸ì„œ í‰ê°€ ë°©ì‹ë³´ë‹¤ ì„±ëŠ¥ì´ ë›°ì–´ë‚˜ë©°, ì‹¤ì œ ë¬¸ì¥ ì •ë ¬ì„ ì‚¬ìš©í•œ í‰ê°€ì™€ ë¹„êµí•  ë§Œí•œ ìˆ˜ì¤€ì…ë‹ˆë‹¤.
- 4. SEGALEë¥¼ ì±… ê¸¸ì´ì˜ í…ìŠ¤íŠ¸ì— ì ìš©í•œ ê²°ê³¼, ë§ì€ ì˜¤í”ˆ ì›¨ì´íŠ¸ LLMì´ ë³´ê³ ëœ ìµœëŒ€ ë¬¸ë§¥ ê¸¸ì´ì—ì„œ ë¬¸ì„œë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ë²ˆì—­í•˜ì§€ ëª»í•œë‹¤ëŠ” ì ì„ ìƒˆë¡­ê²Œ ì…ì¦í–ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 03:22:35*