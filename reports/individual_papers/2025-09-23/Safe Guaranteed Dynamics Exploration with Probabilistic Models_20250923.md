---
keywords:
  - Safe Dynamics Learning
  - Probabilistic Models
  - Online Learning
  - Non-Episodic Learning
category: cs.LG
publish_date: 2025-09-23
arxiv_id: 2509.16650
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T02:12:18.629871",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Safe Dynamics Learning",
    "Probabilistic Models",
    "Online Learning",
    "Non-Episodic Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Safe Dynamics Learning": 0.78,
    "Probabilistic Models": 0.7,
    "Online Learning": 0.77,
    "Non-Episodic Learning": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "safe dynamics learning",
        "canonical": "Safe Dynamics Learning",
        "aliases": [
          "safe dynamics exploration"
        ],
        "category": "unique_technical",
        "rationale": "This concept is central to the paper's approach and represents a novel method for ensuring safety in unknown dynamics.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "probabilistic models",
        "canonical": "Probabilistic Models",
        "aliases": [
          "stochastic models"
        ],
        "category": "broad_technical",
        "rationale": "Probabilistic models are a foundational concept in the paper, linking to broader machine learning techniques.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.6,
        "link_intent_score": 0.7
      },
      {
        "surface": "online learning",
        "canonical": "Online Learning",
        "aliases": [
          "continuous learning"
        ],
        "category": "specific_connectable",
        "rationale": "Online learning is a key feature of the proposed method, connecting to ongoing research in adaptive systems.",
        "novelty_score": 0.55,
        "connectivity_score": 0.82,
        "specificity_score": 0.72,
        "link_intent_score": 0.77
      },
      {
        "surface": "non-episodic setting",
        "canonical": "Non-Episodic Learning",
        "aliases": [
          "continuous setting"
        ],
        "category": "unique_technical",
        "rationale": "The non-episodic setting is a unique aspect of the approach, differentiating it from typical RL methods.",
        "novelty_score": 0.68,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "optimality",
      "safety",
      "model uncertainty"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "safe dynamics learning",
      "resolved_canonical": "Safe Dynamics Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "probabilistic models",
      "resolved_canonical": "Probabilistic Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.6,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "online learning",
      "resolved_canonical": "Online Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.82,
        "specificity": 0.72,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "non-episodic setting",
      "resolved_canonical": "Non-Episodic Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Safe Guaranteed Dynamics Exploration with Probabilistic Models

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16650.pdf)
**Category**: cs.LG
**Published**: 2025-09-23
**ArXiv ID**: [2509.16650](https://arxiv.org/abs/2509.16650)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Hierarchical Reinforcement Learning with Low-Level MPC for Multi-Agent Control_20250922|Hierarchical Reinforcement Learning with Low-Level MPC for Multi-Agent Control]] (85.4% similar)
- [[2025-09-19/Digital Twin-based Cooperative Autonomous Driving in Smart Intersections_ A Multi-Agent Reinforcement Learning Approach_20250919|Digital Twin-based Cooperative Autonomous Driving in Smart Intersections: A Multi-Agent Reinforcement Learning Approach]] (84.4% similar)
- [[2025-09-19/Online Learning of Deceptive Policies under Intermittent Observation_20250919|Online Learning of Deceptive Policies under Intermittent Observation]] (83.5% similar)
- [[2025-09-23/Automating Steering for Safe Multimodal Large Language Models_20250923|Automating Steering for Safe Multimodal Large Language Models]] (82.4% similar)
- [[2025-09-23/ORN-CBF_ Learning Observation-conditioned Residual Neural Control Barrier Functions via Hypernetworks_20250923|ORN-CBF: Learning Observation-conditioned Residual Neural Control Barrier Functions via Hypernetworks]] (82.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Probabilistic Models|Probabilistic Models]]
**ğŸ”— Specific Connectable**: [[keywords/Online Learning|Online Learning]]
**âš¡ Unique Technical**: [[keywords/Safe Dynamics Learning|Safe Dynamics Learning]], [[keywords/Non-Episodic Learning|Non-Episodic Learning]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16650v1 Announce Type: cross 
Abstract: Ensuring both optimality and safety is critical for the real-world deployment of agents, but becomes particularly challenging when the system dynamics are unknown. To address this problem, we introduce a notion of maximum safe dynamics learning via sufficient exploration in the space of safe policies. We propose a $\textit{pessimistically}$ safe framework that $\textit{optimistically}$ explores informative states and, despite not reaching them due to model uncertainty, ensures continuous online learning of dynamics. The framework achieves first-of-its-kind results: learning the dynamics model sufficiently $-$ up to an arbitrary small tolerance (subject to noise) $-$ in a finite time, while ensuring provably safe operation throughout with high probability and without requiring resets. Building on this, we propose an algorithm to maximize rewards while learning the dynamics $\textit{only to the extent needed}$ to achieve close-to-optimal performance. Unlike typical reinforcement learning (RL) methods, our approach operates online in a non-episodic setting and ensures safety throughout the learning process. We demonstrate the effectiveness of our approach in challenging domains such as autonomous car racing and drone navigation under aerodynamic effects $-$ scenarios where safety is critical and accurate modeling is difficult.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì‹œìŠ¤í…œ ë™ì‘ì´ ì•Œë ¤ì§€ì§€ ì•Šì€ ìƒí™©ì—ì„œ ì—ì´ì „íŠ¸ì˜ ìµœì ì„±ê³¼ ì•ˆì „ì„±ì„ ë³´ì¥í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ì ‘ê·¼ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì €ìë“¤ì€ ì•ˆì „í•œ ì •ì±… ê³µê°„ì—ì„œ ì¶©ë¶„í•œ íƒìƒ‰ì„ í†µí•´ ìµœëŒ€ ì•ˆì „ ë™ì  í•™ìŠµ ê°œë…ì„ ë„ì…í•˜ê³ , ë¹„ê´€ì ìœ¼ë¡œ ì•ˆì „í•œ í”„ë ˆì„ì›Œí¬ê°€ ë‚™ê´€ì ìœ¼ë¡œ ì •ë³´ ìƒíƒœë¥¼ íƒìƒ‰í•˜ë„ë¡ í•©ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ëª¨ë¸ ë¶ˆí™•ì‹¤ì„±ì—ë„ ë¶ˆêµ¬í•˜ê³  ì—°ì†ì ì¸ ì˜¨ë¼ì¸ ë™ì  í•™ìŠµì„ ë³´ì¥í•˜ë©°, ì•ˆì „í•œ ì‘ë™ì„ ë†’ì€ í™•ë¥ ë¡œ ë³´ì¥í•˜ë©´ì„œë„ ë¦¬ì…‹ì´ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë˜í•œ, ë™ì  ëª¨ë¸ì„ í•„ìš”í•œ ë§Œí¼ë§Œ í•™ìŠµí•˜ì—¬ ê±°ì˜ ìµœì ì˜ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ì ‘ê·¼ë²•ì€ ë¹„ì—í”¼ì†Œë“œ í™˜ê²½ì—ì„œ ì˜¨ë¼ì¸ìœ¼ë¡œ ì‘ë™í•˜ë©°, í•™ìŠµ ê³¼ì • ë‚´ë‚´ ì•ˆì „ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤. ììœ¨ì£¼í–‰ ìë™ì°¨ ê²½ì£¼ì™€ ë“œë¡  ë‚´ë¹„ê²Œì´ì…˜ê³¼ ê°™ì€ ì•ˆì „ì´ ì¤‘ìš”í•œ ë„ë©”ì¸ì—ì„œ ê·¸ íš¨ê³¼ë¥¼ ì…ì¦í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì‹œìŠ¤í…œ ë™ì‘ì´ ì•Œë ¤ì§€ì§€ ì•Šì€ ìƒí™©ì—ì„œ ìµœì ì„±ê³¼ ì•ˆì „ì„±ì„ ë™ì‹œì— ë³´ì¥í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ì•ˆì „ ë™ì  í•™ìŠµ ê°œë…ì„ ì œì•ˆí•©ë‹ˆë‹¤.
- 2. ì œì•ˆëœ í”„ë ˆì„ì›Œí¬ëŠ” ì•ˆì „í•œ ì •ì±… ê³µê°„ì—ì„œ ì¶©ë¶„í•œ íƒìƒ‰ì„ í†µí•´ ìµœëŒ€í•œì˜ ì•ˆì „í•œ ë™ì  í•™ìŠµì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
- 3. ì˜¨ë¼ì¸ í•™ìŠµì„ í†µí•´ ëª¨ë¸ ë¶ˆí™•ì‹¤ì„±ì—ë„ ë¶ˆêµ¬í•˜ê³  ì§€ì†ì ì¸ ë™ì  í•™ìŠµì„ ë³´ì¥í•˜ë©°, ì•ˆì „í•œ ì‘ë™ì„ ë†’ì€ í™•ë¥ ë¡œ ë³´ì¥í•©ë‹ˆë‹¤.
- 4. ì œì•ˆëœ ì•Œê³ ë¦¬ì¦˜ì€ ë™ì  ëª¨ë¸ì„ í•„ìš”í•œ ë²”ìœ„ ë‚´ì—ì„œë§Œ í•™ìŠµí•˜ì—¬ ê±°ì˜ ìµœì ì˜ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.
- 5. ììœ¨ì£¼í–‰ ìë™ì°¨ ê²½ì£¼ ë° ë“œë¡  ë‚´ë¹„ê²Œì´ì…˜ê³¼ ê°™ì€ ë„ì „ì ì¸ ë„ë©”ì¸ì—ì„œ ì œì•ˆëœ ì ‘ê·¼ ë°©ì‹ì˜ íš¨ê³¼ë¥¼ ì…ì¦í•˜ì˜€ìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 02:12:18*