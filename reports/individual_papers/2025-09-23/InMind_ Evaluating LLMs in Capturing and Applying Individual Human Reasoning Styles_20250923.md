---
keywords:
  - Large Language Model
  - Social Deduction Games
  - Cognitively Grounded Evaluation Framework
  - Reasoning-Enhanced LLMs
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2508.16072
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T00:32:04.826361",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Social Deduction Games",
    "Cognitively Grounded Evaluation Framework",
    "Reasoning-Enhanced LLMs"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Social Deduction Games": 0.78,
    "Cognitively Grounded Evaluation Framework": 0.82,
    "Reasoning-Enhanced LLMs": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "This term is central to the paper's focus on evaluating AI models in reasoning tasks.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Social Deduction Games",
        "canonical": "Social Deduction Games",
        "aliases": [
          "SDGs"
        ],
        "category": "unique_technical",
        "rationale": "This concept is crucial for understanding the context in which reasoning styles are evaluated.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Cognitively Grounded Evaluation Framework",
        "canonical": "Cognitively Grounded Evaluation Framework",
        "aliases": [
          "InMind"
        ],
        "category": "unique_technical",
        "rationale": "This framework is a novel approach introduced in the paper for evaluating reasoning styles.",
        "novelty_score": 0.8,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.82
      },
      {
        "surface": "Reasoning-Enhanced LLMs",
        "canonical": "Reasoning-Enhanced LLMs",
        "aliases": [
          "DeepSeek-R1"
        ],
        "category": "evolved_concepts",
        "rationale": "This represents an advancement in LLMs, focusing on style-sensitive reasoning.",
        "novelty_score": 0.68,
        "connectivity_score": 0.72,
        "specificity_score": 0.78,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "Observer",
      "Participant",
      "Avalon"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Social Deduction Games",
      "resolved_canonical": "Social Deduction Games",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Cognitively Grounded Evaluation Framework",
      "resolved_canonical": "Cognitively Grounded Evaluation Framework",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Reasoning-Enhanced LLMs",
      "resolved_canonical": "Reasoning-Enhanced LLMs",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.72,
        "specificity": 0.78,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# InMind: Evaluating LLMs in Capturing and Applying Individual Human Reasoning Styles

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2508.16072.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2508.16072](https://arxiv.org/abs/2508.16072)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Evaluating LLM-Generated Versus Human-Authored Responses in Role-Play Dialogues_20250923|Evaluating LLM-Generated Versus Human-Authored Responses in Role-Play Dialogues]] (85.9% similar)
- [[2025-09-22/It Depends_ Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge_20250922|It Depends: Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge]] (85.7% similar)
- [[2025-09-23/Evaluating Behavioral Alignment in Conflict Dialogue_ A Multi-Dimensional Comparison of LLM Agents and Humans_20250923|Evaluating Behavioral Alignment in Conflict Dialogue: A Multi-Dimensional Comparison of LLM Agents and Humans]] (85.6% similar)
- [[2025-09-22/Can LLMs Judge Debates? Evaluating Non-Linear Reasoning via Argumentation Theory Semantics_20250922|Can LLMs Judge Debates? Evaluating Non-Linear Reasoning via Argumentation Theory Semantics]] (85.2% similar)
- [[2025-09-22/DivLogicEval_ A Framework for Benchmarking Logical Reasoning Evaluation in Large Language Models_20250922|DivLogicEval: A Framework for Benchmarking Logical Reasoning Evaluation in Large Language Models]] (85.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**âš¡ Unique Technical**: [[keywords/Social Deduction Games|Social Deduction Games]], [[keywords/Cognitively Grounded Evaluation Framework|Cognitively Grounded Evaluation Framework]]
**ğŸš€ Evolved Concepts**: [[keywords/Reasoning-Enhanced LLMs|Reasoning-Enhanced LLMs]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2508.16072v3 Announce Type: replace 
Abstract: LLMs have shown strong performance on human-centric reasoning tasks. While previous evaluations have explored whether LLMs can infer intentions or detect deception, they often overlook the individualized reasoning styles that influence how people interpret and act in social contexts. Social deduction games (SDGs) provide a natural testbed for evaluating individualized reasoning styles, where different players may adopt diverse but contextually valid reasoning strategies under identical conditions. To address this, we introduce InMind, a cognitively grounded evaluation framework designed to assess whether LLMs can capture and apply personalized reasoning styles in SDGs. InMind enhances structured gameplay data with round-level strategy traces and post-game reflections, collected under both Observer and Participant modes. It supports four cognitively motivated tasks that jointly evaluate both static alignment and dynamic adaptation. As a case study, we apply InMind to the game Avalon, evaluating 11 state-of-the-art LLMs. General-purpose LLMs, even GPT-4o frequently rely on lexical cues, struggling to anchor reflections in temporal gameplay or adapt to evolving strategies. In contrast, reasoning-enhanced LLMs like DeepSeek-R1 exhibit early signs of style-sensitive reasoning. These findings reveal key limitations in current LLMs' capacity for individualized, adaptive reasoning, and position InMind as a step toward cognitively aligned human-AI interaction.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì¸ê°„ ì¤‘ì‹¬ì˜ ì¶”ë¡  ê³¼ì œë¥¼ ìˆ˜í–‰í•˜ëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤. ê¸°ì¡´ ì—°êµ¬ëŠ” LLMì´ ì˜ë„ë¥¼ ì¶”ë¡ í•˜ê±°ë‚˜ ì†ì„ìˆ˜ë¥¼ ê°ì§€í•  ìˆ˜ ìˆëŠ”ì§€ë¥¼ íƒêµ¬í–ˆì§€ë§Œ, ê°œë³„í™”ëœ ì¶”ë¡  ìŠ¤íƒ€ì¼ì„ ê°„ê³¼í–ˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ì €ìë“¤ì€ ì‚¬íšŒì  ì¶”ë¡  ê²Œì„(SDG)ì—ì„œ LLMì˜ ê°œì¸í™”ëœ ì¶”ë¡  ìŠ¤íƒ€ì¼ì„ í‰ê°€í•˜ëŠ” InMindë¼ëŠ” í‰ê°€ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. InMindëŠ” ê²Œì„ ë°ì´í„°ì™€ ì „ëµ ì¶”ì , ê²Œì„ í›„ ë°˜ì„± ìë£Œë¥¼ í™œìš©í•˜ì—¬ LLMì˜ ì •ì  ì •ë ¬ê³¼ ë™ì  ì ì‘ ëŠ¥ë ¥ì„ í‰ê°€í•©ë‹ˆë‹¤. Avalon ê²Œì„ì„ í†µí•´ 11ê°œì˜ ìµœì‹  LLMì„ í‰ê°€í•œ ê²°ê³¼, ì¼ë°˜ LLMì€ ì–´íœ˜ì  ë‹¨ì„œì— ì˜ì¡´í•˜ë©°, ì¶”ë¡  ê°•í™” LLMì€ ìŠ¤íƒ€ì¼ì— ë¯¼ê°í•œ ì¶”ë¡ ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŠ” í˜„ì¬ LLMì˜ ê°œë³„í™”ëœ ì ì‘ ì¶”ë¡ ì˜ í•œê³„ë¥¼ ë“œëŸ¬ë‚´ë©°, InMindê°€ ì¸ê°„-AI ìƒí˜¸ì‘ìš©ì˜ ì¸ì§€ì  ì •ë ¬ì„ í–¥í•œ ì§„ì „ì„ ì œì‹œí•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. LLMsëŠ” ì¸ê°„ ì¤‘ì‹¬ì˜ ì¶”ë¡  ì‘ì—…ì—ì„œ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì§€ë§Œ, ê°œì¸í™”ëœ ì¶”ë¡  ìŠ¤íƒ€ì¼ì„ ê°„ê³¼í•˜ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤.
- 2. InMindëŠ” ì‚¬íšŒì  ì¶”ë¡  ê²Œì„(SDGs)ì—ì„œ LLMsê°€ ê°œì¸í™”ëœ ì¶”ë¡  ìŠ¤íƒ€ì¼ì„ í¬ì°©í•˜ê³  ì ìš©í•  ìˆ˜ ìˆëŠ”ì§€ë¥¼ í‰ê°€í•˜ê¸° ìœ„í•œ ì¸ì§€ ê¸°ë°˜ í‰ê°€ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.
- 3. InMindëŠ” ê´€ì°°ì ëª¨ë“œì™€ ì°¸ê°€ì ëª¨ë“œì—ì„œ ìˆ˜ì§‘ëœ ì „ëµ ì¶”ì ê³¼ ê²Œì„ í›„ ë°˜ì„±ì„ í†µí•´ êµ¬ì¡°í™”ëœ ê²Œì„ ë°ì´í„°ë¥¼ ê°•í™”í•©ë‹ˆë‹¤.
- 4. ì¼ë°˜ì ì¸ LLMsëŠ” ì–´íœ˜ì  ë‹¨ì„œì— ì˜ì¡´í•˜ë©°, ì‹œê°„ì  ê²Œì„í”Œë ˆì´ì— ë°˜ì˜í•˜ê±°ë‚˜ ë³€í™”í•˜ëŠ” ì „ëµì— ì ì‘í•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªìŠµë‹ˆë‹¤.
- 5. DeepSeek-R1ê³¼ ê°™ì€ ì¶”ë¡  ê°•í™” LLMsëŠ” ìŠ¤íƒ€ì¼ì— ë¯¼ê°í•œ ì¶”ë¡ ì˜ ì´ˆê¸° ì§•í›„ë¥¼ ë³´ì´ë©°, InMindëŠ” ì¸ì§€ì ìœ¼ë¡œ ì •ë ¬ëœ ì¸ê°„-AI ìƒí˜¸ì‘ìš©ì„ ìœ„í•œ ì§„ì „ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.


---

*Generated on 2025-09-24 00:32:04*