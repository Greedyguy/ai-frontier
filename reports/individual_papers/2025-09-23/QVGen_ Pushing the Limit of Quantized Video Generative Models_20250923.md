---
keywords:
  - Video Diffusion Models
  - Quantization-Aware Training
  - Singular Value Decomposition
  - Rank-Based Regularization
category: cs.CV
publish_date: 2025-09-23
arxiv_id: 2505.11497
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T05:22:34.503606",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Video Diffusion Models",
    "Quantization-Aware Training",
    "Singular Value Decomposition",
    "Rank-Based Regularization"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Video Diffusion Models": 0.78,
    "Quantization-Aware Training": 0.77,
    "Singular Value Decomposition": 0.72,
    "Rank-Based Regularization": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Video Diffusion Models",
        "canonical": "Video Diffusion Models",
        "aliases": [
          "Video DMs"
        ],
        "category": "unique_technical",
        "rationale": "This term is central to the paper's focus on improving video synthesis efficiency, making it a unique technical concept.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Quantization-Aware Training",
        "canonical": "Quantization-Aware Training",
        "aliases": [
          "QAT"
        ],
        "category": "unique_technical",
        "rationale": "QAT is a key technique discussed in the paper for improving video model efficiency under low-bit quantization.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      },
      {
        "surface": "Singular Value Decomposition",
        "canonical": "Singular Value Decomposition",
        "aliases": [
          "SVD"
        ],
        "category": "broad_technical",
        "rationale": "SVD is a mathematical technique used in the paper's proposed strategy to optimize model performance.",
        "novelty_score": 0.4,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.72
      },
      {
        "surface": "Rank-Based Regularization",
        "canonical": "Rank-Based Regularization",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This is a novel method introduced in the paper to enhance model efficiency by managing component contributions.",
        "novelty_score": 0.8,
        "connectivity_score": 0.55,
        "specificity_score": 0.88,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Video Diffusion Models",
      "resolved_canonical": "Video Diffusion Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Quantization-Aware Training",
      "resolved_canonical": "Quantization-Aware Training",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Singular Value Decomposition",
      "resolved_canonical": "Singular Value Decomposition",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "Rank-Based Regularization",
      "resolved_canonical": "Rank-Based Regularization",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.55,
        "specificity": 0.88,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# QVGen: Pushing the Limit of Quantized Video Generative Models

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2505.11497.pdf)
**Category**: cs.CV
**Published**: 2025-09-23
**ArXiv ID**: [2505.11497](https://arxiv.org/abs/2505.11497)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/MEC-Quant_ Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training_20250922|MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training]] (84.9% similar)
- [[2025-09-23/4DGCPro_ Efficient Hierarchical 4D Gaussian Compression for Progressive Volumetric Video Streaming_20250923|4DGCPro: Efficient Hierarchical 4D Gaussian Compression for Progressive Volumetric Video Streaming]] (84.8% similar)
- [[2025-09-23/VQToken_ Neural Discrete Token Representation Learning for Extreme Token Reduction in Video Large Language Models_20250923|VQToken: Neural Discrete Token Representation Learning for Extreme Token Reduction in Video Large Language Models]] (84.3% similar)
- [[2025-09-23/FG-Attn_ Leveraging Fine-Grained Sparsity In Diffusion Transformers_20250923|FG-Attn: Leveraging Fine-Grained Sparsity In Diffusion Transformers]] (82.6% similar)
- [[2025-09-23/PTQTP_ Post-Training Quantization to Trit-Planes for Large Language Models_20250923|PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models]] (82.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Singular Value Decomposition|Singular Value Decomposition]]
**âš¡ Unique Technical**: [[keywords/Video Diffusion Models|Video Diffusion Models]], [[keywords/Quantization-Aware Training|Quantization-Aware Training]], [[keywords/Rank-Based Regularization|Rank-Based Regularization]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2505.11497v3 Announce Type: replace 
Abstract: Video diffusion models (DMs) have enabled high-quality video synthesis. Yet, their substantial computational and memory demands pose serious challenges to real-world deployment, even on high-end GPUs. As a commonly adopted solution, quantization has proven notable success in reducing cost for image DMs, while its direct application to video DMs remains ineffective. In this paper, we present QVGen, a novel quantization-aware training (QAT) framework tailored for high-performance and inference-efficient video DMs under extremely low-bit quantization (e.g., 4-bit or below). We begin with a theoretical analysis demonstrating that reducing the gradient norm is essential to facilitate convergence for QAT. To this end, we introduce auxiliary modules ($\Phi$) to mitigate large quantization errors, leading to significantly enhanced convergence. To eliminate the inference overhead of $\Phi$, we propose a rank-decay strategy that progressively eliminates $\Phi$. Specifically, we repeatedly employ singular value decomposition (SVD) and a proposed rank-based regularization $\mathbf{\gamma}$ to identify and decay low-contributing components. This strategy retains performance while zeroing out inference overhead. Extensive experiments across $4$ state-of-the-art (SOTA) video DMs, with parameter sizes ranging from $1.3$B $\sim14$B, show that QVGen is the first to reach full-precision comparable quality under 4-bit settings. Moreover, it significantly outperforms existing methods. For instance, our 3-bit CogVideoX-2B achieves improvements of $+25.28$ in Dynamic Degree and $+8.43$ in Scene Consistency on VBench.

## ğŸ“ ìš”ì•½

QVGenì€ ê³ ì„±ëŠ¥ ë¹„ë””ì˜¤ í™•ì‚° ëª¨ë¸(VDM)ì„ ìœ„í•œ ìƒˆë¡œìš´ ì–‘ìí™” ì¸ì‹ í•™ìŠµ(QAT) í”„ë ˆì„ì›Œí¬ë¡œ, ë§¤ìš° ë‚®ì€ ë¹„íŠ¸ ì–‘ìí™”(ì˜ˆ: 4ë¹„íŠ¸ ì´í•˜)ì—ì„œë„ íš¨ìœ¨ì ì¸ ì¶”ë¡ ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” QATì˜ ìˆ˜ë ´ì„ ìœ„í•´ ê·¸ë˜ë””ì–¸íŠ¸ ë…¸ë¦„ ê°ì†Œê°€ í•„ìš”í•¨ì„ ì´ë¡ ì ìœ¼ë¡œ ë¶„ì„í•˜ê³ , ì´ë¥¼ ìœ„í•´ ë³´ì¡° ëª¨ë“ˆ(Î¦)ì„ ë„ì…í•˜ì—¬ ì–‘ìí™” ì˜¤ë¥˜ë¥¼ ì¤„ì—¬ ìˆ˜ë ´ì„±ì„ í¬ê²Œ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤. ë˜í•œ, SVDì™€ ë­í¬ ê¸°ë°˜ ì •ê·œí™”ë¥¼ í™œìš©í•œ ë­í¬ ê°ì‡  ì „ëµì„ í†µí•´ ì„±ëŠ¥ì„ ìœ ì§€í•˜ë©´ì„œë„ ì¶”ë¡  ì˜¤ë²„í—¤ë“œë¥¼ ì œê±°í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, QVGenì€ 4ë¹„íŠ¸ ì„¤ì •ì—ì„œ í’€ í”„ë¦¬ì‹œì „ê³¼ ìœ ì‚¬í•œ í’ˆì§ˆì„ ë‹¬ì„±í•˜ë©°, ê¸°ì¡´ ë°©ë²•ì„ ëŠ¥ê°€í•˜ëŠ” ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, 3ë¹„íŠ¸ CogVideoX-2BëŠ” VBenchì—ì„œ Dynamic Degreeì™€ Scene Consistencyì—ì„œ ê°ê° +25.28, +8.43ì˜ ê°œì„ ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. QVGenì€ ë¹„ë””ì˜¤ í™•ì‚° ëª¨ë¸ì˜ ê³ ì„±ëŠ¥ê³¼ ì¶”ë¡  íš¨ìœ¨ì„±ì„ ìœ„í•œ ì €ë¹„íŠ¸ ì–‘ìí™” ì¸ì‹ í›ˆë ¨(QAT) í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.
- 2. ì´ë¡ ì  ë¶„ì„ì„ í†µí•´ QATì˜ ìˆ˜ë ´ì„ ì´‰ì§„í•˜ê¸° ìœ„í•´ì„œëŠ” ê·¸ë˜ë””ì–¸íŠ¸ ë…¸ë¦„ì„ ì¤„ì´ëŠ” ê²ƒì´ í•„ìˆ˜ì ì„ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.
- 3. ë³´ì¡° ëª¨ë“ˆ($\Phi$)ì„ ë„ì…í•˜ì—¬ í° ì–‘ìí™” ì˜¤ë¥˜ë¥¼ ì™„í™”í•˜ê³  ìˆ˜ë ´ì„ í¬ê²Œ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.
- 4. ë­í¬ ê°ì†Œ ì „ëµì„ í†µí•´ $\Phi$ì˜ ì¶”ë¡  ì˜¤ë²„í—¤ë“œë¥¼ ì œê±°í•˜ë©´ì„œ ì„±ëŠ¥ì„ ìœ ì§€í•©ë‹ˆë‹¤.
- 5. QVGenì€ 4ë¹„íŠ¸ ì„¤ì •ì—ì„œ í’€ í”„ë¦¬ì‹œì „ê³¼ ë¹„êµ ê°€ëŠ¥í•œ í’ˆì§ˆì„ ë‹¬ì„±í•˜ë©°, ê¸°ì¡´ ë°©ë²•ë“¤ì„ ëŠ¥ê°€í•˜ëŠ” ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.


---

*Generated on 2025-09-24 05:22:34*