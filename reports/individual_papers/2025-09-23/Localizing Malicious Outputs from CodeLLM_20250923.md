---
keywords:
  - Large Language Model
  - FreqRank
  - Backdoor Triggers
  - Mutation-Based Defense
category: cs.LG
publish_date: 2025-09-23
arxiv_id: 2509.17070
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T02:18:59.616638",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "FreqRank",
    "Backdoor Triggers",
    "Mutation-Based Defense"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "FreqRank": 0.88,
    "Backdoor Triggers": 0.82,
    "Mutation-Based Defense": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "LLM",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Large Language Models"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are central to the paper's discussion on detecting malicious outputs.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "FreqRank",
        "canonical": "FreqRank",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "FreqRank is a novel method introduced in the paper for localizing malicious components.",
        "novelty_score": 0.95,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.88
      },
      {
        "surface": "backdoor triggers",
        "canonical": "Backdoor Triggers",
        "aliases": [
          "backdoor trigger"
        ],
        "category": "specific_connectable",
        "rationale": "Backdoor triggers are a key concept for understanding the malicious behavior in models.",
        "novelty_score": 0.6,
        "connectivity_score": 0.78,
        "specificity_score": 0.8,
        "link_intent_score": 0.82
      },
      {
        "surface": "mutation-based defense",
        "canonical": "Mutation-Based Defense",
        "aliases": [
          "mutation defense"
        ],
        "category": "unique_technical",
        "rationale": "This is a specific defense strategy proposed in the paper, relevant for understanding the methodology.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.75,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "malicious outputs",
      "attack success rate"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "LLM",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "FreqRank",
      "resolved_canonical": "FreqRank",
      "decision": "linked",
      "scores": {
        "novelty": 0.95,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "backdoor triggers",
      "resolved_canonical": "Backdoor Triggers",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.78,
        "specificity": 0.8,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "mutation-based defense",
      "resolved_canonical": "Mutation-Based Defense",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.75,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# Localizing Malicious Outputs from CodeLLM

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17070.pdf)
**Category**: cs.LG
**Published**: 2025-09-23
**ArXiv ID**: [2509.17070](https://arxiv.org/abs/2509.17070)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Inverting Trojans in LLMs_20250922|Inverting Trojans in LLMs]] (84.4% similar)
- [[2025-09-18/Evaluating and Improving the Robustness of Security Attack Detectors Generated by LLMs_20250918|Evaluating and Improving the Robustness of Security Attack Detectors Generated by LLMs]] (83.8% similar)
- [[2025-09-23/FC-Attack_ Jailbreaking Multimodal Large Language Models via Auto-Generated Flowcharts_20250923|FC-Attack: Jailbreaking Multimodal Large Language Models via Auto-Generated Flowcharts]] (81.7% similar)
- [[2025-09-17/Beyond Classification_ Evaluating LLMs for Fine-Grained Automatic Malware Behavior Auditing_20250917|Beyond Classification: Evaluating LLMs for Fine-Grained Automatic Malware Behavior Auditing]] (81.5% similar)
- [[2025-09-22/Backdoor Mitigation via Invertible Pruning Masks_20250922|Backdoor Mitigation via Invertible Pruning Masks]] (81.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Backdoor Triggers|Backdoor Triggers]]
**âš¡ Unique Technical**: [[keywords/FreqRank|FreqRank]], [[keywords/Mutation-Based Defense|Mutation-Based Defense]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17070v1 Announce Type: cross 
Abstract: We introduce FreqRank, a mutation-based defense to localize malicious components in LLM outputs and their corresponding backdoor triggers. FreqRank assumes that the malicious sub-string(s) consistently appear in outputs for triggered inputs and uses a frequency-based ranking system to identify them. Our ranking system then leverages this knowledge to localize the backdoor triggers present in the inputs. We create nine malicious models through fine-tuning or custom instructions for three downstream tasks, namely, code completion (CC), code generation (CG), and code summarization (CS), and show that they have an average attack success rate (ASR) of 86.6%. Furthermore, FreqRank's ranking system highlights the malicious outputs as one of the top five suggestions in 98% of cases. We also demonstrate that FreqRank's effectiveness scales as the number of mutants increases and show that FreqRank is capable of localizing the backdoor trigger effectively even with a limited number of triggered samples. Finally, we show that our approach is 35-50% more effective than other defense methods.

## ğŸ“ ìš”ì•½

FreqRankëŠ” LLM ì¶œë ¥ì—ì„œ ì•…ì„± êµ¬ì„± ìš”ì†Œì™€ ë°±ë„ì–´ íŠ¸ë¦¬ê±°ë¥¼ ì‹ë³„í•˜ëŠ” ëŒì—°ë³€ì´ ê¸°ë°˜ ë°©ì–´ ê¸°ë²•ì…ë‹ˆë‹¤. ì•…ì„± ë¬¸ìì—´ì´ íŠ¸ë¦¬ê±°ëœ ì…ë ¥ì—ì„œ ì¼ê´€ë˜ê²Œ ë‚˜íƒ€ë‚œë‹¤ëŠ” ê°€ì • í•˜ì—, ë¹ˆë„ ê¸°ë°˜ ë­í‚¹ ì‹œìŠ¤í…œì„ í†µí•´ ì´ë¥¼ ì‹ë³„í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì…ë ¥ì— ì¡´ì¬í•˜ëŠ” ë°±ë„ì–´ íŠ¸ë¦¬ê±°ë¥¼ ì°¾ì•„ëƒ…ë‹ˆë‹¤. ì½”ë“œ ì™„ì„±, ì½”ë“œ ìƒì„±, ì½”ë“œ ìš”ì•½ì˜ ì„¸ ê°€ì§€ ì‘ì—…ì— ëŒ€í•´ 9ê°œì˜ ì•…ì„± ëª¨ë¸ì„ ìƒì„±í•˜ì—¬ í‰ê·  ê³µê²© ì„±ê³µë¥ ì´ 86.6%ì„ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. FreqRankëŠ” ì•…ì„± ì¶œë ¥ì„ ìƒìœ„ ë‹¤ì„¯ ê°œ ì œì•ˆ ì¤‘ í•˜ë‚˜ë¡œ 98%ì˜ ê²½ìš°ì— ê°•ì¡°í•˜ë©°, ëŒì—°ë³€ì´ ìˆ˜ê°€ ì¦ê°€í• ìˆ˜ë¡ íš¨ê³¼ê°€ ì¦ê°€í•©ë‹ˆë‹¤. ì œí•œëœ íŠ¸ë¦¬ê±° ìƒ˜í”Œë¡œë„ ë°±ë„ì–´ íŠ¸ë¦¬ê±°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì‹ë³„í•  ìˆ˜ ìˆìœ¼ë©°, ë‹¤ë¥¸ ë°©ì–´ ë°©ë²•ë³´ë‹¤ 35-50% ë” íš¨ê³¼ì ì…ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. FreqRankëŠ” LLM ì¶œë ¥ì—ì„œ ì•…ì„± êµ¬ì„± ìš”ì†Œì™€ ë°±ë„ì–´ íŠ¸ë¦¬ê±°ë¥¼ ì‹ë³„í•˜ëŠ” ë³€ì´ ê¸°ë°˜ ë°©ì–´ ê¸°ë²•ì…ë‹ˆë‹¤.
- 2. FreqRankëŠ” ë¹ˆë„ ê¸°ë°˜ ë­í‚¹ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•˜ì—¬ íŠ¸ë¦¬ê±°ëœ ì…ë ¥ì—ì„œ ì¼ê´€ë˜ê²Œ ë‚˜íƒ€ë‚˜ëŠ” ì•…ì„± í•˜ìœ„ ë¬¸ìì—´ì„ ì‹ë³„í•©ë‹ˆë‹¤.
- 3. FreqRankëŠ” ì½”ë“œ ì™„ì„±, ì½”ë“œ ìƒì„±, ì½”ë“œ ìš”ì•½ì˜ ì„¸ ê°€ì§€ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—…ì„ í†µí•´ í‰ê·  86.6%ì˜ ê³µê²© ì„±ê³µë¥ ì„ ë³´ì´ëŠ” 9ê°œì˜ ì•…ì„± ëª¨ë¸ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.
- 4. FreqRankì˜ ë­í‚¹ ì‹œìŠ¤í…œì€ 98%ì˜ ê²½ìš°ì—ì„œ ì•…ì„± ì¶œë ¥ì„ ìƒìœ„ ë‹¤ì„¯ ê°€ì§€ ì œì•ˆ ì¤‘ í•˜ë‚˜ë¡œ ê°•ì¡°í•©ë‹ˆë‹¤.
- 5. FreqRankëŠ” ë‹¤ë¥¸ ë°©ì–´ ë°©ë²•ë³´ë‹¤ 35-50% ë” íš¨ê³¼ì ì´ë©°, ì œí•œëœ ìˆ˜ì˜ íŠ¸ë¦¬ê±° ìƒ˜í”Œë¡œë„ ë°±ë„ì–´ íŠ¸ë¦¬ê±°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì§€ì—­í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 02:18:59*