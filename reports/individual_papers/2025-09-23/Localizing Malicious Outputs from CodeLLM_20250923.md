---
keywords:
  - Large Language Model
  - FreqRank
  - Backdoor Triggers
  - Mutation-Based Defense
category: cs.LG
publish_date: 2025-09-23
arxiv_id: 2509.17070
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T02:18:59.616638",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "FreqRank",
    "Backdoor Triggers",
    "Mutation-Based Defense"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "FreqRank": 0.88,
    "Backdoor Triggers": 0.82,
    "Mutation-Based Defense": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "LLM",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Large Language Models"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are central to the paper's discussion on detecting malicious outputs.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "FreqRank",
        "canonical": "FreqRank",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "FreqRank is a novel method introduced in the paper for localizing malicious components.",
        "novelty_score": 0.95,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.88
      },
      {
        "surface": "backdoor triggers",
        "canonical": "Backdoor Triggers",
        "aliases": [
          "backdoor trigger"
        ],
        "category": "specific_connectable",
        "rationale": "Backdoor triggers are a key concept for understanding the malicious behavior in models.",
        "novelty_score": 0.6,
        "connectivity_score": 0.78,
        "specificity_score": 0.8,
        "link_intent_score": 0.82
      },
      {
        "surface": "mutation-based defense",
        "canonical": "Mutation-Based Defense",
        "aliases": [
          "mutation defense"
        ],
        "category": "unique_technical",
        "rationale": "This is a specific defense strategy proposed in the paper, relevant for understanding the methodology.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.75,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "malicious outputs",
      "attack success rate"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "LLM",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "FreqRank",
      "resolved_canonical": "FreqRank",
      "decision": "linked",
      "scores": {
        "novelty": 0.95,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "backdoor triggers",
      "resolved_canonical": "Backdoor Triggers",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.78,
        "specificity": 0.8,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "mutation-based defense",
      "resolved_canonical": "Mutation-Based Defense",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.75,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# Localizing Malicious Outputs from CodeLLM

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17070.pdf)
**Category**: cs.LG
**Published**: 2025-09-23
**ArXiv ID**: [2509.17070](https://arxiv.org/abs/2509.17070)

## 🔗 유사한 논문
- [[2025-09-22/Inverting Trojans in LLMs_20250922|Inverting Trojans in LLMs]] (84.4% similar)
- [[2025-09-18/Evaluating and Improving the Robustness of Security Attack Detectors Generated by LLMs_20250918|Evaluating and Improving the Robustness of Security Attack Detectors Generated by LLMs]] (83.8% similar)
- [[2025-09-23/FC-Attack_ Jailbreaking Multimodal Large Language Models via Auto-Generated Flowcharts_20250923|FC-Attack: Jailbreaking Multimodal Large Language Models via Auto-Generated Flowcharts]] (81.7% similar)
- [[2025-09-17/Beyond Classification_ Evaluating LLMs for Fine-Grained Automatic Malware Behavior Auditing_20250917|Beyond Classification: Evaluating LLMs for Fine-Grained Automatic Malware Behavior Auditing]] (81.5% similar)
- [[2025-09-22/Backdoor Mitigation via Invertible Pruning Masks_20250922|Backdoor Mitigation via Invertible Pruning Masks]] (81.5% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Backdoor Triggers|Backdoor Triggers]]
**⚡ Unique Technical**: [[keywords/FreqRank|FreqRank]], [[keywords/Mutation-Based Defense|Mutation-Based Defense]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.17070v1 Announce Type: cross 
Abstract: We introduce FreqRank, a mutation-based defense to localize malicious components in LLM outputs and their corresponding backdoor triggers. FreqRank assumes that the malicious sub-string(s) consistently appear in outputs for triggered inputs and uses a frequency-based ranking system to identify them. Our ranking system then leverages this knowledge to localize the backdoor triggers present in the inputs. We create nine malicious models through fine-tuning or custom instructions for three downstream tasks, namely, code completion (CC), code generation (CG), and code summarization (CS), and show that they have an average attack success rate (ASR) of 86.6%. Furthermore, FreqRank's ranking system highlights the malicious outputs as one of the top five suggestions in 98% of cases. We also demonstrate that FreqRank's effectiveness scales as the number of mutants increases and show that FreqRank is capable of localizing the backdoor trigger effectively even with a limited number of triggered samples. Finally, we show that our approach is 35-50% more effective than other defense methods.

## 📝 요약

FreqRank는 LLM 출력에서 악성 구성 요소와 백도어 트리거를 식별하는 돌연변이 기반 방어 기법입니다. 악성 문자열이 트리거된 입력에서 일관되게 나타난다는 가정 하에, 빈도 기반 랭킹 시스템을 통해 이를 식별합니다. 이를 통해 입력에 존재하는 백도어 트리거를 찾아냅니다. 코드 완성, 코드 생성, 코드 요약의 세 가지 작업에 대해 9개의 악성 모델을 생성하여 평균 공격 성공률이 86.6%임을 보였습니다. FreqRank는 악성 출력을 상위 다섯 개 제안 중 하나로 98%의 경우에 강조하며, 돌연변이 수가 증가할수록 효과가 증가합니다. 제한된 트리거 샘플로도 백도어 트리거를 효과적으로 식별할 수 있으며, 다른 방어 방법보다 35-50% 더 효과적입니다.

## 🎯 주요 포인트

- 1. FreqRank는 LLM 출력에서 악성 구성 요소와 백도어 트리거를 식별하는 변이 기반 방어 기법입니다.
- 2. FreqRank는 빈도 기반 랭킹 시스템을 사용하여 트리거된 입력에서 일관되게 나타나는 악성 하위 문자열을 식별합니다.
- 3. FreqRank는 코드 완성, 코드 생성, 코드 요약의 세 가지 다운스트림 작업을 통해 평균 86.6%의 공격 성공률을 보이는 9개의 악성 모델을 생성했습니다.
- 4. FreqRank의 랭킹 시스템은 98%의 경우에서 악성 출력을 상위 다섯 가지 제안 중 하나로 강조합니다.
- 5. FreqRank는 다른 방어 방법보다 35-50% 더 효과적이며, 제한된 수의 트리거 샘플로도 백도어 트리거를 효과적으로 지역화할 수 있습니다.


---

*Generated on 2025-09-24 02:18:59*