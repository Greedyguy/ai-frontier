---
keywords:
  - Large Language Model
  - Tibetan Language Understanding Evaluation Benchmark
  - Multi-task Understanding Benchmark
  - Safety Benchmark
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2503.12051
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:53:05.865817",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Tibetan Language Understanding Evaluation Benchmark",
    "Multi-task Understanding Benchmark",
    "Safety Benchmark"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Tibetan Language Understanding Evaluation Benchmark": 0.88,
    "Multi-task Understanding Benchmark": 0.8,
    "Safety Benchmark": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are central to the paper's focus on evaluating language understanding capabilities.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Tibetan Language Understanding Evaluation Benchmark",
        "canonical": "Tibetan Language Understanding Evaluation Benchmark",
        "aliases": [
          "TLUE"
        ],
        "category": "unique_technical",
        "rationale": "TLUE is a unique benchmark introduced in the paper, crucial for linking Tibetan language evaluation efforts.",
        "novelty_score": 0.92,
        "connectivity_score": 0.7,
        "specificity_score": 0.9,
        "link_intent_score": 0.88
      },
      {
        "surface": "multi-task understanding benchmark",
        "canonical": "Multi-task Understanding Benchmark",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "This benchmark is a key component of TLUE, relevant for linking multi-task evaluation methods.",
        "novelty_score": 0.58,
        "connectivity_score": 0.75,
        "specificity_score": 0.78,
        "link_intent_score": 0.8
      },
      {
        "surface": "safety benchmark",
        "canonical": "Safety Benchmark",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "The safety benchmark is a distinct aspect of TLUE, important for linking safety evaluation in language models.",
        "novelty_score": 0.6,
        "connectivity_score": 0.72,
        "specificity_score": 0.76,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "evaluation",
      "benchmark",
      "language model"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Tibetan Language Understanding Evaluation Benchmark",
      "resolved_canonical": "Tibetan Language Understanding Evaluation Benchmark",
      "decision": "linked",
      "scores": {
        "novelty": 0.92,
        "connectivity": 0.7,
        "specificity": 0.9,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "multi-task understanding benchmark",
      "resolved_canonical": "Multi-task Understanding Benchmark",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.75,
        "specificity": 0.78,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "safety benchmark",
      "resolved_canonical": "Safety Benchmark",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.72,
        "specificity": 0.76,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# TLUE: A Tibetan Language Understanding Evaluation Benchmark

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2503.12051.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2503.12051](https://arxiv.org/abs/2503.12051)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Ticket-Bench_ A Kickoff for Multilingual and Regionalized Agent Evaluation_20250919|Ticket-Bench: A Kickoff for Multilingual and Regionalized Agent Evaluation]] (82.9% similar)
- [[2025-09-23/EquiBench_ Benchmarking Large Language Models' Reasoning about Program Semantics via Equivalence Checking_20250923|EquiBench: Benchmarking Large Language Models' Reasoning about Program Semantics via Equivalence Checking]] (82.4% similar)
- [[2025-09-19/Rationality Check! Benchmarking the Rationality of Large Language Models_20250919|Rationality Check! Benchmarking the Rationality of Large Language Models]] (82.4% similar)
- [[2025-09-22/MUG-Eval_ A Proxy Evaluation Framework for Multilingual Generation Capabilities in Any Language_20250922|MUG-Eval: A Proxy Evaluation Framework for Multilingual Generation Capabilities in Any Language]] (82.2% similar)
- [[2025-09-23/TMD-TTS_ A Unified Tibetan Multi-Dialect Text-to-Speech Synthesis for \"U-Tsang, Amdo and Kham Speech Dataset Generation_20250923|TMD-TTS: A Unified Tibetan Multi-Dialect Text-to-Speech Synthesis for \"U-Tsang, Amdo and Kham Speech Dataset Generation]] (82.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Multi-task Understanding Benchmark|Multi-task Understanding Benchmark]], [[keywords/Safety Benchmark|Safety Benchmark]]
**âš¡ Unique Technical**: [[keywords/Tibetan Language Understanding Evaluation Benchmark|Tibetan Language Understanding Evaluation Benchmark]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2503.12051v4 Announce Type: replace 
Abstract: Large language models have made tremendous progress in recent years, but low-resource languages, like Tibetan, remain significantly underrepresented in their evaluation. Despite Tibetan being spoken by over seven million people, it has largely been neglected in the development and assessment of large language models. To address this gap, we present a \textbf{T}ibetan \textbf{L}anguage \textbf{U}nderstanding \textbf{E}valuation Benchmark, \textbf{TLUE}, the first large-scale benchmark for measuring the proficiency of LLMs in the Tibetan language. \textbf{TLUE} comprises two major components: a comprehensive multi-task understanding benchmark spanning 5 domains and 67 subdomains, and a safety benchmark encompassing 7 subdomains. Then, we evaluate a diverse set of state-of-the-art large language models. Experimental results demonstrate that most large language models perform below the random baseline, highlighting the considerable challenges they face in Tibetan language processing. \textbf{TLUE} provides a crucial foundation for advancing future research in Tibetan language understanding and highlights the importance of promoting greater inclusivity in the development of large language models.

## ğŸ“ ìš”ì•½

ìµœê·¼ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ ë°œì „ì—ë„ ë¶ˆêµ¬í•˜ê³  í‹°ë² íŠ¸ì–´ì™€ ê°™ì€ ì €ìì› ì–¸ì–´ëŠ” í‰ê°€ì—ì„œ í¬ê²Œ ì†Œì™¸ë˜ì–´ ì™”ìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ í‹°ë² íŠ¸ì–´ ëŠ¥ë ¥ì„ ì¸¡ì •í•˜ëŠ” ìµœì´ˆì˜ ëŒ€ê·œëª¨ ë²¤ì¹˜ë§ˆí¬ì¸ TLUEë¥¼ ì œì‹œí•©ë‹ˆë‹¤. TLUEëŠ” 5ê°œ ë„ë©”ì¸ê³¼ 67ê°œ í•˜ìœ„ ë„ë©”ì¸ì— ê±¸ì¹œ ë‹¤ì¤‘ ì‘ì—… ì´í•´ ë²¤ì¹˜ë§ˆí¬ì™€ 7ê°œ í•˜ìœ„ ë„ë©”ì¸ì˜ ì•ˆì „ì„± ë²¤ì¹˜ë§ˆí¬ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. ë‹¤ì–‘í•œ ìµœì‹  ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì„ í‰ê°€í•œ ê²°ê³¼, ëŒ€ë¶€ë¶„ì˜ ëª¨ë¸ì´ ë¬´ì‘ìœ„ ê¸°ì¤€ë³´ë‹¤ ë‚®ì€ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë©°, ì´ëŠ” í‹°ë² íŠ¸ì–´ ì²˜ë¦¬ì˜ ì–´ë ¤ì›€ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. TLUEëŠ” í‹°ë² íŠ¸ì–´ ì´í•´ ì—°êµ¬ì˜ ë°œì „ì„ ìœ„í•œ ì¤‘ìš”í•œ ê¸°ì´ˆë¥¼ ì œê³µí•˜ë©°, ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ ê°œë°œì—ì„œ í¬ìš©ì„±ì„ ë†’ì´ëŠ” ê²ƒì˜ ì¤‘ìš”ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. í‹°ë² íŠ¸ì–´ëŠ” 700ë§Œ ëª… ì´ìƒì´ ì‚¬ìš©í•˜ëŠ” ì–¸ì–´ì„ì—ë„ ë¶ˆêµ¬í•˜ê³  ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ í‰ê°€ì—ì„œ í¬ê²Œ ì†Œì™¸ë˜ì–´ ì™”ìŠµë‹ˆë‹¤.
- 2. í‹°ë² íŠ¸ì–´ ì´í•´ í‰ê°€ ë²¤ì¹˜ë§ˆí¬(TLUE)ëŠ” í‹°ë² íŠ¸ì–´ì—ì„œ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ ëŠ¥ë ¥ì„ ì¸¡ì •í•˜ê¸° ìœ„í•œ ìµœì´ˆì˜ ëŒ€ê·œëª¨ ë²¤ì¹˜ë§ˆí¬ì…ë‹ˆë‹¤.
- 3. TLUEëŠ” 5ê°œ ë„ë©”ì¸ê³¼ 67ê°œ í•˜ìœ„ ë„ë©”ì¸ì„ ì•„ìš°ë¥´ëŠ” ì¢…í•©ì ì¸ ë‹¤ì¤‘ ì‘ì—… ì´í•´ ë²¤ì¹˜ë§ˆí¬ì™€ 7ê°œ í•˜ìœ„ ë„ë©”ì¸ì„ í¬í•¨í•˜ëŠ” ì•ˆì „ì„± ë²¤ì¹˜ë§ˆí¬ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
- 4. ì‹¤í—˜ ê²°ê³¼, ëŒ€ë¶€ë¶„ì˜ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì´ ë¬´ì‘ìœ„ ê¸°ì¤€ë³´ë‹¤ ë‚®ì€ ì„±ëŠ¥ì„ ë³´ì´ë©°, í‹°ë² íŠ¸ì–´ ì²˜ë¦¬ì—ì„œ ìƒë‹¹í•œ ì–´ë ¤ì›€ì„ ê²ªê³  ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
- 5. TLUEëŠ” í‹°ë² íŠ¸ì–´ ì´í•´ ì—°êµ¬ë¥¼ ë°œì „ì‹œí‚¤ê¸° ìœ„í•œ ì¤‘ìš”í•œ ê¸°ë°˜ì„ ì œê³µí•˜ë©°, ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ ê°œë°œì—ì„œ ë” í° í¬ìš©ì„±ì„ ì´‰ì§„í•˜ëŠ” ê²ƒì˜ ì¤‘ìš”ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 03:53:05*