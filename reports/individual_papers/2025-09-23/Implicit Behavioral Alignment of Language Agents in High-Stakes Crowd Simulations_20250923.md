---
keywords:
  - Generative Agents
  - Behavior-Realism Gap
  - PEBA
  - PersonaEvolve
  - Large Language Model
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.16457
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T23:21:07.135416",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Generative Agents",
    "Behavior-Realism Gap",
    "PEBA",
    "PersonaEvolve",
    "Large Language Model"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Generative Agents": 0.78,
    "Behavior-Realism Gap": 0.77,
    "PEBA": 0.8,
    "PersonaEvolve": 0.82,
    "Large Language Model": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Language-driven generative agents",
        "canonical": "Generative Agents",
        "aliases": [
          "Language Agents",
          "Generative Language Agents"
        ],
        "category": "unique_technical",
        "rationale": "This concept is central to the paper's focus on social simulations and aligns with the novel framework proposed.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Behavior-Realism Gap",
        "canonical": "Behavior-Realism Gap",
        "aliases": [
          "Behavior Gap",
          "Realism Gap"
        ],
        "category": "unique_technical",
        "rationale": "Identifying and addressing this gap is a key contribution of the paper, offering a new perspective on agent behavior.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      },
      {
        "surface": "Persona-Environment Behavioral Alignment",
        "canonical": "PEBA",
        "aliases": [
          "Persona-Environment Alignment",
          "Behavioral Alignment"
        ],
        "category": "unique_technical",
        "rationale": "PEBA is a novel framework introduced in the paper, crucial for understanding the proposed alignment method.",
        "novelty_score": 0.9,
        "connectivity_score": 0.7,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "PersonaEvolve",
        "canonical": "PersonaEvolve",
        "aliases": [
          "PEvo"
        ],
        "category": "unique_technical",
        "rationale": "As the proposed algorithm, it is central to the paper's methodology and results.",
        "novelty_score": 0.85,
        "connectivity_score": 0.75,
        "specificity_score": 0.88,
        "link_intent_score": 0.82
      },
      {
        "surface": "Large Language Model",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "LLMs are foundational to the paper's approach, providing the basis for the proposed algorithm.",
        "novelty_score": 0.4,
        "connectivity_score": 0.9,
        "specificity_score": 0.5,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "method",
      "simulation",
      "framework"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Language-driven generative agents",
      "resolved_canonical": "Generative Agents",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Behavior-Realism Gap",
      "resolved_canonical": "Behavior-Realism Gap",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Persona-Environment Behavioral Alignment",
      "resolved_canonical": "PEBA",
      "decision": "linked",
      "scores": {
        "novelty": 0.9,
        "connectivity": 0.7,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "PersonaEvolve",
      "resolved_canonical": "PersonaEvolve",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.75,
        "specificity": 0.88,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Large Language Model",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.9,
        "specificity": 0.5,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# Implicit Behavioral Alignment of Language Agents in High-Stakes Crowd Simulations

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16457.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.16457](https://arxiv.org/abs/2509.16457)

## 🔗 유사한 논문
- [[2025-09-22/PILOT_ Steering Synthetic Data Generation with Psychological & Linguistic Output Targeting_20250922|PILOT: Steering Synthetic Data Generation with Psychological & Linguistic Output Targeting]] (84.5% similar)
- [[2025-09-22/P2VA_ Converting Persona Descriptions into Voice Attributes for Fair and Controllable Text-to-Speech_20250922|P2VA: Converting Persona Descriptions into Voice Attributes for Fair and Controllable Text-to-Speech]] (83.8% similar)
- [[2025-09-18/Programmable Cognitive Bias in Social Agents_20250918|Programmable Cognitive Bias in Social Agents]] (82.9% similar)
- [[2025-09-22/Personalized Language Models via Privacy-Preserving Evolutionary Model Merging_20250922|Personalized Language Models via Privacy-Preserving Evolutionary Model Merging]] (82.6% similar)
- [[2025-09-18/$Agent^2$_ An Agent-Generates-Agent Framework for Reinforcement Learning Automation_20250918|$Agent^2$: An Agent-Generates-Agent Framework for Reinforcement Learning Automation]] (82.5% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**⚡ Unique Technical**: [[keywords/Generative Agents|Generative Agents]], [[keywords/Behavior-Realism Gap|Behavior-Realism Gap]], [[keywords/PEBA|PEBA]], [[keywords/PersonaEvolve|PersonaEvolve]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.16457v1 Announce Type: cross 
Abstract: Language-driven generative agents have enabled large-scale social simulations with transformative uses, from interpersonal training to aiding global policy-making. However, recent studies indicate that generative agent behaviors often deviate from expert expectations and real-world data--a phenomenon we term the Behavior-Realism Gap. To address this, we introduce a theoretical framework called Persona-Environment Behavioral Alignment (PEBA), formulated as a distribution matching problem grounded in Lewin's behavior equation stating that behavior is a function of the person and their environment. Leveraging PEBA, we propose PersonaEvolve (PEvo), an LLM-based optimization algorithm that iteratively refines agent personas, implicitly aligning their collective behaviors with realistic expert benchmarks within a specified environmental context. We validate PEvo in an active shooter incident simulation we developed, achieving an 84% average reduction in distributional divergence compared to no steering and a 34% improvement over explicit instruction baselines. Results also show PEvo-refined personas generalize to novel, related simulation scenarios. Our method greatly enhances behavioral realism and reliability in high-stakes social simulations. More broadly, the PEBA-PEvo framework provides a principled approach to developing trustworthy LLM-driven social simulations.

## 📝 요약

이 논문은 언어 기반 생성 에이전트를 활용한 대규모 사회 시뮬레이션에서 발생하는 행동-현실성 격차 문제를 해결하기 위해 PEBA라는 이론적 프레임워크를 제안합니다. 이는 Lewin의 행동 방정식에 기반하여 에이전트의 행동을 환경과 조화롭게 맞추는 것을 목표로 합니다. 이를 바탕으로 개발된 PersonaEvolve(PEvo) 알고리즘은 에이전트의 페르소나를 최적화하여 현실적인 전문가 기준에 부합하도록 합니다. 이 방법은 모의 총기 난사 사건 시뮬레이션에서 84%의 행동 분포 차이를 줄였으며, 다른 시뮬레이션에서도 일반화 가능성을 보였습니다. PEBA-PEvo 프레임워크는 신뢰할 수 있는 사회 시뮬레이션 개발에 기여합니다.

## 🎯 주요 포인트

- 1. 언어 기반 생성 에이전트의 행동이 전문가 기대치 및 실제 데이터와 종종 불일치하는 "행동-현실 격차" 문제를 해결하기 위해 PEBA 이론적 프레임워크를 도입했습니다.
- 2. PEBA는 Lewin의 행동 방정식을 기반으로 한 분포 매칭 문제로, 개인과 환경의 함수로서 행동을 설명합니다.
- 3. 제안된 PersonaEvolve(PEvo) 알고리즘은 에이전트의 페르소나를 반복적으로 개선하여, 환경적 맥락 내에서 전문가 벤치마크와의 행동 일치를 강화합니다.
- 4. PEvo는 활발한 총격 사건 시뮬레이션에서 84%의 평균 분포적 차이 감소 및 명시적 지침 기준 대비 34%의 개선을 달성했습니다.
- 5. PEvo로 개선된 페르소나는 새로운 관련 시뮬레이션 시나리오에도 일반화되며, 높은 신뢰성을 갖춘 사회 시뮬레이션 개발에 기여합니다.


---

*Generated on 2025-09-23 23:21:07*