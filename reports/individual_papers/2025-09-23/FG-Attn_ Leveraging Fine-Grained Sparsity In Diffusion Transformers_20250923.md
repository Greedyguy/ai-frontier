---
keywords:
  - Transformer
  - FG-Attn
  - Attention Mechanism
  - Video Diffusion Models
category: cs.CV
publish_date: 2025-09-23
arxiv_id: 2509.16518
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T04:25:54.580041",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Transformer",
    "FG-Attn",
    "Attention Mechanism",
    "Video Diffusion Models"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Transformer": 0.8,
    "FG-Attn": 0.7,
    "Attention Mechanism": 0.78,
    "Video Diffusion Models": 0.68
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Diffusion Transformers",
        "canonical": "Transformer",
        "aliases": [
          "Diffusion Transformer"
        ],
        "category": "broad_technical",
        "rationale": "This connects to the broader concept of Transformers, which are central to the paper's focus on video generation.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.8
      },
      {
        "surface": "FG-Attn",
        "canonical": "FG-Attn",
        "aliases": [
          "Fine-Grained Attention"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel attention mechanism specific to the paper, enhancing understanding of fine-grained sparsity.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.7
      },
      {
        "surface": "Sparse Attention Mechanism",
        "canonical": "Attention Mechanism",
        "aliases": [
          "Sparse Attention"
        ],
        "category": "specific_connectable",
        "rationale": "Links to the concept of Attention Mechanism, a key component in neural network architectures.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.78
      },
      {
        "surface": "Video Diffusion Models",
        "canonical": "Video Diffusion Models",
        "aliases": [
          "Video Diffusion"
        ],
        "category": "unique_technical",
        "rationale": "Specifically addresses the application of diffusion models in video generation, a unique aspect of the paper.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.68
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Diffusion Transformers",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "FG-Attn",
      "resolved_canonical": "FG-Attn",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Sparse Attention Mechanism",
      "resolved_canonical": "Attention Mechanism",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Video Diffusion Models",
      "resolved_canonical": "Video Diffusion Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.68
      }
    }
  ]
}
-->

# FG-Attn: Leveraging Fine-Grained Sparsity In Diffusion Transformers

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16518.pdf)
**Category**: cs.CV
**Published**: 2025-09-23
**ArXiv ID**: [2509.16518](https://arxiv.org/abs/2509.16518)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-17/BWCache_ Accelerating Video Diffusion Transformers through Block-Wise Caching_20250917|BWCache: Accelerating Video Diffusion Transformers through Block-Wise Caching]] (84.3% similar)
- [[2025-09-23/70% Size, 100% Accuracy_ Lossless LLM Compression for Efficient GPU Inference via Dynamic-Length Float_20250923|70% Size, 100% Accuracy: Lossless LLM Compression for Efficient GPU Inference via Dynamic-Length Float]] (83.0% similar)
- [[2025-09-22/G2D2_ Gradient-Guided Discrete Diffusion for Inverse Problem Solving_20250922|G2D2: Gradient-Guided Discrete Diffusion for Inverse Problem Solving]] (82.4% similar)
- [[2025-09-22/LowDiff_ Efficient Diffusion Sampling with Low-Resolution Condition_20250922|LowDiff: Efficient Diffusion Sampling with Low-Resolution Condition]] (82.3% similar)
- [[2025-09-23/Optimizing Inference in Transformer-Based Models_ A Multi-Method Benchmark_20250923|Optimizing Inference in Transformer-Based Models: A Multi-Method Benchmark]] (81.9% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Transformer|Transformer]]
**ğŸ”— Specific Connectable**: [[keywords/Attention Mechanism|Attention Mechanism]]
**âš¡ Unique Technical**: [[keywords/FG-Attn|FG-Attn]], [[keywords/Video Diffusion Models|Video Diffusion Models]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16518v1 Announce Type: new 
Abstract: Generating realistic videos with diffusion transformers demands significant computation, with attention layers the central bottleneck; even producing a short clip requires running a transformer over a very long sequence of embeddings, e.g., more than 30K embeddings for a 5-second video, incurring significant latency. Prior work aims to mitigate this bottleneck by exploiting sparsity in the attention layers to reduce computation. However, these works typically rely on block-sparse attention, which skips score computation only when all entries in a block of attention scores (corresponding to M queries and M keys, with M = 64 typically) are zero. This coarse-granular skipping of attention scores does not fully exploit sparsity in the attention map and leaves room for improvement. In this work, we propose FG-Attn, a sparse attention mechanism for long-context diffusion transformers that leverages sparsity at a fine granularity. Unlike block-sparse attention, which skips entire MxM blocks, our approach skips computations at the granularity of Mx1 slices of the attention map. Each slice is produced by query-key dot products between a block of query vectors and a single key. To implement our proposed sparse attention mechanism, we develop a new efficient bulk-load operation called asynchronous-gather load. This load operation gathers a sparse set of relevant key-value vectors from memory and arranges them into packed tiles in the GPU's shared memory. Only a sparse set of keys relevant to those queries are loaded into shared memory when computing attention for a block of queries, in contrast to loading full blocks of key tokens in block-sparse attention. Our fine-grained sparse attention, applied to video diffusion models, achieves an average 1.55X (up to 1.65X) speedup for 5 second, 480p videos, and an average 1.41X (up to 1.49X) for 5 second, 720p videos on a single H100 GPU.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ê¸´ ë¬¸ë§¥ì„ ì²˜ë¦¬í•˜ëŠ” í™•ì‚° ë³€í™˜ê¸°ì—ì„œ ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì˜ ê³„ì‚°ëŸ‰ì„ ì¤„ì´ê¸° ìœ„í•œ FG-Attnì´ë¼ëŠ” ì„¸ë°€í•œ í¬ì†Œ ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë¸”ë¡ í¬ì†Œ ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì€ MxM ë¸”ë¡ ë‹¨ìœ„ë¡œ ê³„ì‚°ì„ ê±´ë„ˆë›°ì§€ë§Œ, FG-Attnì€ Mx1 ìŠ¬ë¼ì´ìŠ¤ ë‹¨ìœ„ë¡œ ê³„ì‚°ì„ ê±´ë„ˆë›°ì–´ ë” ì„¸ë°€í•˜ê²Œ í¬ì†Œì„±ì„ í™œìš©í•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ë¹„ë™ê¸° ìˆ˜ì§‘ ë¡œë“œë¼ëŠ” ìƒˆë¡œìš´ íš¨ìœ¨ì  ë¡œë“œ ì‘ì—…ì„ ê°œë°œí•˜ì—¬, ê´€ë ¨ í‚¤-ê°’ ë²¡í„°ë§Œì„ GPUì˜ ê³µìœ  ë©”ëª¨ë¦¬ì— ë¶ˆëŸ¬ì˜µë‹ˆë‹¤. ì´ ë°©ë²•ì€ 5ì´ˆ ê¸¸ì´ì˜ 480p ë¹„ë””ì˜¤ì—ì„œ í‰ê·  1.55ë°°, 720p ë¹„ë””ì˜¤ì—ì„œ í‰ê·  1.41ë°°ì˜ ì†ë„ í–¥ìƒì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. FG-Attnì€ ê¸´ ë¬¸ë§¥ì„ ì²˜ë¦¬í•˜ëŠ” í™•ì‚° ë³€í™˜ê¸°ì—ì„œ ì„¸ë°€í•œ ìˆ˜ì¤€ì˜ í¬ì†Œì„±ì„ í™œìš©í•˜ì—¬ ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì˜ íš¨ìœ¨ì„±ì„ ê°œì„ í•©ë‹ˆë‹¤.
- 2. ê¸°ì¡´ì˜ ë¸”ë¡ í¬ì†Œ ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ê³¼ ë‹¬ë¦¬, FG-Attnì€ Mx1 ìŠ¬ë¼ì´ìŠ¤ ë‹¨ìœ„ë¡œ ê³„ì‚°ì„ ê±´ë„ˆë›°ì–´ ì£¼ì˜ ë§µì˜ í¬ì†Œì„±ì„ ë” ì˜ í™œìš©í•©ë‹ˆë‹¤.
- 3. ë¹„ë™ê¸° ìˆ˜ì§‘ ë¡œë“œë¼ëŠ” ìƒˆë¡œìš´ íš¨ìœ¨ì ì¸ ë²Œí¬ ë¡œë“œ ì‘ì—…ì„ ê°œë°œí•˜ì—¬, ë©”ëª¨ë¦¬ì—ì„œ ê´€ë ¨ í‚¤-ê°’ ë²¡í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  GPUì˜ ê³µìœ  ë©”ëª¨ë¦¬ì— ë°°ì¹˜í•©ë‹ˆë‹¤.
- 4. FG-Attnì„ ë¹„ë””ì˜¤ í™•ì‚° ëª¨ë¸ì— ì ìš©í•˜ë©´, 5ì´ˆ ê¸¸ì´ì˜ 480p ë¹„ë””ì˜¤ì—ì„œ í‰ê·  1.55ë°°(ìµœëŒ€ 1.65ë°°), 720p ë¹„ë””ì˜¤ì—ì„œ í‰ê·  1.41ë°°(ìµœëŒ€ 1.49ë°°) ì†ë„ í–¥ìƒì„ ë‹¬ì„±í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 04:25:54*