---
keywords:
  - Multimodal Learning
  - OCR Hallucination
  - Vision-Faithful Reasoning
  - Reinforcement Learning
  - KIE-HVQA Benchmark
category: cs.CV
publish_date: 2025-09-23
arxiv_id: 2506.20168
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T05:25:35.164357",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multimodal Learning",
    "OCR Hallucination",
    "Vision-Faithful Reasoning",
    "Reinforcement Learning",
    "KIE-HVQA Benchmark"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multimodal Learning": 0.82,
    "OCR Hallucination": 0.78,
    "Vision-Faithful Reasoning": 0.77,
    "Reinforcement Learning": 0.7,
    "KIE-HVQA Benchmark": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "multimodal large language models",
        "canonical": "Multimodal Learning",
        "aliases": [
          "multimodal LLMs"
        ],
        "category": "specific_connectable",
        "rationale": "This term connects advancements in integrating textual and visual information, linking to broader multimodal research.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.82
      },
      {
        "surface": "OCR hallucination",
        "canonical": "OCR Hallucination",
        "aliases": [
          "optical character recognition hallucination"
        ],
        "category": "unique_technical",
        "rationale": "This unique phenomenon is central to the paper's focus on visual degradation and model accuracy.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "vision-faithful reasoning",
        "canonical": "Vision-Faithful Reasoning",
        "aliases": [
          "accurate visual reasoning"
        ],
        "category": "unique_technical",
        "rationale": "This concept is key to understanding how models can avoid hallucinations by accurately interpreting visual data.",
        "novelty_score": 0.68,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      },
      {
        "surface": "reinforcement learning framework",
        "canonical": "Reinforcement Learning",
        "aliases": [
          "RL framework"
        ],
        "category": "broad_technical",
        "rationale": "Reinforcement learning is a foundational technique applied to improve model performance in the study.",
        "novelty_score": 0.4,
        "connectivity_score": 0.85,
        "specificity_score": 0.65,
        "link_intent_score": 0.7
      },
      {
        "surface": "KIE-HVQA",
        "canonical": "KIE-HVQA Benchmark",
        "aliases": [
          "KIE-HVQA dataset"
        ],
        "category": "unique_technical",
        "rationale": "This benchmark is a novel contribution of the paper, essential for evaluating OCR hallucination.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.9,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "document understanding",
      "visual degradation",
      "linguistic priors"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "multimodal large language models",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "OCR hallucination",
      "resolved_canonical": "OCR Hallucination",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "vision-faithful reasoning",
      "resolved_canonical": "Vision-Faithful Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "reinforcement learning framework",
      "resolved_canonical": "Reinforcement Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.85,
        "specificity": 0.65,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "KIE-HVQA",
      "resolved_canonical": "KIE-HVQA Benchmark",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.9,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Seeing is Believing? Mitigating OCR Hallucinations in Multimodal Large Language Models

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2506.20168.pdf)
**Category**: cs.CV
**Published**: 2025-09-23
**ArXiv ID**: [2506.20168](https://arxiv.org/abs/2506.20168)

## 🔗 유사한 논문
- [[2025-09-23/Uncertainty-Aware Attention Heads_ Efficient Unsupervised Uncertainty Quantification for LLMs_20250923|Uncertainty-Aware Attention Heads: Efficient Unsupervised Uncertainty Quantification for LLMs]] (85.8% similar)
- [[2025-09-22/ORCA_ Agentic Reasoning For Hallucination and Adversarial Robustness in Vision-Language Models_20250922|ORCA: Agentic Reasoning For Hallucination and Adversarial Robustness in Vision-Language Models]] (84.8% similar)
- [[2025-09-23/SafeEraser_ Enhancing Safety in Multimodal Large Language Models through Multimodal Machine Unlearning_20250923|SafeEraser: Enhancing Safety in Multimodal Large Language Models through Multimodal Machine Unlearning]] (84.1% similar)
- [[2025-09-23/Eye Gaze Tells You Where to Compute_ Gaze-Driven Efficient VLMs_20250923|Eye Gaze Tells You Where to Compute: Gaze-Driven Efficient VLMs]] (84.0% similar)
- [[2025-09-22/EyePCR_ A Comprehensive Benchmark for Fine-Grained Perception, Knowledge Comprehension and Clinical Reasoning in Ophthalmic Surgery_20250922|EyePCR: A Comprehensive Benchmark for Fine-Grained Perception, Knowledge Comprehension and Clinical Reasoning in Ophthalmic Surgery]] (83.8% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Reinforcement Learning|Reinforcement Learning]]
**🔗 Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**⚡ Unique Technical**: [[keywords/OCR Hallucination|OCR Hallucination]], [[keywords/Vision-Faithful Reasoning|Vision-Faithful Reasoning]], [[keywords/KIE-HVQA Benchmark|KIE-HVQA Benchmark]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2506.20168v2 Announce Type: replace 
Abstract: Recent advancements in multimodal large language models have enhanced document understanding by integrating textual and visual information. However, existing models exhibit incompleteness within their paradigm in real-world scenarios, particularly under visual degradation. In such conditions, the current response paradigm often fails to adequately perceive visual degradation and ambiguity, leading to overreliance on linguistic priors or misaligned visual-textual reasoning. This difficulty in recognizing uncertainty frequently results in the generation of hallucinatory content, especially when a precise answer is not feasible. To better demonstrate and analyze this phenomenon and problem, we propose KIE-HVQA, the first benchmark dedicated to evaluating OCR hallucination in degraded document understanding. This dataset includes test samples spanning identity cards and invoices, with simulated real-world degradations for OCR reliability. This setup allows for evaluating models' capacity, under degraded input, to distinguish reliable visual information and answer accordingly, thereby highlighting the challenge of avoiding hallucination on uncertain data. To achieve vision-faithful reasoning and thereby avoid the aforementioned issues, we further introduce a GRPO-based framework featuring a novel reward mechanism. By incorporating a self-awareness of visual uncertainty and an analysis method that initiates refusal to answer to increase task difficulty within our supervised fine-tuning and reinforcement learning framework, we successfully mitigated hallucinations in ambiguous regions. Experiments on Qwen2.5-VL demonstrate that our 7B-parameter model achieves a 22\% absolute improvement in hallucination-free accuracy over GPT-4o on KIE-HVQA and there is no significant performance drop in standard tasks, highlighting both effectiveness and robustness.

## 📝 요약

최근 멀티모달 대형 언어 모델의 발전으로 텍스트와 시각 정보를 통합하여 문서 이해가 향상되었습니다. 그러나 시각적 열화가 있는 실제 시나리오에서는 기존 모델이 불완전성을 보입니다. 이러한 상황에서 모델은 시각적 불확실성을 인식하지 못하고 언어적 편향에 의존하거나 시각-텍스트 추론이 잘못되어 환각적 내용을 생성할 수 있습니다. 이를 해결하기 위해, 우리는 열화된 문서 이해에서 OCR 환각을 평가하는 최초의 벤치마크인 KIE-HVQA를 제안합니다. 이 데이터셋은 신분증과 청구서 등의 샘플을 포함하며, OCR 신뢰성을 위한 시뮬레이션된 열화를 제공합니다. 또한, 시각적 불확실성을 인식하고 답변을 거부하는 새로운 보상 메커니즘을 포함한 GRPO 기반 프레임워크를 도입하여 환각을 줄였습니다. 실험 결과, Qwen2.5-VL 모델은 KIE-HVQA에서 GPT-4o 대비 22%의 환각 없는 정확도 향상을 보였으며, 표준 작업에서 성능 저하 없이 효과성과 견고성을 입증했습니다.

## 🎯 주요 포인트

- 1. 멀티모달 대형 언어 모델은 텍스트와 시각 정보를 통합하여 문서 이해를 향상시켰지만, 시각적 열화 상황에서는 불완전함을 드러냅니다.
- 2. 시각적 열화와 모호성을 충분히 인식하지 못해 언어적 선입견에 의존하거나 시각-텍스트 추론이 잘못 정렬되는 문제가 발생합니다.
- 3. KIE-HVQA는 열화된 문서 이해에서 OCR 환각을 평가하기 위한 최초의 벤치마크로, 신분증과 송장을 포함한 테스트 샘플을 제공합니다.
- 4. GRPO 기반 프레임워크와 새로운 보상 메커니즘을 도입하여 시각적 불확실성을 인식하고 답변 거부를 통해 환각을 줄였습니다.
- 5. Qwen2.5-VL 실험 결과, KIE-HVQA에서 GPT-4o 대비 환각 없는 정확도가 22% 향상되었으며, 표준 작업에서 성능 저하가 없음을 확인했습니다.


---

*Generated on 2025-09-24 05:25:35*