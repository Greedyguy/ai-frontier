---
keywords:
  - Machine Unlearning
  - Contrastive Learning
  - Semantic Similarity
  - Supervised Learning
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.16391
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T23:17:41.289773",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Machine Unlearning",
    "Contrastive Learning",
    "Semantic Similarity",
    "Supervised Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Machine Unlearning": 0.88,
    "Contrastive Learning": 0.8,
    "Semantic Similarity": 0.77,
    "Supervised Learning": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Machine Unlearning",
        "canonical": "Machine Unlearning",
        "aliases": [
          "MU"
        ],
        "category": "unique_technical",
        "rationale": "Machine Unlearning is a novel concept central to the paper, enhancing connectivity with discussions on data privacy and model adaptation.",
        "novelty_score": 0.85,
        "connectivity_score": 0.78,
        "specificity_score": 0.82,
        "link_intent_score": 0.88
      },
      {
        "surface": "Contrastive Learning",
        "canonical": "Contrastive Learning",
        "aliases": [
          "CL"
        ],
        "category": "specific_connectable",
        "rationale": "Contrastive Learning is a key technique used in the paper, linking it to broader discussions on representation learning.",
        "novelty_score": 0.65,
        "connectivity_score": 0.84,
        "specificity_score": 0.75,
        "link_intent_score": 0.8
      },
      {
        "surface": "Semantic Similarity",
        "canonical": "Semantic Similarity",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Semantic Similarity is crucial for understanding how the model differentiates between 'retain' and 'forget' data.",
        "novelty_score": 0.6,
        "connectivity_score": 0.79,
        "specificity_score": 0.7,
        "link_intent_score": 0.77
      },
      {
        "surface": "Supervised Learning",
        "canonical": "Supervised Learning",
        "aliases": [],
        "category": "broad_technical",
        "rationale": "Supervised Learning is a fundamental technique applied to retain data, connecting to a wide range of machine learning discussions.",
        "novelty_score": 0.4,
        "connectivity_score": 0.85,
        "specificity_score": 0.65,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "model weight perturbations",
      "label manipulation"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Machine Unlearning",
      "resolved_canonical": "Machine Unlearning",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.78,
        "specificity": 0.82,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "Contrastive Learning",
      "resolved_canonical": "Contrastive Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.84,
        "specificity": 0.75,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Semantic Similarity",
      "resolved_canonical": "Semantic Similarity",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.79,
        "specificity": 0.7,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Supervised Learning",
      "resolved_canonical": "Supervised Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.85,
        "specificity": 0.65,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# CoUn: Empowering Machine Unlearning via Contrastive Learning

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16391.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.16391](https://arxiv.org/abs/2509.16391)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/CUFG_ Curriculum Unlearning Guided by the Forgetting Gradient_20250918|CUFG: Curriculum Unlearning Guided by the Forgetting Gradient]] (86.2% similar)
- [[2025-09-22/Concept Unlearning in Large Language Models via Self-Constructed Knowledge Triplets_20250922|Concept Unlearning in Large Language Models via Self-Constructed Knowledge Triplets]] (85.6% similar)
- [[2025-09-22/ToFU_ Transforming How Federated Learning Systems Forget User Data_20250922|ToFU: Transforming How Federated Learning Systems Forget User Data]] (83.7% similar)
- [[2025-09-17/Scrub It Out! Erasing Sensitive Memorization in Code Language Models via Machine Unlearning_20250917|Scrub It Out! Erasing Sensitive Memorization in Code Language Models via Machine Unlearning]] (83.5% similar)
- [[2025-09-22/Sparse-Autoencoder-Guided Internal Representation Unlearning for Large Language Models_20250922|Sparse-Autoencoder-Guided Internal Representation Unlearning for Large Language Models]] (82.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Supervised Learning|Supervised Learning]]
**ğŸ”— Specific Connectable**: [[keywords/Contrastive Learning|Contrastive Learning]], [[keywords/Semantic Similarity|Semantic Similarity]]
**âš¡ Unique Technical**: [[keywords/Machine Unlearning|Machine Unlearning]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16391v1 Announce Type: cross 
Abstract: Machine unlearning (MU) aims to remove the influence of specific "forget" data from a trained model while preserving its knowledge of the remaining "retain" data. Existing MU methods based on label manipulation or model weight perturbations often achieve limited unlearning effectiveness. To address this, we introduce CoUn, a novel MU framework inspired by the observation that a model retrained from scratch using only retain data classifies forget data based on their semantic similarity to the retain data. CoUn emulates this behavior by adjusting learned data representations through contrastive learning (CL) and supervised learning, applied exclusively to retain data. Specifically, CoUn (1) leverages semantic similarity between data samples to indirectly adjust forget representations using CL, and (2) maintains retain representations within their respective clusters through supervised learning. Extensive experiments across various datasets and model architectures show that CoUn consistently outperforms state-of-the-art MU baselines in unlearning effectiveness. Additionally, integrating our CL module into existing baselines empowers their unlearning effectiveness.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ê¸°ê³„ í•™ìŠµ ëª¨ë¸ì—ì„œ íŠ¹ì • ë°ì´í„°ë¥¼ ìŠê²Œ í•˜ëŠ” 'ê¸°ê³„ ì–¸ëŸ¬ë‹(MU)'ì˜ íš¨ê³¼ë¥¼ ê°œì„ í•˜ê¸° ìœ„í•´ ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ CoUnì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ MU ë°©ë²•ë“¤ì€ ë ˆì´ë¸” ì¡°ì‘ì´ë‚˜ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë³€í™”ë¥¼ ì‚¬ìš©í•˜ì§€ë§Œ, íš¨ê³¼ê°€ ì œí•œì ì…ë‹ˆë‹¤. CoUnì€ ë‚¨ê²¨ì•¼ í•  ë°ì´í„°ë§Œìœ¼ë¡œ ëª¨ë¸ì„ ì¬í›ˆë ¨í–ˆì„ ë•Œ, ìŠì–´ì•¼ í•  ë°ì´í„°ë¥¼ ë‚¨ê²¨ì•¼ í•  ë°ì´í„°ì™€ì˜ ì˜ë¯¸ì  ìœ ì‚¬ì„±ì— ë”°ë¼ ë¶„ë¥˜í•œë‹¤ëŠ” ì ì— ì°©ì•ˆí–ˆìŠµë‹ˆë‹¤. CoUnì€ ëŒ€ì¡° í•™ìŠµê³¼ ì§€ë„ í•™ìŠµì„ í†µí•´ ë‚¨ê²¨ì•¼ í•  ë°ì´í„°ì˜ í‘œí˜„ì„ ì¡°ì •í•˜ì—¬ ì´ë¥¼ ëª¨ë°©í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, CoUnì€ ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ê³¼ ëª¨ë¸ êµ¬ì¡°ì—ì„œ ê¸°ì¡´ì˜ ìµœì²¨ë‹¨ MU ë°©ë²•ë“¤ë³´ë‹¤ ì¼ê´€ë˜ê²Œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë©°, ê¸°ì¡´ ë°©ë²•ì— CL ëª¨ë“ˆì„ í†µí•©í•˜ë©´ ì–¸ëŸ¬ë‹ íš¨ê³¼ê°€ í–¥ìƒë¨ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. CoUnì€ íŠ¹ì • "ìŠì–´ì•¼ í• " ë°ì´í„°ì˜ ì˜í–¥ì„ ì œê±°í•˜ë©´ì„œ "ìœ ì§€í• " ë°ì´í„°ì˜ ì§€ì‹ì„ ë³´ì¡´í•˜ëŠ” ìƒˆë¡œìš´ ê¸°ê³„ í•™ìŠµ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.
- 2. CoUnì€ ëŒ€ì¡° í•™ìŠµê³¼ ì§€ë„ í•™ìŠµì„ í†µí•´ í•™ìŠµëœ ë°ì´í„° í‘œí˜„ì„ ì¡°ì •í•˜ì—¬ ìŠì–´ì•¼ í•  ë°ì´í„°ì˜ í‘œí˜„ì„ ê°„ì ‘ì ìœ¼ë¡œ ì¡°ì •í•©ë‹ˆë‹¤.
- 3. CoUnì€ ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ê³¼ ëª¨ë¸ ì•„í‚¤í…ì²˜ì—ì„œ ê¸°ì¡´ì˜ ìµœì²¨ë‹¨ ê¸°ê³„ í•™ìŠµ ë°©ë²•ë³´ë‹¤ ì¼ê´€ë˜ê²Œ ë” ë†’ì€ ìŠê¸° íš¨ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
- 4. CoUnì˜ ëŒ€ì¡° í•™ìŠµ ëª¨ë“ˆì„ ê¸°ì¡´ì˜ ê¸°ê³„ í•™ìŠµ ë°©ë²•ì— í†µí•©í•˜ë©´ ìŠê¸° íš¨ê³¼ê°€ í–¥ìƒë©ë‹ˆë‹¤.


---

*Generated on 2025-09-23 23:17:41*