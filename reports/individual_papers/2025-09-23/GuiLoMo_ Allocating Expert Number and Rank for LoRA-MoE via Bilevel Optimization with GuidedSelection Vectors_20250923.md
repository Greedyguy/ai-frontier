---
keywords:
  - Low-Rank Adaptation
  - Mixture-of-Experts
  - GuidedSelection Vectors
  - Bilevel Optimization
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2506.14646
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T04:05:37.152540",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Low-Rank Adaptation",
    "Mixture-of-Experts",
    "GuidedSelection Vectors",
    "Bilevel Optimization"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Low-Rank Adaptation": 0.75,
    "Mixture-of-Experts": 0.8,
    "GuidedSelection Vectors": 0.7,
    "Bilevel Optimization": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Low-Rank Adaptation",
        "canonical": "Low-Rank Adaptation",
        "aliases": [
          "LoRA"
        ],
        "category": "unique_technical",
        "rationale": "LoRA is a specific technique for parameter-efficient fine-tuning, crucial for adapting large language models.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      },
      {
        "surface": "Mixture-of-Experts",
        "canonical": "Mixture-of-Experts",
        "aliases": [
          "MoE"
        ],
        "category": "specific_connectable",
        "rationale": "MoE is a significant concept in enhancing model capacity and is relevant for linking with other expert-based methods.",
        "novelty_score": 0.6,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "GuidedSelection Vectors",
        "canonical": "GuidedSelection Vectors",
        "aliases": [
          "GSVs"
        ],
        "category": "unique_technical",
        "rationale": "GSVs are a novel mechanism proposed in the paper for optimizing expert allocation, offering a unique linking opportunity.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.7
      },
      {
        "surface": "Bilevel Optimization",
        "canonical": "Bilevel Optimization",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Bilevel optimization is a key method used in the paper, relevant for linking with optimization techniques.",
        "novelty_score": 0.5,
        "connectivity_score": 0.75,
        "specificity_score": 0.65,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "fine-tuning",
      "performance",
      "backbone models"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Low-Rank Adaptation",
      "resolved_canonical": "Low-Rank Adaptation",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Mixture-of-Experts",
      "resolved_canonical": "Mixture-of-Experts",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "GuidedSelection Vectors",
      "resolved_canonical": "GuidedSelection Vectors",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Bilevel Optimization",
      "resolved_canonical": "Bilevel Optimization",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.75,
        "specificity": 0.65,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# GuiLoMo: Allocating Expert Number and Rank for LoRA-MoE via Bilevel Optimization with GuidedSelection Vectors

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2506.14646.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2506.14646](https://arxiv.org/abs/2506.14646)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Robust Federated Finetuning of LLMs via Alternating Optimization of LoRA_20250923|Robust Federated Finetuning of LLMs via Alternating Optimization of LoRA]] (86.1% similar)
- [[2025-09-23/MoEs Are Stronger than You Think_ Hyper-Parallel Inference Scaling with RoE_20250923|MoEs Are Stronger than You Think: Hyper-Parallel Inference Scaling with RoE]] (85.4% similar)
- [[2025-09-19/Opening the Black Box_ Interpretable LLMs via Semantic Resonance Architecture_20250919|Opening the Black Box: Interpretable LLMs via Semantic Resonance Architecture]] (84.9% similar)
- [[2025-09-17/Mixture of Low-Rank Adapter Experts in Generalizable Audio Deepfake Detection_20250917|Mixture of Low-Rank Adapter Experts in Generalizable Audio Deepfake Detection]] (84.3% similar)
- [[2025-09-23/SparseDoctor_ Towards Efficient Chat Doctor with Mixture of Experts Enhanced Large Language Models_20250923|SparseDoctor: Towards Efficient Chat Doctor with Mixture of Experts Enhanced Large Language Models]] (83.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Mixture-of-Experts|Mixture-of-Experts]], [[keywords/Bilevel Optimization|Bilevel Optimization]]
**âš¡ Unique Technical**: [[keywords/Low-Rank Adaptation|Low-Rank Adaptation]], [[keywords/GuidedSelection Vectors|GuidedSelection Vectors]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2506.14646v2 Announce Type: replace 
Abstract: Parameter-efficient fine-tuning (PEFT) methods, particularly Low-Rank Adaptation (LoRA), offer an efficient way to adapt large language models with reduced computational costs. However, their performance is limited by the small number of trainable parameters. Recent work combines LoRA with the Mixture-of-Experts (MoE), i.e., LoRA-MoE, to enhance capacity, but two limitations remain in hindering the full exploitation of its potential: 1) the influence of downstream tasks when assigning expert numbers, and 2) the uniform rank assignment across all LoRA experts, which restricts representational diversity. To mitigate these gaps, we propose GuiLoMo, a fine-grained layer-wise expert numbers and ranks allocation strategy with GuidedSelection Vectors (GSVs). GSVs are learned via a prior bilevel optimization process to capture both model- and task-specific needs, and are then used to allocate optimal expert numbers and ranks. Experiments on three backbone models across diverse benchmarks show that GuiLoMo consistently achieves superior or comparable performance to all baselines. Further analysis offers key insights into how expert numbers and ranks vary across layers and tasks, highlighting the benefits of adaptive expert configuration. Our code is available at https://github.com/Liar406/Gui-LoMo.git.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì ì‘ì‹œí‚¤ê¸° ìœ„í•œ ë°©ë²•ìœ¼ë¡œ Low-Rank Adaptation (LoRA)ì™€ Mixture-of-Experts (MoE)ë¥¼ ê²°í•©í•œ LoRA-MoEì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ GuiLoMoë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. GuiLoMoëŠ” GuidedSelection Vectors (GSVs)ë¥¼ í†µí•´ ì„¸ë°€í•œ ë ˆì´ì–´ë³„ ì „ë¬¸ê°€ ìˆ˜ì™€ ë­í¬ë¥¼ í• ë‹¹í•˜ì—¬ ëª¨ë¸ê³¼ ì‘ì—…ì˜ íŠ¹ìˆ˜í•œ ìš”êµ¬ë¥¼ ë°˜ì˜í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, GuiLoMoëŠ” ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ê¸°ì¡´ ë°©ë²•ë“¤ê³¼ ë¹„êµí•´ ìš°ìˆ˜í•˜ê±°ë‚˜ ë™ë“±í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë©°, ë ˆì´ì–´ì™€ ì‘ì—…ì— ë”°ë¼ ì „ë¬¸ê°€ ìˆ˜ì™€ ë­í¬ê°€ ì–´ë–»ê²Œ ë³€í™”í•˜ëŠ”ì§€ì— ëŒ€í•œ í†µì°°ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. LoRA-MoEì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ GuiLoMoë¥¼ ì œì•ˆí•˜ì—¬ ë ˆì´ì–´ë³„ ì „ë¬¸ê°€ ìˆ˜ì™€ ìˆœìœ„ë¥¼ ì„¸ë°€í•˜ê²Œ í• ë‹¹í•˜ëŠ” ì „ëµì„ ë„ì…í–ˆìŠµë‹ˆë‹¤.
- 2. GuidedSelection Vectors (GSVs)ë¥¼ í†µí•´ ëª¨ë¸ ë° ì‘ì—…ë³„ ìš”êµ¬ ì‚¬í•­ì„ ë°˜ì˜í•˜ì—¬ ìµœì ì˜ ì „ë¬¸ê°€ ìˆ˜ì™€ ìˆœìœ„ë¥¼ í• ë‹¹í•©ë‹ˆë‹¤.
- 3. GuiLoMoëŠ” ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ê¸°ì¡´ ë°©ë²•ë“¤ê³¼ ë¹„êµí•˜ì—¬ ì¼ê´€ë˜ê²Œ ìš°ìˆ˜í•˜ê±°ë‚˜ ìœ ì‚¬í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
- 4. ì‹¤í—˜ ë¶„ì„ì„ í†µí•´ ë ˆì´ì–´ì™€ ì‘ì—…ì— ë”°ë¼ ì „ë¬¸ê°€ ìˆ˜ì™€ ìˆœìœ„ê°€ ì–´ë–»ê²Œ ë‹¬ë¼ì§€ëŠ”ì§€ì— ëŒ€í•œ ì¤‘ìš”í•œ í†µì°°ì„ ì œê³µí•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 04:05:37*