---
keywords:
  - Multimodal Learning
  - YOLO Model
  - Vision-Language Model
  - Few-Shot Learning
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2506.14629
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T04:17:12.922151",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multimodal Learning",
    "YOLO Model",
    "Vision-Language Model",
    "Few-Shot Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multimodal Learning": 0.85,
    "YOLO Model": 0.78,
    "Vision-Language Model": 0.82,
    "Few-Shot Learning": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multimodal dataset",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal data",
          "Multimodal integration"
        ],
        "category": "specific_connectable",
        "rationale": "Links to the integration of visual and textual data, a key aspect of the study.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "YOLOv9s model",
        "canonical": "YOLO Model",
        "aliases": [
          "YOLOv9s",
          "YOLO"
        ],
        "category": "unique_technical",
        "rationale": "Specific model used for object detection, relevant for technical discussions.",
        "novelty_score": 0.65,
        "connectivity_score": 0.72,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Vision-language models",
        "canonical": "Vision-Language Model",
        "aliases": [
          "Vision-language",
          "LVLMs"
        ],
        "category": "evolved_concepts",
        "rationale": "Represents the integration of vision and language processing, central to the paper's methodology.",
        "novelty_score": 0.58,
        "connectivity_score": 0.85,
        "specificity_score": 0.75,
        "link_intent_score": 0.82
      },
      {
        "surface": "Few-shot settings",
        "canonical": "Few-Shot Learning",
        "aliases": [
          "Few-shot",
          "Few-shot learning"
        ],
        "category": "specific_connectable",
        "rationale": "Highlights the learning approach tested in the study, relevant for linking learning paradigms.",
        "novelty_score": 0.6,
        "connectivity_score": 0.8,
        "specificity_score": 0.78,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "object detection",
      "segmentation precision",
      "BLEU score"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multimodal dataset",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "YOLOv9s model",
      "resolved_canonical": "YOLO Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.72,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Vision-language models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.85,
        "specificity": 0.75,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Few-shot settings",
      "resolved_canonical": "Few-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.8,
        "specificity": 0.78,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# VisText-Mosquito: A Unified Multimodal Benchmark Dataset for Visual Detection, Segmentation, and Textual Reasoning on Mosquito Breeding Sites

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2506.14629.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2506.14629](https://arxiv.org/abs/2506.14629)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/UnifiedVisual_ A Framework for Constructing Unified Vision-Language Datasets_20250919|UnifiedVisual: A Framework for Constructing Unified Vision-Language Datasets]] (81.6% similar)
- [[2025-09-22/Quality-Driven Curation of Remote Sensing Vision-Language Data via Learned Scoring Models_20250922|Quality-Driven Curation of Remote Sensing Vision-Language Data via Learned Scoring Models]] (81.4% similar)
- [[2025-09-19/MedVAL_ Toward Expert-Level Medical Text Validation with Language Models_20250919|MedVAL: Toward Expert-Level Medical Text Validation with Language Models]] (80.8% similar)
- [[2025-09-18/Iterative Prompt Refinement for Safer Text-to-Image Generation_20250918|Iterative Prompt Refinement for Safer Text-to-Image Generation]] (80.8% similar)
- [[2025-09-22/SAR-TEXT_ A Large-Scale SAR Image-Text Dataset Built with SAR-Narrator and Progressive Transfer Learning_20250922|SAR-TEXT: A Large-Scale SAR Image-Text Dataset Built with SAR-Narrator and Progressive Transfer Learning]] (80.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]], [[keywords/Few-Shot Learning|Few-Shot Learning]]
**âš¡ Unique Technical**: [[keywords/YOLO Model|YOLO Model]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2506.14629v2 Announce Type: replace-cross 
Abstract: Mosquito-borne diseases pose a major global health risk, requiring early detection and proactive control of breeding sites to prevent outbreaks. In this paper, we present VisText-Mosquito, a multimodal dataset that integrates visual and textual data to support automated detection, segmentation, and reasoning for mosquito breeding site analysis. The dataset includes 1,828 annotated images for object detection, 142 images for water surface segmentation, and natural language reasoning texts linked to each image. The YOLOv9s model achieves the highest precision of 0.92926 and mAP@50 of 0.92891 for object detection, while YOLOv11n-Seg reaches a segmentation precision of 0.91587 and mAP@50 of 0.79795. For reasoning generation, we tested a range of large vision-language models (LVLMs) in both zero-shot and few-shot settings. Our fine-tuned Mosquito-LLaMA3-8B model achieved the best results, with a final loss of 0.0028, a BLEU score of 54.7, BERTScore of 0.91, and ROUGE-L of 0.85. This dataset and model framework emphasize the theme "Prevention is Better than Cure", showcasing how AI-based detection can proactively address mosquito-borne disease risks. The dataset and implementation code are publicly available at GitHub: https://github.com/adnanul-islam-jisun/VisText-Mosquito

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëª¨ê¸° ë§¤ê°œ ì§ˆë³‘ì˜ ì¡°ê¸° íƒì§€ì™€ ë²ˆì‹ì§€ í†µì œë¥¼ ìœ„í•œ VisText-Mosquitoë¼ëŠ” ë©€í‹°ëª¨ë‹¬ ë°ì´í„°ì…‹ì„ ì†Œê°œí•©ë‹ˆë‹¤. ì´ ë°ì´í„°ì…‹ì€ ì‹œê° ë° í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ í†µí•©í•˜ì—¬ ëª¨ê¸° ë²ˆì‹ì§€ ë¶„ì„ì„ ìœ„í•œ ìë™ íƒì§€, ë¶„í• , ì¶”ë¡ ì„ ì§€ì›í•©ë‹ˆë‹¤. YOLOv9s ëª¨ë¸ì€ ê°ì²´ íƒì§€ì—ì„œ ë†’ì€ ì •ë°€ë„ì™€ mAPë¥¼ ê¸°ë¡í•˜ì˜€ìœ¼ë©°, YOLOv11n-SegëŠ” ë¶„í• ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ì¶”ë¡  ìƒì„±ì—ì„œëŠ” Mosquito-LLaMA3-8B ëª¨ë¸ì´ ìµœìƒì˜ ê²°ê³¼ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” "ì˜ˆë°©ì´ ì¹˜ë£Œë³´ë‹¤ ë‚«ë‹¤"ëŠ” ì£¼ì œë¥¼ ê°•ì¡°í•˜ë©°, AI ê¸°ë°˜ íƒì§€ê°€ ëª¨ê¸° ë§¤ê°œ ì§ˆë³‘ì˜ ìœ„í—˜ì„ ì‚¬ì „ì— í•´ê²°í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë°ì´í„°ì…‹ê³¼ êµ¬í˜„ ì½”ë“œëŠ” GitHubì—ì„œ ê³µê°œë©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. VisText-MosquitoëŠ” ëª¨ê¸° ì„œì‹ì§€ ë¶„ì„ì„ ìœ„í•œ ì‹œê° ë° í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ í†µí•©í•œ ë©€í‹°ëª¨ë‹¬ ë°ì´í„°ì…‹ì„ ì œê³µí•©ë‹ˆë‹¤.
- 2. YOLOv9s ëª¨ë¸ì€ ê°ì²´ íƒì§€ì—ì„œ 0.92926ì˜ ë†’ì€ ì •ë°€ë„ì™€ 0.92891ì˜ mAP@50ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.
- 3. YOLOv11n-Seg ëª¨ë¸ì€ ìˆ˜ë©´ ë¶„í• ì—ì„œ 0.91587ì˜ ì •ë°€ë„ì™€ 0.79795ì˜ mAP@50ì„ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤.
- 4. Mosquito-LLaMA3-8B ëª¨ë¸ì€ ì¶”ë¡  ìƒì„±ì—ì„œ BLEU ì ìˆ˜ 54.7, BERTScore 0.91, ROUGE-L 0.85ë¡œ ìµœê³ ì˜ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.
- 5. ì´ ë°ì´í„°ì…‹ê³¼ ëª¨ë¸ì€ "ì˜ˆë°©ì´ ì¹˜ë£Œë³´ë‹¤ ë‚«ë‹¤"ëŠ” ì£¼ì œë¥¼ ê°•ì¡°í•˜ë©°, AI ê¸°ë°˜ íƒì§€ê°€ ëª¨ê¸° ë§¤ê°œ ì§ˆë³‘ ìœ„í—˜ì„ ì‚¬ì „ì— í•´ê²°í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.


---

*Generated on 2025-09-24 04:17:12*