---
keywords:
  - Large Language Model
  - Sparse Autoencoder
  - Mechanistic Interpretability
  - Neuronpedia API
  - Religious Identity
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.17665
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T00:05:34.692565",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Sparse Autoencoder",
    "Mechanistic Interpretability",
    "Neuronpedia API",
    "Religious Identity"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Sparse Autoencoder": 0.78,
    "Mechanistic Interpretability": 0.8,
    "Neuronpedia API": 0.75,
    "Religious Identity": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's focus on bias and interpretability in AI.",
        "novelty_score": 0.3,
        "connectivity_score": 0.95,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Sparse Autoencoders",
        "canonical": "Sparse Autoencoder",
        "aliases": [
          "SAEs"
        ],
        "category": "unique_technical",
        "rationale": "Key method used for mechanistic interpretability in the study.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Mechanistic Interpretability",
        "canonical": "Mechanistic Interpretability",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Describes the approach used to probe internal representations in models.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Neuronpedia API",
        "canonical": "Neuronpedia API",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Specific tool mentioned for analyzing latent feature activations.",
        "novelty_score": 0.8,
        "connectivity_score": 0.5,
        "specificity_score": 0.9,
        "link_intent_score": 0.75
      },
      {
        "surface": "Religious Identity",
        "canonical": "Religious Identity",
        "aliases": [],
        "category": "evolved_concepts",
        "rationale": "Explores a less-studied dimension of bias in LLMs.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.75,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "violence",
      "geography"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.95,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Sparse Autoencoders",
      "resolved_canonical": "Sparse Autoencoder",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Mechanistic Interpretability",
      "resolved_canonical": "Mechanistic Interpretability",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Neuronpedia API",
      "resolved_canonical": "Neuronpedia API",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.5,
        "specificity": 0.9,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Religious Identity",
      "resolved_canonical": "Religious Identity",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.75,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Mechanistic Interpretability with SAEs: Probing Religion, Violence, and Geography in Large Language Models

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17665.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.17665](https://arxiv.org/abs/2509.17665)

## 🔗 유사한 논문
- [[2025-09-18/Do LLMs Align Human Values Regarding Social Biases? Judging and Explaining Social Biases with LLMs_20250918|Do LLMs Align Human Values Regarding Social Biases? Judging and Explaining Social Biases with LLMs]] (82.9% similar)
- [[2025-09-19/Opening the Black Box_ Interpretable LLMs via Semantic Resonance Architecture_20250919|Opening the Black Box: Interpretable LLMs via Semantic Resonance Architecture]] (82.0% similar)
- [[2025-09-17/Simulating a Bias Mitigation Scenario in Large Language Models_20250917|Simulating a Bias Mitigation Scenario in Large Language Models]] (82.0% similar)
- [[2025-09-19/Assessing Historical Structural Oppression Worldwide via Rule-Guided Prompting of Large Language Models_20250919|Assessing Historical Structural Oppression Worldwide via Rule-Guided Prompting of Large Language Models]] (82.0% similar)
- [[2025-09-19/Large Multi-modal Models Can Interpret Features in Large Multi-modal Models_20250919|Large Multi-modal Models Can Interpret Features in Large Multi-modal Models]] (81.7% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**⚡ Unique Technical**: [[keywords/Sparse Autoencoder|Sparse Autoencoder]], [[keywords/Mechanistic Interpretability|Mechanistic Interpretability]], [[keywords/Neuronpedia API|Neuronpedia API]]
**🚀 Evolved Concepts**: [[keywords/Religious Identity|Religious Identity]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.17665v1 Announce Type: cross 
Abstract: Despite growing research on bias in large language models (LLMs), most work has focused on gender and race, with little attention to religious identity. This paper explores how religion is internally represented in LLMs and how it intersects with concepts of violence and geography. Using mechanistic interpretability and Sparse Autoencoders (SAEs) via the Neuronpedia API, we analyze latent feature activations across five models. We measure overlap between religion- and violence-related prompts and probe semantic patterns in activation contexts. While all five religions show comparable internal cohesion, Islam is more frequently linked to features associated with violent language. In contrast, geographic associations largely reflect real-world religious demographics, revealing how models embed both factual distributions and cultural stereotypes. These findings highlight the value of structural analysis in auditing not just outputs but also internal representations that shape model behavior.

## 📝 요약

이 논문은 대형 언어 모델(LLMs)에서 종교적 정체성이 어떻게 내재적으로 표현되는지를 탐구하며, 폭력 및 지리적 개념과의 교차를 분석합니다. 연구는 Neuronpedia API를 통해 기계적 해석 가능성과 희소 오토인코더(SAEs)를 사용하여 다섯 개 모델의 잠재적 특징 활성화를 분석합니다. 종교와 폭력 관련 프롬프트 간의 중첩을 측정하고, 활성화 맥락에서의 의미 패턴을 조사합니다. 모든 종교가 유사한 내부 결속을 보이는 반면, 이슬람은 폭력적 언어와 더 자주 연결됩니다. 지리적 연관성은 실제 종교 인구 통계를 반영하여 모델이 사실적 분포와 문화적 고정관념을 어떻게 내포하는지를 드러냅니다. 이러한 발견은 모델의 출력뿐만 아니라 행동을 형성하는 내부 표현을 감사하는 구조적 분석의 가치를 강조합니다.

## 🎯 주요 포인트

- 1. 대형 언어 모델(LLMs)에서 종교적 정체성의 표현과 폭력 및 지리적 개념과의 교차점을 탐구합니다.
- 2. Neuronpedia API를 사용하여 다섯 가지 모델의 잠재적 특징 활성화를 분석하고, 종교 및 폭력 관련 프롬프트 간의 중첩을 측정합니다.
- 3. 이슬람은 다른 종교들보다 폭력적 언어와 관련된 특징과 더 자주 연결됩니다.
- 4. 지리적 연관성은 실제 종교적 인구 분포를 반영하며, 모델이 사실적 분포와 문화적 고정관념을 어떻게 내재화하는지를 보여줍니다.
- 5. 구조적 분석을 통해 모델의 출력뿐만 아니라 행동을 형성하는 내부 표현을 감사하는 것이 중요함을 강조합니다.


---

*Generated on 2025-09-24 00:05:34*