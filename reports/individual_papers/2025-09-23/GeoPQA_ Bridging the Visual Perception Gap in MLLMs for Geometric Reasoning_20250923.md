---
keywords:
  - Multimodal Learning
  - Geometric Reasoning
  - Reinforcement Learning
  - Geo-Perception Question-Answering
  - Vision-Language Model
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2509.17437
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:26:35.043877",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multimodal Learning",
    "Geometric Reasoning",
    "Reinforcement Learning",
    "Geo-Perception Question-Answering",
    "Vision-Language Model"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multimodal Learning": 0.85,
    "Geometric Reasoning": 0.78,
    "Reinforcement Learning": 0.8,
    "Geo-Perception Question-Answering": 0.77,
    "Vision-Language Model": 0.82
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multimodal LLMs",
        "canonical": "Multimodal Learning",
        "aliases": [
          "MLLMs"
        ],
        "category": "specific_connectable",
        "rationale": "Multimodal Learning is crucial for linking vision and language models, which is central to the paper's focus.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.82,
        "link_intent_score": 0.85
      },
      {
        "surface": "Geometric Reasoning",
        "canonical": "Geometric Reasoning",
        "aliases": [
          "Spatial Reasoning"
        ],
        "category": "unique_technical",
        "rationale": "Geometric Reasoning is a unique technical focus of the paper, highlighting the specific challenges in vision tasks.",
        "novelty_score": 0.72,
        "connectivity_score": 0.65,
        "specificity_score": 0.91,
        "link_intent_score": 0.78
      },
      {
        "surface": "Reinforcement Learning",
        "canonical": "Reinforcement Learning",
        "aliases": [
          "RL"
        ],
        "category": "broad_technical",
        "rationale": "Reinforcement Learning is a foundational technique used in the paper's proposed framework.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Geo-Perception Question-Answering",
        "canonical": "Geo-Perception Question-Answering",
        "aliases": [
          "GeoPQA"
        ],
        "category": "unique_technical",
        "rationale": "GeoPQA is a novel benchmark introduced in the paper, central to evaluating MLLMs' geometric reasoning abilities.",
        "novelty_score": 0.85,
        "connectivity_score": 0.6,
        "specificity_score": 0.89,
        "link_intent_score": 0.77
      },
      {
        "surface": "Vision-Language Model",
        "canonical": "Vision-Language Model",
        "aliases": [
          "Vision-Language"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-Language Models are key to understanding the integration of visual perception and language reasoning.",
        "novelty_score": 0.5,
        "connectivity_score": 0.87,
        "specificity_score": 0.75,
        "link_intent_score": 0.82
      }
    ],
    "ban_list_suggestions": [
      "hallucinate",
      "perceptual bottleneck"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multimodal LLMs",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.82,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Geometric Reasoning",
      "resolved_canonical": "Geometric Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.65,
        "specificity": 0.91,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Reinforcement Learning",
      "resolved_canonical": "Reinforcement Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Geo-Perception Question-Answering",
      "resolved_canonical": "Geo-Perception Question-Answering",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.6,
        "specificity": 0.89,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Vision-Language Model",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.87,
        "specificity": 0.75,
        "link_intent": 0.82
      }
    }
  ]
}
-->

# GeoPQA: Bridging the Visual Perception Gap in MLLMs for Geometric Reasoning

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17437.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2509.17437](https://arxiv.org/abs/2509.17437)

## 🔗 유사한 논문
- [[2025-09-22/Perception-R1_ Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward_20250922|Perception-R1: Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward]] (88.9% similar)
- [[2025-09-23/Reinforcement Learning Meets Large Language Models_ A Survey of Advancements and Applications Across the LLM Lifecycle_20250923|Reinforcement Learning Meets Large Language Models: A Survey of Advancements and Applications Across the LLM Lifecycle]] (85.7% similar)
- [[2025-09-23/ProReason_ Multi-Modal Proactive Reasoning with Decoupled Eyesight and Wisdom_20250923|ProReason: Multi-Modal Proactive Reasoning with Decoupled Eyesight and Wisdom]] (85.4% similar)
- [[2025-09-22/GRE Suite_ Geo-localization Inference via Fine-Tuned Vision-Language Models and Enhanced Reasoning Chains_20250922|GRE Suite: Geo-localization Inference via Fine-Tuned Vision-Language Models and Enhanced Reasoning Chains]] (85.2% similar)
- [[2025-09-19/Generalizable Geometric Image Caption Synthesis_20250919|Generalizable Geometric Image Caption Synthesis]] (85.2% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Reinforcement Learning|Reinforcement Learning]]
**🔗 Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**⚡ Unique Technical**: [[keywords/Geometric Reasoning|Geometric Reasoning]], [[keywords/Geo-Perception Question-Answering|Geo-Perception Question-Answering]]
**🚀 Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.17437v1 Announce Type: new 
Abstract: Recent advancements in reinforcement learning (RL) have enhanced the reasoning abilities of large language models (LLMs), yet the impact on multimodal LLMs (MLLMs) is limited. Particularly in vision-intensive tasks like geometric reasoning, MLLMs hallucinate frequently, leading to inaccurate reasoning. We attribute this to the perceptual bottleneck in MLLMs, which caps the benefits of reasoning training. To quantify this, we design a Geo-Perception Question-Answering (GeoPQA) benchmark, targeting basic geometric concepts and spatial relationships. Experiments on GeoPQA reveal significant shortcomings of MLLMs in visual perception, which constrain RL reward signals for effective training. To address this bottleneck, we propose a two-stage RL training framework by first enhancing the visual perception of geometric structures, then fostering reasoning capabilities. Applied to Qwen2.5-VL-3B-Instruct, our two-stage training improves geometric reasoning by 9.7% and geometric problem solving by 9.1%, compared to the direct reasoning training approach. Our method also generalizes to other vision-intensive domains like figure understanding, highlighting the importance of perceptual grounding in effective MLLM reasoning.

## 📝 요약

최근 강화 학습(RL)의 발전은 대형 언어 모델(LLM)의 추론 능력을 향상시켰으나, 다중 모달 LLM(MLLM)에는 그 영향이 제한적입니다. 특히 기하학적 추론과 같은 시각 중심의 작업에서 MLLM은 자주 오류를 발생시킵니다. 이는 MLLM의 인지적 병목 현상 때문으로, 이를 해결하기 위해 Geo-Perception Question-Answering(GeoPQA) 벤치마크를 설계했습니다. 실험 결과, MLLM의 시각적 인식 한계가 RL 보상 신호를 제한함을 확인했습니다. 이를 극복하기 위해, 우리는 시각적 인식을 먼저 향상시키고 추론 능력을 강화하는 2단계 RL 훈련 프레임워크를 제안했습니다. 이 방법을 Qwen2.5-VL-3B-Instruct에 적용한 결과, 기하학적 추론이 9.7%, 문제 해결이 9.1% 향상되었습니다. 이 방법은 다른 시각 중심 영역에도 적용 가능하며, 효과적인 MLLM 추론에 인지적 기반의 중요성을 강조합니다.

## 🎯 주요 포인트

- 1. 최근 강화 학습의 발전은 대형 언어 모델의 추론 능력을 향상시켰으나, 멀티모달 언어 모델(MLLMs)에는 제한적인 영향을 미쳤습니다.
- 2. 시각 중심의 작업에서 MLLMs는 자주 환각을 일으켜 부정확한 추론을 초래하며, 이는 지각적 병목 현상 때문입니다.
- 3. Geo-Perception Question-Answering (GeoPQA) 벤치마크를 설계하여 MLLMs의 시각적 지각의 한계를 측정하고자 했습니다.
- 4. 두 단계의 강화 학습 훈련 프레임워크를 제안하여, 먼저 기하학적 구조의 시각적 지각을 향상시키고, 이후 추론 능력을 강화합니다.
- 5. 제안된 방법은 Qwen2.5-VL-3B-Instruct에 적용되어 기하학적 추론과 문제 해결 능력을 각각 9.7%와 9.1% 향상시켰습니다.


---

*Generated on 2025-09-24 03:26:35*