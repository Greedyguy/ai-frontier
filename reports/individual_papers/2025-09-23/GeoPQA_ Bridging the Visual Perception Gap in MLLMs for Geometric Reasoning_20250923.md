---
keywords:
  - Multimodal Learning
  - Geometric Reasoning
  - Reinforcement Learning
  - Geo-Perception Question-Answering
  - Vision-Language Model
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2509.17437
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:26:35.043877",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multimodal Learning",
    "Geometric Reasoning",
    "Reinforcement Learning",
    "Geo-Perception Question-Answering",
    "Vision-Language Model"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multimodal Learning": 0.85,
    "Geometric Reasoning": 0.78,
    "Reinforcement Learning": 0.8,
    "Geo-Perception Question-Answering": 0.77,
    "Vision-Language Model": 0.82
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multimodal LLMs",
        "canonical": "Multimodal Learning",
        "aliases": [
          "MLLMs"
        ],
        "category": "specific_connectable",
        "rationale": "Multimodal Learning is crucial for linking vision and language models, which is central to the paper's focus.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.82,
        "link_intent_score": 0.85
      },
      {
        "surface": "Geometric Reasoning",
        "canonical": "Geometric Reasoning",
        "aliases": [
          "Spatial Reasoning"
        ],
        "category": "unique_technical",
        "rationale": "Geometric Reasoning is a unique technical focus of the paper, highlighting the specific challenges in vision tasks.",
        "novelty_score": 0.72,
        "connectivity_score": 0.65,
        "specificity_score": 0.91,
        "link_intent_score": 0.78
      },
      {
        "surface": "Reinforcement Learning",
        "canonical": "Reinforcement Learning",
        "aliases": [
          "RL"
        ],
        "category": "broad_technical",
        "rationale": "Reinforcement Learning is a foundational technique used in the paper's proposed framework.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Geo-Perception Question-Answering",
        "canonical": "Geo-Perception Question-Answering",
        "aliases": [
          "GeoPQA"
        ],
        "category": "unique_technical",
        "rationale": "GeoPQA is a novel benchmark introduced in the paper, central to evaluating MLLMs' geometric reasoning abilities.",
        "novelty_score": 0.85,
        "connectivity_score": 0.6,
        "specificity_score": 0.89,
        "link_intent_score": 0.77
      },
      {
        "surface": "Vision-Language Model",
        "canonical": "Vision-Language Model",
        "aliases": [
          "Vision-Language"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-Language Models are key to understanding the integration of visual perception and language reasoning.",
        "novelty_score": 0.5,
        "connectivity_score": 0.87,
        "specificity_score": 0.75,
        "link_intent_score": 0.82
      }
    ],
    "ban_list_suggestions": [
      "hallucinate",
      "perceptual bottleneck"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multimodal LLMs",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.82,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Geometric Reasoning",
      "resolved_canonical": "Geometric Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.65,
        "specificity": 0.91,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Reinforcement Learning",
      "resolved_canonical": "Reinforcement Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Geo-Perception Question-Answering",
      "resolved_canonical": "Geo-Perception Question-Answering",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.6,
        "specificity": 0.89,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Vision-Language Model",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.87,
        "specificity": 0.75,
        "link_intent": 0.82
      }
    }
  ]
}
-->

# GeoPQA: Bridging the Visual Perception Gap in MLLMs for Geometric Reasoning

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17437.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2509.17437](https://arxiv.org/abs/2509.17437)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Perception-R1_ Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward_20250922|Perception-R1: Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward]] (88.9% similar)
- [[2025-09-23/Reinforcement Learning Meets Large Language Models_ A Survey of Advancements and Applications Across the LLM Lifecycle_20250923|Reinforcement Learning Meets Large Language Models: A Survey of Advancements and Applications Across the LLM Lifecycle]] (85.7% similar)
- [[2025-09-23/ProReason_ Multi-Modal Proactive Reasoning with Decoupled Eyesight and Wisdom_20250923|ProReason: Multi-Modal Proactive Reasoning with Decoupled Eyesight and Wisdom]] (85.4% similar)
- [[2025-09-22/GRE Suite_ Geo-localization Inference via Fine-Tuned Vision-Language Models and Enhanced Reasoning Chains_20250922|GRE Suite: Geo-localization Inference via Fine-Tuned Vision-Language Models and Enhanced Reasoning Chains]] (85.2% similar)
- [[2025-09-19/Generalizable Geometric Image Caption Synthesis_20250919|Generalizable Geometric Image Caption Synthesis]] (85.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Reinforcement Learning|Reinforcement Learning]]
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**âš¡ Unique Technical**: [[keywords/Geometric Reasoning|Geometric Reasoning]], [[keywords/Geo-Perception Question-Answering|Geo-Perception Question-Answering]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17437v1 Announce Type: new 
Abstract: Recent advancements in reinforcement learning (RL) have enhanced the reasoning abilities of large language models (LLMs), yet the impact on multimodal LLMs (MLLMs) is limited. Particularly in vision-intensive tasks like geometric reasoning, MLLMs hallucinate frequently, leading to inaccurate reasoning. We attribute this to the perceptual bottleneck in MLLMs, which caps the benefits of reasoning training. To quantify this, we design a Geo-Perception Question-Answering (GeoPQA) benchmark, targeting basic geometric concepts and spatial relationships. Experiments on GeoPQA reveal significant shortcomings of MLLMs in visual perception, which constrain RL reward signals for effective training. To address this bottleneck, we propose a two-stage RL training framework by first enhancing the visual perception of geometric structures, then fostering reasoning capabilities. Applied to Qwen2.5-VL-3B-Instruct, our two-stage training improves geometric reasoning by 9.7% and geometric problem solving by 9.1%, compared to the direct reasoning training approach. Our method also generalizes to other vision-intensive domains like figure understanding, highlighting the importance of perceptual grounding in effective MLLM reasoning.

## ğŸ“ ìš”ì•½

ìµœê·¼ ê°•í™” í•™ìŠµ(RL)ì˜ ë°œì „ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì¶”ë¡  ëŠ¥ë ¥ì„ í–¥ìƒì‹œì¼°ìœ¼ë‚˜, ë‹¤ì¤‘ ëª¨ë‹¬ LLM(MLLM)ì—ëŠ” ê·¸ ì˜í–¥ì´ ì œí•œì ì…ë‹ˆë‹¤. íŠ¹íˆ ê¸°í•˜í•™ì  ì¶”ë¡ ê³¼ ê°™ì€ ì‹œê° ì¤‘ì‹¬ì˜ ì‘ì—…ì—ì„œ MLLMì€ ìì£¼ ì˜¤ë¥˜ë¥¼ ë°œìƒì‹œí‚µë‹ˆë‹¤. ì´ëŠ” MLLMì˜ ì¸ì§€ì  ë³‘ëª© í˜„ìƒ ë•Œë¬¸ìœ¼ë¡œ, ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ Geo-Perception Question-Answering(GeoPQA) ë²¤ì¹˜ë§ˆí¬ë¥¼ ì„¤ê³„í–ˆìŠµë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, MLLMì˜ ì‹œê°ì  ì¸ì‹ í•œê³„ê°€ RL ë³´ìƒ ì‹ í˜¸ë¥¼ ì œí•œí•¨ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ì´ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ì‹œê°ì  ì¸ì‹ì„ ë¨¼ì € í–¥ìƒì‹œí‚¤ê³  ì¶”ë¡  ëŠ¥ë ¥ì„ ê°•í™”í•˜ëŠ” 2ë‹¨ê³„ RL í›ˆë ¨ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí–ˆìŠµë‹ˆë‹¤. ì´ ë°©ë²•ì„ Qwen2.5-VL-3B-Instructì— ì ìš©í•œ ê²°ê³¼, ê¸°í•˜í•™ì  ì¶”ë¡ ì´ 9.7%, ë¬¸ì œ í•´ê²°ì´ 9.1% í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ë°©ë²•ì€ ë‹¤ë¥¸ ì‹œê° ì¤‘ì‹¬ ì˜ì—­ì—ë„ ì ìš© ê°€ëŠ¥í•˜ë©°, íš¨ê³¼ì ì¸ MLLM ì¶”ë¡ ì— ì¸ì§€ì  ê¸°ë°˜ì˜ ì¤‘ìš”ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ìµœê·¼ ê°•í™” í•™ìŠµì˜ ë°œì „ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ ì¶”ë¡  ëŠ¥ë ¥ì„ í–¥ìƒì‹œì¼°ìœ¼ë‚˜, ë©€í‹°ëª¨ë‹¬ ì–¸ì–´ ëª¨ë¸(MLLMs)ì—ëŠ” ì œí•œì ì¸ ì˜í–¥ì„ ë¯¸ì³¤ìŠµë‹ˆë‹¤.
- 2. ì‹œê° ì¤‘ì‹¬ì˜ ì‘ì—…ì—ì„œ MLLMsëŠ” ìì£¼ í™˜ê°ì„ ì¼ìœ¼ì¼œ ë¶€ì •í™•í•œ ì¶”ë¡ ì„ ì´ˆë˜í•˜ë©°, ì´ëŠ” ì§€ê°ì  ë³‘ëª© í˜„ìƒ ë•Œë¬¸ì…ë‹ˆë‹¤.
- 3. Geo-Perception Question-Answering (GeoPQA) ë²¤ì¹˜ë§ˆí¬ë¥¼ ì„¤ê³„í•˜ì—¬ MLLMsì˜ ì‹œê°ì  ì§€ê°ì˜ í•œê³„ë¥¼ ì¸¡ì •í•˜ê³ ì í–ˆìŠµë‹ˆë‹¤.
- 4. ë‘ ë‹¨ê³„ì˜ ê°•í™” í•™ìŠµ í›ˆë ¨ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•˜ì—¬, ë¨¼ì € ê¸°í•˜í•™ì  êµ¬ì¡°ì˜ ì‹œê°ì  ì§€ê°ì„ í–¥ìƒì‹œí‚¤ê³ , ì´í›„ ì¶”ë¡  ëŠ¥ë ¥ì„ ê°•í™”í•©ë‹ˆë‹¤.
- 5. ì œì•ˆëœ ë°©ë²•ì€ Qwen2.5-VL-3B-Instructì— ì ìš©ë˜ì–´ ê¸°í•˜í•™ì  ì¶”ë¡ ê³¼ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì„ ê°ê° 9.7%ì™€ 9.1% í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 03:26:35*