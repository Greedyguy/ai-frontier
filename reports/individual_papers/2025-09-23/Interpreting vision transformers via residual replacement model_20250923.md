---
keywords:
  - Transformer
  - Residual Replacement Model
  - Sparse Autoencoder
  - Feature Evolution
  - Debiasing Techniques
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.17401
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T23:54:50.189852",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Transformer",
    "Residual Replacement Model",
    "Sparse Autoencoder",
    "Feature Evolution",
    "Debiasing Techniques"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Transformer": 0.85,
    "Residual Replacement Model": 0.8,
    "Sparse Autoencoder": 0.78,
    "Feature Evolution": 0.7,
    "Debiasing Techniques": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Vision Transformers",
        "canonical": "Transformer",
        "aliases": [
          "ViT",
          "Vision Transformer"
        ],
        "category": "broad_technical",
        "rationale": "Transformers are a foundational model in deep learning, and linking this to the broader concept of Transformers facilitates understanding of its application in vision tasks.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Residual Replacement Model",
        "canonical": "Residual Replacement Model",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This is a novel model introduced in the paper, offering a new perspective on interpretability in vision transformers.",
        "novelty_score": 0.95,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Sparse Autoencoders",
        "canonical": "Sparse Autoencoder",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Sparse autoencoders are a specific technique used in the analysis, linking to broader discussions on feature extraction and representation learning.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.78
      },
      {
        "surface": "Feature Evolution",
        "canonical": "Feature Evolution",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Understanding feature evolution is crucial for interpreting how vision transformers process information, making it a unique technical concept.",
        "novelty_score": 0.65,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      },
      {
        "surface": "Debiasing Spurious Correlations",
        "canonical": "Debiasing Techniques",
        "aliases": [
          "Debiasing Spurious Correlations"
        ],
        "category": "evolved_concepts",
        "rationale": "Debiasing is a growing area of interest in machine learning, and linking this concept helps in understanding its application in vision transformers.",
        "novelty_score": 0.6,
        "connectivity_score": 0.7,
        "specificity_score": 0.75,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "feature types",
      "spatial positions",
      "curves"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Vision Transformers",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Residual Replacement Model",
      "resolved_canonical": "Residual Replacement Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.95,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Sparse Autoencoders",
      "resolved_canonical": "Sparse Autoencoder",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Feature Evolution",
      "resolved_canonical": "Feature Evolution",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Debiasing Spurious Correlations",
      "resolved_canonical": "Debiasing Techniques",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.7,
        "specificity": 0.75,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# Interpreting vision transformers via residual replacement model

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17401.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.17401](https://arxiv.org/abs/2509.17401)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Large Vision Models Can Solve Mental Rotation Problems_20250922|Large Vision Models Can Solve Mental Rotation Problems]] (85.4% similar)
- [[2025-09-22/Which Direction to Choose? An Analysis on the Representation Power of Self-Supervised ViTs in Downstream Tasks_20250922|Which Direction to Choose? An Analysis on the Representation Power of Self-Supervised ViTs in Downstream Tasks]] (85.3% similar)
- [[2025-09-18/[Re] Improving Interpretation Faithfulness for Vision Transformers_20250918|[Re] Improving Interpretation Faithfulness for Vision Transformers]] (82.9% similar)
- [[2025-09-22/ViSpec_ Accelerating Vision-Language Models with Vision-Aware Speculative Decoding_20250922|ViSpec: Accelerating Vision-Language Models with Vision-Aware Speculative Decoding]] (81.6% similar)
- [[2025-09-22/Emulating Human-like Adaptive Vision for Efficient and Flexible Machine Visual Perception_20250922|Emulating Human-like Adaptive Vision for Efficient and Flexible Machine Visual Perception]] (81.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Transformer|Transformer]]
**ğŸ”— Specific Connectable**: [[keywords/Sparse Autoencoder|Sparse Autoencoder]]
**âš¡ Unique Technical**: [[keywords/Residual Replacement Model|Residual Replacement Model]], [[keywords/Feature Evolution|Feature Evolution]]
**ğŸš€ Evolved Concepts**: [[keywords/Debiasing Techniques|Debiasing Techniques]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17401v1 Announce Type: cross 
Abstract: How do vision transformers (ViTs) represent and process the world? This paper addresses this long-standing question through the first systematic analysis of 6.6K features across all layers, extracted via sparse autoencoders, and by introducing the residual replacement model, which replaces ViT computations with interpretable features in the residual stream. Our analysis reveals not only a feature evolution from low-level patterns to high-level semantics, but also how ViTs encode curves and spatial positions through specialized feature types. The residual replacement model scalably produces a faithful yet parsimonious circuit for human-scale interpretability by significantly simplifying the original computations. As a result, this framework enables intuitive understanding of ViT mechanisms. Finally, we demonstrate the utility of our framework in debiasing spurious correlations.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë¹„ì „ íŠ¸ëœìŠ¤í¬ë¨¸(ViT)ì˜ ì‘ë™ ë°©ì‹ì„ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤. 6,600ê°œì˜ íŠ¹ì§•ì„ ì¸µë³„ë¡œ ë¶„ì„í•˜ê³ , ì”ì—¬ ëŒ€ì²´ ëª¨ë¸ì„ ë„ì…í•˜ì—¬ ViTì˜ ê³„ì‚°ì„ í•´ì„ ê°€ëŠ¥í•œ íŠ¹ì§•ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤. ë¶„ì„ ê²°ê³¼, ViTê°€ ì €ìˆ˜ì¤€ íŒ¨í„´ì—ì„œ ê³ ìˆ˜ì¤€ ì˜ë¯¸ë¡œ íŠ¹ì§•ì„ ë°œì „ì‹œí‚¤ê³ , ê³¡ì„  ë° ê³µê°„ ìœ„ì¹˜ë¥¼ íŠ¹ìˆ˜í•œ íŠ¹ì§• ìœ í˜•ìœ¼ë¡œ ì¸ì½”ë”©í•˜ëŠ” ë°©ì‹ì„ ë°í˜€ëƒˆìŠµë‹ˆë‹¤. ì”ì—¬ ëŒ€ì²´ ëª¨ë¸ì€ ì›ë˜ì˜ ë³µì¡í•œ ê³„ì‚°ì„ ë‹¨ìˆœí™”í•˜ì—¬ ì¸ê°„ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” í•´ì„ ê°€ëŠ¥í•œ íšŒë¡œë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ViT ë©”ì»¤ë‹ˆì¦˜ì— ëŒ€í•œ ì§ê´€ì ì¸ ì´í•´ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ë©°, í¸í–¥ëœ ìƒê´€ê´€ê³„ë¥¼ ì œê±°í•˜ëŠ” ë° ìœ ìš©í•¨ì„ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì´ ë…¼ë¬¸ì€ ë¹„ì „ íŠ¸ëœìŠ¤í¬ë¨¸(ViTs)ì˜ ëª¨ë“  ì¸µì—ì„œ 6.6K íŠ¹ì§•ì„ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ViTsê°€ ì„¸ìƒì„ ì–´ë–»ê²Œ í‘œí˜„í•˜ê³  ì²˜ë¦¬í•˜ëŠ”ì§€ë¥¼ íƒêµ¬í•©ë‹ˆë‹¤.
- 2. í¬ì†Œ ì˜¤í† ì¸ì½”ë”ë¥¼ í†µí•´ ì¶”ì¶œëœ íŠ¹ì§•ì„ ë°”íƒ•ìœ¼ë¡œ, ViTsì˜ íŠ¹ì§•ì´ ì €ìˆ˜ì¤€ íŒ¨í„´ì—ì„œ ê³ ìˆ˜ì¤€ ì˜ë¯¸ë¡œ ì§„í™”í•˜ëŠ” ê³¼ì •ì„ ë°í˜€ëƒ…ë‹ˆë‹¤.
- 3. ViTsê°€ ê³¡ì„ ê³¼ ê³µê°„ì  ìœ„ì¹˜ë¥¼ íŠ¹ìˆ˜í™”ëœ íŠ¹ì§• ìœ í˜•ì„ í†µí•´ ì¸ì½”ë”©í•˜ëŠ” ë°©ì‹ì„ ë¶„ì„í•©ë‹ˆë‹¤.
- 4. ì”ì—¬ ëŒ€ì²´ ëª¨ë¸ì„ ë„ì…í•˜ì—¬ ViT ê³„ì‚°ì„ í•´ì„ ê°€ëŠ¥í•œ íŠ¹ì§•ìœ¼ë¡œ ëŒ€ì²´í•¨ìœ¼ë¡œì¨, ì¸ê°„ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ì§ê´€ì ì¸ ViT ë©”ì»¤ë‹ˆì¦˜ì„ ì œê³µí•©ë‹ˆë‹¤.
- 5. ì œì•ˆëœ í”„ë ˆì„ì›Œí¬ëŠ” í¸í–¥ëœ ìƒê´€ê´€ê³„ë¥¼ ì œê±°í•˜ëŠ” ë° ìœ ìš©í•¨ì„ ì…ì¦í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-23 23:54:50*