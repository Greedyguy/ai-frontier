---
keywords:
  - Counterfactual Explanations
  - Deep Learning
  - Feature Space
  - Decision Boundaries
  - Mirror-CFE
category: cs.CV
publish_date: 2025-09-23
arxiv_id: 2509.16822
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T04:35:35.402311",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Counterfactual Explanations",
    "Deep Learning",
    "Feature Space",
    "Decision Boundaries",
    "Mirror-CFE"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Counterfactual Explanations": 0.78,
    "Deep Learning": 0.72,
    "Feature Space": 0.79,
    "Decision Boundaries": 0.81,
    "Mirror-CFE": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Counterfactual explanations",
        "canonical": "Counterfactual Explanations",
        "aliases": [
          "CFE"
        ],
        "category": "unique_technical",
        "rationale": "Counterfactual explanations are crucial for understanding model decisions, offering a unique perspective in model interpretability.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Deep image classifiers",
        "canonical": "Deep Learning",
        "aliases": [
          "Deep Image Classification"
        ],
        "category": "broad_technical",
        "rationale": "Deep learning is a fundamental concept in the paper, linking it to broader discussions on neural networks and image processing.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.72
      },
      {
        "surface": "Feature space",
        "canonical": "Feature Space",
        "aliases": [
          "Feature Representation"
        ],
        "category": "specific_connectable",
        "rationale": "Feature space is a critical element in understanding how classifiers make decisions, connecting to discussions on model architecture.",
        "novelty_score": 0.58,
        "connectivity_score": 0.82,
        "specificity_score": 0.78,
        "link_intent_score": 0.79
      },
      {
        "surface": "Decision boundaries",
        "canonical": "Decision Boundaries",
        "aliases": [
          "Classification Boundaries"
        ],
        "category": "specific_connectable",
        "rationale": "Decision boundaries are essential for understanding classifier behavior, providing strong links to model evaluation discussions.",
        "novelty_score": 0.6,
        "connectivity_score": 0.85,
        "specificity_score": 0.8,
        "link_intent_score": 0.81
      },
      {
        "surface": "Mirror-CFE",
        "canonical": "Mirror-CFE",
        "aliases": [
          "Mirror Counterfactual Explanations"
        ],
        "category": "unique_technical",
        "rationale": "Mirror-CFE is a novel method introduced in the paper, offering a unique contribution to the field of model interpretability.",
        "novelty_score": 0.85,
        "connectivity_score": 0.7,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "experiment"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Counterfactual explanations",
      "resolved_canonical": "Counterfactual Explanations",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Deep image classifiers",
      "resolved_canonical": "Deep Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "Feature space",
      "resolved_canonical": "Feature Space",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.82,
        "specificity": 0.78,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Decision boundaries",
      "resolved_canonical": "Decision Boundaries",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.85,
        "specificity": 0.8,
        "link_intent": 0.81
      }
    },
    {
      "candidate_surface": "Mirror-CFE",
      "resolved_canonical": "Mirror-CFE",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.7,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# Looking in the mirror: A faithful counterfactual explanation method for interpreting deep image classification models

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16822.pdf)
**Category**: cs.CV
**Published**: 2025-09-23
**ArXiv ID**: [2509.16822](https://arxiv.org/abs/2509.16822)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/V-CECE_ Visual Counterfactual Explanations via Conceptual Edits_20250923|V-CECE: Visual Counterfactual Explanations via Conceptual Edits]] (82.7% similar)
- [[2025-09-19/MARIC_ Multi-Agent Reasoning for Image Classification_20250919|MARIC: Multi-Agent Reasoning for Image Classification]] (82.4% similar)
- [[2025-09-22/Shedding Light on Depth_ Explainability Assessment in Monocular Depth Estimation_20250922|Shedding Light on Depth: Explainability Assessment in Monocular Depth Estimation]] (82.3% similar)
- [[2025-09-18/Locally Explaining Prediction Behavior via Gradual Interventions and Measuring Property Gradients_20250918|Locally Explaining Prediction Behavior via Gradual Interventions and Measuring Property Gradients]] (81.4% similar)
- [[2025-09-23/From Easy to Hard_ The MIR Benchmark for Progressive Interleaved Multi-Image Reasoning_20250923|From Easy to Hard: The MIR Benchmark for Progressive Interleaved Multi-Image Reasoning]] (81.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Deep Learning|Deep Learning]]
**ğŸ”— Specific Connectable**: [[keywords/Feature Space|Feature Space]], [[keywords/Decision Boundaries|Decision Boundaries]]
**âš¡ Unique Technical**: [[keywords/Counterfactual Explanations|Counterfactual Explanations]], [[keywords/Mirror-CFE|Mirror-CFE]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16822v1 Announce Type: new 
Abstract: Counterfactual explanations (CFE) for deep image classifiers aim to reveal how minimal input changes lead to different model decisions, providing critical insights for model interpretation and improvement. However, existing CFE methods often rely on additional image encoders and generative models to create plausible images, neglecting the classifier's own feature space and decision boundaries. As such, they do not explain the intrinsic feature space and decision boundaries learned by the classifier. To address this limitation, we propose Mirror-CFE, a novel method that generates faithful counterfactual explanations by operating directly in the classifier's feature space, treating decision boundaries as mirrors that ``reflect'' feature representations in the mirror. Mirror-CFE learns a mapping function from feature space to image space while preserving distance relationships, enabling smooth transitions between source images and their counterfactuals. Through extensive experiments on four image datasets, we demonstrate that Mirror-CFE achieves superior performance in validity while maintaining input resemblance compared to state-of-the-art explanation methods. Finally, mirror-CFE provides interpretable visualization of the classifier's decision process by generating step-wise transitions that reveal how features evolve as classification confidence changes.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì‹¬ì¸µ ì´ë¯¸ì§€ ë¶„ë¥˜ê¸°ì˜ ë°˜ì‚¬ì‹¤ì  ì„¤ëª…(CFE)ì„ ê°œì„ í•˜ê¸° ìœ„í•´ Mirror-CFEë¼ëŠ” ìƒˆë¡œìš´ ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ CFE ë°©ë²•ì€ ì¶”ê°€ì ì¸ ì´ë¯¸ì§€ ì¸ì½”ë”ì™€ ìƒì„± ëª¨ë¸ì— ì˜ì¡´í•˜ì—¬ ë¶„ë¥˜ê¸°ì˜ ê³ ìœ í•œ íŠ¹ì§• ê³µê°„ê³¼ ê²°ì • ê²½ê³„ë¥¼ ì„¤ëª…í•˜ì§€ ëª»í•˜ëŠ” í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤. Mirror-CFEëŠ” ë¶„ë¥˜ê¸°ì˜ íŠ¹ì§• ê³µê°„ì—ì„œ ì§ì ‘ ì‘ë™í•˜ì—¬ ê²°ì • ê²½ê³„ë¥¼ 'ê±°ìš¸'ë¡œ í™œìš©, íŠ¹ì§• í‘œí˜„ì„ ë°˜ì‚¬ì‹œí‚µë‹ˆë‹¤. ì´ë¥¼ í†µí•´ íŠ¹ì§• ê³µê°„ì—ì„œ ì´ë¯¸ì§€ ê³µê°„ìœ¼ë¡œì˜ ë§¤í•‘ì„ í•™ìŠµí•˜ë©°, ì…ë ¥ ì´ë¯¸ì§€ì™€ ë°˜ì‚¬ì‹¤ì  ì´ë¯¸ì§€ ê°„ì˜ ë§¤ë„ëŸ¬ìš´ ì „í™˜ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ë„¤ ê°€ì§€ ì´ë¯¸ì§€ ë°ì´í„°ì…‹ì— ëŒ€í•œ ì‹¤í—˜ ê²°ê³¼, Mirror-CFEëŠ” ê¸°ì¡´ ë°©ë²•ë³´ë‹¤ ë†’ì€ ìœ íš¨ì„±ì„ ìœ ì§€í•˜ë©´ì„œ ì…ë ¥ ìœ ì‚¬ì„±ì„ ìœ ì§€í•˜ëŠ” ë° ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ë˜í•œ, ë¶„ë¥˜ê¸°ì˜ ê²°ì • ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ ì‹œê°í™”í•˜ì—¬ í•´ì„ ê°€ëŠ¥í•œ ì„¤ëª…ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Mirror-CFEëŠ” ë¶„ë¥˜ê¸°ì˜ íŠ¹ì§• ê³µê°„ì—ì„œ ì§ì ‘ ì‘ë™í•˜ì—¬ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë°˜ì‚¬ì  ë°˜ì‚¬ ì„¤ëª…ì„ ìƒì„±í•˜ëŠ” ìƒˆë¡œìš´ ë°©ë²•ì…ë‹ˆë‹¤.
- 2. ì´ ë°©ë²•ì€ íŠ¹ì§• ê³µê°„ì—ì„œ ì´ë¯¸ì§€ ê³µê°„ìœ¼ë¡œì˜ ë§¤í•‘ í•¨ìˆ˜ë¥¼ í•™ìŠµí•˜ì—¬ ì›ë³¸ ì´ë¯¸ì§€ì™€ ë°˜ì‚¬ì  ë°˜ì‚¬ ì´ë¯¸ì§€ ê°„ì˜ ë¶€ë“œëŸ¬ìš´ ì „í™˜ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
- 3. Mirror-CFEëŠ” ë„¤ ê°€ì§€ ì´ë¯¸ì§€ ë°ì´í„°ì…‹ì— ëŒ€í•œ ì‹¤í—˜ì„ í†µí•´ ìµœì‹  ì„¤ëª… ë°©ë²•ê³¼ ë¹„êµí•˜ì—¬ ìœ íš¨ì„±ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
- 4. ì´ ë°©ë²•ì€ ë¶„ë¥˜ê¸°ì˜ ê²°ì • ê³¼ì •ì„ í•´ì„ ê°€ëŠ¥í•œ ì‹œê°í™”ë¡œ ì œê³µí•˜ì—¬ ë¶„ë¥˜ ì‹ ë¢°ë„ê°€ ë³€í™”í•¨ì— ë”°ë¼ íŠ¹ì§•ì´ ì–´ë–»ê²Œ ì§„í™”í•˜ëŠ”ì§€ë¥¼ ë‹¨ê³„ë³„ë¡œ ë“œëŸ¬ëƒ…ë‹ˆë‹¤.


---

*Generated on 2025-09-24 04:35:35*