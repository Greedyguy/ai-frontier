---
keywords:
  - Large Language Model
  - Multimodal Learning
  - ExTrActor Framework
  - AirQA Dataset
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.16952
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T23:38:37.991469",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Multimodal Learning",
    "ExTrActor Framework",
    "AirQA Dataset"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Multimodal Learning": 0.82,
    "ExTrActor Framework": 0.78,
    "AirQA Dataset": 0.83
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Key technology enabling automated QA workflows, relevant for linking AI research.",
        "novelty_score": 0.45,
        "connectivity_score": 0.89,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Multimodal",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal"
        ],
        "category": "specific_connectable",
        "rationale": "Important for understanding the dataset's scope in handling diverse data types.",
        "novelty_score": 0.55,
        "connectivity_score": 0.78,
        "specificity_score": 0.8,
        "link_intent_score": 0.82
      },
      {
        "surface": "ExTrActor",
        "canonical": "ExTrActor Framework",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "A novel framework for data synthesis, crucial for dataset generation and evaluation.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "AirQA",
        "canonical": "AirQA Dataset",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Central to the paper, representing a new QA dataset for AI research.",
        "novelty_score": 0.8,
        "connectivity_score": 0.7,
        "specificity_score": 0.9,
        "link_intent_score": 0.83
      }
    ],
    "ban_list_suggestions": [
      "question answering",
      "dataset",
      "evaluation"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.89,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Multimodal",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.78,
        "specificity": 0.8,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "ExTrActor",
      "resolved_canonical": "ExTrActor Framework",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "AirQA",
      "resolved_canonical": "AirQA Dataset",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.7,
        "specificity": 0.9,
        "link_intent": 0.83
      }
    }
  ]
}
-->

# AirQA: A Comprehensive QA Dataset for AI Research with Instance-Level Evaluation

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16952.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.16952](https://arxiv.org/abs/2509.16952)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/SWE-QA_ Can Language Models Answer Repository-level Code Questions?_20250919|SWE-QA: Can Language Models Answer Repository-level Code Questions?]] (82.0% similar)
- [[2025-09-19/MovieCORE_ COgnitive REasoning in Movies_20250919|MovieCORE: COgnitive REasoning in Movies]] (81.8% similar)
- [[2025-09-19/OpenLens AI_ Fully Autonomous Research Agent for Health Infomatics_20250919|OpenLens AI: Fully Autonomous Research Agent for Health Infomatics]] (80.7% similar)
- [[2025-09-18/MAFA_ A multi-agent framework for annotation_20250918|MAFA: A multi-agent framework for annotation]] (80.3% similar)
- [[2025-09-18/Self-Guided Function Calling in Large Language Models via Stepwise Experience Recall_20250918|Self-Guided Function Calling in Large Language Models via Stepwise Experience Recall]] (80.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**âš¡ Unique Technical**: [[keywords/ExTrActor Framework|ExTrActor Framework]], [[keywords/AirQA Dataset|AirQA Dataset]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16952v1 Announce Type: cross 
Abstract: The growing volume of academic papers has made it increasingly difficult for researchers to efficiently extract key information. While large language models (LLMs) based agents are capable of automating question answering (QA) workflows for scientific papers, there still lacks a comprehensive and realistic benchmark to evaluate their capabilities. Moreover, training an interactive agent for this specific task is hindered by the shortage of high-quality interaction trajectories. In this work, we propose AirQA, a human-annotated comprehensive paper QA dataset in the field of artificial intelligence (AI), with 13,948 papers and 1,246 questions, that encompasses multi-task, multi-modal and instance-level evaluation. Furthermore, we propose ExTrActor, an automated framework for instruction data synthesis. With three LLM-based agents, ExTrActor can perform example generation and trajectory collection without human intervention. Evaluations of multiple open-source and proprietary models show that most models underperform on AirQA, demonstrating the quality of our dataset. Extensive experiments confirm that ExTrActor consistently improves the multi-turn tool-use capability of small models, enabling them to achieve performance comparable to larger ones.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì—°êµ¬ìë“¤ì´ í•™ìˆ  ë…¼ë¬¸ì—ì„œ í•µì‹¬ ì •ë³´ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì¶”ì¶œí•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªê³  ìˆëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, AI ë¶„ì•¼ì˜ ë…¼ë¬¸ì— ëŒ€í•œ ì§ˆë¬¸ ì‘ë‹µ(QA) ë°ì´í„°ì…‹ì¸ AirQAë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. AirQAëŠ” 13,948ê°œì˜ ë…¼ë¬¸ê³¼ 1,246ê°œì˜ ì§ˆë¬¸ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ë‹¤ì¤‘ ì‘ì—…, ë‹¤ì¤‘ ëª¨ë“œ, ì¸ìŠ¤í„´ìŠ¤ ìˆ˜ì¤€ í‰ê°€ë¥¼ í¬í•¨í•©ë‹ˆë‹¤. ë˜í•œ, ExTrActorë¼ëŠ” ìë™í™”ëœ í”„ë ˆì„ì›Œí¬ë¥¼ í†µí•´ ì˜ˆì œ ìƒì„±ê³¼ ê²½ë¡œ ìˆ˜ì§‘ì„ ì¸ê°„ì˜ ê°œì… ì—†ì´ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—¬ëŸ¬ ëª¨ë¸ í‰ê°€ ê²°ê³¼, ëŒ€ë¶€ë¶„ì˜ ëª¨ë¸ì´ AirQAì—ì„œ ë‚®ì€ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë©°, ì´ëŠ” ë°ì´í„°ì…‹ì˜ í’ˆì§ˆì„ ì…ì¦í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ExTrActorëŠ” ì‘ì€ ëª¨ë¸ì˜ ë‹¤ì¤‘ í„´ ë„êµ¬ ì‚¬ìš© ëŠ¥ë ¥ì„ í–¥ìƒì‹œì¼œ, ë” í° ëª¨ë¸ê³¼ ìœ ì‚¬í•œ ì„±ëŠ¥ì„ ë‹¬ì„±í•  ìˆ˜ ìˆìŒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. í•™ìˆ  ë…¼ë¬¸ì˜ ì¦ê°€ë¡œ ì¸í•´ ì—°êµ¬ìë“¤ì´ í•µì‹¬ ì •ë³´ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì¶”ì¶œí•˜ëŠ” ê²ƒì´ ì–´ë ¤ì›Œì§€ê³  ìˆë‹¤.
- 2. AirQAëŠ” AI ë¶„ì•¼ì˜ 13,948ê°œ ë…¼ë¬¸ê³¼ 1,246ê°œ ì§ˆë¬¸ì„ í¬í•¨í•œ ì¸ê°„ ì£¼ì„ ê¸°ë°˜ì˜ í¬ê´„ì ì¸ ë…¼ë¬¸ QA ë°ì´í„°ì…‹ì´ë‹¤.
- 3. ExTrActorëŠ” ì¸ê°„ì˜ ê°œì… ì—†ì´ ì˜ˆì œ ìƒì„±ê³¼ ê²½ë¡œ ìˆ˜ì§‘ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ìë™í™”ëœ í”„ë ˆì„ì›Œí¬ì´ë‹¤.
- 4. AirQA ë°ì´í„°ì…‹ì„ í†µí•´ ëŒ€ë¶€ë¶„ì˜ ëª¨ë¸ì´ ì„±ëŠ¥ì´ ë¶€ì¡±í•¨ì„ ë³´ì—¬ì£¼ë©°, ì´ëŠ” ë°ì´í„°ì…‹ì˜ í’ˆì§ˆì„ ì…ì¦í•œë‹¤.
- 5. ExTrActorëŠ” ì†Œí˜• ëª¨ë¸ì˜ ë‹¤ì¤‘ í„´ ë„êµ¬ ì‚¬ìš© ëŠ¥ë ¥ì„ í–¥ìƒì‹œì¼œ ëŒ€í˜• ëª¨ë¸ì— í•„ì í•˜ëŠ” ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ê²Œ í•œë‹¤.


---

*Generated on 2025-09-23 23:38:37*