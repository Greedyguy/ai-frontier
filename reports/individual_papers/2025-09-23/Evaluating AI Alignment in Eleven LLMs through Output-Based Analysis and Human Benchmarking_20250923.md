---
keywords:
  - Large Language Model
  - AI Alignment
  - Human Benchmarking
  - Value Prioritization
  - Human-Centric Models
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2506.12617
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T00:27:41.128108",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "AI Alignment",
    "Human Benchmarking",
    "Value Prioritization",
    "Human-Centric Models"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "AI Alignment": 0.9,
    "Human Benchmarking": 0.82,
    "Value Prioritization": 0.8,
    "Human-Centric Models": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "A core technology discussed in the paper, crucial for linking to related AI alignment and evaluation research.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "AI Alignment",
        "canonical": "AI Alignment",
        "aliases": [
          "Alignment"
        ],
        "category": "specific_connectable",
        "rationale": "Central theme of the paper, connecting to broader discussions on aligning AI systems with human values.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.8,
        "link_intent_score": 0.9
      },
      {
        "surface": "Human Benchmarking",
        "canonical": "Human Benchmarking",
        "aliases": [
          "Human Evaluation"
        ],
        "category": "unique_technical",
        "rationale": "Highlights the method of comparing AI outputs to human judgments, relevant for linking to evaluation methodologies.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "Value Prioritization",
        "canonical": "Value Prioritization",
        "aliases": [
          "Value Ranking"
        ],
        "category": "unique_technical",
        "rationale": "Describes the process of ranking values, which is key to understanding AI behavior in the study.",
        "novelty_score": 0.6,
        "connectivity_score": 0.75,
        "specificity_score": 0.77,
        "link_intent_score": 0.8
      },
      {
        "surface": "Human-Centric Models",
        "canonical": "Human-Centric Models",
        "aliases": [
          "Human-Oriented Models"
        ],
        "category": "evolved_concepts",
        "rationale": "Differentiates models that align closely with human values, important for discussions on model design.",
        "novelty_score": 0.7,
        "connectivity_score": 0.72,
        "specificity_score": 0.82,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "PAPERS",
      "Study 1",
      "Study 2",
      "Study 3"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "AI Alignment",
      "resolved_canonical": "AI Alignment",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.8,
        "link_intent": 0.9
      }
    },
    {
      "candidate_surface": "Human Benchmarking",
      "resolved_canonical": "Human Benchmarking",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Value Prioritization",
      "resolved_canonical": "Value Prioritization",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.75,
        "specificity": 0.77,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Human-Centric Models",
      "resolved_canonical": "Human-Centric Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.72,
        "specificity": 0.82,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# Evaluating AI Alignment in Eleven LLMs through Output-Based Analysis and Human Benchmarking

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2506.12617.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2506.12617](https://arxiv.org/abs/2506.12617)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/Do LLMs Align Human Values Regarding Social Biases? Judging and Explaining Social Biases with LLMs_20250918|Do LLMs Align Human Values Regarding Social Biases? Judging and Explaining Social Biases with LLMs]] (86.9% similar)
- [[2025-09-23/Evaluating Behavioral Alignment in Conflict Dialogue_ A Multi-Dimensional Comparison of LLM Agents and Humans_20250923|Evaluating Behavioral Alignment in Conflict Dialogue: A Multi-Dimensional Comparison of LLM Agents and Humans]] (86.7% similar)
- [[2025-09-23/AIPsychoBench_ Understanding the Psychometric Differences between LLMs and Humans_20250923|AIPsychoBench: Understanding the Psychometric Differences between LLMs and Humans]] (85.1% similar)
- [[2025-09-19/Adding LLMs to the psycholinguistic norming toolbox_ A practical guide to getting the most out of human ratings_20250919|Adding LLMs to the psycholinguistic norming toolbox: A practical guide to getting the most out of human ratings]] (84.2% similar)
- [[2025-09-19/Rationality Check! Benchmarking the Rationality of Large Language Models_20250919|Rationality Check! Benchmarking the Rationality of Large Language Models]] (84.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/AI Alignment|AI Alignment]]
**âš¡ Unique Technical**: [[keywords/Human Benchmarking|Human Benchmarking]], [[keywords/Value Prioritization|Value Prioritization]]
**ğŸš€ Evolved Concepts**: [[keywords/Human-Centric Models|Human-Centric Models]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2506.12617v3 Announce Type: replace 
Abstract: Large language models (LLMs) are increasingly used in psychological research and practice, yet traditional benchmarks reveal little about the values they express in real interaction. We introduce PAPERS, an output-based evaluation of the values LLMs prioritise in their text. Study 1 thematically analysed responses from eleven LLMs, identifying five recurring dimensions (Purposeful Contribution, Adaptive Growth, Positive Relationality, Ethical Integrity, and Robust Functionality) with Self-Actualised Autonomy appearing only under a hypothetical sentience prompt. These results suggest that LLMs are trained to prioritise humanistic and utility values as dual objectives of optimal functioning, a pattern supported by existing AI alignment and prioritisation frameworks. Study 2 operationalised PAPERS as a ranking instrument across the same eleven LLMs, yielding stable, non-random value priorities alongside systematic between-model differences. Hierarchical clustering distinguished "human-centric" models (e.g., ChatGPT-4o, Claude Sonnet 4) that prioritised relational/ethical values from "utility-driven" models (e.g., Llama 4, Gemini 2.5 Pro) that emphasised operational priorities. Study 3 benchmarked four LLMs against human judgements (N = 376) under matched prompts, finding near-perfect rank-order convergence (r = .97-.98) but moderate absolute agreement; among tested models, ChatGPT-4o showed the closest alignment with human ratings (ICC = .78). Humans also showed limited readiness to endorse sentient AI systems. Taken together, PAPERS enabled systematic value audits and revealed trade-offs with direct implications for deployment: human-centric models aligned more closely with human value judgments and appear better suited for humanistic psychological applications, whereas utility-driven models emphasised functional efficiency and may be more appropriate for instrumental or back-office tasks.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì´ ì‹¤ì œ ìƒí˜¸ì‘ìš©ì—ì„œ í‘œí˜„í•˜ëŠ” ê°€ì¹˜ë¥¼ í‰ê°€í•˜ê¸° ìœ„í•´ PAPERSë¼ëŠ” í‰ê°€ ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì—°êµ¬ 1ì—ì„œëŠ” 11ê°œì˜ LLMì„ ë¶„ì„í•˜ì—¬ ë‹¤ì„¯ ê°€ì§€ ê°€ì¹˜ ì°¨ì›(ëª©ì  ìˆëŠ” ê¸°ì—¬, ì ì‘ì  ì„±ì¥, ê¸ì •ì  ê´€ê³„ì„±, ìœ¤ë¦¬ì  ë¬´ê²°ì„±, ê²¬ê³ í•œ ê¸°ëŠ¥ì„±)ì„ ì‹ë³„í–ˆìŠµë‹ˆë‹¤. ì—°êµ¬ 2ì—ì„œëŠ” PAPERSë¥¼ í†µí•´ ëª¨ë¸ ê°„ì˜ ê°€ì¹˜ ìš°ì„ ìˆœìœ„ë¥¼ í‰ê°€í–ˆìœ¼ë©°, ì¸ê°„ ì¤‘ì‹¬ ëª¨ë¸(ì˜ˆ: ChatGPT-4o)ì´ ê´€ê³„ì /ìœ¤ë¦¬ì  ê°€ì¹˜ë¥¼, íš¨ìš© ì¤‘ì‹¬ ëª¨ë¸(ì˜ˆ: Llama 4)ì´ ê¸°ëŠ¥ì  ìš°ì„ ìˆœìœ„ë¥¼ ê°•ì¡°í•˜ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤. ì—°êµ¬ 3ì—ì„œëŠ” LLMê³¼ ì¸ê°„ì˜ ê°€ì¹˜ íŒë‹¨ì„ ë¹„êµí•˜ì—¬ ChatGPT-4oê°€ ì¸ê°„ í‰ê°€ì™€ ê°€ì¥ ì˜ ì¼ì¹˜í•¨ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ì¸ê°„ ì¤‘ì‹¬ ëª¨ë¸ì´ ì‹¬ë¦¬í•™ì  ì‘ìš©ì— ì í•©í•˜ê³ , íš¨ìš© ì¤‘ì‹¬ ëª¨ë¸ì´ ê¸°ëŠ¥ì  íš¨ìœ¨ì„±ì„ ì¤‘ì‹œí•˜ëŠ” ì—…ë¬´ì— ì í•©í•¨ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì€ ì‹¬ë¦¬í•™ ì—°êµ¬ ë° ì‹¤ë¬´ì—ì„œ ì ì  ë” ë§ì´ ì‚¬ìš©ë˜ê³  ìˆìœ¼ë©°, ì´ë“¤ì˜ í…ìŠ¤íŠ¸ì—ì„œ í‘œí˜„ë˜ëŠ” ê°€ì¹˜ ìš°ì„ ìˆœìœ„ë¥¼ í‰ê°€í•˜ê¸° ìœ„í•´ PAPERSë¼ëŠ” í‰ê°€ ë°©ë²•ì´ ë„ì…ë˜ì—ˆìŠµë‹ˆë‹¤.
- 2. ì—°êµ¬ 1ì—ì„œëŠ” 11ê°œì˜ LLMì„ ë¶„ì„í•˜ì—¬ ë‹¤ì„¯ ê°€ì§€ ë°˜ë³µì ì¸ ê°€ì¹˜ ì°¨ì›(ëª©ì  ìˆëŠ” ê¸°ì—¬, ì ì‘ì  ì„±ì¥, ê¸ì •ì  ê´€ê³„ì„±, ìœ¤ë¦¬ì  ë¬´ê²°ì„±, ê²¬ê³ í•œ ê¸°ëŠ¥ì„±)ì„ ì‹ë³„í•˜ì˜€ìœ¼ë©°, ììœ¨ì„±ì€ ê°€ìƒì˜ ê°ì„± í”„ë¡¬í”„íŠ¸ì—ì„œë§Œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.
- 3. ì—°êµ¬ 2ì—ì„œëŠ” PAPERSë¥¼ ë­í‚¹ ë„êµ¬ë¡œ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ ê°„ì˜ ê°€ì¹˜ ìš°ì„ ìˆœìœ„ë¥¼ í‰ê°€í–ˆìœ¼ë©°, ì¸ê°„ ì¤‘ì‹¬ ëª¨ë¸ê³¼ íš¨ìš© ì¤‘ì‹¬ ëª¨ë¸ ê°„ì˜ ì²´ê³„ì ì¸ ì°¨ì´ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.
- 4. ì—°êµ¬ 3ì—ì„œëŠ” ì¸ê°„ì˜ íŒë‹¨ê³¼ ë¹„êµí•˜ì—¬ LLMì˜ ìˆœìœ„ ì¼ì¹˜ë„ë¥¼ í‰ê°€í–ˆìœ¼ë©°, ChatGPT-4oê°€ ì¸ê°„ì˜ ê°€ì¹˜ íŒë‹¨ê³¼ ê°€ì¥ ê°€ê¹Œìš´ ì¼ì¹˜ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.
- 5. PAPERSë¥¼ í†µí•´ ì¸ê°„ ì¤‘ì‹¬ ëª¨ë¸ì€ ì¸ê°„ì˜ ê°€ì¹˜ íŒë‹¨ê³¼ ë” ì˜ ë§ì•„ ì‹¬ë¦¬í•™ì  ì‘ìš©ì— ì í•©í•˜ë©°, íš¨ìš© ì¤‘ì‹¬ ëª¨ë¸ì€ ê¸°ëŠ¥ì  íš¨ìœ¨ì„±ì„ ê°•ì¡°í•˜ì—¬ ë„êµ¬ì  ë˜ëŠ” ë°±ì˜¤í”¼ìŠ¤ ì‘ì—…ì— ì í•©í•˜ë‹¤ëŠ” ê²°ë¡ ì„ ë„ì¶œí–ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 00:27:41*