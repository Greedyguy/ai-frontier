---
keywords:
  - Neural Network
  - ReLU Activation
  - Boolean Network
  - Formal Verification
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.16547
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T22:49:54.886865",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Neural Network",
    "ReLU Activation",
    "Boolean Network",
    "Formal Verification"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Neural Network": 0.85,
    "ReLU Activation": 0.7,
    "Boolean Network": 0.65,
    "Formal Verification": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Neural Networks",
        "canonical": "Neural Network",
        "aliases": [
          "NN",
          "Neural Nets"
        ],
        "category": "broad_technical",
        "rationale": "Central topic of the paper, providing a broad technical context for linking.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.5,
        "link_intent_score": 0.85
      },
      {
        "surface": "ReLU-activation",
        "canonical": "ReLU Activation",
        "aliases": [
          "Rectified Linear Unit"
        ],
        "category": "specific_connectable",
        "rationale": "Specific activation function discussed, relevant for linking to detailed neural network architectures.",
        "novelty_score": 0.55,
        "connectivity_score": 0.78,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      },
      {
        "surface": "Boolean networks",
        "canonical": "Boolean Network",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Distinct type of network analyzed, offering unique technical insights.",
        "novelty_score": 0.65,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.65
      },
      {
        "surface": "formal verification",
        "canonical": "Formal Verification",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Key method used for rule checking, important for linking to verification techniques.",
        "novelty_score": 0.6,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "rule",
      "algorithm",
      "complexity theoretic"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Neural Networks",
      "resolved_canonical": "Neural Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.5,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "ReLU-activation",
      "resolved_canonical": "ReLU Activation",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.78,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Boolean networks",
      "resolved_canonical": "Boolean Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.65
      }
    },
    {
      "candidate_surface": "formal verification",
      "resolved_canonical": "Formal Verification",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# Checking extracted rules in Neural Networks

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16547.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.16547](https://arxiv.org/abs/2509.16547)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Adversarial generalization of unfolding (model-based) networks_20250922|Adversarial generalization of unfolding (model-based) networks]] (80.4% similar)
- [[2025-09-17/A Neural Network for the Identical Kuramoto Equation_ Architectural Considerations and Performance Evaluation_20250917|A Neural Network for the Identical Kuramoto Equation: Architectural Considerations and Performance Evaluation]] (79.5% similar)
- [[2025-09-17/Circuit realization and hardware linearization of monotone operator equilibrium networks_20250917|Circuit realization and hardware linearization of monotone operator equilibrium networks]] (79.2% similar)
- [[2025-09-19/Mini-Batch Robustness Verification of Deep Neural Networks_20250919|Mini-Batch Robustness Verification of Deep Neural Networks]] (79.2% similar)
- [[2025-09-18/Self-Explaining Reinforcement Learning for Mobile Network Resource Allocation_20250918|Self-Explaining Reinforcement Learning for Mobile Network Resource Allocation]] (78.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Neural Network|Neural Network]]
**ğŸ”— Specific Connectable**: [[keywords/ReLU Activation|ReLU Activation]], [[keywords/Formal Verification|Formal Verification]]
**âš¡ Unique Technical**: [[keywords/Boolean Network|Boolean Network]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16547v1 Announce Type: new 
Abstract: In this paper we investigate formal verification of extracted rules for Neural Networks under a complexity theoretic point of view. A rule is a global property or a pattern concerning a large portion of the input space of a network. These rules are algorithmically extracted from networks in an effort to better understand their inner way of working. Here, three problems will be in the focus: Does a given set of rules apply to a given network? Is a given set of rules consistent or do the rules contradict themselves? Is a given set of rules exhaustive in the sense that for every input the output is determined? Finding algorithms that extract such rules out of networks has been investigated over the last 30 years, however, to the author's current knowledge, no attempt in verification was made until now. A lot of attempts of extracting rules use heuristics involving randomness and over-approximation, so it might be beneficial to know whether knowledge obtained in that way can actually be trusted.
  We investigate the above questions for neural networks with ReLU-activation as well as for Boolean networks, each for several types of rules. We demonstrate how these problems can be reduced to each other and show that most of them are co-NP-complete.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì‹ ê²½ë§ì—ì„œ ì¶”ì¶œëœ ê·œì¹™ì˜ í˜•ì‹ì  ê²€ì¦ì„ ë³µì¡ë„ ì´ë¡  ê´€ì ì—ì„œ ì—°êµ¬í•©ë‹ˆë‹¤. ê·œì¹™ì€ ë„¤íŠ¸ì›Œí¬ì˜ ì…ë ¥ ê³µê°„ì˜ í° ë¶€ë¶„ì— ëŒ€í•œ ì „ì—­ì  íŠ¹ì„±ì´ë‚˜ íŒ¨í„´ì„ ì˜ë¯¸í•˜ë©°, ë„¤íŠ¸ì›Œí¬ì˜ ì‘ë™ ë°©ì‹ì„ ì´í•´í•˜ê¸° ìœ„í•´ ì•Œê³ ë¦¬ì¦˜ì ìœ¼ë¡œ ì¶”ì¶œë©ë‹ˆë‹¤. ë³¸ ì—°êµ¬ëŠ” ì„¸ ê°€ì§€ ë¬¸ì œì— ì´ˆì ì„ ë§ì¶¥ë‹ˆë‹¤: ì£¼ì–´ì§„ ê·œì¹™ ì„¸íŠ¸ê°€ íŠ¹ì • ë„¤íŠ¸ì›Œí¬ì— ì ìš©ë˜ëŠ”ì§€, ê·œì¹™ì´ ì¼ê´€ì„±ì´ ìˆëŠ”ì§€, ëª¨ë“  ì…ë ¥ì— ëŒ€í•´ ì¶œë ¥ì´ ê²°ì •ë˜ëŠ”ì§€ ì—¬ë¶€ì…ë‹ˆë‹¤. ì €ìëŠ” ReLU í™œì„±í™” í•¨ìˆ˜ê°€ ìˆëŠ” ì‹ ê²½ë§ê³¼ ë¶ˆ ëŒ€ìˆ˜ ë„¤íŠ¸ì›Œí¬ì— ëŒ€í•´ ì´ëŸ¬í•œ ë¬¸ì œë¥¼ ì¡°ì‚¬í•˜ë©°, ëŒ€ë¶€ë¶„ì˜ ë¬¸ì œê°€ co-NP-ì™„ì „ì„ì„ ë³´ì…ë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ê·œì¹™ ì¶”ì¶œì˜ ì‹ ë¢°ì„±ì„ ë†’ì´ê¸° ìœ„í•œ ê²€ì¦ ì‹œë„ë¥¼ ì²˜ìŒìœ¼ë¡œ ì œì•ˆí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì‹ ê²½ë§ì—ì„œ ì¶”ì¶œëœ ê·œì¹™ì˜ í˜•ì‹ì  ê²€ì¦ì„ ë³µì¡ë„ ì´ë¡ ì  ê´€ì ì—ì„œ ì¡°ì‚¬í•©ë‹ˆë‹¤.
- 2. ê·œì¹™ì˜ ì ìš© ê°€ëŠ¥ì„±, ì¼ê´€ì„±, í¬ê´„ì„±ì„ ê²€ì¦í•˜ëŠ” ì„¸ ê°€ì§€ ë¬¸ì œë¥¼ ì¤‘ì ì ìœ¼ë¡œ ë‹¤ë£¹ë‹ˆë‹¤.
- 3. ì‹ ê²½ë§ì—ì„œ ê·œì¹™ì„ ì¶”ì¶œí•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì€ 30ë…„ê°„ ì—°êµ¬ë˜ì—ˆì§€ë§Œ, ê²€ì¦ ì‹œë„ëŠ” ì´ë²ˆì´ ì²˜ìŒì…ë‹ˆë‹¤.
- 4. ReLU í™œì„±í™” í•¨ìˆ˜ì™€ ë¶ˆ ëŒ€ìˆ˜ ë„¤íŠ¸ì›Œí¬ì— ëŒ€í•´ ì—¬ëŸ¬ ìœ í˜•ì˜ ê·œì¹™ì„ ì¡°ì‚¬í•©ë‹ˆë‹¤.
- 5. ëŒ€ë¶€ë¶„ì˜ ë¬¸ì œëŠ” ì„œë¡œ í™˜ì› ê°€ëŠ¥í•˜ë©°, co-NP-ì™„ì „ì„ì„ ë³´ì…ë‹ˆë‹¤.


---

*Generated on 2025-09-23 22:49:54*