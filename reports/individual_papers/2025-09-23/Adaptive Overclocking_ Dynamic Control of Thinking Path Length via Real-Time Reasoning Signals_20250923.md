---
keywords:
  - Adaptive Overclocking
  - Large Language Model
  - Uncertainty-Aware Alpha Scheduling
  - Complexity-Guided Alpha Initialization
  - Hybrid Adaptive Control
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.17000
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T23:40:39.141530",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Adaptive Overclocking",
    "Large Language Model",
    "Uncertainty-Aware Alpha Scheduling",
    "Complexity-Guided Alpha Initialization",
    "Hybrid Adaptive Control"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Adaptive Overclocking": 0.8,
    "Large Language Model": 0.85,
    "Uncertainty-Aware Alpha Scheduling": 0.78,
    "Complexity-Guided Alpha Initialization": 0.78,
    "Hybrid Adaptive Control": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Adaptive Overclocking",
        "canonical": "Adaptive Overclocking",
        "aliases": [
          "Dynamic Overclocking",
          "Real-Time Overclocking"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel method proposed in the paper, offering a unique approach to dynamic reasoning control.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "Large Reasoning Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LRM"
        ],
        "category": "broad_technical",
        "rationale": "Links to the broader category of models that include reasoning capabilities, relevant for understanding computational efficiency.",
        "novelty_score": 0.4,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Uncertainty-Aware Alpha Scheduling",
        "canonical": "Uncertainty-Aware Alpha Scheduling",
        "aliases": [
          "UA-αS"
        ],
        "category": "unique_technical",
        "rationale": "Represents a specific strategy within the proposed method, highlighting its role in dynamic control.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Complexity-Guided Alpha Initialization",
        "canonical": "Complexity-Guided Alpha Initialization",
        "aliases": [
          "CG-αI"
        ],
        "category": "unique_technical",
        "rationale": "Another specific strategy that contributes to the method's effectiveness, focusing on initialization based on input complexity.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Hybrid Adaptive Control",
        "canonical": "Hybrid Adaptive Control",
        "aliases": [
          "HAC"
        ],
        "category": "unique_technical",
        "rationale": "Combines multiple strategies for enhanced performance, crucial for understanding the method's comprehensive approach.",
        "novelty_score": 0.72,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "overthinking",
      "reasoning speed",
      "accuracy-latency trade-offs"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Adaptive Overclocking",
      "resolved_canonical": "Adaptive Overclocking",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Large Reasoning Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Uncertainty-Aware Alpha Scheduling",
      "resolved_canonical": "Uncertainty-Aware Alpha Scheduling",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Complexity-Guided Alpha Initialization",
      "resolved_canonical": "Complexity-Guided Alpha Initialization",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Hybrid Adaptive Control",
      "resolved_canonical": "Hybrid Adaptive Control",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Adaptive Overclocking: Dynamic Control of Thinking Path Length via Real-Time Reasoning Signals

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17000.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.17000](https://arxiv.org/abs/2509.17000)

## 🔗 유사한 논문
- [[2025-09-23/Mitigating Strategy-Selection Bias in Reasoning for More Effective Test-Time Scaling_20250923|Mitigating Strategy-Selection Bias in Reasoning for More Effective Test-Time Scaling]] (82.9% similar)
- [[2025-09-23/Sycophancy Mitigation Through Reinforcement Learning with Uncertainty-Aware Adaptive Reasoning Trajectories_20250923|Sycophancy Mitigation Through Reinforcement Learning with Uncertainty-Aware Adaptive Reasoning Trajectories]] (82.6% similar)
- [[2025-09-22/Cache-of-Thought_ Master-Apprentice Framework for Cost-Effective Vision Language Model Reasoning_20250922|Cache-of-Thought: Master-Apprentice Framework for Cost-Effective Vision Language Model Reasoning]] (82.6% similar)
- [[2025-09-22/ConCISE_ Confidence-guided Compression in Step-by-step Efficient Reasoning_20250922|ConCISE: Confidence-guided Compression in Step-by-step Efficient Reasoning]] (82.6% similar)
- [[2025-09-23/Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates_20250923|Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates]] (82.5% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**⚡ Unique Technical**: [[keywords/Adaptive Overclocking|Adaptive Overclocking]], [[keywords/Uncertainty-Aware Alpha Scheduling|Uncertainty-Aware Alpha Scheduling]], [[keywords/Complexity-Guided Alpha Initialization|Complexity-Guided Alpha Initialization]], [[keywords/Hybrid Adaptive Control|Hybrid Adaptive Control]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.17000v1 Announce Type: cross 
Abstract: Large Reasoning Models (LRMs) often suffer from computational inefficiency due to overthinking, where a fixed reasoning budget fails to match the varying complexity of tasks. To address this issue, we propose Adaptive Overclocking, a method that makes the overclocking hyperparameter $\alpha$ dynamic and context-aware. Our method adjusts reasoning speed in real time through two complementary signals: (1) token-level model uncertainty for fine-grained step-wise control, and (2) input complexity estimation for informed initialization. We implement this approach with three strategies: Uncertainty-Aware Alpha Scheduling (UA-$\alpha$S), Complexity-Guided Alpha Initialization (CG-$\alpha$I), and a Hybrid Adaptive Control (HAC) that combines both. Experiments on GSM8K, MATH, and SVAMP show that HAC achieves superior accuracy-latency trade-offs, reducing unnecessary computation on simple problems while allocating more resources to challenging ones. By mitigating overthinking, Adaptive Overclocking enhances both efficiency and overall reasoning performance.

## 📝 요약

대형 추론 모델(LRMs)은 과도한 연산으로 인해 비효율성을 겪습니다. 이를 해결하기 위해, 우리는 적응형 오버클로킹 방법을 제안합니다. 이 방법은 오버클로킹 하이퍼파라미터 $\alpha$를 동적으로 조정하여 문맥에 맞게 반응합니다. 두 가지 신호, 즉 토큰 수준의 모델 불확실성과 입력 복잡도 추정을 통해 실시간으로 추론 속도를 조절합니다. 이 접근법은 불확실성 기반 알파 스케줄링(UA-$\alpha$S), 복잡도 기반 알파 초기화(CG-$\alpha$I), 그리고 두 가지를 결합한 하이브리드 적응 제어(HAC) 전략을 포함합니다. GSM8K, MATH, SVAMP 데이터셋 실험에서 HAC는 정확도와 지연 시간의 균형을 잘 맞추며, 간단한 문제에서는 불필요한 계산을 줄이고 복잡한 문제에는 더 많은 자원을 할당합니다. 적응형 오버클로킹은 과도한 연산을 줄여 효율성과 추론 성능을 향상시킵니다.

## 🎯 주요 포인트

- 1. 대규모 추론 모델(LRMs)은 과도한 연산으로 인해 비효율성이 발생하는 문제를 겪고 있습니다.
- 2. 이를 해결하기 위해, 우리는 과도한 연산의 하이퍼파라미터 $\alpha$를 동적이고 상황에 맞게 조정하는 Adaptive Overclocking 방법을 제안합니다.
- 3. 이 방법은 토큰 수준의 모델 불확실성과 입력 복잡도 추정을 통해 실시간으로 추론 속도를 조절합니다.
- 4. Uncertainty-Aware Alpha Scheduling (UA-$\alpha$S), Complexity-Guided Alpha Initialization (CG-$\alpha$I), Hybrid Adaptive Control (HAC) 세 가지 전략을 구현했습니다.
- 5. 실험 결과, HAC는 단순한 문제에서는 불필요한 연산을 줄이고, 복잡한 문제에는 더 많은 자원을 할당하여 정확성과 지연 시간의 균형을 개선했습니다.


---

*Generated on 2025-09-23 23:40:39*