---
keywords:
  - Neural Network
  - Confidence-Gated Training
  - Indian Pines Dataset
  - Fashion-MNIST Dataset
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.17885
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T00:11:57.709747",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Neural Network",
    "Confidence-Gated Training",
    "Indian Pines Dataset",
    "Fashion-MNIST Dataset"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Neural Network": 0.85,
    "Confidence-Gated Training": 0.78,
    "Indian Pines Dataset": 0.72,
    "Fashion-MNIST Dataset": 0.74
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Early-exit neural networks",
        "canonical": "Neural Network",
        "aliases": [
          "early exit networks",
          "exit networks"
        ],
        "category": "broad_technical",
        "rationale": "Links to the concept of neural networks with a focus on efficiency, relevant to resource-constrained environments.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Confidence-Gated Training",
        "canonical": "Confidence-Gated Training",
        "aliases": [
          "CGT"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel training paradigm that mitigates gradient interference, enhancing early-exit strategies.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Indian Pines",
        "canonical": "Indian Pines Dataset",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "A specific dataset used in experiments, relevant for linking to other works using the same dataset.",
        "novelty_score": 0.55,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.72
      },
      {
        "surface": "Fashion-MNIST",
        "canonical": "Fashion-MNIST Dataset",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "A widely used dataset for benchmarking, facilitating connections to other studies using this dataset.",
        "novelty_score": 0.5,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.74
      }
    ],
    "ban_list_suggestions": [
      "gradient interference",
      "resource-constrained environments"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Early-exit neural networks",
      "resolved_canonical": "Neural Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Confidence-Gated Training",
      "resolved_canonical": "Confidence-Gated Training",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Indian Pines",
      "resolved_canonical": "Indian Pines Dataset",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "Fashion-MNIST",
      "resolved_canonical": "Fashion-MNIST Dataset",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.74
      }
    }
  ]
}
-->

# Confidence-gated training for efficient early-exit neural networks

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17885.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.17885](https://arxiv.org/abs/2509.17885)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/CBPNet_ A Continual Backpropagation Prompt Network for Alleviating Plasticity Loss on Edge Devices_20250922|CBPNet: A Continual Backpropagation Prompt Network for Alleviating Plasticity Loss on Edge Devices]] (81.8% similar)
- [[2025-09-22/Deep Reinforcement Learning with Gradient Eligibility Traces_20250922|Deep Reinforcement Learning with Gradient Eligibility Traces]] (81.7% similar)
- [[2025-09-23/Gradient Interference-Aware Graph Coloring for Multitask Learning_20250923|Gradient Interference-Aware Graph Coloring for Multitask Learning]] (81.2% similar)
- [[2025-09-22/Neural Networks for Learnable and Scalable Influence Estimation of Instruction Fine-Tuning Data_20250922|Neural Networks for Learnable and Scalable Influence Estimation of Instruction Fine-Tuning Data]] (81.1% similar)
- [[2025-09-22/DIVEBATCH_ Accelerating Model Training Through Gradient-Diversity Aware Batch Size Adaptation_20250922|DIVEBATCH: Accelerating Model Training Through Gradient-Diversity Aware Batch Size Adaptation]] (81.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Neural Network|Neural Network]]
**ğŸ”— Specific Connectable**: [[keywords/Indian Pines Dataset|Indian Pines Dataset]], [[keywords/Fashion-MNIST Dataset|Fashion-MNIST Dataset]]
**âš¡ Unique Technical**: [[keywords/Confidence-Gated Training|Confidence-Gated Training]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17885v1 Announce Type: cross 
Abstract: Early-exit neural networks reduce inference cost by enabling confident predictions at intermediate layers. However, joint training often leads to gradient interference, with deeper classifiers dominating optimization. We propose Confidence-Gated Training (CGT), a paradigm that conditionally propagates gradients from deeper exits only when preceding exits fail. This encourages shallow classifiers to act as primary decision points while reserving deeper layers for harder inputs. By aligning training with the inference-time policy, CGT mitigates overthinking, improves early-exit accuracy, and preserves efficiency. Experiments on the Indian Pines and Fashion-MNIST benchmarks show that CGT lowers average inference cost while improving overall accuracy, offering a practical solution for deploying deep models in resource-constrained environments.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì¤‘ê°„ ê³„ì¸µì—ì„œ ìì‹  ìˆëŠ” ì˜ˆì¸¡ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ì—¬ ì¶”ë¡  ë¹„ìš©ì„ ì¤„ì´ëŠ” ì¡°ê¸° ì¢…ë£Œ ì‹ ê²½ë§ì— ëŒ€í•´ ë‹¤ë£¹ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê³µë™ í•™ìŠµ ì‹œ ê¹Šì€ ê³„ì¸µì˜ ë¶„ë¥˜ê¸°ê°€ ìµœì í™”ë¥¼ ì§€ë°°í•˜ëŠ” ë¬¸ì œì ì´ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” Confidence-Gated Training (CGT)ì´ë¼ëŠ” ë°©ë²•ë¡ ì„ ì œì•ˆí•©ë‹ˆë‹¤. CGTëŠ” ì´ì „ ê³„ì¸µì´ ì‹¤íŒ¨í•  ê²½ìš°ì—ë§Œ ê¹Šì€ ê³„ì¸µì—ì„œì˜ ê¸°ìš¸ê¸°ë¥¼ ì¡°ê±´ë¶€ë¡œ ì „íŒŒí•˜ì—¬ ì–•ì€ ê³„ì¸µì´ ì£¼ìš” ê²°ì • ì§€ì ìœ¼ë¡œ ì‘ìš©í•˜ë„ë¡ ìœ ë„í•©ë‹ˆë‹¤. ì´ëŠ” í›ˆë ¨ì„ ì¶”ë¡  ì‹œê°„ ì •ì±…ê³¼ ì¼ì¹˜ì‹œì¼œ ê³¼ë„í•œ ê³„ì‚°ì„ ì¤„ì´ê³ , ì¡°ê¸° ì¢…ë£Œ ì •í™•ë„ë¥¼ ê°œì„ í•˜ë©°, íš¨ìœ¨ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤. Indian Pinesì™€ Fashion-MNIST ë²¤ì¹˜ë§ˆí¬ ì‹¤í—˜ ê²°ê³¼, CGTëŠ” í‰ê·  ì¶”ë¡  ë¹„ìš©ì„ ë‚®ì¶”ë©´ì„œ ì „ì²´ ì •í™•ë„ë¥¼ í–¥ìƒì‹œì¼œ, ìì›ì´ ì œí•œëœ í™˜ê²½ì—ì„œ ì‹¬ì¸µ ëª¨ë¸ì„ ë°°í¬í•˜ëŠ” ì‹¤ìš©ì ì¸ ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì¡°ê¸° ì¢…ë£Œ ì‹ ê²½ë§ì€ ì¤‘ê°„ ê³„ì¸µì—ì„œ ìì‹  ìˆëŠ” ì˜ˆì¸¡ì„ í†µí•´ ì¶”ë¡  ë¹„ìš©ì„ ì¤„ì…ë‹ˆë‹¤.
- 2. ê³µë™ í•™ìŠµ ì‹œ ê¹Šì€ ê³„ì¸µì˜ ë¶„ë¥˜ê¸°ê°€ ìµœì í™”ë¥¼ ì§€ë°°í•˜ì—¬ ê·¸ë˜ë””ì–¸íŠ¸ ê°„ì„­ì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- 3. Confidence-Gated Training(CGT)ì€ ì´ì „ ê³„ì¸µì´ ì‹¤íŒ¨í•  ê²½ìš°ì—ë§Œ ê¹Šì€ ê³„ì¸µì˜ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ì „íŒŒí•˜ì—¬ ì–•ì€ ë¶„ë¥˜ê¸°ê°€ ì£¼ìš” ê²°ì • ì§€ì ìœ¼ë¡œ ì‘ìš©í•˜ë„ë¡ ìœ ë„í•©ë‹ˆë‹¤.
- 4. CGTëŠ” í›ˆë ¨ì„ ì¶”ë¡  ì‹œê°„ ì •ì±…ê³¼ ì •ë ¬í•˜ì—¬ ê³¼ë„í•œ ì—°ì‚°ì„ ì¤„ì´ê³ , ì¡°ê¸° ì¢…ë£Œ ì •í™•ë„ë¥¼ ê°œì„ í•˜ë©° íš¨ìœ¨ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤.
- 5. Indian Pinesì™€ Fashion-MNIST ë²¤ì¹˜ë§ˆí¬ ì‹¤í—˜ì—ì„œ CGTëŠ” í‰ê·  ì¶”ë¡  ë¹„ìš©ì„ ë‚®ì¶”ë©´ì„œ ì „ì²´ ì •í™•ë„ë¥¼ í–¥ìƒì‹œì¼œ, ìì›ì´ ì œí•œëœ í™˜ê²½ì—ì„œ ì‹¬ì¸µ ëª¨ë¸ì„ ë°°í¬í•˜ê¸° ìœ„í•œ ì‹¤ìš©ì ì¸ ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 00:11:57*