---
keywords:
  - Multi-Agent Systems
  - Large Language Model
  - Model Context Protocol
  - Agent-to-Agent Communication
  - Multimodal Learning
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2507.21105
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T01:15:28.134319",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multi-Agent Systems",
    "Large Language Model",
    "Model Context Protocol",
    "Agent-to-Agent Communication",
    "Multimodal Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multi-Agent Systems": 0.78,
    "Large Language Model": 0.82,
    "Model Context Protocol": 0.8,
    "Agent-to-Agent Communication": 0.79,
    "Multimodal Learning": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multi-Agent Systems",
        "canonical": "Multi-Agent Systems",
        "aliases": [
          "MAS"
        ],
        "category": "broad_technical",
        "rationale": "Multi-Agent Systems are central to the framework and connect to broader AI concepts.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.78
      },
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "LLMs are integral to the system's functionality and link to existing AI research.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.82
      },
      {
        "surface": "Model Context Protocol",
        "canonical": "Model Context Protocol",
        "aliases": [
          "MCP"
        ],
        "category": "unique_technical",
        "rationale": "MCP is a specific protocol used in the framework, highlighting its novelty.",
        "novelty_score": 0.75,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Agent-to-Agent communication",
        "canonical": "Agent-to-Agent Communication",
        "aliases": [
          "A2A"
        ],
        "category": "unique_technical",
        "rationale": "A2A is a novel communication protocol crucial for inter-agent interaction.",
        "novelty_score": 0.78,
        "connectivity_score": 0.72,
        "specificity_score": 0.82,
        "link_intent_score": 0.79
      },
      {
        "surface": "Multimodal Information Retrieval",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal Retrieval"
        ],
        "category": "specific_connectable",
        "rationale": "This concept connects to the trending area of integrating multiple data types in AI.",
        "novelty_score": 0.68,
        "connectivity_score": 0.85,
        "specificity_score": 0.78,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "framework",
      "system",
      "interface"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multi-Agent Systems",
      "resolved_canonical": "Multi-Agent Systems",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Model Context Protocol",
      "resolved_canonical": "Model Context Protocol",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Agent-to-Agent communication",
      "resolved_canonical": "Agent-to-Agent Communication",
      "decision": "linked",
      "scores": {
        "novelty": 0.78,
        "connectivity": 0.72,
        "specificity": 0.82,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Multimodal Information Retrieval",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.85,
        "specificity": 0.78,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# AgentMaster: A Multi-Agent Conversational Framework Using A2A and MCP Protocols for Multimodal Information Retrieval and Analysis

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2507.21105.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2507.21105](https://arxiv.org/abs/2507.21105)

## 🔗 유사한 논문
- [[2025-09-18/AppAgent v2_ Advanced Agent for Flexible Mobile Interactions_20250918|AppAgent v2: Advanced Agent for Flexible Mobile Interactions]] (85.7% similar)
- [[2025-09-23/XAgents_ A Framework for Interpretable Rule-Based Multi-Agents Cooperation_20250923|XAgents: A Framework for Interpretable Rule-Based Multi-Agents Cooperation]] (85.0% similar)
- [[2025-09-18/$Agent^2$_ An Agent-Generates-Agent Framework for Reinforcement Learning Automation_20250918|$Agent^2$: An Agent-Generates-Agent Framework for Reinforcement Learning Automation]] (84.8% similar)
- [[2025-09-19/Internalizing Self-Consistency in Language Models_ Multi-Agent Consensus Alignment_20250919|Internalizing Self-Consistency in Language Models: Multi-Agent Consensus Alignment]] (84.6% similar)
- [[2025-09-19/An LLM-based multi-agent framework for agile effort estimation_20250919|An LLM-based multi-agent framework for agile effort estimation]] (84.3% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Multi-Agent Systems|Multi-Agent Systems]], [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**⚡ Unique Technical**: [[keywords/Model Context Protocol|Model Context Protocol]], [[keywords/Agent-to-Agent Communication|Agent-to-Agent Communication]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2507.21105v2 Announce Type: replace-cross 
Abstract: The rise of Multi-Agent Systems (MAS) in Artificial Intelligence (AI), especially integrated with Large Language Models (LLMs), has greatly facilitated the resolution of complex tasks. However, current systems are still facing challenges of inter-agent communication, coordination, and interaction with heterogeneous tools and resources. Most recently, the Model Context Protocol (MCP) by Anthropic and Agent-to-Agent (A2A) communication protocol by Google have been introduced, and to the best of our knowledge, very few applications exist where both protocols are employed within a single MAS framework. We present a pilot study of AgentMaster, a novel modular multi-protocol MAS framework with self-implemented A2A and MCP, enabling dynamic coordination, flexible communication, and rapid development with faster iteration. Through a unified conversational interface, the system supports natural language interaction without prior technical expertise and responds to multimodal queries for tasks including information retrieval, question answering, and image analysis. The experiments are validated through both human evaluation and quantitative metrics, including BERTScore F1 (96.3%) and LLM-as-a-Judge G-Eval (87.1%). These results demonstrate robust automated inter-agent coordination, query decomposition, task allocation, dynamic routing, and domain-specific relevant responses. Overall, our proposed framework contributes to the potential capabilities of domain-specific, cooperative, and scalable conversational AI powered by MAS.

## 📝 요약

이 논문은 대규모 언어 모델(LLM)과 통합된 다중 에이전트 시스템(MAS)의 발전을 다루며, 특히 Anthropic의 MCP와 Google's A2A 통신 프로토콜을 결합한 AgentMaster라는 새로운 MAS 프레임워크를 소개합니다. 이 시스템은 에이전트 간의 동적 조정과 유연한 통신을 가능하게 하며, 기술적 전문 지식 없이도 자연어 상호작용을 지원합니다. 실험 결과, BERTScore F1 96.3%와 LLM-as-a-Judge G-Eval 87.1%의 높은 성능을 보이며, 자동화된 에이전트 간 조정 및 도메인 특화 응답의 가능성을 입증했습니다. 이 연구는 협력적이고 확장 가능한 대화형 AI의 잠재력을 제시합니다.

## 🎯 주요 포인트

- 1. Multi-Agent Systems(MAS)와 대형 언어 모델(LLM)의 통합은 복잡한 작업 해결을 크게 촉진하지만, 현재 시스템은 에이전트 간의 통신, 조정 및 이질적인 도구와 자원의 상호작용에서 여전히 어려움을 겪고 있습니다.
- 2. Anthropic의 Model Context Protocol(MCP)과 Google의 Agent-to-Agent(A2A) 통신 프로토콜이 최근 도입되었으며, 두 프로토콜이 단일 MAS 프레임워크 내에서 사용되는 사례는 거의 없습니다.
- 3. AgentMaster는 A2A와 MCP를 자체 구현한 새로운 모듈형 다중 프로토콜 MAS 프레임워크로, 동적 조정, 유연한 통신 및 빠른 개발을 가능하게 합니다.
- 4. 이 시스템은 통합된 대화형 인터페이스를 통해 기술적 전문 지식 없이 자연어 상호작용을 지원하며, 정보 검색, 질문 응답 및 이미지 분석을 포함한 작업에 대한 다중 모드 쿼리에 응답합니다.
- 5. 실험 결과는 BERTScore F1(96.3%) 및 LLM-as-a-Judge G-Eval(87.1%)을 포함한 정량적 지표와 인간 평가를 통해 검증되었으며, 강력한 자동화된 에이전트 간 조정 및 도메인별 관련 응답을 보여줍니다.


---

*Generated on 2025-09-24 01:15:28*