---
keywords:
  - Large Language Model
  - Visual Program Reasoning
  - Vision-Language Model
  - Fast-Slow Reasoning Framework
  - Parameter Search
category: cs.CV
publish_date: 2025-09-23
arxiv_id: 2509.17743
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T05:01:28.877566",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Visual Program Reasoning",
    "Vision-Language Model",
    "Fast-Slow Reasoning Framework",
    "Parameter Search"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Visual Program Reasoning": 0.78,
    "Vision-Language Model": 0.8,
    "Fast-Slow Reasoning Framework": 0.82,
    "Parameter Search": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "LLMs are central to the paper's approach and connect to existing research in language models.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Visual Program Reasoning",
        "canonical": "Visual Program Reasoning",
        "aliases": [
          "Visual Reasoning"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel approach introduced in the paper, providing a unique perspective on videoQA.",
        "novelty_score": 0.75,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Vision-Language Models",
        "canonical": "Vision-Language Model",
        "aliases": [
          "VideoLLMs"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-Language Models are crucial for the integration of visual and textual data in the paper.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.75,
        "link_intent_score": 0.8
      },
      {
        "surface": "Fast-Slow Reasoning Framework",
        "canonical": "Fast-Slow Reasoning Framework",
        "aliases": [
          "FS-VisPR"
        ],
        "category": "unique_technical",
        "rationale": "This framework is a key contribution of the paper, offering a new method for handling complex queries.",
        "novelty_score": 0.8,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.82
      },
      {
        "surface": "Parameter Search",
        "canonical": "Parameter Search",
        "aliases": [
          "Parameter Tuning"
        ],
        "category": "specific_connectable",
        "rationale": "Parameter search is a critical component for optimizing visual programs, linking to broader optimization techniques.",
        "novelty_score": 0.4,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "program workflows",
      "subtitle retrieval"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Visual Program Reasoning",
      "resolved_canonical": "Visual Program Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Vision-Language Models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.75,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Fast-Slow Reasoning Framework",
      "resolved_canonical": "Fast-Slow Reasoning Framework",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Parameter Search",
      "resolved_canonical": "Parameter Search",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# Adaptive Fast-and-Slow Visual Program Reasoning for Long-Form VideoQA

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17743.pdf)
**Category**: cs.CV
**Published**: 2025-09-23
**ArXiv ID**: [2509.17743](https://arxiv.org/abs/2509.17743)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/ProReason_ Multi-Modal Proactive Reasoning with Decoupled Eyesight and Wisdom_20250923|ProReason: Multi-Modal Proactive Reasoning with Decoupled Eyesight and Wisdom]] (85.8% similar)
- [[2025-09-23/Open Vision Reasoner_ Transferring Linguistic Cognitive Behavior for Visual Reasoning_20250923|Open Vision Reasoner: Transferring Linguistic Cognitive Behavior for Visual Reasoning]] (84.7% similar)
- [[2025-09-23/Eye Gaze Tells You Where to Compute_ Gaze-Driven Efficient VLMs_20250923|Eye Gaze Tells You Where to Compute: Gaze-Driven Efficient VLMs]] (83.6% similar)
- [[2025-09-22/Think, Verbalize, then Speak_ Bridging Complex Thoughts and Comprehensible Speech_20250922|Think, Verbalize, then Speak: Bridging Complex Thoughts and Comprehensible Speech]] (83.0% similar)
- [[2025-09-23/ProtoVQA_ An Adaptable Prototypical Framework for Explainable Fine-Grained Visual Question Answering_20250923|ProtoVQA: An Adaptable Prototypical Framework for Explainable Fine-Grained Visual Question Answering]] (82.9% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Parameter Search|Parameter Search]]
**âš¡ Unique Technical**: [[keywords/Visual Program Reasoning|Visual Program Reasoning]], [[keywords/Fast-Slow Reasoning Framework|Fast-Slow Reasoning Framework]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17743v1 Announce Type: new 
Abstract: Large language models (LLMs) have shown promise in generating program workflows for visual tasks. However, previous approaches often rely on closed-source models, lack systematic reasoning, and struggle with long-form video question answering (videoQA). To address these challenges, we introduce the FS-VisPR framework, an adaptive visual program reasoning approach that balances fast reasoning for simple queries with slow reasoning for difficult ones. First, we design efficient visual modules (e.g., key clip retrieval and subtitle retrieval) to support long-form video tasks. Then, we construct a diverse and high-quality fast-slow reasoning dataset with a strong LLM to align open-source language models' ability to generate visual program workflows as FS-LLM. Next, we design a fast-slow reasoning framework with FS-LLM: Simple queries are directly solved by VideoLLMs, while difficult ones invoke visual program reasoning, motivated by human-like reasoning processes. During this process, low-confidence fast-thinking answers will trigger a second-stage slow-reasoning process, and a fallback mechanism to fast reasoning is activated if the program execution fails. Moreover, we improve visual programs through parameter search during both training and inference. By adjusting the parameters of the visual modules within the program, multiple variants are generated: during training, programs that yield correct answers are selected, while during inference, the program with the highest confidence result is applied. Experiments show that FS-VisPR improves both efficiency and reliability in visual program workflows. It achieves 50.4% accuracy on LVBench, surpassing GPT-4o, matching the performance of Qwen2.5VL-72B on VideoMME.

## ğŸ“ ìš”ì•½

FS-VisPR í”„ë ˆì„ì›Œí¬ëŠ” ì‹œê°ì  í”„ë¡œê·¸ë¨ ì¶”ë¡ ì„ í†µí•´ ì¥ë¬¸ì˜ ë¹„ë””ì˜¤ ì§ˆë¬¸ ì‘ë‹µ(videoQA) ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ì ‘ê·¼ë²•ì…ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ê°„ë‹¨í•œ ì¿¼ë¦¬ì—ëŠ” ë¹ ë¥¸ ì¶”ë¡ ì„, ë³µì¡í•œ ì¿¼ë¦¬ì—ëŠ” ëŠë¦° ì¶”ë¡ ì„ ì ìš©í•˜ì—¬ íš¨ìœ¨ì„±ì„ ë†’ì…ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ í‚¤ í´ë¦½ ë° ìë§‰ ê²€ìƒ‰ê³¼ ê°™ì€ íš¨ìœ¨ì ì¸ ì‹œê° ëª¨ë“ˆì„ ì„¤ê³„í•˜ê³ , ë‹¤ì–‘í•œ ë¹ ë¥¸-ëŠë¦° ì¶”ë¡  ë°ì´í„°ì…‹ì„ êµ¬ì¶•í•˜ì—¬ ì˜¤í”ˆì†ŒìŠ¤ ì–¸ì–´ ëª¨ë¸ì˜ ì‹œê° í”„ë¡œê·¸ë¨ ì›Œí¬í”Œë¡œìš° ìƒì„± ëŠ¥ë ¥ì„ ê°•í™”í–ˆìŠµë‹ˆë‹¤. FS-LLMì„ í™œìš©í•œ ì´ í”„ë ˆì„ì›Œí¬ëŠ” ì¸ê°„ì˜ ì‚¬ê³  ê³¼ì •ì„ ëª¨ë°©í•˜ì—¬, ë‚®ì€ ì‹ ë¢°ë„ì˜ ë¹ ë¥¸ ì¶”ë¡  ê²°ê³¼ëŠ” ëŠë¦° ì¶”ë¡  ë‹¨ê³„ë¡œ ì „í™˜í•˜ë©°, í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì‹¤íŒ¨ ì‹œ ë¹ ë¥¸ ì¶”ë¡ ìœ¼ë¡œ ë³µê·€í•©ë‹ˆë‹¤. ë˜í•œ, ì‹œê° ëª¨ë“ˆì˜ ë§¤ê°œë³€ìˆ˜ ì¡°ì •ì„ í†µí•´ ë‹¤ì–‘í•œ í”„ë¡œê·¸ë¨ ë³€í˜•ì„ ìƒì„±í•˜ê³ , í›ˆë ¨ ë° ì¶”ë¡  ê³¼ì •ì—ì„œ ìµœì ì˜ í”„ë¡œê·¸ë¨ì„ ì„ íƒí•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, FS-VisPRì€ LVBenchì—ì„œ 50.4%ì˜ ì •í™•ë„ë¥¼ ê¸°ë¡í•˜ë©°, GPT-4oë¥¼ ëŠ¥ê°€í•˜ê³  Qwen2.5VL-72Bì™€ ìœ ì‚¬í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. FS-VisPR í”„ë ˆì„ì›Œí¬ëŠ” ê°„ë‹¨í•œ ì¿¼ë¦¬ì—ëŠ” ë¹ ë¥¸ ì¶”ë¡ ì„, ì–´ë ¤ìš´ ì¿¼ë¦¬ì—ëŠ” ëŠë¦° ì¶”ë¡ ì„ ì ìš©í•˜ì—¬ ë¹„ì£¼ì–¼ í”„ë¡œê·¸ë¨ ì›Œí¬í”Œë¡œìš°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
- 2. íš¨ìœ¨ì ì¸ ë¹„ì£¼ì–¼ ëª¨ë“ˆ(ì˜ˆ: í‚¤ í´ë¦½ ê²€ìƒ‰ ë° ìë§‰ ê²€ìƒ‰)ì„ ì„¤ê³„í•˜ì—¬ ì¥ê¸° ë¹„ë””ì˜¤ ì‘ì—…ì„ ì§€ì›í•©ë‹ˆë‹¤.
- 3. FS-LLMì„ í†µí•´ ì˜¤í”ˆ ì†ŒìŠ¤ ì–¸ì–´ ëª¨ë¸ì˜ ë¹„ì£¼ì–¼ í”„ë¡œê·¸ë¨ ì›Œí¬í”Œë¡œìš° ìƒì„± ëŠ¥ë ¥ì„ ê°•í™”í•˜ê³ , ë‹¤ì–‘í•œ ê³ í’ˆì§ˆì˜ ë¹ ë¥¸-ëŠë¦° ì¶”ë¡  ë°ì´í„°ì…‹ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.
- 4. ë‚®ì€ ì‹ ë¢°ë„ì˜ ë¹ ë¥¸ ì¶”ë¡  ë‹µë³€ì€ ë‘ ë²ˆì§¸ ë‹¨ê³„ì˜ ëŠë¦° ì¶”ë¡  ê³¼ì •ì„ ìœ ë°œí•˜ë©°, í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì‹¤íŒ¨ ì‹œ ë¹ ë¥¸ ì¶”ë¡ ìœ¼ë¡œ ë˜ëŒì•„ê°€ëŠ” ë©”ì»¤ë‹ˆì¦˜ì´ ì‘ë™í•©ë‹ˆë‹¤.
- 5. FS-VisPRì€ LVBenchì—ì„œ 50.4%ì˜ ì •í™•ë„ë¥¼ ë‹¬ì„±í•˜ë©°, GPT-4oë¥¼ ëŠ¥ê°€í•˜ê³  Qwen2.5VL-72Bì™€ ì„±ëŠ¥ì„ ë§ì¶¥ë‹ˆë‹¤.


---

*Generated on 2025-09-24 05:01:28*