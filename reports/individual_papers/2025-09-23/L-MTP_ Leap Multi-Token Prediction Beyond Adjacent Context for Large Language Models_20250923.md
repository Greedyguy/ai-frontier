---
keywords:
  - Large Language Model
  - Leap Multi-Token Prediction
  - Next-Token Prediction
  - Inference Efficiency
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2505.17505
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:57:53.151212",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Leap Multi-Token Prediction",
    "Next-Token Prediction",
    "Inference Efficiency"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Leap Multi-Token Prediction": 0.9,
    "Next-Token Prediction": 0.8,
    "Inference Efficiency": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Large Language Models"
        ],
        "category": "broad_technical",
        "rationale": "This is a fundamental concept in the paper, connecting to a wide range of topics in AI and NLP.",
        "novelty_score": 0.2,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Leap Multi-Token Prediction",
        "canonical": "Leap Multi-Token Prediction",
        "aliases": [
          "L-MTP"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel prediction mechanism that is central to the paper's contributions.",
        "novelty_score": 0.9,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.9
      },
      {
        "surface": "Next-Token Prediction",
        "canonical": "Next-Token Prediction",
        "aliases": [
          "NTP"
        ],
        "category": "specific_connectable",
        "rationale": "A key concept in language model training that contrasts with the proposed method.",
        "novelty_score": 0.3,
        "connectivity_score": 0.7,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Inference Efficiency",
        "canonical": "Inference Efficiency",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "A critical aspect of model performance discussed in the paper.",
        "novelty_score": 0.4,
        "connectivity_score": 0.75,
        "specificity_score": 0.65,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.2,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Leap Multi-Token Prediction",
      "resolved_canonical": "Leap Multi-Token Prediction",
      "decision": "linked",
      "scores": {
        "novelty": 0.9,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.9
      }
    },
    {
      "candidate_surface": "Next-Token Prediction",
      "resolved_canonical": "Next-Token Prediction",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.7,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Inference Efficiency",
      "resolved_canonical": "Inference Efficiency",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.75,
        "specificity": 0.65,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# L-MTP: Leap Multi-Token Prediction Beyond Adjacent Context for Large Language Models

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2505.17505.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2505.17505](https://arxiv.org/abs/2505.17505)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Modular Machine Learning_ An Indispensable Path towards New-Generation Large Language Models_20250919|Modular Machine Learning: An Indispensable Path towards New-Generation Large Language Models]] (86.4% similar)
- [[2025-09-23/Probabilistic Token Alignment for Large Language Model Fusion_20250923|Probabilistic Token Alignment for Large Language Model Fusion]] (86.1% similar)
- [[2025-09-19/DetectAnyLLM_ Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models_20250919|DetectAnyLLM: Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models]] (86.0% similar)
- [[2025-09-22/Predicting Language Models' Success at Zero-Shot Probabilistic Prediction_20250922|Predicting Language Models' Success at Zero-Shot Probabilistic Prediction]] (86.0% similar)
- [[2025-09-23/Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates_20250923|Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates]] (85.7% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Next-Token Prediction|Next-Token Prediction]], [[keywords/Inference Efficiency|Inference Efficiency]]
**âš¡ Unique Technical**: [[keywords/Leap Multi-Token Prediction|Leap Multi-Token Prediction]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2505.17505v2 Announce Type: replace 
Abstract: Large language models (LLMs) have achieved notable progress. Despite their success, next-token prediction (NTP), the dominant method for LLM training and inference, is constrained in both contextual coverage and inference efficiency due to its inherently sequential process. To overcome these challenges, we propose leap multi-token prediction~(L-MTP), an innovative token prediction method that extends the capabilities of multi-token prediction (MTP) by introducing a leap-based mechanism. Unlike conventional MTP, which generates multiple tokens at adjacent positions, L-MTP strategically skips over intermediate tokens, predicting non-sequential ones in a single forward pass. This structured leap not only enhances the model's ability to capture long-range dependencies but also enables a decoding strategy specially optimized for non-sequential leap token generation, effectively accelerating inference. We theoretically demonstrate the benefit of L-MTP in improving inference efficiency. Experiments across diverse benchmarks validate its merit in boosting both LLM performance and inference speed. The source code is available at https://github.com/Xiaohao-Liu/L-MTP.

## ğŸ“ ìš”ì•½

ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ ìƒë‹¹í•œ ë°œì „ì„ ì´ë£¨ì—ˆìœ¼ë‚˜, ê¸°ì¡´ì˜ ë‹¤ìŒ í† í° ì˜ˆì¸¡(NTP) ë°©ì‹ì€ ìˆœì°¨ì  ì²˜ë¦¬ë¡œ ì¸í•´ ë¬¸ë§¥ ë²”ìœ„ì™€ ì¶”ë¡  íš¨ìœ¨ì„±ì— í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ë„ì•½ ê¸°ë°˜ ë©”ì»¤ë‹ˆì¦˜ì„ ë„ì…í•œ í˜ì‹ ì ì¸ í† í° ì˜ˆì¸¡ ë°©ë²•ì¸ L-MTPë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. L-MTPëŠ” ê¸°ì¡´ì˜ ë‹¤ì¤‘ í† í° ì˜ˆì¸¡(MTP)ê³¼ ë‹¬ë¦¬ ì¤‘ê°„ í† í°ì„ ê±´ë„ˆë›°ì–´ ë¹„ìˆœì°¨ì ìœ¼ë¡œ ì˜ˆì¸¡í•˜ë©°, ì´ëŠ” ëª¨ë¸ì´ ì¥ê±°ë¦¬ ì˜ì¡´ì„±ì„ ë” ì˜ í¬ì°©í•˜ê³  ì¶”ë¡  ì†ë„ë¥¼ ê°€ì†í™”í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤. ì´ ë°©ë²•ì˜ ì´ë¡ ì  ì´ì ê³¼ ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ ì‹¤í—˜ì„ í†µí•´ LLM ì„±ëŠ¥ê³¼ ì¶”ë¡  ì†ë„ í–¥ìƒì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ê¸°ì¡´ ë‹¤ìŒ í† í° ì˜ˆì¸¡(NTP) ë°©ì‹ì€ ìˆœì°¨ì  ì²˜ë¦¬ë¡œ ì¸í•´ ë¬¸ë§¥ì  ë²”ìœ„ì™€ ì¶”ë¡  íš¨ìœ¨ì„±ì— í•œê³„ê°€ ìˆë‹¤.
- 2. L-MTPëŠ” ê¸°ì¡´ ë‹¤ì¤‘ í† í° ì˜ˆì¸¡(MTP) ë°©ì‹ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ë„ì•½ ê¸°ë°˜ ë©”ì»¤ë‹ˆì¦˜ì„ ë„ì…í•˜ì—¬ ë¹„ìˆœì°¨ì  í† í°ì„ ì˜ˆì¸¡í•œë‹¤.
- 3. L-MTPëŠ” ì¤‘ê°„ í† í°ì„ ê±´ë„ˆë›°ê³  ë¹„ìˆœì°¨ì  í† í°ì„ ì˜ˆì¸¡í•¨ìœ¼ë¡œì¨, ì¥ê±°ë¦¬ ì˜ì¡´ì„±ì„ ë” ì˜ í¬ì°©í•˜ê³  ì¶”ë¡  ì†ë„ë¥¼ ê°€ì†í™”í•œë‹¤.
- 4. ì´ë¡ ì ìœ¼ë¡œ L-MTPëŠ” ì¶”ë¡  íš¨ìœ¨ì„±ì„ ê°œì„ í•˜ëŠ” ë° ìœ ë¦¬í•¨ì„ ì…ì¦í•˜ì˜€ë‹¤.
- 5. ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ ì‹¤í—˜ì—ì„œ L-MTPëŠ” LLMì˜ ì„±ëŠ¥ê³¼ ì¶”ë¡  ì†ë„ë¥¼ ëª¨ë‘ í–¥ìƒì‹œí‚¤ëŠ” ê²ƒìœ¼ë¡œ ê²€ì¦ë˜ì—ˆë‹¤.


---

*Generated on 2025-09-24 03:57:53*