---
keywords:
  - Multimodal Learning
  - EmoBench-Reddit
  - Vision-Language Model
  - Emotion Understanding
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2509.11101
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T04:12:38.431099",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multimodal Learning",
    "EmoBench-Reddit",
    "Vision-Language Model",
    "Emotion Understanding"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multimodal Learning": 0.88,
    "EmoBench-Reddit": 0.8,
    "Vision-Language Model": 0.82,
    "Emotion Understanding": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multimodal Large Language Models",
        "canonical": "Multimodal Learning",
        "aliases": [
          "MLLMs"
        ],
        "category": "specific_connectable",
        "rationale": "Multimodal Learning is crucial for linking models that integrate multiple data types, such as text and images.",
        "novelty_score": 0.45,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.88
      },
      {
        "surface": "EmoBench-Reddit",
        "canonical": "EmoBench-Reddit",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "EmoBench-Reddit is a unique benchmark specifically designed for evaluating emotional intelligence in multimodal models.",
        "novelty_score": 0.95,
        "connectivity_score": 0.6,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "Vision-Language Tasks",
        "canonical": "Vision-Language Model",
        "aliases": [
          "Vision-Language Tasks"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-Language Models are central to understanding tasks that involve both visual and textual data.",
        "novelty_score": 0.4,
        "connectivity_score": 0.78,
        "specificity_score": 0.65,
        "link_intent_score": 0.82
      },
      {
        "surface": "Emotion Understanding",
        "canonical": "Emotion Understanding",
        "aliases": [
          "Emotional Intelligence"
        ],
        "category": "unique_technical",
        "rationale": "Emotion Understanding is a specialized area that evaluates a model's ability to interpret human emotions.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "benchmark",
      "task framework",
      "annotation quality"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multimodal Large Language Models",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "EmoBench-Reddit",
      "resolved_canonical": "EmoBench-Reddit",
      "decision": "linked",
      "scores": {
        "novelty": 0.95,
        "connectivity": 0.6,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Vision-Language Tasks",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.78,
        "specificity": 0.65,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Emotion Understanding",
      "resolved_canonical": "Emotion Understanding",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# EmoBench-Reddit: A Hierarchical Benchmark for Evaluating the Emotional Intelligence of Multimodal Large Language Models

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.11101.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2509.11101](https://arxiv.org/abs/2509.11101)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Benchmarking Contextual and Paralinguistic Reasoning in Speech-LLMs_ A Case Study with In-the-Wild Data_20250923|Benchmarking Contextual and Paralinguistic Reasoning in Speech-LLMs: A Case Study with In-the-Wild Data]] (85.0% similar)
- [[2025-09-23/MOMENTS_ A Comprehensive Multimodal Benchmark for Theory of Mind_20250923|MOMENTS: A Comprehensive Multimodal Benchmark for Theory of Mind]] (83.8% similar)
- [[2025-09-18/Humor in Pixels_ Benchmarking Large Multimodal Models Understanding of Online Comics_20250918|Humor in Pixels: Benchmarking Large Multimodal Models Understanding of Online Comics]] (83.5% similar)
- [[2025-09-22/MEDAL_ A Framework for Benchmarking LLMs as Multilingual Open-Domain Dialogue Evaluators_20250922|MEDAL: A Framework for Benchmarking LLMs as Multilingual Open-Domain Dialogue Evaluators]] (83.5% similar)
- [[2025-09-23/RealBench_ A Chinese Multi-image Understanding Benchmark Close to Real-world Scenarios_20250923|RealBench: A Chinese Multi-image Understanding Benchmark Close to Real-world Scenarios]] (83.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**âš¡ Unique Technical**: [[keywords/EmoBench-Reddit|EmoBench-Reddit]], [[keywords/Emotion Understanding|Emotion Understanding]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.11101v2 Announce Type: replace 
Abstract: With the rapid advancement of Multimodal Large Language Models (MLLMs), they have demonstrated exceptional capabilities across a variety of vision-language tasks. However, current evaluation benchmarks predominantly focus on objective visual question answering or captioning, inadequately assessing the models' ability to understand complex and subjective human emotions. To bridge this gap, we introduce EmoBench-Reddit, a novel, hierarchical benchmark for multimodal emotion understanding. The dataset comprises 350 meticulously curated samples from the social media platform Reddit, each containing an image, associated user-provided text, and an emotion category (sad, humor, sarcasm, happy) confirmed by user flairs. We designed a hierarchical task framework that progresses from basic perception to advanced cognition, with each data point featuring six multiple-choice questions and one open-ended question of increasing difficulty. Perception tasks evaluate the model's ability to identify basic visual elements (e.g., colors, objects), while cognition tasks require scene reasoning, intent understanding, and deep empathy integrating textual context. We ensured annotation quality through a combination of AI assistance (Claude 4) and manual verification.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë©€í‹°ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(MLLMs)ì˜ ê°ì • ì´í•´ ëŠ¥ë ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•´ ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ì¸ EmoBench-Redditë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ í‰ê°€ ê¸°ì¤€ì´ ì£¼ë¡œ ê°ê´€ì ì¸ ì‹œê° ì§ˆë¬¸ ì‘ë‹µì´ë‚˜ ìº¡ì…”ë‹ì— ì¹˜ì¤‘ë˜ì–´ ìˆì–´ ë³µì¡í•˜ê³  ì£¼ê´€ì ì¸ ì¸ê°„ ê°ì •ì„ ì´í•´í•˜ëŠ” ëª¨ë¸ì˜ ëŠ¥ë ¥ì„ ì¶©ë¶„íˆ í‰ê°€í•˜ì§€ ëª»í•œë‹¤ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê³ ì í•©ë‹ˆë‹¤. EmoBench-RedditëŠ” Redditì—ì„œ ìˆ˜ì§‘í•œ 350ê°œì˜ ìƒ˜í”Œë¡œ êµ¬ì„±ë˜ë©°, ê° ìƒ˜í”Œì€ ì´ë¯¸ì§€, ì‚¬ìš©ì ì œê³µ í…ìŠ¤íŠ¸, ê°ì • ì¹´í…Œê³ ë¦¬(ìŠ¬í””, ìœ ë¨¸, í’ì, í–‰ë³µ)ë¥¼ í¬í•¨í•©ë‹ˆë‹¤. ê³„ì¸µì  ê³¼ì œ í”„ë ˆì„ì›Œí¬ëŠ” ê¸°ë³¸ì ì¸ ì¸ì‹ì—ì„œ ê³ ê¸‰ ì¸ì§€ë¡œ ì§„í–‰ë˜ë©°, ê° ë°ì´í„° í¬ì¸íŠ¸ëŠ” ë‚œì´ë„ê°€ ì¦ê°€í•˜ëŠ” 6ê°œì˜ ê°ê´€ì‹ ì§ˆë¬¸ê³¼ 1ê°œì˜ ì£¼ê´€ì‹ ì§ˆë¬¸ì„ í¬í•¨í•©ë‹ˆë‹¤. ì¸ì‹ ê³¼ì œëŠ” ê¸°ë³¸ì ì¸ ì‹œê° ìš”ì†Œ ì‹ë³„ì„ í‰ê°€í•˜ê³ , ì¸ì§€ ê³¼ì œëŠ” ì¥ë©´ ì¶”ë¡ , ì˜ë„ ì´í•´, í…ìŠ¤íŠ¸ ë§¥ë½ì„ í†µí•©í•œ ê¹Šì€ ê³µê°ì„ ìš”êµ¬í•©ë‹ˆë‹¤. ì£¼ì„ í’ˆì§ˆì€ AI ë³´ì¡°(Claude 4)ì™€ ìˆ˜ë™ ê²€ì¦ì„ í†µí•´ ë³´ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë©€í‹°ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(MLLMs)ì€ ì‹œê°-ì–¸ì–´ ê³¼ì œì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì´ì§€ë§Œ, ë³µì¡í•˜ê³  ì£¼ê´€ì ì¸ ì¸ê°„ ê°ì •ì„ ì´í•´í•˜ëŠ” ëŠ¥ë ¥ì„ í‰ê°€í•˜ëŠ” ë° í•œê³„ê°€ ìˆë‹¤.
- 2. EmoBench-RedditëŠ” ë©€í‹°ëª¨ë‹¬ ê°ì • ì´í•´ë¥¼ ìœ„í•œ ìƒˆë¡œìš´ ê³„ì¸µì  ë²¤ì¹˜ë§ˆí¬ë¡œ, Redditì—ì„œ ìˆ˜ì§‘í•œ 350ê°œì˜ ìƒ˜í”Œì„ í¬í•¨í•œë‹¤.
- 3. ë°ì´í„°ì…‹ì€ ì´ë¯¸ì§€, ì‚¬ìš©ì ì œê³µ í…ìŠ¤íŠ¸, ê°ì • ì¹´í…Œê³ ë¦¬(ìŠ¬í””, ìœ ë¨¸, í’ì, í–‰ë³µ)ë¥¼ í¬í•¨í•˜ë©°, ì‚¬ìš©ì í”Œë ˆì–´ë¡œ í™•ì¸ëœ ê°ì • ì •ë³´ë¥¼ ì œê³µí•œë‹¤.
- 4. ê³„ì¸µì  ê³¼ì œ í”„ë ˆì„ì›Œí¬ëŠ” ê¸°ë³¸ì ì¸ ì§€ê°ì—ì„œ ê³ ê¸‰ ì¸ì§€ë¡œ ì§„í–‰ë˜ë©°, ê° ë°ì´í„° í¬ì¸íŠ¸ëŠ” ë‚œì´ë„ê°€ ì¦ê°€í•˜ëŠ” ì—¬ì„¯ ê°œì˜ ê°ê´€ì‹ ì§ˆë¬¸ê³¼ í•˜ë‚˜ì˜ ì£¼ê´€ì‹ ì§ˆë¬¸ì„ í¬í•¨í•œë‹¤.
- 5. ì£¼ì„ í’ˆì§ˆì€ AI ì§€ì›(Claude 4)ê³¼ ìˆ˜ì‘ì—… ê²€ì¦ì„ í†µí•´ ë³´ì¥ëœë‹¤.


---

*Generated on 2025-09-24 04:12:38*