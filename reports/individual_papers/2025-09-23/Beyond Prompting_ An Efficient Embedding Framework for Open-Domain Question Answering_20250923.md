---
keywords:
  - Large Language Model
  - Open-Domain Question Answering
  - Self-supervised Learning
  - Embedding Framework
  - Entropy-based Selection
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2503.01606
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T00:49:16.468930",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Open-Domain Question Answering",
    "Self-supervised Learning",
    "Embedding Framework",
    "Entropy-based Selection"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Open-Domain Question Answering": 0.88,
    "Self-supervised Learning": 0.8,
    "Embedding Framework": 0.78,
    "Entropy-based Selection": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "language models"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are foundational to the field and connect with numerous related concepts in NLP.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Open Domain Question Answering",
        "canonical": "Open-Domain Question Answering",
        "aliases": [
          "ODQA",
          "open-domain QA"
        ],
        "category": "specific_connectable",
        "rationale": "Open-Domain Question Answering is a specific task that connects with various retrieval and reading strategies.",
        "novelty_score": 0.7,
        "connectivity_score": 0.78,
        "specificity_score": 0.82,
        "link_intent_score": 0.88
      },
      {
        "surface": "Contrastive Learning",
        "canonical": "Self-supervised Learning",
        "aliases": [
          "contrastive objective"
        ],
        "category": "specific_connectable",
        "rationale": "Contrastive Learning is a self-supervised approach that enhances model training, linking to broader self-supervised methods.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Embedding Framework",
        "canonical": "Embedding Framework",
        "aliases": [
          "embedding model",
          "embedding approach"
        ],
        "category": "unique_technical",
        "rationale": "The Embedding Framework is a novel approach proposed in the paper, offering unique insights into embedding-based QA.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Entropy-based Selection",
        "canonical": "Entropy-based Selection",
        "aliases": [
          "entropy selection",
          "entropy mechanism"
        ],
        "category": "unique_technical",
        "rationale": "Entropy-based Selection is a unique mechanism introduced in the paper, enhancing answer selection processes.",
        "novelty_score": 0.68,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "retriever-reader pipelines",
      "retrieval coverage",
      "exploratory embedding"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Open Domain Question Answering",
      "resolved_canonical": "Open-Domain Question Answering",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.78,
        "specificity": 0.82,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "Contrastive Learning",
      "resolved_canonical": "Self-supervised Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Embedding Framework",
      "resolved_canonical": "Embedding Framework",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Entropy-based Selection",
      "resolved_canonical": "Entropy-based Selection",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# Beyond Prompting: An Efficient Embedding Framework for Open-Domain Question Answering

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2503.01606.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2503.01606](https://arxiv.org/abs/2503.01606)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Select to Know_ An Internal-External Knowledge Self-Selection Framework for Domain-Specific Question Answering_20250919|Select to Know: An Internal-External Knowledge Self-Selection Framework for Domain-Specific Question Answering]] (84.3% similar)
- [[2025-09-22/MMAPG_ A Training-Free Framework for Multimodal Multi-hop Question Answering via Adaptive Planning Graphs_20250922|MMAPG: A Training-Free Framework for Multimodal Multi-hop Question Answering via Adaptive Planning Graphs]] (83.9% similar)
- [[2025-09-22/Query Optimization for Parametric Knowledge Refinement in Retrieval-Augmented Large Language Models_20250922|Query Optimization for Parametric Knowledge Refinement in Retrieval-Augmented Large Language Models]] (83.5% similar)
- [[2025-09-19/SWE-QA_ Can Language Models Answer Repository-level Code Questions?_20250919|SWE-QA: Can Language Models Answer Repository-level Code Questions?]] (83.2% similar)
- [[2025-09-22/Search and Refine During Think_ Facilitating Knowledge Refinement for Improved Retrieval-Augmented Reasoning_20250922|Search and Refine During Think: Facilitating Knowledge Refinement for Improved Retrieval-Augmented Reasoning]] (83.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Open-Domain Question Answering|Open-Domain Question Answering]], [[keywords/Self-supervised Learning|Self-supervised Learning]]
**âš¡ Unique Technical**: [[keywords/Embedding Framework|Embedding Framework]], [[keywords/Entropy-based Selection|Entropy-based Selection]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2503.01606v3 Announce Type: replace-cross 
Abstract: Large language models have recently pushed open domain question answering (ODQA) to new frontiers. However, prevailing retriever-reader pipelines often depend on multiple rounds of prompt level instructions, leading to high computational overhead, instability, and suboptimal retrieval coverage. In this paper, we propose EmbQA, an embedding-level framework that alleviates these shortcomings by enhancing both the retriever and the reader. Specifically, we refine query representations via lightweight linear layers under an unsupervised contrastive learning objective, thereby reordering retrieved passages to highlight those most likely to contain correct answers. Additionally, we introduce an exploratory embedding that broadens the model's latent semantic space to diversify candidate generation and employs an entropy-based selection mechanism to choose the most confident answer automatically. Extensive experiments across three open-source LLMs, three retrieval methods, and four ODQA benchmarks demonstrate that EmbQA substantially outperforms recent baselines in both accuracy and efficiency.

## ğŸ“ ìš”ì•½

ìµœê·¼ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì€ ê°œë°©í˜• ë„ë©”ì¸ ì§ˆë¬¸ ì‘ë‹µ(ODQA) ë¶„ì•¼ì—ì„œ ìƒˆë¡œìš´ ê°€ëŠ¥ì„±ì„ ì—´ì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê¸°ì¡´ì˜ ê²€ìƒ‰ê¸°-ë¦¬ë” íŒŒì´í”„ë¼ì¸ì€ ì—¬ëŸ¬ ë²ˆì˜ í”„ë¡¬í”„íŠ¸ ìˆ˜ì¤€ ì§€ì¹¨ì— ì˜ì¡´í•˜ì—¬ ë†’ì€ ê³„ì‚° ë¹„ìš©ê³¼ ë¶ˆì•ˆì •ì„±, ë¹„íš¨ìœ¨ì ì¸ ê²€ìƒ‰ ë²”ìœ„ë¥¼ ì´ˆë˜í•©ë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ EmbQAë¼ëŠ” ì„ë² ë”© ìˆ˜ì¤€ì˜ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ê²€ìƒ‰ê¸°ì™€ ë¦¬ë”ë¥¼ ê°œì„ í•˜ì—¬ ì¿¼ë¦¬ í‘œí˜„ì„ ê²½ëŸ‰í™”ëœ ì„ í˜• ê³„ì¸µê³¼ ë¹„ì§€ë„ ëŒ€ì¡° í•™ìŠµ ëª©í‘œë¥¼ í†µí•´ ê°œì„ í•˜ê³ , ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ìˆœì„œë¥¼ ì¬ì¡°ì •í•˜ì—¬ ì˜¬ë°”ë¥¸ ë‹µë³€ì„ í¬í•¨í•  ê°€ëŠ¥ì„±ì´ ë†’ì€ ë¬¸ì„œë¥¼ ê°•ì¡°í•©ë‹ˆë‹¤. ë˜í•œ, ëª¨ë¸ì˜ ì ì¬ ì˜ë¯¸ ê³µê°„ì„ í™•ì¥í•˜ëŠ” íƒìƒ‰ ì„ë² ë”©ì„ ë„ì…í•˜ê³ , ì—”íŠ¸ë¡œí”¼ ê¸°ë°˜ ì„ íƒ ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´ ê°€ì¥ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë‹µë³€ì„ ìë™ìœ¼ë¡œ ì„ íƒí•©ë‹ˆë‹¤. ì„¸ ê°€ì§€ ì˜¤í”ˆ ì†ŒìŠ¤ LLM, ì„¸ ê°€ì§€ ê²€ìƒ‰ ë°©ë²•, ë„¤ ê°€ì§€ ODQA ë²¤ì¹˜ë§ˆí¬ë¥¼ ëŒ€ìƒìœ¼ë¡œ í•œ ê´‘ë²”ìœ„í•œ ì‹¤í—˜ ê²°ê³¼, EmbQAëŠ” ì •í™•ì„±ê³¼ íš¨ìœ¨ì„± ë©´ì—ì„œ ìµœê·¼ì˜ ê¸°ì¤€ì„ ì„ í¬ê²Œ ëŠ¥ê°€í•˜ëŠ” ì„±ê³¼ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. EmbQAëŠ” ODQAì—ì„œ ë°œìƒí•˜ëŠ” ë†’ì€ ê³„ì‚° ë¹„ìš©, ë¶ˆì•ˆì •ì„±, ë¹„íš¨ìœ¨ì ì¸ ê²€ìƒ‰ ë²”ìœ„ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì œì•ˆëœ ì„ë² ë”© ìˆ˜ì¤€ì˜ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.
- 2. EmbQAëŠ” ë¹„ì§€ë„ ëŒ€ì¡° í•™ìŠµ ëª©í‘œ í•˜ì— ê²½ëŸ‰ì˜ ì„ í˜• ë ˆì´ì–´ë¥¼ í†µí•´ ì¿¼ë¦¬ í‘œí˜„ì„ ê°œì„ í•˜ì—¬, ì˜¬ë°”ë¥¸ ë‹µë³€ì„ í¬í•¨í•  ê°€ëŠ¥ì„±ì´ ë†’ì€ ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ì¬ì •ë ¬í•©ë‹ˆë‹¤.
- 3. íƒìƒ‰ì  ì„ë² ë”©ì„ ë„ì…í•˜ì—¬ ëª¨ë¸ì˜ ì ì¬ ì˜ë¯¸ ê³µê°„ì„ í™•ì¥í•˜ê³ , ì—”íŠ¸ë¡œí”¼ ê¸°ë°˜ ì„ íƒ ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´ ê°€ì¥ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë‹µë³€ì„ ìë™ìœ¼ë¡œ ì„ íƒí•©ë‹ˆë‹¤.
- 4. ì„¸ ê°€ì§€ ì˜¤í”ˆ ì†ŒìŠ¤ LLM, ì„¸ ê°€ì§€ ê²€ìƒ‰ ë°©ë²•, ë„¤ ê°€ì§€ ODQA ë²¤ì¹˜ë§ˆí¬ì—ì„œì˜ ê´‘ë²”ìœ„í•œ ì‹¤í—˜ì„ í†µí•´ EmbQAê°€ ìµœê·¼ì˜ ê¸°ì¤€ ëª¨ë¸ë“¤ë³´ë‹¤ ì •í™•ì„±ê³¼ íš¨ìœ¨ì„±ì—ì„œ í¬ê²Œ ìš°ìˆ˜í•¨ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 00:49:16*