---
keywords:
  - Large Language Model
  - Chain-of-Thought Reasoning
  - Step Guided Reasoning
  - Mathematical Reasoning
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2410.19817
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T00:23:35.736447",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Chain-of-Thought Reasoning",
    "Step Guided Reasoning",
    "Mathematical Reasoning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Chain-of-Thought Reasoning": 0.78,
    "Step Guided Reasoning": 0.82,
    "Mathematical Reasoning": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Language Models"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are central to the paper's discussion and connect well with existing research in NLP.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Chain-of-Thought inference",
        "canonical": "Chain-of-Thought Reasoning",
        "aliases": [
          "CoT inference",
          "Step-by-step Reasoning"
        ],
        "category": "specific_connectable",
        "rationale": "Chain-of-Thought Reasoning is a key concept in enhancing LLM capabilities and links to cognitive processes.",
        "novelty_score": 0.7,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Step Guided Reasoning",
        "canonical": "Step Guided Reasoning",
        "aliases": [
          "Guided Reasoning",
          "Step Reasoning"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel framework introduced in the paper, crucial for understanding the proposed method.",
        "novelty_score": 0.85,
        "connectivity_score": 0.6,
        "specificity_score": 0.9,
        "link_intent_score": 0.82
      },
      {
        "surface": "Mathematical Reasoning",
        "canonical": "Mathematical Reasoning",
        "aliases": [
          "Math Reasoning"
        ],
        "category": "specific_connectable",
        "rationale": "Mathematical Reasoning is the primary application area discussed, linking to educational and cognitive studies.",
        "novelty_score": 0.5,
        "connectivity_score": 0.78,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "inference datasets",
      "computational accuracy",
      "reflective process"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Chain-of-Thought inference",
      "resolved_canonical": "Chain-of-Thought Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Step Guided Reasoning",
      "resolved_canonical": "Step Guided Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.6,
        "specificity": 0.9,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Mathematical Reasoning",
      "resolved_canonical": "Mathematical Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.78,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# Step Guided Reasoning: Improving Mathematical Reasoning using Guidance Generation and Step Reasoning

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2410.19817.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2410.19817](https://arxiv.org/abs/2410.19817)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/GPO_ Learning from Critical Steps to Improve LLM Reasoning_20250923|GPO: Learning from Critical Steps to Improve LLM Reasoning]] (86.3% similar)
- [[2025-09-23/Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates_20250923|Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates]] (85.9% similar)
- [[2025-09-17/THOR_ Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning_20250917|THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning]] (84.9% similar)
- [[2025-09-19/Enhancing Logical Reasoning in Language Models via Symbolically-Guided Monte Carlo Process Supervision_20250919|Enhancing Logical Reasoning in Language Models via Symbolically-Guided Monte Carlo Process Supervision]] (84.6% similar)
- [[2025-09-23/On LLM-Based Scientific Inductive Reasoning Beyond Equations_20250923|On LLM-Based Scientific Inductive Reasoning Beyond Equations]] (84.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Chain-of-Thought Reasoning|Chain-of-Thought Reasoning]], [[keywords/Mathematical Reasoning|Mathematical Reasoning]]
**âš¡ Unique Technical**: [[keywords/Step Guided Reasoning|Step Guided Reasoning]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2410.19817v3 Announce Type: replace 
Abstract: Mathematical reasoning has been challenging for large language models (LLMs), and the introduction of step-by-step Chain-of-Thought (CoT) inference has significantly advanced the mathematical capabilities of LLMs. However, current approaches either necessitate extensive inference datasets for training or depend on few-shot methods that frequently compromise computational accuracy. To address these fundamental limitations, we propose Step Guided Reasoning, a novel training-free adaptation framework that efficiently equips general-purpose pre-trained language models with enhanced mathematical reasoning capabilities. In this approach, LLMs reflect on small reasoning steps, similar to how humans deliberate and focus attention on what to do next. By incorporating this reflective process into the inference stage, LLMs can effectively guide their reasoning from one step to the next. Through extensive experiments, we demonstrate the significant effect of Step Guided Reasoning in enhancing mathematical performance in state-of-the-art language models -- Qwen2-72B-Instruct outperforms its math-specific counterpart, Qwen2.5-72B-Math-Instruct, on MMLU-STEM with a score of 90.9%, compared to 87.3%. The average scores of Qwen2-7B-Instruct and Qwen2-72B-Instruct increase from 27.1% to 36. 3% and from 36. 5% to 47.4% in the math domain, respectively.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ìˆ˜í•™ì  ì¶”ë¡ ì—ì„œ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ìƒˆë¡œìš´ ë°©ë²•ì¸ 'ë‹¨ê³„ ìœ ë„ ì¶”ë¡ (Step Guided Reasoning)'ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ ë°©ë²•ë“¤ì€ ëŒ€ê·œëª¨ ì¶”ë¡  ë°ì´í„°ì…‹ì´ë‚˜ ëª‡ ê°€ì§€ ì˜ˆì‹œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ë°©ë²•ì— ì˜ì¡´í•˜ì—¬ ê³„ì‚° ì •í™•ë„ê°€ ë–¨ì–´ì§€ëŠ” ë¬¸ì œê°€ ìˆì—ˆìŠµë‹ˆë‹¤. ì œì•ˆëœ ë°©ë²•ì€ í›ˆë ¨ ì—†ì´ ì¼ë°˜ì ì¸ ì‚¬ì „ í•™ìŠµëœ ì–¸ì–´ ëª¨ë¸ì— ìˆ˜í•™ì  ì¶”ë¡  ëŠ¥ë ¥ì„ ë¶€ì—¬í•˜ë©°, ì¸ê°„ì´ ë‹¤ìŒ ë‹¨ê³„ì— ì§‘ì¤‘í•˜ëŠ” ê²ƒì²˜ëŸ¼ ì‘ì€ ì¶”ë¡  ë‹¨ê³„ë¥¼ ë°˜ì˜í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ LLMì€ ì¶”ë¡  ê³¼ì •ì„ íš¨ê³¼ì ìœ¼ë¡œ ì•ˆë‚´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì€ ìµœì²¨ë‹¨ ì–¸ì–´ ëª¨ë¸ì˜ ìˆ˜í•™ì  ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œì¼°ìœ¼ë©°, Qwen2-72B-Instruct ëª¨ë¸ì€ MMLU-STEMì—ì„œ 90.9%ì˜ ì ìˆ˜ë¥¼ ê¸°ë¡í•˜ì—¬ ìˆ˜í•™ ì „ìš© ëª¨ë¸ì¸ Qwen2.5-72B-Math-Instructë¥¼ ëŠ¥ê°€í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, Qwen2-7B-Instructì™€ Qwen2-72B-Instructì˜ ìˆ˜í•™ ì˜ì—­ í‰ê·  ì ìˆ˜ë„ ê°ê° 27.1%ì—ì„œ 36.3%, 36.5%ì—ì„œ 47.4%ë¡œ ì¦ê°€í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ìˆ˜í•™ì  ì¶”ë¡ ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì—ê²Œ ë„ì „ ê³¼ì œì˜€ìœ¼ë©°, ë‹¨ê³„ë³„ Chain-of-Thought(CoT) ì¶”ë¡ ì˜ ë„ì…ìœ¼ë¡œ LLMì˜ ìˆ˜í•™ì  ëŠ¥ë ¥ì´ í¬ê²Œ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤.
- 2. í˜„ì¬ ì ‘ê·¼ ë°©ì‹ì€ ê´‘ë²”ìœ„í•œ ì¶”ë¡  ë°ì´í„°ì…‹ì„ í•„ìš”ë¡œ í•˜ê±°ë‚˜, ì¢…ì¢… ê³„ì‚° ì •í™•ì„±ì„ íƒ€í˜‘í•˜ëŠ” ì†Œìˆ˜ì˜ ìƒ· ë°©ë²•ì— ì˜ì¡´í•©ë‹ˆë‹¤.
- 3. Step Guided Reasoningì€ ì¼ë°˜ ëª©ì ì˜ ì‚¬ì „ í›ˆë ¨ëœ ì–¸ì–´ ëª¨ë¸ì— ìˆ˜í•™ì  ì¶”ë¡  ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ìƒˆë¡œìš´ í›ˆë ¨ ì—†ëŠ” ì ì‘ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.
- 4. ì´ ì ‘ê·¼ ë°©ì‹ì€ LLMì´ ì‘ì€ ì¶”ë¡  ë‹¨ê³„ë¥¼ ë°˜ì˜í•˜ì—¬ ë‹¤ìŒ ë‹¨ê³„ë¡œì˜ ì¶”ë¡ ì„ íš¨ê³¼ì ìœ¼ë¡œ ì•ˆë‚´í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
- 5. ì‹¤í—˜ ê²°ê³¼, Step Guided Reasoningì€ ìµœì²¨ë‹¨ ì–¸ì–´ ëª¨ë¸ì˜ ìˆ˜í•™ì  ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚¤ë©°, Qwen2-72B-Instructê°€ MMLU-STEMì—ì„œ 90.9%ì˜ ì ìˆ˜ë¡œ ìˆ˜í•™ ì „ìš© ëª¨ë¸ì„ ëŠ¥ê°€í–ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 00:23:35*