---
keywords:
  - Diffusion Models
  - Attention Mechanism
  - Cross Identity Supervision
  - Portrait Animation
category: cs.CV
publish_date: 2025-09-23
arxiv_id: 2509.17476
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T04:53:03.851229",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Diffusion Models",
    "Attention Mechanism",
    "Cross Identity Supervision",
    "Portrait Animation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Diffusion Models": 0.85,
    "Attention Mechanism": 0.82,
    "Cross Identity Supervision": 0.8,
    "Portrait Animation": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "diffusion models",
        "canonical": "Diffusion Models",
        "aliases": [
          "diffusion-based models"
        ],
        "category": "unique_technical",
        "rationale": "Diffusion models are central to the proposed framework, offering a unique approach to portrait animation.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.85
      },
      {
        "surface": "spatial temporal attention mechanisms",
        "canonical": "Attention Mechanism",
        "aliases": [
          "spatial-temporal attention"
        ],
        "category": "specific_connectable",
        "rationale": "This mechanism is crucial for capturing subtle motions, linking to broader attention mechanism concepts.",
        "novelty_score": 0.6,
        "connectivity_score": 0.9,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "cross identity supervision",
        "canonical": "Cross Identity Supervision",
        "aliases": [
          "cross-identity training"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel training strategy enhancing model generalization, relevant for identity-related tasks.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "portrait animation",
        "canonical": "Portrait Animation",
        "aliases": [
          "photo-realistic animation"
        ],
        "category": "unique_technical",
        "rationale": "Central to the paper, this term defines the specific application of the proposed methods.",
        "novelty_score": 0.65,
        "connectivity_score": 0.55,
        "specificity_score": 0.88,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance",
      "framework",
      "training"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "diffusion models",
      "resolved_canonical": "Diffusion Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "spatial temporal attention mechanisms",
      "resolved_canonical": "Attention Mechanism",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.9,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "cross identity supervision",
      "resolved_canonical": "Cross Identity Supervision",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "portrait animation",
      "resolved_canonical": "Portrait Animation",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.55,
        "specificity": 0.88,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# Stable Video-Driven Portraits

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17476.pdf)
**Category**: cs.CV
**Published**: 2025-09-23
**ArXiv ID**: [2509.17476](https://arxiv.org/abs/2509.17476)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Follow-Your-Emoji-Faster_ Towards Efficient, Fine-Controllable, and Expressive Freestyle Portrait Animation_20250923|Follow-Your-Emoji-Faster: Towards Efficient, Fine-Controllable, and Expressive Freestyle Portrait Animation]] (87.3% similar)
- [[2025-09-19/Controllable Localized Face Anonymization Via Diffusion Inpainting_20250919|Controllable Localized Face Anonymization Via Diffusion Inpainting]] (85.1% similar)
- [[2025-09-22/FLOAT_ Generative Motion Latent Flow Matching for Audio-driven Talking Portrait_20250922|FLOAT: Generative Motion Latent Flow Matching for Audio-driven Talking Portrait]] (84.1% similar)
- [[2025-09-23/Penalizing Boundary Activation for Object Completeness in Diffusion Models_20250923|Penalizing Boundary Activation for Object Completeness in Diffusion Models]] (82.7% similar)
- [[2025-09-19/FMGS-Avatar_ Mesh-Guided 2D Gaussian Splatting with Foundation Model Priors for 3D Monocular Avatar Reconstruction_20250919|FMGS-Avatar: Mesh-Guided 2D Gaussian Splatting with Foundation Model Priors for 3D Monocular Avatar Reconstruction]] (82.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Attention Mechanism|Attention Mechanism]]
**âš¡ Unique Technical**: [[keywords/Diffusion Models|Diffusion Models]], [[keywords/Cross Identity Supervision|Cross Identity Supervision]], [[keywords/Portrait Animation|Portrait Animation]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17476v1 Announce Type: new 
Abstract: Portrait animation aims to generate photo-realistic videos from a single source image by reenacting the expression and pose from a driving video. While early methods relied on 3D morphable models or feature warping techniques, they often suffered from limited expressivity, temporal inconsistency, and poor generalization to unseen identities or large pose variations. Recent advances using diffusion models have demonstrated improved quality but remain constrained by weak control signals and architectural limitations. In this work, we propose a novel diffusion based framework that leverages masked facial regions specifically the eyes, nose, and mouth from the driving video as strong motion control cues. To enable robust training without appearance leakage, we adopt cross identity supervision. To leverage the strong prior from the pretrained diffusion model, our novel architecture introduces minimal new parameters that converge faster and help in better generalization. We introduce spatial temporal attention mechanisms that allow inter frame and intra frame interactions, effectively capturing subtle motions and reducing temporal artifacts. Our model uses history frames to ensure continuity across segments. At inference, we propose a novel signal fusion strategy that balances motion fidelity with identity preservation. Our approach achieves superior temporal consistency and accurate expression control, enabling high-quality, controllable portrait animation suitable for real-world applications.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë‹¨ì¼ ì´ë¯¸ì§€ì—ì„œ ì‚¬ì§„ê³¼ ê°™ì€ ì˜ìƒì„ ìƒì„±í•˜ëŠ” ì´ˆìƒí™” ì• ë‹ˆë©”ì´ì…˜ ê¸°ìˆ ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ ë°©ë²•ë“¤ì€ 3D ëª¨ë¸ì´ë‚˜ íŠ¹ì§• ì™œê³¡ ê¸°ìˆ ì— ì˜ì¡´í–ˆìœ¼ë‚˜, í‘œí˜„ë ¥ ë¶€ì¡±ê³¼ ì‹œê°„ì  ì¼ê´€ì„± ë¬¸ì œë¥¼ ê²ªì—ˆìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ëŠ” í™•ì‚° ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ëˆˆ, ì½”, ì… ë“± ì–¼êµ´ì˜ íŠ¹ì • ë¶€ìœ„ë¥¼ ê°•ë ¥í•œ ì›€ì§ì„ ì œì–´ ì‹ í˜¸ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤. ì™¸ê´€ ëˆ„ì¶œ ì—†ì´ ê°•ë ¥í•œ í•™ìŠµì„ ìœ„í•´ êµì°¨ ì‹ ì› ê°ë…ì„ ì±„íƒí•˜ê³ , ì‚¬ì „ í•™ìŠµëœ í™•ì‚° ëª¨ë¸ì˜ ê°•ë ¥í•œ ì‚¬ì „ ì§€ì‹ì„ í™œìš©í•˜ì—¬ ìµœì†Œí•œì˜ ìƒˆë¡œìš´ ë§¤ê°œë³€ìˆ˜ë¥¼ ë„ì…í–ˆìŠµë‹ˆë‹¤. ê³µê°„-ì‹œê°„ ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´ í”„ë ˆì„ ê°„ ìƒí˜¸ì‘ìš©ì„ ì´‰ì§„í•˜ì—¬ ë¯¸ì„¸í•œ ì›€ì§ì„ì„ í¬ì°©í•˜ê³  ì‹œê°„ì  ì™œê³¡ì„ ì¤„ì˜€ìŠµë‹ˆë‹¤. ì¶”ë¡  ì‹œì—ëŠ” ì›€ì§ì„ ì¶©ì‹¤ë„ì™€ ì‹ ì› ë³´ì¡´ì„ ê· í˜• ìˆê²Œ ìœ ì§€í•˜ëŠ” ì‹ í˜¸ ìœµí•© ì „ëµì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ì ‘ê·¼ë²•ì€ ì‹œê°„ì  ì¼ê´€ì„±ê³¼ ì •í™•í•œ í‘œí˜„ ì œì–´ë¥¼ ë‹¬ì„±í•˜ì—¬ ì‹¤ì œ ì‘ìš©ì— ì í•©í•œ ê³ í’ˆì§ˆì˜ ì´ˆìƒí™” ì• ë‹ˆë©”ì´ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë³¸ ì—°êµ¬ëŠ” ë‹¨ì¼ ì†ŒìŠ¤ ì´ë¯¸ì§€ì—ì„œ ì£¼í–‰ ë¹„ë””ì˜¤ì˜ í‘œì •ê³¼ ìì„¸ë¥¼ ì¬í˜„í•˜ì—¬ ì‚¬ì§„ ì‹¤ê° ë¹„ë””ì˜¤ë¥¼ ìƒì„±í•˜ëŠ” ì´ˆìƒí™” ì• ë‹ˆë©”ì´ì…˜ì„ ëª©í‘œë¡œ í•œë‹¤.
- 2. ê¸°ì¡´ ë°©ë²•ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´, ì£¼í–‰ ë¹„ë””ì˜¤ì—ì„œ ëˆˆ, ì½”, ì… ë“± ë§ˆìŠ¤í¬ëœ ì–¼êµ´ ë¶€ìœ„ë¥¼ ê°•ë ¥í•œ ëª¨ì…˜ ì œì–´ ì‹ í˜¸ë¡œ í™œìš©í•˜ëŠ” ìƒˆë¡œìš´ í™•ì‚° ê¸°ë°˜ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•œë‹¤.
- 3. êµì°¨ ì •ì²´ì„± ê°ë…ì„ ì±„íƒí•˜ì—¬ ì™¸ëª¨ ëˆ„ì¶œ ì—†ì´ ê°•ë ¥í•œ í›ˆë ¨ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ê³ , ì‚¬ì „ í•™ìŠµëœ í™•ì‚° ëª¨ë¸ì˜ ê°•ë ¥í•œ ì‚¬ì „ ì§€ì‹ì„ í™œìš©í•˜ê¸° ìœ„í•´ ìµœì†Œí•œì˜ ìƒˆë¡œìš´ ë§¤ê°œë³€ìˆ˜ë¥¼ ë„ì…í•œë‹¤.
- 4. ê³µê°„ì  ì‹œê°„ì  ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì„ ë„ì…í•˜ì—¬ í”„ë ˆì„ ê°„ ë° í”„ë ˆì„ ë‚´ ìƒí˜¸ì‘ìš©ì„ í—ˆìš©í•˜ê³ , ë¯¸ì„¸í•œ ì›€ì§ì„ì„ íš¨ê³¼ì ìœ¼ë¡œ í¬ì°©í•˜ë©° ì‹œê°„ì  ì•„í‹°íŒ©íŠ¸ë¥¼ ì¤„ì¸ë‹¤.
- 5. ì œì•ˆëœ ëª¨ë¸ì€ ëª¨ì…˜ ì¶©ì‹¤ë„ì™€ ì •ì²´ì„± ë³´ì¡´ì„ ê· í˜• ìˆê²Œ ìœ ì§€í•˜ëŠ” ìƒˆë¡œìš´ ì‹ í˜¸ ìœµí•© ì „ëµì„ í†µí•´ ë†’ì€ í’ˆì§ˆì˜ ì œì–´ ê°€ëŠ¥í•œ ì´ˆìƒí™” ì• ë‹ˆë©”ì´ì…˜ì„ ì‹¤í˜„í•œë‹¤.


---

*Generated on 2025-09-24 04:53:03*