---
keywords:
  - Generative Value Learning
  - Vision-Language Model
  - OpenGVL
  - Temporal Progress Prediction
  - Robotics Data Curation
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2509.17321
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:41:10.280411",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Generative Value Learning",
    "Vision-Language Model",
    "OpenGVL",
    "Temporal Progress Prediction",
    "Robotics Data Curation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Generative Value Learning": 0.78,
    "Vision-Language Model": 0.85,
    "OpenGVL": 0.8,
    "Temporal Progress Prediction": 0.77,
    "Robotics Data Curation": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Generative Value Learning",
        "canonical": "Generative Value Learning",
        "aliases": [
          "GVL"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel approach specific to the paper, enhancing connectivity with topics on task progress prediction.",
        "novelty_score": 0.85,
        "connectivity_score": 0.7,
        "specificity_score": 0.9,
        "link_intent_score": 0.78
      },
      {
        "surface": "Vision-Language Models",
        "canonical": "Vision-Language Model",
        "aliases": [
          "VLMs"
        ],
        "category": "evolved_concepts",
        "rationale": "Connects with the trending topic of integrating vision and language for task prediction.",
        "novelty_score": 0.5,
        "connectivity_score": 0.88,
        "specificity_score": 0.8,
        "link_intent_score": 0.85
      },
      {
        "surface": "OpenGVL",
        "canonical": "OpenGVL",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Represents a specific benchmark introduced in the paper, crucial for linking to data curation topics.",
        "novelty_score": 0.9,
        "connectivity_score": 0.65,
        "specificity_score": 0.92,
        "link_intent_score": 0.8
      },
      {
        "surface": "Temporal Progress Prediction",
        "canonical": "Temporal Progress Prediction",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "A key concept for linking discussions on task completion and data annotation.",
        "novelty_score": 0.6,
        "connectivity_score": 0.75,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      },
      {
        "surface": "Robotics Data Curation",
        "canonical": "Robotics Data Curation",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Essential for connecting with themes on data management and utilization in robotics.",
        "novelty_score": 0.65,
        "connectivity_score": 0.82,
        "specificity_score": 0.78,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "task",
      "performance",
      "method"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Generative Value Learning",
      "resolved_canonical": "Generative Value Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.7,
        "specificity": 0.9,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Vision-Language Models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.88,
        "specificity": 0.8,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "OpenGVL",
      "resolved_canonical": "OpenGVL",
      "decision": "linked",
      "scores": {
        "novelty": 0.9,
        "connectivity": 0.65,
        "specificity": 0.92,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Temporal Progress Prediction",
      "resolved_canonical": "Temporal Progress Prediction",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.75,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Robotics Data Curation",
      "resolved_canonical": "Robotics Data Curation",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.82,
        "specificity": 0.78,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# OpenGVL - Benchmarking Visual Temporal Progress for Data Curation

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17321.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2509.17321](https://arxiv.org/abs/2509.17321)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/A Vision-Language-Action-Critic Model for Robotic Real-World Reinforcement Learning_20250922|A Vision-Language-Action-Critic Model for Robotic Real-World Reinforcement Learning]] (85.0% similar)
- [[2025-09-23/Look, Focus, Act_ Efficient and Robust Robot Learning via Human Gaze and Foveated Vision Transformers_20250923|Look, Focus, Act: Efficient and Robust Robot Learning via Human Gaze and Foveated Vision Transformers]] (84.1% similar)
- [[2025-09-19/ForceVLA_ Enhancing VLA Models with a Force-aware MoE for Contact-rich Manipulation_20250919|ForceVLA: Enhancing VLA Models with a Force-aware MoE for Contact-rich Manipulation]] (83.6% similar)
- [[2025-09-19/ScaleCUA_ Scaling Open-Source Computer Use Agents with Cross-Platform Data_20250919|ScaleCUA: Scaling Open-Source Computer Use Agents with Cross-Platform Data]] (82.6% similar)
- [[2025-09-18/TrajBooster_ Boosting Humanoid Whole-Body Manipulation via Trajectory-Centric Learning_20250918|TrajBooster: Boosting Humanoid Whole-Body Manipulation via Trajectory-Centric Learning]] (82.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Temporal Progress Prediction|Temporal Progress Prediction]], [[keywords/Robotics Data Curation|Robotics Data Curation]]
**âš¡ Unique Technical**: [[keywords/Generative Value Learning|Generative Value Learning]], [[keywords/OpenGVL|OpenGVL]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17321v1 Announce Type: cross 
Abstract: Data scarcity remains one of the most limiting factors in driving progress in robotics. However, the amount of available robotics data in the wild is growing exponentially, creating new opportunities for large-scale data utilization. Reliable temporal task completion prediction could help automatically annotate and curate this data at scale. The Generative Value Learning (GVL) approach was recently proposed, leveraging the knowledge embedded in vision-language models (VLMs) to predict task progress from visual observations. Building upon GVL, we propose OpenGVL, a comprehensive benchmark for estimating task progress across diverse challenging manipulation tasks involving both robotic and human embodiments. We evaluate the capabilities of publicly available open-source foundation models, showing that open-source model families significantly underperform closed-source counterparts, achieving only approximately $70\%$ of their performance on temporal progress prediction tasks. Furthermore, we demonstrate how OpenGVL can serve as a practical tool for automated data curation and filtering, enabling efficient quality assessment of large-scale robotics datasets. We release the benchmark along with the complete codebase at \href{github.com/budzianowski/opengvl}{OpenGVL}.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë¡œë´‡ ê³µí•™ì—ì„œ ë°ì´í„° ë¶€ì¡± ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì œì•ˆëœ Generative Value Learning(GVL) ì ‘ê·¼ë²•ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ OpenGVL ë²¤ì¹˜ë§ˆí¬ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. OpenGVLì€ ë‹¤ì–‘í•œ ë¡œë´‡ ë° ì¸ê°„ ì¡°ì‘ ì‘ì—…ì—ì„œ ê³¼ì œ ì§„í–‰ ìƒí™©ì„ ì˜ˆì¸¡í•˜ëŠ” ë° ì¤‘ì ì„ ë‘ê³  ìˆìŠµë‹ˆë‹¤. ì—°êµ¬ ê²°ê³¼, ê³µê°œëœ ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ì´ ë¹„ê³µê°œ ëª¨ë¸ì— ë¹„í•´ ì„±ëŠ¥ì´ ì•½ 70%ì— ê·¸ì¹œë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤. OpenGVLì€ ëŒ€ê·œëª¨ ë¡œë´‡ ë°ì´í„°ì…‹ì˜ ìë™í™”ëœ ë°ì´í„° íë ˆì´ì…˜ ë° í•„í„°ë§ ë„êµ¬ë¡œ í™œìš©ë  ìˆ˜ ìˆìœ¼ë©°, ì´ë¥¼ í†µí•´ ë°ì´í„° í’ˆì§ˆ í‰ê°€ê°€ íš¨ìœ¨ì ìœ¼ë¡œ ì´ë£¨ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—°êµ¬íŒ€ì€ OpenGVL ë²¤ì¹˜ë§ˆí¬ì™€ ì „ì²´ ì½”ë“œë² ì´ìŠ¤ë¥¼ ê³µê°œí–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë°ì´í„° ë¶€ì¡±ì€ ë¡œë´‡ ê³µí•™ ë°œì „ì˜ ì£¼ìš” ì œí•œ ìš”ì¸ ì¤‘ í•˜ë‚˜ë¡œ ë‚¨ì•„ ìˆì§€ë§Œ, ì•¼ìƒì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ë¡œë´‡ ë°ì´í„°ì˜ ì–‘ì´ ê¸°í•˜ê¸‰ìˆ˜ì ìœ¼ë¡œ ì¦ê°€í•˜ê³  ìˆë‹¤.
- 2. Generative Value Learning (GVL) ì ‘ê·¼ë²•ì€ ì‹œê°-ì–¸ì–´ ëª¨ë¸(VLMs)ì— ë‚´ì¬ëœ ì§€ì‹ì„ í™œìš©í•˜ì—¬ ì‹œê°ì  ê´€ì°°ë¡œë¶€í„° ì‘ì—… ì§„í–‰ì„ ì˜ˆì¸¡í•œë‹¤.
- 3. OpenGVLì€ ë¡œë´‡ ë° ì¸ê°„ êµ¬í˜„ì„ í¬í•¨í•œ ë‹¤ì–‘í•œ ì¡°ì‘ ì‘ì—…ì—ì„œ ì‘ì—… ì§„í–‰ì„ ì¶”ì •í•˜ê¸° ìœ„í•œ ì¢…í•©ì ì¸ ë²¤ì¹˜ë§ˆí¬ë¥¼ ì œì•ˆí•œë‹¤.
- 4. ê³µê°œëœ ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ë“¤ì´ ë¹„ê³µê°œ ëª¨ë¸ë“¤ì— ë¹„í•´ ì„±ëŠ¥ì´ ì•½ 70%ì— ë¶ˆê³¼í•œ ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ë‹¤.
- 5. OpenGVLì€ ëŒ€ê·œëª¨ ë¡œë´‡ ë°ì´í„°ì…‹ì˜ íš¨ìœ¨ì ì¸ í’ˆì§ˆ í‰ê°€ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ìë™ ë°ì´í„° íë ˆì´ì…˜ ë° í•„í„°ë§ì˜ ì‹¤ìš©ì ì¸ ë„êµ¬ë¡œ í™œìš©ë  ìˆ˜ ìˆë‹¤.


---

*Generated on 2025-09-24 03:41:10*