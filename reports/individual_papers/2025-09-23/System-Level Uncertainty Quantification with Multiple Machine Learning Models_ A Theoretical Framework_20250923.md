---
keywords:
  - Machine Learning
  - Model Uncertainty
  - Input Uncertainty
  - Joint Distribution
category: cs.LG
publish_date: 2025-09-23
arxiv_id: 2509.16663
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T02:12:34.317115",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Machine Learning",
    "Model Uncertainty",
    "Input Uncertainty",
    "Joint Distribution"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Machine Learning": 0.8,
    "Model Uncertainty": 0.7,
    "Input Uncertainty": 0.65,
    "Joint Distribution": 0.6
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Machine Learning Models",
        "canonical": "Machine Learning",
        "aliases": [
          "ML Models",
          "Machine Learning Systems"
        ],
        "category": "broad_technical",
        "rationale": "Machine Learning is a foundational concept that connects to a wide range of technical topics.",
        "novelty_score": 0.2,
        "connectivity_score": 0.9,
        "specificity_score": 0.5,
        "link_intent_score": 0.8
      },
      {
        "surface": "Model Uncertainty",
        "canonical": "Model Uncertainty",
        "aliases": [
          "Uncertainty Quantification",
          "Prediction Uncertainty"
        ],
        "category": "unique_technical",
        "rationale": "Model Uncertainty is crucial for understanding and improving ML model predictions.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      },
      {
        "surface": "Input Uncertainty",
        "canonical": "Input Uncertainty",
        "aliases": [
          "Data Uncertainty",
          "Input Variability"
        ],
        "category": "unique_technical",
        "rationale": "Input Uncertainty is important for assessing the reliability of ML model inputs.",
        "novelty_score": 0.65,
        "connectivity_score": 0.55,
        "specificity_score": 0.75,
        "link_intent_score": 0.65
      },
      {
        "surface": "Joint Distribution",
        "canonical": "Joint Distribution",
        "aliases": [
          "Joint Probability Distribution",
          "Multivariate Distribution"
        ],
        "category": "unique_technical",
        "rationale": "Understanding joint distributions is key to modeling dependencies in ML predictions.",
        "novelty_score": 0.6,
        "connectivity_score": 0.7,
        "specificity_score": 0.7,
        "link_intent_score": 0.6
      }
    ],
    "ban_list_suggestions": [
      "theoretical framework",
      "decision-making",
      "design"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Machine Learning Models",
      "resolved_canonical": "Machine Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.2,
        "connectivity": 0.9,
        "specificity": 0.5,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Model Uncertainty",
      "resolved_canonical": "Model Uncertainty",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Input Uncertainty",
      "resolved_canonical": "Input Uncertainty",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.55,
        "specificity": 0.75,
        "link_intent": 0.65
      }
    },
    {
      "candidate_surface": "Joint Distribution",
      "resolved_canonical": "Joint Distribution",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.7,
        "specificity": 0.7,
        "link_intent": 0.6
      }
    }
  ]
}
-->

# System-Level Uncertainty Quantification with Multiple Machine Learning Models: A Theoretical Framework

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16663.pdf)
**Category**: cs.LG
**Published**: 2025-09-23
**ArXiv ID**: [2509.16663](https://arxiv.org/abs/2509.16663)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/Post-Hoc Split-Point Self-Consistency Verification for Efficient, Unified Quantification of Aleatoric and Epistemic Uncertainty in Deep Learning_20250918|Post-Hoc Split-Point Self-Consistency Verification for Efficient, Unified Quantification of Aleatoric and Epistemic Uncertainty in Deep Learning]] (83.1% similar)
- [[2025-09-22/Quantifying Uncertainty in Natural Language Explanations of Large Language Models for Question Answering_20250922|Quantifying Uncertainty in Natural Language Explanations of Large Language Models for Question Answering]] (82.7% similar)
- [[2025-09-22/Boosting Active Learning with Knowledge Transfer_20250922|Boosting Active Learning with Knowledge Transfer]] (82.0% similar)
- [[2025-09-23/Both Text and Images Leaked! A Systematic Analysis of Data Contamination in Multimodal LLM_20250923|Both Text and Images Leaked! A Systematic Analysis of Data Contamination in Multimodal LLM]] (81.9% similar)
- [[2025-09-23/Causal Fuzzing for Verifying Machine Unlearning_20250923|Causal Fuzzing for Verifying Machine Unlearning]] (81.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Machine Learning|Machine Learning]]
**âš¡ Unique Technical**: [[keywords/Model Uncertainty|Model Uncertainty]], [[keywords/Input Uncertainty|Input Uncertainty]], [[keywords/Joint Distribution|Joint Distribution]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16663v1 Announce Type: cross 
Abstract: ML models have errors when used for predictions. The errors are unknown but can be quantified by model uncertainty. When multiple ML models are trained using the same training points, their model uncertainties may be statistically dependent. In reality, model inputs are also random with input uncertainty. The effects of these types of uncertainty must be considered in decision-making and design. This study develops a theoretical framework that generates the joint distribution of multiple ML predictions given the joint distribution of model uncertainties and the joint distribution of model inputs. The strategy is to decouple the coupling between the two types of uncertainty and transform them as independent random variables. The framework lays a foundation for numerical algorithm development for various specific applications.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” ë‹¤ì¤‘ ê¸°ê³„ í•™ìŠµ(ML) ëª¨ë¸ì˜ ì˜ˆì¸¡ ì‹œ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜ì™€ ê´€ë ¨ëœ ë¶ˆí™•ì‹¤ì„±ì„ ë‹¤ë£¨ëŠ” ì´ë¡ ì  í”„ë ˆì„ì›Œí¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ëª¨ë¸ ë¶ˆí™•ì‹¤ì„±ê³¼ ì…ë ¥ ë¶ˆí™•ì‹¤ì„±ì´ í†µê³„ì ìœ¼ë¡œ ì˜ì¡´ì ì¼ ìˆ˜ ìˆìŒì„ ê³ ë ¤í•˜ì—¬, ì´ ë‘ ë¶ˆí™•ì‹¤ì„±ì„ ë…ë¦½ì ì¸ í™•ë¥  ë³€ìˆ˜ë¡œ ë³€í™˜í•˜ëŠ” ì „ëµì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë‹¤ì¤‘ ML ì˜ˆì¸¡ì˜ ê²°í•© ë¶„í¬ë¥¼ ìƒì„±í•˜ëŠ” ë°©ë²•ì„ ê°œë°œí•˜ì˜€ìœ¼ë©°, ì´ëŠ” ë‹¤ì–‘í•œ ì‘ìš© ë¶„ì•¼ì—ì„œ ìˆ˜ì¹˜ ì•Œê³ ë¦¬ì¦˜ ê°œë°œì˜ ê¸°ì´ˆë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì£¼ìš” ê¸°ì—¬ëŠ” ë¶ˆí™•ì‹¤ì„±ì˜ ì˜í–¥ì„ ê³ ë ¤í•œ ì˜ì‚¬ê²°ì • ë° ì„¤ê³„ì— ëŒ€í•œ ìƒˆë¡œìš´ ì ‘ê·¼ë²•ì„ ì œì‹œí•œ ê²ƒì…ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ML ëª¨ë¸ì˜ ì˜ˆì¸¡ ì˜¤ë¥˜ëŠ” ëª¨ë¸ ë¶ˆí™•ì‹¤ì„±ìœ¼ë¡œ ì •ëŸ‰í™”í•  ìˆ˜ ìˆë‹¤.
- 2. ë™ì¼í•œ í•™ìŠµ ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ ì—¬ëŸ¬ ML ëª¨ë¸ì˜ ë¶ˆí™•ì‹¤ì„±ì€ í†µê³„ì ìœ¼ë¡œ ì˜ì¡´ì ì¼ ìˆ˜ ìˆë‹¤.
- 3. ëª¨ë¸ ì…ë ¥ë„ ë¶ˆí™•ì‹¤ì„±ì„ ê°€ì§€ë©°, ì´ëŠ” ì˜ì‚¬ê²°ì • ë° ì„¤ê³„ì— ê³ ë ¤ë˜ì–´ì•¼ í•œë‹¤.
- 4. ë³¸ ì—°êµ¬ëŠ” ëª¨ë¸ ë¶ˆí™•ì‹¤ì„±ê³¼ ì…ë ¥ ë¶ˆí™•ì‹¤ì„±ì˜ ê²°í•©ì„ ë…ë¦½ì ì¸ í™•ë¥  ë³€ìˆ˜ë¡œ ë³€í™˜í•˜ëŠ” ì´ë¡ ì  í”„ë ˆì„ì›Œí¬ë¥¼ ê°œë°œí•˜ì˜€ë‹¤.
- 5. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ë‹¤ì–‘í•œ íŠ¹ì • ì‘ìš©ì„ ìœ„í•œ ìˆ˜ì¹˜ ì•Œê³ ë¦¬ì¦˜ ê°œë°œì˜ ê¸°ì´ˆë¥¼ ë§ˆë ¨í•œë‹¤.


---

*Generated on 2025-09-24 02:12:34*