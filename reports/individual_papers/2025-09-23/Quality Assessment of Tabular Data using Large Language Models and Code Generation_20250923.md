---
keywords:
  - Large Language Model
  - Retrieval Augmented Generation
  - Few-Shot Learning
  - Code Generation
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.10572
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T01:28:12.619225",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Retrieval Augmented Generation",
    "Few-Shot Learning",
    "Code Generation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.88,
    "Retrieval Augmented Generation": 0.91,
    "Few-Shot Learning": 0.87,
    "Code Generation": 0.84
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are central to the framework and connect to a wide range of NLP and AI research.",
        "novelty_score": 0.45,
        "connectivity_score": 0.92,
        "specificity_score": 0.68,
        "link_intent_score": 0.88
      },
      {
        "surface": "Retrieval-augmented generation",
        "canonical": "Retrieval Augmented Generation",
        "aliases": [
          "RAG"
        ],
        "category": "specific_connectable",
        "rationale": "RAG is a trending technique that enhances LLMs with external knowledge, crucial for generating reliable quality rules.",
        "novelty_score": 0.78,
        "connectivity_score": 0.85,
        "specificity_score": 0.82,
        "link_intent_score": 0.91
      },
      {
        "surface": "Few-shot examples",
        "canonical": "Few-Shot Learning",
        "aliases": [
          "few-shot"
        ],
        "category": "specific_connectable",
        "rationale": "Few-Shot Learning is a key method for training models with minimal data, relevant to the framework's iterative prompting.",
        "novelty_score": 0.65,
        "connectivity_score": 0.88,
        "specificity_score": 0.76,
        "link_intent_score": 0.87
      },
      {
        "surface": "Code-generating LLMs",
        "canonical": "Code Generation",
        "aliases": [
          "code synthesis"
        ],
        "category": "unique_technical",
        "rationale": "Code Generation is a unique aspect of the framework, enabling the creation of executable validators.",
        "novelty_score": 0.72,
        "connectivity_score": 0.79,
        "specificity_score": 0.81,
        "link_intent_score": 0.84
      }
    ],
    "ban_list_suggestions": [
      "rule-based validation",
      "traditional clustering"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.92,
        "specificity": 0.68,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "Retrieval-augmented generation",
      "resolved_canonical": "Retrieval Augmented Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.78,
        "connectivity": 0.85,
        "specificity": 0.82,
        "link_intent": 0.91
      }
    },
    {
      "candidate_surface": "Few-shot examples",
      "resolved_canonical": "Few-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.88,
        "specificity": 0.76,
        "link_intent": 0.87
      }
    },
    {
      "candidate_surface": "Code-generating LLMs",
      "resolved_canonical": "Code Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.79,
        "specificity": 0.81,
        "link_intent": 0.84
      }
    }
  ]
}
-->

# Quality Assessment of Tabular Data using Large Language Models and Code Generation

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.10572.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.10572](https://arxiv.org/abs/2509.10572)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Table2LaTeX-RL_ High-Fidelity LaTeX Code Generation from Table Images via Reinforced Multimodal Language Models_20250923|Table2LaTeX-RL: High-Fidelity LaTeX Code Generation from Table Images via Reinforced Multimodal Language Models]] (85.9% similar)
- [[2025-09-23/From Scores to Steps_ Diagnosing and Improving LLM Performance in Evidence-Based Medical Calculations_20250923|From Scores to Steps: Diagnosing and Improving LLM Performance in Evidence-Based Medical Calculations]] (84.3% similar)
- [[2025-09-22/SeCodePLT_ A Unified Platform for Evaluating the Security of Code GenAI_20250922|SeCodePLT: A Unified Platform for Evaluating the Security of Code GenAI]] (84.2% similar)
- [[2025-09-22/SyGra_ A Unified Graph-Based Framework for Scalable Generation, Quality Tagging, and Management of Synthetic Data_20250922|SyGra: A Unified Graph-Based Framework for Scalable Generation, Quality Tagging, and Management of Synthetic Data]] (83.8% similar)
- [[2025-09-23/EquiBench_ Benchmarking Large Language Models' Reasoning about Program Semantics via Equivalence Checking_20250923|EquiBench: Benchmarking Large Language Models' Reasoning about Program Semantics via Equivalence Checking]] (83.7% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Retrieval Augmented Generation|Retrieval Augmented Generation]], [[keywords/Few-Shot Learning|Few-Shot Learning]]
**âš¡ Unique Technical**: [[keywords/Code Generation|Code Generation]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.10572v2 Announce Type: replace-cross 
Abstract: Reliable data quality is crucial for downstream analysis of tabular datasets, yet rule-based validation often struggles with inefficiency, human intervention, and high computational costs. We present a three-stage framework that combines statistical inliner detection with LLM-driven rule and code generation. After filtering data samples through traditional clustering, we iteratively prompt LLMs to produce semantically valid quality rules and synthesize their executable validators through code-generating LLMs. To generate reliable quality rules, we aid LLMs with retrieval-augmented generation (RAG) by leveraging external knowledge sources and domain-specific few-shot examples. Robust guardrails ensure the accuracy and consistency of both rules and code snippets. Extensive evaluations on benchmark datasets confirm the effectiveness of our approach.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ í‘œ í˜•ì‹ ë°ì´í„°ì˜ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ìƒˆë¡œìš´ 3ë‹¨ê³„ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ê·œì¹™ ê¸°ë°˜ ê²€ì¦ì´ ë¹„íš¨ìœ¨ì ì´ê³  ë¹„ìš©ì´ ë§ì´ ë“œëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, í†µê³„ì  ì´ìƒì¹˜ íƒì§€ì™€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ í™œìš©í•œ ê·œì¹™ ë° ì½”ë“œ ìƒì„± ë°©ì‹ì„ ê²°í•©í–ˆìŠµë‹ˆë‹¤. ë°ì´í„° ìƒ˜í”Œì„ ì „í†µì ì¸ í´ëŸ¬ìŠ¤í„°ë§ìœ¼ë¡œ í•„í„°ë§í•œ í›„, LLMì„ í†µí•´ ì˜ë¯¸ì ìœ¼ë¡œ ìœ íš¨í•œ í’ˆì§ˆ ê·œì¹™ì„ ìƒì„±í•˜ê³ , ì½”ë“œ ìƒì„± LLMì„ í†µí•´ ì‹¤í–‰ ê°€ëŠ¥í•œ ê²€ì¦ê¸°ë¥¼ ë§Œë“­ë‹ˆë‹¤. ì™¸ë¶€ ì§€ì‹ ì†ŒìŠ¤ì™€ ë„ë©”ì¸ íŠ¹í™” ì˜ˆì œë¥¼ í™œìš©í•œ ê²€ìƒ‰ ì¦ê°• ìƒì„±(RAG)ì„ í†µí•´ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” í’ˆì§ˆ ê·œì¹™ì„ ìƒì„±í•˜ë©°, ê²¬ê³ í•œ ê°€ë“œë ˆì¼ì„ í†µí•´ ê·œì¹™ê³¼ ì½”ë“œì˜ ì •í™•ì„±ê³¼ ì¼ê´€ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤. ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì— ëŒ€í•œ ê´‘ë²”ìœ„í•œ í‰ê°€ë¥¼ í†µí•´ ì´ ì ‘ê·¼ ë°©ì‹ì˜ íš¨ê³¼ë¥¼ ì…ì¦í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë°ì´í„° í’ˆì§ˆì€ í…Œì´ë¸” í˜•ì‹ ë°ì´í„°ì˜ í›„ì† ë¶„ì„ì— í•„ìˆ˜ì ì´ë©°, ê¸°ì¡´ì˜ ê·œì¹™ ê¸°ë°˜ ê²€ì¦ì€ ë¹„íš¨ìœ¨ì„±ê³¼ ë†’ì€ ê³„ì‚° ë¹„ìš© ë¬¸ì œë¥¼ ê²ªê³  ìˆë‹¤.
- 2. ë³¸ ì—°êµ¬ëŠ” í†µê³„ì  ì´ìƒì¹˜ íƒì§€ì™€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ í™œìš©í•œ ê·œì¹™ ë° ì½”ë“œ ìƒì„±ì„ ê²°í•©í•œ 3ë‹¨ê³„ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•œë‹¤.
- 3. ì „í†µì ì¸ í´ëŸ¬ìŠ¤í„°ë§ì„ í†µí•´ ë°ì´í„° ìƒ˜í”Œì„ í•„í„°ë§í•œ í›„, LLMì„ ë°˜ë³µì ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ ì˜ë¯¸ì ìœ¼ë¡œ ìœ íš¨í•œ í’ˆì§ˆ ê·œì¹™ì„ ìƒì„±í•˜ê³  ì½”ë“œ ìƒì„± LLMì„ í†µí•´ ì‹¤í–‰ ê°€ëŠ¥í•œ ê²€ì¦ê¸°ë¥¼ í•©ì„±í•œë‹¤.
- 4. ì™¸ë¶€ ì§€ì‹ ì†ŒìŠ¤ì™€ ë„ë©”ì¸ íŠ¹í™” ì˜ˆì œë¥¼ í™œìš©í•œ ê²€ìƒ‰ ì¦ê°• ìƒì„±(RAG)ì„ í†µí•´ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” í’ˆì§ˆ ê·œì¹™ ìƒì„±ì„ ì§€ì›í•œë‹¤.
- 5. ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì— ëŒ€í•œ ê´‘ë²”ìœ„í•œ í‰ê°€ ê²°ê³¼, ì œì•ˆëœ ì ‘ê·¼ ë°©ì‹ì˜ íš¨ê³¼ê°€ ì…ì¦ë˜ì—ˆë‹¤.


---

*Generated on 2025-09-24 01:28:12*