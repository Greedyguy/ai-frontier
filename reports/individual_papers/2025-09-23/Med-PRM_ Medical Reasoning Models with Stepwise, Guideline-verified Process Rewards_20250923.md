---
keywords:
  - Large Language Model
  - Retrieval Augmented Generation
  - Clinical Guidelines
  - Medical Reasoning Models
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2506.11474
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T04:04:36.583644",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Retrieval Augmented Generation",
    "Clinical Guidelines",
    "Medical Reasoning Models"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Retrieval Augmented Generation": 0.9,
    "Clinical Guidelines": 0.78,
    "Medical Reasoning Models": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large language models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "Large language models are central to the paper's methodology and are a key concept in natural language processing.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Retrieval-augmented generation",
        "canonical": "Retrieval Augmented Generation",
        "aliases": [
          "RAG"
        ],
        "category": "specific_connectable",
        "rationale": "This technique is crucial for verifying reasoning steps, linking it to recent advancements in model augmentation.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.82,
        "link_intent_score": 0.9
      },
      {
        "surface": "Clinical guidelines",
        "canonical": "Clinical Guidelines",
        "aliases": [
          "Medical Guidelines"
        ],
        "category": "unique_technical",
        "rationale": "Clinical guidelines are used as a verification source, making them a unique aspect of the model's validation process.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Medical reasoning models",
        "canonical": "Medical Reasoning Models",
        "aliases": [
          "Med-PRM"
        ],
        "category": "unique_technical",
        "rationale": "The paper introduces a novel framework for medical reasoning, which is central to its contribution.",
        "novelty_score": 0.7,
        "connectivity_score": 0.75,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "process reward modeling",
      "state-of-the-art performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large language models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Retrieval-augmented generation",
      "resolved_canonical": "Retrieval Augmented Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.82,
        "link_intent": 0.9
      }
    },
    {
      "candidate_surface": "Clinical guidelines",
      "resolved_canonical": "Clinical Guidelines",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Medical reasoning models",
      "resolved_canonical": "Medical Reasoning Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.75,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# Med-PRM: Medical Reasoning Models with Stepwise, Guideline-verified Process Rewards

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2506.11474.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2506.11474](https://arxiv.org/abs/2506.11474)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/ReasonMed_ A 370K Multi-Agent Generated Dataset for Advancing Medical Reasoning_20250923|ReasonMed: A 370K Multi-Agent Generated Dataset for Advancing Medical Reasoning]] (87.9% similar)
- [[2025-09-23/From Scores to Steps_ Diagnosing and Improving LLM Performance in Evidence-Based Medical Calculations_20250923|From Scores to Steps: Diagnosing and Improving LLM Performance in Evidence-Based Medical Calculations]] (87.5% similar)
- [[2025-09-19/MedFact-R1_ Towards Factual Medical Reasoning via Pseudo-Label Augmentation_20250919|MedFact-R1: Towards Factual Medical Reasoning via Pseudo-Label Augmentation]] (87.2% similar)
- [[2025-09-22/Entropy-Regularized Process Reward Model_20250922|Entropy-Regularized Process Reward Model]] (86.8% similar)
- [[2025-09-22/Fleming-R1_ Toward Expert-Level Medical Reasoning via Reinforcement Learning_20250922|Fleming-R1: Toward Expert-Level Medical Reasoning via Reinforcement Learning]] (86.7% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Retrieval Augmented Generation|Retrieval Augmented Generation]]
**âš¡ Unique Technical**: [[keywords/Clinical Guidelines|Clinical Guidelines]], [[keywords/Medical Reasoning Models|Medical Reasoning Models]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2506.11474v2 Announce Type: replace 
Abstract: Large language models have shown promise in clinical decision making, but current approaches struggle to localize and correct errors at specific steps of the reasoning process. This limitation is critical in medicine, where identifying and addressing reasoning errors is essential for accurate diagnosis and effective patient care. We introduce Med-PRM, a process reward modeling framework that leverages retrieval-augmented generation to verify each reasoning step against established medical knowledge bases. By verifying intermediate reasoning steps with evidence retrieved from clinical guidelines and literature, our model can precisely assess the reasoning quality in a fine-grained manner. Evaluations on five medical QA benchmarks and two open-ended diagnostic tasks demonstrate that Med-PRM achieves state-of-the-art performance, with improving the performance of base models by up to 13.50% using Med-PRM. Moreover, we demonstrate the generality of Med-PRM by integrating it in a plug-and-play fashion with strong policy models such as Meerkat, achieving over 80\% accuracy on MedQA for the first time using small-scale models of 8 billion parameters. Our code and data are available at: https://med-prm.github.io/

## ğŸ“ ìš”ì•½

ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì€ ì„ìƒ ì˜ì‚¬ ê²°ì •ì—ì„œ ìœ ë§í•˜ì§€ë§Œ, í˜„ì¬ ì ‘ê·¼ë²•ì€ ì¶”ë¡  ê³¼ì •ì˜ íŠ¹ì • ë‹¨ê³„ì—ì„œ ì˜¤ë¥˜ë¥¼ ì§€ì—­í™”í•˜ê³  ìˆ˜ì •í•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªê³  ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ í•œê³„ëŠ” ì •í™•í•œ ì§„ë‹¨ê³¼ íš¨ê³¼ì ì¸ í™˜ì ì¹˜ë£Œë¥¼ ìœ„í•´ ì¤‘ìš”í•œ ì˜í•™ ë¶„ì•¼ì—ì„œ íŠ¹íˆ ì¤‘ìš”í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” Med-PRMì´ë¼ëŠ” í”„ë¡œì„¸ìŠ¤ ë³´ìƒ ëª¨ë¸ë§ í”„ë ˆì„ì›Œí¬ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ì´ëŠ” ê²€ìƒ‰ ë³´ê°• ìƒì„± ë°©ì‹ì„ í™œìš©í•˜ì—¬ ê° ì¶”ë¡  ë‹¨ê³„ë¥¼ í™•ë¦½ëœ ì˜í•™ ì§€ì‹ ê¸°ë°˜ê³¼ ëŒ€ì¡°í•˜ì—¬ ê²€ì¦í•©ë‹ˆë‹¤. ì„ìƒ ì§€ì¹¨ê³¼ ë¬¸í—Œì—ì„œ ê²€ìƒ‰í•œ ì¦ê±°ë¡œ ì¤‘ê°„ ì¶”ë¡  ë‹¨ê³„ë¥¼ ê²€ì¦í•¨ìœ¼ë¡œì¨, ëª¨ë¸ì€ ì„¸ë°€í•œ ë°©ì‹ìœ¼ë¡œ ì¶”ë¡ ì˜ ì§ˆì„ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ì„¯ ê°œì˜ ì˜í•™ QA ë²¤ì¹˜ë§ˆí¬ì™€ ë‘ ê°œì˜ ê°œë°©í˜• ì§„ë‹¨ ê³¼ì œ í‰ê°€ì—ì„œ Med-PRMì€ ìµœëŒ€ 13.50%ì˜ ì„±ëŠ¥ í–¥ìƒì„ ì´ë£¨ë©° ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, Med-PRMì€ Meerkatê³¼ ê°™ì€ ê°•ë ¥í•œ ì •ì±… ëª¨ë¸ì— ì†ì‰½ê²Œ í†µí•©ë˜ì–´, 80% ì´ìƒì˜ ì •í™•ë„ë¡œ MedQAì—ì„œ ì†Œê·œëª¨ ëª¨ë¸(80ì–µ ë§¤ê°œë³€ìˆ˜)ë¡œ ì²˜ìŒìœ¼ë¡œ ë†’ì€ ì„±ê³¼ë¥¼ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤. ì½”ë“œì™€ ë°ì´í„°ëŠ” https://med-prm.github.io/ì—ì„œ ì´ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Med-PRMì€ ì˜ë£Œ ì˜ì‚¬ ê²°ì •ì—ì„œ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ ì˜¤ë¥˜ë¥¼ ì‹ë³„í•˜ê³  ìˆ˜ì •í•˜ëŠ” ë° ë„ì›€ì„ ì£¼ëŠ” í”„ë¡œì„¸ìŠ¤ ë³´ìƒ ëª¨ë¸ë§ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.
- 2. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ì„ìƒ ì§€ì¹¨ê³¼ ë¬¸í—Œì—ì„œ ê²€ìƒ‰í•œ ì¦ê±°ë¥¼ í†µí•´ ì¤‘ê°„ ì¶”ë¡  ë‹¨ê³„ë¥¼ ê²€ì¦í•˜ì—¬ ì„¸ë°€í•˜ê²Œ ì¶”ë¡  í’ˆì§ˆì„ í‰ê°€í•©ë‹ˆë‹¤.
- 3. Med-PRMì€ 5ê°œì˜ ì˜ë£Œ QA ë²¤ì¹˜ë§ˆí¬ì™€ 2ê°œì˜ ê°œë°©í˜• ì§„ë‹¨ ê³¼ì œì—ì„œ ê¸°ì¡´ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ìµœëŒ€ 13.50% í–¥ìƒì‹œí‚¤ë©° ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.
- 4. Med-PRMì€ Meerkatê³¼ ê°™ì€ ê°•ë ¥í•œ ì •ì±… ëª¨ë¸ê³¼ì˜ í†µí•©ì„ í†µí•´ MedQAì—ì„œ 80% ì´ìƒì˜ ì •í™•ë„ë¥¼ ì²˜ìŒìœ¼ë¡œ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.
- 5. Med-PRMì˜ ì½”ë“œëŠ” https://med-prm.github.io/ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 04:04:36*