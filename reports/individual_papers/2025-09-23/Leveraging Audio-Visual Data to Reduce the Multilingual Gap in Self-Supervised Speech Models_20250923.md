---
keywords:
  - Self-supervised Learning
  - Multilingual Self-supervised Learning
  - Visual Grounding
  - Zero-Shot Learning
  - Speech Representation Learning
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2509.17523
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:29:39.148807",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Self-supervised Learning",
    "Multilingual Self-supervised Learning",
    "Visual Grounding",
    "Zero-Shot Learning",
    "Speech Representation Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Self-supervised Learning": 0.88,
    "Multilingual Self-supervised Learning": 0.75,
    "Visual Grounding": 0.8,
    "Zero-Shot Learning": 0.77,
    "Speech Representation Learning": 0.82
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Self-supervised learning",
        "canonical": "Self-supervised Learning",
        "aliases": [
          "SSL"
        ],
        "category": "specific_connectable",
        "rationale": "A core method in the paper, connecting with existing models like wav2vec 2.0 and HuBERT.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.85,
        "link_intent_score": 0.88
      },
      {
        "surface": "Multilingual SSL models",
        "canonical": "Multilingual Self-supervised Learning",
        "aliases": [
          "Multilingual SSL"
        ],
        "category": "unique_technical",
        "rationale": "Addresses the multilingual gap, a central challenge discussed in the paper.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      },
      {
        "surface": "Visual grounding",
        "canonical": "Visual Grounding",
        "aliases": [
          "Visual Context"
        ],
        "category": "specific_connectable",
        "rationale": "Introduces a novel approach to improve multilingual model performance.",
        "novelty_score": 0.68,
        "connectivity_score": 0.78,
        "specificity_score": 0.82,
        "link_intent_score": 0.8
      },
      {
        "surface": "Zero-shot phonetic discrimination",
        "canonical": "Zero-Shot Learning",
        "aliases": [
          "Zero-shot Discrimination"
        ],
        "category": "specific_connectable",
        "rationale": "Highlights the performance improvement in zero-shot scenarios, a key result.",
        "novelty_score": 0.55,
        "connectivity_score": 0.72,
        "specificity_score": 0.79,
        "link_intent_score": 0.77
      },
      {
        "surface": "Speech representation learning",
        "canonical": "Speech Representation Learning",
        "aliases": [
          "Speech Embeddings"
        ],
        "category": "broad_technical",
        "rationale": "Fundamental to the paper's focus on improving speech model performance.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.82
      }
    ],
    "ban_list_suggestions": [
      "multilingual gap",
      "performance gap"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Self-supervised learning",
      "resolved_canonical": "Self-supervised Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.85,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "Multilingual SSL models",
      "resolved_canonical": "Multilingual Self-supervised Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Visual grounding",
      "resolved_canonical": "Visual Grounding",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.78,
        "specificity": 0.82,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Zero-shot phonetic discrimination",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.72,
        "specificity": 0.79,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Speech representation learning",
      "resolved_canonical": "Speech Representation Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.82
      }
    }
  ]
}
-->

# Leveraging Audio-Visual Data to Reduce the Multilingual Gap in Self-Supervised Speech Models

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17523.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2509.17523](https://arxiv.org/abs/2509.17523)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/LESS_ Large Language Model Enhanced Semi-Supervised Learning for Speech Foundational Models Using in-the-wild Data_20250922|LESS: Large Language Model Enhanced Semi-Supervised Learning for Speech Foundational Models Using in-the-wild Data]] (84.3% similar)
- [[2025-09-22/The Curious Case of Visual Grounding_ Different Effects for Speech- and Text-based Language Encoders_20250922|The Curious Case of Visual Grounding: Different Effects for Speech- and Text-based Language Encoders]] (84.2% similar)
- [[2025-09-22/Exploring Fine-Tuning of Large Audio Language Models for Spoken Language Understanding under Limited Speech data_20250922|Exploring Fine-Tuning of Large Audio Language Models for Spoken Language Understanding under Limited Speech data]] (84.0% similar)
- [[2025-09-22/Chunk Based Speech Pre-training with High Resolution Finite Scalar Quantization_20250922|Chunk Based Speech Pre-training with High Resolution Finite Scalar Quantization]] (83.7% similar)
- [[2025-09-23/An Effective Strategy for Modeling Score Ordinality and Non-uniform Intervals in Automated Speaking Assessment_20250923|An Effective Strategy for Modeling Score Ordinality and Non-uniform Intervals in Automated Speaking Assessment]] (83.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Speech Representation Learning|Speech Representation Learning]]
**ğŸ”— Specific Connectable**: [[keywords/Self-supervised Learning|Self-supervised Learning]], [[keywords/Visual Grounding|Visual Grounding]], [[keywords/Zero-Shot Learning|Zero-Shot Learning]]
**âš¡ Unique Technical**: [[keywords/Multilingual Self-supervised Learning|Multilingual Self-supervised Learning]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17523v1 Announce Type: new 
Abstract: Self-supervised learning (SSL) has made significant advances in speech representation learning. Models like wav2vec 2.0 and HuBERT have achieved state-of-the-art results in tasks such as speech recognition, particularly in monolingual settings. However, multilingual SSL models tend to underperform their monolingual counterparts on each individual language, especially in multilingual scenarios with few languages such as the bilingual setting. In this work, we investigate a novel approach to reduce this performance gap by introducing limited visual grounding into bilingual speech SSL models. Our results show that visual grounding benefits both monolingual and bilingual models, with especially pronounced gains for the latter, reducing the multilingual performance gap on zero-shot phonetic discrimination from 31.5% for audio-only models to 8.04% with grounding.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ìŒì„± í‘œí˜„ í•™ìŠµì—ì„œ ìê°€ ì§€ë„ í•™ìŠµ(SSL)ì˜ ë°œì „ì„ ë‹¤ë£¹ë‹ˆë‹¤. ê¸°ì¡´ì˜ wav2vec 2.0ê³¼ HuBERT ëª¨ë¸ì€ ë‹¨ì¼ ì–¸ì–´ í™˜ê²½ì—ì„œ ë›°ì–´ë‚œ ì„±ê³¼ë¥¼ ë³´ì˜€ìœ¼ë‚˜, ë‹¤ì¤‘ ì–¸ì–´ SSL ëª¨ë¸ì€ ê°œë³„ ì–¸ì–´ì—ì„œ ì„±ëŠ¥ì´ ì €í•˜ë˜ëŠ” ë¬¸ì œê°€ ìˆì—ˆìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ëŠ” ì´ ì„±ëŠ¥ ê²©ì°¨ë¥¼ ì¤„ì´ê¸° ìœ„í•´ ì‹œê°ì  ê¸°ë°˜ì„ ë„ì…í•˜ëŠ” ìƒˆë¡œìš´ ì ‘ê·¼ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì—°êµ¬ ê²°ê³¼, ì‹œê°ì  ê¸°ë°˜ì€ ë‹¨ì¼ ì–¸ì–´ ë° ì´ì¤‘ ì–¸ì–´ ëª¨ë¸ ëª¨ë‘ì— ì´ì ì„ ì œê³µí•˜ë©°, íŠ¹íˆ ì´ì¤‘ ì–¸ì–´ ëª¨ë¸ì—ì„œ ì„±ëŠ¥ ê²©ì°¨ë¥¼ í¬ê²Œ ì¤„ì˜€ìŠµë‹ˆë‹¤. ì‹œê°ì  ê¸°ë°˜ì„ í†µí•´ ì˜¤ë””ì˜¤ ì „ìš© ëª¨ë¸ì˜ 31.5% ì„±ëŠ¥ ê²©ì°¨ê°€ 8.04%ë¡œ ê°ì†Œí–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ìê°€ ì§€ë„ í•™ìŠµ(SSL)ì€ ìŒì„± í‘œí˜„ í•™ìŠµì—ì„œ í° ë°œì „ì„ ì´ë£¨ì—ˆìœ¼ë©°, wav2vec 2.0ê³¼ HuBERTì™€ ê°™ì€ ëª¨ë¸ì€ ë‹¨ì¼ ì–¸ì–´ í™˜ê²½ì—ì„œ ë›°ì–´ë‚œ ì„±ê³¼ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.
- 2. ë‹¤êµ­ì–´ SSL ëª¨ë¸ì€ ê° ê°œë³„ ì–¸ì–´ì—ì„œ ë‹¨ì¼ ì–¸ì–´ ëª¨ë¸ë³´ë‹¤ ì„±ëŠ¥ì´ ë–¨ì–´ì§€ë©°, íŠ¹íˆ ì´ì¤‘ ì–¸ì–´ì™€ ê°™ì€ ì†Œìˆ˜ ì–¸ì–´ í™˜ê²½ì—ì„œ ê·¸ ì°¨ì´ê°€ ë‘ë“œëŸ¬ì§‘ë‹ˆë‹¤.
- 3. ë³¸ ì—°êµ¬ì—ì„œëŠ” ì´ ì„±ëŠ¥ ê²©ì°¨ë¥¼ ì¤„ì´ê¸° ìœ„í•´ ì´ì¤‘ ì–¸ì–´ ìŒì„± SSL ëª¨ë¸ì— ì œí•œëœ ì‹œê°ì  ê¸°ì´ˆë¥¼ ë„ì…í•˜ëŠ” ìƒˆë¡œìš´ ì ‘ê·¼ ë°©ì‹ì„ ì œì•ˆí•©ë‹ˆë‹¤.
- 4. ì‹œê°ì  ê¸°ì´ˆëŠ” ë‹¨ì¼ ì–¸ì–´ ë° ì´ì¤‘ ì–¸ì–´ ëª¨ë¸ ëª¨ë‘ì— ì´ì ì„ ì œê³µí•˜ë©°, íŠ¹íˆ ì´ì¤‘ ì–¸ì–´ ëª¨ë¸ì—ì„œ ë‘ë“œëŸ¬ì§„ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
- 5. ì‹œê°ì  ê¸°ì´ˆë¥¼ ë„ì…í•¨ìœ¼ë¡œì¨ ì˜¤ë””ì˜¤ ì „ìš© ëª¨ë¸ì˜ ë‹¤êµ­ì–´ ì„±ëŠ¥ ê²©ì°¨ê°€ 31.5%ì—ì„œ 8.04%ë¡œ ê°ì†Œí–ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 03:29:39*