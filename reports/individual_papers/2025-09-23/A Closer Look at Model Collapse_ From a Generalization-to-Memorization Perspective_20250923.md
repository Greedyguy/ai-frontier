---
keywords:
  - Diffusion Models
  - Model Collapse
  - Entropy-Based Data Selection
  - Generalization to Memorization Transition
category: cs.LG
publish_date: 2025-09-23
arxiv_id: 2509.16499
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T01:37:45.877176",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Diffusion Models",
    "Model Collapse",
    "Entropy-Based Data Selection",
    "Generalization to Memorization Transition"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Diffusion Models": 0.82,
    "Model Collapse": 0.78,
    "Entropy-Based Data Selection": 0.77,
    "Generalization to Memorization Transition": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "diffusion models",
        "canonical": "Diffusion Models",
        "aliases": [
          "diffusion model"
        ],
        "category": "specific_connectable",
        "rationale": "Diffusion models are central to the discussion of model collapse and are increasingly relevant in AI-generated data contexts.",
        "novelty_score": 0.55,
        "connectivity_score": 0.85,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "model collapse",
        "canonical": "Model Collapse",
        "aliases": [
          "collapse in models"
        ],
        "category": "unique_technical",
        "rationale": "Model collapse is a unique phenomenon discussed in the paper, crucial for understanding performance degradation in recursive training.",
        "novelty_score": 0.75,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "entropy-based data selection",
        "canonical": "Entropy-Based Data Selection",
        "aliases": [
          "entropy data selection"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel strategy proposed to mitigate model collapse, providing a specific technique for improving model performance.",
        "novelty_score": 0.8,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      },
      {
        "surface": "generalization to memorization",
        "canonical": "Generalization to Memorization Transition",
        "aliases": [
          "memorization transition"
        ],
        "category": "unique_technical",
        "rationale": "The transition from generalization to memorization is a key aspect of model collapse, offering insights into model behavior changes.",
        "novelty_score": 0.7,
        "connectivity_score": 0.68,
        "specificity_score": 0.82,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "performance degradation",
      "synthetic data",
      "training cycle"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "diffusion models",
      "resolved_canonical": "Diffusion Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.85,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "model collapse",
      "resolved_canonical": "Model Collapse",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "entropy-based data selection",
      "resolved_canonical": "Entropy-Based Data Selection",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "generalization to memorization",
      "resolved_canonical": "Generalization to Memorization Transition",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.68,
        "specificity": 0.82,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# A Closer Look at Model Collapse: From a Generalization-to-Memorization Perspective

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16499.pdf)
**Category**: cs.LG
**Published**: 2025-09-23
**ArXiv ID**: [2509.16499](https://arxiv.org/abs/2509.16499)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Mitigating data replication in text-to-audio generative diffusion models through anti-memorization guidance_20250919|Mitigating data replication in text-to-audio generative diffusion models through anti-memorization guidance]] (83.6% similar)
- [[2025-09-18/Data coarse graining can improve model performance_20250918|Data coarse graining can improve model performance]] (83.6% similar)
- [[2025-09-22/Navigate Beyond Shortcuts_ Debiased Learning through the Lens of Neural Collapse_20250922|Navigate Beyond Shortcuts: Debiased Learning through the Lens of Neural Collapse]] (83.0% similar)
- [[2025-09-22/Kuramoto Orientation Diffusion Models_20250922|Kuramoto Orientation Diffusion Models]] (82.7% similar)
- [[2025-09-22/Autoguided Online Data Curation for Diffusion Model Training_20250922|Autoguided Online Data Curation for Diffusion Model Training]] (81.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Diffusion Models|Diffusion Models]]
**âš¡ Unique Technical**: [[keywords/Model Collapse|Model Collapse]], [[keywords/Entropy-Based Data Selection|Entropy-Based Data Selection]], [[keywords/Generalization to Memorization Transition|Generalization to Memorization Transition]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16499v1 Announce Type: new 
Abstract: The widespread use of diffusion models has led to an abundance of AI-generated data, raising concerns about model collapse -- a phenomenon in which recursive iterations of training on synthetic data lead to performance degradation. Prior work primarily characterizes this collapse via variance shrinkage or distribution shift, but these perspectives miss practical manifestations of model collapse. This paper identifies a transition from generalization to memorization during model collapse in diffusion models, where models increasingly replicate training data instead of generating novel content during iterative training on synthetic samples. This transition is directly driven by the declining entropy of the synthetic training data produced in each training cycle, which serves as a clear indicator of model degradation. Motivated by this insight, we propose an entropy-based data selection strategy to mitigate the transition from generalization to memorization and alleviate model collapse. Empirical results show that our approach significantly enhances visual quality and diversity in recursive generation, effectively preventing collapse.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ í™•ì‚° ëª¨ë¸ì˜ ë°˜ë³µì ì¸ í›ˆë ¨ ê³¼ì •ì—ì„œ ë°œìƒí•˜ëŠ” ëª¨ë¸ ë¶•ê´´ í˜„ìƒì„ ë‹¤ë£¹ë‹ˆë‹¤. ê¸°ì¡´ ì—°êµ¬ëŠ” ì£¼ë¡œ ë¶„ì‚° ê°ì†Œë‚˜ ë¶„í¬ ë³€í™”ë¡œ ëª¨ë¸ ë¶•ê´´ë¥¼ ì„¤ëª…í•˜ì§€ë§Œ, ì´ ë…¼ë¬¸ì€ ì¼ë°˜í™”ì—ì„œ ì•”ê¸°ë¡œì˜ ì „í™˜ì„ ëª¨ë¸ ë¶•ê´´ì˜ í•µì‹¬ìœ¼ë¡œ ì§€ì í•©ë‹ˆë‹¤. ì´ëŠ” ë°˜ë³µì ì¸ í•©ì„± ë°ì´í„° í›ˆë ¨ì—ì„œ ëª¨ë¸ì´ ìƒˆë¡œìš´ ì½˜í…ì¸ ë¥¼ ìƒì„±í•˜ê¸°ë³´ë‹¤ ê¸°ì¡´ ë°ì´í„°ë¥¼ ë°˜ë³µí•˜ëŠ” í˜„ìƒìœ¼ë¡œ, í•©ì„± ë°ì´í„°ì˜ ì—”íŠ¸ë¡œí”¼ ê°ì†Œê°€ ì›ì¸ì…ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì—”íŠ¸ë¡œí”¼ ê¸°ë°˜ ë°ì´í„° ì„ íƒ ì „ëµì„ ì œì•ˆí•˜ë©°, ì‹¤í—˜ ê²°ê³¼ ì´ ë°©ë²•ì´ ì‹œê°ì  í’ˆì§ˆê³¼ ë‹¤ì–‘ì„±ì„ í–¥ìƒì‹œì¼œ ëª¨ë¸ ë¶•ê´´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ë°©ì§€í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. í™•ì‚° ëª¨ë¸ì˜ ë°˜ë³µì ì¸ í•©ì„± ë°ì´í„° í•™ìŠµì€ ëª¨ë¸ ë¶•ê´´ë¥¼ ì´ˆë˜í•˜ë©°, ì´ëŠ” ì¼ë°˜í™”ì—ì„œ ì•”ê¸°ë¡œì˜ ì „í™˜ì„ í¬í•¨í•©ë‹ˆë‹¤.
- 2. ëª¨ë¸ ë¶•ê´´ëŠ” í•©ì„± ë°ì´í„°ì˜ ì—”íŠ¸ë¡œí”¼ ê°ì†Œì— ì˜í•´ ì§ì ‘ì ìœ¼ë¡œ ìœ ë°œë˜ë©°, ì´ëŠ” ëª¨ë¸ ì„±ëŠ¥ ì €í•˜ì˜ ëª…í™•í•œ ì§€í‘œë¡œ ì‘ìš©í•©ë‹ˆë‹¤.
- 3. ì—”íŠ¸ë¡œí”¼ ê¸°ë°˜ ë°ì´í„° ì„ íƒ ì „ëµì„ í†µí•´ ì¼ë°˜í™”ì—ì„œ ì•”ê¸°ë¡œì˜ ì „í™˜ì„ ì™„í™”í•˜ê³  ëª¨ë¸ ë¶•ê´´ë¥¼ ë°©ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- 4. ì œì•ˆëœ ì ‘ê·¼ë²•ì€ ë°˜ë³µ ìƒì„± ê³¼ì •ì—ì„œ ì‹œê°ì  í’ˆì§ˆê³¼ ë‹¤ì–‘ì„±ì„ í¬ê²Œ í–¥ìƒì‹œì¼œ ëª¨ë¸ ë¶•ê´´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ë°©ì§€í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 01:37:45*