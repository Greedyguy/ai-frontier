---
keywords:
  - Transformer
  - Graph Neural Network
  - Bidirectional Cross-Stream Fusion
  - Spatiotemporal Features
category: cs.CV
publish_date: 2025-09-23
arxiv_id: 2509.16623
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T04:28:07.193996",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Transformer",
    "Graph Neural Network",
    "Bidirectional Cross-Stream Fusion",
    "Spatiotemporal Features"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Transformer": 0.85,
    "Graph Neural Network": 0.82,
    "Bidirectional Cross-Stream Fusion": 0.7,
    "Spatiotemporal Features": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Transformer",
        "canonical": "Transformer",
        "aliases": [],
        "category": "broad_technical",
        "rationale": "Transformers are central to the proposed framework, linking to a wide range of machine learning applications.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Graph Convolution",
        "canonical": "Graph Neural Network",
        "aliases": [
          "GNN"
        ],
        "category": "specific_connectable",
        "rationale": "Graph Convolution is a key component of the framework, directly linking to Graph Neural Networks.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "Bidirectional Cross-Stream Fusion",
        "canonical": "Bidirectional Cross-Stream Fusion",
        "aliases": [
          "BCSF"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel module introduced in the paper, enhancing the framework's capability to integrate information.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.7
      },
      {
        "surface": "Spatiotemporal Features",
        "canonical": "Spatiotemporal Features",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Capturing spatiotemporal features is crucial for gait emotion recognition, linking to broader computer vision tasks.",
        "novelty_score": 0.5,
        "connectivity_score": 0.78,
        "specificity_score": 0.72,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "testing"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Transformer",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Graph Convolution",
      "resolved_canonical": "Graph Neural Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Bidirectional Cross-Stream Fusion",
      "resolved_canonical": "Bidirectional Cross-Stream Fusion",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Spatiotemporal Features",
      "resolved_canonical": "Spatiotemporal Features",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.78,
        "specificity": 0.72,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# CGTGait: Collaborative Graph and Transformer for Gait Emotion Recognition

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16623.pdf)
**Category**: cs.CV
**Published**: 2025-09-23
**ArXiv ID**: [2509.16623](https://arxiv.org/abs/2509.16623)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Explainable Gait Abnormality Detection Using Dual-Dataset CNN-LSTM Models_20250923|Explainable Gait Abnormality Detection Using Dual-Dataset CNN-LSTM Models]] (82.1% similar)
- [[2025-09-23/Confidence-gated training for efficient early-exit neural networks_20250923|Confidence-gated training for efficient early-exit neural networks]] (81.4% similar)
- [[2025-09-23/MSGAT-GRU_ A Multi-Scale Graph Attention and Recurrent Model for Spatiotemporal Road Accident Prediction_20250923|MSGAT-GRU: A Multi-Scale Graph Attention and Recurrent Model for Spatiotemporal Road Accident Prediction]] (81.2% similar)
- [[2025-09-19/Brain-HGCN_ A Hyperbolic Graph Convolutional Network for Brain Functional Network Analysis_20250919|Brain-HGCN: A Hyperbolic Graph Convolutional Network for Brain Functional Network Analysis]] (80.4% similar)
- [[2025-09-18/LSTC-MDA_ A Unified Framework for Long-Short Term Temporal Convolution and Mixed Data Augmentation in Skeleton-Based Action Recognition_20250918|LSTC-MDA: A Unified Framework for Long-Short Term Temporal Convolution and Mixed Data Augmentation in Skeleton-Based Action Recognition]] (80.4% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Transformer|Transformer]]
**ğŸ”— Specific Connectable**: [[keywords/Graph Neural Network|Graph Neural Network]], [[keywords/Spatiotemporal Features|Spatiotemporal Features]]
**âš¡ Unique Technical**: [[keywords/Bidirectional Cross-Stream Fusion|Bidirectional Cross-Stream Fusion]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16623v1 Announce Type: new 
Abstract: Skeleton-based gait emotion recognition has received significant attention due to its wide-ranging applications. However, existing methods primarily focus on extracting spatial and local temporal motion information, failing to capture long-range temporal representations. In this paper, we propose \textbf{CGTGait}, a novel framework that collaboratively integrates graph convolution and transformers to extract discriminative spatiotemporal features for gait emotion recognition. Specifically, CGTGait consists of multiple CGT blocks, where each block employs graph convolution to capture frame-level spatial topology and the transformer to model global temporal dependencies. Additionally, we introduce a Bidirectional Cross-Stream Fusion (BCSF) module to effectively aggregate posture and motion spatiotemporal features, facilitating the exchange of complementary information between the two streams. We evaluate our method on two widely used datasets, Emotion-Gait and ELMD, demonstrating that our CGTGait achieves state-of-the-art or at least competitive performance while reducing computational complexity by approximately \textbf{82.2\%} (only requiring 0.34G FLOPs) during testing. Code is available at \small{https://github.com/githubzjj1/CGTGait.}

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì—ì„œëŠ” ê³¨ê²© ê¸°ë°˜ ë³´í–‰ ê°ì • ì¸ì‹ì„ ìœ„í•œ ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ì¸ CGTGaitë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ ë°©ë²•ë“¤ì´ ì£¼ë¡œ ê³µê°„ì  ë° êµ­ì†Œì  ì‹œê°„ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ë° ì¤‘ì ì„ ë‘ëŠ” ë°˜ë©´, CGTGaitëŠ” ê·¸ë˜í”„ ì»¨ë³¼ë£¨ì…˜ê³¼ íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ ê²°í•©í•˜ì—¬ ì°¨ë³„í™”ëœ ì‹œê³µê°„ íŠ¹ì§•ì„ ì¶”ì¶œí•©ë‹ˆë‹¤. CGTGaitëŠ” ê° ë¸”ë¡ì—ì„œ ê·¸ë˜í”„ ì»¨ë³¼ë£¨ì…˜ì„ í†µí•´ í”„ë ˆì„ ìˆ˜ì¤€ì˜ ê³µê°„ì  í† í´ë¡œì§€ë¥¼ í¬ì°©í•˜ê³ , íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ í†µí•´ ì „ì—­ ì‹œê°„ ì˜ì¡´ì„±ì„ ëª¨ë¸ë§í•©ë‹ˆë‹¤. ë˜í•œ, ìì„¸ì™€ ì›€ì§ì„ì˜ ì‹œê³µê°„ íŠ¹ì§•ì„ íš¨ê³¼ì ìœ¼ë¡œ í†µí•©í•˜ê¸° ìœ„í•´ ì–‘ë°©í–¥ êµì°¨ ìŠ¤íŠ¸ë¦¼ ìœµí•© ëª¨ë“ˆ(BCSF)ì„ ë„ì…í•©ë‹ˆë‹¤. Emotion-Gaitì™€ ELMD ë°ì´í„°ì…‹ì—ì„œ í‰ê°€í•œ ê²°ê³¼, CGTGaitëŠ” ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ê±°ë‚˜ ìµœì†Œí•œ ê²½ìŸë ¥ ìˆëŠ” ì„±ëŠ¥ì„ ë³´ì´ë©°, í…ŒìŠ¤íŠ¸ ì‹œ ì•½ 82.2%ì˜ ê³„ì‚° ë³µì¡ì„±ì„ ì¤„ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. CGTGaitëŠ” ê·¸ë˜í”„ ì»¨ë³¼ë£¨ì…˜ê³¼ íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ ê²°í•©í•˜ì—¬ ì°¨ë³„ì ì¸ ì‹œê³µê°„ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.
- 2. CGTGaitëŠ” í”„ë ˆì„ ìˆ˜ì¤€ì˜ ê³µê°„ì  í† í´ë¡œì§€ë¥¼ í¬ì°©í•˜ê¸° ìœ„í•´ ê·¸ë˜í”„ ì»¨ë³¼ë£¨ì…˜ì„ ì‚¬ìš©í•˜ê³ , ê¸€ë¡œë²Œ ì‹œê°„ ì˜ì¡´ì„±ì„ ëª¨ë¸ë§í•˜ê¸° ìœ„í•´ íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
- 3. ì–‘ë°©í–¥ êµì°¨ ìŠ¤íŠ¸ë¦¼ ìœµí•©(BCSF) ëª¨ë“ˆì„ ë„ì…í•˜ì—¬ ìì„¸ì™€ ì›€ì§ì„ì˜ ì‹œê³µê°„ íŠ¹ì§•ì„ íš¨ê³¼ì ìœ¼ë¡œ ì§‘ê³„í•˜ê³ , ë‘ ìŠ¤íŠ¸ë¦¼ ê°„ì˜ ë³´ì™„ ì •ë³´ë¥¼ êµí™˜í•©ë‹ˆë‹¤.
- 4. Emotion-Gaitì™€ ELMD ë°ì´í„°ì…‹ì—ì„œ CGTGaitëŠ” ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ê±°ë‚˜ ìµœì†Œí•œ ê²½ìŸë ¥ ìˆëŠ” ì„±ëŠ¥ì„ ë³´ì´ë©°, í…ŒìŠ¤íŠ¸ ì‹œ ì•½ 82.2%ì˜ ê³„ì‚° ë³µì¡ì„±ì„ ì¤„ì…ë‹ˆë‹¤.


---

*Generated on 2025-09-24 04:28:07*