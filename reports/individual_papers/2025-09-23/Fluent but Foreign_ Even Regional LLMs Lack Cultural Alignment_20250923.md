---
keywords:
  - Large Language Model
  - Cultural Alignment
  - Regional Language Models
  - Community-authored Corpora
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2505.21548
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T01:03:16.552481",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Cultural Alignment",
    "Regional Language Models",
    "Community-authored Corpora"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Cultural Alignment": 0.78,
    "Regional Language Models": 0.72,
    "Community-authored Corpora": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "This is a foundational concept in the paper, linking to broader discussions on language models.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.5,
        "link_intent_score": 0.85
      },
      {
        "surface": "Cultural Alignment",
        "canonical": "Cultural Alignment",
        "aliases": [
          "Cultural Fit"
        ],
        "category": "unique_technical",
        "rationale": "Central to the paper's thesis, it addresses the alignment of models with local cultures.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Regional LLMs",
        "canonical": "Regional Language Models",
        "aliases": [
          "Localized LLMs"
        ],
        "category": "unique_technical",
        "rationale": "Highlights the focus on locally adapted language models, a key theme in the paper.",
        "novelty_score": 0.65,
        "connectivity_score": 0.65,
        "specificity_score": 0.75,
        "link_intent_score": 0.72
      },
      {
        "surface": "Community-authored Corpora",
        "canonical": "Community-authored Corpora",
        "aliases": [
          "Community Data"
        ],
        "category": "unique_technical",
        "rationale": "Emphasizes the importance of community-driven data for model training.",
        "novelty_score": 0.68,
        "connectivity_score": 0.55,
        "specificity_score": 0.78,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "values",
      "practices",
      "surveys"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.5,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Cultural Alignment",
      "resolved_canonical": "Cultural Alignment",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Regional LLMs",
      "resolved_canonical": "Regional Language Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.65,
        "specificity": 0.75,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "Community-authored Corpora",
      "resolved_canonical": "Community-authored Corpora",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.55,
        "specificity": 0.78,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# Fluent but Foreign: Even Regional LLMs Lack Cultural Alignment

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2505.21548.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2505.21548](https://arxiv.org/abs/2505.21548)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/CultureScope_ A Dimensional Lens for Probing Cultural Understanding in LLMs_20250922|CultureScope: A Dimensional Lens for Probing Cultural Understanding in LLMs]] (86.3% similar)
- [[2025-09-19/Ticket-Bench_ A Kickoff for Multilingual and Regionalized Agent Evaluation_20250919|Ticket-Bench: A Kickoff for Multilingual and Regionalized Agent Evaluation]] (83.2% similar)
- [[2025-09-22/A method for improving multilingual quality and diversity of instruction fine-tuning datasets_20250922|A method for improving multilingual quality and diversity of instruction fine-tuning datasets]] (82.8% similar)
- [[2025-09-22/The Effect of Language Diversity When Fine-Tuning Large Language Models for Translation_20250922|The Effect of Language Diversity When Fine-Tuning Large Language Models for Translation]] (82.4% similar)
- [[2025-09-22/Benchmark of stylistic variation in LLM-generated texts_20250922|Benchmark of stylistic variation in LLM-generated texts]] (82.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**âš¡ Unique Technical**: [[keywords/Cultural Alignment|Cultural Alignment]], [[keywords/Regional Language Models|Regional Language Models]], [[keywords/Community-authored Corpora|Community-authored Corpora]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2505.21548v2 Announce Type: replace-cross 
Abstract: Large language models (LLMs) are used worldwide, yet exhibit Western cultural tendencies. Many countries are now building ``regional'' LLMs, but it remains unclear whether they reflect local values and practices or merely speak local languages. Using India as a case study, we evaluate six Indic and six global LLMs on two dimensions -- values and practices -- grounded in nationally representative surveys and community-sourced QA datasets. Across tasks, Indic models do not align better with Indian norms than global models; in fact, a U.S. respondent is a closer proxy for Indian values than any Indic model. Prompting and regional fine-tuning fail to recover alignment and can even degrade existing knowledge. We attribute this to scarce culturally grounded data, especially for pretraining. We position cultural evaluation as a first-class requirement alongside multilingual benchmarks and offer a reusable, community-grounded methodology. We call for native, community-authored corpora and thick x wide evaluations to build truly sovereign LLMs.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì´ ì„œêµ¬ ë¬¸í™”ì  ê²½í–¥ì„ ë³´ì´ëŠ” ë¬¸ì œë¥¼ ì§€ì í•˜ë©°, ì¸ë„ë¥¼ ì‚¬ë¡€ë¡œ ì§€ì—­ì  LLMì´ ì‹¤ì œë¡œ ì§€ì—­ì˜ ê°€ì¹˜ì™€ ê´€í–‰ì„ ë°˜ì˜í•˜ëŠ”ì§€ë¥¼ í‰ê°€í•©ë‹ˆë‹¤. ì—°êµ¬ ê²°ê³¼, ì¸ë„ ì§€ì—­ ëª¨ë¸ì´ ê¸€ë¡œë²Œ ëª¨ë¸ë³´ë‹¤ ì¸ë„ ë¬¸í™”ì— ë” ì˜ ë§ì§€ ì•Šìœ¼ë©°, ë¯¸êµ­ ì‘ë‹µìê°€ ì¸ë„ ê°€ì¹˜ë¥¼ ë” ì˜ ëŒ€ë³€í•  ìˆ˜ ìˆë‹¤ëŠ” ì ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ ì¡°ì •ê³¼ ì§€ì—­ì  ë¯¸ì„¸ ì¡°ì •ë„ íš¨ê³¼ì ì´ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì´ëŠ” ë¬¸í™”ì ìœ¼ë¡œ ê¸°ë°˜ì´ ëœ ë°ì´í„°ì˜ ë¶€ì¡± ë•Œë¬¸ìœ¼ë¡œ, ì €ìë“¤ì€ ë¬¸í™”ì  í‰ê°€ë¥¼ ë‹¤êµ­ì–´ ë²¤ì¹˜ë§ˆí¬ì™€ í•¨ê»˜ ì¤‘ìš”í•œ ìš”êµ¬ì‚¬í•­ìœ¼ë¡œ ì œì•ˆí•˜ë©°, ì§€ì—­ ì‚¬íšŒê°€ ì‘ì„±í•œ ì½”í¼ìŠ¤ì™€ í­ë„“ì€ í‰ê°€ë¥¼ í†µí•´ ì§„ì •í•œ ì£¼ê¶Œì  LLMì„ êµ¬ì¶•í•  ê²ƒì„ ì´‰êµ¬í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì€ ì „ ì„¸ê³„ì ìœ¼ë¡œ ì‚¬ìš©ë˜ì§€ë§Œ ì„œêµ¬ ë¬¸í™”ì  ê²½í–¥ì„ ë³´ì¸ë‹¤.
- 2. ì¸ë„ ì‚¬ë¡€ ì—°êµ¬ë¥¼ í†µí•´ ì§€ì—­ LLMsê°€ ì¸ë„ì  ê·œë²”ì— ë” ì˜ ë§ì§€ ì•ŠìŒì„ ë°œê²¬í–ˆë‹¤.
- 3. í”„ë¡¬í”„íŠ¸ ë° ì§€ì—­ ë¯¸ì„¸ ì¡°ì •ì€ ì •ë ¬ì„ íšŒë³µí•˜ì§€ ëª»í•˜ê³  ê¸°ì¡´ ì§€ì‹ì„ ì €í•˜ì‹œí‚¬ ìˆ˜ ìˆë‹¤.
- 4. ë¬¸í™”ì ìœ¼ë¡œ ê¸°ë°˜ì´ ëœ ë°ì´í„°ì˜ ë¶€ì¡±ì´ ì´ëŸ¬í•œ ë¬¸ì œì˜ ì›ì¸ìœ¼ë¡œ ì§€ëª©ëœë‹¤.
- 5. ë¬¸í™” í‰ê°€ë¥¼ ë‹¤êµ­ì–´ ë²¤ì¹˜ë§ˆí¬ì™€ í•¨ê»˜ ì¤‘ìš”í•œ ìš”êµ¬ì‚¬í•­ìœ¼ë¡œ ì œì•ˆí•˜ê³ , ì§€ì—­ ì‚¬íšŒê°€ ì‘ì„±í•œ ì½”í¼ìŠ¤ì˜ í•„ìš”ì„±ì„ ê°•ì¡°í•œë‹¤.


---

*Generated on 2025-09-24 01:03:16*