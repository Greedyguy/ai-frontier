---
keywords:
  - Sharpness-aware Minimization
  - m-Sharpness
  - Stochastic Gradient Noise
  - Stochastic Differential Equation
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.18001
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T00:16:20.422453",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Sharpness-aware Minimization",
    "m-Sharpness",
    "Stochastic Gradient Noise",
    "Stochastic Differential Equation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Sharpness-aware Minimization": 0.78,
    "m-Sharpness": 0.77,
    "Stochastic Gradient Noise": 0.79,
    "Stochastic Differential Equation": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Sharpness-aware minimization",
        "canonical": "Sharpness-aware Minimization",
        "aliases": [
          "SAM"
        ],
        "category": "unique_technical",
        "rationale": "SAM is a unique optimization technique that directly relates to model generalization, making it a valuable link for understanding advanced learning methods.",
        "novelty_score": 0.75,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "m-sharpness",
        "canonical": "m-Sharpness",
        "aliases": [
          "micro-batch sharpness"
        ],
        "category": "unique_technical",
        "rationale": "m-Sharpness is a specific phenomenon within SAM that offers insights into optimization dynamics, providing a unique angle for linking related research.",
        "novelty_score": 0.8,
        "connectivity_score": 0.65,
        "specificity_score": 0.88,
        "link_intent_score": 0.77
      },
      {
        "surface": "Stochastic Gradient Noise",
        "canonical": "Stochastic Gradient Noise",
        "aliases": [
          "SGN"
        ],
        "category": "specific_connectable",
        "rationale": "Understanding the structure of SGN is crucial for linking to works on optimization and noise in machine learning models.",
        "novelty_score": 0.65,
        "connectivity_score": 0.85,
        "specificity_score": 0.8,
        "link_intent_score": 0.79
      },
      {
        "surface": "Stochastic Differential Equation",
        "canonical": "Stochastic Differential Equation",
        "aliases": [
          "SDE"
        ],
        "category": "broad_technical",
        "rationale": "SDEs are foundational in modeling stochastic processes, providing a broad technical link to mathematical frameworks in machine learning.",
        "novelty_score": 0.55,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "performance",
      "method",
      "experiment"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Sharpness-aware minimization",
      "resolved_canonical": "Sharpness-aware Minimization",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "m-sharpness",
      "resolved_canonical": "m-Sharpness",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.65,
        "specificity": 0.88,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Stochastic Gradient Noise",
      "resolved_canonical": "Stochastic Gradient Noise",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.85,
        "specificity": 0.8,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Stochastic Differential Equation",
      "resolved_canonical": "Stochastic Differential Equation",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Unveiling m-Sharpness Through the Structure of Stochastic Gradient Noise

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18001.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.18001](https://arxiv.org/abs/2509.18001)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/SAMPO_Scale-wise Autoregression with Motion PrOmpt for generative world models_20250922|SAMPO:Scale-wise Autoregression with Motion PrOmpt for generative world models]] (79.6% similar)
- [[2025-09-22/Adaptive Algorithms with Sharp Convergence Rates for Stochastic Hierarchical Optimization_20250922|Adaptive Algorithms with Sharp Convergence Rates for Stochastic Hierarchical Optimization]] (79.6% similar)
- [[2025-09-22/Accelerated Gradient Methods with Biased Gradient Estimates_ Risk Sensitivity, High-Probability Guarantees, and Large Deviation Bounds_20250922|Accelerated Gradient Methods with Biased Gradient Estimates: Risk Sensitivity, High-Probability Guarantees, and Large Deviation Bounds]] (79.4% similar)
- [[2025-09-22/Generalization and Optimization of SGD with Lookahead_20250922|Generalization and Optimization of SGD with Lookahead]] (79.2% similar)
- [[2025-09-22/TASAM_ Terrain-and-Aware Segment Anything Model for Temporal-Scale Remote Sensing Segmentation_20250922|TASAM: Terrain-and-Aware Segment Anything Model for Temporal-Scale Remote Sensing Segmentation]] (79.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Stochastic Differential Equation|Stochastic Differential Equation]]
**ğŸ”— Specific Connectable**: [[keywords/Stochastic Gradient Noise|Stochastic Gradient Noise]]
**âš¡ Unique Technical**: [[keywords/Sharpness-aware Minimization|Sharpness-aware Minimization]], [[keywords/m-Sharpness|m-Sharpness]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18001v1 Announce Type: cross 
Abstract: Sharpness-aware minimization (SAM) has emerged as a highly effective technique for improving model generalization, but its underlying principles are not fully understood. We investigated the phenomenon known as m-sharpness, where the performance of SAM improves monotonically as the micro-batch size for computing perturbations decreases. Leveraging an extended Stochastic Differential Equation (SDE) framework, combined with an analysis of the structure of stochastic gradient noise (SGN), we precisely characterize the dynamics of various SAM variants. Our findings reveal that the stochastic noise introduced during SAM perturbations inherently induces a variance-based sharpness regularization effect. Motivated by our theoretical insights, we introduce Reweighted SAM, which employs sharpness-weighted sampling to mimic the generalization benefits of m-SAM while remaining parallelizable. Comprehensive experiments validate the effectiveness of our theoretical analysis and proposed method.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëª¨ë¸ ì¼ë°˜í™”ë¥¼ í–¥ìƒì‹œí‚¤ëŠ” íš¨ê³¼ì ì¸ ê¸°ë²•ì¸ Sharpness-aware minimization (SAM)ì˜ ì›ë¦¬ë¥¼ íƒêµ¬í•©ë‹ˆë‹¤. ì—°êµ¬ì—ì„œëŠ” m-sharpness í˜„ìƒì„ ì¡°ì‚¬í•˜ë©°, ì´ëŠ” SAMì˜ ì„±ëŠ¥ì´ ë¯¸ì„¸ ë°°ì¹˜ í¬ê¸°ê°€ ì¤„ì–´ë“¤ìˆ˜ë¡ ê°œì„ ë˜ëŠ” í˜„ìƒì…ë‹ˆë‹¤. í™•ì¥ëœ í™•ë¥  ë¯¸ë¶„ ë°©ì •ì‹(SDE) í”„ë ˆì„ì›Œí¬ì™€ í™•ë¥ ì  ê·¸ë˜ë””ì–¸íŠ¸ ë…¸ì´ì¦ˆ(SGN) êµ¬ì¡° ë¶„ì„ì„ í†µí•´ ë‹¤ì–‘í•œ SAM ë³€í˜•ì˜ ë™íƒœë¥¼ ì •í™•íˆ ê·œëª…í–ˆìŠµë‹ˆë‹¤. ì—°êµ¬ ê²°ê³¼, SAMì˜ ì„­ë™ ê³¼ì •ì—ì„œ ë„ì…ëœ í™•ë¥ ì  ë…¸ì´ì¦ˆê°€ ë³¸ì§ˆì ìœ¼ë¡œ ë¶„ì‚° ê¸°ë°˜ì˜ sharpness ì •ê·œí™” íš¨ê³¼ë¥¼ ìœ ë„í•¨ì„ ë°í˜”ìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì´ë¡ ì  í†µì°°ì„ ë°”íƒ•ìœ¼ë¡œ, m-SAMì˜ ì¼ë°˜í™” ì´ì ì„ ëª¨ë°©í•˜ë©´ì„œ ë³‘ë ¬í™”ê°€ ê°€ëŠ¥í•œ Reweighted SAMì„ ì œì•ˆí–ˆìŠµë‹ˆë‹¤. ì‹¤í—˜ì„ í†µí•´ ì´ë¡ ì  ë¶„ì„ê³¼ ì œì•ˆëœ ë°©ë²•ì˜ íš¨ê³¼ì„±ì„ ê²€ì¦í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Sharpness-aware minimization (SAM)ì€ ëª¨ë¸ ì¼ë°˜í™” ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” íš¨ê³¼ì ì¸ ê¸°ë²•ì´ì§€ë§Œ, ê·¸ ê¸°ì € ì›ë¦¬ëŠ” ì™„ì „íˆ ì´í•´ë˜ì§€ ì•Šì•˜ë‹¤.
- 2. m-sharpness í˜„ìƒì—ì„œëŠ” ë¯¸ì„¸ ë°°ì¹˜ í¬ê¸°ê°€ ê°ì†Œí• ìˆ˜ë¡ SAMì˜ ì„±ëŠ¥ì´ ë‹¨ì¡°ë¡­ê²Œ í–¥ìƒëœë‹¤.
- 3. í™•ì¥ëœ í™•ë¥  ë¯¸ë¶„ ë°©ì •ì‹(SDE) í”„ë ˆì„ì›Œí¬ì™€ í™•ë¥ ì  ê·¸ë˜ë””ì–¸íŠ¸ ë…¸ì´ì¦ˆ(SGN) êµ¬ì¡° ë¶„ì„ì„ í†µí•´ ë‹¤ì–‘í•œ SAM ë³€ì¢…ì˜ ë™ì—­í•™ì„ ì •í™•íˆ íŠ¹ì„±í™”í–ˆë‹¤.
- 4. SAMì˜ ì„­ë™ ê³¼ì •ì—ì„œ ë„ì…ëœ í™•ë¥ ì  ë…¸ì´ì¦ˆëŠ” ë³¸ì§ˆì ìœ¼ë¡œ ë¶„ì‚° ê¸°ë°˜ì˜ ìƒ¤í”„ë‹ˆìŠ¤ ì •ê·œí™” íš¨ê³¼ë¥¼ ìœ ë„í•œë‹¤.
- 5. ì´ë¡ ì  í†µì°°ì„ ë°”íƒ•ìœ¼ë¡œ, m-SAMì˜ ì¼ë°˜í™” ì´ì ì„ ëª¨ë°©í•˜ë©´ì„œ ë³‘ë ¬í™”ê°€ ê°€ëŠ¥í•œ Reweighted SAMì„ ì œì•ˆí–ˆë‹¤.


---

*Generated on 2025-09-24 00:16:20*