---
keywords:
  - Large Language Model
  - Step-by-step Reasoning
  - Evaluation Criteria
  - Factuality
  - Coherence
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2502.12289
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:49:10.429676",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Step-by-step Reasoning",
    "Evaluation Criteria",
    "Factuality",
    "Coherence"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Step-by-step Reasoning": 0.8,
    "Evaluation Criteria": 0.78,
    "Factuality": 0.77,
    "Coherence": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's focus on reasoning traces, connecting with a wide range of NLP research.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Step-by-step Reasoning",
        "canonical": "Step-by-step Reasoning",
        "aliases": [
          "Sequential Reasoning"
        ],
        "category": "unique_technical",
        "rationale": "Key concept of the paper, offering a unique angle on evaluating reasoning processes.",
        "novelty_score": 0.7,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.8
      },
      {
        "surface": "Evaluation Criteria",
        "canonical": "Evaluation Criteria",
        "aliases": [
          "Assessment Criteria"
        ],
        "category": "unique_technical",
        "rationale": "Essential for linking to research on evaluation methodologies and benchmarks.",
        "novelty_score": 0.65,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.78
      },
      {
        "surface": "Factuality",
        "canonical": "Factuality",
        "aliases": [
          "Fact-checking"
        ],
        "category": "specific_connectable",
        "rationale": "Part of the proposed taxonomy, relevant for discussions on truthfulness in AI outputs.",
        "novelty_score": 0.55,
        "connectivity_score": 0.8,
        "specificity_score": 0.75,
        "link_intent_score": 0.77
      },
      {
        "surface": "Coherence",
        "canonical": "Coherence",
        "aliases": [
          "Logical Consistency"
        ],
        "category": "specific_connectable",
        "rationale": "A critical aspect of reasoning evaluation, linking to studies on narrative and logical flow.",
        "novelty_score": 0.5,
        "connectivity_score": 0.78,
        "specificity_score": 0.72,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "Evaluator Design",
      "Benchmark Development"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Step-by-step Reasoning",
      "resolved_canonical": "Step-by-step Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Evaluation Criteria",
      "resolved_canonical": "Evaluation Criteria",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Factuality",
      "resolved_canonical": "Factuality",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.8,
        "specificity": 0.75,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Coherence",
      "resolved_canonical": "Coherence",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.78,
        "specificity": 0.72,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Evaluating Step-by-step Reasoning Traces: A Survey

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2502.12289.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2502.12289](https://arxiv.org/abs/2502.12289)

## 🔗 유사한 논문
- [[2025-09-22/DivLogicEval_ A Framework for Benchmarking Logical Reasoning Evaluation in Large Language Models_20250922|DivLogicEval: A Framework for Benchmarking Logical Reasoning Evaluation in Large Language Models]] (86.3% similar)
- [[2025-09-23/Step Guided Reasoning_ Improving Mathematical Reasoning using Guidance Generation and Step Reasoning_20250923|Step Guided Reasoning: Improving Mathematical Reasoning using Guidance Generation and Step Reasoning]] (84.8% similar)
- [[2025-09-23/GPO_ Learning from Critical Steps to Improve LLM Reasoning_20250923|GPO: Learning from Critical Steps to Improve LLM Reasoning]] (84.7% similar)
- [[2025-09-23/seqBench_ A Tunable Benchmark to Quantify Sequential Reasoning Limits of LLMs_20250923|seqBench: A Tunable Benchmark to Quantify Sequential Reasoning Limits of LLMs]] (84.5% similar)
- [[2025-09-23/Does Reasoning Introduce Bias? A Study of Social Bias Evaluation and Mitigation in LLM Reasoning_20250923|Does Reasoning Introduce Bias? A Study of Social Bias Evaluation and Mitigation in LLM Reasoning]] (84.2% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Factuality|Factuality]], [[keywords/Coherence|Coherence]]
**⚡ Unique Technical**: [[keywords/Step-by-step Reasoning|Step-by-step Reasoning]], [[keywords/Evaluation Criteria|Evaluation Criteria]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2502.12289v3 Announce Type: replace 
Abstract: Step-by-step reasoning is widely used to enhance the reasoning ability of large language models (LLMs) in complex problems. Evaluating the quality of reasoning traces is crucial for understanding and improving LLM reasoning. However, existing evaluation practices are highly inconsistent, resulting in fragmented progress across evaluator design and benchmark development. To address this gap, this survey provides a comprehensive overview of step-by-step reasoning evaluation, proposing a taxonomy of evaluation criteria with four top-level categories (factuality, validity, coherence, and utility). Based on the taxonomy, we review different datasets, evaluator implementations, and recent findings, leading to promising directions for future research.

## 📝 요약

이 논문은 대형 언어 모델(LLM)의 복잡한 문제 해결 능력을 향상시키기 위해 사용되는 단계별 추론의 평가 방법을 다룹니다. 현재의 평가 방식이 일관성이 부족하여 평가자 설계 및 벤치마크 개발에서 단편적인 발전만 이루어지고 있는 문제를 해결하기 위해, 이 논문은 평가 기준을 사실성, 타당성, 일관성, 유용성의 네 가지 상위 범주로 분류한 체계를 제안합니다. 이를 바탕으로 다양한 데이터셋, 평가자 구현 및 최근 연구 결과를 검토하며 향후 연구 방향을 제시합니다.

## 🎯 주요 포인트

- 1. 대형 언어 모델(LLM)의 복잡한 문제 해결 능력을 향상시키기 위해 단계별 추론이 널리 사용된다.
- 2. LLM의 추론 능력을 이해하고 개선하기 위해 추론 과정의 품질 평가가 중요하다.
- 3. 기존의 평가 방식은 일관성이 부족하여 평가자 설계 및 벤치마크 개발에서 단편적인 진전을 초래한다.
- 4. 이 논문은 단계별 추론 평가에 대한 포괄적인 개요를 제공하며, 사실성, 타당성, 일관성, 유용성의 네 가지 상위 범주로 평가 기준의 분류 체계를 제안한다.
- 5. 제안된 분류 체계를 바탕으로 다양한 데이터셋, 평가자 구현 및 최근 연구 결과를 검토하고, 향후 연구를 위한 유망한 방향을 제시한다.


---

*Generated on 2025-09-24 03:49:10*