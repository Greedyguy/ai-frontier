---
keywords:
  - Meta-learning
  - Contrastive Meta-Objective
  - Task Identity
  - In-Context Learning
category: cs.LG
publish_date: 2025-09-23
arxiv_id: 2410.05975
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T02:35:53.215203",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Meta-learning",
    "Contrastive Meta-Objective",
    "Task Identity",
    "In-Context Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Meta-learning": 0.85,
    "Contrastive Meta-Objective": 0.78,
    "Task Identity": 0.7,
    "In-Context Learning": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Meta-learning",
        "canonical": "Meta-learning",
        "aliases": [
          "Meta Learning"
        ],
        "category": "broad_technical",
        "rationale": "Meta-learning is a foundational concept in machine learning that enables linking across various adaptive learning systems.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Contrastive Meta-Objective",
        "canonical": "Contrastive Meta-Objective",
        "aliases": [
          "ConML"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel concept introduced in the paper, offering a unique perspective on meta-training frameworks.",
        "novelty_score": 0.85,
        "connectivity_score": 0.6,
        "specificity_score": 0.9,
        "link_intent_score": 0.78
      },
      {
        "surface": "Task Identity",
        "canonical": "Task Identity",
        "aliases": [
          "Task ID"
        ],
        "category": "specific_connectable",
        "rationale": "Task identity provides a crucial link for understanding task-specific adaptations in meta-learning.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      },
      {
        "surface": "In-Context Learning",
        "canonical": "In-Context Learning",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "In-context learning is a trending approach that enhances the adaptability of learning models.",
        "novelty_score": 0.5,
        "connectivity_score": 0.82,
        "specificity_score": 0.78,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "mini-batch episodic training",
      "problem- and learner-agnostic"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Meta-learning",
      "resolved_canonical": "Meta-learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Contrastive Meta-Objective",
      "resolved_canonical": "Contrastive Meta-Objective",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.6,
        "specificity": 0.9,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Task Identity",
      "resolved_canonical": "Task Identity",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "In-Context Learning",
      "resolved_canonical": "In-Context Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.82,
        "specificity": 0.78,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# Learning to Learn with Contrastive Meta-Objective

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2410.05975.pdf)
**Category**: cs.LG
**Published**: 2025-09-23
**ArXiv ID**: [2410.05975](https://arxiv.org/abs/2410.05975)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/CoUn_ Empowering Machine Unlearning via Contrastive Learning_20250923|CoUn: Empowering Machine Unlearning via Contrastive Learning]] (82.8% similar)
- [[2025-09-22/Two Is Better Than One_ Aligned Representation Pairs for Anomaly Detection_20250922|Two Is Better Than One: Aligned Representation Pairs for Anomaly Detection]] (82.5% similar)
- [[2025-09-22/Towards Robust Visual Continual Learning with Multi-Prototype Supervision_20250922|Towards Robust Visual Continual Learning with Multi-Prototype Supervision]] (82.1% similar)
- [[2025-09-22/XAutoLM_ Efficient Fine-Tuning of Language Models via Meta-Learning and AutoML_20250922|XAutoLM: Efficient Fine-Tuning of Language Models via Meta-Learning and AutoML]] (81.7% similar)
- [[2025-09-19/Modular Machine Learning_ An Indispensable Path towards New-Generation Large Language Models_20250919|Modular Machine Learning: An Indispensable Path towards New-Generation Large Language Models]] (81.4% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Meta-learning|Meta-learning]]
**ğŸ”— Specific Connectable**: [[keywords/Task Identity|Task Identity]], [[keywords/In-Context Learning|In-Context Learning]]
**âš¡ Unique Technical**: [[keywords/Contrastive Meta-Objective|Contrastive Meta-Objective]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2410.05975v3 Announce Type: replace 
Abstract: Meta-learning enables learning systems to adapt quickly to new tasks, similar to humans. Different meta-learning approaches all work under/with the mini-batch episodic training framework. Such framework naturally gives the information about task identity, which can serve as additional supervision for meta-training to improve generalizability. We propose to exploit task identity as additional supervision in meta-training, inspired by the alignment and discrimination ability which is is intrinsic in human's fast learning. This is achieved by contrasting what meta-learners learn, i.e., model representations. The proposed ConML is evaluating and optimizing the contrastive meta-objective under a problem- and learner-agnostic meta-training framework. We demonstrate that ConML integrates seamlessly with existing meta-learners, as well as in-context learning models, and brings significant boost in performance with small implementation cost.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë©”íƒ€ëŸ¬ë‹ ì‹œìŠ¤í…œì´ ìƒˆë¡œìš´ ì‘ì—…ì— ë¹ ë¥´ê²Œ ì ì‘í•  ìˆ˜ ìˆë„ë¡ ë•ëŠ” ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë©”íƒ€ëŸ¬ë‹ ì ‘ê·¼ë²•ì€ ë¯¸ë‹ˆë°°ì¹˜ ì—í”¼ì†Œë“œ í›ˆë ¨ í”„ë ˆì„ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ë©°, ì´ ê³¼ì •ì—ì„œ ì‘ì—… ì‹ë³„ ì •ë³´ë¥¼ ì¶”ê°€ì ì¸ ê°ë…ìœ¼ë¡œ í™œìš©í•˜ì—¬ ì¼ë°˜í™” ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì €ìë“¤ì€ ì¸ê°„ì˜ ë¹ ë¥¸ í•™ìŠµì—ì„œ ë‚˜íƒ€ë‚˜ëŠ” ì •ë ¬ ë° êµ¬ë³„ ëŠ¥ë ¥ì— ì˜ê°ì„ ë°›ì•„, ì‘ì—… ì‹ë³„ì„ ë©”íƒ€í›ˆë ¨ì˜ ì¶”ê°€ ê°ë…ìœ¼ë¡œ í™œìš©í•˜ëŠ” ConMLì„ ì œì•ˆí•©ë‹ˆë‹¤. ConMLì€ ë¬¸ì œ ë° í•™ìŠµìì— ë¬´ê´€í•œ ë©”íƒ€í›ˆë ¨ í”„ë ˆì„ì›Œí¬ì—ì„œ ëŒ€ì¡° ë©”íƒ€ ëª©í‘œë¥¼ í‰ê°€í•˜ê³  ìµœì í™”í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ConMLì€ ê¸°ì¡´ ë©”íƒ€ëŸ¬ë„ˆ ë° ì»¨í…ìŠ¤íŠ¸ í•™ìŠµ ëª¨ë¸ê³¼ ì›í™œí•˜ê²Œ í†µí•©ë˜ë©°, ì ì€ êµ¬í˜„ ë¹„ìš©ìœ¼ë¡œ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë©”íƒ€ëŸ¬ë‹ì€ ì¸ê°„ê³¼ ìœ ì‚¬í•˜ê²Œ ìƒˆë¡œìš´ ì‘ì—…ì— ë¹ ë¥´ê²Œ ì ì‘í•  ìˆ˜ ìˆë„ë¡ í•™ìŠµ ì‹œìŠ¤í…œì„ ì§€ì›í•©ë‹ˆë‹¤.
- 2. ë¯¸ë‹ˆë°°ì¹˜ ì—í”¼ì†Œë“œ í›ˆë ¨ í”„ë ˆì„ì›Œí¬ëŠ” ì‘ì—… ì‹ë³„ ì •ë³´ë¥¼ ì œê³µí•˜ì—¬ ë©”íƒ€í›ˆë ¨ì˜ ì¼ë°˜í™”ë¥¼ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- 3. ì œì•ˆëœ ConMLì€ ë¬¸ì œ ë° í•™ìŠµìì— ë¬´ê´€í•œ ë©”íƒ€í›ˆë ¨ í”„ë ˆì„ì›Œí¬ì—ì„œ ëŒ€ì¡°ì ì¸ ë©”íƒ€ëª©í‘œë¥¼ í‰ê°€í•˜ê³  ìµœì í™”í•©ë‹ˆë‹¤.
- 4. ConMLì€ ê¸°ì¡´ ë©”íƒ€ëŸ¬ë„ˆ ë° ì¸ì»¨í…ìŠ¤íŠ¸ í•™ìŠµ ëª¨ë¸ê³¼ ì›í™œí•˜ê²Œ í†µí•©ë˜ë©°, ì ì€ êµ¬í˜„ ë¹„ìš©ìœ¼ë¡œ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
- 5. ì‘ì—… ì‹ë³„ì„ ì¶”ê°€ì ì¸ ê°ë…ìœ¼ë¡œ í™œìš©í•˜ì—¬ ë©”íƒ€í›ˆë ¨ì˜ ì •ë ¬ ë° ì°¨ë³„í™” ëŠ¥ë ¥ì„ ê°•í™”í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 02:35:53*