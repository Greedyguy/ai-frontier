---
keywords:
  - Retrieval Augmented Generation
  - Multimodal Knowledge Graph
  - Visual-Audio-Text Knowledge Graph
  - Multimodal Learning
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2506.21556
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T04:06:26.826666",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Retrieval Augmented Generation",
    "Multimodal Knowledge Graph",
    "Visual-Audio-Text Knowledge Graph",
    "Multimodal Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Retrieval Augmented Generation": 0.85,
    "Multimodal Knowledge Graph": 0.78,
    "Visual-Audio-Text Knowledge Graph": 0.82,
    "Multimodal Learning": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Retrieval Augmented Generation",
        "canonical": "Retrieval Augmented Generation",
        "aliases": [
          "RAG"
        ],
        "category": "specific_connectable",
        "rationale": "This concept is central to the paper's proposed framework and is a trending topic, enhancing connectivity with related research.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.78,
        "link_intent_score": 0.85
      },
      {
        "surface": "Multimodal Knowledge Graph",
        "canonical": "Multimodal Knowledge Graph",
        "aliases": [
          "MMKG"
        ],
        "category": "unique_technical",
        "rationale": "The paper introduces a novel type of knowledge graph, which is crucial for understanding its contributions.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.82,
        "link_intent_score": 0.78
      },
      {
        "surface": "Visual-Audio-Text Knowledge Graph",
        "canonical": "Visual-Audio-Text Knowledge Graph",
        "aliases": [
          "VAT-KG"
        ],
        "category": "unique_technical",
        "rationale": "This is a specific implementation of the proposed concept, highlighting its unique contribution to the field.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.82
      },
      {
        "surface": "Multimodal Learning",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal"
        ],
        "category": "specific_connectable",
        "rationale": "The paper's focus on integrating multiple modalities aligns with this trending concept, facilitating broader connections.",
        "novelty_score": 0.5,
        "connectivity_score": 0.83,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "knowledge",
      "dataset",
      "framework"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Retrieval Augmented Generation",
      "resolved_canonical": "Retrieval Augmented Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.78,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Multimodal Knowledge Graph",
      "resolved_canonical": "Multimodal Knowledge Graph",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.82,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Visual-Audio-Text Knowledge Graph",
      "resolved_canonical": "Visual-Audio-Text Knowledge Graph",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Multimodal Learning",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.83,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# VAT-KG: Knowledge-Intensive Multimodal Knowledge Graph Dataset for Retrieval-Augmented Generation

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2506.21556.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2506.21556](https://arxiv.org/abs/2506.21556)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/MMAPG_ A Training-Free Framework for Multimodal Multi-hop Question Answering via Adaptive Planning Graphs_20250922|MMAPG: A Training-Free Framework for Multimodal Multi-hop Question Answering via Adaptive Planning Graphs]] (83.2% similar)
- [[2025-09-23/GRIL_ Knowledge Graph Retrieval-Integrated Learning with Large Language Models_20250923|GRIL: Knowledge Graph Retrieval-Integrated Learning with Large Language Models]] (82.5% similar)
- [[2025-09-19/UnifiedVisual_ A Framework for Constructing Unified Vision-Language Datasets_20250919|UnifiedVisual: A Framework for Constructing Unified Vision-Language Datasets]] (82.1% similar)
- [[2025-09-18/KBM_ Delineating Knowledge Boundary for Adaptive Retrieval in Large Language Models_20250918|KBM: Delineating Knowledge Boundary for Adaptive Retrieval in Large Language Models]] (82.1% similar)
- [[2025-09-22/DistillMatch_ Leveraging Knowledge Distillation from Vision Foundation Model for Multimodal Image Matching_20250922|DistillMatch: Leveraging Knowledge Distillation from Vision Foundation Model for Multimodal Image Matching]] (82.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Retrieval Augmented Generation|Retrieval Augmented Generation]], [[keywords/Multimodal Learning|Multimodal Learning]]
**âš¡ Unique Technical**: [[keywords/Multimodal Knowledge Graph|Multimodal Knowledge Graph]], [[keywords/Visual-Audio-Text Knowledge Graph|Visual-Audio-Text Knowledge Graph]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2506.21556v2 Announce Type: replace 
Abstract: Multimodal Knowledge Graphs (MMKGs), which represent explicit knowledge across multiple modalities, play a pivotal role by complementing the implicit knowledge of Multimodal Large Language Models (MLLMs) and enabling more grounded reasoning via Retrieval Augmented Generation (RAG). However, existing MMKGs are generally limited in scope: they are often constructed by augmenting pre-existing knowledge graphs, which restricts their knowledge, resulting in outdated or incomplete knowledge coverage, and they often support only a narrow range of modalities, such as text and visual information. These limitations reduce their extensibility and applicability to a broad range of multimodal tasks, particularly as the field shifts toward richer modalities such as video and audio in recent MLLMs. Therefore, we propose the Visual-Audio-Text Knowledge Graph (VAT-KG), the first concept-centric and knowledge-intensive multimodal knowledge graph that covers visual, audio, and text information, where each triplet is linked to multimodal data and enriched with detailed descriptions of concepts. Specifically, our construction pipeline ensures cross-modal knowledge alignment between multimodal data and fine-grained semantics through a series of stringent filtering and alignment steps, enabling the automatic generation of MMKGs from any multimodal dataset. We further introduce a novel multimodal RAG framework that retrieves detailed concept-level knowledge in response to queries from arbitrary modalities. Experiments on question answering tasks across various modalities demonstrate the effectiveness of VAT-KG in supporting MLLMs, highlighting its practical value in unifying and leveraging multimodal knowledge.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì‹œê°, ì˜¤ë””ì˜¤, í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ì•„ìš°ë¥´ëŠ” ìµœì´ˆì˜ ê°œë… ì¤‘ì‹¬ ë©€í‹°ëª¨ë‹¬ ì§€ì‹ ê·¸ë˜í”„ì¸ VAT-KGë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ ë©€í‹°ëª¨ë‹¬ ì§€ì‹ ê·¸ë˜í”„ëŠ” ì£¼ë¡œ ê¸°ì¡´ ì§€ì‹ ê·¸ë˜í”„ë¥¼ í™•ì¥í•˜ì—¬ êµ¬ì¶•ë˜ë©°, í…ìŠ¤íŠ¸ì™€ ì‹œê° ì •ë³´ì— êµ­í•œë˜ì–´ ìˆì–´ ì§€ì‹ ë²”ìœ„ê°€ ì œí•œì ì…ë‹ˆë‹¤. VAT-KGëŠ” ì´ëŸ¬í•œ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³ , ê°œë…ì˜ ìƒì„¸í•œ ì„¤ëª…ê³¼ ë©€í‹°ëª¨ë‹¬ ë°ì´í„°ë¥¼ ì—°ê²°í•˜ì—¬ ë³´ë‹¤ í’ë¶€í•œ ì§€ì‹ í‘œí˜„ì„ ì œê³µí•©ë‹ˆë‹¤. ë˜í•œ, ìƒˆë¡œìš´ ë©€í‹°ëª¨ë‹¬ RAG í”„ë ˆì„ì›Œí¬ë¥¼ í†µí•´ ë‹¤ì–‘í•œ ëª¨ë‹¬ë¦¬í‹°ì˜ ì§ˆì˜ì— ëŒ€í•´ ê°œë… ìˆ˜ì¤€ì˜ ìƒì„¸í•œ ì§€ì‹ì„ ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, VAT-KGëŠ” ë©€í‹°ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(MLLMs)ì„ íš¨ê³¼ì ìœ¼ë¡œ ì§€ì›í•˜ë©°, ë©€í‹°ëª¨ë‹¬ ì§€ì‹ì„ í†µí•©í•˜ê³  í™œìš©í•˜ëŠ” ë° ì‹¤ì§ˆì ì¸ ê°€ì¹˜ë¥¼ ê°€ì§ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ê¸°ì¡´ì˜ ë©€í‹°ëª¨ë‹¬ ì§€ì‹ ê·¸ë˜í”„(MMKG)ëŠ” ë²”ìœ„ê°€ ì œí•œì ì´ë©°, ì£¼ë¡œ ê¸°ì¡´ ì§€ì‹ ê·¸ë˜í”„ë¥¼ ë³´ê°•í•˜ì—¬ êµ¬ì¶•ë˜ì–´ ì§€ì‹ì´ ì œí•œì ì´ê³  ìµœì‹  ì •ë³´ê°€ ë¶€ì¡±í•˜ë‹¤.
- 2. VAT-KGëŠ” ì‹œê°, ì˜¤ë””ì˜¤, í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ í¬í•¨í•˜ëŠ” ìµœì´ˆì˜ ê°œë… ì¤‘ì‹¬ ë©€í‹°ëª¨ë‹¬ ì§€ì‹ ê·¸ë˜í”„ë¡œ, ê° ì‚¼ì¤‘í•­ì´ ë©€í‹°ëª¨ë‹¬ ë°ì´í„°ì™€ ì—°ê²°ë˜ì–´ ìˆë‹¤.
- 3. VAT-KGì˜ êµ¬ì¶• íŒŒì´í”„ë¼ì¸ì€ ì—„ê²©í•œ í•„í„°ë§ê³¼ ì •ë ¬ ë‹¨ê³„ë¥¼ í†µí•´ ë©€í‹°ëª¨ë‹¬ ë°ì´í„°ì™€ ì„¸ë°€í•œ ì˜ë¯¸ ê°„ì˜ êµì°¨ ëª¨ë‹¬ ì§€ì‹ ì •ë ¬ì„ ë³´ì¥í•œë‹¤.
- 4. ìƒˆë¡œìš´ ë©€í‹°ëª¨ë‹¬ RAG í”„ë ˆì„ì›Œí¬ëŠ” ì„ì˜ì˜ ëª¨ë‹¬ë¦¬í‹°ë¡œë¶€í„°ì˜ ì¿¼ë¦¬ì— ëŒ€í•´ ìƒì„¸í•œ ê°œë… ìˆ˜ì¤€ì˜ ì§€ì‹ì„ ê²€ìƒ‰í•  ìˆ˜ ìˆë‹¤.
- 5. ë‹¤ì–‘í•œ ëª¨ë‹¬ë¦¬í‹°ì˜ ì§ˆë¬¸ ì‘ë‹µ ì‹¤í—˜ì—ì„œ VAT-KGëŠ” MLLMì„ ì§€ì›í•˜ëŠ” ë° íš¨ê³¼ì ì´ë©°, ë©€í‹°ëª¨ë‹¬ ì§€ì‹ì„ í†µí•©í•˜ê³  í™œìš©í•˜ëŠ” ì‹¤ì§ˆì ì¸ ê°€ì¹˜ë¥¼ ì…ì¦í•œë‹¤.


---

*Generated on 2025-09-24 04:06:26*