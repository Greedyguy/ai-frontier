---
keywords:
  - Large Language Model
  - Brain Alignment
  - Formal Linguistic Competence
  - Functional Linguistic Competence
  - Neural Language Benchmarks
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2503.01830
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:51:33.092466",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Brain Alignment",
    "Formal Linguistic Competence",
    "Functional Linguistic Competence",
    "Neural Language Benchmarks"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Brain Alignment": 0.8,
    "Formal Linguistic Competence": 0.78,
    "Functional Linguistic Competence": 0.77,
    "Neural Language Benchmarks": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large language models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Central to the study, linking to a broad range of AI research.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "brain alignment",
        "canonical": "Brain Alignment",
        "aliases": [
          "neural alignment"
        ],
        "category": "unique_technical",
        "rationale": "Key concept in understanding the relationship between models and human cognition.",
        "novelty_score": 0.75,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.8
      },
      {
        "surface": "formal linguistic competence",
        "canonical": "Formal Linguistic Competence",
        "aliases": [
          "linguistic rules knowledge"
        ],
        "category": "unique_technical",
        "rationale": "Highlights the focus on structural language understanding in models.",
        "novelty_score": 0.65,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "functional linguistic competence",
        "canonical": "Functional Linguistic Competence",
        "aliases": [
          "world knowledge and reasoning"
        ],
        "category": "unique_technical",
        "rationale": "Contrasts with formal competence, emphasizing broader cognitive functions.",
        "novelty_score": 0.68,
        "connectivity_score": 0.6,
        "specificity_score": 0.82,
        "link_intent_score": 0.77
      },
      {
        "surface": "neural language benchmarks",
        "canonical": "Neural Language Benchmarks",
        "aliases": [
          "language benchmarks"
        ],
        "category": "specific_connectable",
        "rationale": "Essential for evaluating model performance against human-like understanding.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "training checkpoints",
      "model sizes",
      "feature size"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large language models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "brain alignment",
      "resolved_canonical": "Brain Alignment",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "formal linguistic competence",
      "resolved_canonical": "Formal Linguistic Competence",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "functional linguistic competence",
      "resolved_canonical": "Functional Linguistic Competence",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.6,
        "specificity": 0.82,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "neural language benchmarks",
      "resolved_canonical": "Neural Language Benchmarks",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# From Language to Cognition: How LLMs Outgrow the Human Language Network

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2503.01830.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2503.01830](https://arxiv.org/abs/2503.01830)

## 🔗 유사한 논문
- [[2025-09-18/Do LLMs Align Human Values Regarding Social Biases? Judging and Explaining Social Biases with LLMs_20250918|Do LLMs Align Human Values Regarding Social Biases? Judging and Explaining Social Biases with LLMs]] (85.7% similar)
- [[2025-09-22/How do Language Models Generate Slang_ A Systematic Comparison between Human and Machine-Generated Slang Usages_20250922|How do Language Models Generate Slang: A Systematic Comparison between Human and Machine-Generated Slang Usages]] (85.5% similar)
- [[2025-09-23/AIPsychoBench_ Understanding the Psychometric Differences between LLMs and Humans_20250923|AIPsychoBench: Understanding the Psychometric Differences between LLMs and Humans]] (85.5% similar)
- [[2025-09-22/Modeling Transformers as complex networks to analyze learning dynamics_20250922|Modeling Transformers as complex networks to analyze learning dynamics]] (85.5% similar)
- [[2025-09-22/Can Large Language Models Infer Causal Relationships from Real-World Text?_20250922|Can Large Language Models Infer Causal Relationships from Real-World Text?]] (85.5% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Neural Language Benchmarks|Neural Language Benchmarks]]
**⚡ Unique Technical**: [[keywords/Brain Alignment|Brain Alignment]], [[keywords/Formal Linguistic Competence|Formal Linguistic Competence]], [[keywords/Functional Linguistic Competence|Functional Linguistic Competence]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2503.01830v2 Announce Type: replace 
Abstract: Large language models (LLMs) exhibit remarkable similarity to neural activity in the human language network. However, the key properties of language shaping brain-like representations, and their evolution during training as a function of different tasks remain unclear. We here benchmark 34 training checkpoints spanning 300B tokens across 8 different model sizes to analyze how brain alignment relates to linguistic competence. Specifically, we find that brain alignment tracks the development of formal linguistic competence -- i.e., knowledge of linguistic rules -- more closely than functional linguistic competence. While functional competence, which involves world knowledge and reasoning, continues to develop throughout training, its relationship with brain alignment is weaker, suggesting that the human language network primarily encodes formal linguistic structure rather than broader cognitive functions. We further show that model size is not a reliable predictor of brain alignment when controlling for feature size and find that the correlation between next-word prediction, behavioral alignment and brain alignment fades once models surpass human language proficiency. Finally, using the largest set of rigorous neural language benchmarks to date, we show that language brain alignment benchmarks remain unsaturated, highlighting opportunities for improving future models. Taken together, our findings suggest that the human language network is best modeled by formal, rather than functional, aspects of language.

## 📝 요약

이 논문은 대형 언어 모델(LLM)이 인간의 언어 네트워크와 유사한 신경 활동을 보이지만, 언어가 뇌와 유사한 표현을 형성하는 주요 특성과 훈련 중 다양한 과제에 따른 진화는 명확하지 않다고 지적합니다. 연구에서는 8가지 모델 크기에서 3000억 개의 토큰을 포함한 34개의 훈련 체크포인트를 분석하여 뇌 정렬이 언어적 능력과 어떻게 관련되는지를 조사했습니다. 뇌 정렬은 언어 규칙에 대한 지식인 형식적 언어 능력의 발달과 밀접하게 관련되지만, 세계 지식과 추론을 포함하는 기능적 언어 능력과의 관계는 약하다는 것을 발견했습니다. 또한, 모델 크기는 뇌 정렬의 신뢰할 수 있는 예측 변수가 아니며, 모델이 인간의 언어 능력을 초과하면 다음 단어 예측, 행동 정렬 및 뇌 정렬 간의 상관관계가 감소한다고 밝혔습니다. 이 연구는 언어 뇌 정렬 벤치마크가 아직 포화되지 않았음을 보여주며, 미래 모델 개선의 기회를 제시합니다. 결론적으로, 인간의 언어 네트워크는 기능적 측면보다는 형식적 측면에 의해 가장 잘 모델링된다는 것을 시사합니다.

## 🎯 주요 포인트

- 1. 대형 언어 모델(LLMs)은 인간 언어 네트워크의 신경 활동과 유사한 특성을 보인다.
- 2. 뇌 정렬은 형식적 언어 능력의 발달과 더 밀접하게 관련되어 있으며, 기능적 언어 능력과의 관계는 약하다.
- 3. 모델 크기는 뇌 정렬의 신뢰할 수 있는 예측 변수가 아니며, 인간 언어 능력을 초과하는 모델에서는 예측 정확도와 뇌 정렬의 상관관계가 감소한다.
- 4. 언어 뇌 정렬 벤치마크는 아직 포화되지 않았으며, 이는 향후 모델 개선의 기회를 제공한다.
- 5. 인간 언어 네트워크는 기능적 측면보다는 형식적 측면으로 가장 잘 모델링된다.


---

*Generated on 2025-09-24 03:51:33*