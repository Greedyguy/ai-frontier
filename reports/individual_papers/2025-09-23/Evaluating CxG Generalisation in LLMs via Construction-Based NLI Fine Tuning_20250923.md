---
keywords:
  - Large Language Model
  - Construction Grammar
  - Natural Language Inference
  - Zero-Shot Learning
  - Schematic Pattern
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2509.16422
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:12:09.364618",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Construction Grammar",
    "Natural Language Inference",
    "Zero-Shot Learning",
    "Schematic Pattern"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Construction Grammar": 0.78,
    "Natural Language Inference": 0.82,
    "Zero-Shot Learning": 0.79,
    "Schematic Pattern": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "This is a fundamental concept in the paper, linking to many related technical discussions.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Construction Grammars",
        "canonical": "Construction Grammar",
        "aliases": [
          "CxG"
        ],
        "category": "unique_technical",
        "rationale": "A unique theoretical framework central to the paper's methodology.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Natural Language Inference",
        "canonical": "Natural Language Inference",
        "aliases": [
          "NLI"
        ],
        "category": "specific_connectable",
        "rationale": "A key task in NLP that the paper focuses on, providing strong linkage to related works.",
        "novelty_score": 0.4,
        "connectivity_score": 0.85,
        "specificity_score": 0.75,
        "link_intent_score": 0.82
      },
      {
        "surface": "Zero-Shot Tests",
        "canonical": "Zero-Shot Learning",
        "aliases": [
          "Zero-Shot"
        ],
        "category": "specific_connectable",
        "rationale": "Highlights the paper's evaluation method, connecting to a growing area of interest.",
        "novelty_score": 0.5,
        "connectivity_score": 0.8,
        "specificity_score": 0.7,
        "link_intent_score": 0.79
      },
      {
        "surface": "Schematic Patterns",
        "canonical": "Schematic Pattern",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Represents a specific challenge in the paper, offering a unique linkage point.",
        "novelty_score": 0.65,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "pipeline",
      "synthetic",
      "benchmark"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Construction Grammars",
      "resolved_canonical": "Construction Grammar",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Natural Language Inference",
      "resolved_canonical": "Natural Language Inference",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.85,
        "specificity": 0.75,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Zero-Shot Tests",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.8,
        "specificity": 0.7,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Schematic Patterns",
      "resolved_canonical": "Schematic Pattern",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Evaluating CxG Generalisation in LLMs via Construction-Based NLI Fine Tuning

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16422.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2509.16422](https://arxiv.org/abs/2509.16422)

## 🔗 유사한 논문
- [[2025-09-23/Large Language Models Badly Generalize across Option Length, Problem Types, and Irrelevant Noun Replacements_20250923|Large Language Models Badly Generalize across Option Length, Problem Types, and Irrelevant Noun Replacements]] (87.5% similar)
- [[2025-09-22/It Depends_ Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge_20250922|It Depends: Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge]] (86.2% similar)
- [[2025-09-22/A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages_20250922|A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages]] (85.7% similar)
- [[2025-09-23/EquiBench_ Benchmarking Large Language Models' Reasoning about Program Semantics via Equivalence Checking_20250923|EquiBench: Benchmarking Large Language Models' Reasoning about Program Semantics via Equivalence Checking]] (85.4% similar)
- [[2025-09-19/Adding LLMs to the psycholinguistic norming toolbox_ A practical guide to getting the most out of human ratings_20250919|Adding LLMs to the psycholinguistic norming toolbox: A practical guide to getting the most out of human ratings]] (85.3% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Natural Language Inference|Natural Language Inference]], [[keywords/Zero-Shot Learning|Zero-Shot Learning]]
**⚡ Unique Technical**: [[keywords/Construction Grammar|Construction Grammar]], [[keywords/Schematic Pattern|Schematic Pattern]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.16422v1 Announce Type: new 
Abstract: We probe large language models' ability to learn deep form-meaning mappings as defined by construction grammars. We introduce the ConTest-NLI benchmark of 80k sentences covering eight English constructions from highly lexicalized to highly schematic. Our pipeline generates diverse synthetic NLI triples via templating and the application of a model-in-the-loop filter. This provides aspects of human validation to ensure challenge and label reliability. Zero-shot tests on leading LLMs reveal a 24% drop in accuracy between naturalistic (88%) and adversarial data (64%), with schematic patterns proving hardest. Fine-tuning on a subset of ConTest-NLI yields up to 9% improvement, yet our results highlight persistent abstraction gaps in current LLMs and offer a scalable framework for evaluating construction-informed learning.

## 📝 요약

이 논문은 대형 언어 모델(LLM)이 구성 문법에 정의된 깊은 형태-의미 매핑을 학습하는 능력을 탐구합니다. 연구진은 8개의 영어 구문을 포함하는 80,000개의 문장으로 구성된 ConTest-NLI 벤치마크를 소개합니다. 이 벤치마크는 템플릿과 모델 기반 필터를 사용하여 다양한 합성 NLI 삼중항을 생성하며, 인간 검증을 통해 도전과 라벨의 신뢰성을 보장합니다. 주요 LLM에 대한 제로샷 테스트 결과, 자연스러운 데이터(88%)와 적대적 데이터(64%) 간 정확도가 24% 감소하며, 특히 도식적 패턴이 가장 어려운 것으로 나타났습니다. ConTest-NLI의 일부에 대한 미세 조정은 최대 9%의 성능 향상을 가져왔지만, 여전히 현재 LLM의 추상화 격차가 존재함을 강조하고, 구문 기반 학습 평가를 위한 확장 가능한 프레임워크를 제공합니다.

## 🎯 주요 포인트

- 1. 대형 언어 모델의 깊은 형태-의미 매핑 학습 능력을 평가하기 위해 ConTest-NLI 벤치마크를 도입했습니다.
- 2. ConTest-NLI는 8개의 영어 구문을 포함한 80,000개의 문장으로 구성되어 있으며, 다양한 합성 NLI 트리플을 생성합니다.
- 3. 주요 LLM에 대한 제로샷 테스트 결과, 자연스러운 데이터(88%)와 적대적 데이터(64%) 간의 정확도 차이가 24%로 나타났습니다.
- 4. ConTest-NLI의 일부를 사용한 파인튜닝은 최대 9%의 성능 향상을 가져왔습니다.
- 5. 현재 LLM의 추상화 격차를 강조하며, 구문 정보를 반영한 학습 평가를 위한 확장 가능한 프레임워크를 제공합니다.


---

*Generated on 2025-09-24 03:12:09*