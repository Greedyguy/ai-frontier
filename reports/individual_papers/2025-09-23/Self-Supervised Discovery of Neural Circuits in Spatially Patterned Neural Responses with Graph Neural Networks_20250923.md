---
keywords:
  - Graph Neural Network
  - Self-supervised Learning
  - Neural Circuitry Inference
  - Ring Attractor Networks
category: cs.LG
publish_date: 2025-09-23
arxiv_id: 2509.17174
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T02:20:15.748901",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Graph Neural Network",
    "Self-supervised Learning",
    "Neural Circuitry Inference",
    "Ring Attractor Networks"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Graph Neural Network": 0.92,
    "Self-supervised Learning": 0.85,
    "Neural Circuitry Inference": 0.78,
    "Ring Attractor Networks": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Graph Neural Networks",
        "canonical": "Graph Neural Network",
        "aliases": [
          "GNN",
          "Graph Networks"
        ],
        "category": "specific_connectable",
        "rationale": "Central to the study, GNNs are used to model neural interactions and infer connectivity.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.85,
        "link_intent_score": 0.92
      },
      {
        "surface": "Self-supervised structure learning",
        "canonical": "Self-supervised Learning",
        "aliases": [
          "Self-supervised structure discovery"
        ],
        "category": "specific_connectable",
        "rationale": "The study employs self-supervised learning to infer neural circuitry, linking connectivity and dynamics.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.8,
        "link_intent_score": 0.85
      },
      {
        "surface": "Neural circuitry inference",
        "canonical": "Neural Circuitry Inference",
        "aliases": [
          "Neural circuit discovery"
        ],
        "category": "unique_technical",
        "rationale": "This is a unique application of GNNs in neuroscience, focusing on inferring neural circuits.",
        "novelty_score": 0.7,
        "connectivity_score": 0.75,
        "specificity_score": 0.9,
        "link_intent_score": 0.78
      },
      {
        "surface": "Ring attractor networks",
        "canonical": "Ring Attractor Networks",
        "aliases": [
          "Ring attractors"
        ],
        "category": "unique_technical",
        "rationale": "Used as a synthetic data source, these networks are pivotal for testing the model's inference capabilities.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.88,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "neural activity",
      "spiking activity",
      "real data"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Graph Neural Networks",
      "resolved_canonical": "Graph Neural Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.85,
        "link_intent": 0.92
      }
    },
    {
      "candidate_surface": "Self-supervised structure learning",
      "resolved_canonical": "Self-supervised Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.8,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Neural circuitry inference",
      "resolved_canonical": "Neural Circuitry Inference",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.75,
        "specificity": 0.9,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Ring attractor networks",
      "resolved_canonical": "Ring Attractor Networks",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.88,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# Self-Supervised Discovery of Neural Circuits in Spatially Patterned Neural Responses with Graph Neural Networks

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17174.pdf)
**Category**: cs.LG
**Published**: 2025-09-23
**ArXiv ID**: [2509.17174](https://arxiv.org/abs/2509.17174)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Neuro-inspired Ensemble-to-Ensemble Communication Primitives for Sparse and Efficient ANNs_20250923|Neuro-inspired Ensemble-to-Ensemble Communication Primitives for Sparse and Efficient ANNs]] (84.6% similar)
- [[2025-09-18/GraphTorque_ Torque-Driven Rewiring Graph Neural Network_20250918|GraphTorque: Torque-Driven Rewiring Graph Neural Network]] (84.3% similar)
- [[2025-09-22/GIN-Graph_ A Generative Interpretation Network for Model-Level Explanation of Graph Neural Networks_20250922|GIN-Graph: A Generative Interpretation Network for Model-Level Explanation of Graph Neural Networks]] (84.3% similar)
- [[2025-09-19/Brain-HGCN_ A Hyperbolic Graph Convolutional Network for Brain Functional Network Analysis_20250919|Brain-HGCN: A Hyperbolic Graph Convolutional Network for Brain Functional Network Analysis]] (83.8% similar)
- [[2025-09-22/Schreier-Coset Graph Propagation_20250922|Schreier-Coset Graph Propagation]] (83.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Graph Neural Network|Graph Neural Network]], [[keywords/Self-supervised Learning|Self-supervised Learning]]
**âš¡ Unique Technical**: [[keywords/Neural Circuitry Inference|Neural Circuitry Inference]], [[keywords/Ring Attractor Networks|Ring Attractor Networks]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17174v1 Announce Type: cross 
Abstract: Inferring synaptic connectivity from neural population activity is a fundamental challenge in computational neuroscience, complicated by partial observability and mismatches between inference models and true circuit dynamics. In this study, we propose a graph-based neural inference model that simultaneously predicts neural activity and infers latent connectivity by modeling neurons as interacting nodes in a graph. The architecture features two distinct modules: one for learning structural connectivity and another for predicting future spiking activity via a graph neural network (GNN). Our model accommodates unobserved neurons through auxiliary nodes, allowing for inference in partially observed circuits. We evaluate this approach using synthetic data from ring attractor networks and real spike recordings from head direction cells in mice. Across a wide range of conditions, including varying recurrent connectivity, external inputs, and incomplete observations, our model consistently outperforms standard baselines, resolving spurious correlations more effectively and recovering accurate weight profiles. When applied to real data, the inferred connectivity aligns with theoretical predictions of continuous attractor models. These results highlight the potential of GNN-based models to infer latent neural circuitry through self-supervised structure learning, while leveraging the spike prediction task to flexibly link connectivity and dynamics across both simulated and biological neural systems.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” ì‹ ê²½ ì§‘ë‹¨ í™œë™ìœ¼ë¡œë¶€í„° ì‹œëƒ…ìŠ¤ ì—°ê²°ì„±ì„ ì¶”ë¡ í•˜ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ê·¸ë˜í”„ ê¸°ë°˜ ì‹ ê²½ ì¶”ë¡  ëª¨ë¸ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ë‰´ëŸ°ì„ ê·¸ë˜í”„ì˜ ìƒí˜¸ì‘ìš© ë…¸ë“œë¡œ ëª¨ë¸ë§í•˜ì—¬ ì‹ ê²½ í™œë™ì„ ì˜ˆì¸¡í•˜ê³  ì ì¬ì  ì—°ê²°ì„±ì„ ì¶”ë¡ í•©ë‹ˆë‹¤. ë‘ ê°œì˜ ëª¨ë“ˆë¡œ êµ¬ì„±ëœ ì´ ì•„í‚¤í…ì²˜ëŠ” êµ¬ì¡°ì  ì—°ê²°ì„±ì„ í•™ìŠµí•˜ê³  ê·¸ë˜í”„ ì‹ ê²½ë§(GNN)ì„ í†µí•´ ë¯¸ë˜ì˜ ìŠ¤íŒŒì´í¬ í™œë™ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤. ê´€ì¸¡ë˜ì§€ ì•Šì€ ë‰´ëŸ°ì€ ë³´ì¡° ë…¸ë“œë¥¼ í†µí•´ ì²˜ë¦¬í•˜ì—¬ ë¶€ë¶„ì ìœ¼ë¡œ ê´€ì¸¡ëœ íšŒë¡œì—ì„œë„ ì¶”ë¡ ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ë§ ì–´íŠ¸ë™í„° ë„¤íŠ¸ì›Œí¬ì˜ í•©ì„± ë°ì´í„°ì™€ ì¥ì˜ ë¨¸ë¦¬ ë°©í–¥ ì„¸í¬ì—ì„œ ì–»ì€ ì‹¤ì œ ìŠ¤íŒŒì´í¬ ê¸°ë¡ì„ ì‚¬ìš©í•˜ì—¬ í‰ê°€ë˜ì—ˆìœ¼ë©°, ë‹¤ì–‘í•œ ì¡°ê±´ì—ì„œ ê¸°ì¡´ì˜ ê¸°ì¤€ ëª¨ë¸ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. íŠ¹íˆ, ì˜ëª»ëœ ìƒê´€ê´€ê³„ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í•´ê²°í•˜ê³  ì •í™•í•œ ê°€ì¤‘ì¹˜ í”„ë¡œíŒŒì¼ì„ ë³µì›í•˜ëŠ” ë° ë›°ì–´ë‚¬ìŠµë‹ˆë‹¤. ì‹¤ì œ ë°ì´í„°ì— ì ìš©í–ˆì„ ë•Œ, ì¶”ë¡ ëœ ì—°ê²°ì„±ì€ ì´ë¡ ì  ì˜ˆì¸¡ê³¼ ì¼ì¹˜í–ˆìŠµë‹ˆë‹¤. ì´ ê²°ê³¼ëŠ” GNN ê¸°ë°˜ ëª¨ë¸ì´ ìê°€ ì§€ë„ êµ¬ì¡° í•™ìŠµì„ í†µí•´ ì ì¬ì  ì‹ ê²½ íšŒë¡œë¥¼ ì¶”ë¡ í•  ìˆ˜ ìˆëŠ” ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë³¸ ì—°êµ¬ëŠ” ê·¸ë˜í”„ ê¸°ë°˜ ì‹ ê²½ ì¶”ë¡  ëª¨ë¸ì„ ì œì•ˆí•˜ì—¬ ì‹ ê²½ í™œë™ì„ ì˜ˆì¸¡í•˜ê³  ì ì¬ì  ì—°ê²°ì„±ì„ ì¶”ë¡ í•©ë‹ˆë‹¤.
- 2. ëª¨ë¸ì€ êµ¬ì¡°ì  ì—°ê²°ì„±ì„ í•™ìŠµí•˜ëŠ” ëª¨ë“ˆê³¼ ê·¸ë˜í”„ ì‹ ê²½ë§(GNN)ì„ í†µí•œ ë¯¸ë˜ ìŠ¤íŒŒì´í¬ í™œë™ ì˜ˆì¸¡ ëª¨ë“ˆë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.
- 3. ë³´ì¡° ë…¸ë“œë¥¼ í†µí•´ ê´€ì°°ë˜ì§€ ì•Šì€ ë‰´ëŸ°ì„ ìˆ˜ìš©í•˜ì—¬ ë¶€ë¶„ì ìœ¼ë¡œ ê´€ì°°ëœ íšŒë¡œì—ì„œë„ ì¶”ë¡ ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
- 4. ë‹¤ì–‘í•œ ì¡°ê±´ì—ì„œ ëª¨ë¸ì€ í‘œì¤€ ê¸°ì¤€ì„ ëŠ¥ê°€í•˜ë©°, ì˜ëª»ëœ ìƒê´€ê´€ê³„ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í•´ê²°í•˜ê³  ì •í™•í•œ ê°€ì¤‘ì¹˜ í”„ë¡œíŒŒì¼ì„ ë³µì›í•©ë‹ˆë‹¤.
- 5. ì‹¤ì œ ë°ì´í„°ì— ì ìš© ì‹œ, ì¶”ë¡ ëœ ì—°ê²°ì„±ì€ ì—°ì† ì–´íŠ¸ë™í„° ëª¨ë¸ì˜ ì´ë¡ ì  ì˜ˆì¸¡ê³¼ ì¼ì¹˜í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 02:20:15*