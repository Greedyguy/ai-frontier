---
keywords:
  - Dataset Distillation
  - DD-Ranking
  - Soft Labels
  - Data Augmentation
  - Evaluation Metrics
category: cs.CV
publish_date: 2025-09-23
arxiv_id: 2505.13300
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T05:23:38.697601",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Dataset Distillation",
    "DD-Ranking",
    "Soft Labels",
    "Data Augmentation",
    "Evaluation Metrics"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Dataset Distillation": 0.85,
    "DD-Ranking": 0.88,
    "Soft Labels": 0.78,
    "Data Augmentation": 0.7,
    "Evaluation Metrics": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "dataset distillation",
        "canonical": "Dataset Distillation",
        "aliases": [
          "data distillation",
          "synthetic dataset creation"
        ],
        "category": "unique_technical",
        "rationale": "Dataset distillation is a key concept in the paper, central to its methodology and evaluation.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.82,
        "link_intent_score": 0.85
      },
      {
        "surface": "DD-Ranking",
        "canonical": "DD-Ranking",
        "aliases": [
          "distillation ranking",
          "dataset ranking"
        ],
        "category": "unique_technical",
        "rationale": "DD-Ranking is a novel evaluation framework proposed in the paper, crucial for understanding its contributions.",
        "novelty_score": 0.8,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.88
      },
      {
        "surface": "soft labels",
        "canonical": "Soft Labels",
        "aliases": [
          "soft targets",
          "probabilistic labels"
        ],
        "category": "specific_connectable",
        "rationale": "Soft labels are a significant technique in dataset distillation, enhancing the understanding of model training.",
        "novelty_score": 0.6,
        "connectivity_score": 0.72,
        "specificity_score": 0.7,
        "link_intent_score": 0.78
      },
      {
        "surface": "data augmentation",
        "canonical": "Data Augmentation",
        "aliases": [
          "augmentation techniques",
          "data enhancement"
        ],
        "category": "broad_technical",
        "rationale": "Data augmentation is a widely used technique in machine learning, relevant to the paper's context.",
        "novelty_score": 0.45,
        "connectivity_score": 0.85,
        "specificity_score": 0.6,
        "link_intent_score": 0.7
      },
      {
        "surface": "evaluation metrics",
        "canonical": "Evaluation Metrics",
        "aliases": [
          "performance metrics",
          "assessment criteria"
        ],
        "category": "specific_connectable",
        "rationale": "Evaluation metrics are crucial for assessing the effectiveness of dataset distillation methods.",
        "novelty_score": 0.55,
        "connectivity_score": 0.78,
        "specificity_score": 0.65,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "accuracy",
      "performance improvements"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "dataset distillation",
      "resolved_canonical": "Dataset Distillation",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.82,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "DD-Ranking",
      "resolved_canonical": "DD-Ranking",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "soft labels",
      "resolved_canonical": "Soft Labels",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.72,
        "specificity": 0.7,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "data augmentation",
      "resolved_canonical": "Data Augmentation",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.85,
        "specificity": 0.6,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "evaluation metrics",
      "resolved_canonical": "Evaluation Metrics",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.78,
        "specificity": 0.65,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# DD-Ranking: Rethinking the Evaluation of Dataset Distillation

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2505.13300.pdf)
**Category**: cs.CV
**Published**: 2025-09-23
**ArXiv ID**: [2505.13300](https://arxiv.org/abs/2505.13300)

## 🔗 유사한 논문
- [[2025-09-23/Rethinking Evaluation of Infrared Small Target Detection_20250923|Rethinking Evaluation of Infrared Small Target Detection]] (83.0% similar)
- [[2025-09-22/Efficient Multimodal Dataset Distillation via Generative Models_20250922|Efficient Multimodal Dataset Distillation via Generative Models]] (82.1% similar)
- [[2025-09-23/IPF-RDA_ An Information-Preserving Framework for Robust Data Augmentation_20250923|IPF-RDA: An Information-Preserving Framework for Robust Data Augmentation]] (80.8% similar)
- [[2025-09-23/D-REX_ A Benchmark for Detecting Deceptive Reasoning in Large Language Models_20250923|D-REX: A Benchmark for Detecting Deceptive Reasoning in Large Language Models]] (80.5% similar)
- [[2025-09-22/RMT-KD_ Random Matrix Theoretic Causal Knowledge Distillation_20250922|RMT-KD: Random Matrix Theoretic Causal Knowledge Distillation]] (80.2% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Data Augmentation|Data Augmentation]]
**🔗 Specific Connectable**: [[keywords/Soft Labels|Soft Labels]], [[keywords/Evaluation Metrics|Evaluation Metrics]]
**⚡ Unique Technical**: [[keywords/Dataset Distillation|Dataset Distillation]], [[keywords/DD-Ranking|DD-Ranking]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2505.13300v3 Announce Type: replace 
Abstract: In recent years, dataset distillation has provided a reliable solution for data compression, where models trained on the resulting smaller synthetic datasets achieve performance comparable to those trained on the original datasets. To further improve the performance of synthetic datasets, various training pipelines and optimization objectives have been proposed, greatly advancing the field of dataset distillation. Recent decoupled dataset distillation methods introduce soft labels and stronger data augmentation during the post-evaluation phase and scale dataset distillation up to larger datasets (e.g., ImageNet-1K). However, this raises a question: Is accuracy still a reliable metric to fairly evaluate dataset distillation methods? Our empirical findings suggest that the performance improvements of these methods often stem from additional techniques rather than the inherent quality of the images themselves, with even randomly sampled images achieving superior results. Such misaligned evaluation settings severely hinder the development of DD. Therefore, we propose DD-Ranking, a unified evaluation framework, along with new general evaluation metrics to uncover the true performance improvements achieved by different methods. By refocusing on the actual information enhancement of distilled datasets, DD-Ranking provides a more comprehensive and fair evaluation standard for future research advancements.

## 📝 요약

최근 데이터셋 증류는 데이터 압축의 신뢰할 수 있는 해결책으로, 작은 합성 데이터셋으로도 원본 데이터셋과 유사한 성능을 달성할 수 있습니다. 그러나 성능 향상이 추가 기법에 기인하는 경우가 많아 정확도가 데이터셋 증류 방법 평가에 적절한지 의문이 제기됩니다. 본 연구는 이러한 문제를 해결하기 위해 DD-Ranking이라는 통합 평가 프레임워크와 새로운 평가 지표를 제안합니다. 이는 증류된 데이터셋의 실제 정보 향상에 초점을 맞춰 공정한 평가 기준을 제공하며, 향후 연구 발전에 기여할 것입니다.

## 🎯 주요 포인트

- 1. 데이터셋 증류는 작은 합성 데이터셋으로도 원본 데이터셋과 유사한 성능을 달성할 수 있는 데이터 압축 솔루션을 제공한다.
- 2. 최근의 데이터셋 증류 방법은 소프트 레이블과 강력한 데이터 증강을 도입하여 대규모 데이터셋으로 확장하고 있다.
- 3. 기존의 정확도 기반 평가 방식은 데이터셋 증류 방법의 성능을 공정하게 평가하지 못할 수 있다.
- 4. DD-Ranking이라는 통합 평가 프레임워크와 새로운 평가 지표를 제안하여 데이터셋 증류 방법의 실제 성능 향상을 파악한다.
- 5. DD-Ranking은 증류된 데이터셋의 정보 향상에 초점을 맞추어 미래 연구 발전을 위한 공정한 평가 기준을 제공한다.


---

*Generated on 2025-09-24 05:23:38*