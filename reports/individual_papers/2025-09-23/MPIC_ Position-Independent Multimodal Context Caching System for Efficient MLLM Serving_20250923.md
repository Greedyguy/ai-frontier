---
keywords:
  - Multimodal Learning
  - Retrieval Augmented Generation
  - Position-Independent Caching
  - Multimodal Information Management
category: cs.LG
publish_date: 2025-09-23
arxiv_id: 2502.01960
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T02:37:29.277929",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multimodal Learning",
    "Retrieval Augmented Generation",
    "Position-Independent Caching",
    "Multimodal Information Management"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multimodal Learning": 0.8,
    "Retrieval Augmented Generation": 0.79,
    "Position-Independent Caching": 0.72,
    "Multimodal Information Management": 0.71
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multimodal Large Language Model",
        "canonical": "Multimodal Learning",
        "aliases": [
          "MLLM"
        ],
        "category": "specific_connectable",
        "rationale": "Connects to the growing field of integrating multiple data types in language models.",
        "novelty_score": 0.65,
        "connectivity_score": 0.85,
        "specificity_score": 0.78,
        "link_intent_score": 0.8
      },
      {
        "surface": "Retrieval-Augmented Generation",
        "canonical": "Retrieval Augmented Generation",
        "aliases": [
          "RAG"
        ],
        "category": "specific_connectable",
        "rationale": "Links to methods that enhance model outputs with external data retrieval.",
        "novelty_score": 0.6,
        "connectivity_score": 0.88,
        "specificity_score": 0.82,
        "link_intent_score": 0.79
      },
      {
        "surface": "Position-Independent Caching",
        "canonical": "Position-Independent Caching",
        "aliases": [
          "PIC"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel caching approach specific to this paper's methodology.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.72
      },
      {
        "surface": "Multimodal Information Management",
        "canonical": "Multimodal Information Management",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Describes a specific technique for handling diverse data types efficiently.",
        "novelty_score": 0.68,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.71
      }
    ],
    "ban_list_suggestions": [
      "context caching",
      "system-level challenges",
      "algorithm-level challenges"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multimodal Large Language Model",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.85,
        "specificity": 0.78,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Retrieval-Augmented Generation",
      "resolved_canonical": "Retrieval Augmented Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.88,
        "specificity": 0.82,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Position-Independent Caching",
      "resolved_canonical": "Position-Independent Caching",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "Multimodal Information Management",
      "resolved_canonical": "Multimodal Information Management",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.71
      }
    }
  ]
}
-->

# MPIC: Position-Independent Multimodal Context Caching System for Efficient MLLM Serving

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2502.01960.pdf)
**Category**: cs.LG
**Published**: 2025-09-23
**ArXiv ID**: [2502.01960](https://arxiv.org/abs/2502.01960)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/KVCompose_ Efficient Structured KV Cache Compression with Composite Tokens_20250922|KVCompose: Efficient Structured KV Cache Compression with Composite Tokens]] (85.8% similar)
- [[2025-09-23/PDTrim_ Targeted Pruning for Prefill-Decode Disaggregation in Inference_20250923|PDTrim: Targeted Pruning for Prefill-Decode Disaggregation in Inference]] (83.7% similar)
- [[2025-09-22/M-PACE_ Mother Child Framework for Multimodal Compliance_20250922|M-PACE: Mother Child Framework for Multimodal Compliance]] (83.5% similar)
- [[2025-09-19/A Multi-To-One Interview Paradigm for Efficient MLLM Evaluation_20250919|A Multi-To-One Interview Paradigm for Efficient MLLM Evaluation]] (83.2% similar)
- [[2025-09-22/MMAPG_ A Training-Free Framework for Multimodal Multi-hop Question Answering via Adaptive Planning Graphs_20250922|MMAPG: A Training-Free Framework for Multimodal Multi-hop Question Answering via Adaptive Planning Graphs]] (83.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]], [[keywords/Retrieval Augmented Generation|Retrieval Augmented Generation]]
**âš¡ Unique Technical**: [[keywords/Position-Independent Caching|Position-Independent Caching]], [[keywords/Multimodal Information Management|Multimodal Information Management]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2502.01960v2 Announce Type: replace 
Abstract: The context caching technique is employed to accelerate the Multimodal Large Language Model (MLLM) inference by prevailing serving platforms currently. However, this approach merely reuses the Key-Value (KV) cache of the initial sequence of prompt, resulting in full KV cache recomputation even if the prefix differs slightly. This becomes particularly inefficient in the context of interleaved text and images, as well as multimodal retrieval-augmented generation. This paper proposes position-independent caching as a more effective approach for multimodal information management. We have designed and implemented a caching system, named MPIC, to address both system-level and algorithm-level challenges. MPIC stores the KV cache on local disks when receiving multimodal data, and calculates and loads the KV cache in parallel during inference. To mitigate accuracy degradation, we have incorporated the integrated reuse and recompute mechanism within the system. The experimental results demonstrate that MPIC can achieve up to 54\% reduction in response time and 2$\times$ improvement in throughput compared to existing context caching systems, while maintaining negligible or no accuracy loss.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë©€í‹°ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(MLLM) ì¶”ë¡ ì„ ê°€ì†í™”í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ìºì‹± ì‹œìŠ¤í…œì¸ MPICë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë¬¸ë§¥ ìºì‹± ê¸°ë²•ì€ í”„ë¡¬í”„íŠ¸ì˜ ì´ˆê¸° ì‹œí€€ìŠ¤ì˜ í‚¤-ê°’(KV) ìºì‹œë§Œ ì¬ì‚¬ìš©í•˜ì—¬, í”„ë¦¬í”½ìŠ¤ê°€ ì•½ê°„ë§Œ ë‹¬ë¼ë„ ì „ì²´ KV ìºì‹œë¥¼ ë‹¤ì‹œ ê³„ì‚°í•´ì•¼ í•˜ëŠ” ë¹„íš¨ìœ¨ì„±ì´ ìˆì—ˆìŠµë‹ˆë‹¤. íŠ¹íˆ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ê°€ ì„ì¸ ê²½ìš°ë‚˜ ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰-ì¦ê°• ìƒì„±ì—ì„œ ë¹„íš¨ìœ¨ì ì…ë‹ˆë‹¤. MPICëŠ” ìœ„ì¹˜ì— ë…ë¦½ì ì¸ ìºì‹± ë°©ì‹ì„ í†µí•´ ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ë©°, ì‹œìŠ¤í…œ ë° ì•Œê³ ë¦¬ì¦˜ ìˆ˜ì¤€ì˜ ë„ì „ ê³¼ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤. MPICëŠ” ë©€í‹°ëª¨ë‹¬ ë°ì´í„°ë¥¼ ë°›ì„ ë•Œ ë¡œì»¬ ë””ìŠ¤í¬ì— KV ìºì‹œë¥¼ ì €ì¥í•˜ê³ , ì¶”ë¡  ì¤‘ ë³‘ë ¬ë¡œ ê³„ì‚° ë° ë¡œë“œë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, MPICëŠ” ê¸°ì¡´ ì‹œìŠ¤í…œ ëŒ€ë¹„ ì‘ë‹µ ì‹œê°„ì„ ìµœëŒ€ 54% ë‹¨ì¶•í•˜ê³  ì²˜ë¦¬ëŸ‰ì„ 2ë°° í–¥ìƒì‹œí‚¤ë©´ì„œë„ ì •í™•ë„ ì†ì‹¤ì´ ê±°ì˜ ì—†ìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ê¸°ì¡´ì˜ ë¬¸ë§¥ ìºì‹± ê¸°ë²•ì€ ì´ˆê¸° í”„ë¡¬í”„íŠ¸ì˜ í‚¤-ê°’(KV) ìºì‹œë§Œ ì¬ì‚¬ìš©í•˜ì—¬ í”„ë¦¬í”½ìŠ¤ê°€ ì•½ê°„ë§Œ ë‹¬ë¼ë„ ì „ì²´ KV ìºì‹œë¥¼ ë‹¤ì‹œ ê³„ì‚°í•´ì•¼ í•˜ëŠ” ë¹„íš¨ìœ¨ì„±ì„ ì´ˆë˜í•©ë‹ˆë‹¤.
- 2. ë³¸ ë…¼ë¬¸ì€ ìœ„ì¹˜ ë…ë¦½ì ì¸ ìºì‹±ì„ ì œì•ˆí•˜ì—¬ ë‹¤ì¤‘ ëª¨ë“œ ì •ë³´ ê´€ë¦¬ì˜ íš¨ìœ¨ì„±ì„ ë†’ì…ë‹ˆë‹¤.
- 3. ì œì•ˆëœ MPIC ì‹œìŠ¤í…œì€ ë©€í‹°ëª¨ë‹¬ ë°ì´í„°ë¥¼ ë°›ì„ ë•Œ ë¡œì»¬ ë””ìŠ¤í¬ì— KV ìºì‹œë¥¼ ì €ì¥í•˜ê³ , ì¶”ë¡  ì‹œ ë³‘ë ¬ë¡œ KV ìºì‹œë¥¼ ê³„ì‚° ë° ë¡œë“œí•©ë‹ˆë‹¤.
- 4. MPICëŠ” ê¸°ì¡´ ë¬¸ë§¥ ìºì‹± ì‹œìŠ¤í…œ ëŒ€ë¹„ ìµœëŒ€ 54%ì˜ ì‘ë‹µ ì‹œê°„ ê°ì†Œì™€ 2ë°°ì˜ ì²˜ë¦¬ëŸ‰ í–¥ìƒì„ ì´ë£¨ë©°, ì •í™•ë„ ì†ì‹¤ì€ ê±°ì˜ ì—†ìŠµë‹ˆë‹¤.
- 5. ì‹œìŠ¤í…œ ë‚´ í†µí•© ì¬ì‚¬ìš© ë° ì¬ê³„ì‚° ë©”ì»¤ë‹ˆì¦˜ì„ ë„ì…í•˜ì—¬ ì •í™•ë„ ì €í•˜ë¥¼ ì™„í™”í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 02:37:29*