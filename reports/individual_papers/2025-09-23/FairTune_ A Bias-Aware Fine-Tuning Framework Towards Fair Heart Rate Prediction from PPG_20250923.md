---
keywords:
  - Transformer
  - FairTune
  - Group Distributionally Robust Optimization
  - Adversarial Debiasing
  - Photoplethysmography
category: cs.LG
publish_date: 2025-09-23
arxiv_id: 2509.16491
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T01:37:26.090478",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Transformer",
    "FairTune",
    "Group Distributionally Robust Optimization",
    "Adversarial Debiasing",
    "Photoplethysmography"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Transformer": 0.85,
    "FairTune": 0.8,
    "Group Distributionally Robust Optimization": 0.78,
    "Adversarial Debiasing": 0.77,
    "Photoplethysmography": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Transformer-based foundation model",
        "canonical": "Transformer",
        "aliases": [
          "Transformer model"
        ],
        "category": "broad_technical",
        "rationale": "Transformers are a fundamental architecture in deep learning, crucial for linking with other models and techniques.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "FairTune",
        "canonical": "FairTune",
        "aliases": [
          "bias-aware fine-tuning framework"
        ],
        "category": "unique_technical",
        "rationale": "FairTune is a novel framework specifically designed for bias mitigation in heart rate prediction models.",
        "novelty_score": 0.85,
        "connectivity_score": 0.7,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "Group Distributionally Robust Optimization",
        "canonical": "Group Distributionally Robust Optimization",
        "aliases": [
          "GroupDRO"
        ],
        "category": "specific_connectable",
        "rationale": "GroupDRO is a specific technique for fairness optimization, linking to broader discussions on robust optimization methods.",
        "novelty_score": 0.6,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Adversarial debiasing",
        "canonical": "Adversarial Debiasing",
        "aliases": [
          "ADV"
        ],
        "category": "specific_connectable",
        "rationale": "Adversarial debiasing is a key method for reducing bias in models, connecting to adversarial learning techniques.",
        "novelty_score": 0.55,
        "connectivity_score": 0.78,
        "specificity_score": 0.75,
        "link_intent_score": 0.77
      },
      {
        "surface": "Photoplethysmography signals",
        "canonical": "Photoplethysmography",
        "aliases": [
          "PPG signals"
        ],
        "category": "specific_connectable",
        "rationale": "Photoplethysmography is central to the study, linking to other physiological signal processing research.",
        "novelty_score": 0.4,
        "connectivity_score": 0.8,
        "specificity_score": 0.85,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "fine-tuning",
      "mean absolute error",
      "demographic fairness"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Transformer-based foundation model",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "FairTune",
      "resolved_canonical": "FairTune",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.7,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Group Distributionally Robust Optimization",
      "resolved_canonical": "Group Distributionally Robust Optimization",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Adversarial debiasing",
      "resolved_canonical": "Adversarial Debiasing",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.78,
        "specificity": 0.75,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Photoplethysmography signals",
      "resolved_canonical": "Photoplethysmography",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.8,
        "specificity": 0.85,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# FairTune: A Bias-Aware Fine-Tuning Framework Towards Fair Heart Rate Prediction from PPG

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16491.pdf)
**Category**: cs.LG
**Published**: 2025-09-23
**ArXiv ID**: [2509.16491](https://arxiv.org/abs/2509.16491)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Estimating Clinical Lab Test Result Trajectories from PPG using Physiological Foundation Model and Patient-Aware State Space Model -- a UNIPHY+ Approach_20250923|Estimating Clinical Lab Test Result Trajectories from PPG using Physiological Foundation Model and Patient-Aware State Space Model -- a UNIPHY+ Approach]] (82.3% similar)
- [[2025-09-17/APFEx_ Adaptive Pareto Front Explorer for Intersectional Fairness_20250917|APFEx: Adaptive Pareto Front Explorer for Intersectional Fairness]] (81.4% similar)
- [[2025-09-22/Deep learning and abstractive summarisation for radiological reports_ an empirical study for adapting the PEGASUS models' family with scarce data_20250922|Deep learning and abstractive summarisation for radiological reports: an empirical study for adapting the PEGASUS models' family with scarce data]] (81.3% similar)
- [[2025-09-22/Where Fact Ends and Fairness Begins_ Redefining AI Bias Evaluation through Cognitive Biases_20250922|Where Fact Ends and Fairness Begins: Redefining AI Bias Evaluation through Cognitive Biases]] (81.1% similar)
- [[2025-09-22/Mind the Gap_ Data Rewriting for Stable Off-Policy Supervised Fine-Tuning_20250922|Mind the Gap: Data Rewriting for Stable Off-Policy Supervised Fine-Tuning]] (81.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Transformer|Transformer]]
**ğŸ”— Specific Connectable**: [[keywords/Group Distributionally Robust Optimization|Group Distributionally Robust Optimization]], [[keywords/Adversarial Debiasing|Adversarial Debiasing]], [[keywords/Photoplethysmography|Photoplethysmography]]
**âš¡ Unique Technical**: [[keywords/FairTune|FairTune]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16491v1 Announce Type: new 
Abstract: Foundation models pretrained on physiological data such as photoplethysmography (PPG) signals are increasingly used to improve heart rate (HR) prediction across diverse settings. Fine-tuning these models for local deployment is often seen as a practical and scalable strategy. However, its impact on demographic fairness particularly under domain shifts remains underexplored. We fine-tune PPG-GPT a transformer-based foundation model pretrained on intensive care unit (ICU) data across three heterogeneous datasets (ICU, wearable, smartphone) and systematically evaluate the effects on HR prediction accuracy and gender fairness. While fine-tuning substantially reduces mean absolute error (up to 80%), it can simultaneously widen fairness gaps, especially in larger models and under significant distributional characteristics shifts. To address this, we introduce FairTune, a bias-aware fine-tuning framework in which we benchmark three mitigation strategies: class weighting based on inverse group frequency (IF), Group Distributionally Robust Optimization (GroupDRO), and adversarial debiasing (ADV). We find that IF and GroupDRO significantly reduce fairness gaps without compromising accuracy, with effectiveness varying by deployment domain. Representation analyses further reveal that mitigation techniques reshape internal embeddings to reduce demographic clustering. Our findings highlight that fairness does not emerge as a natural byproduct of fine-tuning and that explicit mitigation is essential for equitable deployment of physiological foundation models.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ê´‘í˜ˆë¥˜ì¸¡ì •(PPG) ì‹ í˜¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹¬ë°•ìˆ˜ ì˜ˆì¸¡ì„ ê°œì„ í•˜ê¸° ìœ„í•´ ì‚¬ì „ í•™ìŠµëœ ê¸°ì´ˆ ëª¨ë¸ì˜ ë¯¸ì„¸ ì¡°ì •ì´ ì¸êµ¬í†µê³„í•™ì  ê³µì •ì„±ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ íƒêµ¬í•©ë‹ˆë‹¤. ì—°êµ¬ì—ì„œëŠ” ICU, ì›¨ì–´ëŸ¬ë¸”, ìŠ¤ë§ˆíŠ¸í° ë°ì´í„°ì…‹ì—ì„œ PPG-GPT ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ì—¬ ì‹¬ë°•ìˆ˜ ì˜ˆì¸¡ ì •í™•ë„ì™€ ì„±ë³„ ê³µì •ì„±ì„ í‰ê°€í–ˆìŠµë‹ˆë‹¤. ë¯¸ì„¸ ì¡°ì •ì€ í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ë¥¼ ìµœëŒ€ 80%ê¹Œì§€ ì¤„ì˜€ì§€ë§Œ, ê³µì •ì„± ê²©ì°¨ë¥¼ í™•ëŒ€í•  ìˆ˜ ìˆìŒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ FairTuneì´ë¼ëŠ” í¸í–¥ ì¸ì‹ ë¯¸ì„¸ ì¡°ì • í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•˜ê³ , ì—­ ê·¸ë£¹ ë¹ˆë„ ê¸°ë°˜ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜(IF), ê·¸ë£¹ ë¶„í¬ì  ê°•ê±´ ìµœì í™”(GroupDRO), ì ëŒ€ì  ë””ë°”ì´ì‹±(ADV) ë“± ì„¸ ê°€ì§€ ì™„í™” ì „ëµì„ ë¹„êµí–ˆìŠµë‹ˆë‹¤. IFì™€ GroupDROëŠ” ì •í™•ì„±ì„ ìœ ì§€í•˜ë©´ì„œ ê³µì •ì„± ê²©ì°¨ë¥¼ ì¤„ì´ëŠ” ë° íš¨ê³¼ì ì´ì—ˆìœ¼ë©°, ë°°í¬ ë„ë©”ì¸ì— ë”°ë¼ íš¨ê³¼ê°€ ë‹¬ë¼ì¡ŒìŠµë‹ˆë‹¤. ì—°êµ¬ ê²°ê³¼ëŠ” ê³µì •ì„±ì´ ë¯¸ì„¸ ì¡°ì •ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ê²°ê³¼ë¡œ ë‚˜íƒ€ë‚˜ì§€ ì•Šìœ¼ë©°, ëª…ì‹œì ì¸ ì™„í™”ê°€ í•„ìš”í•¨ì„ ê°•ì¡°í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. PPG ì‹ í˜¸ì™€ ê°™ì€ ìƒë¦¬í•™ì  ë°ì´í„°ë¡œ ì‚¬ì „ í•™ìŠµëœ ê¸°ì´ˆ ëª¨ë¸ì€ ë‹¤ì–‘í•œ í™˜ê²½ì—ì„œ ì‹¬ë°•ìˆ˜ ì˜ˆì¸¡ì„ ê°œì„ í•˜ëŠ” ë° ì‚¬ìš©ëœë‹¤.
- 2. ì„¸ ê°€ì§€ ì´ì§ˆì ì¸ ë°ì´í„°ì…‹ì—ì„œ PPG-GPT ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ì—¬ ì‹¬ë°•ìˆ˜ ì˜ˆì¸¡ ì •í™•ì„±ê³¼ ì„±ë³„ ê³µì •ì„±ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ í‰ê°€í•˜ì˜€ë‹¤.
- 3. ë¯¸ì„¸ ì¡°ì •ì€ í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ë¥¼ ìµœëŒ€ 80%ê¹Œì§€ ì¤„ì¼ ìˆ˜ ìˆì§€ë§Œ, ê³µì •ì„± ê²©ì°¨ë¥¼ í™•ëŒ€í•  ìˆ˜ ìˆë‹¤.
- 4. FairTuneì´ë¼ëŠ” í¸í–¥ ì¸ì‹ ë¯¸ì„¸ ì¡°ì • í”„ë ˆì„ì›Œí¬ë¥¼ ë„ì…í•˜ì—¬ ì„¸ ê°€ì§€ ì™„í™” ì „ëµì„ ë²¤ì¹˜ë§ˆí‚¹í•˜ì˜€ë‹¤.
- 5. IFì™€ GroupDROëŠ” ì •í™•ì„±ì„ ìœ ì§€í•˜ë©´ì„œ ê³µì •ì„± ê²©ì°¨ë¥¼ í¬ê²Œ ì¤„ì´ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ë‹¤.


---

*Generated on 2025-09-24 01:37:26*