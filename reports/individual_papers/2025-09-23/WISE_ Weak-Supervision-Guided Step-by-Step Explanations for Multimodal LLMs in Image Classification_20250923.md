---
keywords:
  - Multimodal Learning
  - Multimodal Chain-of-Thought
  - Concept Bottleneck Models
  - Weak-supervision-guided Explanation
  - Fine-grained Visual Understanding
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2509.17740
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:41:58.583309",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multimodal Learning",
    "Multimodal Chain-of-Thought",
    "Concept Bottleneck Models",
    "Weak-supervision-guided Explanation",
    "Fine-grained Visual Understanding"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multimodal Learning": 0.8,
    "Multimodal Chain-of-Thought": 0.78,
    "Concept Bottleneck Models": 0.77,
    "Weak-supervision-guided Explanation": 0.75,
    "Fine-grained Visual Understanding": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multimodal Large Language Models",
        "canonical": "Multimodal Learning",
        "aliases": [
          "MLLMs"
        ],
        "category": "specific_connectable",
        "rationale": "Links to the trending concept of integrating multiple modalities in learning systems.",
        "novelty_score": 0.45,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Multimodal Chain-of-Thought",
        "canonical": "Multimodal Chain-of-Thought",
        "aliases": [
          "MCoT"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel approach to reasoning in multimodal contexts, enhancing interpretability.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Concept Bottleneck Models",
        "canonical": "Concept Bottleneck Models",
        "aliases": [
          "CBMs"
        ],
        "category": "unique_technical",
        "rationale": "Represents a specific model type crucial for concept-based reasoning in image classification.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      },
      {
        "surface": "Weak-supervision-guided Step-by-step Explanation",
        "canonical": "Weak-supervision-guided Explanation",
        "aliases": [
          "WISE"
        ],
        "category": "unique_technical",
        "rationale": "Describes a new method for improving interpretability in image classification tasks.",
        "novelty_score": 0.8,
        "connectivity_score": 0.55,
        "specificity_score": 0.82,
        "link_intent_score": 0.75
      },
      {
        "surface": "Fine-grained Visual Understanding",
        "canonical": "Fine-grained Visual Understanding",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Focuses on detailed analysis of visual data, relevant to advancements in computer vision.",
        "novelty_score": 0.6,
        "connectivity_score": 0.7,
        "specificity_score": 0.78,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "interpretability",
      "accuracy"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multimodal Large Language Models",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Multimodal Chain-of-Thought",
      "resolved_canonical": "Multimodal Chain-of-Thought",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Concept Bottleneck Models",
      "resolved_canonical": "Concept Bottleneck Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Weak-supervision-guided Step-by-step Explanation",
      "resolved_canonical": "Weak-supervision-guided Explanation",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.55,
        "specificity": 0.82,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Fine-grained Visual Understanding",
      "resolved_canonical": "Fine-grained Visual Understanding",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.7,
        "specificity": 0.78,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# WISE: Weak-Supervision-Guided Step-by-Step Explanations for Multimodal LLMs in Image Classification

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17740.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2509.17740](https://arxiv.org/abs/2509.17740)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Perception-R1_ Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward_20250922|Perception-R1: Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward]] (86.2% similar)
- [[2025-09-18/Uni-cot_ Towards Unified Chain-of-Thought Reasoning Across Text and Vision_20250918|Uni-cot: Towards Unified Chain-of-Thought Reasoning Across Text and Vision]] (85.3% similar)
- [[2025-09-23/Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates_20250923|Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates]] (85.0% similar)
- [[2025-09-23/MCP_ A Control-Theoretic Orchestration Framework for Synergistic Efficiency and Interpretability in Multimodal Large Language Models_20250923|MCP: A Control-Theoretic Orchestration Framework for Synergistic Efficiency and Interpretability in Multimodal Large Language Models]] (84.5% similar)
- [[2025-09-22/Cache-of-Thought_ Master-Apprentice Framework for Cost-Effective Vision Language Model Reasoning_20250922|Cache-of-Thought: Master-Apprentice Framework for Cost-Effective Vision Language Model Reasoning]] (84.4% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]], [[keywords/Fine-grained Visual Understanding|Fine-grained Visual Understanding]]
**âš¡ Unique Technical**: [[keywords/Multimodal Chain-of-Thought|Multimodal Chain-of-Thought]], [[keywords/Concept Bottleneck Models|Concept Bottleneck Models]], [[keywords/Weak-supervision-guided Explanation|Weak-supervision-guided Explanation]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17740v1 Announce Type: cross 
Abstract: Multimodal Large Language Models (MLLMs) have shown promise in visual-textual reasoning, with Multimodal Chain-of-Thought (MCoT) prompting significantly enhancing interpretability. However, existing MCoT methods rely on rationale-rich datasets and largely focus on inter-object reasoning, overlooking the intra-object understanding crucial for image classification. To address this gap, we propose WISE, a Weak-supervision-guided Step-by-step Explanation method that augments any image classification dataset with MCoTs by reformulating the concept-based representations from Concept Bottleneck Models (CBMs) into concise, interpretable reasoning chains under weak supervision. Experiments across ten datasets show that our generated MCoTs not only improve interpretability by 37% but also lead to gains in classification accuracy when used to fine-tune MLLMs. Our work bridges concept-based interpretability and generative MCoT reasoning, providing a generalizable framework for enhancing MLLMs in fine-grained visual understanding.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì´ë¯¸ì§€ ë¶„ë¥˜ì—ì„œ ì¤‘ìš”í•œ ê°ì²´ ë‚´ë¶€ ì´í•´ë¥¼ ë‹¤ë£¨ê¸° ìœ„í•´ WISEë¼ëŠ” ë°©ë²•ë¡ ì„ ì œì•ˆí•©ë‹ˆë‹¤. WISEëŠ” ì•½í•œ ì§€ë„ í•™ìŠµì„ í†µí•´ ê°œë… ë³‘ëª© ëª¨ë¸(CBM)ì˜ ê°œë… ê¸°ë°˜ í‘œí˜„ì„ ê°„ê²°í•˜ê³  í•´ì„ ê°€ëŠ¥í•œ ì¶”ë¡  ì²´ì¸ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ MCoTë¥¼ ìƒì„±í•©ë‹ˆë‹¤. 10ê°œì˜ ë°ì´í„°ì…‹ ì‹¤í—˜ ê²°ê³¼, ì´ ë°©ë²•ì€ í•´ì„ ê°€ëŠ¥ì„±ì„ 37% í–¥ìƒì‹œí‚¤ê³ , MLLMì˜ ë¶„ë¥˜ ì •í™•ë„ë¥¼ ë†’ì´ëŠ” ë° ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ê°œë… ê¸°ë°˜ í•´ì„ ê°€ëŠ¥ì„±ê³¼ ìƒì„±ì  MCoT ì¶”ë¡ ì„ ì—°ê²°í•˜ì—¬ MLLMì˜ ì„¸ë°€í•œ ì‹œê°ì  ì´í•´ë¥¼ ê°•í™”í•˜ëŠ” ì¼ë°˜í™” ê°€ëŠ¥í•œ í”„ë ˆì„ì›Œí¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë‹¤ì¤‘ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(MLLMs)ì€ ì‹œê°-í…ìŠ¤íŠ¸ ì¶”ë¡ ì—ì„œ ìœ ë§í•œ ì„±ê³¼ë¥¼ ë³´ì´ê³  ìˆìœ¼ë©°, MCoT(Multimodal Chain-of-Thought) í”„ë¡¬í”„íŠ¸ëŠ” í•´ì„ ê°€ëŠ¥ì„±ì„ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
- 2. ê¸°ì¡´ MCoT ë°©ë²•ì€ ì£¼ë¡œ ê°ì²´ ê°„ ì¶”ë¡ ì— ì´ˆì ì„ ë§ì¶”ê³  ìˆì–´ ì´ë¯¸ì§€ ë¶„ë¥˜ì— ì¤‘ìš”í•œ ê°ì²´ ë‚´ ì´í•´ë¥¼ ê°„ê³¼í•˜ê³  ìˆìŠµë‹ˆë‹¤.
- 3. WISEëŠ” ì•½ì§€ë„ ê¸°ë°˜ ë‹¨ê³„ë³„ ì„¤ëª… ë°©ë²•ìœ¼ë¡œ, ì´ë¯¸ì§€ ë¶„ë¥˜ ë°ì´í„°ì…‹ì„ MCoTë¡œ ë³´ê°•í•˜ì—¬ í•´ì„ ê°€ëŠ¥ì„±ì„ 37% í–¥ìƒì‹œí‚µë‹ˆë‹¤.
- 4. WISEëŠ” ê°œë… ë³‘ëª© ëª¨ë¸(CBMs)ì˜ ê°œë… ê¸°ë°˜ í‘œí˜„ì„ ì•½ì§€ë„ í•˜ì— ê°„ê²°í•˜ê³  í•´ì„ ê°€ëŠ¥í•œ ì¶”ë¡  ì²´ì¸ìœ¼ë¡œ ì¬êµ¬ì„±í•©ë‹ˆë‹¤.
- 5. ìš°ë¦¬ì˜ ì—°êµ¬ëŠ” ê°œë… ê¸°ë°˜ í•´ì„ ê°€ëŠ¥ì„±ê³¼ ìƒì„±ì  MCoT ì¶”ë¡ ì„ ì—°ê²°í•˜ì—¬ MLLMsì˜ ì„¸ë°€í•œ ì‹œê°ì  ì´í•´ë¥¼ í–¥ìƒì‹œí‚¤ëŠ” ì¼ë°˜í™” ê°€ëŠ¥í•œ í”„ë ˆì„ì›Œí¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 03:41:58*