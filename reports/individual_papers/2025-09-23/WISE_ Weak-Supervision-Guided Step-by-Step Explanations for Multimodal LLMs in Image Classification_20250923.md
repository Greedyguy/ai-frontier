---
keywords:
  - Multimodal Learning
  - Multimodal Chain-of-Thought
  - Concept Bottleneck Models
  - Weak-supervision-guided Explanation
  - Fine-grained Visual Understanding
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2509.17740
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:41:58.583309",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multimodal Learning",
    "Multimodal Chain-of-Thought",
    "Concept Bottleneck Models",
    "Weak-supervision-guided Explanation",
    "Fine-grained Visual Understanding"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multimodal Learning": 0.8,
    "Multimodal Chain-of-Thought": 0.78,
    "Concept Bottleneck Models": 0.77,
    "Weak-supervision-guided Explanation": 0.75,
    "Fine-grained Visual Understanding": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multimodal Large Language Models",
        "canonical": "Multimodal Learning",
        "aliases": [
          "MLLMs"
        ],
        "category": "specific_connectable",
        "rationale": "Links to the trending concept of integrating multiple modalities in learning systems.",
        "novelty_score": 0.45,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Multimodal Chain-of-Thought",
        "canonical": "Multimodal Chain-of-Thought",
        "aliases": [
          "MCoT"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel approach to reasoning in multimodal contexts, enhancing interpretability.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Concept Bottleneck Models",
        "canonical": "Concept Bottleneck Models",
        "aliases": [
          "CBMs"
        ],
        "category": "unique_technical",
        "rationale": "Represents a specific model type crucial for concept-based reasoning in image classification.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      },
      {
        "surface": "Weak-supervision-guided Step-by-step Explanation",
        "canonical": "Weak-supervision-guided Explanation",
        "aliases": [
          "WISE"
        ],
        "category": "unique_technical",
        "rationale": "Describes a new method for improving interpretability in image classification tasks.",
        "novelty_score": 0.8,
        "connectivity_score": 0.55,
        "specificity_score": 0.82,
        "link_intent_score": 0.75
      },
      {
        "surface": "Fine-grained Visual Understanding",
        "canonical": "Fine-grained Visual Understanding",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Focuses on detailed analysis of visual data, relevant to advancements in computer vision.",
        "novelty_score": 0.6,
        "connectivity_score": 0.7,
        "specificity_score": 0.78,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "interpretability",
      "accuracy"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multimodal Large Language Models",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Multimodal Chain-of-Thought",
      "resolved_canonical": "Multimodal Chain-of-Thought",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Concept Bottleneck Models",
      "resolved_canonical": "Concept Bottleneck Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Weak-supervision-guided Step-by-step Explanation",
      "resolved_canonical": "Weak-supervision-guided Explanation",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.55,
        "specificity": 0.82,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Fine-grained Visual Understanding",
      "resolved_canonical": "Fine-grained Visual Understanding",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.7,
        "specificity": 0.78,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# WISE: Weak-Supervision-Guided Step-by-Step Explanations for Multimodal LLMs in Image Classification

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17740.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2509.17740](https://arxiv.org/abs/2509.17740)

## 🔗 유사한 논문
- [[2025-09-22/Perception-R1_ Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward_20250922|Perception-R1: Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward]] (86.2% similar)
- [[2025-09-18/Uni-cot_ Towards Unified Chain-of-Thought Reasoning Across Text and Vision_20250918|Uni-cot: Towards Unified Chain-of-Thought Reasoning Across Text and Vision]] (85.3% similar)
- [[2025-09-23/Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates_20250923|Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates]] (85.0% similar)
- [[2025-09-23/MCP_ A Control-Theoretic Orchestration Framework for Synergistic Efficiency and Interpretability in Multimodal Large Language Models_20250923|MCP: A Control-Theoretic Orchestration Framework for Synergistic Efficiency and Interpretability in Multimodal Large Language Models]] (84.5% similar)
- [[2025-09-22/Cache-of-Thought_ Master-Apprentice Framework for Cost-Effective Vision Language Model Reasoning_20250922|Cache-of-Thought: Master-Apprentice Framework for Cost-Effective Vision Language Model Reasoning]] (84.4% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]], [[keywords/Fine-grained Visual Understanding|Fine-grained Visual Understanding]]
**⚡ Unique Technical**: [[keywords/Multimodal Chain-of-Thought|Multimodal Chain-of-Thought]], [[keywords/Concept Bottleneck Models|Concept Bottleneck Models]], [[keywords/Weak-supervision-guided Explanation|Weak-supervision-guided Explanation]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.17740v1 Announce Type: cross 
Abstract: Multimodal Large Language Models (MLLMs) have shown promise in visual-textual reasoning, with Multimodal Chain-of-Thought (MCoT) prompting significantly enhancing interpretability. However, existing MCoT methods rely on rationale-rich datasets and largely focus on inter-object reasoning, overlooking the intra-object understanding crucial for image classification. To address this gap, we propose WISE, a Weak-supervision-guided Step-by-step Explanation method that augments any image classification dataset with MCoTs by reformulating the concept-based representations from Concept Bottleneck Models (CBMs) into concise, interpretable reasoning chains under weak supervision. Experiments across ten datasets show that our generated MCoTs not only improve interpretability by 37% but also lead to gains in classification accuracy when used to fine-tune MLLMs. Our work bridges concept-based interpretability and generative MCoT reasoning, providing a generalizable framework for enhancing MLLMs in fine-grained visual understanding.

## 📝 요약

이 논문은 이미지 분류에서 중요한 객체 내부 이해를 다루기 위해 WISE라는 방법론을 제안합니다. WISE는 약한 지도 학습을 통해 개념 병목 모델(CBM)의 개념 기반 표현을 간결하고 해석 가능한 추론 체인으로 변환하여 MCoT를 생성합니다. 10개의 데이터셋 실험 결과, 이 방법은 해석 가능성을 37% 향상시키고, MLLM의 분류 정확도를 높이는 데 기여했습니다. 이 연구는 개념 기반 해석 가능성과 생성적 MCoT 추론을 연결하여 MLLM의 세밀한 시각적 이해를 강화하는 일반화 가능한 프레임워크를 제공합니다.

## 🎯 주요 포인트

- 1. 다중모달 대형 언어 모델(MLLMs)은 시각-텍스트 추론에서 유망한 성과를 보이고 있으며, MCoT(Multimodal Chain-of-Thought) 프롬프트는 해석 가능성을 크게 향상시킵니다.
- 2. 기존 MCoT 방법은 주로 객체 간 추론에 초점을 맞추고 있어 이미지 분류에 중요한 객체 내 이해를 간과하고 있습니다.
- 3. WISE는 약지도 기반 단계별 설명 방법으로, 이미지 분류 데이터셋을 MCoT로 보강하여 해석 가능성을 37% 향상시킵니다.
- 4. WISE는 개념 병목 모델(CBMs)의 개념 기반 표현을 약지도 하에 간결하고 해석 가능한 추론 체인으로 재구성합니다.
- 5. 우리의 연구는 개념 기반 해석 가능성과 생성적 MCoT 추론을 연결하여 MLLMs의 세밀한 시각적 이해를 향상시키는 일반화 가능한 프레임워크를 제공합니다.


---

*Generated on 2025-09-24 03:41:58*