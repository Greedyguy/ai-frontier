---
keywords:
  - Large Language Model
  - RephQA
  - Readability Enhancement
  - Group Relative Policy Optimization
category: cs.CL
publish_date: 2025-09-23
arxiv_id: 2509.16360
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T03:11:05.733141",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "RephQA",
    "Readability Enhancement",
    "Group Relative Policy Optimization"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "RephQA": 0.78,
    "Readability Enhancement": 0.81,
    "Group Relative Policy Optimization": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "This is a foundational concept in the paper, linking it to the broader context of AI and NLP.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "RephQA",
        "canonical": "RephQA",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Introduces a new benchmark specific to the paper's focus on readability in public health QA.",
        "novelty_score": 0.92,
        "connectivity_score": 0.55,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "readability-enhancing strategies",
        "canonical": "Readability Enhancement",
        "aliases": [
          "readability strategies"
        ],
        "category": "specific_connectable",
        "rationale": "Key concept for improving LLM outputs, relevant to practical applications in NLP.",
        "novelty_score": 0.68,
        "connectivity_score": 0.72,
        "specificity_score": 0.77,
        "link_intent_score": 0.81
      },
      {
        "surface": "Group Relative Policy Optimization",
        "canonical": "Group Relative Policy Optimization",
        "aliases": [
          "GRPO"
        ],
        "category": "unique_technical",
        "rationale": "A novel strategy discussed in the paper to enhance readability, contributing to specific technical discourse.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "public health",
      "question answering",
      "evaluation"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "RephQA",
      "resolved_canonical": "RephQA",
      "decision": "linked",
      "scores": {
        "novelty": 0.92,
        "connectivity": 0.55,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "readability-enhancing strategies",
      "resolved_canonical": "Readability Enhancement",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.72,
        "specificity": 0.77,
        "link_intent": 0.81
      }
    },
    {
      "candidate_surface": "Group Relative Policy Optimization",
      "resolved_canonical": "Group Relative Policy Optimization",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# RephQA: Evaluating Readability of Large Language Models in Public Health Question Answering

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16360.pdf)
**Category**: cs.CL
**Published**: 2025-09-23
**ArXiv ID**: [2509.16360](https://arxiv.org/abs/2509.16360)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Large Language Models Meet Knowledge Graphs for Question Answering_ Synthesis and Opportunities_20250923|Large Language Models Meet Knowledge Graphs for Question Answering: Synthesis and Opportunities]] (86.3% similar)
- [[2025-09-23/SparseDoctor_ Towards Efficient Chat Doctor with Mixture of Experts Enhanced Large Language Models_20250923|SparseDoctor: Towards Efficient Chat Doctor with Mixture of Experts Enhanced Large Language Models]] (86.2% similar)
- [[2025-09-23/A State-Update Prompting Strategy for Efficient and Robust Multi-turn Dialogue_20250923|A State-Update Prompting Strategy for Efficient and Robust Multi-turn Dialogue]] (85.2% similar)
- [[2025-09-23/From Scores to Steps_ Diagnosing and Improving LLM Performance in Evidence-Based Medical Calculations_20250923|From Scores to Steps: Diagnosing and Improving LLM Performance in Evidence-Based Medical Calculations]] (85.1% similar)
- [[2025-09-22/EHR-MCP_ Real-world Evaluation of Clinical Information Retrieval by Large Language Models via Model Context Protocol_20250922|EHR-MCP: Real-world Evaluation of Clinical Information Retrieval by Large Language Models via Model Context Protocol]] (85.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Readability Enhancement|Readability Enhancement]]
**âš¡ Unique Technical**: [[keywords/RephQA|RephQA]], [[keywords/Group Relative Policy Optimization|Group Relative Policy Optimization]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16360v1 Announce Type: new 
Abstract: Large Language Models (LLMs) hold promise in addressing complex medical problems. However, while most prior studies focus on improving accuracy and reasoning abilities, a significant bottleneck in developing effective healthcare agents lies in the readability of LLM-generated responses, specifically, their ability to answer public health problems clearly and simply to people without medical backgrounds. In this work, we introduce RephQA, a benchmark for evaluating the readability of LLMs in public health question answering (QA). It contains 533 expert-reviewed QA pairs from 27 sources across 13 topics, and includes a proxy multiple-choice task to assess informativeness, along with two readability metrics: Flesch-Kincaid grade level and professional score. Evaluation of 25 LLMs reveals that most fail to meet readability standards, highlighting a gap between reasoning and effective communication. To address this, we explore four readability-enhancing strategies-standard prompting, chain-of-thought prompting, Group Relative Policy Optimization (GRPO), and a token-adapted variant. Token-adapted GRPO achieves the best results, advancing the development of more practical and user-friendly public health agents. These results represent a step toward building more practical agents for public health.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì´ ë³µì¡í•œ ì˜ë£Œ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë° ìœ ë§í•˜ì§€ë§Œ, ë¹„ì „ë¬¸ê°€ì—ê²Œ ëª…í™•í•˜ê³  ê°„ë‹¨í•˜ê²Œ ë‹µë³€í•˜ëŠ” ì½ê¸° ì‰¬ìš´ ì‘ë‹µ ìƒì„±ì´ ì£¼ìš” ê³¼ì œì„ì„ ì§€ì í•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ê³µì¤‘ ë³´ê±´ ì§ˆë¬¸ ì‘ë‹µ(QA)ì˜ ê°€ë…ì„±ì„ í‰ê°€í•˜ëŠ” ë²¤ì¹˜ë§ˆí¬ì¸ RephQAë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. 13ê°œ ì£¼ì œì—ì„œ 533ê°œì˜ ì „ë¬¸ê°€ ê²€í†  QA ìŒì„ í¬í•¨í•˜ë©°, ì •ë³´ì„± í‰ê°€ë¥¼ ìœ„í•œ ë‹¤ì§€ì„ ë‹¤í˜• ê³¼ì œì™€ ë‘ ê°€ì§€ ê°€ë…ì„± ì§€í‘œë¥¼ ì œê³µí•©ë‹ˆë‹¤. 25ê°œì˜ LLMì„ í‰ê°€í•œ ê²°ê³¼, ëŒ€ë¶€ë¶„ì´ ê°€ë…ì„± ê¸°ì¤€ì„ ì¶©ì¡±í•˜ì§€ ëª»í–ˆìœ¼ë©°, ì´ëŠ” ì¶”ë¡ ê³¼ íš¨ê³¼ì ì¸ ì˜ì‚¬ì†Œí†µ ê°„ì˜ ê²©ì°¨ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë„¤ ê°€ì§€ ê°€ë…ì„± í–¥ìƒ ì „ëµì„ íƒêµ¬í–ˆìœ¼ë©°, Token-adapted GRPOê°€ ê°€ì¥ ìš°ìˆ˜í•œ ê²°ê³¼ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ì‹¤ìš©ì ì´ê³  ì‚¬ìš©ì ì¹œí™”ì ì¸ ê³µì¤‘ ë³´ê±´ ì—ì´ì „íŠ¸ ê°œë°œì— ê¸°ì—¬í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì€ ë³µì¡í•œ ì˜ë£Œ ë¬¸ì œ í•´ê²°ì— ì ì¬ë ¥ì„ ê°€ì§€ê³  ìˆì§€ë§Œ, ë¹„ì „ë¬¸ê°€ì—ê²Œ ëª…í™•í•˜ê³  ê°„ë‹¨í•˜ê²Œ ë‹µë³€í•˜ëŠ” ëŠ¥ë ¥ì—ì„œ í•œê³„ê°€ ìˆë‹¤.
- 2. RephQAëŠ” ê³µì¤‘ ë³´ê±´ ì§ˆë¬¸ ì‘ë‹µì—ì„œ LLMì˜ ê°€ë…ì„±ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ë²¤ì¹˜ë§ˆí¬ë¡œ, 13ê°œ ì£¼ì œì—ì„œ 533ê°œì˜ ì „ë¬¸ê°€ ê²€í†  QA ìŒì„ í¬í•¨í•œë‹¤.
- 3. 25ê°œì˜ LLM í‰ê°€ ê²°ê³¼, ëŒ€ë¶€ë¶„ì´ ê°€ë…ì„± ê¸°ì¤€ì„ ì¶©ì¡±í•˜ì§€ ëª»í•˜ë©°, ì¶”ë¡ ê³¼ íš¨ê³¼ì ì¸ ì˜ì‚¬ì†Œí†µ ê°„ì˜ ê²©ì°¨ê°€ ë“œëŸ¬ë‚¬ë‹¤.
- 4. ê°€ë…ì„± í–¥ìƒì„ ìœ„í•´ í‘œì¤€ í”„ë¡¬í”„íŠ¸, ì‚¬ê³ ì˜ ì—°ì‡„ í”„ë¡¬í”„íŠ¸, ê·¸ë£¹ ìƒëŒ€ ì •ì±… ìµœì í™”(GRPO), í† í° ì ì‘í˜• ë³€í˜• ë“± ë„¤ ê°€ì§€ ì „ëµì„ íƒêµ¬í–ˆë‹¤.
- 5. í† í° ì ì‘í˜• GRPOê°€ ê°€ì¥ ìš°ìˆ˜í•œ ê²°ê³¼ë¥¼ ë³´ì—¬, ë³´ë‹¤ ì‹¤ìš©ì ì´ê³  ì‚¬ìš©ì ì¹œí™”ì ì¸ ê³µì¤‘ ë³´ê±´ ì—ì´ì „íŠ¸ ê°œë°œì— ê¸°ì—¬í–ˆë‹¤.


---

*Generated on 2025-09-24 03:11:05*