---
keywords:
  - Multimodal Learning
  - Self-supervised Learning
  - Modality Fusion
  - Distribution Shift
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.17492
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T23:59:54.133158",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multimodal Learning",
    "Self-supervised Learning",
    "Modality Fusion",
    "Distribution Shift"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multimodal Learning": 0.8,
    "Self-supervised Learning": 0.85,
    "Modality Fusion": 0.78,
    "Distribution Shift": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multimodal Medical Image Classification",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal Image Classification"
        ],
        "category": "specific_connectable",
        "rationale": "Multimodal Learning is a trending concept that connects various modalities, enhancing the understanding of complex data structures.",
        "novelty_score": 0.65,
        "connectivity_score": 0.85,
        "specificity_score": 0.78,
        "link_intent_score": 0.8
      },
      {
        "surface": "Self-supervised Learning",
        "canonical": "Self-supervised Learning",
        "aliases": [
          "SSL"
        ],
        "category": "specific_connectable",
        "rationale": "Self-supervised Learning is crucial for leveraging unlabeled data, which is a key aspect of the proposed framework.",
        "novelty_score": 0.6,
        "connectivity_score": 0.88,
        "specificity_score": 0.82,
        "link_intent_score": 0.85
      },
      {
        "surface": "Modality Fusion",
        "canonical": "Modality Fusion",
        "aliases": [
          "Fusion of Modalities"
        ],
        "category": "unique_technical",
        "rationale": "Modality Fusion is a unique technical concept central to the paper's approach to integrating various data types.",
        "novelty_score": 0.7,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Distribution Shift",
        "canonical": "Distribution Shift",
        "aliases": [
          "Shift in Distribution"
        ],
        "category": "unique_technical",
        "rationale": "Addressing Distribution Shift is essential for improving model robustness and reducing prediction uncertainty.",
        "novelty_score": 0.68,
        "connectivity_score": 0.7,
        "specificity_score": 0.76,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "pretraining",
      "fine-tuning",
      "baseline model",
      "extensive experiments"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multimodal Medical Image Classification",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.85,
        "specificity": 0.78,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Self-supervised Learning",
      "resolved_canonical": "Self-supervised Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.88,
        "specificity": 0.82,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Modality Fusion",
      "resolved_canonical": "Modality Fusion",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Distribution Shift",
      "resolved_canonical": "Distribution Shift",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.7,
        "specificity": 0.76,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Multimodal Medical Image Classification via Synergistic Learning Pre-training

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17492.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.17492](https://arxiv.org/abs/2509.17492)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Self-supervised learning of imaging and clinical signatures using a multimodal joint-embedding predictive architecture_20250922|Self-supervised learning of imaging and clinical signatures using a multimodal joint-embedding predictive architecture]] (84.3% similar)
- [[2025-09-22/Exploring the Capabilities of LLM Encoders for Image-Text Retrieval in Chest X-rays_20250922|Exploring the Capabilities of LLM Encoders for Image-Text Retrieval in Chest X-rays]] (83.7% similar)
- [[2025-09-22/UniMRSeg_ Unified Modality-Relax Segmentation via Hierarchical Self-Supervised Compensation_20250922|UniMRSeg: Unified Modality-Relax Segmentation via Hierarchical Self-Supervised Compensation]] (83.4% similar)
- [[2025-09-22/SLaM-DiMM_ Shared Latent Modeling for Diffusion Based Missing Modality Synthesis in MRI_20250922|SLaM-DiMM: Shared Latent Modeling for Diffusion Based Missing Modality Synthesis in MRI]] (83.4% similar)
- [[2025-09-22/RegionMed-CLIP_ A Region-Aware Multimodal Contrastive Learning Pre-trained Model for Medical Image Understanding_20250922|RegionMed-CLIP: A Region-Aware Multimodal Contrastive Learning Pre-trained Model for Medical Image Understanding]] (83.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]], [[keywords/Self-supervised Learning|Self-supervised Learning]]
**âš¡ Unique Technical**: [[keywords/Modality Fusion|Modality Fusion]], [[keywords/Distribution Shift|Distribution Shift]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17492v1 Announce Type: cross 
Abstract: Multimodal pathological images are usually in clinical diagnosis, but computer vision-based multimodal image-assisted diagnosis faces challenges with modality fusion, especially in the absence of expert-annotated data. To achieve the modality fusion in multimodal images with label scarcity, we propose a novel ``pretraining + fine-tuning" framework for multimodal semi-supervised medical image classification. Specifically, we propose a synergistic learning pretraining framework of consistency, reconstructive, and aligned learning. By treating one modality as an augmented sample of another modality, we implement a self-supervised learning pre-train, enhancing the baseline model's feature representation capability. Then, we design a fine-tuning method for multimodal fusion. During the fine-tuning stage, we set different encoders to extract features from the original modalities and provide a multimodal fusion encoder for fusion modality. In addition, we propose a distribution shift method for multimodal fusion features, which alleviates the prediction uncertainty and overfitting risks caused by the lack of labeled samples. We conduct extensive experiments on the publicly available gastroscopy image datasets Kvasir and Kvasirv2. Quantitative and qualitative results demonstrate that the proposed method outperforms the current state-of-the-art classification methods. The code will be released at: https://github.com/LQH89757/MICS.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë¼ë²¨ì´ ë¶€ì¡±í•œ ë‹¤ì¤‘ ëª¨ë‹¬ ë³‘ë¦¬ ì´ë¯¸ì§€ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ìœµí•©í•˜ì—¬ ì§„ë‹¨í•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì €ìë“¤ì€ 'ì‚¬ì „ í•™ìŠµ + ë¯¸ì„¸ ì¡°ì •' í”„ë ˆì„ì›Œí¬ë¥¼ í†µí•´ ì¼ê´€ì„±, ì¬êµ¬ì„±, ì •ë ¬ í•™ìŠµì„ ê²°í•©í•œ ì‹œë„ˆì§€ í•™ìŠµì„ ì œì•ˆí•©ë‹ˆë‹¤. í•œ ëª¨ë‹¬ë¦¬í‹°ë¥¼ ë‹¤ë¥¸ ëª¨ë‹¬ë¦¬í‹°ì˜ ì¦ê°• ìƒ˜í”Œë¡œ ê°„ì£¼í•˜ì—¬ ìê°€ ì§€ë„ í•™ìŠµì„ ìˆ˜í–‰í•˜ê³ , ë‹¤ì–‘í•œ ì¸ì½”ë”ë¥¼ í†µí•´ ì›ë³¸ ëª¨ë‹¬ë¦¬í‹°ì˜ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ì—¬ ìœµí•© ëª¨ë‹¬ë¦¬í‹°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ë˜í•œ, ë¶„í¬ ì´ë™ ë°©ë²•ì„ í†µí•´ ë¼ë²¨ ë¶€ì¡±ìœ¼ë¡œ ì¸í•œ ì˜ˆì¸¡ ë¶ˆí™•ì‹¤ì„±ê³¼ ê³¼ì í•© ë¬¸ì œë¥¼ ì™„í™”í•©ë‹ˆë‹¤. Kvasirì™€ Kvasirv2 ë°ì´í„°ì…‹ì„ í™œìš©í•œ ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì´ ê¸°ì¡´ì˜ ìµœì²¨ë‹¨ ë¶„ë¥˜ ë°©ë²•ë³´ë‹¤ ìš°ìˆ˜í•¨ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë³¸ ì—°êµ¬ëŠ” ë ˆì´ë¸”ì´ ë¶€ì¡±í•œ ìƒí™©ì—ì„œ ë‹¤ì¤‘ ëª¨ë‹¬ë¦¬í‹° ì´ë¯¸ì§€ë¥¼ ìœµí•©í•˜ê¸° ìœ„í•œ "ì‚¬ì „ í•™ìŠµ + ë¯¸ì„¸ ì¡°ì •" í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.
- 2. ì œì•ˆëœ í”„ë ˆì„ì›Œí¬ëŠ” ì¼ê´€ì„±, ì¬êµ¬ì„±, ì •ë ¬ í•™ìŠµì˜ ì‹œë„ˆì§€ì  í•™ìŠµ ì‚¬ì „ í›ˆë ¨ì„ í†µí•´ íŠ¹ì§• í‘œí˜„ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
- 3. ë¯¸ì„¸ ì¡°ì • ë‹¨ê³„ì—ì„œëŠ” ì›ë³¸ ëª¨ë‹¬ë¦¬í‹°ë¡œë¶€í„° íŠ¹ì§•ì„ ì¶”ì¶œí•˜ëŠ” ì¸ì½”ë”ì™€ ìœµí•© ëª¨ë‹¬ë¦¬í‹°ë¥¼ ìœ„í•œ ë‹¤ì¤‘ ëª¨ë‹¬ë¦¬í‹° ìœµí•© ì¸ì½”ë”ë¥¼ ì„¤ê³„í•©ë‹ˆë‹¤.
- 4. ë¶„í¬ ë³€í™” ë°©ë²•ì„ ì œì•ˆí•˜ì—¬ ë ˆì´ë¸”ì´ ë¶€ì¡±í•œ ìƒí™©ì—ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ì˜ˆì¸¡ ë¶ˆí™•ì‹¤ì„±ê³¼ ê³¼ì í•© ìœ„í—˜ì„ ì™„í™”í•©ë‹ˆë‹¤.
- 5. Kvasir ë° Kvasirv2 ë°ì´í„°ì…‹ì„ í™œìš©í•œ ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì´ ê¸°ì¡´ ìµœì²¨ë‹¨ ë¶„ë¥˜ ë°©ë²•ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-23 23:59:54*