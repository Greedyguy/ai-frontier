---
keywords:
  - MCTS-EP
  - Large Language Model
  - Monte Carlo Tree Search
  - Preference Optimization
  - Multimodal Learning
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.17116
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T22:56:25.905392",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "MCTS-EP",
    "Large Language Model",
    "Monte Carlo Tree Search",
    "Preference Optimization",
    "Multimodal Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "MCTS-EP": 0.8,
    "Large Language Model": 0.78,
    "Monte Carlo Tree Search": 0.82,
    "Preference Optimization": 0.77,
    "Multimodal Learning": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "MCTS-EP",
        "canonical": "MCTS-EP",
        "aliases": [
          "Monte Carlo Tree Search with Embodied Planning"
        ],
        "category": "unique_technical",
        "rationale": "MCTS-EP is a novel framework that combines Monte Carlo Tree Search with preference optimization, offering a unique approach to embodied agent training.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are integral to the MCTS-EP framework, enabling advanced language processing capabilities.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.78
      },
      {
        "surface": "Monte Carlo Tree Search",
        "canonical": "Monte Carlo Tree Search",
        "aliases": [
          "MCTS"
        ],
        "category": "specific_connectable",
        "rationale": "Monte Carlo Tree Search is a core component of the MCTS-EP framework, crucial for exploration and optimization.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.8,
        "link_intent_score": 0.82
      },
      {
        "surface": "Preference Optimization",
        "canonical": "Preference Optimization",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Preference Optimization is a unique aspect of the MCTS-EP framework, enhancing its training pipeline.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.75,
        "link_intent_score": 0.77
      },
      {
        "surface": "Multi-modal Reasoning",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multi-modal Reasoning"
        ],
        "category": "specific_connectable",
        "rationale": "Multi-modal Reasoning is essential for integrating different data types in MCTS-EP, aligning with the concept of Multimodal Learning.",
        "novelty_score": 0.55,
        "connectivity_score": 0.83,
        "specificity_score": 0.78,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "on-policy algorithms",
      "success rates",
      "average reward"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "MCTS-EP",
      "resolved_canonical": "MCTS-EP",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Monte Carlo Tree Search",
      "resolved_canonical": "Monte Carlo Tree Search",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.8,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Preference Optimization",
      "resolved_canonical": "Preference Optimization",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.75,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Multi-modal Reasoning",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.83,
        "specificity": 0.78,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# MCTS-EP: Empowering Embodied Planning with Online Preference Optimization

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17116.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.17116](https://arxiv.org/abs/2509.17116)

## 🔗 유사한 논문
- [[2025-09-18/TGPO_ Tree-Guided Preference Optimization for Robust Web Agent Reinforcement Learning_20250918|TGPO: Tree-Guided Preference Optimization for Robust Web Agent Reinforcement Learning]] (83.9% similar)
- [[2025-09-17/TGPO_ Tree-Guided Preference Optimization for Robust Web Agent Reinforcement Learning_20250917|TGPO: Tree-Guided Preference Optimization for Robust Web Agent Reinforcement Learning]] (83.4% similar)
- [[2025-09-19/Process-Supervised Reinforcement Learning for Interactive Multimodal Tool-Use Agents_20250919|Process-Supervised Reinforcement Learning for Interactive Multimodal Tool-Use Agents]] (82.2% similar)
- [[2025-09-19/LEED_ A Highly Efficient and Scalable LLM-Empowered Expert Demonstrations Framework for Multi-Agent Reinforcement Learning_20250919|LEED: A Highly Efficient and Scalable LLM-Empowered Expert Demonstrations Framework for Multi-Agent Reinforcement Learning]] (81.8% similar)
- [[2025-09-19/WebCoT_ Enhancing Web Agent Reasoning by Reconstructing Chain-of-Thought in Reflection, Branching, and Rollback_20250919|WebCoT: Enhancing Web Agent Reasoning by Reconstructing Chain-of-Thought in Reflection, Branching, and Rollback]] (81.4% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Monte Carlo Tree Search|Monte Carlo Tree Search]], [[keywords/Multimodal Learning|Multimodal Learning]]
**⚡ Unique Technical**: [[keywords/MCTS-EP|MCTS-EP]], [[keywords/Preference Optimization|Preference Optimization]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.17116v1 Announce Type: new 
Abstract: This paper introduces MCTS-EP, an online learning framework that combines large language models (LLM) with Monte Carlo Tree Search (MCTS) for training embodied agents. MCTS-EP integrates three key components: MCTS-guided exploration for preference data collection, efficient multi-modal reasoning mechanism, and iterative training pipeline based on preference optimization. We theoretically prove that MCTS-EP achieves better performance bounds than conventional on-policy algorithms when the loss function is strongly convex, and demonstrate that it can be formulated as a search-enhanced variant of GAIL. MCTS-EP achieves state-of-the-art performace across serval benchmarks. In ALFWorld, it achieves 92% and 87% success rates for textual and visual tasks. In WebShop, it reaches an average reward of 0.81. MTCS-EP also reduces average interaction steps from from 18.7/19.5 to 10.2/9.9 steps in visual ALFWorld.Code available at: https://github.com/xuhang-2/Embodied-Agent-Planning

## 📝 요약

이 논문은 대형 언어 모델(LLM)과 몬테카를로 트리 탐색(MCTS)을 결합한 온라인 학습 프레임워크인 MCTS-EP를 소개합니다. MCTS-EP는 MCTS를 활용한 탐색을 통해 선호 데이터 수집, 효율적인 다중 모달 추론 메커니즘, 선호 최적화 기반의 반복적 학습 파이프라인을 통합합니다. 이론적으로 MCTS-EP가 손실 함수가 강하게 볼록할 때 기존의 온-정책 알고리즘보다 더 나은 성능 경계를 달성함을 증명하고, GAIL의 탐색 강화 변형으로서의 가능성을 제시합니다. MCTS-EP는 여러 벤치마크에서 최첨단 성능을 보이며, ALFWorld에서는 텍스트 및 시각적 작업에서 각각 92%와 87%의 성공률을 기록합니다. WebShop에서는 평균 보상 0.81을 달성하며, 시각적 ALFWorld에서 평균 상호작용 단계를 18.7/19.5에서 10.2/9.9로 줄입니다.

## 🎯 주요 포인트

- 1. MCTS-EP는 대형 언어 모델(LLM)과 몬테카를로 트리 탐색(MCTS)을 결합하여 구현된 온라인 학습 프레임워크입니다.
- 2. 이 프레임워크는 MCTS를 통한 탐색 기반 선호 데이터 수집, 효율적인 다중 모달 추론 메커니즘, 선호 최적화 기반의 반복 학습 파이프라인을 통합합니다.
- 3. MCTS-EP는 강하게 볼록한 손실 함수에서 기존의 정책 기반 알고리즘보다 더 나은 성능 경계를 이론적으로 증명하며, GAIL의 검색 강화 변형으로 공식화될 수 있습니다.
- 4. ALFWorld에서 텍스트 및 시각적 작업에 대해 각각 92%와 87%의 성공률을 달성하며, WebShop에서는 평균 보상 0.81을 기록합니다.
- 5. MCTS-EP는 시각적 ALFWorld에서 평균 상호작용 단계를 18.7/19.5에서 10.2/9.9로 줄입니다.


---

*Generated on 2025-09-23 22:56:25*