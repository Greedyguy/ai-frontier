---
keywords:
  - Multitask Graphs
  - Non-Smooth Regularization
  - Decentralized Learning
  - Piecewise-Constant Relationships
category: cs.LG
publish_date: 2025-09-23
arxiv_id: 2509.17728
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T01:55:12.087682",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multitask Graphs",
    "Non-Smooth Regularization",
    "Decentralized Learning",
    "Piecewise-Constant Relationships"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multitask Graphs": 0.8,
    "Non-Smooth Regularization": 0.78,
    "Decentralized Learning": 0.72,
    "Piecewise-Constant Relationships": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "multitask graphs",
        "canonical": "Multitask Graphs",
        "aliases": [
          "multi-task graphs"
        ],
        "category": "unique_technical",
        "rationale": "Multitask graphs represent a unique approach to learning where each node (task) can benefit from the structure of the graph, making it a novel concept in graph-based learning.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "non-smooth regularization",
        "canonical": "Non-Smooth Regularization",
        "aliases": [
          "non-smooth regularizer"
        ],
        "category": "unique_technical",
        "rationale": "Non-smooth regularization is a specific technique that promotes sparsity and piecewise constant transitions, which is crucial for the paper's framework.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "decentralized learning",
        "canonical": "Decentralized Learning",
        "aliases": [
          "distributed learning"
        ],
        "category": "broad_technical",
        "rationale": "Decentralized learning is a broad technical concept that underpins the proposed approach, facilitating efficient solutions across distributed systems.",
        "novelty_score": 0.55,
        "connectivity_score": 0.7,
        "specificity_score": 0.65,
        "link_intent_score": 0.72
      },
      {
        "surface": "piecewise-constant relationships",
        "canonical": "Piecewise-Constant Relationships",
        "aliases": [
          "piecewise constant transitions"
        ],
        "category": "unique_technical",
        "rationale": "This concept is central to the paper's approach, describing the desired outcome of the non-smooth regularization technique.",
        "novelty_score": 0.68,
        "connectivity_score": 0.55,
        "specificity_score": 0.78,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "optimization problem",
      "cost functions",
      "regularization"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "multitask graphs",
      "resolved_canonical": "Multitask Graphs",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "non-smooth regularization",
      "resolved_canonical": "Non-Smooth Regularization",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "decentralized learning",
      "resolved_canonical": "Decentralized Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.7,
        "specificity": 0.65,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "piecewise-constant relationships",
      "resolved_canonical": "Piecewise-Constant Relationships",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.55,
        "specificity": 0.78,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# A non-smooth regularization framework for learning over multitask graphs

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.17728.pdf)
**Category**: cs.LG
**Published**: 2025-09-23
**ArXiv ID**: [2509.17728](https://arxiv.org/abs/2509.17728)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Gradient Interference-Aware Graph Coloring for Multitask Learning_20250923|Gradient Interference-Aware Graph Coloring for Multitask Learning]] (84.3% similar)
- [[2025-09-18/Data-Driven Distributed Optimization via Aggregative Tracking and Deep-Learning_20250918|Data-Driven Distributed Optimization via Aggregative Tracking and Deep-Learning]] (84.0% similar)
- [[2025-09-17/Decentralized Optimization with Topology-Independent Communication_20250917|Decentralized Optimization with Topology-Independent Communication]] (83.8% similar)
- [[2025-09-22/Fully Decentralized Cooperative Multi-Agent Reinforcement Learning is A Context Modeling Problem_20250922|Fully Decentralized Cooperative Multi-Agent Reinforcement Learning is A Context Modeling Problem]] (82.8% similar)
- [[2025-09-19/Learning Discrete Abstractions for Visual Rearrangement Tasks Using Vision-Guided Graph Coloring_20250919|Learning Discrete Abstractions for Visual Rearrangement Tasks Using Vision-Guided Graph Coloring]] (82.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Decentralized Learning|Decentralized Learning]]
**âš¡ Unique Technical**: [[keywords/Multitask Graphs|Multitask Graphs]], [[keywords/Non-Smooth Regularization|Non-Smooth Regularization]], [[keywords/Piecewise-Constant Relationships|Piecewise-Constant Relationships]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.17728v1 Announce Type: new 
Abstract: In this work, we consider learning over multitask graphs, where each agent aims to estimate its own parameter vector. Although agents seek distinct objectives, collaboration among them can be beneficial in scenarios where relationships between tasks exist. Among the various approaches to promoting relationships between tasks and, consequently, enhancing collaboration between agents, one notable method is regularization. While previous multitask learning studies have focused on smooth regularization to enforce graph smoothness, this work explores non-smooth regularization techniques that promote sparsity, making them particularly effective in encouraging piecewise constant transitions on the graph. We begin by formulating a global regularized optimization problem, which involves minimizing the aggregate sum of individual costs, regularized by a general non-smooth term designed to promote piecewise-constant relationships between the tasks of neighboring agents. Based on the forward-backward splitting strategy, we propose a decentralized learning approach that enables efficient solutions to the regularized optimization problem. Then, under convexity assumptions on the cost functions and co-regularization, we establish that the proposed approach converges in the mean-square-error sense within $O(\mu)$ of the optimal solution of the globally regularized cost. For broader applicability and improved computational efficiency, we also derive closed-form expressions for commonly used non-smooth (and, possibly, non-convex) regularizers, such as the weighted sum of the $\ell_0$-norm, $\ell_1$-norm, and elastic net regularization. Finally, we illustrate both the theoretical findings and the effectiveness of the approach through simulations.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” ë©€í‹°íƒœìŠ¤í¬ ê·¸ë˜í”„ì—ì„œ ê° ì—ì´ì „íŠ¸ê°€ ìì‹ ì˜ íŒŒë¼ë¯¸í„° ë²¡í„°ë¥¼ ì¶”ì •í•˜ëŠ” ë¬¸ì œë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. ì—ì´ì „íŠ¸ë“¤ì´ ì„œë¡œ ë‹¤ë¥¸ ëª©í‘œë¥¼ ì¶”êµ¬í•˜ì§€ë§Œ, íƒœìŠ¤í¬ ê°„ ê´€ê³„ê°€ ì¡´ì¬í•  ë•Œ í˜‘ë ¥ì´ ìœ ìµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ëŠ” íƒœìŠ¤í¬ ê°„ ê´€ê³„ë¥¼ ì´‰ì§„í•˜ëŠ” ë°©ë²• ì¤‘ ë¹„ë§¤ë„ëŸ¬ìš´ ì •ê·œí™” ê¸°ë²•ì„ íƒêµ¬í•˜ì—¬ ê·¸ë˜í”„ì—ì„œ ì¡°ê°ë³„ ìƒìˆ˜ ì „í™˜ì„ ì¥ë ¤í•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´, ì¸ì ‘ ì—ì´ì „íŠ¸ì˜ íƒœìŠ¤í¬ ê°„ ì¡°ê°ë³„ ìƒìˆ˜ ê´€ê³„ë¥¼ ì´‰ì§„í•˜ëŠ” ë¹„ë§¤ë„ëŸ¬ìš´ í•­ìœ¼ë¡œ ì •ê·œí™”ëœ ê¸€ë¡œë²Œ ìµœì í™” ë¬¸ì œë¥¼ ì œì‹œí•˜ê³ , ë¶„ì‚° í•™ìŠµ ì ‘ê·¼ë²•ì„ í†µí•´ íš¨ìœ¨ì ì¸ í•´ê²°ì±…ì„ ì œì•ˆí•©ë‹ˆë‹¤. ë¹„ìš© í•¨ìˆ˜ì™€ ê³µë™ ì •ê·œí™”ì˜ ë³¼ë¡ì„± ê°€ì • í•˜ì—, ì œì•ˆëœ ì ‘ê·¼ë²•ì´ í‰ê·  ì œê³± ì˜¤ì°¨ ê´€ì ì—ì„œ ìµœì  ì†”ë£¨ì…˜ì— ìˆ˜ë ´í•¨ì„ ì¦ëª…í•©ë‹ˆë‹¤. ë˜í•œ, ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ë¹„ë§¤ë„ëŸ¬ìš´ ì •ê·œí™” ê¸°ë²•ì— ëŒ€í•œ ë‹«íŒ í˜•ì‹ì˜ í‘œí˜„ì‹ì„ ë„ì¶œí•˜ì—¬ ê³„ì‚° íš¨ìœ¨ì„±ì„ ê°œì„ í•©ë‹ˆë‹¤. ì´ë¡ ì  ë°œê²¬ê³¼ ì ‘ê·¼ë²•ì˜ íš¨ê³¼ëŠ” ì‹œë®¬ë ˆì´ì…˜ì„ í†µí•´ ì…ì¦ë©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë³¸ ì—°êµ¬ëŠ” ì—ì´ì „íŠ¸ë“¤ì´ ê°ìì˜ íŒŒë¼ë¯¸í„° ë²¡í„°ë¥¼ ì¶”ì •í•˜ëŠ” ë©€í‹°íƒœìŠ¤í¬ ê·¸ë˜í”„ í•™ìŠµì„ ë‹¤ë£¨ë©°, ì—ì´ì „íŠ¸ ê°„ì˜ í˜‘ì—…ì´ ìœ ìµí•  ìˆ˜ ìˆëŠ” ì‹œë‚˜ë¦¬ì˜¤ë¥¼ íƒêµ¬í•©ë‹ˆë‹¤.
- 2. ê¸°ì¡´ì˜ ë§¤ë„ëŸ¬ìš´ ì •ê·œí™” ëŒ€ì‹  ë¹„ë§¤ë„ëŸ¬ìš´ ì •ê·œí™” ê¸°ë²•ì„ ì‚¬ìš©í•˜ì—¬ ê·¸ë˜í”„ì—ì„œ ì¡°ê°ë³„ ìƒìˆ˜ ì „í™˜ì„ ì´‰ì§„í•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤.
- 3. ì „ë°©-í›„ë°© ë¶„í•  ì „ëµì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ë¶„ì‚° í•™ìŠµ ì ‘ê·¼ë²•ì„ ì œì•ˆí•˜ì—¬ ì •ê·œí™”ëœ ìµœì í™” ë¬¸ì œë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ í•´ê²°í•©ë‹ˆë‹¤.
- 4. ë¹„ìš© í•¨ìˆ˜ì™€ ê³µë™ ì •ê·œí™”ì˜ ë³¼ë¡ì„± ê°€ì • í•˜ì— ì œì•ˆëœ ì ‘ê·¼ë²•ì´ í‰ê·  ì œê³± ì˜¤ì°¨ ê´€ì ì—ì„œ ìµœì  ì†”ë£¨ì…˜ì— ìˆ˜ë ´í•¨ì„ ì¦ëª…í•©ë‹ˆë‹¤.
- 5. ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ë¹„ë§¤ë„ëŸ¬ìš´ ì •ê·œí™” í•­ì— ëŒ€í•œ ë‹«íŒ í˜•íƒœì˜ í‘œí˜„ì‹ì„ ë„ì¶œí•˜ì—¬ ê³„ì‚° íš¨ìœ¨ì„±ì„ ê°œì„ í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 01:55:12*