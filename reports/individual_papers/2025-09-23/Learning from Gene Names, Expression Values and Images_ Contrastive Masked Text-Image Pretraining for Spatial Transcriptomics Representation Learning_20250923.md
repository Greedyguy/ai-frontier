---
keywords:
  - Contrastive Masked Text-Image Pretraining
  - Spatial Transcriptomics
  - Zero-Shot Learning
  - Masked Feature Modeling
  - Gene-Text Encoder
category: cs.AI
publish_date: 2025-09-23
arxiv_id: 2509.16892
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T23:37:07.548640",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Contrastive Masked Text-Image Pretraining",
    "Spatial Transcriptomics",
    "Zero-Shot Learning",
    "Masked Feature Modeling",
    "Gene-Text Encoder"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Contrastive Masked Text-Image Pretraining": 0.78,
    "Spatial Transcriptomics": 0.82,
    "Zero-Shot Learning": 0.75,
    "Masked Feature Modeling": 0.72,
    "Gene-Text Encoder": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Contrastive Masked Text-Image Pretraining",
        "canonical": "Contrastive Masked Text-Image Pretraining",
        "aliases": [
          "CoMTIP"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel framework specific to the paper, integrating text and image modalities in spatial transcriptomics.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.78
      },
      {
        "surface": "Spatial Transcriptomics",
        "canonical": "Spatial Transcriptomics",
        "aliases": [
          "Spatial Gene Expression"
        ],
        "category": "specific_connectable",
        "rationale": "Central to the paper's focus, linking gene expression with spatial data in transcriptomics.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.85,
        "link_intent_score": 0.82
      },
      {
        "surface": "Zero-Shot Gene Expression Prediction",
        "canonical": "Zero-Shot Learning",
        "aliases": [
          "Zero-Shot Prediction"
        ],
        "category": "specific_connectable",
        "rationale": "Highlights a key capability of the proposed method, connecting it to broader zero-shot learning concepts.",
        "novelty_score": 0.55,
        "connectivity_score": 0.8,
        "specificity_score": 0.78,
        "link_intent_score": 0.75
      },
      {
        "surface": "Masked Feature Modeling",
        "canonical": "Masked Feature Modeling",
        "aliases": [
          "Feature Masking"
        ],
        "category": "unique_technical",
        "rationale": "A specific technique used in the vision branch of the framework, crucial for context-aware learning.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.82,
        "link_intent_score": 0.72
      },
      {
        "surface": "Gene-Text Encoder",
        "canonical": "Gene-Text Encoder",
        "aliases": [
          "Gene Encoder"
        ],
        "category": "unique_technical",
        "rationale": "A novel component of the framework that processes gene sentences, enhancing connectivity in gene expression studies.",
        "novelty_score": 0.75,
        "connectivity_score": 0.7,
        "specificity_score": 0.88,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "pre-training",
      "downstream tasks"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Contrastive Masked Text-Image Pretraining",
      "resolved_canonical": "Contrastive Masked Text-Image Pretraining",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Spatial Transcriptomics",
      "resolved_canonical": "Spatial Transcriptomics",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.85,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Zero-Shot Gene Expression Prediction",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.8,
        "specificity": 0.78,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Masked Feature Modeling",
      "resolved_canonical": "Masked Feature Modeling",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.82,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "Gene-Text Encoder",
      "resolved_canonical": "Gene-Text Encoder",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.7,
        "specificity": 0.88,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Learning from Gene Names, Expression Values and Images: Contrastive Masked Text-Image Pretraining for Spatial Transcriptomics Representation Learning

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16892.pdf)
**Category**: cs.AI
**Published**: 2025-09-23
**ArXiv ID**: [2509.16892](https://arxiv.org/abs/2509.16892)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/RegionMed-CLIP_ A Region-Aware Multimodal Contrastive Learning Pre-trained Model for Medical Image Understanding_20250922|RegionMed-CLIP: A Region-Aware Multimodal Contrastive Learning Pre-trained Model for Medical Image Understanding]] (82.9% similar)
- [[2025-09-22/MaskAttn-SDXL_ Controllable Region-Level Text-To-Image Generation_20250922|MaskAttn-SDXL: Controllable Region-Level Text-To-Image Generation]] (82.5% similar)
- [[2025-09-22/Exploring the Capabilities of LLM Encoders for Image-Text Retrieval in Chest X-rays_20250922|Exploring the Capabilities of LLM Encoders for Image-Text Retrieval in Chest X-rays]] (80.5% similar)
- [[2025-09-22/AcT2I_ Evaluating and Improving Action Depiction in Text-to-Image Models_20250922|AcT2I: Evaluating and Improving Action Depiction in Text-to-Image Models]] (80.0% similar)
- [[2025-09-22/CLIPTTA_ Robust Contrastive Vision-Language Test-Time Adaptation_20250922|CLIPTTA: Robust Contrastive Vision-Language Test-Time Adaptation]] (80.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Spatial Transcriptomics|Spatial Transcriptomics]], [[keywords/Zero-Shot Learning|Zero-Shot Learning]]
**âš¡ Unique Technical**: [[keywords/Contrastive Masked Text-Image Pretraining|Contrastive Masked Text-Image Pretraining]], [[keywords/Masked Feature Modeling|Masked Feature Modeling]], [[keywords/Gene-Text Encoder|Gene-Text Encoder]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16892v1 Announce Type: cross 
Abstract: Spatial transcriptomics aims to connect high-resolution histology images with spatially resolved gene expression. To achieve better performance on downstream tasks such as gene expression prediction, large-scale pre-training is required to obtain generalisable representations that can bridge histology and transcriptomics across tissues, protocols, and laboratories. Existing cross-modal pre-training approaches for spatial transcriptomics rely on either gene names or expression values in isolation, which strips the gene branch of essential semantics and breaks the association between each gene and its quantitative magnitude. In addition, by restricting supervision to image-text alignment, these methods ignore intrinsic visual cues that are critical for learning robust image features. We present CoMTIP, the first Contrastive Masked Text-Image Pretraining framework that jointly learns from images, gene names, and expression values while capturing fine-grained visual context for spatial transcriptomics. The vision branch uses Masked Feature Modeling to reconstruct occluded patches and learn context-aware image embeddings. The text branch applies a scalable Gene-Text Encoder that processes all gene sentences in parallel, enriches each gene and its numerical value with dedicated embeddings, and employs Pair-aware Adversarial Training (PAAT) to preserve correct gene-value associations. Image and text representations are aligned in a shared InfoNCE-optimised space. Experiments on public spatial transcriptomics datasets show that CoMTIP not only surpasses previous methods on diverse downstream tasks but also achieves zero-shot gene expression prediction, a capability that existing approaches do not provide.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ê³µê°„ ì „ì‚¬ì²´í•™(spatial transcriptomics)ì—ì„œ ê³ í•´ìƒë„ ì¡°ì§ ì´ë¯¸ì§€ë¥¼ ê³µê°„ì ìœ¼ë¡œ í•´ìƒëœ ìœ ì „ì ë°œí˜„ê³¼ ì—°ê²°í•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë°©ë²•ë“¤ì€ ìœ ì „ì ì´ë¦„ì´ë‚˜ ë°œí˜„ ê°’ë§Œì„ ì‚¬ìš©í•˜ì—¬ ìœ ì „ìì™€ ê·¸ ì–‘ì  í¬ê¸° ê°„ì˜ ì—°ê´€ì„±ì„ ì•½í™”ì‹œì¼°ìŠµë‹ˆë‹¤. ë˜í•œ ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ì •ë ¬ì—ë§Œ ì´ˆì ì„ ë§ì¶° ì¤‘ìš”í•œ ì‹œê°ì  ë‹¨ì„œë¥¼ ë¬´ì‹œí–ˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, CoMTIPë¼ëŠ” ëŒ€ì¡°ì  ë§ˆìŠ¤í‚¹ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ì‚¬ì „ í•™ìŠµ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ì´ë¯¸ì§€, ìœ ì „ì ì´ë¦„, ë°œí˜„ ê°’ì„ í•¨ê»˜ í•™ìŠµí•˜ì—¬ ì„¸ë°€í•œ ì‹œê°ì  ë§¥ë½ì„ í¬ì°©í•©ë‹ˆë‹¤. ì´ë¯¸ì§€ ë¶€ë¶„ì€ ë§ˆìŠ¤í‚¹ëœ íŠ¹ì§• ëª¨ë¸ë§ì„ ì‚¬ìš©í•˜ì—¬ ë§¥ë½ì„ ì¸ì‹í•˜ëŠ” ì´ë¯¸ì§€ ì„ë² ë”©ì„ í•™ìŠµí•˜ê³ , í…ìŠ¤íŠ¸ ë¶€ë¶„ì€ í™•ì¥ ê°€ëŠ¥í•œ ìœ ì „ì-í…ìŠ¤íŠ¸ ì¸ì½”ë”ë¥¼ ì‚¬ìš©í•˜ì—¬ ìœ ì „ìì™€ ê·¸ ìˆ˜ì¹˜ ê°’ì„ ê°•í™”í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, CoMTIPëŠ” ë‹¤ì–‘í•œ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—…ì—ì„œ ê¸°ì¡´ ë°©ë²•ì„ ëŠ¥ê°€í•˜ë©°, ì œë¡œìƒ· ìœ ì „ì ë°œí˜„ ì˜ˆì¸¡ë„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. CoMTIPëŠ” ì´ë¯¸ì§€, ìœ ì „ì ì´ë¦„, ë°œí˜„ ê°’ì„ í•¨ê»˜ í•™ìŠµí•˜ì—¬ ê³µê°„ ì „ì‚¬ì²´í•™ì„ ìœ„í•œ ì„¸ë°€í•œ ì‹œê°ì  ë§¥ë½ì„ í¬ì°©í•©ë‹ˆë‹¤.
- 2. ë¹„ì „ ë¸Œëœì¹˜ëŠ” ë§ˆìŠ¤í¬ë“œ í”¼ì²˜ ëª¨ë¸ë§ì„ ì‚¬ìš©í•˜ì—¬ ê°€ë ¤ì§„ íŒ¨ì¹˜ë¥¼ ë³µì›í•˜ê³  ë§¥ë½ ì¸ì‹ ì´ë¯¸ì§€ ì„ë² ë”©ì„ í•™ìŠµí•©ë‹ˆë‹¤.
- 3. í…ìŠ¤íŠ¸ ë¸Œëœì¹˜ëŠ” ëª¨ë“  ìœ ì „ì ë¬¸ì¥ì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬í•˜ê³ , ê° ìœ ì „ìì™€ ê·¸ ìˆ˜ì¹˜ ê°’ì„ ì „ìš© ì„ë² ë”©ìœ¼ë¡œ í’ë¶€í•˜ê²Œ í•˜ë©°, PAATë¥¼ í†µí•´ ì˜¬ë°”ë¥¸ ìœ ì „ì-ê°’ ì—°ê´€ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤.
- 4. ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ í‘œí˜„ì€ ê³µìœ ëœ InfoNCE ìµœì í™” ê³µê°„ì—ì„œ ì •ë ¬ë©ë‹ˆë‹¤.
- 5. CoMTIPëŠ” ë‹¤ì–‘í•œ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—…ì—ì„œ ê¸°ì¡´ ë°©ë²•ì„ ëŠ¥ê°€í•  ë¿ë§Œ ì•„ë‹ˆë¼ ê¸°ì¡´ ì ‘ê·¼ ë°©ì‹ì´ ì œê³µí•˜ì§€ ì•ŠëŠ” ì œë¡œìƒ· ìœ ì „ì ë°œí˜„ ì˜ˆì¸¡ë„ ë‹¬ì„±í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-23 23:37:07*