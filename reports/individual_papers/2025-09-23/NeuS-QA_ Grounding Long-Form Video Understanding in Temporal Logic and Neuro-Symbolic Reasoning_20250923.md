---
keywords:
  - Long-Form Video Question Answering
  - Vision-Language Model
  - Temporal Logic
  - Neuro-Symbolic Reasoning
  - Model Checking
category: cs.CV
publish_date: 2025-09-23
arxiv_id: 2509.18041
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T05:07:39.517883",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Long-Form Video Question Answering",
    "Vision-Language Model",
    "Temporal Logic",
    "Neuro-Symbolic Reasoning",
    "Model Checking"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Long-Form Video Question Answering": 0.9,
    "Vision-Language Model": 0.85,
    "Temporal Logic": 0.88,
    "Neuro-Symbolic Reasoning": 0.92,
    "Model Checking": 0.86
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Long-Form Video Question Answering",
        "canonical": "Long-Form Video Question Answering",
        "aliases": [
          "LVQA"
        ],
        "category": "unique_technical",
        "rationale": "This term is central to the paper's focus on video understanding and reasoning.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.9
      },
      {
        "surface": "Vision-Language Models",
        "canonical": "Vision-Language Model",
        "aliases": [
          "VLMs"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-Language Models are crucial for linking video content with language queries.",
        "novelty_score": 0.5,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Temporal Logic",
        "canonical": "Temporal Logic",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Temporal Logic is essential for understanding and reasoning about event sequences in videos.",
        "novelty_score": 0.7,
        "connectivity_score": 0.8,
        "specificity_score": 0.8,
        "link_intent_score": 0.88
      },
      {
        "surface": "Neuro-Symbolic Reasoning",
        "canonical": "Neuro-Symbolic Reasoning",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Neuro-Symbolic Reasoning is a novel approach combining neural networks with symbolic logic, central to the paper's methodology.",
        "novelty_score": 0.8,
        "connectivity_score": 0.7,
        "specificity_score": 0.9,
        "link_intent_score": 0.92
      },
      {
        "surface": "Model Checking",
        "canonical": "Model Checking",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Model Checking is used to verify logical requirements in video segments, linking logic with video content.",
        "novelty_score": 0.65,
        "connectivity_score": 0.75,
        "specificity_score": 0.75,
        "link_intent_score": 0.86
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance",
      "approach",
      "result"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Long-Form Video Question Answering",
      "resolved_canonical": "Long-Form Video Question Answering",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.9
      }
    },
    {
      "candidate_surface": "Vision-Language Models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Temporal Logic",
      "resolved_canonical": "Temporal Logic",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.8,
        "specificity": 0.8,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "Neuro-Symbolic Reasoning",
      "resolved_canonical": "Neuro-Symbolic Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.7,
        "specificity": 0.9,
        "link_intent": 0.92
      }
    },
    {
      "candidate_surface": "Model Checking",
      "resolved_canonical": "Model Checking",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.75,
        "specificity": 0.75,
        "link_intent": 0.86
      }
    }
  ]
}
-->

# NeuS-QA: Grounding Long-Form Video Understanding in Temporal Logic and Neuro-Symbolic Reasoning

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18041.pdf)
**Category**: cs.CV
**Published**: 2025-09-23
**ArXiv ID**: [2509.18041](https://arxiv.org/abs/2509.18041)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Adaptive Fast-and-Slow Visual Program Reasoning for Long-Form VideoQA_20250923|Adaptive Fast-and-Slow Visual Program Reasoning for Long-Form VideoQA]] (83.3% similar)
- [[2025-09-23/ProtoVQA_ An Adaptable Prototypical Framework for Explainable Fine-Grained Visual Question Answering_20250923|ProtoVQA: An Adaptable Prototypical Framework for Explainable Fine-Grained Visual Question Answering]] (82.8% similar)
- [[2025-09-19/MovieCORE_ COgnitive REasoning in Movies_20250919|MovieCORE: COgnitive REasoning in Movies]] (82.7% similar)
- [[2025-09-23/Enhancing Scientific Visual Question Answering via Vision-Caption aware Supervised Fine-Tuning_20250923|Enhancing Scientific Visual Question Answering via Vision-Caption aware Supervised Fine-Tuning]] (82.0% similar)
- [[2025-09-23/Large Language Models Meet Knowledge Graphs for Question Answering_ Synthesis and Opportunities_20250923|Large Language Models Meet Knowledge Graphs for Question Answering: Synthesis and Opportunities]] (81.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Temporal Logic|Temporal Logic]], [[keywords/Model Checking|Model Checking]]
**âš¡ Unique Technical**: [[keywords/Long-Form Video Question Answering|Long-Form Video Question Answering]], [[keywords/Neuro-Symbolic Reasoning|Neuro-Symbolic Reasoning]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18041v1 Announce Type: new 
Abstract: Long-Form Video Question Answering (LVQA) poses challenges beyond traditional visual question answering (VQA), which is often limited to static images or short video clips. While current vision-language models (VLMs) perform well in those settings, they struggle with complex queries in LVQA over long videos involving multi-step temporal reasoning and causality. Vanilla approaches, which sample frames uniformly and feed them to a VLM with the question, incur significant token overhead, forcing severe downsampling. As a result, the model often misses fine-grained visual structure, subtle event transitions, or key temporal cues, ultimately leading to incorrect answers. To address these limitations, recent works have explored query-adaptive frame sampling, hierarchical keyframe selection, and agent-based iterative querying. However, these methods remain fundamentally heuristic: they lack explicit temporal representations and cannot enforce or verify logical event relationships. As a result, there are no formal guarantees that the sampled context actually encodes the compositional or causal logic demanded by the question. To address these foundational gaps, we introduce NeuS-QA, a training-free, plug-and-play neuro-symbolic pipeline for LVQA. NeuS-QA translates a natural language question into a formal temporal logic expression, constructs a video automaton from frame-level semantic propositions, and applies model checking to rigorously identify video segments satisfying the question's logical requirements. Only these logic-verified segments are submitted to the VLM, thus improving interpretability, reducing hallucinations, and enabling compositional reasoning without modifying or fine-tuning the model. Experiments on LongVideoBench and CinePile show NeuS-QA improves performance by over 10%, especially on questions involving event ordering, causality, and multi-step compositional reasoning.

## ğŸ“ ìš”ì•½

Long-Form Video Question Answering (LVQA)ëŠ” ê¸°ì¡´ì˜ ì‹œê°ì  ì§ˆë¬¸ ì‘ë‹µ(VQA)ë³´ë‹¤ ë³µì¡í•œ ë¬¸ì œë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë¹„ì „-ì–¸ì–´ ëª¨ë¸(VLM)ì€ ì •ì  ì´ë¯¸ì§€ë‚˜ ì§§ì€ ë¹„ë””ì˜¤ í´ë¦½ì—ì„œëŠ” ì˜ ì‘ë™í•˜ì§€ë§Œ, ê¸´ ë¹„ë””ì˜¤ì—ì„œì˜ ë³µì¡í•œ ì§ˆì˜ì—ëŠ” ì–´ë ¤ì›€ì„ ê²ªìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ NeuS-QAë¼ëŠ” ìƒˆë¡œìš´ ì‹ ê²½-ìƒì§•ì  íŒŒì´í”„ë¼ì¸ì„ ì œì•ˆí•©ë‹ˆë‹¤. NeuS-QAëŠ” ìì—°ì–´ ì§ˆë¬¸ì„ í˜•ì‹ì  ì‹œê°„ ë…¼ë¦¬ í‘œí˜„ìœ¼ë¡œ ë³€í™˜í•˜ê³ , ë¹„ë””ì˜¤ ì˜¤í† ë§ˆí†¤ì„ êµ¬ì„±í•˜ì—¬ ë…¼ë¦¬ì  ìš”êµ¬ë¥¼ ì¶©ì¡±í•˜ëŠ” ë¹„ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì‹ë³„í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ë…¼ë¦¬ ê²€ì¦ëœ ì„¸ê·¸ë¨¼íŠ¸ë§Œì„ VLMì— ì œì¶œí•˜ì—¬ í•´ì„ ê°€ëŠ¥ì„±ì„ ë†’ì´ê³ , ì˜ëª»ëœ ì¶”ë¡ ì„ ì¤„ì´ë©°, ëª¨ë¸ì„ ìˆ˜ì •í•˜ì§€ ì•Šê³ ë„ êµ¬ì„±ì  ì¶”ë¡ ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, NeuS-QAëŠ” LongVideoBenchì™€ CinePileì—ì„œ ì„±ëŠ¥ì„ 10% ì´ìƒ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤. íŠ¹íˆ ì‚¬ê±´ ìˆœì„œ, ì¸ê³¼ê´€ê³„, ë‹¤ë‹¨ê³„ êµ¬ì„±ì  ì¶”ë¡ ì´ í•„ìš”í•œ ì§ˆë¬¸ì—ì„œ ë‘ë“œëŸ¬ì§„ ì„±ê³¼ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Long-Form Video Question Answering (LVQA)ëŠ” ê¸°ì¡´ì˜ ì‹œê°ì  ì§ˆë¬¸ ì‘ë‹µ(VQA)ë³´ë‹¤ ë³µì¡í•œ ë‹¤ë‹¨ê³„ ì‹œê°„ì  ì¶”ë¡ ê³¼ ì¸ê³¼ê´€ê³„ë¥¼ í¬í•¨í•œ ê¸´ ë¹„ë””ì˜¤ì—ì„œì˜ ì§ˆì˜ ì²˜ë¦¬ì— ì–´ë ¤ì›€ì„ ê²ªìŠµë‹ˆë‹¤.
- 2. ê¸°ì¡´ ë°©ë²•ë“¤ì€ ê· ì¼í•œ í”„ë ˆì„ ìƒ˜í”Œë§ì„ ì‚¬ìš©í•˜ì—¬ ë¹„ë””ì˜¤ì˜ ì„¸ë¶€ì ì¸ ì‹œê°ì  êµ¬ì¡°ë‚˜ ì¤‘ìš”í•œ ì‹œê°„ì  ë‹¨ì„œë¥¼ ë†“ì¹˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.
- 3. NeuS-QAëŠ” ìì—°ì–´ ì§ˆë¬¸ì„ í˜•ì‹ì  ì‹œê°„ ë…¼ë¦¬ í‘œí˜„ìœ¼ë¡œ ë³€í™˜í•˜ê³ , ë¹„ë””ì˜¤ ì˜¤í† ë§ˆí†¤ì„ êµ¬ì„±í•˜ì—¬ ë…¼ë¦¬ì ìœ¼ë¡œ ìš”êµ¬ë˜ëŠ” ë¹„ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì‹ë³„í•˜ëŠ” ì‹ ê²½-ìƒì§•ì  íŒŒì´í”„ë¼ì¸ì„ ì œì•ˆí•©ë‹ˆë‹¤.
- 4. NeuS-QAëŠ” ëª¨ë¸ì˜ ìˆ˜ì •ì´ë‚˜ ë¯¸ì„¸ ì¡°ì • ì—†ì´ í•´ì„ ê°€ëŠ¥ì„±ì„ ë†’ì´ê³ , í™˜ê°ì„ ì¤„ì´ë©°, êµ¬ì„±ì  ì¶”ë¡ ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
- 5. LongVideoBenchì™€ CinePile ì‹¤í—˜ì—ì„œ NeuS-QAëŠ” íŠ¹íˆ ì‚¬ê±´ ìˆœì„œ, ì¸ê³¼ê´€ê³„, ë‹¤ë‹¨ê³„ êµ¬ì„±ì  ì¶”ë¡ ì´ í¬í•¨ëœ ì§ˆë¬¸ì—ì„œ ì„±ëŠ¥ì„ 10% ì´ìƒ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 05:07:39*