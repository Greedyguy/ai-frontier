---
keywords:
  - Long-Form Video Question Answering
  - Vision-Language Model
  - Temporal Logic
  - Neuro-Symbolic Reasoning
  - Model Checking
category: cs.CV
publish_date: 2025-09-23
arxiv_id: 2509.18041
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T05:07:39.517883",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Long-Form Video Question Answering",
    "Vision-Language Model",
    "Temporal Logic",
    "Neuro-Symbolic Reasoning",
    "Model Checking"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Long-Form Video Question Answering": 0.9,
    "Vision-Language Model": 0.85,
    "Temporal Logic": 0.88,
    "Neuro-Symbolic Reasoning": 0.92,
    "Model Checking": 0.86
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Long-Form Video Question Answering",
        "canonical": "Long-Form Video Question Answering",
        "aliases": [
          "LVQA"
        ],
        "category": "unique_technical",
        "rationale": "This term is central to the paper's focus on video understanding and reasoning.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.9
      },
      {
        "surface": "Vision-Language Models",
        "canonical": "Vision-Language Model",
        "aliases": [
          "VLMs"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-Language Models are crucial for linking video content with language queries.",
        "novelty_score": 0.5,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Temporal Logic",
        "canonical": "Temporal Logic",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Temporal Logic is essential for understanding and reasoning about event sequences in videos.",
        "novelty_score": 0.7,
        "connectivity_score": 0.8,
        "specificity_score": 0.8,
        "link_intent_score": 0.88
      },
      {
        "surface": "Neuro-Symbolic Reasoning",
        "canonical": "Neuro-Symbolic Reasoning",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Neuro-Symbolic Reasoning is a novel approach combining neural networks with symbolic logic, central to the paper's methodology.",
        "novelty_score": 0.8,
        "connectivity_score": 0.7,
        "specificity_score": 0.9,
        "link_intent_score": 0.92
      },
      {
        "surface": "Model Checking",
        "canonical": "Model Checking",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Model Checking is used to verify logical requirements in video segments, linking logic with video content.",
        "novelty_score": 0.65,
        "connectivity_score": 0.75,
        "specificity_score": 0.75,
        "link_intent_score": 0.86
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance",
      "approach",
      "result"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Long-Form Video Question Answering",
      "resolved_canonical": "Long-Form Video Question Answering",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.9
      }
    },
    {
      "candidate_surface": "Vision-Language Models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Temporal Logic",
      "resolved_canonical": "Temporal Logic",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.8,
        "specificity": 0.8,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "Neuro-Symbolic Reasoning",
      "resolved_canonical": "Neuro-Symbolic Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.7,
        "specificity": 0.9,
        "link_intent": 0.92
      }
    },
    {
      "candidate_surface": "Model Checking",
      "resolved_canonical": "Model Checking",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.75,
        "specificity": 0.75,
        "link_intent": 0.86
      }
    }
  ]
}
-->

# NeuS-QA: Grounding Long-Form Video Understanding in Temporal Logic and Neuro-Symbolic Reasoning

## 📋 메타데이터

**Links**: [[daily_digest_20250923|20250923]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18041.pdf)
**Category**: cs.CV
**Published**: 2025-09-23
**ArXiv ID**: [2509.18041](https://arxiv.org/abs/2509.18041)

## 🔗 유사한 논문
- [[2025-09-23/Adaptive Fast-and-Slow Visual Program Reasoning for Long-Form VideoQA_20250923|Adaptive Fast-and-Slow Visual Program Reasoning for Long-Form VideoQA]] (83.3% similar)
- [[2025-09-23/ProtoVQA_ An Adaptable Prototypical Framework for Explainable Fine-Grained Visual Question Answering_20250923|ProtoVQA: An Adaptable Prototypical Framework for Explainable Fine-Grained Visual Question Answering]] (82.8% similar)
- [[2025-09-19/MovieCORE_ COgnitive REasoning in Movies_20250919|MovieCORE: COgnitive REasoning in Movies]] (82.7% similar)
- [[2025-09-23/Enhancing Scientific Visual Question Answering via Vision-Caption aware Supervised Fine-Tuning_20250923|Enhancing Scientific Visual Question Answering via Vision-Caption aware Supervised Fine-Tuning]] (82.0% similar)
- [[2025-09-23/Large Language Models Meet Knowledge Graphs for Question Answering_ Synthesis and Opportunities_20250923|Large Language Models Meet Knowledge Graphs for Question Answering: Synthesis and Opportunities]] (81.8% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Temporal Logic|Temporal Logic]], [[keywords/Model Checking|Model Checking]]
**⚡ Unique Technical**: [[keywords/Long-Form Video Question Answering|Long-Form Video Question Answering]], [[keywords/Neuro-Symbolic Reasoning|Neuro-Symbolic Reasoning]]
**🚀 Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.18041v1 Announce Type: new 
Abstract: Long-Form Video Question Answering (LVQA) poses challenges beyond traditional visual question answering (VQA), which is often limited to static images or short video clips. While current vision-language models (VLMs) perform well in those settings, they struggle with complex queries in LVQA over long videos involving multi-step temporal reasoning and causality. Vanilla approaches, which sample frames uniformly and feed them to a VLM with the question, incur significant token overhead, forcing severe downsampling. As a result, the model often misses fine-grained visual structure, subtle event transitions, or key temporal cues, ultimately leading to incorrect answers. To address these limitations, recent works have explored query-adaptive frame sampling, hierarchical keyframe selection, and agent-based iterative querying. However, these methods remain fundamentally heuristic: they lack explicit temporal representations and cannot enforce or verify logical event relationships. As a result, there are no formal guarantees that the sampled context actually encodes the compositional or causal logic demanded by the question. To address these foundational gaps, we introduce NeuS-QA, a training-free, plug-and-play neuro-symbolic pipeline for LVQA. NeuS-QA translates a natural language question into a formal temporal logic expression, constructs a video automaton from frame-level semantic propositions, and applies model checking to rigorously identify video segments satisfying the question's logical requirements. Only these logic-verified segments are submitted to the VLM, thus improving interpretability, reducing hallucinations, and enabling compositional reasoning without modifying or fine-tuning the model. Experiments on LongVideoBench and CinePile show NeuS-QA improves performance by over 10%, especially on questions involving event ordering, causality, and multi-step compositional reasoning.

## 📝 요약

Long-Form Video Question Answering (LVQA)는 기존의 시각적 질문 응답(VQA)보다 복잡한 문제를 다룹니다. 기존의 비전-언어 모델(VLM)은 정적 이미지나 짧은 비디오 클립에서는 잘 작동하지만, 긴 비디오에서의 복잡한 질의에는 어려움을 겪습니다. 이를 해결하기 위해 NeuS-QA라는 새로운 신경-상징적 파이프라인을 제안합니다. NeuS-QA는 자연어 질문을 형식적 시간 논리 표현으로 변환하고, 비디오 오토마톤을 구성하여 논리적 요구를 충족하는 비디오 세그먼트를 식별합니다. 이러한 논리 검증된 세그먼트만을 VLM에 제출하여 해석 가능성을 높이고, 잘못된 추론을 줄이며, 모델을 수정하지 않고도 구성적 추론을 가능하게 합니다. 실험 결과, NeuS-QA는 LongVideoBench와 CinePile에서 성능을 10% 이상 향상시켰습니다. 특히 사건 순서, 인과관계, 다단계 구성적 추론이 필요한 질문에서 두드러진 성과를 보였습니다.

## 🎯 주요 포인트

- 1. Long-Form Video Question Answering (LVQA)는 기존의 시각적 질문 응답(VQA)보다 복잡한 다단계 시간적 추론과 인과관계를 포함한 긴 비디오에서의 질의 처리에 어려움을 겪습니다.
- 2. 기존 방법들은 균일한 프레임 샘플링을 사용하여 비디오의 세부적인 시각적 구조나 중요한 시간적 단서를 놓치는 경우가 많습니다.
- 3. NeuS-QA는 자연어 질문을 형식적 시간 논리 표현으로 변환하고, 비디오 오토마톤을 구성하여 논리적으로 요구되는 비디오 세그먼트를 식별하는 신경-상징적 파이프라인을 제안합니다.
- 4. NeuS-QA는 모델의 수정이나 미세 조정 없이 해석 가능성을 높이고, 환각을 줄이며, 구성적 추론을 가능하게 합니다.
- 5. LongVideoBench와 CinePile 실험에서 NeuS-QA는 특히 사건 순서, 인과관계, 다단계 구성적 추론이 포함된 질문에서 성능을 10% 이상 향상시켰습니다.


---

*Generated on 2025-09-24 05:07:39*