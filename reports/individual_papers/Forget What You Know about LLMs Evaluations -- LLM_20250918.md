
# Forget What You Know about LLMs Evaluations -- LLMs are Like a Chameleon

**Korean Title:** LLM í‰ê°€ì— ëŒ€í•´ ì•Œê³  ìˆë˜ ê²ƒì„ ìŠì–´ë²„ë¦¬ì„¸ìš” - LLMì€ ì¹´ë©œë ˆì˜¨ê³¼ ê°™ìŠµë‹ˆë‹¤.

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-18|2025-09-18]] [[keywords/evolved/Resilience in LLM Evaluation|Resilience in LLM Evaluation]] [[keywords/broad/Large Language Models|Large Language Models]] [[keywords/broad/Benchmark Overfit Detector|Benchmark Overfit Detector]] [[keywords/specific/Meta-evaluation Framework|Meta-evaluation Framework]] [[keywords/unique/Chameleon Benchmark Overfit Detector|Chameleon Benchmark Overfit Detector]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Meta-evaluation Framework
**ğŸ”¬ Broad Technical**: Large Language Models, Benchmark Evaluation
**ğŸ”— Specific Connectable**: Chameleon Benchmark Overfit Detector
**â­ Unique Technical**: C-BOD

**ArXiv ID**: [2502.07445](https://arxiv.org/abs/2502.07445)
**Published**: 2025-09-18
**Category**: cs.AI
**PDF**: [Download](https://arxiv.org/pdf/2502.07445.pdf)


## ğŸ·ï¸ ì¶”ì¶œëœ í‚¤ì›Œë“œ



`Large Language Models` â€¢ 

`Benchmark Overfit Detector` â€¢ 

`MMLU benchmark` â€¢ 

`Chameleon Benchmark Overfit Detector (C-BOD` â€¢ 

`Resilience in LLM evaluation`



## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2502.07445v2 Announce Type: replace-cross 
Abstract: Large language models (LLMs) often appear to excel on public benchmarks, but these high scores may mask an overreliance on dataset-specific surface cues rather than true language understanding. We introduce the Chameleon Benchmark Overfit Detector (C-BOD), a meta-evaluation framework that systematically distorts benchmark prompts via a parametric transformation and detects overfitting of LLMs. By rephrasing inputs while preserving their semantic content and labels, C-BOD exposes whether a model's performance is driven by memorized patterns. Evaluated on the MMLU benchmark using 26 leading LLMs, our method reveals an average performance degradation of 2.15% under modest perturbations, with 20 out of 26 models exhibiting statistically significant differences. Notably, models with higher baseline accuracy exhibit larger performance differences under perturbation, and larger LLMs tend to be more sensitive to rephrasings, indicating that both cases may overrely on fixed prompt patterns. In contrast, the Llama family and models with lower baseline accuracy show insignificant degradation, suggesting reduced dependency on superficial cues. Moreover, C-BOD's dataset- and model-agnostic design allows easy integration into training pipelines to promote more robust language understanding. Our findings challenge the community to look beyond leaderboard scores and prioritize resilience and generalization in LLM evaluation.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2502.07445v2 ë°œí‘œ ìœ í˜•: replace-cross
ìš”ì•½: ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ (LLMs)ì€ ì¢…ì¢… ê³µê°œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìš°ìˆ˜í•œ ì„±ê³¼ë¥¼ ë³´ì´ì§€ë§Œ, ì´ëŸ¬í•œ ë†’ì€ ì ìˆ˜ëŠ” ì‹¤ì œ ì–¸ì–´ ì´í•´ë³´ë‹¤ëŠ” ë°ì´í„°ì…‹ íŠ¹ì • í‘œë©´ ë‹¨ì„œì— ì§€ë‚˜ì¹˜ê²Œ ì˜ì¡´í•  ìˆ˜ ìˆë‹¤. ìš°ë¦¬ëŠ” ì¹´ë©œë ˆì˜¨ ë²¤ì¹˜ë§ˆí¬ ì˜¤ë²„í”¼íŒ… íƒì§€ê¸° (C-BOD)ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ì´ëŠ” ë²¤ì¹˜ë§ˆí¬ í”„ë¡¬í”„íŠ¸ë¥¼ ë§¤ê°œë³€ìˆ˜ ë³€í™˜ì„ í†µí•´ ì²´ê³„ì ìœ¼ë¡œ ì™œê³¡í•˜ê³  LLMsì˜ ì˜¤ë²„í”¼íŒ…ì„ ê°ì§€í•˜ëŠ” ë©”íƒ€í‰ê°€ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ì…ë ¥ì„ ë‹¤ì‹œ í‘œí˜„í•˜ë©´ì„œ ì˜ë¯¸ ì½˜í…ì¸ ì™€ ë ˆì´ë¸”ì„ ë³´ì¡´í•¨ìœ¼ë¡œì¨, C-BODëŠ” ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ê¸°ì–µëœ íŒ¨í„´ì— ì˜í•´ ì£¼ë„ë˜ëŠ”ì§€ ì—¬ë¶€ë¥¼ ë“œëŸ¬ëƒ…ë‹ˆë‹¤. 26ê°œì˜ ì£¼ìš” LLMì„ ì‚¬ìš©í•˜ì—¬ MMLU ë²¤ì¹˜ë§ˆí¬ì—ì„œ í‰ê°€í•œ ê²°ê³¼, ìš°ë¦¬ì˜ ë°©ë²•ì€ ì ì€ ë³€í˜•ì—ì„œ 2.15%ì˜ í‰ê·  ì„±ëŠ¥ ì €í•˜ë¥¼ ë³´ì—¬ì£¼ë©°, 26ê°œ ì¤‘ 20ê°œì˜ ëª¨ë¸ì´ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì°¨ì´ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. íŠ¹íˆ, ë†’ì€ ê¸°ì¤€ ì •í™•ë„ë¥¼ ê°€ì§„ ëª¨ë¸ì€ ë³€í˜•ì— ëŒ€í•´ ë” í° ì„±ëŠ¥ ì°¨ì´ë¥¼ ë³´ì´ë©°, í° LLMì€ ë‹¤ì‹œ í‘œí˜„ì— ë” ë¯¼ê°í•  ê°€ëŠ¥ì„±ì´ ìˆì–´ì„œ ë‘˜ ë‹¤ ê³ ì •ëœ í”„ë¡¬í”„íŠ¸ íŒ¨í„´ì— ì§€ë‚˜ì¹˜ê²Œ ì˜ì¡´í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ë°˜ë©´, Llama íŒ¨ë°€ë¦¬ì™€ ê¸°ì¤€ ì •í™•ë„ê°€ ë‚®ì€ ëª¨ë¸ì€ ë¬´ì˜ë¯¸í•œ ì €í•˜ë¥¼ ë³´ì—¬ì£¼ì–´ í‘œë©´ì ì¸ ë‹¨ì„œì— ëŒ€í•œ ì˜ì¡´ì„±ì´ ì¤„ì–´ë“¤ì—ˆë‹¤ê³  ì œì•ˆí•©ë‹ˆë‹¤. ë”ìš±ì´, C-BODì˜ ë°ì´í„°ì…‹ ë° ëª¨ë¸ì— ì¤‘ë¦½ì ì¸ ë””ìì¸ì€ í›ˆë ¨ íŒŒì´í”„ë¼ì¸ì— ì‰½ê²Œ í†µí•©ë˜ì–´ ë” ê²¬ê³ í•œ ì–¸ì–´ ì´í•´ë¥¼ ì´‰ì§„í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì—°êµ¬ ê²°ê³¼ëŠ” ì»¤ë®¤ë‹ˆí‹°ì—ê²Œ ë¦¬ë”ë³´ë“œ ì ìˆ˜ë¥¼ ë„˜ì–´ì„œ LLM í‰ê°€ì—ì„œ íƒ„ë ¥ì„±ê³¼ ì¼ë°˜í™”ë¥¼ ìš°ì„ ì‹œí•˜ë„ë¡ ë„ì „í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ˆëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì€ ê³µê°œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë›°ì–´ë‚œ ì„±ì ì„ ë³´ì´ì§€ë§Œ, ì´ëŠ” ì‹¤ì œ ì–¸ì–´ ì´í•´ê°€ ì•„ë‹Œ ë°ì´í„°ì…‹ íŠ¹ì • í‘œë©´ ë‹¨ì„œì— ì§€ë‚˜ì¹˜ê²Œ ì˜ì¡´í•  ìˆ˜ ìˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” Chameleon Benchmark Overfit Detector (C-BOD)ë¥¼ ì†Œê°œí•˜ì—¬ ë²¤ì¹˜ë§ˆí¬ í”„ë¡¬í”„íŠ¸ë¥¼ ì™œê³¡í•˜ê³  LLMì˜ ì˜¤ë²„í”¼íŒ…ì„ ê°ì§€í•˜ëŠ” ë©”íƒ€í‰ê°€ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì‹œí•œë‹¤. MMLU ë²¤ì¹˜ë§ˆí¬ë¥¼ ì‚¬ìš©í•˜ì—¬ 26ê°œì˜ ì£¼ìš” LLMì„ í‰ê°€í•œ ê²°ê³¼, ìš°ë¦¬ì˜ ë°©ë²•ì€ ì ì€ ì™œê³¡ìœ¼ë¡œ í‰ê·  ì„±ëŠ¥ í•˜ë½ë¥ ì´ 2.15%ì´ë©°, 26ê°œ ëª¨ë¸ ì¤‘ 20ê°œê°€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì°¨ì´ë¥¼ ë³´ì˜€ë‹¤. ë” í° ê¸°ë³¸ ì •í™•ë„ë¥¼ ê°€ì§„ ëª¨ë¸ì¼ìˆ˜ë¡ ì™œê³¡ì— ë¯¼ê°í•˜ë©°, í° LLMì¼ìˆ˜ë¡ ë‹¤ì‹œ í‘œí˜„ì— ë¯¼ê°í•  ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ë‹¤. ì´ì— ë°˜í•´, Llama íŒ¨ë°€ë¦¬ì™€ ë‚®ì€ ê¸°ë³¸ ì •í™•ë„ë¥¼ ê°€ì§„ ëª¨ë¸ì€ ì¤‘ìš”í•˜ì§€ ì•Šì€ í•˜ë½ì„ ë³´ì—¬ ì–•ì€ ë‹¨ì„œì— ëŒ€í•œ ì˜ì¡´ì„±ì´ ì¤„ì–´ë“  ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ë‹¤. ë˜í•œ, C-BODì˜ ë°ì´í„°ì…‹ ë° ëª¨ë¸ì— ëŒ€í•œ ë””ìì¸ì€ í›ˆë ¨ íŒŒì´í”„ë¼ì¸ì— ì‰½ê²Œ í†µí•©ë˜ì–´ ë” ê²¬ê³ í•œ ì–¸ì–´ ì´í•´ë¥¼ ì´‰ì§„í•œë‹¤. ìš°ë¦¬ì˜ ì—°êµ¬ ê²°ê³¼ëŠ” ë¦¬ë”ë³´ë“œ ì ìˆ˜ë¥¼ ë„˜ì–´ì„œ LLM í‰ê°€ì—ì„œ íƒ„ë ¥ì„±ê³¼ ì¼ë°˜í™”ë¥¼ ìš°ì„ ì‹œí•´ì•¼ í•¨ì„ ë„ì „í•œë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸


- ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì€ ê³µê°œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìš°ìˆ˜í•œ ì„±ê³¼ë¥¼ ë³´ì´ì§€ë§Œ ì´ëŠ” ë°ì´í„°ì…‹ íŠ¹ì • í‘œë©´ ë‹¨ì„œì— ì§€ë‚˜ì¹˜ê²Œ ì˜ì¡´í•  ìˆ˜ ìˆìŒ

- Chameleon Benchmark Overfit Detector (C-BOD)ëŠ” ë²¤ì¹˜ë§ˆí¬ í”„ë¡¬í”„íŠ¸ë¥¼ ì™œê³¡ì‹œì¼œ LLMì˜ ì˜¤ë²„í”¼íŒ…ì„ ê°ì§€í•˜ëŠ” ë©”íƒ€í‰ê°€ í”„ë ˆì„ì›Œí¬ë¥¼ ì†Œê°œ

- C-BODëŠ” ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ì•”ê¸°ëœ íŒ¨í„´ì— ì˜í•´ ì£¼ë„ë˜ëŠ”ì§€ ë…¸ì¶œì‹œí‚¤ë©°, ëŒ€ë¶€ë¶„ì˜ ëª¨ë¸ì´ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì°¨ì´ë¥¼ ë³´ì„

- ë” í° LLMì¼ìˆ˜ë¡ rephrasingì— ë¯¼ê°í•  ê°€ëŠ¥ì„±ì´ ë†’ìœ¼ë©°, Llama íŒ¨ë°€ë¦¬ ë° ë‚®ì€ ê¸°ì¤€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ëª¨ë¸ì€ í‘œë©´ì ì¸ ë‹¨ì„œì— ëŒ€í•œ ì˜ì¡´ì„±ì´ ì¤„ì–´ë“¤ì—ˆë‹¤ê³  ì œì•ˆí•¨

- C-BODëŠ” ë°ì´í„°ì…‹ ë° ëª¨ë¸ì— ì¤‘ë¦½ì ì¸ ì„¤ê³„ë¡œ ê°•ê±´í•œ ì–¸ì–´ ì´í•´ë¥¼ ì´‰ì§„í•˜ê¸° ìœ„í•´ í›ˆë ¨ íŒŒì´í”„ë¼ì¸ì— ì‰½ê²Œ í†µí•©ë  ìˆ˜ ìˆìŒ.


---

*Generated on 2025-09-18 16:31:00*