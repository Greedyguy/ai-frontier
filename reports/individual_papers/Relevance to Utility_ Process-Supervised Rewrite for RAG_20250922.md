# Relevance to Utility: Process-Supervised Rewrite for RAG

**Korean Title:** ìœ ìš©ì„±ì— ëŒ€í•œ ê´€ë ¨ì„±: RAGë¥¼ ìœ„í•œ í”„ë¡œì„¸ìŠ¤ ê°ë… ì¬ì‘ì„±

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Efficient Distillation Pipeline

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Enhancing Retrieval Augmentation via Adversarial Collaboration_20250919|Enhancing Retrieval Augmentation via Adversarial Collaboration]] (86.1% similar)
- [[2025-09-19/ImpRAG_ Retrieval-Augmented Generation with Implicit Queries_20250919|ImpRAG Retrieval-Augmented Generation with Implicit Queries]] (85.7% similar)
- [[2025-09-19/AIP_ Subverting Retrieval-Augmented Generation via Adversarial Instructional Prompt_20250919|AIP Subverting Retrieval-Augmented Generation via Adversarial Instructional Prompt]] (85.5% similar)
- [[2025-09-19/GRADA_ Graph-based Reranking against Adversarial Documents Attack_20250919|GRADA Graph-based Reranking against Adversarial Documents Attack]] (85.3% similar)
- [[2025-09-19/Causal-Counterfactual RAG_ The Integration of Causal-Counterfactual Reasoning into RAG_20250919|Causal-Counterfactual RAG The Integration of Causal-Counterfactual Reasoning into RAG]] (84.5% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15577v1 Announce Type: cross 
Abstract: Retrieval-Augmented Generation systems often suffer from a gap between optimizing retrieval relevance and generative utility: retrieved documents may be topically relevant but still lack the content needed for effective reasoning during generation. While existing "bridge" modules attempt to rewrite the retrieved text for better generation, we show how they fail to capture true document utility. In this work, we propose R2U, with a key distinction of directly optimizing to maximize the probability of generating a correct answer through process supervision. As such direct observation is expensive, we also propose approximating an efficient distillation pipeline by scaling the supervision from LLMs, which helps the smaller rewriter model generalize better. We evaluate our method across multiple open-domain question-answering benchmarks. The empirical results demonstrate consistent improvements over strong bridging baselines.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15577v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ê²€ìƒ‰-ì¦ê°• ìƒì„± ì‹œìŠ¤í…œì€ ì¢…ì¢… ê²€ìƒ‰ ê´€ë ¨ì„±ê³¼ ìƒì„± ìœ ìš©ì„± ê°„ì˜ ê²©ì°¨ë¡œ ì¸í•´ ê³ í†µë°›ìŠµë‹ˆë‹¤. ê²€ìƒ‰ëœ ë¬¸ì„œëŠ” ì£¼ì œì ìœ¼ë¡œ ê´€ë ¨ì„±ì´ ìˆì„ ìˆ˜ ìˆì§€ë§Œ ìƒì„± ì¤‘ íš¨ê³¼ì ì¸ ì¶”ë¡ ì— í•„ìš”í•œ ë‚´ìš©ì„ ì—¬ì „íˆ ê²°ì—¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê¸°ì¡´ì˜ "ë¸Œë¦¬ì§€" ëª¨ë“ˆì€ ë” ë‚˜ì€ ìƒì„±ì„ ìœ„í•´ ê²€ìƒ‰ëœ í…ìŠ¤íŠ¸ë¥¼ ì¬ì‘ì„±í•˜ë ¤ê³  ì‹œë„í•˜ì§€ë§Œ, ìš°ë¦¬ëŠ” ì´ë“¤ì´ ì§„ì •í•œ ë¬¸ì„œ ìœ ìš©ì„±ì„ í¬ì°©í•˜ì§€ ëª»í•˜ëŠ” ë°©ì‹ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” R2Uë¥¼ ì œì•ˆí•˜ë©°, ì˜¬ë°”ë¥¸ ë‹µë³€ì„ ìƒì„±í•  í™•ë¥ ì„ ìµœëŒ€í™”í•˜ê¸° ìœ„í•´ í”„ë¡œì„¸ìŠ¤ ê°ë…ì„ í†µí•´ ì§ì ‘ ìµœì í™”í•˜ëŠ” ê²ƒì„ ì£¼ìš” ì°¨ë³„ì ìœ¼ë¡œ ì‚¼ìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì§ì ‘ ê´€ì°°ì€ ë¹„ìš©ì´ ë§ì´ ë“¤ê¸° ë•Œë¬¸ì—, ìš°ë¦¬ëŠ” ë˜í•œ LLMì—ì„œ ê°ë…ì„ í™•ì¥í•˜ì—¬ ë” ì‘ì€ ë¦¬ë¼ì´í„° ëª¨ë¸ì´ ë” ì˜ ì¼ë°˜í™”í•  ìˆ˜ ìˆë„ë¡ ë•ëŠ” íš¨ìœ¨ì ì¸ ì¦ë¥˜ íŒŒì´í”„ë¼ì¸ì„ ê·¼ì‚¬í•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì—¬ëŸ¬ ì˜¤í”ˆ ë„ë©”ì¸ ì§ˆë¬¸-ì‘ë‹µ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìš°ë¦¬ì˜ ë°©ë²•ì„ í‰ê°€í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼ëŠ” ê°•ë ¥í•œ ë¸Œë¦¬ì§€ ê¸°ì¤€ì„ ì„ ì´ˆê³¼í•˜ëŠ” ì¼ê´€ëœ ê°œì„ ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ê²€ìƒ‰ ê¸°ë°˜ ìƒì„± ì‹œìŠ¤í…œì˜ ë¬¸ì œì ì„ í•´ê²°í•˜ê¸° ìœ„í•´ R2Uë¼ëŠ” ìƒˆë¡œìš´ ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ "ë¸Œë¦¿ì§€" ëª¨ë“ˆì€ ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ë‚´ìš©ì„ ì¬ì‘ì„±í•˜ì—¬ ìƒì„±ì˜ íš¨ìš©ì„±ì„ ë†’ì´ë ¤ í•˜ì§€ë§Œ, ì‹¤ì œ ë¬¸ì„œì˜ ìœ ìš©ì„±ì„ ì œëŒ€ë¡œ ë°˜ì˜í•˜ì§€ ëª»í•©ë‹ˆë‹¤. R2UëŠ” ì •ë‹µ ìƒì„± í™•ë¥ ì„ ìµœëŒ€í™”í•˜ë„ë¡ ì§ì ‘ ìµœì í™”í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ ê°ë… ë°©ì‹ì„ ë„ì…í•˜ì—¬ ì´ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤. ë˜í•œ, ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì—ì„œ ê°ë…ì„ í™•ì¥í•˜ì—¬ íš¨ìœ¨ì ì¸ ì¦ë¥˜ íŒŒì´í”„ë¼ì¸ì„ ì œì•ˆí•¨ìœ¼ë¡œì¨ ì‘ì€ ì¬ì‘ì„± ëª¨ë¸ì˜ ì¼ë°˜í™” ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì—¬ëŸ¬ ì˜¤í”ˆ ë„ë©”ì¸ ì§ˆë¬¸-ì‘ë‹µ ë²¤ì¹˜ë§ˆí¬ì—ì„œ í‰ê°€í•œ ê²°ê³¼, R2UëŠ” ê¸°ì¡´ì˜ ê°•ë ¥í•œ ë¸Œë¦¿ì§€ ê¸°ë²•ë“¤ë³´ë‹¤ ì¼ê´€ëœ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Retrieval-Augmented Generation ì‹œìŠ¤í…œì€ ê²€ìƒ‰ ê´€ë ¨ì„±ê³¼ ìƒì„± ìœ ìš©ì„± ê°„ì˜ ê²©ì°¨ë¡œ ì¸í•´ ì–´ë ¤ì›€ì„ ê²ªìŠµë‹ˆë‹¤.

- 2. ê¸°ì¡´ì˜ "ë¸Œë¦¬ì§€" ëª¨ë“ˆì€ ê²€ìƒ‰ëœ í…ìŠ¤íŠ¸ë¥¼ ì¬ì‘ì„±í•˜ë ¤ í•˜ì§€ë§Œ, ë¬¸ì„œì˜ ì‹¤ì œ ìœ ìš©ì„±ì„ í¬ì°©í•˜ëŠ” ë° ì‹¤íŒ¨í•©ë‹ˆë‹¤.

- 3. R2UëŠ” ì •ë‹µì„ ìƒì„±í•  í™•ë¥ ì„ ìµœëŒ€í™”í•˜ê¸° ìœ„í•´ í”„ë¡œì„¸ìŠ¤ ê°ë…ì„ í†µí•´ ì§ì ‘ ìµœì í™”í•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤.

- 4. LLMsë¡œë¶€í„° ê°ë…ì„ í™•ì¥í•˜ì—¬ íš¨ìœ¨ì ì¸ ì¦ë¥˜ íŒŒì´í”„ë¼ì¸ì„ ê·¼ì‚¬í•¨ìœ¼ë¡œì¨ ì‘ì€ ì¬ì‘ì„± ëª¨ë¸ì´ ë” ì˜ ì¼ë°˜í™”í•  ìˆ˜ ìˆë„ë¡ ë•ìŠµë‹ˆë‹¤.

- 5. ì—¬ëŸ¬ ì˜¤í”ˆ ë„ë©”ì¸ ì§ˆë¬¸-ì‘ë‹µ ë²¤ì¹˜ë§ˆí¬ì—ì„œ í‰ê°€í•œ ê²°ê³¼, ê°•ë ¥í•œ ë¸Œë¦¬ì§€ ê¸°ì¤€ì„ ë³´ë‹¤ ì¼ê´€ëœ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

---

*Generated on 2025-09-22 14:03:55*