# Compose by Focus: Scene Graph-based Atomic Skills

**Korean Title:** í¬ì»¤ìŠ¤ì— ì˜í•œ êµ¬ì„±: ì¥ë©´ ê·¸ë˜í”„ ê¸°ë°˜ì˜ ì›ìì  ê¸°ìˆ 

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: Graph Neural Network, Vision Language Model

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Learning Discrete Abstractions for Visual Rearrangement Tasks Using Vision-Guided Graph Coloring_20250919|Learning Discrete Abstractions for Visual Rearrangement Tasks Using Vision-Guided Graph Coloring]] (82.5% similar)
- [[2025-09-19/CRAFT_ Coaching Reinforcement Learning Autonomously using Foundation Models for Multi-Robot Coordination Tasks_20250919|CRAFT Coaching Reinforcement Learning Autonomously using Foundation Models for Multi-Robot Coordination Tasks]] (82.2% similar)
- [[2025-09-19/Local-Canonicalization Equivariant Graph Neural Networks for Sample-Efficient and Generalizable Swarm Robot Control_20250919|Local-Canonicalization Equivariant Graph Neural Networks for Sample-Efficient and Generalizable Swarm Robot Control]] (81.9% similar)
- [[2025-09-18/textsc{Gen2Real}_ Towards Demo-Free Dexterous Manipulation by Harnessing Generated Video_20250918|textsc{Gen2Real} Towards Demo-Free Dexterous Manipulation by Harnessing Generated Video]] (81.1% similar)
- [[2025-09-19/ThinkAct_ Vision-Language-Action Reasoning via Reinforced Visual Latent Planning_20250919|ThinkAct Vision-Language-Action Reasoning via Reinforced Visual Latent Planning]] (80.7% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16053v1 Announce Type: cross 
Abstract: A key requirement for generalist robots is compositional generalization - the ability to combine atomic skills to solve complex, long-horizon tasks. While prior work has primarily focused on synthesizing a planner that sequences pre-learned skills, robust execution of the individual skills themselves remains challenging, as visuomotor policies often fail under distribution shifts induced by scene composition. To address this, we introduce a scene graph-based representation that focuses on task-relevant objects and relations, thereby mitigating sensitivity to irrelevant variation. Building on this idea, we develop a scene-graph skill learning framework that integrates graph neural networks with diffusion-based imitation learning, and further combine "focused" scene-graph skills with a vision-language model (VLM) based task planner. Experiments in both simulation and real-world manipulation tasks demonstrate substantially higher success rates than state-of-the-art baselines, highlighting improved robustness and compositional generalization in long-horizon tasks.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.16053v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ì¼ë°˜ì ì¸ ë¡œë´‡ì—ê²Œ ì¤‘ìš”í•œ ìš”êµ¬ ì‚¬í•­ ì¤‘ í•˜ë‚˜ëŠ” ì¡°í•©ì  ì¼ë°˜í™”(compositional generalization)ì…ë‹ˆë‹¤. ì´ëŠ” ì›ìì  ê¸°ìˆ ì„ ê²°í•©í•˜ì—¬ ë³µì¡í•˜ê³  ì¥ê¸°ì ì¸ ê³¼ì œë¥¼ í•´ê²°í•˜ëŠ” ëŠ¥ë ¥ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì´ì „ ì—°êµ¬ëŠ” ì£¼ë¡œ ì‚¬ì „ì— í•™ìŠµëœ ê¸°ìˆ ì„ ìˆœì„œëŒ€ë¡œ ë°°ì—´í•˜ëŠ” ê³„íšìë¥¼ í•©ì„±í•˜ëŠ” ë° ì¤‘ì ì„ ë‘ì—ˆì§€ë§Œ, ê°œë³„ ê¸°ìˆ ì˜ ê²¬ê³ í•œ ì‹¤í–‰ì€ ì—¬ì „íˆ ë„ì „ ê³¼ì œë¡œ ë‚¨ì•„ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ì¥ë©´ êµ¬ì„±ì— ì˜í•´ ìœ ë„ëœ ë¶„í¬ ë³€í™”ì—ì„œ ì‹œê°-ìš´ë™ ì •ì±…ì´ ì¢…ì¢… ì‹¤íŒ¨í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ìš°ë¦¬ëŠ” ê³¼ì œì™€ ê´€ë ¨ëœ ê°ì²´ì™€ ê´€ê³„ì— ì¤‘ì ì„ ë‘” ì¥ë©´ ê·¸ë˜í”„ ê¸°ë°˜ í‘œí˜„ì„ ë„ì…í•˜ì—¬ ê´€ë ¨ ì—†ëŠ” ë³€ë™ì— ëŒ€í•œ ë¯¼ê°ì„±ì„ ì™„í™”í•©ë‹ˆë‹¤. ì´ ì•„ì´ë””ì–´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ìš°ë¦¬ëŠ” ê·¸ë˜í”„ ì‹ ê²½ë§ê³¼ í™•ì‚° ê¸°ë°˜ ëª¨ë°© í•™ìŠµì„ í†µí•©í•œ ì¥ë©´ ê·¸ë˜í”„ ê¸°ìˆ  í•™ìŠµ í”„ë ˆì„ì›Œí¬ë¥¼ ê°œë°œí•˜ê³ , "ì§‘ì¤‘ëœ" ì¥ë©´ ê·¸ë˜í”„ ê¸°ìˆ ì„ ë¹„ì „-ì–¸ì–´ ëª¨ë¸(VLM) ê¸°ë°˜ ê³¼ì œ ê³„íšìì™€ ê²°í•©í•©ë‹ˆë‹¤. ì‹œë®¬ë ˆì´ì…˜ ë° ì‹¤ì œ ì¡°ì‘ ì‘ì—…ì—ì„œì˜ ì‹¤í—˜ì€ ìµœì²¨ë‹¨ ê¸°ì¤€ì„ ë³´ë‹¤ ìƒë‹¹íˆ ë†’ì€ ì„±ê³µë¥ ì„ ë³´ì—¬ì£¼ë©°, ì¥ê¸° ê³¼ì œì—ì„œì˜ í–¥ìƒëœ ê²¬ê³ ì„±ê³¼ ì¡°í•©ì  ì¼ë°˜í™”ë¥¼ ê°•ì¡°í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì¼ë°˜ ë¡œë´‡ì˜ ì¡°í•©ì  ì¼ë°˜í™” ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ì¥ë©´ ê·¸ë˜í”„ ê¸°ë°˜ì˜ í‘œí˜„ ë°©ì‹ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ëŠ” ê³¼ì œì™€ ê´€ë ¨ëœ ê°ì²´ì™€ ê´€ê³„ì— ì§‘ì¤‘í•˜ì—¬ ë¶ˆí•„ìš”í•œ ë³€ë™ì— ëŒ€í•œ ë¯¼ê°ì„±ì„ ì¤„ì…ë‹ˆë‹¤. ê·¸ë˜í”„ ì‹ ê²½ë§ê³¼ í™•ì‚° ê¸°ë°˜ ëª¨ë°© í•™ìŠµì„ í†µí•©í•œ ì¥ë©´ ê·¸ë˜í”„ ê¸°ìˆ  í•™ìŠµ í”„ë ˆì„ì›Œí¬ë¥¼ ê°œë°œí•˜ê³ , ì´ë¥¼ ë¹„ì „-ì–¸ì–´ ëª¨ë¸(VLM) ê¸°ë°˜ì˜ ì‘ì—… ê³„íšìì™€ ê²°í•©í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì‹œë®¬ë ˆì´ì…˜ ë° ì‹¤ì œ ì¡°ì‘ ì‘ì—…ì—ì„œ ìµœì²¨ë‹¨ ê¸°ì¤€ë³´ë‹¤ ë†’ì€ ì„±ê³µë¥ ì„ ë³´ì—¬ì£¼ë©°, ì¥ê¸° ì‘ì—…ì—ì„œì˜ ê°•ì¸ì„±ê³¼ ì¡°í•©ì  ì¼ë°˜í™”ê°€ ê°œì„ ë¨ì„ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì¼ë°˜ ë¡œë´‡ì˜ í•µì‹¬ ìš”êµ¬ ì‚¬í•­ì€ ì›ìì  ê¸°ìˆ ì„ ê²°í•©í•˜ì—¬ ë³µì¡í•œ ì¥ê¸° ê³¼ì œë¥¼ í•´ê²°í•˜ëŠ” ì¡°í•©ì  ì¼ë°˜í™” ëŠ¥ë ¥ì´ë‹¤.

- 2. ê¸°ì¡´ ì—°êµ¬ëŠ” ì£¼ë¡œ ì‚¬ì „ í•™ìŠµëœ ê¸°ìˆ ì„ ìˆœì°¨ì ìœ¼ë¡œ ê³„íší•˜ëŠ” ë° ì´ˆì ì„ ë§ì¶”ì—ˆìœ¼ë‚˜, ê°œë³„ ê¸°ìˆ ì˜ ê²¬ê³ í•œ ì‹¤í–‰ì€ ì—¬ì „íˆ ë„ì „ ê³¼ì œì´ë‹¤.

- 3. ì¥ë©´ ê·¸ë˜í”„ ê¸°ë°˜ í‘œí˜„ì„ ë„ì…í•˜ì—¬ ì‘ì—… ê´€ë ¨ ê°ì²´ì™€ ê´€ê³„ì— ì§‘ì¤‘í•¨ìœ¼ë¡œì¨ ë¶ˆí•„ìš”í•œ ë³€ë™ì— ëŒ€í•œ ë¯¼ê°ì„±ì„ ì™„í™”í•œë‹¤.

- 4. ê·¸ë˜í”„ ì‹ ê²½ë§ê³¼ í™•ì‚° ê¸°ë°˜ ëª¨ë°© í•™ìŠµì„ í†µí•©í•œ ì¥ë©´ ê·¸ë˜í”„ ê¸°ìˆ  í•™ìŠµ í”„ë ˆì„ì›Œí¬ë¥¼ ê°œë°œí•˜ê³ , ì‹œê°-ì–¸ì–´ ëª¨ë¸ ê¸°ë°˜ì˜ ì‘ì—… ê³„íšìì™€ ê²°í•©í•œë‹¤.

- 5. ì‹œë®¬ë ˆì´ì…˜ ë° ì‹¤ì œ ì¡°ì‘ ì‘ì—… ì‹¤í—˜ì—ì„œ ìµœì²¨ë‹¨ ê¸°ì¤€ë³´ë‹¤ ë†’ì€ ì„±ê³µë¥ ì„ ë³´ì—¬ ì¥ê¸° ê³¼ì œì—ì„œì˜ í–¥ìƒëœ ê²¬ê³ ì„±ê³¼ ì¡°í•©ì  ì¼ë°˜í™”ë¥¼ ê°•ì¡°í•œë‹¤.

---

*Generated on 2025-09-22 14:23:21*