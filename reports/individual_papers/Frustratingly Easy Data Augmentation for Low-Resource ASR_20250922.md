# Frustratingly Easy Data Augmentation for Low-Resource ASR

**Korean Title:** ì €ìì›ì´ ì ì€ ASRë¥¼ ìœ„í•œ ì¢Œì ˆìŠ¤ëŸ½ë„ë¡ ì‰¬ìš´ ë°ì´í„° ì¦ê°•

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[reports/digests/daily_digest_20250922|2025-09-22]] [[keywords/evolved/Low-resource ASR|Low-resource ASR]] [[keywords/specific/Data Augmentation|Data Augmentation]] [[keywords/broad/Automatic Speech Recognition|Automatic Speech Recognition]] [[keywords/broad/Text-to-Speech|Text-to-Speech]] [[keywords/unique/Gloss-based Replacement|Gloss-based Replacement]] [[categories/cs.CL|cs.CL]] [[2025-09-22/AS-ASR_ A Lightweight Framework for Aphasia-Specific Automatic Speech Recognition_20250922|AS-ASR: A Lightweight Framework for Aphasia-Specific Automatic Speech Recognition]] (84.0% similar) [[2025-09-22/Exploring Fine-Tuning of Large Audio Language Models for Spoken Language Understanding under Limited Speech data_20250922|Exploring Fine-Tuning of Large Audio Language Models for Spoken Language Understanding under Limited Speech data]] (82.9% similar) [[2025-09-19/Listening, Imagining & Refining_ A Heuristic Optimized ASR Correction Framework with LLMs_20250919|Listening, Imagining \& Refining: A Heuristic Optimized ASR Correction Framework with LLMs]] (82.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: Data Augmentation
**ğŸ”¬ Broad Technical**: Automatic Speech Recognition, Text-to-Speech
**â­ Unique Technical**: Gloss-based Replacement
## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/AS-ASR_ A Lightweight Framework for Aphasia-Specific Automatic Speech Recognition_20250922|AS-ASR A Lightweight Framework for Aphasia-Specific Automatic Speech Recognition]] (84.0% similar)
- [[2025-09-22/Exploring Fine-Tuning of Large Audio Language Models for Spoken Language Understanding under Limited Speech data_20250922|Exploring Fine-Tuning of Large Audio Language Models for Spoken Language Understanding under Limited Speech data]] (82.9% similar)
- [[2025-09-19/Listening, Imagining & Refining_ A Heuristic Optimized ASR Correction Framework with LLMs_20250919|Listening, Imagining & Refining A Heuristic Optimized ASR Correction Framework with LLMs]] (82.2% similar)
- [[2025-09-17/Exploring Data and Parameter Efficient Strategies for Arabic Dialect Identifications_20250917|Exploring Data and Parameter Efficient Strategies for Arabic Dialect Identifications]] (81.3% similar)
- [[2025-09-22/mucAI at BAREC Shared Task 2025_ Towards Uncertainty Aware Arabic Readability Assessment_20250922|mucAI at BAREC Shared Task 2025 Towards Uncertainty Aware Arabic Readability Assessment]] (81.2% similar)


**ArXiv ID**: [2509.15373](https://arxiv.org/abs/2509.15373)
**Published**: 2025-09-22
**Category**: cs.CL
**PDF**: [Download](https://arxiv.org/pdf/2509.15373.pdf)


**ArXiv ID**: [2509.15373](https://arxiv.org/abs/2509.15373)
**Published**: 2025-09-22
**Category**: cs.CL
**PDF**: [Download](https://arxiv.org/pdf/2509.15373.pdf)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: Data Augmentation, Wav2Vec2-XLSR-53
**â­ Unique Technical**: Gloss-based Replacement
**ğŸ”¬ Broad Technical**: Automatic Speech Recognition, Text-to-Speech

## ğŸ·ï¸ ì¶”ì¶œëœ í‚¤ì›Œë“œ



`Automatic Speech Recognition` â€¢ 

`Text-to-Speech` â€¢ 

`Data Augmentation` â€¢ 

`Gloss-based Replacement` â€¢ 

`Low-resource ASR`



## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸

Similar papers will be displayed here based on embedding similarity.

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15373v1 Announce Type: new 
Abstract: This paper introduces three self-contained data augmentation methods for low-resource Automatic Speech Recognition (ASR). Our techniques first generate novel text--using gloss-based replacement, random replacement, or an LLM-based approach--and then apply Text-to-Speech (TTS) to produce synthetic audio. We apply these methods, which leverage only the original annotated data, to four languages with extremely limited resources (Vatlongos, Nashta, Shinekhen Buryat, and Kakabe). Fine-tuning a pretrained Wav2Vec2-XLSR-53 model on a combination of the original audio and generated synthetic data yields significant performance gains, including a 14.3% absolute WER reduction for Nashta. The methods prove effective across all four low-resource languages and also show utility for high-resource languages like English, demonstrating their broad applicability.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15373v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: ì´ ë…¼ë¬¸ì€ ìì›ì´ ë¶€ì¡±í•œ ìë™ ìŒì„± ì¸ì‹(ASR)ì„ ìœ„í•œ ì„¸ ê°€ì§€ ë…ë¦½ì ì¸ ë°ì´í„° ì¦ê°• ë°©ë²•ì„ ì†Œê°œí•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ê¸°ë²•ì€ ë¨¼ì € ê¸€ë¡œìŠ¤ ê¸°ë°˜ ëŒ€ì²´, ë¬´ì‘ìœ„ ëŒ€ì²´, ë˜ëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM) ê¸°ë°˜ ì ‘ê·¼ ë°©ì‹ì„ ì‚¬ìš©í•˜ì—¬ ìƒˆë¡œìš´ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•œ ë‹¤ìŒ, í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜(TTS)í•˜ì—¬ í•©ì„± ì˜¤ë””ì˜¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì´ëŸ¬í•œ ë°©ë²•ì„ ì›ë˜ ì£¼ì„ì´ ë‹¬ë¦° ë°ì´í„°ë§Œì„ í™œìš©í•˜ì—¬ ìì›ì´ ê·¹íˆ ì œí•œëœ ë„¤ ê°œì˜ ì–¸ì–´(Vatlongos, Nashta, Shinekhen Buryat, Kakabe)ì— ì ìš©í•©ë‹ˆë‹¤. ì›ë³¸ ì˜¤ë””ì˜¤ì™€ ìƒì„±ëœ í•©ì„± ë°ì´í„°ë¥¼ ê²°í•©í•˜ì—¬ ì‚¬ì „ í•™ìŠµëœ Wav2Vec2-XLSR-53 ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•œ ê²°ê³¼, Nashta ì–¸ì–´ì—ì„œ 14.3%ì˜ ì ˆëŒ€ WER ê°ì†Œë¥¼ í¬í•¨í•˜ì—¬ ìƒë‹¹í•œ ì„±ëŠ¥ í–¥ìƒì„ ì–»ì—ˆìŠµë‹ˆë‹¤. ì´ ë°©ë²•ë“¤ì€ ë„¤ ê°œì˜ ìì› ë¶€ì¡± ì–¸ì–´ ëª¨ë‘ì— íš¨ê³¼ì ì´ë©°, ì˜ì–´ì™€ ê°™ì€ ìì›ì´ í’ë¶€í•œ ì–¸ì–´ì—ë„ ìœ ìš©ì„±ì„ ë³´ì—¬ì£¼ì–´ ê´‘ë²”ìœ„í•œ ì ìš© ê°€ëŠ¥ì„±ì„ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ìì›ì´ ë¶€ì¡±í•œ ìë™ ìŒì„± ì¸ì‹ì„ ìœ„í•œ ì„¸ ê°€ì§€ ë°ì´í„° ì¦ê°• ë°©ë²•ì„ ì†Œê°œí•©ë‹ˆë‹¤. ì´ ë°©ë²•ë“¤ì€ ìƒˆë¡œìš´ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•œ í›„, ì´ë¥¼ ìŒì„± í•©ì„±(TTS)ì„ í†µí•´ ì˜¤ë””ì˜¤ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ë„¤ ê°€ì§€ ìì›ì´ ë§¤ìš° ì œí•œëœ ì–¸ì–´(Vatlongos, Nashta, Shinekhen Buryat, Kakabe)ì— ì ìš©í•œ ê²°ê³¼, ì‚¬ì „ í•™ìŠµëœ Wav2Vec2-XLSR-53 ëª¨ë¸ì„ ì›ë³¸ ì˜¤ë””ì˜¤ì™€ í•©ì„± ë°ì´í„°ë¥¼ ê²°í•©í•˜ì—¬ ë¯¸ì„¸ ì¡°ì •í•˜ë©´ ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤. íŠ¹íˆ Nashta ì–¸ì–´ì˜ ê²½ìš° 14.3%ì˜ ì ˆëŒ€ WER ê°ì†Œë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤. ì´ ë°©ë²•ë“¤ì€ ëª¨ë“  ì €ìì› ì–¸ì–´ì—ì„œ íš¨ê³¼ì ì´ë©°, ì˜ì–´ì™€ ê°™ì€ ê³ ìì› ì–¸ì–´ì—ë„ ì ìš© ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸


- 1. ë³¸ ë…¼ë¬¸ì€ ì €ìë“¤ì´ ì œì•ˆí•œ ì„¸ ê°€ì§€ ë…ë¦½ì ì¸ ë°ì´í„° ì¦ê°• ê¸°ë²•ì„ í†µí•´ ì €ìì›ì´ ìë™ ìŒì„± ì¸ì‹(ASR) ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë°©ë²•ì„ ì†Œê°œí•©ë‹ˆë‹¤.

- 2. ì œì•ˆëœ ê¸°ë²•ì€ ê¸€ë¡œìŠ¤ ê¸°ë°˜ ëŒ€ì²´, ë¬´ì‘ìœ„ ëŒ€ì²´, LLM ê¸°ë°˜ ì ‘ê·¼ë²•ì„ ì‚¬ìš©í•˜ì—¬ ìƒˆë¡œìš´ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ê³ , ì´ë¥¼ í…ìŠ¤íŠ¸-ìŒì„± ë³€í™˜(TTS)ìœ¼ë¡œ í•©ì„± ì˜¤ë””ì˜¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

- 3. ì´ ë°©ë²•ë“¤ì€ ì œí•œëœ ìì›ì„ ê°€ì§„ ë„¤ ê°œì˜ ì–¸ì–´(Vatlongos, Nashta, Shinekhen Buryat, Kakabe)ì— ì ìš©ë˜ë©°, Nashta ì–¸ì–´ì—ì„œ 14.3%ì˜ ì ˆëŒ€ WER ê°ì†Œë¥¼ í¬í•¨í•œ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

- 4. ì œì•ˆëœ ê¸°ë²•ì€ ì €ìì› ì–¸ì–´ë¿ë§Œ ì•„ë‹ˆë¼ ì˜ì–´ì™€ ê°™ì€ ê³ ìì› ì–¸ì–´ì—ë„ íš¨ê³¼ì ì´ë©°, ê´‘ë²”ìœ„í•œ ì ìš© ê°€ëŠ¥ì„±ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.


---

*Generated on 2025-09-22 16:20:52*