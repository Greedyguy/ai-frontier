
# COMI-LINGUA: Expert Annotated Large-Scale Dataset for Multitask NLP in Hindi-English Code-Mixing

**Korean Title:** COMI-LINGUA: 힌디어-영어 코드 혼용에서의 다중 작업 NLP를 위한 전문 주석 대규모 데이터셋 유지하기.

## 📋 메타데이터

**Links**: [[daily/2025-09-18|2025-09-18]] [[keywords/evolved/One-shot Prompting|One-shot Prompting]] [[keywords/broad/LLMs|LLMs]] [[keywords/broad/Machine Translation|Machine Translation]] [[keywords/specific/Zero-shot Learning|Zero-shot Learning]] [[keywords/unique/COMI-LINGUA|COMI-LINGUA]] [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: One-shot Prompting
**🔬 Broad Technical**: LLM, Machine Translation
**🔗 Specific Connectable**: Zero-shot Learning
**⭐ Unique Technical**: COMI-LINGUA

**ArXiv ID**: [2503.21670](https://arxiv.org/abs/2503.21670)
**Published**: 2025-09-18
**Category**: cs.AI
**PDF**: [Download](https://arxiv.org/pdf/2503.21670.pdf)


## 🏷️ 추출된 키워드



`LLM` • 

`Machine Translation` • 

`Zero-shot Learning` • 

`COMI-LINGUA` • 

`One-shot Prompting`



## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2503.21670v3 Announce Type: replace-cross 
Abstract: We introduce COMI-LINGUA, the largest manually annotated Hindi-English code-mixed dataset, comprising 125K+ high-quality instances across five core NLP tasks: Matrix Language Identification, Token-level Language Identification, Part-Of-Speech Tagging, Named Entity Recognition, and Machine Translation. Each instance is annotated by three bilingual annotators, yielding over 376K expert annotations with strong inter-annotator agreement (Fleiss' Kappa $\geq$ 0.81). The rigorously preprocessed and filtered dataset covers both Devanagari and Roman scripts and spans diverse domains, ensuring real-world linguistic coverage. Evaluation reveals that closed-source LLMs significantly outperform traditional tools and open-source models in zero-shot settings. Notably, one-shot prompting consistently boosts performance across tasks, especially in structure-sensitive predictions like POS and NER. Fine-tuning state-of-the-art LLMs on COMI-LINGUA demonstrates substantial improvements, achieving up to 95.25 F1 in NER, 98.77 F1 in MLI, and competitive MT performance, setting new benchmarks for Hinglish code-mixed text. COMI-LINGUA is publicly available at this URL: https://huggingface.co/datasets/LingoIITGN/COMI-LINGUA.

## 🔍 Abstract (한글 번역)

arXiv:2503.21670v3 발표 유형: 대체-교차
요약: 우리는 COMI-LINGUA를 소개합니다. 이는 125K개 이상의 고품질 인스턴스로 구성된 가장 큰 수동 주석이 달린 힌디어-영어 혼합 코드 데이터셋으로, 행렬 언어 식별, 토큰 수준 언어 식별, 품사 태깅, 명명된 개체 인식 및 기계 번역의 다섯 가지 핵심 NLP 작업에 걸쳐 있습니다. 각 인스턴스는 세 명의 이중 어노테이터에 의해 주석이 달려 있으며, 강한 상호 어노테이터 합의(Fleiss' Kappa $\geq$ 0.81)를 통해 376K개 이상의 전문가 주석이 생성되었습니다. 엄격하게 전처리 및 필터링된 데이터셋은 데바나가리 및 로만 문자를 모두 다루며 다양한 도메인을 포괄하여 현실 세계 언어적 커버리지를 보장합니다. 평가 결과, 폐쇄형 LLM은 영 제로샷 환경에서 전통적인 도구 및 오픈 소스 모델을 크게 능가합니다. 특히, 원샷 프롬프팅은 POS 및 NER과 같은 구조에 민감한 예측에서 작업 전반에 걸쳐 성능을 일관되게 향상시킵니다. COMI-LINGUA에서 최첨단 LLM을 세밀하게 조정하면, NER에서 최대 95.25 F1, MLI에서 98.77 F1 및 경쟁력 있는 MT 성능을 달성하여, Hinglish 혼합 코드 텍스트에 대한 새로운 기준을 설정합니다. COMI-LINGUA는 다음 URL에서 공개적으로 이용 가능합니다: https://huggingface.co/datasets/LingoIITGN/COMI-LINGUA.

## 📝 요약

COMI-LINGUA는 힌디어-영어 혼합코드 최대 수동 주석 데이터셋으로, 5가지 핵심 NLP 작업에 대해 125K+ 고품질 인스턴스를 포함하고 있습니다. 각 인스턴스는 세 명의 이중 어노테이터에 의해 주석이 달려 있으며, 강한 상호 어노테이터 합의(Fleiss' Kappa ≥ 0.81)를 보여주는 376K개의 전문 주석을 제공합니다. COMI-LINGUA는 Devanagari 및 로만 문자를 모두 다루며 다양한 도메인을 포함하여 현실 세계 언어학적 커버리지를 보장합니다. 평가 결과, 닫힌 소스 LLMs는 영 제로샷 설정에서 전통적인 도구와 오픈 소스 모델보다 우수한 성능을 보입니다. COMI-LINGUA를 사용한 최첨단 LLMs의 파인튜닝은 NER에서 최대 95.25 F1, MLI에서 98.77 F1 및 경쟁력 있는 MT 성능을 달성하여 Hinglish 혼합 텍스트에 대한 새로운 기준을 제시합니다.

## 🎯 주요 포인트


- 1. COMI-LINGUA는 힌디어-영어 코드 혼합 데이터셋으로, 5가지 핵심 NLP 작업에 대해 125K+ 고품질 인스턴스를 포함하고 있습니다.

- 2. 각 인스턴스는 세 명의 이중 어노테이터에 의해 주석이 달려 있으며, 강한 상호 어노테이터 합의를 가진 376K개의 전문 주석이 있습니다.

- 3. 평가 결과, LLMs는 영점 샷 설정에서 전통적인 도구와 오픈 소스 모델보다 우수한 성능을 보이며, 한 번의 프롬프팅은 특히 POS 및 NER과 같은 구조에 민감한 예측에서 성능을 꾸준히 향상시킵니다.


---

*Generated on 2025-09-18 16:32:03*