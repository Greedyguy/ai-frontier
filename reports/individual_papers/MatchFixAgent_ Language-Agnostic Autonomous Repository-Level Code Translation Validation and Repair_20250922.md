# MatchFixAgent: Language-Agnostic Autonomous Repository-Level Code Translation Validation and Repair

**Korean Title:** MatchFixAgent: ì–¸ì–´ ë¹„ì¢…ì†ì  ììœ¨ ì €ì¥ì†Œ ìˆ˜ì¤€ ì½”ë“œ ë²ˆì—­ ê²€ì¦ ë° ìˆ˜ë¦¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[reports/digests/daily_digest_20250922|2025-09-22]] [[keywords/evolved/Multi-agent Architecture|Multi-agent Architecture]] [[keywords/specific/Equivalence Validation|Equivalence Validation]] [[keywords/specific/Code Translation|Code Translation]] [[keywords/broad/Large Language Model|Large Language Model]] [[keywords/unique/MatchFixAgent|MatchFixAgent]] [[categories/cs.LG|cs.LG]] [[2025-09-18/Semantic Alignment-Enhanced Code Translation via an LLM-Based Multi-Agent System_20250918|Semantic Alignment-Enhanced Code Translation via an LLM-Based Multi-Agent System]] (86.4% similar) [[2025-09-19/RulER_ Automated Rule-Based Semantic Error Localization and Repair for Code Translation_20250919|RulER: Automated Rule-Based Semantic Error Localization and Repair for Code Translation]] (84.0% similar) [[2025-09-19/On the Use of Agentic Coding_ An Empirical Study of Pull Requests on GitHub_20250919|On the Use of Agentic Coding: An Empirical Study of Pull Requests on GitHub]] (81.4% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Multi-agent Architecture
**ğŸ”— Specific Connectable**: Equivalence Validation
**ğŸ”¬ Broad Technical**: Large Language Model
**â­ Unique Technical**: MatchFixAgent
## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/Semantic Alignment-Enhanced Code Translation via an LLM-Based Multi-Agent System_20250918|Semantic Alignment-Enhanced Code Translation via an LLM-Based Multi-Agent System]] (86.4% similar)
- [[2025-09-19/RulER_ Automated Rule-Based Semantic Error Localization and Repair for Code Translation_20250919|RulER Automated Rule-Based Semantic Error Localization and Repair for Code Translation]] (84.0% similar)
- [[2025-09-19/On the Use of Agentic Coding_ An Empirical Study of Pull Requests on GitHub_20250919|On the Use of Agentic Coding An Empirical Study of Pull Requests on GitHub]] (81.4% similar)
- [[2025-09-19/Translate, then Detect_ Leveraging Machine Translation for Cross-Lingual Toxicity Classification_20250919|Translate, then Detect Leveraging Machine Translation for Cross-Lingual Toxicity Classification]] (80.4% similar)
- [[2025-09-19/Ticket-Bench_ A Kickoff for Multilingual and Regionalized Agent Evaluation_20250919|Ticket-Bench A Kickoff for Multilingual and Regionalized Agent Evaluation]] (80.3% similar)


**ArXiv ID**: [2509.16187](https://arxiv.org/abs/2509.16187)
**Published**: 2025-09-22
**Category**: cs.LG
**PDF**: [Download](https://arxiv.org/pdf/2509.16187.pdf)


**ArXiv ID**: [2509.16187](https://arxiv.org/abs/2509.16187)
**Published**: 2025-09-22
**Category**: cs.LG
**PDF**: [Download](https://arxiv.org/pdf/2509.16187.pdf)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Multi-agent Architecture
**ğŸ”— Specific Connectable**: Equivalence Validation, Translation Repair
**â­ Unique Technical**: MatchFixAgent
**ğŸ”¬ Broad Technical**: Large Language Model

## ğŸ·ï¸ ì¶”ì¶œëœ í‚¤ì›Œë“œ



`Large Language Model` â€¢ 

`Equivalence Validation` â€¢ 

`MatchFixAgent` â€¢ 

`Multi-agent Architecture`



## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸

Similar papers will be displayed here based on embedding similarity.

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16187v1 Announce Type: cross 
Abstract: Code translation transforms source code from one programming language (PL) to another. Validating the functional equivalence of translation and repairing, if necessary, are critical steps in code translation. Existing automated validation and repair approaches struggle to generalize to many PLs due to high engineering overhead, and they rely on existing and often inadequate test suites, which results in false claims of equivalence and ineffective translation repair. We develop MatchFixAgent, a large language model (LLM)-based, PL-agnostic framework for equivalence validation and repair of translations. MatchFixAgent features a multi-agent architecture that divides equivalence validation into several sub-tasks to ensure thorough and consistent semantic analysis of the translation. Then it feeds this analysis to test agent to write and execute tests. Upon observing a test failure, the repair agent attempts to fix the translation bug. The final (in)equivalence decision is made by the verdict agent, considering semantic analyses and test execution results.
  We compare MatchFixAgent's validation and repair results with four repository-level code translation techniques. We use 2,219 translation pairs from their artifacts, which cover 6 PL pairs, and are collected from 24 GitHub projects totaling over 900K lines of code. Our results demonstrate that MatchFixAgent produces (in)equivalence verdicts for 99.2% of translation pairs, with the same equivalence validation result as prior work on 72.8% of them. When MatchFixAgent's result disagrees with prior work, we find that 60.7% of the time MatchFixAgent's result is actually correct. In addition, we show that MatchFixAgent can repair 50.6% of inequivalent translation, compared to prior work's 18.5%. This demonstrates that MatchFixAgent is far more adaptable to many PL pairs than prior work, while producing highly accurate validation results.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.16187v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ì½”ë“œ ë²ˆì—­ì€ ì†ŒìŠ¤ ì½”ë“œë¥¼ í•˜ë‚˜ì˜ í”„ë¡œê·¸ë˜ë° ì–¸ì–´(PL)ì—ì„œ ë‹¤ë¥¸ ì–¸ì–´ë¡œ ë³€í™˜í•˜ëŠ” ì‘ì—…ì…ë‹ˆë‹¤. ë²ˆì—­ì˜ ê¸°ëŠ¥ì  ë™ë“±ì„±ì„ ê²€ì¦í•˜ê³  í•„ìš”í•œ ê²½ìš° ìˆ˜ì •í•˜ëŠ” ê²ƒì€ ì½”ë“œ ë²ˆì—­ì—ì„œ ì¤‘ìš”í•œ ë‹¨ê³„ì…ë‹ˆë‹¤. ê¸°ì¡´ì˜ ìë™í™”ëœ ê²€ì¦ ë° ìˆ˜ì • ì ‘ê·¼ë²•ì€ ë†’ì€ ì—”ì§€ë‹ˆì–´ë§ ë¶€ë‹´ìœ¼ë¡œ ì¸í•´ ë§ì€ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì— ì¼ë°˜í™”í•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªìœ¼ë©°, ê¸°ì¡´ì˜ ë¶ˆì¶©ë¶„í•œ í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ì— ì˜ì¡´í•˜ì—¬ ë™ë“±ì„±ì— ëŒ€í•œ ì˜ëª»ëœ ì£¼ì¥ê³¼ ë¹„íš¨ìœ¨ì ì¸ ë²ˆì—­ ìˆ˜ì •ì„ ì´ˆë˜í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ë²ˆì—­ì˜ ë™ë“±ì„± ê²€ì¦ ë° ìˆ˜ì •ì„ ìœ„í•œ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM) ê¸°ë°˜ì˜ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì— êµ¬ì• ë°›ì§€ ì•ŠëŠ” í”„ë ˆì„ì›Œí¬ì¸ MatchFixAgentë¥¼ ê°œë°œí–ˆìŠµë‹ˆë‹¤. MatchFixAgentëŠ” ë²ˆì—­ì˜ ì² ì €í•˜ê³  ì¼ê´€ëœ ì˜ë¯¸ ë¶„ì„ì„ ë³´ì¥í•˜ê¸° ìœ„í•´ ë™ë“±ì„± ê²€ì¦ì„ ì—¬ëŸ¬ í•˜ìœ„ ì‘ì—…ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì•„í‚¤í…ì²˜ë¥¼ íŠ¹ì§•ìœ¼ë¡œ í•©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ ì´ ë¶„ì„ì„ í…ŒìŠ¤íŠ¸ ì—ì´ì „íŠ¸ì— ì „ë‹¬í•˜ì—¬ í…ŒìŠ¤íŠ¸ë¥¼ ì‘ì„±í•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ê°€ ê´€ì°°ë˜ë©´ ìˆ˜ì • ì—ì´ì „íŠ¸ê°€ ë²ˆì—­ ë²„ê·¸ë¥¼ ìˆ˜ì •í•˜ë ¤ê³  ì‹œë„í•©ë‹ˆë‹¤. ìµœì¢… ë™ë“±ì„± ì—¬ë¶€ ê²°ì •ì€ ì˜ë¯¸ ë¶„ì„ê³¼ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ê²°ê³¼ë¥¼ ê³ ë ¤í•˜ì—¬ íŒê²° ì—ì´ì „íŠ¸ì— ì˜í•´ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.  
ìš°ë¦¬ëŠ” MatchFixAgentì˜ ê²€ì¦ ë° ìˆ˜ì • ê²°ê³¼ë¥¼ ë„¤ ê°€ì§€ ì €ì¥ì†Œ ìˆ˜ì¤€ ì½”ë“œ ë²ˆì—­ ê¸°ìˆ ê³¼ ë¹„êµí–ˆìŠµë‹ˆë‹¤. 6ê°œì˜ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ ìŒì„ ë‹¤ë£¨ê³ , 24ê°œì˜ GitHub í”„ë¡œì íŠ¸ì—ì„œ ì´ 90ë§Œ ì¤„ ì´ìƒì˜ ì½”ë“œì—ì„œ ìˆ˜ì§‘ëœ 2,219ê°œì˜ ë²ˆì—­ ìŒì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. ìš°ë¦¬ì˜ ê²°ê³¼ëŠ” MatchFixAgentê°€ ë²ˆì—­ ìŒì˜ 99.2%ì— ëŒ€í•´ ë™ë“±ì„± ì—¬ë¶€ë¥¼ íŒê²°í•˜ë©°, ê·¸ ì¤‘ 72.8%ëŠ” ì´ì „ ì—°êµ¬ì™€ ë™ì¼í•œ ë™ë“±ì„± ê²€ì¦ ê²°ê³¼ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. MatchFixAgentì˜ ê²°ê³¼ê°€ ì´ì „ ì—°êµ¬ì™€ ì¼ì¹˜í•˜ì§€ ì•Šì„ ë•Œ, 60.7%ì˜ ê²½ìš° MatchFixAgentì˜ ê²°ê³¼ê°€ ì‹¤ì œë¡œ ì˜¬ë°”ë¥´ë‹¤ëŠ” ê²ƒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, MatchFixAgentëŠ” ì´ì „ ì—°êµ¬ì˜ 18.5%ì— ë¹„í•´ 50.6%ì˜ ë¹„ë™ë“± ë²ˆì—­ì„ ìˆ˜ì •í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŠ” MatchFixAgentê°€ ë§ì€ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ ìŒì— ëŒ€í•´ ì´ì „ ì—°êµ¬ë³´ë‹¤ í›¨ì”¬ ë” ì ì‘ë ¥ì´ ë›°ì–´ë‚˜ë©°, ë†’ì€ ì •í™•ë„ì˜ ê²€ì¦ ê²°ê³¼ë¥¼ ìƒì„±í•¨ì„ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì½”ë“œ ë²ˆì—­ì˜ ê¸°ëŠ¥ì  ë™ë“±ì„±ì„ ê²€ì¦í•˜ê³  í•„ìš” ì‹œ ìˆ˜ì •í•˜ëŠ” ìƒˆë¡œìš´ ë°©ë²•ë¡ ì¸ MatchFixAgentë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. MatchFixAgentëŠ” í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì— êµ¬ì• ë°›ì§€ ì•ŠëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ê¸°ë°˜ì˜ í”„ë ˆì„ì›Œí¬ë¡œ, ë‹¤ì¤‘ ì—ì´ì „íŠ¸ êµ¬ì¡°ë¥¼ í†µí•´ ë²ˆì—­ì˜ ì˜ë¯¸ ë¶„ì„ì„ ì„¸ë¶„í™”í•˜ì—¬ ì² ì €í•œ ê²€ì¦ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ ì—ì´ì „íŠ¸ê°€ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ê³ , ì‹¤íŒ¨ ì‹œ ìˆ˜ì • ì—ì´ì „íŠ¸ê°€ ë²ˆì—­ ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤. ìµœì¢… íŒë‹¨ì€ íŒê²° ì—ì´ì „íŠ¸ê°€ ë‚´ë¦½ë‹ˆë‹¤. 6ê°œì˜ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ ìŒì„ í¬í•¨í•œ 2,219ê°œì˜ ë²ˆì—­ ìŒì„ ëŒ€ìƒìœ¼ë¡œ í•œ ì‹¤í—˜ì—ì„œ MatchFixAgentëŠ” 99.2%ì˜ ë²ˆì—­ ìŒì— ëŒ€í•´ ë™ë“±ì„± ì—¬ë¶€ë¥¼ íŒë‹¨í–ˆìœ¼ë©°, ê¸°ì¡´ ê¸°ë²•ë³´ë‹¤ 60.7% ë” ì •í™•í•œ ê²°ê³¼ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤. ë˜í•œ, MatchFixAgentëŠ” ê¸°ì¡´ ê¸°ë²•ë³´ë‹¤ 50.6% ë” ë§ì€ ë¹„ë™ë“± ë²ˆì—­ì„ ì„±ê³µì ìœ¼ë¡œ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” MatchFixAgentê°€ ë‹¤ì–‘í•œ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ ìŒì— ë” ì ì‘ë ¥ì´ ë›°ì–´ë‚˜ê³  ë†’ì€ ì •í™•ë„ì˜ ê²€ì¦ ê²°ê³¼ë¥¼ ì œê³µí•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸


- 1. MatchFixAgentëŠ” í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì— êµ¬ì• ë°›ì§€ ì•ŠëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ê¸°ë°˜ì˜ ë²ˆì—­ ë“±ê°€ì„± ê²€ì¦ ë° ìˆ˜ì •ì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.

- 2. MatchFixAgentëŠ” ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì•„í‚¤í…ì²˜ë¥¼ í†µí•´ ë²ˆì—­ì˜ ì² ì €í•˜ê³  ì¼ê´€ëœ ì˜ë¯¸ ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³ , í…ŒìŠ¤íŠ¸ ì—ì´ì „íŠ¸ë¥¼ í†µí•´ í…ŒìŠ¤íŠ¸ë¥¼ ì‘ì„± ë° ì‹¤í–‰í•©ë‹ˆë‹¤.

- 3. MatchFixAgentëŠ” 2,219ê°œì˜ ë²ˆì—­ ìŒì„ ëŒ€ìƒìœ¼ë¡œ 99.2%ì˜ ë²ˆì—­ ìŒì— ëŒ€í•´ (ë¹„)ë“±ê°€ì„± íŒê²°ì„ ë‚´ë ¸ìœ¼ë©°, ì´ì „ ì—°êµ¬ì™€ 72.8%ì˜ ì¼ì¹˜ìœ¨ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

- 4. MatchFixAgentëŠ” ì´ì „ ì—°êµ¬ë³´ë‹¤ 50.6%ì˜ ë¹„ë“±ê°€ ë²ˆì—­ì„ ìˆ˜ì •í•  ìˆ˜ ìˆìœ¼ë©°, ì´ëŠ” ì´ì „ ì—°êµ¬ì˜ 18.5%ì™€ ë¹„êµí•˜ì—¬ í›¨ì”¬ ë†’ì€ ìˆ˜ì • ëŠ¥ë ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

- 5. MatchFixAgentëŠ” ë‹¤ì–‘í•œ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ ìŒì— ëŒ€í•´ ë†’ì€ ì ì‘ì„±ì„ ê°€ì§€ë©°, ë§¤ìš° ì •í™•í•œ ê²€ì¦ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.


---

*Generated on 2025-09-22 15:48:34*