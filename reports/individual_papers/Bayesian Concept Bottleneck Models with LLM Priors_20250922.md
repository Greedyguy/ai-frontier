# Bayesian Concept Bottleneck Models with LLM Priors

**Korean Title:** ë² ì´ì§€ì•ˆ ê°œë… ë³‘ëª© ëª¨ë¸ê³¼ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ ì‚¬ì „ ë¶„í¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Interpretability Accuracy Tradeoff

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/EnCoBo_ Energy-Guided Concept Bottlenecks for Interpretable Generation_20250919|EnCoBo Energy-Guided Concept Bottlenecks for Interpretable Generation]] (83.7% similar)
- [[2025-09-19/Modular Machine Learning_ An Indispensable Path towards New-Generation Large Language Models_20250919|Modular Machine Learning An Indispensable Path towards New-Generation Large Language Models]] (80.4% similar)
- [[2025-09-17/Simulating a Bias Mitigation Scenario in Large Language Models_20250917|Simulating a Bias Mitigation Scenario in Large Language Models]] (80.1% similar)
- [[2025-09-19/Enhancing Logical Reasoning in Language Models via Symbolically-Guided Monte Carlo Process Supervision_20250919|Enhancing Logical Reasoning in Language Models via Symbolically-Guided Monte Carlo Process Supervision]] (79.9% similar)
- [[2025-09-22/KITE_ Kernelized and Information Theoretic Exemplars for In-Context Learning_20250922|KITE Kernelized and Information Theoretic Exemplars for In-Context Learning]] (79.9% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2410.15555v2 Announce Type: replace-cross 
Abstract: Concept Bottleneck Models (CBMs) have been proposed as a compromise between white-box and black-box models, aiming to achieve interpretability without sacrificing accuracy. The standard training procedure for CBMs is to predefine a candidate set of human-interpretable concepts, extract their values from the training data, and identify a sparse subset as inputs to a transparent prediction model. However, such approaches are often hampered by the tradeoff between exploring a sufficiently large set of concepts versus controlling the cost of obtaining concept extractions, resulting in a large interpretability-accuracy tradeoff. This work investigates a novel approach that sidesteps these challenges: BC-LLM iteratively searches over a potentially infinite set of concepts within a Bayesian framework, in which Large Language Models (LLMs) serve as both a concept extraction mechanism and prior. Even though LLMs can be miscalibrated and hallucinate, we prove that BC-LLM can provide rigorous statistical inference and uncertainty quantification. Across image, text, and tabular datasets, BC-LLM outperforms interpretable baselines and even black-box models in certain settings, converges more rapidly towards relevant concepts, and is more robust to out-of-distribution samples.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2410.15555v2 ë°œí‘œ ìœ í˜•: êµì²´-êµì°¨  
ì´ˆë¡: ê°œë… ë³‘ëª© ëª¨ë¸(CBMs)ì€ í•´ì„ ê°€ëŠ¥ì„±ê³¼ ì •í™•ì„±ì„ ë™ì‹œì— ë‹¬ì„±í•˜ê¸° ìœ„í•œ ì ˆì¶©ì•ˆìœ¼ë¡œ, í™”ì´íŠ¸ë°•ìŠ¤ì™€ ë¸”ë™ë°•ìŠ¤ ëª¨ë¸ ì‚¬ì´ì˜ íƒ€í˜‘ì ìœ¼ë¡œ ì œì•ˆë˜ì—ˆìŠµë‹ˆë‹¤. CBMsì˜ í‘œì¤€ í•™ìŠµ ì ˆì°¨ëŠ” ì¸ê°„ì´ í•´ì„í•  ìˆ˜ ìˆëŠ” ê°œë…ì˜ í›„ë³´ ì§‘í•©ì„ ë¯¸ë¦¬ ì •ì˜í•˜ê³ , í•™ìŠµ ë°ì´í„°ì—ì„œ ê·¸ ê°’ì„ ì¶”ì¶œí•œ í›„, íˆ¬ëª…í•œ ì˜ˆì¸¡ ëª¨ë¸ì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•  í¬ì†Œí•œ ë¶€ë¶„ ì§‘í•©ì„ ì‹ë³„í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ëŸ¬í•œ ì ‘ê·¼ ë°©ì‹ì€ ì¶©ë¶„íˆ í° ê°œë… ì§‘í•©ì„ íƒìƒ‰í•˜ëŠ” ê²ƒê³¼ ê°œë… ì¶”ì¶œ ë¹„ìš©ì„ ì œì–´í•˜ëŠ” ê²ƒ ì‚¬ì´ì˜ ê· í˜•ì„ ë§ì¶”ê¸° ì–´ë ¤ì›Œ, í•´ì„ ê°€ëŠ¥ì„±ê³¼ ì •í™•ì„± ê°„ì˜ í° íŠ¸ë ˆì´ë“œì˜¤í”„ê°€ ë°œìƒí•˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ëŠ” ì´ëŸ¬í•œ ë¬¸ì œë¥¼ ìš°íšŒí•˜ëŠ” ìƒˆë¡œìš´ ì ‘ê·¼ ë°©ì‹ì„ ì¡°ì‚¬í•©ë‹ˆë‹¤: BC-LLMì€ ë² ì´ì§€ì•ˆ í”„ë ˆì„ì›Œí¬ ë‚´ì—ì„œ ì ì¬ì ìœ¼ë¡œ ë¬´í•œí•œ ê°œë… ì§‘í•©ì„ ë°˜ë³µì ìœ¼ë¡œ íƒìƒ‰í•˜ë©°, ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì´ ê°œë… ì¶”ì¶œ ë©”ì»¤ë‹ˆì¦˜ê³¼ ì‚¬ì „ìœ¼ë¡œ ì‘ìš©í•©ë‹ˆë‹¤. LLMì´ ì˜ëª» ì¡°ì •ë˜ê±°ë‚˜ í™˜ìƒì„ ì¼ìœ¼í‚¬ ìˆ˜ ìˆìŒì—ë„ ë¶ˆêµ¬í•˜ê³ , ìš°ë¦¬ëŠ” BC-LLMì´ ì—„ê²©í•œ í†µê³„ì  ì¶”ë¡ ê³¼ ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™”ë¥¼ ì œê³µí•  ìˆ˜ ìˆìŒì„ ì¦ëª…í•©ë‹ˆë‹¤. ì´ë¯¸ì§€, í…ìŠ¤íŠ¸, í‘œ í˜•ì‹ ë°ì´í„°ì…‹ ì „ë°˜ì— ê±¸ì³, BC-LLMì€ í•´ì„ ê°€ëŠ¥í•œ ê¸°ì¤€ ëª¨ë¸ê³¼ íŠ¹ì • ì„¤ì •ì—ì„œ ë¸”ë™ë°•ìŠ¤ ëª¨ë¸ì„ ëŠ¥ê°€í•˜ë©°, ê´€ë ¨ ê°œë…ì— ë” ë¹ ë¥´ê²Œ ìˆ˜ë ´í•˜ê³ , ë¶„í¬ ì™¸ ìƒ˜í”Œì— ë” ê°•ì¸í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ í•´ì„ ê°€ëŠ¥ì„±ê³¼ ì •í™•ì„±ì„ ë™ì‹œì— ì¶”êµ¬í•˜ëŠ” Concept Bottleneck Models(CBMs)ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ì ‘ê·¼ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ CBMsëŠ” í•´ì„ ê°€ëŠ¥í•œ ê°œë… ì§‘í•©ì„ ë¯¸ë¦¬ ì •ì˜í•˜ê³  ì´ë¥¼ ì˜ˆì¸¡ ëª¨ë¸ì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ”ë°, ì´ëŠ” ê°œë… íƒìƒ‰ ë²”ìœ„ì™€ ë¹„ìš© ê°„ì˜ ê· í˜• ë¬¸ì œë¥¼ ì•¼ê¸°í•©ë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” BC-LLMì´ë¼ëŠ” ìƒˆë¡œìš´ ë°©ë²•ì„ ì œì•ˆí•˜ì—¬, ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì„ í™œìš©í•´ ë¬´í•œí•œ ê°œë… ì§‘í•©ì„ íƒìƒ‰í•˜ê³ , ë² ì´ì§€ì•ˆ í”„ë ˆì„ì›Œí¬ ë‚´ì—ì„œ ê°œë… ì¶”ì¶œê³¼ ì‚¬ì „ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤. BC-LLMì€ LLMì˜ í•œê³„ì—ë„ ë¶ˆêµ¬í•˜ê³  í†µê³„ì  ì¶”ë¡ ê³¼ ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™”ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ë©°, ì´ë¯¸ì§€, í…ìŠ¤íŠ¸, í‘œ í˜•ì‹ ë°ì´í„°ì—ì„œ í•´ì„ ê°€ëŠ¥í•œ ëª¨ë¸ê³¼ ë¸”ë™ë°•ìŠ¤ ëª¨ë¸ì„ ëŠ¥ê°€í•˜ëŠ” ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤. ë˜í•œ, ê´€ë ¨ ê°œë…ìœ¼ë¡œì˜ ìˆ˜ë ´ì´ ë¹ ë¥´ê³ , ë¶„í¬ ë°– ìƒ˜í”Œì— ëŒ€í•œ ê°•ê±´ì„±ì„ ë³´ì…ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Concept Bottleneck Models (CBMs)ëŠ” í•´ì„ ê°€ëŠ¥ì„±ê³¼ ì •í™•ì„±ì„ ë™ì‹œì— ì¶”êµ¬í•˜ëŠ” ëª¨ë¸ë¡œ, ì¸ê°„ì´ í•´ì„í•  ìˆ˜ ìˆëŠ” ê°œë…ì„ ë¯¸ë¦¬ ì •ì˜í•˜ì—¬ íˆ¬ëª…í•œ ì˜ˆì¸¡ ëª¨ë¸ì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ì´ë‹¤.

- 2. ê¸°ì¡´ CBM ì ‘ê·¼ë²•ì€ ê°œë… ì§‘í•©ì˜ í¬ê¸°ì™€ ê°œë… ì¶”ì¶œ ë¹„ìš© ê°„ì˜ ê· í˜•ì„ ë§ì¶”ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªìœ¼ë©°, í•´ì„ ê°€ëŠ¥ì„±ê³¼ ì •í™•ì„± ê°„ì˜ í° íŠ¸ë ˆì´ë“œì˜¤í”„ê°€ ë°œìƒí•œë‹¤.

- 3. BC-LLMì€ Bayesian í”„ë ˆì„ì›Œí¬ ë‚´ì—ì„œ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ ê°œë… ì¶”ì¶œ ë©”ì»¤ë‹ˆì¦˜ ë° ì‚¬ì „ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ ë¬´í•œí•œ ê°œë… ì§‘í•©ì„ íƒìƒ‰í•˜ëŠ” ìƒˆë¡œìš´ ì ‘ê·¼ë²•ì„ ì œì•ˆí•œë‹¤.

- 4. BC-LLMì€ ì´ë¯¸ì§€, í…ìŠ¤íŠ¸, í…Œì´ë¸” ë°ì´í„°ì…‹ì—ì„œ í•´ì„ ê°€ëŠ¥í•œ ê¸°ì¤€ ëª¨ë¸ ë° ì¼ë¶€ ì„¤ì •ì—ì„œ ë¸”ë™ë°•ìŠ¤ ëª¨ë¸ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì´ë©°, ê´€ë ¨ ê°œë…ìœ¼ë¡œì˜ ìˆ˜ë ´ ì†ë„ê°€ ë¹ ë¥´ê³  ë¶„í¬ ì™¸ ìƒ˜í”Œì— ëŒ€í•œ ê°•ê±´ì„±ì„ ê°€ì§„ë‹¤.

- 5. LLMì´ ì˜ëª» ì¡°ì •ë˜ê±°ë‚˜ í™˜ìƒì„ ì¼ìœ¼í‚¬ ìˆ˜ ìˆìŒì—ë„ ë¶ˆêµ¬í•˜ê³ , BC-LLMì€ ì—„ê²©í•œ í†µê³„ì  ì¶”ë¡ ê³¼ ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™”ë¥¼ ì œê³µí•  ìˆ˜ ìˆìŒì„ ì…ì¦í•œë‹¤.

---

*Generated on 2025-09-22 14:40:04*