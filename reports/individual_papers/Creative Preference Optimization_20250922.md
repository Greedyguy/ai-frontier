# Creative Preference Optimization

**Korean Title:** ì°½ì˜ì  ì„ í˜¸ ìµœì í™”

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Creativity Augmentation

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/Evolving Language Models without Labels_ Majority Drives Selection, Novelty Promotes Variation_20250918|Evolving Language Models without Labels Majority Drives Selection, Novelty Promotes Variation]] (83.3% similar)
- [[2025-09-19/Enhancing Logical Reasoning in Language Models via Symbolically-Guided Monte Carlo Process Supervision_20250919|Enhancing Logical Reasoning in Language Models via Symbolically-Guided Monte Carlo Process Supervision]] (83.2% similar)
- [[2025-09-22/Exploring the Impact of Personality Traits on LLM Bias and Toxicity_20250922|Exploring the Impact of Personality Traits on LLM Bias and Toxicity]] (83.0% similar)
- [[2025-09-19/Modular Machine Learning_ An Indispensable Path towards New-Generation Large Language Models_20250919|Modular Machine Learning An Indispensable Path towards New-Generation Large Language Models]] (82.8% similar)
- [[2025-09-18/LLM-I_ LLMs are Naturally Interleaved Multimodal Creators_20250918|LLM-I LLMs are Naturally Interleaved Multimodal Creators]] (82.8% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2505.14442v2 Announce Type: replace-cross 
Abstract: While Large Language Models (LLMs) have demonstrated impressive performance across natural language generation tasks, their ability to generate truly creative content-characterized by novelty, diversity, surprise, and quality-remains limited. Existing methods for enhancing LLM creativity often focus narrowly on diversity or specific tasks, failing to address creativity's multifaceted nature in a generalizable way. In this work, we propose Creative Preference Optimization (CrPO), a novel alignment method that injects signals from multiple creativity dimensions into the preference optimization objective in a modular fashion. We train and evaluate creativity-augmented versions of several models using CrPO and MuCE, a new large-scale human preference dataset spanning over 200,000 human-generated responses and ratings from more than 30 psychological creativity assessments. Our models outperform strong baselines, including GPT-4o, on both automated and human evaluations, producing more novel, diverse, and surprising generations while maintaining high output quality. Additional evaluations on NoveltyBench further confirm the generalizability of our approach. Together, our results demonstrate that directly optimizing for creativity within preference frameworks is a promising direction for advancing the creative capabilities of LLMs without compromising output quality.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2505.14442v2 ë°œí‘œ ìœ í˜•: êµì²´-êµì°¨  
ì´ˆë¡: ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ ìì—°ì–´ ìƒì„± ì‘ì—…ì—ì„œ ì¸ìƒì ì¸ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì—ˆì§€ë§Œ, ì°¸ì‹ ì„±, ë‹¤ì–‘ì„±, ë†€ë¼ì›€, í’ˆì§ˆë¡œ íŠ¹ì§•ì§€ì–´ì§€ëŠ” ì§„ì •í•œ ì°½ì˜ì  ì½˜í…ì¸ ë¥¼ ìƒì„±í•˜ëŠ” ëŠ¥ë ¥ì€ ì—¬ì „íˆ ì œí•œì ì…ë‹ˆë‹¤. LLMì˜ ì°½ì˜ì„±ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ê¸°ì¡´ ë°©ë²•ì€ ì¢…ì¢… ë‹¤ì–‘ì„±ì´ë‚˜ íŠ¹ì • ì‘ì—…ì—ë§Œ ì¢ê²Œ ì´ˆì ì„ ë§ì¶”ì–´, ì°½ì˜ì„±ì˜ ë‹¤ë©´ì ì¸ ë³¸ì§ˆì„ ì¼ë°˜í™” ê°€ëŠ¥í•œ ë°©ì‹ìœ¼ë¡œ ë‹¤ë£¨ì§€ ëª»í•©ë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” ì°½ì˜ì  ì„ í˜¸ ìµœì í™”(CrPO)ë¼ëŠ” ìƒˆë¡œìš´ ì •ë ¬ ë°©ë²•ì„ ì œì•ˆí•˜ì—¬, ëª¨ë“ˆì‹ ë°©ì‹ìœ¼ë¡œ ì—¬ëŸ¬ ì°½ì˜ì„± ì°¨ì›ì˜ ì‹ í˜¸ë¥¼ ì„ í˜¸ ìµœì í™” ëª©í‘œì— ì£¼ì…í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” CrPOì™€ 30ê°œ ì´ìƒì˜ ì‹¬ë¦¬ì  ì°½ì˜ì„± í‰ê°€ì—ì„œ 200,000ê°œ ì´ìƒì˜ ì¸ê°„ ìƒì„± ì‘ë‹µê³¼ í‰ê°€ë¥¼ í¬í•¨í•˜ëŠ” ìƒˆë¡œìš´ ëŒ€ê·œëª¨ ì¸ê°„ ì„ í˜¸ ë°ì´í„°ì…‹ì¸ MuCEë¥¼ ì‚¬ìš©í•˜ì—¬ ì—¬ëŸ¬ ëª¨ë¸ì˜ ì°½ì˜ì„± ê°•í™” ë²„ì „ì„ í›ˆë ¨í•˜ê³  í‰ê°€í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ëª¨ë¸ì€ GPT-4oë¥¼ í¬í•¨í•œ ê°•ë ¥í•œ ê¸°ì¤€ ëª¨ë¸ë“¤ì„ ìë™ ë° ì¸ê°„ í‰ê°€ ëª¨ë‘ì—ì„œ ëŠ¥ê°€í•˜ë©°, ë” ì°¸ì‹ í•˜ê³  ë‹¤ì–‘í•˜ë©° ë†€ë¼ìš´ ìƒì„±ë¬¼ì„ ìƒì‚°í•˜ë©´ì„œë„ ë†’ì€ ì¶œë ¥ í’ˆì§ˆì„ ìœ ì§€í•©ë‹ˆë‹¤. ì¶”ê°€ì ì¸ NoveltyBench í‰ê°€ì—ì„œë„ ìš°ë¦¬ì˜ ì ‘ê·¼ ë°©ì‹ì˜ ì¼ë°˜í™” ê°€ëŠ¥ì„±ì„ ë”ìš± í™•ì¸í•©ë‹ˆë‹¤. ì¢…í•©ì ìœ¼ë¡œ, ìš°ë¦¬ì˜ ê²°ê³¼ëŠ” ì„ í˜¸ í”„ë ˆì„ì›Œí¬ ë‚´ì—ì„œ ì°½ì˜ì„±ì„ ì§ì ‘ ìµœì í™”í•˜ëŠ” ê²ƒì´ ì¶œë ¥ í’ˆì§ˆì„ ì†ìƒì‹œí‚¤ì§€ ì•Šìœ¼ë©´ì„œ LLMì˜ ì°½ì˜ì  ëŠ¥ë ¥ì„ ë°œì „ì‹œí‚¤ëŠ” ìœ ë§í•œ ë°©í–¥ì„ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì°½ì˜ì  ì½˜í…ì¸  ìƒì„± ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ Creative Preference Optimization(CrPO)ë¼ëŠ” ìƒˆë¡œìš´ ì •ë ¬ ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. CrPOëŠ” ì°½ì˜ì„±ì˜ ì—¬ëŸ¬ ì°¨ì›ì„ ëª¨ë“ˆ ë°©ì‹ìœ¼ë¡œ ìµœì í™” ëª©í‘œì— í†µí•©í•˜ì—¬ ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤. ì—°êµ¬ì—ì„œëŠ” 30ê°œ ì´ìƒì˜ ì‹¬ë¦¬í•™ì  ì°½ì˜ì„± í‰ê°€ë¥¼ í¬í•¨í•œ 20ë§Œ ê°œ ì´ìƒì˜ ì¸ê°„ ìƒì„± ì‘ë‹µê³¼ í‰ê°€ë¥¼ ë‹´ì€ MuCE ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬ ëª¨ë¸ì„ í‰ê°€í–ˆìŠµë‹ˆë‹¤. ê·¸ ê²°ê³¼, ì œì•ˆëœ ëª¨ë¸ì€ GPT-4oë¥¼ í¬í•¨í•œ ê°•ë ¥í•œ ê¸°ì¤€ ëª¨ë¸ë“¤ë³´ë‹¤ ë” ìƒˆë¡­ê³  ë‹¤ì–‘í•˜ë©° ë†€ë¼ìš´ ê²°ê³¼ë¥¼ ìƒì„±í•˜ë©´ì„œë„ ë†’ì€ í’ˆì§ˆì„ ìœ ì§€í–ˆìŠµë‹ˆë‹¤. NoveltyBenchë¥¼ í†µí•œ ì¶”ê°€ í‰ê°€ì—ì„œë„ ì´ ì ‘ê·¼ë²•ì˜ ì¼ë°˜í™” ê°€ëŠ¥ì„±ì´ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ëŠ” LLMì˜ ì°½ì˜ì  ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° ìˆì–´ ìœ ë§í•œ ë°©í–¥ì„ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì°½ì˜ì  ì½˜í…ì¸  ìƒì„± ëŠ¥ë ¥ì€ ì—¬ì „íˆ ì œí•œì ì´ë‹¤.

- 2. ê¸°ì¡´ì˜ LLM ì°½ì˜ì„± í–¥ìƒ ë°©ë²•ì€ ë‹¤ì–‘ì„±ì´ë‚˜ íŠ¹ì • ì‘ì—…ì— ì§‘ì¤‘í•˜ì—¬ ì°½ì˜ì„±ì˜ ë‹¤ë©´ì  íŠ¹ì„±ì„ ì¼ë°˜í™”í•˜ì§€ ëª»í•œë‹¤.

- 3. Creative Preference Optimization(CrPO)ëŠ” ì—¬ëŸ¬ ì°½ì˜ì„± ì°¨ì›ì˜ ì‹ í˜¸ë¥¼ ì„ í˜¸ë„ ìµœì í™” ëª©í‘œì— ëª¨ë“ˆì‹ìœ¼ë¡œ ì£¼ì…í•˜ëŠ” ìƒˆë¡œìš´ ì •ë ¬ ë°©ë²•ì´ë‹¤.

- 4. CrPOì™€ MuCEë¥¼ ì‚¬ìš©í•œ ëª¨ë¸ì€ GPT-4oë¥¼ í¬í•¨í•œ ê°•ë ¥í•œ ê¸°ì¤€ ëª¨ë¸ë³´ë‹¤ ë” ì°¸ì‹ í•˜ê³  ë‹¤ì–‘í•˜ë©° ë†€ë¼ìš´ ê²°ê³¼ë¥¼ ìƒì„±í•œë‹¤.

- 5. NoveltyBenchì—ì„œì˜ ì¶”ê°€ í‰ê°€ë¥¼ í†µí•´ ì œì•ˆëœ ì ‘ê·¼ë²•ì˜ ì¼ë°˜í™” ê°€ëŠ¥ì„±ì´ í™•ì¸ë˜ì—ˆë‹¤.

---

*Generated on 2025-09-22 14:49:26*