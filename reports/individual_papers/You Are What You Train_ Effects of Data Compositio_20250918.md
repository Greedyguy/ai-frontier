
# You Are What You Train: Effects of Data Composition on Training Context-aware Machine Translation Models

**Korean Title:** λ‹Ήμ‹ μ€ λ‹Ήμ‹ μ΄ ν›λ ¨ν•λ” λ€λ΅ λ©λ‹λ‹¤: λ°μ΄ν„° κµ¬μ„±μ΄ ν›λ ¨μ— λ―ΈμΉλ” μν–¥ - λ¬Έλ§¥ μΈμ‹ κΈ°κ³„ λ²μ—­ λ¨λΈμ— λ€ν• μ—°κµ¬

## π“‹ λ©”νƒ€λ°μ΄ν„°

**Links**: [[daily/2025-09-18|2025-09-18]] [[keywords/evolved/Cross-lingual Transfer|Cross-lingual Transfer]] [[keywords/broad/Context-aware Machine Translation|Context-aware Machine Translation]] [[keywords/broad/Training Data Sparsity|Training Data Sparsity]] [[keywords/specific/Pronoun Disambiguation|Pronoun Disambiguation]] [[keywords/unique/ctxPro|ctxPro]] [[categories/cs.AI|cs.AI]]

## π·οΈ μΉ΄ν…κ³ λ¦¬ν™”λ ν‚¤μ›λ“
**π€ Evolved Concepts**: Cross-lingual Transfer
**π”¬ Broad Technical**: Context-aware Machine Translation Models, Training Datasets
**π”— Specific Connectable**: Pronoun Disambiguation
**β­ Unique Technical**: ctxPro

**ArXiv ID**: [2509.14031](https://arxiv.org/abs/2509.14031)
**Published**: 2025-09-18
**Category**: cs.AI
**PDF**: [Download](https://arxiv.org/pdf/2509.14031.pdf)


## π·οΈ μ¶”μ¶λ ν‚¤μ›λ“



`Context-aware Machine Translation` β€Ά 

`Training Data Sparsity` β€Ά 

`Pronoun Disambiguation` β€Ά 

`ctxPro` β€Ά 

`Cross-lingual Transfer`



## π“‹ μ €μ μ •λ³΄

**Authors:** 

## π“„ Abstract (μ›λ¬Έ)

arXiv:2509.14031v1 Announce Type: cross 
Abstract: Achieving human-level translations requires leveraging context to ensure coherence and handle complex phenomena like pronoun disambiguation. Sparsity of contextually rich examples in the standard training data has been hypothesized as the reason for the difficulty of context utilization. In this work, we systematically validate this claim in both single- and multilingual settings by constructing training datasets with a controlled proportions of contextually relevant examples. We demonstrate a strong association between training data sparsity and model performance confirming sparsity as a key bottleneck. Importantly, we reveal that improvements in one contextual phenomenon do no generalize to others. While we observe some cross-lingual transfer, it is not significantly higher between languages within the same sub-family. Finally, we propose and empirically evaluate two training strategies designed to leverage the available data. These strategies improve context utilization, resulting in accuracy gains of up to 6 and 8 percentage points on the ctxPro evaluation in single- and multilingual settings respectively.

## π” Abstract (ν•κΈ€ λ²μ—­)

arXiv:2509.14031v1 λ°ν‘ μ ν•: κµμ°¨
μ”μ•½: μΈκ°„ μμ¤€μ λ²μ—­μ„ λ‹¬μ„±ν•κΈ° μ„ν•΄μ„λ” λ§¥λ½μ„ ν™μ©ν•μ—¬ μΌκ΄€μ„±μ„ λ³΄μ¥ν•κ³  λ€λ…μ‚¬ λ¨νΈμ„±κ³Ό κ°™μ€ λ³µμ΅ν• ν„μƒμ„ μ²λ¦¬ν•΄μ•Ό ν•©λ‹λ‹¤. ν‘μ¤€ κµμ΅ λ°μ΄ν„°μ—μ„ λ§¥λ½μ΄ ν’λ¶€ν• μμ μ ν¬μ†μ„±μ΄ λ§¥λ½ ν™μ©μ μ–΄λ ¤μ›€μ μ΄μ λ΅ μ¶”μΈ΅λμ—μµλ‹λ‹¤. λ³Έ μ—°κµ¬μ—μ„λ” λ§¥λ½μ μΌλ΅ κ΄€λ ¨λ μμ μ λΉ„μ¨μ„ μ μ–΄ν•μ—¬ κµμ΅ λ°μ΄ν„° μ„ΈνΈλ¥Ό κµ¬μ¶•ν•¨μΌλ΅μ¨ μ΄ μ£Όμ¥μ„ λ‹¨μΌ λ° λ‹¤κµ­μ–΄ ν™κ²½μ—μ„ μ²΄κ³„μ μΌλ΅ κ²€μ¦ν•©λ‹λ‹¤. κµμ΅ λ°μ΄ν„°μ ν¬μ†μ„±κ³Ό λ¨λΈ μ„±λ¥ μ‚¬μ΄μ— κ°•ν• μ—°κ΄€μ„±μ„ λ³΄μ—¬ ν¬μ†μ„±μ„ μ£Όμ” λ³‘λ© ν„μƒμΌλ΅ ν™•μΈν•©λ‹λ‹¤. μ¤‘μ”ν• μ μ€ ν• κ°€μ§€ λ§¥λ½μ  ν„μƒμ κ°μ„ μ΄ λ‹¤λ¥Έ ν„μƒμΌλ΅ μΌλ°ν™”λμ§€ μ•λ”λ‹¤λ” κ²ƒμ„ λ°ν€λƒ…λ‹λ‹¤. μ°λ¦¬λ” μΌλ¶€ κµμ°¨ μ–Έμ–΄ μ „μ΄λ¥Ό κ΄€μ°°ν•μ§€λ§, λ™μΌν• ν•μ„ ν¨λ°€λ¦¬ λ‚΄μ μ–Έμ–΄ κ°„μ—λ” μ μλ―Έν•κ² λ†’μ§€ μ•μµλ‹λ‹¤. λ§μ§€λ§‰μΌλ΅, μ‚¬μ© κ°€λ¥ν• λ°μ΄ν„°λ¥Ό ν™μ©ν•κΈ° μ„ν•΄ μ„¤κ³„λ λ‘ κ°€μ§€ κµμ΅ μ „λµμ„ μ μ•ν•κ³  κ²½ν—μ μΌλ΅ ν‰κ°€ν•©λ‹λ‹¤. μ΄λ¬ν• μ „λµμ€ λ§¥λ½ ν™μ©μ„ κ°μ„ ν•μ—¬ λ‹¨μΌ λ° λ‹¤κµ­μ–΄ ν™κ²½μ—μ„ κ°κ° ctxPro ν‰κ°€μ—μ„ 6 λ° 8 νΌμ„ΌνΈ ν¬μΈνΈμ μ •ν™•λ„ ν–¥μƒμ„ κ°€μ Έμµλ‹λ‹¤.

## π“ μ”μ•½

μ΄ μ—°κµ¬λ” μΈκ°„ μμ¤€μ λ²μ—­μ„ λ‹¬μ„±ν•κΈ° μ„ν•΄ λ§¥λ½μ„ ν™μ©ν•μ—¬ μΌκ΄€μ„±μ„ μ μ§€ν•κ³  λ€λ…μ‚¬ λ¨νΈμ„±κ³Ό κ°™μ€ λ³µμ΅ν• ν„μƒμ„ μ²λ¦¬ν•΄μ•Ό ν•λ‹¤λ” μ μ„ κ°•μ΅°ν•λ‹¤. ν‘μ¤€ ν›λ ¨ λ°μ΄ν„°μ—μ„ λ§¥λ½μ΄ ν’λ¶€ν• μμ μ ν¬μ†μ„±μ΄ λ§¥λ½ ν™μ©μ μ–΄λ ¤μ›€μ μ΄μ λ΅ μ κΈ°λμ—λ‹¤. μ΄ μ—°κµ¬μ—μ„λ” ν›λ ¨ λ°μ΄ν„°μ…‹μ„ κµ¬μ„±ν•μ—¬ λ§¥λ½μ μΌλ΅ κ΄€λ ¨ μλ” μμ μ λΉ„μ¨μ„ μ΅°μ ν•μ—¬ μ΄ μ£Όμ¥μ„ λ‹¨μΌ λ° λ‹¤κµ­μ–΄ μ„¤μ •μ—μ„ μ²΄κ³„μ μΌλ΅ κ²€μ¦ν•λ‹¤. ν›λ ¨ λ°μ΄ν„°μ ν¬μ†μ„±κ³Ό λ¨λΈ μ„±λ¥ μ‚¬μ΄μ— κ°•ν• κ΄€λ ¨μ„±μ„ μ…μ¦ν•μ—¬ ν¬μ†μ„±μ„ μ£Όμ” λ³‘λ© ν„μƒμΌλ΅ ν™•μΈν•λ‹¤. λν•, ν• κ°€μ§€ λ§¥λ½μ  ν„μƒμ κ°μ„ μ΄ λ‹¤λ¥Έ ν„μƒμΌλ΅ μΌλ°ν™”λμ§€ μ•μμ„ λ°νλ‹¤. λ™μΌ λ¶€λ¬Έ λ‚΄ μ–Έμ–΄ κ°„μ κµμ°¨μ–Έμ–΄ μ „μ΄λ” μΌλ¶€ κ΄€μ°°λμ§€λ§ μ μλ―Έν•κ² λ†’μ§€ μ•λ‹¤. λ§μ§€λ§‰μΌλ΅, μ‚¬μ© κ°€λ¥ν• λ°μ΄ν„°λ¥Ό ν™μ©ν•κΈ° μ„ν•΄ μ„¤κ³„λ λ‘ κ°€μ§€ ν›λ ¨ μ „λµμ„ μ μ•ν•κ³  κ²½ν—μ μΌλ΅ ν‰κ°€ν•λ‹¤. μ΄λ¬ν• μ „λµμ€ λ§¥λ½ ν™μ©μ„ κ°μ„ ν•μ—¬ λ‹¨μΌ λ° λ‹¤κµ­μ–΄ μ„¤μ •μ—μ„ ctxPro ν‰κ°€μ—μ„ μµλ€ 6~8%μ μ •ν™•λ„ ν–¥μƒμ„ μ΄λμ–΄λƒλ‹¤.

## π― μ£Όμ” ν¬μΈνΈ


- μΈκ°„ μμ¤€μ λ²μ—­μ„ λ‹¬μ„±ν•κΈ° μ„ν•΄μ„λ” λ§¥λ½μ„ ν™μ©ν•μ—¬ μΌκ΄€μ„±μ„ μ μ§€ν•κ³  λ€λ…μ‚¬ λ¨νΈμ„±κ³Ό κ°™μ€ λ³µμ΅ν• ν„μƒμ„ μ²λ¦¬ν•΄μ•Ό ν•¨

- ν›λ ¨ λ°μ΄ν„°μ λ§¥λ½μ΄ λ¶€μ΅±ν• κ²ƒμ΄ λ§¥λ½ ν™μ©μ μ–΄λ ¤μ›€μ μ΄μ λ΅ μ μ‹λ¨

- ν›λ ¨ λ°μ΄ν„°μ ν¬μ†μ„±κ³Ό λ¨λΈ μ„±λ¥ μ‚¬μ΄μ— κ°•ν• μ—°κ΄€μ„±μ΄ μμμ„ ν™•μΈν•λ©°, ν¬μ†μ„±μ΄ μ£Όμ” λ³‘λ© ν„μƒμ„μ„ ν™•μΈν•¨

- λ§¥λ½μ  ν„μƒ μ¤‘ ν•λ‚μ κ°μ„ μ΄ λ‹¤λ¥Έ ν„μƒμΌλ΅ μΌλ°ν™”λμ§€ μ•μμ„ λ°νλ©°, μΌλ¶€ μ–Έμ–΄ κ°„μ κµμ°¨ μ–Έμ–΄ μ „μ΄λ¥Ό κ΄€μ°°ν•¨

- μ‚¬μ© κ°€λ¥ν• λ°μ΄ν„°λ¥Ό ν™μ©ν•κΈ° μ„ν•΄ λ‘ κ°€μ§€ ν›λ ¨ μ „λµμ„ μ μ•ν•κ³  μ‹¤ν—μ μΌλ΅ ν‰κ°€ν•¨, μ΄λ΅ μΈν•΄ λ‹¨μΌ λ° λ‹¤μ¤‘ μ–Έμ–΄ μ„¤μ •μ—μ„ ctxPro ν‰κ°€μ—μ„ μ •ν™•λ„ ν–¥μƒμ΄ λ°μƒν•¨ (μµλ€ 6~8%ν¬μΈνΈ)


---

*Generated on 2025-09-18 16:24:48*