# AS-ASR: A Lightweight Framework for Aphasia-Specific Automatic Speech Recognition

**Korean Title:** AS-ASR: ì‹¤ì–´ì¦ íŠ¹í™” ìë™ ìŒì„± ì¸ì‹ì„ ìœ„í•œ ê²½ëŸ‰ í”„ë ˆì„ì›Œí¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Aphasia-specific Speech Recognition

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Listening, Imagining & Refining_ A Heuristic Optimized ASR Correction Framework with LLMs_20250919|Listening, Imagining & Refining A Heuristic Optimized ASR Correction Framework with LLMs]] (85.5% similar)
- [[2025-09-22/Session-Level Spoken Language Assessment with a Multimodal Foundation Model via Multi-Target Learning_20250922|Session-Level Spoken Language Assessment with a Multimodal Foundation Model via Multi-Target Learning]] (81.5% similar)
- [[2025-09-19/SpeechOp_ Inference-Time Task Composition for Generative Speech Processing_20250919|SpeechOp Inference-Time Task Composition for Generative Speech Processing]] (80.9% similar)
- [[2025-09-22/Impact of Phonetics on Speaker Identity in Adversarial Voice Attack_20250922|Impact of Phonetics on Speaker Identity in Adversarial Voice Attack]] (80.0% similar)
- [[2025-09-22/Fed-PISA_ Federated Voice Cloning via Personalized Identity-Style Adaptation_20250922|Fed-PISA Federated Voice Cloning via Personalized Identity-Style Adaptation]] (80.0% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2506.06566v2 Announce Type: replace-cross 
Abstract: This paper proposes AS-ASR, a lightweight aphasia-specific speech recognition framework based on Whisper-tiny, tailored for low-resource deployment on edge devices. Our approach introduces a hybrid training strategy that systematically combines standard and aphasic speech at varying ratios, enabling robust generalization, and a GPT-4-based reference enhancement method that refines noisy aphasic transcripts, improving supervision quality. We conduct extensive experiments across multiple data mixing configurations and evaluation settings. Results show that our fine-tuned model significantly outperforms the zero-shot baseline, reducing WER on aphasic speech by over 30% while preserving performance on standard speech. The proposed framework offers a scalable, efficient solution for real-world disordered speech recognition.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2506.06566v2 ë°œí‘œ ìœ í˜•: êµì°¨ êµì²´  
ì´ˆë¡: ë³¸ ë…¼ë¬¸ì€ Whisper-tinyë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ê²½ëŸ‰ì˜ ì‹¤ì–´ì¦ íŠ¹í™” ìŒì„± ì¸ì‹ í”„ë ˆì„ì›Œí¬ì¸ AS-ASRì„ ì œì•ˆí•˜ë©°, ì—£ì§€ ë””ë°”ì´ìŠ¤ì—ì„œì˜ ì €ìì› ë°°í¬ì— ì í•©í•˜ê²Œ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ìš°ë¦¬ì˜ ì ‘ê·¼ ë°©ì‹ì€ í‘œì¤€ ìŒì„±ê³¼ ì‹¤ì–´ì¦ ìŒì„±ì„ ë‹¤ì–‘í•œ ë¹„ìœ¨ë¡œ ì²´ê³„ì ìœ¼ë¡œ ê²°í•©í•˜ëŠ” í•˜ì´ë¸Œë¦¬ë“œ í›ˆë ¨ ì „ëµì„ ë„ì…í•˜ì—¬ ê°•ë ¥í•œ ì¼ë°˜í™”ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ë©°, GPT-4 ê¸°ë°˜ì˜ ì°¸ì¡° í–¥ìƒ ë°©ë²•ì„ í†µí•´ ì¡ìŒì´ ë§ì€ ì‹¤ì–´ì¦ ì „ì‚¬ë¥¼ ì •ì œí•˜ì—¬ ê°ë… í’ˆì§ˆì„ ê°œì„ í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì—¬ëŸ¬ ë°ì´í„° í˜¼í•© êµ¬ì„± ë° í‰ê°€ ì„¤ì •ì—ì„œ ê´‘ë²”ìœ„í•œ ì‹¤í—˜ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. ê²°ê³¼ì— ë”°ë¥´ë©´, ë¯¸ì„¸ ì¡°ì •ëœ ëª¨ë¸ì€ ì œë¡œìƒ· ê¸°ì¤€ì„ ì„ í¬ê²Œ ëŠ¥ê°€í•˜ë©°, ì‹¤ì–´ì¦ ìŒì„±ì˜ WERì„ 30% ì´ìƒ ê°ì†Œì‹œí‚¤ë©´ì„œ í‘œì¤€ ìŒì„±ì— ëŒ€í•œ ì„±ëŠ¥ì„ ìœ ì§€í•©ë‹ˆë‹¤. ì œì•ˆëœ í”„ë ˆì„ì›Œí¬ëŠ” ì‹¤ì œ í™˜ê²½ì—ì„œì˜ ì¥ì•  ìŒì„± ì¸ì‹ì„ ìœ„í•œ í™•ì¥ ê°€ëŠ¥í•˜ê³  íš¨ìœ¨ì ì¸ ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ê²½ëŸ‰í™”ëœ ì‹¤ì–´ì¦ íŠ¹í™” ìŒì„± ì¸ì‹ í”„ë ˆì„ì›Œí¬ì¸ AS-ASRì„ ì œì•ˆí•©ë‹ˆë‹¤. Whisper-tiny ê¸°ë°˜ìœ¼ë¡œ ì„¤ê³„ëœ ì´ í”„ë ˆì„ì›Œí¬ëŠ” ì—£ì§€ ë””ë°”ì´ìŠ¤ì—ì„œ ì €ìì› í™˜ê²½ì— ì í•©í•©ë‹ˆë‹¤. í‘œì¤€ ìŒì„±ê³¼ ì‹¤ì–´ì¦ ìŒì„±ì„ ë‹¤ì–‘í•œ ë¹„ìœ¨ë¡œ í˜¼í•©í•˜ì—¬ í•™ìŠµí•˜ëŠ” í•˜ì´ë¸Œë¦¬ë“œ í›ˆë ¨ ì „ëµì„ ë„ì…í•˜ì—¬ ì¼ë°˜í™” ëŠ¥ë ¥ì„ ê°•í™”í•˜ì˜€ê³ , GPT-4 ê¸°ë°˜ì˜ ì°¸ì¡° ê°œì„  ë°©ë²•ì„ í†µí•´ ì‹¤ì–´ì¦ ìŒì„±ì˜ ì¡ìŒì„ ì¤„ì—¬ ê°ë… í’ˆì§ˆì„ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤. ì—¬ëŸ¬ ë°ì´í„° í˜¼í•© êµ¬ì„±ê³¼ í‰ê°€ ì„¤ì •ì—ì„œ ì‹¤í—˜í•œ ê²°ê³¼, ë¯¸ì„¸ ì¡°ì •ëœ ëª¨ë¸ì´ ì œë¡œìƒ· ê¸°ì¤€ ëª¨ë¸ë³´ë‹¤ ì‹¤ì–´ì¦ ìŒì„±ì˜ WERì„ 30% ì´ìƒ ê°ì†Œì‹œí‚¤ë©´ì„œ í‘œì¤€ ìŒì„± ì„±ëŠ¥ì„ ìœ ì§€í•˜ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ì‹¤ì œ í™˜ê²½ì—ì„œì˜ ì¥ì•  ìŒì„± ì¸ì‹ì„ ìœ„í•œ í™•ì¥ ê°€ëŠ¥í•˜ê³  íš¨ìœ¨ì ì¸ ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. AS-ASRì€ Whisper-tiny ê¸°ë°˜ì˜ ê²½ëŸ‰í˜• ì‹¤ì–´ì¦ íŠ¹í™” ìŒì„± ì¸ì‹ í”„ë ˆì„ì›Œí¬ë¡œ, ì—£ì§€ ë””ë°”ì´ìŠ¤ì˜ ì €ìì› ë°°í¬ë¥¼ ìœ„í•´ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.

- 2. í‘œì¤€ ë° ì‹¤ì–´ì¦ ìŒì„±ì„ ë‹¤ì–‘í•œ ë¹„ìœ¨ë¡œ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ í›ˆë ¨ ì „ëµì„ ë„ì…í•˜ì—¬ ê°•ë ¥í•œ ì¼ë°˜í™”ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.

- 3. GPT-4 ê¸°ë°˜ì˜ ì°¸ì¡° í–¥ìƒ ë°©ë²•ì„ í†µí•´ ì¡ìŒì´ ìˆëŠ” ì‹¤ì–´ì¦ ì „ì‚¬ë³¸ì„ ê°œì„ í•˜ì—¬ ê°ë… í’ˆì§ˆì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

- 4. ì—¬ëŸ¬ ë°ì´í„° í˜¼í•© êµ¬ì„± ë° í‰ê°€ ì„¤ì •ì—ì„œ ê´‘ë²”ìœ„í•œ ì‹¤í—˜ì„ ìˆ˜í–‰í•œ ê²°ê³¼, ë¯¸ì„¸ ì¡°ì •ëœ ëª¨ë¸ì´ ì œë¡œìƒ· ê¸°ì¤€ì„ í¬ê²Œ ëŠ¥ê°€í•˜ì—¬ ì‹¤ì–´ì¦ ìŒì„±ì˜ WERì„ 30% ì´ìƒ ê°ì†Œì‹œì¼°ìŠµë‹ˆë‹¤.

- 5. ì œì•ˆëœ í”„ë ˆì„ì›Œí¬ëŠ” ì‹¤ì œ í™˜ê²½ì—ì„œì˜ ì¥ì•  ìŒì„± ì¸ì‹ì„ ìœ„í•œ í™•ì¥ ê°€ëŠ¥í•˜ê³  íš¨ìœ¨ì ì¸ ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.

---

*Generated on 2025-09-22 14:54:03*