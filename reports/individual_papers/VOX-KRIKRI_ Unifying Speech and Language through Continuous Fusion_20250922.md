# VOX-KRIKRI: Unifying Speech and Language through Continuous Fusion

**Korean Title:** VOX-KRIKRI: ì—°ì† ìœµí•©ì„ í†µí•œ ìŒì„±ê³¼ ì–¸ì–´ì˜ í†µí•©

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[reports/digests/daily_digest_20250922|2025-09-22]] [[keywords/specific/Cross-modal Attention|Cross-modal Attention]] [[keywords/specific/Multimodal Fusion|Multimodal Fusion]] [[keywords/broad/Large Language Models|Large Language Models]] [[keywords/broad/Automatic Speech Recognition|Automatic Speech Recognition]] [[keywords/unique/VoxKrikri|VoxKrikri]] [[categories/cs.CL|cs.CL]] [[2025-09-22/Speech Language Models for Under-Represented Languages_ Insights from Wolof_20250922|Speech Language Models for Under-Represented Languages: Insights from Wolof]] (81.3% similar) [[2025-09-22/Think, Verbalize, then Speak_ Bridging Complex Thoughts and Comprehensible Speech_20250922|Think, Verbalize, then Speak: Bridging Complex Thoughts and Comprehensible Speech]] (80.8% similar) [[2025-09-19/Cross-Modal Knowledge Distillation for Speech Large Language Models_20250919|Cross-Modal Knowledge Distillation for Speech Large Language Models]] (80.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: Cross-modal Attention, Multimodal Fusion
**ğŸ”¬ Broad Technical**: Large Language Models, Automatic Speech Recognition
**â­ Unique Technical**: VoxKrikri
## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Speech Language Models for Under-Represented Languages_ Insights from Wolof_20250922|Speech Language Models for Under-Represented Languages Insights from Wolof]] (81.3% similar)
- [[2025-09-22/Think, Verbalize, then Speak_ Bridging Complex Thoughts and Comprehensible Speech_20250922|Think, Verbalize, then Speak Bridging Complex Thoughts and Comprehensible Speech]] (80.8% similar)
- [[2025-09-19/Cross-Modal Knowledge Distillation for Speech Large Language Models_20250919|Cross-Modal Knowledge Distillation for Speech Large Language Models]] (80.5% similar)
- [[2025-09-22/Session-Level Spoken Language Assessment with a Multimodal Foundation Model via Multi-Target Learning_20250922|Session-Level Spoken Language Assessment with a Multimodal Foundation Model via Multi-Target Learning]] (80.1% similar)
- [[2025-09-22/Exploring Polyglot Harmony_ On Multilingual Data Allocation for Large Language Models Pretraining_20250922|Exploring Polyglot Harmony On Multilingual Data Allocation for Large Language Models Pretraining]] (79.8% similar)


**ArXiv ID**: [2509.15667](https://arxiv.org/abs/2509.15667)
**Published**: 2025-09-22
**Category**: cs.CL
**PDF**: [Download](https://arxiv.org/pdf/2509.15667.pdf)


**ArXiv ID**: [2509.15667](https://arxiv.org/abs/2509.15667)
**Published**: 2025-09-22
**Category**: cs.CL
**PDF**: [Download](https://arxiv.org/pdf/2509.15667.pdf)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: Cross-modal Attention, Multimodal Fusion
**â­ Unique Technical**: VoxKrikri
**ğŸ”¬ Broad Technical**: Large Language Models, Automatic Speech Recognition

## ğŸ·ï¸ ì¶”ì¶œëœ í‚¤ì›Œë“œ



`Large Language Models` â€¢ 

`Automatic Speech Recognition` â€¢ 

`Cross-modal Attention` â€¢ 

`Multimodal Fusion` â€¢ 

`VoxKrikri`



## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸

Similar papers will be displayed here based on embedding similarity.

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15667v1 Announce Type: new 
Abstract: We present a multimodal fusion framework that bridges pre-trained decoder-based large language models (LLM) and acoustic encoder-decoder architectures such as Whisper, with the aim of building speech-enabled LLMs. Instead of directly using audio embeddings, we explore an intermediate audio-conditioned text space as a more effective mechanism for alignment. Our method operates fully in continuous text representation spaces, fusing Whisper's hidden decoder states with those of an LLM through cross-modal attention, and supports both offline and streaming modes. We introduce \textit{VoxKrikri}, the first Greek speech LLM, and show through analysis that our approach effectively aligns representations across modalities. These results highlight continuous space fusion as a promising path for multilingual and low-resource speech LLMs, while achieving state-of-the-art results for Automatic Speech Recognition in Greek, providing an average $\sim20\%$ relative improvement across benchmarks.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15667v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: ìš°ë¦¬ëŠ” ì‚¬ì „ í›ˆë ¨ëœ ë””ì½”ë” ê¸°ë°˜ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ê³¼ Whisperì™€ ê°™ì€ ìŒí–¥ ì¸ì½”ë”-ë””ì½”ë” ì•„í‚¤í…ì²˜ë¥¼ ì—°ê²°í•˜ì—¬ ìŒì„± ì§€ì› LLMì„ êµ¬ì¶•í•˜ê¸° ìœ„í•œ ë‹¤ì¤‘ ëª¨ë‹¬ ìœµí•© í”„ë ˆì„ì›Œí¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ì˜¤ë””ì˜¤ ì„ë² ë”©ì„ ì§ì ‘ ì‚¬ìš©í•˜ëŠ” ëŒ€ì‹ , ìš°ë¦¬ëŠ” ì •ë ¬ì„ ìœ„í•œ ë³´ë‹¤ íš¨ê³¼ì ì¸ ë©”ì»¤ë‹ˆì¦˜ìœ¼ë¡œì„œ ì¤‘ê°„ ì˜¤ë””ì˜¤ ì¡°ê±´ë¶€ í…ìŠ¤íŠ¸ ê³µê°„ì„ íƒìƒ‰í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ë°©ë²•ì€ Whisperì˜ ìˆ¨ê²¨ì§„ ë””ì½”ë” ìƒíƒœë¥¼ LLMì˜ ìƒíƒœì™€ êµì°¨ ëª¨ë‹¬ ì£¼ì˜ë¥¼ í†µí•´ ìœµí•©í•˜ì—¬, ì—°ì†ì ì¸ í…ìŠ¤íŠ¸ í‘œí˜„ ê³µê°„ì—ì„œ ì™„ì „íˆ ì‘ë™í•˜ë©° ì˜¤í”„ë¼ì¸ ë° ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œë¥¼ ëª¨ë‘ ì§€ì›í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì²« ë²ˆì§¸ ê·¸ë¦¬ìŠ¤ì–´ ìŒì„± LLMì¸ \textit{VoxKrikri}ë¥¼ ì†Œê°œí•˜ê³ , ë¶„ì„ì„ í†µí•´ ìš°ë¦¬ì˜ ì ‘ê·¼ ë°©ì‹ì´ ëª¨ë‹¬ë¦¬í‹° ê°„ í‘œí˜„ì„ íš¨ê³¼ì ìœ¼ë¡œ ì •ë ¬í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŸ¬í•œ ê²°ê³¼ëŠ” ì—°ì† ê³µê°„ ìœµí•©ì´ ë‹¤êµ­ì–´ ë° ì €ìì› ìŒì„± LLMì„ ìœ„í•œ ìœ ë§í•œ ê²½ë¡œì„ì„ ê°•ì¡°í•˜ë©°, ê·¸ë¦¬ìŠ¤ì–´ ìë™ ìŒì„± ì¸ì‹ì—ì„œ ë²¤ì¹˜ë§ˆí¬ ì „ë°˜ì— ê±¸ì³ í‰ê·  ì•½ 20%ì˜ ìƒëŒ€ì  ê°œì„ ì„ ì œê³µí•˜ë©´ì„œ ìµœì²¨ë‹¨ ê²°ê³¼ë¥¼ ë‹¬ì„±í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì‚¬ì „ í•™ìŠµëœ ë””ì½”ë” ê¸°ë°˜ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ê³¼ Whisperì™€ ê°™ì€ ìŒì„± ì¸ì½”ë”-ë””ì½”ë” ì•„í‚¤í…ì²˜ë¥¼ ì—°ê²°í•˜ëŠ” ë‹¤ì¤‘ ëª¨ë‹¬ ìœµí•© í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì˜¤ë””ì˜¤ ì„ë² ë”©ì„ ì§ì ‘ ì‚¬ìš©í•˜ëŠ” ëŒ€ì‹ , ì˜¤ë””ì˜¤ ì¡°ê±´ë¶€ í…ìŠ¤íŠ¸ ê³µê°„ì„ í™œìš©í•˜ì—¬ ë” íš¨ê³¼ì ì¸ ì •ë ¬ ë©”ì»¤ë‹ˆì¦˜ì„ íƒêµ¬í•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ Whisperì˜ ìˆ¨ê²¨ì§„ ë””ì½”ë” ìƒíƒœì™€ LLMì˜ ìƒíƒœë¥¼ êµì°¨ ëª¨ë‹¬ ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ìœ¼ë¡œ ìœµí•©í•˜ì—¬ ì—°ì†ì ì¸ í…ìŠ¤íŠ¸ í‘œí˜„ ê³µê°„ì—ì„œ ì‘ë™í•˜ë©°, ì˜¤í”„ë¼ì¸ ë° ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œë¥¼ ì§€ì›í•©ë‹ˆë‹¤. ì´ ì—°êµ¬ì—ì„œëŠ” ì²« ë²ˆì§¸ ê·¸ë¦¬ìŠ¤ì–´ ìŒì„± LLMì¸ \textit{VoxKrikri}ë¥¼ ì†Œê°œí•˜ê³ , ì œì•ˆëœ ë°©ë²•ì´ ëª¨ë‹¬ë¦¬í‹° ê°„ í‘œí˜„ì„ íš¨ê³¼ì ìœ¼ë¡œ ì •ë ¬í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ ê²°ê³¼ëŠ” ì—°ì† ê³µê°„ ìœµí•©ì´ ë‹¤êµ­ì–´ ë° ì €ìì› ìŒì„± LLMì— ìœ ë§í•œ ê²½ë¡œì„ì„ ê°•ì¡°í•˜ë©°, ê·¸ë¦¬ìŠ¤ì–´ ìë™ ìŒì„± ì¸ì‹ì—ì„œ ìµœì²¨ë‹¨ ê²°ê³¼ë¥¼ ë‹¬ì„±í•˜ì—¬ ë²¤ì¹˜ë§ˆí¬ì—ì„œ í‰ê·  ì•½ 20%ì˜ ìƒëŒ€ì  í–¥ìƒì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸


- 1. ë³¸ ì—°êµ¬ëŠ” Whisperì™€ ê°™ì€ ìŒì„± ì¸ì½”ë”-ë””ì½”ë” ì•„í‚¤í…ì²˜ì™€ ì‚¬ì „ í•™ìŠµëœ ë””ì½”ë” ê¸°ë°˜ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ ì—°ê²°í•˜ëŠ” ë‹¤ì¤‘ ëª¨ë‹¬ ìœµí•© í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.

- 2. ì˜¤ë””ì˜¤ ì„ë² ë”©ì„ ì§ì ‘ ì‚¬ìš©í•˜ëŠ” ëŒ€ì‹ , ì¤‘ê°„ ì˜¤ë””ì˜¤ ì¡°ê±´ë¶€ í…ìŠ¤íŠ¸ ê³µê°„ì„ í™œìš©í•˜ì—¬ ë” íš¨ê³¼ì ì¸ ì •ë ¬ ë©”ì»¤ë‹ˆì¦˜ì„ íƒêµ¬í•©ë‹ˆë‹¤.

- 3. Whisperì˜ ìˆ¨ê²¨ì§„ ë””ì½”ë” ìƒíƒœì™€ LLMì˜ ìƒíƒœë¥¼ êµì°¨ ëª¨ë‹¬ ì£¼ì˜ë¥¼ í†µí•´ ìœµí•©í•˜ì—¬ ì—°ì†ì ì¸ í…ìŠ¤íŠ¸ í‘œí˜„ ê³µê°„ì—ì„œ ì‘ë™í•˜ë©°, ì˜¤í”„ë¼ì¸ ë° ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œë¥¼ ëª¨ë‘ ì§€ì›í•©ë‹ˆë‹¤.

- 4. ê·¸ë¦¬ìŠ¤ì–´ ìŒì„± LLMì¸ \textit{VoxKrikri}ë¥¼ ì†Œê°œí•˜ë©°, ì œì•ˆëœ ë°©ë²•ì´ ëª¨ë‹¬ë¦¬í‹° ê°„ í‘œí˜„ì„ íš¨ê³¼ì ìœ¼ë¡œ ì •ë ¬í•¨ì„ ë¶„ì„ì„ í†µí•´ ì…ì¦í•©ë‹ˆë‹¤.

- 5. ë³¸ ì ‘ê·¼ë²•ì€ ê·¸ë¦¬ìŠ¤ì–´ ìë™ ìŒì„± ì¸ì‹ì—ì„œ ìµœì²¨ë‹¨ ê²°ê³¼ë¥¼ ë‹¬ì„±í•˜ë©°, ë²¤ì¹˜ë§ˆí¬ ì „ë°˜ì— ê±¸ì³ í‰ê·  ì•½ 20%ì˜ ìƒëŒ€ì  ê°œì„ ì„ ì œê³µí•©ë‹ˆë‹¤.


---

*Generated on 2025-09-22 16:25:45*