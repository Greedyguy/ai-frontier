# Nonconvex Regularization for Feature Selection in Reinforcement Learning

**Korean Title:** ë¹„ë³¼ë¡ ì •ê·œí™” ê¸°ë²•ì„ í™œìš©í•œ ê°•í™” í•™ìŠµì—ì„œì˜ íŠ¹ì§• ì„ íƒ

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Forward-Reflected-Backward Splitting

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Multi-Fidelity Hybrid Reinforcement Learning via Information Gain Maximization_20250919|Multi-Fidelity Hybrid Reinforcement Learning via Information Gain Maximization]] (82.9% similar)
- [[2025-09-22/Deep Reinforcement Learning with Gradient Eligibility Traces_20250922|Deep Reinforcement Learning with Gradient Eligibility Traces]] (82.5% similar)
- [[2025-09-22/PVPO_ Pre-Estimated Value-Based Policy Optimization for Agentic Reasoning_20250922|PVPO Pre-Estimated Value-Based Policy Optimization for Agentic Reasoning]] (82.1% similar)
- [[2025-09-22/Uncertainty-Based Smooth Policy Regularisation for Reinforcement Learning with Few Demonstrations_20250922|Uncertainty-Based Smooth Policy Regularisation for Reinforcement Learning with Few Demonstrations]] (82.0% similar)
- [[2025-09-22/Adaptive Algorithms with Sharp Convergence Rates for Stochastic Hierarchical Optimization_20250922|Adaptive Algorithms with Sharp Convergence Rates for Stochastic Hierarchical Optimization]] (81.9% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15652v1 Announce Type: new 
Abstract: This work proposes an efficient batch algorithm for feature selection in reinforcement learning (RL) with theoretical convergence guarantees. To mitigate the estimation bias inherent in conventional regularization schemes, the first contribution extends policy evaluation within the classical least-squares temporal-difference (LSTD) framework by formulating a Bellman-residual objective regularized with the sparsity-inducing, nonconvex projected minimax concave (PMC) penalty. Owing to the weak convexity of the PMC penalty, this formulation can be interpreted as a special instance of a general nonmonotone-inclusion problem. The second contribution establishes novel convergence conditions for the forward-reflected-backward splitting (FRBS) algorithm to solve this class of problems. Numerical experiments on benchmark datasets demonstrate that the proposed approach substantially outperforms state-of-the-art feature-selection methods, particularly in scenarios with many noisy features.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15652v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: ë³¸ ì—°êµ¬ëŠ” ì´ë¡ ì  ìˆ˜ë ´ ë³´ì¥ì„ ê°–ì¶˜ ê°•í™” í•™ìŠµ(RL)ì—ì„œì˜ íš¨ìœ¨ì ì¸ ë°°ì¹˜ ì•Œê³ ë¦¬ì¦˜ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ì •ê·œí™” ë°©ì‹ì— ë‚´ì¬ëœ ì¶”ì • í¸í–¥ì„ ì™„í™”í•˜ê¸° ìœ„í•´, ì²« ë²ˆì§¸ ê¸°ì—¬ëŠ” ê³ ì „ì ì¸ ìµœì†ŒììŠ¹ ì‹œì°¨ì°¨ì´(LSTD) í”„ë ˆì„ì›Œí¬ ë‚´ì—ì„œ ì •ì±… í‰ê°€ë¥¼ í™•ì¥í•˜ì—¬, í¬ì†Œì„±ì„ ìœ ë„í•˜ëŠ” ë¹„ë³¼ë¡ íˆ¬ì˜ ê·¹ì†Œ ì˜¤ëª©(PMC) íŒ¨ë„í‹°ë¡œ ì •ê·œí™”ëœ ë²¨ë§Œ ì”ì°¨ ëª©ì ì„ ê³µì‹í™”í•©ë‹ˆë‹¤. PMC íŒ¨ë„í‹°ì˜ ì•½í•œ ë³¼ë¡ì„± ë•ë¶„ì—, ì´ ê³µì‹ì€ ì¼ë°˜ì ì¸ ë¹„ë‹¨ì¡° í¬í•¨ ë¬¸ì œì˜ íŠ¹ë³„í•œ ì‚¬ë¡€ë¡œ í•´ì„ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‘ ë²ˆì§¸ ê¸°ì—¬ëŠ” ì´ í´ë˜ìŠ¤ì˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ì „ì§„-ë°˜ì‚¬-í›„ì§„ ë¶„í• (FRBS) ì•Œê³ ë¦¬ì¦˜ì— ëŒ€í•œ ìƒˆë¡œìš´ ìˆ˜ë ´ ì¡°ê±´ì„ í™•ë¦½í•©ë‹ˆë‹¤. ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì— ëŒ€í•œ ìˆ˜ì¹˜ ì‹¤í—˜ì€ ì œì•ˆëœ ì ‘ê·¼ ë°©ì‹ì´ íŠ¹íˆ ë§ì€ ì¡ìŒì´ ìˆëŠ” íŠ¹ì§•ì´ ìˆëŠ” ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ìµœì²¨ë‹¨ íŠ¹ì§• ì„ íƒ ë°©ë²•ì„ ìƒë‹¹íˆ ëŠ¥ê°€í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” ê°•í™” í•™ìŠµì—ì„œ íš¨ìœ¨ì ì¸ íŠ¹ì„± ì„ íƒì„ ìœ„í•œ ë°°ì¹˜ ì•Œê³ ë¦¬ì¦˜ì„ ì œì•ˆí•˜ë©°, ì´ë¡ ì  ìˆ˜ë ´ ë³´ì¥ì„ ì œê³µí•©ë‹ˆë‹¤. ì²« ë²ˆì§¸ ê¸°ì—¬ëŠ” ê¸°ì¡´ì˜ ì •ê·œí™” ë°©ì‹ì˜ ì¶”ì • í¸í–¥ì„ ì¤„ì´ê¸° ìœ„í•´, ê³ ì „ì ì¸ ìµœì†ŒììŠ¹ ì‹œì°¨ì°¨ì´(LSTD) í”„ë ˆì„ì›Œí¬ ë‚´ì—ì„œ ë²¨ë§Œ ì”ì°¨ ëª©í‘œë¥¼ í¬ì†Œì„±ì„ ìœ ë„í•˜ëŠ” ë¹„ë³¼ë¡ PMC í˜ë„í‹°ë¡œ ì •ê·œí™”í•˜ì—¬ ì •ì±… í‰ê°€ë¥¼ í™•ì¥í•œ ê²ƒì…ë‹ˆë‹¤. ë‘ ë²ˆì§¸ ê¸°ì—¬ëŠ” ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ FRBS ì•Œê³ ë¦¬ì¦˜ì˜ ìƒˆë¡œìš´ ìˆ˜ë ´ ì¡°ê±´ì„ ì œì‹œí•œ ê²ƒì…ë‹ˆë‹¤. ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì— ëŒ€í•œ ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì´ íŠ¹íˆ ë§ì€ ì¡ìŒì´ ìˆëŠ” íŠ¹ì„± ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ìµœì‹  íŠ¹ì„± ì„ íƒ ë°©ë²•ë³´ë‹¤ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ê°•í™” í•™ìŠµì—ì„œ íš¨ìœ¨ì ì¸ íŠ¹ì§• ì„ íƒì„ ìœ„í•œ ë°°ì¹˜ ì•Œê³ ë¦¬ì¦˜ì„ ì œì•ˆí•˜ê³  ì´ë¡ ì  ìˆ˜ë ´ ë³´ì¥ì„ ì œê³µí•œë‹¤.

- 2. ê¸°ì¡´ ì •ê·œí™” ë°©ì‹ì˜ ì¶”ì • í¸í–¥ì„ ì™„í™”í•˜ê¸° ìœ„í•´, ë¹„ë³¼ë¡ PMC í˜ë„í‹°ë¥¼ ì‚¬ìš©í•œ ë²¨ë§Œ ì”ì°¨ ëª©ì ì„ ê³µì‹í™”í•˜ì—¬ LSTD í”„ë ˆì„ì›Œí¬ ë‚´ì—ì„œ ì •ì±… í‰ê°€ë¥¼ í™•ì¥í•œë‹¤.

- 3. PMC í˜ë„í‹°ì˜ ì•½í•œ ë³¼ë¡ì„± ë•ë¶„ì—, ì´ ê³µì‹í™”ëŠ” ì¼ë°˜ì ì¸ ë¹„ë‹¨ì¡° í¬í•¨ ë¬¸ì œì˜ íŠ¹ìˆ˜í•œ ì‚¬ë¡€ë¡œ í•´ì„ë  ìˆ˜ ìˆë‹¤.

- 4. FRBS ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ìˆ˜ë ´ ì¡°ê±´ì„ í™•ë¦½í•œë‹¤.

- 5. ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì— ëŒ€í•œ ìˆ˜ì¹˜ ì‹¤í—˜ì—ì„œ ì œì•ˆëœ ì ‘ê·¼ë²•ì´ íŠ¹íˆ ë§ì€ ì¡ìŒì´ ìˆëŠ” íŠ¹ì§•ì´ ìˆëŠ” ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ìµœì²¨ë‹¨ íŠ¹ì§• ì„ íƒ ë°©ë²•ì„ ëŠ¥ê°€í•¨ì„ ì…ì¦í•œë‹¤.

---

*Generated on 2025-09-22 15:21:37*