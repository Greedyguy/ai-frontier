---
keywords:
  - Video Generation
  - World Model
  - Image Tokenizer
  - Pre-trained Models
  - Automotive Driving Scenes
category: cs.CV
publish_date: 2025-09-22
arxiv_id: 2509.15479
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:58:16.912892",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Video Generation",
    "World Model",
    "Image Tokenizer",
    "Pre-trained Models",
    "Automotive Driving Scenes"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Video Generation": 0.78,
    "World Model": 0.81,
    "Image Tokenizer": 0.74,
    "Pre-trained Models": 0.79,
    "Automotive Driving Scenes": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "video generation",
        "canonical": "Video Generation",
        "aliases": [
          "video synthesis",
          "video creation"
        ],
        "category": "broad_technical",
        "rationale": "Video generation is a key process in creating realistic driving scenes and connects to broader computer vision tasks.",
        "novelty_score": 0.45,
        "connectivity_score": 0.85,
        "specificity_score": 0.65,
        "link_intent_score": 0.78
      },
      {
        "surface": "world model",
        "canonical": "World Model",
        "aliases": [
          "environment model",
          "scene model"
        ],
        "category": "specific_connectable",
        "rationale": "World models are crucial for predicting future states in video generation, linking to predictive modeling.",
        "novelty_score": 0.58,
        "connectivity_score": 0.79,
        "specificity_score": 0.72,
        "link_intent_score": 0.81
      },
      {
        "surface": "image tokenizer",
        "canonical": "Image Tokenizer",
        "aliases": [
          "visual tokenizer",
          "image encoding"
        ],
        "category": "unique_technical",
        "rationale": "Image tokenization is a unique technical step in the pipeline, essential for processing visual data.",
        "novelty_score": 0.65,
        "connectivity_score": 0.68,
        "specificity_score": 0.77,
        "link_intent_score": 0.74
      },
      {
        "surface": "pre-trained open source models",
        "canonical": "Pre-trained Models",
        "aliases": [
          "open source models",
          "pre-trained frameworks"
        ],
        "category": "specific_connectable",
        "rationale": "Using pre-trained models is a common practice that enhances connectivity with existing machine learning frameworks.",
        "novelty_score": 0.52,
        "connectivity_score": 0.82,
        "specificity_score": 0.7,
        "link_intent_score": 0.79
      },
      {
        "surface": "automotive driving scenes",
        "canonical": "Automotive Driving Scenes",
        "aliases": [
          "driving scenarios",
          "vehicle scenes"
        ],
        "category": "unique_technical",
        "rationale": "This is a specific application area that connects to autonomous driving and simulation research.",
        "novelty_score": 0.67,
        "connectivity_score": 0.73,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "video generation",
      "resolved_canonical": "Video Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.85,
        "specificity": 0.65,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "world model",
      "resolved_canonical": "World Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.79,
        "specificity": 0.72,
        "link_intent": 0.81
      }
    },
    {
      "candidate_surface": "image tokenizer",
      "resolved_canonical": "Image Tokenizer",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.68,
        "specificity": 0.77,
        "link_intent": 0.74
      }
    },
    {
      "candidate_surface": "pre-trained open source models",
      "resolved_canonical": "Pre-trained Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.52,
        "connectivity": 0.82,
        "specificity": 0.7,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "automotive driving scenes",
      "resolved_canonical": "Automotive Driving Scenes",
      "decision": "linked",
      "scores": {
        "novelty": 0.67,
        "connectivity": 0.73,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# OpenViGA: Video Generation for Automotive Driving Scenes by Streamlining and Fine-Tuning Open Source Models with Public Data

**Korean Title:** OpenViGA: ê³µê°œ ë°ì´í„°ë¡œ ì˜¤í”ˆ ì†ŒìŠ¤ ëª¨ë¸ì„ ìµœì í™”í•˜ì—¬ ìë™ì°¨ ì£¼í–‰ ì¥ë©´ì„ ìœ„í•œ ë¹„ë””ì˜¤ ìƒì„±

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15479.pdf)
**Category**: cs.CV
**Published**: 2025-09-22
**ArXiv ID**: [2509.15479](https://arxiv.org/abs/2509.15479)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/WorldForge_ Unlocking Emergent 3D/4D Generation in Video Diffusion Model via Training-Free Guidance_20250919|WorldForge: Unlocking Emergent 3D/4D Generation in Video Diffusion Model via Training-Free Guidance]] (81.9% similar)
- [[2025-09-19/SPATIALGEN_ Layout-guided 3D Indoor Scene Generation_20250919|SPATIALGEN: Layout-guided 3D Indoor Scene Generation]] (81.0% similar)
- [[2025-09-18/FlightDiffusion_ Revolutionising Autonomous Drone Training with Diffusion Models Generating FPV Video_20250918|FlightDiffusion: Revolutionising Autonomous Drone Training with Diffusion Models Generating FPV Video]] (80.6% similar)
- [[2025-09-22/Enhancing Sa2VA for Referent Video Object Segmentation_ 2nd Solution for 7th LSVOS RVOS Track_20250922|Enhancing Sa2VA for Referent Video Object Segmentation: 2nd Solution for 7th LSVOS RVOS Track]] (80.2% similar)
- [[2025-09-19/A Mutual Information Perspective on Multiple Latent Variable Generative Models for Positive View Generation_20250919|A Mutual Information Perspective on Multiple Latent Variable Generative Models for Positive View Generation]] (79.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Video Generation|Video Generation]]
**ğŸ”— Specific Connectable**: [[keywords/World Model|World Model]], [[keywords/Pre-trained Models|Pre-trained Models]]
**âš¡ Unique Technical**: [[keywords/Image Tokenizer|Image Tokenizer]], [[keywords/Automotive Driving Scenes|Automotive Driving Scenes]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15479v1 Announce Type: new 
Abstract: Recent successful video generation systems that predict and create realistic automotive driving scenes from short video inputs assign tokenization, future state prediction (world model), and video decoding to dedicated models. These approaches often utilize large models that require significant training resources, offer limited insight into design choices, and lack publicly available code and datasets. In this work, we address these deficiencies and present OpenViGA, an open video generation system for automotive driving scenes. Our contributions are: Unlike several earlier works for video generation, such as GAIA-1, we provide a deep analysis of the three components of our system by separate quantitative and qualitative evaluation: Image tokenizer, world model, video decoder. Second, we purely build upon powerful pre-trained open source models from various domains, which we fine-tune by publicly available automotive data (BDD100K) on GPU hardware at academic scale. Third, we build a coherent video generation system by streamlining interfaces of our components. Fourth, due to public availability of the underlying models and data, we allow full reproducibility. Finally, we also publish our code and models on Github. For an image size of 256x256 at 4 fps we are able to predict realistic driving scene videos frame-by-frame with only one frame of algorithmic latency.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15479v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: ìµœê·¼ì˜ ì„±ê³µì ì¸ ë¹„ë””ì˜¤ ìƒì„± ì‹œìŠ¤í…œì€ ì§§ì€ ë¹„ë””ì˜¤ ì…ë ¥ìœ¼ë¡œë¶€í„° í˜„ì‹¤ì ì¸ ìë™ì°¨ ìš´ì „ ì¥ë©´ì„ ì˜ˆì¸¡í•˜ê³  ìƒì„±í•˜ë©°, í† í°í™”, ë¯¸ë˜ ìƒíƒœ ì˜ˆì¸¡(ì›”ë“œ ëª¨ë¸), ë¹„ë””ì˜¤ ë””ì½”ë”©ì„ ì „ìš© ëª¨ë¸ì— í• ë‹¹í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì ‘ê·¼ ë°©ì‹ì€ ì¢…ì¢… ìƒë‹¹í•œ í›ˆë ¨ ìì›ì´ í•„ìš”í•œ ëŒ€í˜• ëª¨ë¸ì„ ì‚¬ìš©í•˜ë©°, ì„¤ê³„ ì„ íƒì— ëŒ€í•œ í†µì°°ë ¥ì´ ì œí•œì ì´ê³ , ê³µê°œì ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ì½”ë“œì™€ ë°ì´í„°ì…‹ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” ì´ëŸ¬í•œ ê²°ì ì„ í•´ê²°í•˜ê³  ìë™ì°¨ ìš´ì „ ì¥ë©´ì„ ìœ„í•œ ì˜¤í”ˆ ë¹„ë””ì˜¤ ìƒì„± ì‹œìŠ¤í…œì¸ OpenViGAë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ê¸°ì—¬ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤: GAIA-1ê³¼ ê°™ì€ ì—¬ëŸ¬ ì´ì „ ë¹„ë””ì˜¤ ìƒì„± ì—°êµ¬ì™€ ë‹¬ë¦¬, ìš°ë¦¬ëŠ” ì‹œìŠ¤í…œì˜ ì„¸ ê°€ì§€ êµ¬ì„± ìš”ì†Œ(ì´ë¯¸ì§€ í† í¬ë‚˜ì´ì €, ì›”ë“œ ëª¨ë¸, ë¹„ë””ì˜¤ ë””ì½”ë”)ì— ëŒ€í•œ ì‹¬ì¸µ ë¶„ì„ì„ ë³„ë„ì˜ ì •ëŸ‰ì  ë° ì •ì„±ì  í‰ê°€ë¥¼ í†µí•´ ì œê³µí•©ë‹ˆë‹¤. ë‘ ë²ˆì§¸ë¡œ, ìš°ë¦¬ëŠ” ë‹¤ì–‘í•œ ë„ë©”ì¸ì—ì„œ ê°•ë ¥í•œ ì‚¬ì „ í›ˆë ¨ëœ ì˜¤í”ˆ ì†ŒìŠ¤ ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ì—¬, ê³µê°œì ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ìë™ì°¨ ë°ì´í„°(BDD100K)ë¥¼ GPU í•˜ë“œì›¨ì–´ì—ì„œ í•™ë¬¸ì  ê·œëª¨ë¡œ ë¯¸ì„¸ ì¡°ì •í•©ë‹ˆë‹¤. ì„¸ ë²ˆì§¸ë¡œ, êµ¬ì„± ìš”ì†Œì˜ ì¸í„°í˜ì´ìŠ¤ë¥¼ ê°„ì†Œí™”í•˜ì—¬ ì¼ê´€ëœ ë¹„ë””ì˜¤ ìƒì„± ì‹œìŠ¤í…œì„ êµ¬ì¶•í•©ë‹ˆë‹¤. ë„¤ ë²ˆì§¸ë¡œ, ê¸°ë³¸ ëª¨ë¸ê³¼ ë°ì´í„°ì˜ ê³µê°œ ì‚¬ìš© ê°€ëŠ¥ì„± ë•ë¶„ì— ì™„ì „í•œ ì¬í˜„ì„±ì„ í—ˆìš©í•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ, ìš°ë¦¬ëŠ” Githubì— ì½”ë“œì™€ ëª¨ë¸ì„ ê³µê°œí•©ë‹ˆë‹¤. 256x256 ì´ë¯¸ì§€ í¬ê¸°ì—ì„œ 4 fpsë¡œ, ìš°ë¦¬ëŠ” ì•Œê³ ë¦¬ì¦˜ ì§€ì—°ì´ ë‹¨ í•œ í”„ë ˆì„ì¸ ìƒíƒœì—ì„œ í”„ë ˆì„ë³„ë¡œ í˜„ì‹¤ì ì¸ ìš´ì „ ì¥ë©´ ë¹„ë””ì˜¤ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì—ì„œëŠ” ìë™ì°¨ ì£¼í–‰ ì¥ë©´ì„ ìƒì„±í•˜ëŠ” ë¹„ë””ì˜¤ ìƒì„± ì‹œìŠ¤í…œì¸ OpenViGAë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ëŒ€ê·œëª¨ ëª¨ë¸ê³¼ ë‹¬ë¦¬, OpenViGAëŠ” ì´ë¯¸ì§€ í† í¬ë‚˜ì´ì €, ì›”ë“œ ëª¨ë¸, ë¹„ë””ì˜¤ ë””ì½”ë”ì˜ ì„¸ ê°€ì§€ êµ¬ì„± ìš”ì†Œë¥¼ ì •ëŸ‰ì  ë° ì •ì„±ì ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤. ë˜í•œ, ë‹¤ì–‘í•œ ë„ë©”ì¸ì˜ ê°•ë ¥í•œ ì˜¤í”ˆ ì†ŒìŠ¤ ëª¨ë¸ì„ ì‚¬ìš©í•˜ê³ , ê³µê°œëœ ìë™ì°¨ ë°ì´í„°(BDD100K)ë¥¼ í™œìš©í•˜ì—¬ í•™ë¬¸ì  ê·œëª¨ì˜ GPU í•˜ë“œì›¨ì–´ì—ì„œ ë¯¸ì„¸ ì¡°ì •í•©ë‹ˆë‹¤. ì‹œìŠ¤í…œ êµ¬ì„± ìš”ì†Œ ê°„ì˜ ì¸í„°í˜ì´ìŠ¤ë¥¼ ìµœì í™”í•˜ì—¬ ì¼ê´€ëœ ë¹„ë””ì˜¤ ìƒì„± ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ì˜€ìœ¼ë©°, ëª¨ë“  ëª¨ë¸ê³¼ ë°ì´í„°ë¥¼ ê³µê°œí•˜ì—¬ ì¬í˜„ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤. ìµœì¢…ì ìœ¼ë¡œ, 256x256 í•´ìƒë„ì—ì„œ 4fpsë¡œ í˜„ì‹¤ì ì¸ ì£¼í–‰ ì¥ë©´ ë¹„ë””ì˜¤ë¥¼ í”„ë ˆì„ ë‹¨ìœ„ë¡œ ì˜ˆì¸¡í•  ìˆ˜ ìˆìœ¼ë©°, ì½”ë“œì™€ ëª¨ë¸ì„ Githubì— ê³µê°œí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. OpenViGAëŠ” ìë™ì°¨ ì£¼í–‰ ì¥ë©´ì˜ ë¹„ë””ì˜¤ ìƒì„±ì„ ìœ„í•œ ì˜¤í”ˆ ì‹œìŠ¤í…œìœ¼ë¡œ, ì´ë¯¸ì§€ í† í¬ë‚˜ì´ì €, ì›”ë“œ ëª¨ë¸, ë¹„ë””ì˜¤ ë””ì½”ë”ì˜ ì„¸ ê°€ì§€ êµ¬ì„± ìš”ì†Œë¥¼ ì‹¬ì¸µ ë¶„ì„í•©ë‹ˆë‹¤.
- 2. ë‹¤ì–‘í•œ ë„ë©”ì¸ì—ì„œ ì‚¬ì „ í›ˆë ¨ëœ ì˜¤í”ˆ ì†ŒìŠ¤ ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ì—¬, ê³µê°œëœ ìë™ì°¨ ë°ì´í„°(BDD100K)ë¥¼ ì‚¬ìš©í•´ í•™ìˆ ì  ê·œëª¨ì˜ GPU í•˜ë“œì›¨ì–´ì—ì„œ ë¯¸ì„¸ ì¡°ì •í•©ë‹ˆë‹¤.
- 3. êµ¬ì„± ìš”ì†Œì˜ ì¸í„°í˜ì´ìŠ¤ë¥¼ ê°„ì†Œí™”í•˜ì—¬ ì¼ê´€ëœ ë¹„ë””ì˜¤ ìƒì„± ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ì˜€ìŠµë‹ˆë‹¤.
- 4. ê¸°ë°˜ ëª¨ë¸ê³¼ ë°ì´í„°ì˜ ê³µê°œë¡œ ì¸í•´ ì™„ì „í•œ ì¬í˜„ì„±ì„ ë³´ì¥í•˜ë©°, ì½”ë“œì™€ ëª¨ë¸ì„ Githubì— ê³µê°œí•©ë‹ˆë‹¤.
- 5. 256x256 ì´ë¯¸ì§€ í¬ê¸°ì™€ 4 fpsì—ì„œ ì•Œê³ ë¦¬ì¦˜ ì§€ì—°ì´ í•œ í”„ë ˆì„ì— ë¶ˆê³¼í•œ í˜„ì‹¤ì ì¸ ì£¼í–‰ ì¥ë©´ ë¹„ë””ì˜¤ë¥¼ í”„ë ˆì„ë³„ë¡œ ì˜ˆì¸¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-23 11:58:16*