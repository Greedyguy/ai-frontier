---
keywords:
  - Transfer Learning
  - Multi-Source Transfer Learning
  - Ensemble Learning
  - Statistical Invariant
category: cs.LG
publish_date: 2025-09-22
arxiv_id: 2509.15593
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T10:50:17.772117",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Transfer Learning",
    "Multi-Source Transfer Learning",
    "Ensemble Learning",
    "Statistical Invariant"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Transfer Learning": 0.78,
    "Multi-Source Transfer Learning": 0.82,
    "Ensemble Learning": 0.77,
    "Statistical Invariant": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "transfer learning",
        "canonical": "Transfer Learning",
        "aliases": [
          "domain adaptation",
          "knowledge transfer"
        ],
        "category": "broad_technical",
        "rationale": "Transfer Learning is a foundational concept that connects various domains and methods in machine learning.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.78
      },
      {
        "surface": "multi-source transfer learning",
        "canonical": "Multi-Source Transfer Learning",
        "aliases": [
          "multi-domain transfer",
          "multi-source adaptation"
        ],
        "category": "unique_technical",
        "rationale": "This concept is central to the paper and represents a specific approach within transfer learning.",
        "novelty_score": 0.72,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.82
      },
      {
        "surface": "ensemble learning framework",
        "canonical": "Ensemble Learning",
        "aliases": [
          "ensemble methods",
          "ensemble approach"
        ],
        "category": "specific_connectable",
        "rationale": "Ensemble Learning is a key technique that enhances model performance by combining multiple models.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.77
      },
      {
        "surface": "statistical invariant",
        "canonical": "Statistical Invariant",
        "aliases": [
          "SI",
          "statistical consistency"
        ],
        "category": "unique_technical",
        "rationale": "The concept of Statistical Invariant is novel and crucial for the proposed method in the paper.",
        "novelty_score": 0.78,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance",
      "process",
      "framework"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "transfer learning",
      "resolved_canonical": "Transfer Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "multi-source transfer learning",
      "resolved_canonical": "Multi-Source Transfer Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "ensemble learning framework",
      "resolved_canonical": "Ensemble Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "statistical invariant",
      "resolved_canonical": "Statistical Invariant",
      "decision": "linked",
      "scores": {
        "novelty": 0.78,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# SETrLUSI: Stochastic Ensemble Multi-Source Transfer Learning Using Statistical Invariant

**Korean Title:** SETrLUSI: í†µê³„ì  ë¶ˆë³€ì„±ì„ í™œìš©í•œ í™•ë¥ ì  ì•™ìƒë¸” ë‹¤ì¤‘ ì†ŒìŠ¤ ì „ì´ í•™ìŠµ

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15593.pdf)
**Category**: cs.LG
**Published**: 2025-09-22
**ArXiv ID**: [2509.15593](https://arxiv.org/abs/2509.15593)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Select to Know_ An Internal-External Knowledge Self-Selection Framework for Domain-Specific Question Answering_20250919|Select to Know: An Internal-External Knowledge Self-Selection Framework for Domain-Specific Question Answering]] (80.6% similar)
- [[2025-09-22/TISDiSS_ A Training-Time and Inference-Time Scalable Framework for Discriminative Source Separation_20250922|TISDiSS: A Training-Time and Inference-Time Scalable Framework for Discriminative Source Separation]] (80.5% similar)
- [[2025-09-22/Boosting Active Learning with Knowledge Transfer_20250922|Boosting Active Learning with Knowledge Transfer]] (80.4% similar)
- [[2025-09-22/Efficient Long-Tail Learning in Latent Space by sampling Synthetic Data_20250922|Efficient Long-Tail Learning in Latent Space by sampling Synthetic Data]] (79.7% similar)
- [[2025-09-19/CodeLSI_ Leveraging Foundation Models for Automated Code Generation with Low-Rank Optimization and Domain-Specific Instruction Tuning_20250919|CodeLSI: Leveraging Foundation Models for Automated Code Generation with Low-Rank Optimization and Domain-Specific Instruction Tuning]] (79.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Transfer Learning|Transfer Learning]]
**ğŸ”— Specific Connectable**: [[keywords/Ensemble Learning|Ensemble Learning]]
**âš¡ Unique Technical**: [[keywords/Multi-Source Transfer Learning|Multi-Source Transfer Learning]], [[keywords/Statistical Invariant|Statistical Invariant]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15593v1 Announce Type: cross 
Abstract: In transfer learning, a source domain often carries diverse knowledge, and different domains usually emphasize different types of knowledge. Different from handling only a single type of knowledge from all domains in traditional transfer learning methods, we introduce an ensemble learning framework with a weak mode of convergence in the form of Statistical Invariant (SI) for multi-source transfer learning, formulated as Stochastic Ensemble Multi-Source Transfer Learning Using Statistical Invariant (SETrLUSI). The proposed SI extracts and integrates various types of knowledge from both source and target domains, which not only effectively utilizes diverse knowledge but also accelerates the convergence process. Further, SETrLUSI incorporates stochastic SI selection, proportional source domain sampling, and target domain bootstrapping, which improves training efficiency while enhancing model stability. Experiments show that SETrLUSI has good convergence and outperforms related methods with a lower time cost.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15593v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ì „ì´ í•™ìŠµì—ì„œ ì†ŒìŠ¤ ë„ë©”ì¸ì€ ì¢…ì¢… ë‹¤ì–‘í•œ ì§€ì‹ì„ í¬í•¨í•˜ê³  ìˆìœ¼ë©°, ì„œë¡œ ë‹¤ë¥¸ ë„ë©”ì¸ì€ ë³´í†µ ì„œë¡œ ë‹¤ë¥¸ ìœ í˜•ì˜ ì§€ì‹ì„ ê°•ì¡°í•©ë‹ˆë‹¤. ì „í†µì ì¸ ì „ì´ í•™ìŠµ ë°©ë²•ì—ì„œ ëª¨ë“  ë„ë©”ì¸ìœ¼ë¡œë¶€í„° ë‹¨ì¼ ìœ í˜•ì˜ ì§€ì‹ë§Œì„ ì²˜ë¦¬í•˜ëŠ” ê²ƒê³¼ ë‹¬ë¦¬, ìš°ë¦¬ëŠ” ë‹¤ì¤‘ ì†ŒìŠ¤ ì „ì´ í•™ìŠµì„ ìœ„í•œ í†µê³„ ë¶ˆë³€ëŸ‰(Statistical Invariant, SI)ì˜ í˜•íƒœë¡œ ì•½í•œ ìˆ˜ë ´ ëª¨ë“œë¥¼ ê°–ì¶˜ ì•™ìƒë¸” í•™ìŠµ í”„ë ˆì„ì›Œí¬ë¥¼ ë„ì…í•©ë‹ˆë‹¤. ì´ëŠ” í†µê³„ ë¶ˆë³€ëŸ‰ì„ ì‚¬ìš©í•œ í™•ë¥ ì  ì•™ìƒë¸” ë‹¤ì¤‘ ì†ŒìŠ¤ ì „ì´ í•™ìŠµ(Stochastic Ensemble Multi-Source Transfer Learning Using Statistical Invariant, SETrLUSI)ìœ¼ë¡œ ê³µì‹í™”ë©ë‹ˆë‹¤. ì œì•ˆëœ SIëŠ” ì†ŒìŠ¤ ë° íƒ€ê²Ÿ ë„ë©”ì¸ ëª¨ë‘ì—ì„œ ë‹¤ì–‘í•œ ìœ í˜•ì˜ ì§€ì‹ì„ ì¶”ì¶œí•˜ê³  í†µí•©í•˜ì—¬ ë‹¤ì–‘í•œ ì§€ì‹ì„ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•  ë¿ë§Œ ì•„ë‹ˆë¼ ìˆ˜ë ´ ê³¼ì •ì„ ê°€ì†í™”í•©ë‹ˆë‹¤. ë˜í•œ, SETrLUSIëŠ” í™•ë¥ ì  SI ì„ íƒ, ë¹„ë¡€ ì†ŒìŠ¤ ë„ë©”ì¸ ìƒ˜í”Œë§, íƒ€ê²Ÿ ë„ë©”ì¸ ë¶€íŠ¸ìŠ¤íŠ¸ë˜í•‘ì„ í¬í•¨í•˜ì—¬ í›ˆë ¨ íš¨ìœ¨ì„±ì„ ê°œì„ í•˜ë©´ì„œ ëª¨ë¸ ì•ˆì •ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, SETrLUSIëŠ” ìš°ìˆ˜í•œ ìˆ˜ë ´ì„±ì„ ë³´ì´ë©°, ë‚®ì€ ì‹œê°„ ë¹„ìš©ìœ¼ë¡œ ê´€ë ¨ ë°©ë²•ë“¤ë³´ë‹¤ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë°œíœ˜í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì „ì´ í•™ìŠµì—ì„œ ë‹¤ì–‘í•œ ì§€ì‹ì„ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•˜ê¸° ìœ„í•´ ë‹¤ì¤‘ ì†ŒìŠ¤ ì „ì´ í•™ìŠµì„ ìœ„í•œ í†µê³„ì  ë¶ˆë³€ëŸ‰(SI)ì„ í™œìš©í•œ ì•™ìƒë¸” í•™ìŠµ í”„ë ˆì„ì›Œí¬(SETrLUSI)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. SIëŠ” ì†ŒìŠ¤ì™€ íƒ€ê²Ÿ ë„ë©”ì¸ì—ì„œ ë‹¤ì–‘í•œ ì§€ì‹ì„ ì¶”ì¶œí•˜ê³  í†µí•©í•˜ì—¬ ìˆ˜ë ´ ê³¼ì •ì„ ê°€ì†í™”í•©ë‹ˆë‹¤. ë˜í•œ, í™•ë¥ ì  SI ì„ íƒ, ë¹„ë¡€ì  ì†ŒìŠ¤ ë„ë©”ì¸ ìƒ˜í”Œë§, íƒ€ê²Ÿ ë„ë©”ì¸ ë¶€íŠ¸ìŠ¤íŠ¸ë˜í•‘ì„ í†µí•´ í›ˆë ¨ íš¨ìœ¨ì„±ê³¼ ëª¨ë¸ ì•ˆì •ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, SETrLUSIëŠ” ìš°ìˆ˜í•œ ìˆ˜ë ´ì„±ì„ ë³´ì´ë©° ê´€ë ¨ ë°©ë²•ë“¤ë³´ë‹¤ ë‚®ì€ ì‹œê°„ ë¹„ìš©ìœ¼ë¡œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. SETrLUSIëŠ” ë‹¤ì¤‘ ì†ŒìŠ¤ ì „ì´ í•™ìŠµì„ ìœ„í•´ í†µê³„ì  ë¶ˆë³€ì„±ì„ í™œìš©í•œ ì•™ìƒë¸” í•™ìŠµ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.
- 2. ì œì•ˆëœ í†µê³„ì  ë¶ˆë³€ì„±ì€ ì†ŒìŠ¤ì™€ íƒ€ê²Ÿ ë„ë©”ì¸ì—ì„œ ë‹¤ì–‘í•œ ì§€ì‹ì„ ì¶”ì¶œí•˜ê³  í†µí•©í•˜ì—¬, ì§€ì‹ í™œìš©ì„ ê·¹ëŒ€í™”í•˜ê³  ìˆ˜ë ´ ê³¼ì •ì„ ê°€ì†í™”í•©ë‹ˆë‹¤.
- 3. SETrLUSIëŠ” í™•ë¥ ì  í†µê³„ì  ë¶ˆë³€ì„± ì„ íƒ, ë¹„ë¡€ ì†ŒìŠ¤ ë„ë©”ì¸ ìƒ˜í”Œë§, íƒ€ê²Ÿ ë„ë©”ì¸ ë¶€íŠ¸ìŠ¤íŠ¸ë˜í•‘ì„ í¬í•¨í•˜ì—¬ í›ˆë ¨ íš¨ìœ¨ì„±ì„ ê°œì„ í•˜ê³  ëª¨ë¸ì˜ ì•ˆì •ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
- 4. ì‹¤í—˜ ê²°ê³¼, SETrLUSIëŠ” ìš°ìˆ˜í•œ ìˆ˜ë ´ì„±ì„ ë³´ì´ë©° ê´€ë ¨ ë°©ë²•ë“¤ë³´ë‹¤ ë‚®ì€ ì‹œê°„ ë¹„ìš©ìœ¼ë¡œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë°œíœ˜í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-23 10:50:17*