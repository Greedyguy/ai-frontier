---
keywords:
  - Large Language Model
  - Membership Inference Attack
  - Natural Language Processing
  - Data Leakage Detection
  - Tag&Tab
category: cs.CL
publish_date: 2025-09-22
arxiv_id: 2501.08454
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:51:47.452616",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Membership Inference Attack",
    "Natural Language Processing",
    "Data Leakage Detection",
    "Tag&Tab"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Membership Inference Attack": 0.78,
    "Natural Language Processing": 0.82,
    "Data Leakage Detection": 0.77,
    "Tag&Tab": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's focus on pretraining data detection and membership inference attacks.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Membership Inference Attacks",
        "canonical": "Membership Inference Attack",
        "aliases": [
          "MIA"
        ],
        "category": "specific_connectable",
        "rationale": "Key concept for linking discussions on data privacy and security in machine learning.",
        "novelty_score": 0.7,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Natural Language Processing",
        "canonical": "Natural Language Processing",
        "aliases": [
          "NLP"
        ],
        "category": "broad_technical",
        "rationale": "Relevant for connecting to broader discussions on language model applications and techniques.",
        "novelty_score": 0.2,
        "connectivity_score": 0.88,
        "specificity_score": 0.6,
        "link_intent_score": 0.82
      },
      {
        "surface": "Data Leakage Detection",
        "canonical": "Data Leakage Detection",
        "aliases": [
          "Data Leak Detection"
        ],
        "category": "unique_technical",
        "rationale": "Unique focus of the paper, highlighting advancements in detecting unauthorized data use.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      },
      {
        "surface": "Tag&Tab",
        "canonical": "Tag&Tab",
        "aliases": [
          "Tag and Tab"
        ],
        "category": "unique_technical",
        "rationale": "Proposed novel method in the paper, crucial for understanding the new approach to data detection.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.9,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Membership Inference Attacks",
      "resolved_canonical": "Membership Inference Attack",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Natural Language Processing",
      "resolved_canonical": "Natural Language Processing",
      "decision": "linked",
      "scores": {
        "novelty": 0.2,
        "connectivity": 0.88,
        "specificity": 0.6,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Data Leakage Detection",
      "resolved_canonical": "Data Leakage Detection",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Tag&Tab",
      "resolved_canonical": "Tag&Tab",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.9,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Tag&Tab: Pretraining Data Detection in Large Language Models Using Keyword-Based Membership Inference Attack

**Korean Title:** íƒœê·¸&íƒ­: í‚¤ì›Œë“œ ê¸°ë°˜ ë©¤ë²„ì‹­ ì¶”ë¡  ê³µê²©ì„ ì´ìš©í•œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ì‚¬ì „ í•™ìŠµ ë°ì´í„° íƒì§€

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2501.08454.pdf)
**Category**: cs.CL
**Published**: 2025-09-22
**ArXiv ID**: [2501.08454](https://arxiv.org/abs/2501.08454)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/DetectAnyLLM_ Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models_20250919|DetectAnyLLM: Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models]] (86.0% similar)
- [[2025-09-19/Decoupled Proxy Alignment_ Mitigating Language Prior Conflict for Multimodal Alignment in MLLM_20250919|Decoupled Proxy Alignment: Mitigating Language Prior Conflict for Multimodal Alignment in MLLM]] (84.1% similar)
- [[2025-09-22/Can Large Language Models Infer Causal Relationships from Real-World Text?_20250922|Can Large Language Models Infer Causal Relationships from Real-World Text?]] (84.0% similar)
- [[2025-09-22/Predicting Language Models' Success at Zero-Shot Probabilistic Prediction_20250922|Predicting Language Models' Success at Zero-Shot Probabilistic Prediction]] (83.8% similar)
- [[2025-09-22/SENTRA_ Selected-Next-Token Transformer for LLM Text Detection_20250922|SENTRA: Selected-Next-Token Transformer for LLM Text Detection]] (83.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]], [[keywords/Natural Language Processing|Natural Language Processing]]
**ğŸ”— Specific Connectable**: [[keywords/Membership Inference Attack|Membership Inference Attack]]
**âš¡ Unique Technical**: [[keywords/Data Leakage Detection|Data Leakage Detection]], [[keywords/Tag&Tab|Tag&Tab]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2501.08454v2 Announce Type: replace-cross 
Abstract: Large language models (LLMs) have become essential tools for digital task assistance. Their training relies heavily on the collection of vast amounts of data, which may include copyright-protected or sensitive information. Recent studies on detecting pretraining data in LLMs have primarily focused on sentence- or paragraph-level membership inference attacks (MIAs), usually involving probability analysis of the target model's predicted tokens. However, these methods often exhibit poor accuracy, failing to account for the semantic importance of textual content and word significance. To address these shortcomings, we propose Tag&amp;Tab, a novel approach for detecting data used in LLM pretraining. Our method leverages established natural language processing (NLP) techniques to tag keywords in the input text, a process we term Tagging. Then, the LLM is used to obtain probabilities for these keywords and calculate their average log-likelihood to determine input text membership, a process we refer to as Tabbing. Our experiments on four benchmark datasets (BookMIA, MIMIR, PatentMIA, and the Pile) and several open-source LLMs of varying sizes demonstrate an average increase in AUC scores ranging from 5.3% to 17.6% over state-of-the-art methods. Tag&amp;Tab not only sets a new standard for data leakage detection in LLMs, but its outstanding performance is a testament to the importance of words in MIAs on LLMs.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2501.08454v2 ë°œí‘œ ìœ í˜•: êµì°¨ êµì²´  
ì´ˆë¡: ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ ë””ì§€í„¸ ì‘ì—… ì§€ì›ì„ ìœ„í•œ í•„ìˆ˜ ë„êµ¬ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ë“¤ì˜ í›ˆë ¨ì€ ì£¼ë¡œ ë°©ëŒ€í•œ ì–‘ì˜ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ë° ì˜ì¡´í•˜ë©°, ì—¬ê¸°ì—ëŠ” ì €ì‘ê¶Œ ë³´í˜¸ ë˜ëŠ” ë¯¼ê°í•œ ì •ë³´ê°€ í¬í•¨ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. LLMì—ì„œì˜ ì‚¬ì „ í›ˆë ¨ ë°ì´í„° íƒì§€ì— ê´€í•œ ìµœê·¼ ì—°êµ¬ëŠ” ì£¼ë¡œ ë¬¸ì¥ ë˜ëŠ” ë‹¨ë½ ìˆ˜ì¤€ì˜ ë©¤ë²„ì‹­ ì¶”ë¡  ê³µê²©(MIA)ì— ì´ˆì ì„ ë§ì¶”ê³  ìˆìœ¼ë©°, ì´ëŠ” ë³´í†µ ëŒ€ìƒ ëª¨ë¸ì˜ ì˜ˆì¸¡ëœ í† í°ì— ëŒ€í•œ í™•ë¥  ë¶„ì„ì„ í¬í•¨í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ëŸ¬í•œ ë°©ë²•ì€ ì¢…ì¢… í…ìŠ¤íŠ¸ ë‚´ìš©ì˜ ì˜ë¯¸ì  ì¤‘ìš”ì„±ê³¼ ë‹¨ì–´ì˜ ì¤‘ìš”ì„±ì„ ê³ ë ¤í•˜ì§€ ì•Šì•„ ì •í™•ë„ê°€ ë–¨ì–´ì§€ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë‹¨ì ì„ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” LLM ì‚¬ì „ í›ˆë ¨ì— ì‚¬ìš©ëœ ë°ì´í„°ë¥¼ íƒì§€í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ì ‘ê·¼ ë°©ì‹ì¸ Tag&amp;Tabì„ ì œì•ˆí•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ë°©ë²•ì€ ì…ë ¥ í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œë¥¼ íƒœê·¸í•˜ëŠ” ê¸°ì¡´ì˜ ìì—°ì–´ ì²˜ë¦¬(NLP) ê¸°ìˆ ì„ í™œìš©í•˜ëŠ”ë°, ì´ë¥¼ íƒœê¹…(Tagging)ì´ë¼ê³  ë¶€ë¦…ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ, LLMì„ ì‚¬ìš©í•˜ì—¬ ì´ëŸ¬í•œ í‚¤ì›Œë“œì˜ í™•ë¥ ì„ ì–»ê³ , í‰ê·  ë¡œê·¸ ê°€ëŠ¥ì„±ì„ ê³„ì‚°í•˜ì—¬ ì…ë ¥ í…ìŠ¤íŠ¸ì˜ ë©¤ë²„ì‹­ì„ ê²°ì •í•˜ëŠ”ë°, ì´ë¥¼ íƒœë¹™(Tabbing)ì´ë¼ê³  ë¶€ë¦…ë‹ˆë‹¤. ë„¤ ê°€ì§€ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹(BookMIA, MIMIR, PatentMIA, ë° the Pile)ê³¼ ë‹¤ì–‘í•œ í¬ê¸°ì˜ ì—¬ëŸ¬ ì˜¤í”ˆ ì†ŒìŠ¤ LLMì— ëŒ€í•œ ìš°ë¦¬ì˜ ì‹¤í—˜ì€ ìµœì²¨ë‹¨ ë°©ë²•ì— ë¹„í•´ AUC ì ìˆ˜ê°€ í‰ê·  5.3%ì—ì„œ 17.6%ê¹Œì§€ ì¦ê°€í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. Tag&amp;Tabì€ LLMì—ì„œì˜ ë°ì´í„° ëˆ„ì¶œ íƒì§€ì— ìƒˆë¡œìš´ ê¸°ì¤€ì„ ì„¸ìš¸ ë¿ë§Œ ì•„ë‹ˆë¼, LLMì—ì„œì˜ MIAì— ìˆì–´ì„œ ë‹¨ì–´ì˜ ì¤‘ìš”ì„±ì„ ì…ì¦í•˜ëŠ” ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì‚¬ì „ í•™ìŠµ ë°ì´í„°ì—ì„œ ì €ì‘ê¶Œ ë³´í˜¸ ë˜ëŠ” ë¯¼ê°í•œ ì •ë³´ê°€ í¬í•¨ë  ìˆ˜ ìˆì–´ ë°ì´í„° ìœ ì¶œ ê°ì§€ê°€ ì¤‘ìš”í•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë¬¸ì¥ ë˜ëŠ” ë‹¨ë½ ìˆ˜ì¤€ì˜ ë©¤ë²„ì‹­ ì¶”ë¡  ê³µê²©(MIA)ì€ ì •í™•ë„ê°€ ë‚®ê³  í…ìŠ¤íŠ¸ì˜ ì˜ë¯¸ì  ì¤‘ìš”ì„±ì„ ê³ ë ¤í•˜ì§€ ëª»í•˜ëŠ” í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” Tag&Tabì´ë¼ëŠ” ìƒˆë¡œìš´ ì ‘ê·¼ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ìì—°ì–´ ì²˜ë¦¬(NLP) ê¸°ìˆ ì„ í™œìš©í•´ ì…ë ¥ í…ìŠ¤íŠ¸ì˜ í‚¤ì›Œë“œë¥¼ íƒœê·¸í•˜ê³ , LLMì„ í†µí•´ ì´ í‚¤ì›Œë“œì˜ í™•ë¥ ì„ ê³„ì‚°í•˜ì—¬ í‰ê·  ë¡œê·¸ ê°€ëŠ¥ì„±ì„ ì‚°ì¶œí•¨ìœ¼ë¡œì¨ ë°ì´í„° ì‚¬ìš© ì—¬ë¶€ë¥¼ íŒë‹¨í•©ë‹ˆë‹¤. ë„¤ ê°€ì§€ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ê³¼ ë‹¤ì–‘í•œ ì˜¤í”ˆ ì†ŒìŠ¤ LLMì„ ëŒ€ìƒìœ¼ë¡œ í•œ ì‹¤í—˜ì—ì„œ, ê¸°ì¡´ ë°©ë²• ëŒ€ë¹„ AUC ì ìˆ˜ê°€ í‰ê·  5.3%ì—ì„œ 17.6%ê¹Œì§€ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤. Tag&Tabì€ LLMì˜ ë°ì´í„° ìœ ì¶œ ê°ì§€ì— ìƒˆë¡œìš´ ê¸°ì¤€ì„ ì œì‹œí•˜ë©°, ë‹¨ì–´ì˜ ì¤‘ìš”ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì‚¬ì „ í›ˆë ¨ ë°ì´í„° íƒì§€ì— ëŒ€í•œ ê¸°ì¡´ ì—°êµ¬ëŠ” ë¬¸ì¥ ë˜ëŠ” ë¬¸ë‹¨ ìˆ˜ì¤€ì˜ ë©¤ë²„ì‹­ ì¶”ë¡  ê³µê²©(MIA)ì— ì§‘ì¤‘ë˜ì–´ ìˆìœ¼ë©°, ì´ëŠ” ì¢…ì¢… ì •í™•ë„ê°€ ë‚®ìŠµë‹ˆë‹¤.
- 2. Tag&amp;TabëŠ” ì…ë ¥ í…ìŠ¤íŠ¸ì˜ í‚¤ì›Œë“œë¥¼ íƒœê·¸í•˜ê³ , ì´ í‚¤ì›Œë“œì˜ í‰ê·  ë¡œê·¸ ê°€ëŠ¥ì„±ì„ ê³„ì‚°í•˜ì—¬ ì…ë ¥ í…ìŠ¤íŠ¸ì˜ ë©¤ë²„ì‹­ì„ ê²°ì •í•˜ëŠ” ìƒˆë¡œìš´ ì ‘ê·¼ ë°©ì‹ì…ë‹ˆë‹¤.
- 3. ì œì•ˆëœ ë°©ë²•ì€ ë„¤ ê°€ì§€ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ê³¼ ë‹¤ì–‘í•œ í¬ê¸°ì˜ ì˜¤í”ˆ ì†ŒìŠ¤ LLMì—ì„œ ê¸°ì¡´ ë°©ë²• ëŒ€ë¹„ AUC ì ìˆ˜ë¥¼ í‰ê·  5.3%ì—ì„œ 17.6%ê¹Œì§€ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.
- 4. Tag&amp;TabëŠ” LLMì˜ ë°ì´í„° ëˆ„ì¶œ íƒì§€ì—ì„œ ìƒˆë¡œìš´ ê¸°ì¤€ì„ ì„¤ì •í•˜ë©°, MIAì—ì„œ ë‹¨ì–´ì˜ ì¤‘ìš”ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-23 11:51:47*