---
keywords:
  - Decision Transformers
  - Online Decision Transformers
  - Experience-Weighted Attraction
  - Attention Mechanism
  - Entropy-Regularized Training
category: cs.LG
publish_date: 2025-09-22
arxiv_id: 2509.15498
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T10:27:28.740684",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Decision Transformers",
    "Online Decision Transformers",
    "Experience-Weighted Attraction",
    "Attention Mechanism",
    "Entropy-Regularized Training"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Decision Transformers": 0.78,
    "Online Decision Transformers": 0.77,
    "Experience-Weighted Attraction": 0.75,
    "Attention Mechanism": 0.8,
    "Entropy-Regularized Training": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Decision Transformers",
        "canonical": "Decision Transformers",
        "aliases": [
          "DTs"
        ],
        "category": "unique_technical",
        "rationale": "Represents a novel approach in reinforcement learning by framing it as supervised sequence modeling.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Online Decision Transformers",
        "canonical": "Online Decision Transformers",
        "aliases": [
          "ODTs"
        ],
        "category": "unique_technical",
        "rationale": "An extension of Decision Transformers that incorporates online learning, enhancing exploration capabilities.",
        "novelty_score": 0.72,
        "connectivity_score": 0.68,
        "specificity_score": 0.82,
        "link_intent_score": 0.77
      },
      {
        "surface": "Experience-Weighted Attraction",
        "canonical": "Experience-Weighted Attraction",
        "aliases": [
          "EWA"
        ],
        "category": "unique_technical",
        "rationale": "A cognitive model that influences the proposed method, providing a unique perspective on action-outcome memory.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      },
      {
        "surface": "Attention Mechanism",
        "canonical": "Attention Mechanism",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Central to the paper's methodology, connecting it to broader research on attention in machine learning.",
        "novelty_score": 0.4,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Entropy-Regularized Training",
        "canonical": "Entropy-Regularized Training",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "A specific training technique used to enhance the exploration capabilities of the model.",
        "novelty_score": 0.65,
        "connectivity_score": 0.55,
        "specificity_score": 0.78,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "Transformers",
      "Reinforcement Learning",
      "Soft Actor-Critic"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Decision Transformers",
      "resolved_canonical": "Decision Transformers",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Online Decision Transformers",
      "resolved_canonical": "Online Decision Transformers",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.68,
        "specificity": 0.82,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Experience-Weighted Attraction",
      "resolved_canonical": "Experience-Weighted Attraction",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Attention Mechanism",
      "resolved_canonical": "Attention Mechanism",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Entropy-Regularized Training",
      "resolved_canonical": "Entropy-Regularized Training",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.55,
        "specificity": 0.78,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# Mental Accounts for Actions: EWA-Inspired Attention in Decision Transformers

**Korean Title:** í–‰ë™ì— ëŒ€í•œ ì •ì‹ ì  ê³„ì¢Œ: ê²°ì • ë³€í™˜ê¸°ì—ì„œ EWAì— ì˜ê°ì„ ë°›ì€ ì£¼ì˜ ì§‘ì¤‘

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15498.pdf)
**Category**: cs.LG
**Published**: 2025-09-22
**ArXiv ID**: [2509.15498](https://arxiv.org/abs/2509.15498)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-17/Large Language Model-Empowered Decision Transformer for UAV-Enabled Data Collection_20250917|Large Language Model-Empowered Decision Transformer for UAV-Enabled Data Collection]] (80.7% similar)
- [[2025-09-22/Attention Schema-based Attention Control (ASAC)_ A Cognitive-Inspired Approach for Attention Management in Transformers_20250922|Attention Schema-based Attention Control (ASAC): A Cognitive-Inspired Approach for Attention Management in Transformers]] (80.3% similar)
- [[2025-09-22/AttentionDrop_ A Novel Regularization Method for Transformer Models_20250922|AttentionDrop: A Novel Regularization Method for Transformer Models]] (80.1% similar)
- [[2025-09-17/TGPO_ Tree-Guided Preference Optimization for Robust Web Agent Reinforcement Learning_20250917|TGPO: Tree-Guided Preference Optimization for Robust Web Agent Reinforcement Learning]] (80.0% similar)
- [[2025-09-18/TDRM_ Smooth Reward Models with Temporal Difference for LLM RL and Inference_20250918|TDRM: Smooth Reward Models with Temporal Difference for LLM RL and Inference]] (79.9% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Attention Mechanism|Attention Mechanism]]
**âš¡ Unique Technical**: [[keywords/Decision Transformers|Decision Transformers]], [[keywords/Online Decision Transformers|Online Decision Transformers]], [[keywords/Experience-Weighted Attraction|Experience-Weighted Attraction]], [[keywords/Entropy-Regularized Training|Entropy-Regularized Training]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15498v1 Announce Type: new 
Abstract: Transformers have emerged as a compelling architecture for sequential decision-making by modeling trajectories via self-attention. In reinforcement learning (RL), they enable return-conditioned control without relying on value function approximation. Decision Transformers (DTs) exploit this by casting RL as supervised sequence modeling, but they are restricted to offline data and lack exploration. Online Decision Transformers (ODTs) address this limitation through entropy-regularized training on on-policy rollouts, offering a stable alternative to traditional RL methods like Soft Actor-Critic, which depend on bootstrapped targets and reward shaping. Despite these advantages, ODTs use standard attention, which lacks explicit memory of action-specific outcomes. This leads to inefficiencies in learning long-term action effectiveness. Inspired by cognitive models such as Experience-Weighted Attraction (EWA), we propose Experience-Weighted Attraction with Vector Quantization for Online Decision Transformers (EWA-VQ-ODT), a lightweight module that maintains per-action mental accounts summarizing recent successes and failures. Continuous actions are routed via direct grid lookup to a compact vector-quantized codebook, where each code stores a scalar attraction updated online through decay and reward-based reinforcement. These attractions modulate attention by biasing the columns associated with action tokens, requiring no change to the backbone or training objective. On standard continuous-control benchmarks, EWA-VQ-ODT improves sample efficiency and average return over ODT, particularly in early training. The module is computationally efficient, interpretable via per-code traces, and supported by theoretical guarantees that bound the attraction dynamics and its impact on attention drift.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15498v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” ìê¸° ì£¼ì˜ë¥¼ í†µí•´ ê²½ë¡œë¥¼ ëª¨ë¸ë§í•˜ì—¬ ìˆœì°¨ì  ì˜ì‚¬ê²°ì •ì„ ìœ„í•œ ë§¤ë ¥ì ì¸ ì•„í‚¤í…ì²˜ë¡œ ë¶€ìƒí–ˆìŠµë‹ˆë‹¤. ê°•í™” í•™ìŠµ(RL)ì—ì„œëŠ” ê°€ì¹˜ í•¨ìˆ˜ ê·¼ì‚¬ì— ì˜ì¡´í•˜ì§€ ì•Šê³  ë°˜í™˜ ì¡°ê±´ë¶€ ì œì–´ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. Decision Transformers(DTs)ëŠ” ì´ë¥¼ í™œìš©í•˜ì—¬ RLì„ ì§€ë„ ìˆœì°¨ ëª¨ë¸ë§ìœ¼ë¡œ ë³€í™˜í•˜ì§€ë§Œ, ì˜¤í”„ë¼ì¸ ë°ì´í„°ì— ì œí•œë˜ê³  íƒìƒ‰ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. Online Decision Transformers(ODTs)ëŠ” ì •ì±… ë¡¤ì•„ì›ƒì— ëŒ€í•œ ì—”íŠ¸ë¡œí”¼ ì •ê·œí™” í•™ìŠµì„ í†µí•´ ì´ ì œí•œì„ í•´ê²°í•˜ë©°, ë¶€íŠ¸ìŠ¤íŠ¸ë© ëª©í‘œì™€ ë³´ìƒ í˜•ì„±ì— ì˜ì¡´í•˜ëŠ” Soft Actor-Criticê³¼ ê°™ì€ ì „í†µì ì¸ RL ë°©ë²•ì— ëŒ€í•œ ì•ˆì •ì ì¸ ëŒ€ì•ˆì„ ì œê³µí•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì¥ì ì—ë„ ë¶ˆêµ¬í•˜ê³ , ODTsëŠ” í‘œì¤€ ì£¼ì˜ë¥¼ ì‚¬ìš©í•˜ë©°, ì´ëŠ” í–‰ë™ë³„ ê²°ê³¼ì— ëŒ€í•œ ëª…ì‹œì ì¸ ê¸°ì–µì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ì´ëŠ” ì¥ê¸°ì ì¸ í–‰ë™ íš¨ê³¼ í•™ìŠµì—ì„œ ë¹„íš¨ìœ¨ì„±ì„ ì´ˆë˜í•©ë‹ˆë‹¤. Experience-Weighted Attraction(EWA)ì™€ ê°™ì€ ì¸ì§€ ëª¨ë¸ì—ì„œ ì˜ê°ì„ ë°›ì•„, ìš°ë¦¬ëŠ” Online Decision Transformersë¥¼ ìœ„í•œ ë²¡í„° ì–‘ìí™” ê²½í—˜ ê°€ì¤‘ ë§¤ë ¥(EWA-VQ-ODT)ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ëŠ” ìµœê·¼ì˜ ì„±ê³µê³¼ ì‹¤íŒ¨ë¥¼ ìš”ì•½í•˜ëŠ” í–‰ë™ë³„ ì •ì‹  ê³„ì •ì„ ìœ ì§€í•˜ëŠ” ê²½ëŸ‰ ëª¨ë“ˆì…ë‹ˆë‹¤. ì—°ì†ì ì¸ í–‰ë™ì€ ì§ì ‘ ê·¸ë¦¬ë“œ ì¡°íšŒë¥¼ í†µí•´ ì••ì¶•ëœ ë²¡í„° ì–‘ìí™” ì½”ë“œë¶ìœ¼ë¡œ ë¼ìš°íŒ…ë˜ë©°, ê° ì½”ë“œëŠ” ê°ì‡ ì™€ ë³´ìƒ ê¸°ë°˜ ê°•í™” í•™ìŠµì„ í†µí•´ ì˜¨ë¼ì¸ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ëŠ” ìŠ¤ì¹¼ë¼ ë§¤ë ¥ì„ ì €ì¥í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ë§¤ë ¥ì€ í–‰ë™ í† í°ê³¼ ê´€ë ¨ëœ ì—´ì— í¸í–¥ì„ ì£¼ì–´ ì£¼ì˜ë¥¼ ì¡°ì ˆí•˜ë©°, ë°±ë³¸ì´ë‚˜ í•™ìŠµ ëª©í‘œì˜ ë³€ê²½ì´ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í‘œì¤€ ì—°ì† ì œì–´ ë²¤ì¹˜ë§ˆí¬ì—ì„œ EWA-VQ-ODTëŠ” íŠ¹íˆ ì´ˆê¸° í•™ìŠµì—ì„œ ODTì— ë¹„í•´ ìƒ˜í”Œ íš¨ìœ¨ì„±ê³¼ í‰ê·  ë°˜í™˜ì„ ê°œì„ í•©ë‹ˆë‹¤. ì´ ëª¨ë“ˆì€ ê³„ì‚°ì ìœ¼ë¡œ íš¨ìœ¨ì ì´ë©°, ì½”ë“œë³„ ì¶”ì ì„ í†µí•´ í•´ì„ ê°€ëŠ¥í•˜ê³ , ë§¤ë ¥ ë™ì—­í•™ê³¼ ì£¼ì˜ ë“œë¦¬í”„íŠ¸ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì œí•œí•˜ëŠ” ì´ë¡ ì  ë³´ì¥ì„ ì§€ì›ë°›ìŠµë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” ìê¸° ì£¼ì˜ë¥¼ í†µí•´ ê²½ë¡œë¥¼ ëª¨ë¸ë§í•˜ì—¬ ìˆœì°¨ì  ì˜ì‚¬ ê²°ì •ì— ìœ ë§í•œ êµ¬ì¡°ë¡œ ë¶€ìƒí–ˆìŠµë‹ˆë‹¤. ê°•í™” í•™ìŠµ(RL)ì—ì„œ, íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” ê°€ì¹˜ í•¨ìˆ˜ ê·¼ì‚¬ ì—†ì´ ë°˜í™˜ ì¡°ê±´ë¶€ ì œì–´ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. Decision Transformers(DTs)ëŠ” ì´ë¥¼ í™œìš©í•˜ì—¬ RLì„ ì§€ë„ í•™ìŠµ ì‹œí€€ìŠ¤ ëª¨ë¸ë§ìœ¼ë¡œ ì „í™˜í•˜ì§€ë§Œ, ì˜¤í”„ë¼ì¸ ë°ì´í„°ì— ì œí•œë˜ê³  íƒìƒ‰ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. Online Decision Transformers(ODTs)ëŠ” ì •ì±… ë¡¤ì•„ì›ƒì— ëŒ€í•œ ì—”íŠ¸ë¡œí”¼ ì •ê·œí™” í›ˆë ¨ì„ í†µí•´ ì´ ì œí•œì„ ê·¹ë³µí•˜ì—¬ Soft Actor-Criticê³¼ ê°™ì€ ì „í†µì ì¸ RL ë°©ë²•ì— ëŒ€í•œ ì•ˆì •ì ì¸ ëŒ€ì•ˆì„ ì œê³µí•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ODTëŠ” í‘œì¤€ ì£¼ì˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í–‰ë™ë³„ ê²°ê³¼ì— ëŒ€í•œ ëª…ì‹œì  ê¸°ì–µì´ ë¶€ì¡±í•˜ì—¬ ì¥ê¸°ì ì¸ í–‰ë™ íš¨ê³¼ í•™ìŠµì— ë¹„íš¨ìœ¨ì ì…ë‹ˆë‹¤. ì´ì— ì˜ê°ì„ ë°›ì•„, ìš°ë¦¬ëŠ” Experience-Weighted Attraction with Vector Quantization for Online Decision Transformers(EWA-VQ-ODT)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ëª¨ë“ˆì€ ìµœê·¼ ì„±ê³µê³¼ ì‹¤íŒ¨ë¥¼ ìš”ì•½í•˜ëŠ” í–‰ë™ë³„ ì •ì‹  ê³„ì •ì„ ìœ ì§€í•˜ë©°, ì—°ì†ì ì¸ í–‰ë™ì„ ë²¡í„° ì–‘ìí™”ëœ ì½”ë“œë¶ìœ¼ë¡œ ë¼ìš°íŒ…í•˜ì—¬ ì£¼ì˜ë ¥ì„ ì¡°ì •í•©ë‹ˆë‹¤. EWA-VQ-ODTëŠ” í‘œì¤€ ì—°ì† ì œì–´ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìƒ˜í”Œ íš¨ìœ¨ì„±ê³¼ í‰ê·  ë°˜í™˜ì„ ê°œì„ í•˜ë©°, íŠ¹íˆ ì´ˆê¸° í›ˆë ¨ì—ì„œ ë‘ë“œëŸ¬ì§‘ë‹ˆë‹¤. ì´ ëª¨ë“ˆì€ ê³„ì‚°ì ìœ¼ë¡œ íš¨ìœ¨ì ì´ë©°, ì´ë¡ ì  ë³´ì¥ì„ í†µí•´ ì£¼ì˜ë ¥ ë“œë¦¬í”„íŠ¸ì— ëŒ€í•œ ì˜í–¥ì„ ì œí•œí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” ìê¸° ì£¼ì˜ë¥¼ í†µí•´ ê¶¤ì ì„ ëª¨ë¸ë§í•˜ì—¬ ìˆœì°¨ì  ì˜ì‚¬ê²°ì •ì— ìœ ë¦¬í•œ êµ¬ì¡°ë¡œ ë¶€ìƒí–ˆìŠµë‹ˆë‹¤.
- 2. ì˜¨ë¼ì¸ ì˜ì‚¬ê²°ì • íŠ¸ëœìŠ¤í¬ë¨¸(ODT)ëŠ” ì˜¨ì •ì±… ë¡¤ì•„ì›ƒì— ëŒ€í•œ ì—”íŠ¸ë¡œí”¼ ì •ê·œí™” í›ˆë ¨ì„ í†µí•´ íƒìƒ‰ ë¶€ì¡± ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤.
- 3. EWA-VQ-ODTëŠ” ê° í–‰ë™ì˜ ìµœê·¼ ì„±ê³µê³¼ ì‹¤íŒ¨ë¥¼ ìš”ì•½í•˜ëŠ” ì •ì‹  ê³„ì •ì„ ìœ ì§€í•˜ëŠ” ê²½ëŸ‰ ëª¨ë“ˆë¡œ, í–‰ë™ë³„ ê²°ê³¼ì— ëŒ€í•œ ëª…ì‹œì  ê¸°ì–µì„ ë³´ì™„í•©ë‹ˆë‹¤.
- 4. EWA-VQ-ODTëŠ” í‘œì¤€ ì—°ì† ì œì–´ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìƒ˜í”Œ íš¨ìœ¨ì„±ê³¼ í‰ê·  ìˆ˜ìµì„ ê°œì„ í•˜ë©°, íŠ¹íˆ ì´ˆê¸° í›ˆë ¨ì—ì„œ ë‘ë“œëŸ¬ì§‘ë‹ˆë‹¤.
- 5. ì´ ëª¨ë“ˆì€ ê³„ì‚°ì ìœ¼ë¡œ íš¨ìœ¨ì ì´ë©°, ì´ë¡ ì  ë³´ì¥ì„ í†µí•´ ì£¼ì˜ ì´ë™ì— ëŒ€í•œ ì˜í–¥ì„ ì œí•œí•©ë‹ˆë‹¤.


---

*Generated on 2025-09-23 10:27:28*