---
keywords:
  - AI Privacy and Ethics
  - AI Lifecycle
  - AI Governance
  - Organizational Decision-Making
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2504.01029
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T09:53:48.030857",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "AI Privacy and Ethics",
    "AI Lifecycle",
    "AI Governance",
    "Organizational Decision-Making"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "AI Privacy and Ethics": 0.85,
    "AI Lifecycle": 0.82,
    "AI Governance": 0.88,
    "Organizational Decision-Making": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "AI privacy and ethical incidents",
        "canonical": "AI Privacy and Ethics",
        "aliases": [
          "AI ethical issues",
          "AI privacy concerns"
        ],
        "category": "unique_technical",
        "rationale": "This concept is central to the paper's focus on AI failures and governance, providing a unique angle for linking discussions on AI ethics.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.85
      },
      {
        "surface": "AI lifecycle stages",
        "canonical": "AI Lifecycle",
        "aliases": [
          "AI development stages",
          "AI process stages"
        ],
        "category": "specific_connectable",
        "rationale": "Understanding the AI lifecycle is crucial for linking discussions on AI development and incident management.",
        "novelty_score": 0.55,
        "connectivity_score": 0.78,
        "specificity_score": 0.72,
        "link_intent_score": 0.82
      },
      {
        "surface": "AI governance frameworks",
        "canonical": "AI Governance",
        "aliases": [
          "AI regulatory frameworks",
          "AI policy frameworks"
        ],
        "category": "specific_connectable",
        "rationale": "AI governance is a key topic for linking policy discussions and ethical considerations in AI.",
        "novelty_score": 0.6,
        "connectivity_score": 0.85,
        "specificity_score": 0.75,
        "link_intent_score": 0.88
      },
      {
        "surface": "organizational decisions",
        "canonical": "Organizational Decision-Making",
        "aliases": [
          "corporate decisions",
          "business decisions"
        ],
        "category": "broad_technical",
        "rationale": "This concept connects to broader discussions on how organizations impact AI outcomes.",
        "novelty_score": 0.5,
        "connectivity_score": 0.8,
        "specificity_score": 0.65,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "AI technologies",
      "real-world cases",
      "legal non-compliance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "AI privacy and ethical incidents",
      "resolved_canonical": "AI Privacy and Ethics",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "AI lifecycle stages",
      "resolved_canonical": "AI Lifecycle",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.78,
        "specificity": 0.72,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "AI governance frameworks",
      "resolved_canonical": "AI Governance",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.85,
        "specificity": 0.75,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "organizational decisions",
      "resolved_canonical": "Organizational Decision-Making",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.8,
        "specificity": 0.65,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# Who is Responsible When AI Fails? Mapping Causes, Entities, and Consequences of AI Privacy and Ethical Incidents

**Korean Title:** AI 실패 시 책임은 누구에게 있는가? AI 프라이버시 및 윤리적 사건의 원인, 주체, 결과 분석

## 📋 메타데이터

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2504.01029.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2504.01029](https://arxiv.org/abs/2504.01029)

## 🔗 유사한 논문
- [[2025-09-22/Algorithmic Fairness_ Not a Purely Technical but Socio-Technical Property_20250922|Algorithmic Fairness: Not a Purely Technical but Socio-Technical Property]] (82.3% similar)
- [[2025-09-22/The Great AI Witch Hunt_ Reviewers Perception and (Mis)Conception of Generative AI in Research Writing_20250922|The Great AI Witch Hunt: Reviewers Perception and (Mis)Conception of Generative AI in Research Writing]] (82.2% similar)
- [[2025-09-22/AI for Scientific Discovery is a Social Problem_20250922|AI for Scientific Discovery is a Social Problem]] (82.1% similar)
- [[2025-09-22/From Development to Deployment of AI-assisted Telehealth and Screening for Vision- and Hearing-threatening diseases in resource-constrained settings_ Field Observations, Challenges and Way Forward_20250922|From Development to Deployment of AI-assisted Telehealth and Screening for Vision- and Hearing-threatening diseases in resource-constrained settings: Field Observations, Challenges and Way Forward]] (80.7% similar)
- [[2025-09-18/Designing AI-Agents with Personalities_ A Psychometric Approach_20250918|Designing AI-Agents with Personalities: A Psychometric Approach]] (80.6% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Organizational Decision-Making|Organizational Decision-Making]]
**🔗 Specific Connectable**: [[keywords/AI Lifecycle|AI Lifecycle]], [[keywords/AI Governance|AI Governance]]
**⚡ Unique Technical**: [[keywords/AI Privacy and Ethics|AI Privacy and Ethics]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2504.01029v2 Announce Type: replace-cross 
Abstract: The rapid growth of artificial intelligence (AI) technologies has raised major privacy and ethical concerns. However, existing AI incident taxonomies and guidelines lack grounding in real-world cases, limiting their effectiveness for prevention and mitigation. We analyzed 202 real-world AI privacy and ethical incidents to develop a taxonomy that classifies them across AI lifecycle stages and captures contributing factors, including causes, responsible entities, sources of disclosure, and impacts. Our findings reveal widespread harms from poor organizational decisions and legal non-compliance, limited corrective interventions, and rare reporting from AI developers and adopting entities. Our taxonomy offers a structured approach for systematic incident reporting and emphasizes the weaknesses of current AI governance frameworks. Our findings provide actionable guidance for policymakers and practitioners to strengthen user protections, develop targeted AI policies, enhance reporting practices, and foster responsible AI governance and innovation, especially in contexts such as social media and child protection.

## 🔍 Abstract (한글 번역)

arXiv:2504.01029v2 발표 유형: 교차 교체  
초록: 인공지능(AI) 기술의 급속한 발전은 주요한 개인정보 보호 및 윤리적 문제를 제기하고 있습니다. 그러나 기존의 AI 사건 분류 체계와 지침은 실제 사례에 기반하지 않아 예방 및 완화에 효과적이지 못합니다. 우리는 202건의 실제 AI 개인정보 보호 및 윤리적 사건을 분석하여 AI 생애 주기 단계에 따라 사건을 분류하고 원인, 책임 기관, 공개 출처, 영향 등 기여 요인을 포착하는 분류 체계를 개발했습니다. 우리의 연구 결과는 조직의 잘못된 결정과 법적 비준수로 인한 광범위한 피해, 제한된 교정 조치, AI 개발자와 채택 기관의 드문 보고를 드러냅니다. 우리의 분류 체계는 체계적인 사건 보고를 위한 구조화된 접근 방식을 제공하며, 현재 AI 거버넌스 프레임워크의 약점을 강조합니다. 우리의 연구 결과는 정책 입안자와 실무자에게 사용자 보호를 강화하고, 목표 지향적인 AI 정책을 개발하며, 보고 관행을 개선하고, 특히 소셜 미디어 및 아동 보호와 같은 맥락에서 책임 있는 AI 거버넌스와 혁신을 촉진하기 위한 실행 가능한 지침을 제공합니다.

## 📝 요약

이 논문은 인공지능(AI) 기술의 급속한 발전으로 인한 개인정보 보호 및 윤리적 문제를 해결하기 위해 202건의 실제 AI 관련 사건을 분석하여 새로운 분류 체계를 제안합니다. 이 체계는 AI 생애 주기 단계별로 사건을 분류하고, 원인, 책임 주체, 공개 출처, 영향 등을 포함합니다. 연구 결과, 조직의 부적절한 결정과 법적 비준수로 인한 피해가 광범위하며, AI 개발자와 사용자 측의 보고가 드물다는 점이 드러났습니다. 이 분류 체계는 체계적인 사건 보고를 위한 구조적 접근을 제공하며, 현재 AI 거버넌스의 취약점을 강조합니다. 정책 입안자와 실무자에게 사용자 보호 강화, AI 정책 개발, 보고 관행 개선, 책임 있는 AI 거버넌스 및 혁신 촉진을 위한 실질적인 지침을 제공합니다.

## 🎯 주요 포인트

- 1. 인공지능 기술의 급속한 발전은 주요한 개인정보 및 윤리적 문제를 야기하고 있다.
- 2. 기존의 AI 사건 분류 체계와 지침은 실제 사례에 기반하지 않아 예방 및 완화에 효과적이지 않다.
- 3. 202개의 실제 AI 개인정보 및 윤리 사건을 분석하여 AI 생애주기 단계별로 분류하는 분류 체계를 개발하였다.
- 4. 조직의 부실한 결정과 법적 비준수로 인한 피해가 광범위하며, AI 개발자와 채택 기관의 보고는 드물다.
- 5. 개발된 분류 체계는 체계적인 사건 보고를 위한 구조적 접근을 제공하며, 현재 AI 거버넌스 프레임워크의 약점을 강조한다.


---

*Generated on 2025-09-23 09:53:48*