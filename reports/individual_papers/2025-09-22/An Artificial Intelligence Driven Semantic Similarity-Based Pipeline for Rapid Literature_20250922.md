---
keywords:
  - Semantic Similarity
  - Transformer
  - Cosine Similarity
  - Embedding Models
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2509.15292
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T08:40:36.375361",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Semantic Similarity",
    "Transformer",
    "Cosine Similarity",
    "Embedding Models"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Semantic Similarity": 0.85,
    "Transformer": 0.89,
    "Cosine Similarity": 0.82,
    "Embedding Models": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "semantic similarity",
        "canonical": "Semantic Similarity",
        "aliases": [
          "similarity measure",
          "semantic closeness"
        ],
        "category": "specific_connectable",
        "rationale": "Semantic similarity is crucial for linking related literature and concepts, enhancing connectivity.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.72,
        "link_intent_score": 0.85
      },
      {
        "surface": "transformer based embeddings",
        "canonical": "Transformer",
        "aliases": [
          "transformer embeddings",
          "transformer models"
        ],
        "category": "broad_technical",
        "rationale": "Transformers are a fundamental technology in NLP, providing a strong link to related research.",
        "novelty_score": 0.45,
        "connectivity_score": 0.92,
        "specificity_score": 0.68,
        "link_intent_score": 0.89
      },
      {
        "surface": "cosine similarity",
        "canonical": "Cosine Similarity",
        "aliases": [
          "cosine measure",
          "cosine distance"
        ],
        "category": "specific_connectable",
        "rationale": "Cosine similarity is a widely used metric for measuring semantic similarity, facilitating connections.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.82
      },
      {
        "surface": "embedding models",
        "canonical": "Embedding Models",
        "aliases": [
          "vector embeddings",
          "embedding techniques"
        ],
        "category": "specific_connectable",
        "rationale": "Embedding models are key in transforming text into numerical representations, linking various NLP tasks.",
        "novelty_score": 0.58,
        "connectivity_score": 0.87,
        "specificity_score": 0.75,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "automated pipeline",
      "literature review"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "semantic similarity",
      "resolved_canonical": "Semantic Similarity",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.72,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "transformer based embeddings",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.92,
        "specificity": 0.68,
        "link_intent": 0.89
      }
    },
    {
      "candidate_surface": "cosine similarity",
      "resolved_canonical": "Cosine Similarity",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "embedding models",
      "resolved_canonical": "Embedding Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.87,
        "specificity": 0.75,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# An Artificial Intelligence Driven Semantic Similarity-Based Pipeline for Rapid Literature

**Korean Title:** 인공지능 기반 의미 유사성 기반 파이프라인을 통한 신속한 문헌 연구

## 📋 메타데이터

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15292.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2509.15292](https://arxiv.org/abs/2509.15292)

## 🔗 유사한 논문
- [[2025-09-19/OpenLens AI_ Fully Autonomous Research Agent for Health Infomatics_20250919|OpenLens AI: Fully Autonomous Research Agent for Health Infomatics]] (79.6% similar)
- [[2025-09-22/Efficient Extractive Text Summarization for Online News Articles Using Machine Learning_20250922|Efficient Extractive Text Summarization for Online News Articles Using Machine Learning]] (79.6% similar)
- [[2025-09-19/MOLE_ Metadata Extraction and Validation in Scientific Papers Using LLMs_20250919|MOLE: Metadata Extraction and Validation in Scientific Papers Using LLMs]] (78.2% similar)
- [[2025-09-22/AI Copilots for Reproducibility in Science_ A Case Study_20250922|AI Copilots for Reproducibility in Science: A Case Study]] (77.9% similar)
- [[2025-09-22/Relevance to Utility_ Process-Supervised Rewrite for RAG_20250922|Relevance to Utility: Process-Supervised Rewrite for RAG]] (77.8% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Transformer|Transformer]]
**🔗 Specific Connectable**: [[keywords/Semantic Similarity|Semantic Similarity]], [[keywords/Cosine Similarity|Cosine Similarity]], [[keywords/Embedding Models|Embedding Models]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.15292v1 Announce Type: new 
Abstract: We propose an automated pipeline for performing literature reviews using semantic similarity. Unlike traditional systematic review systems or optimization based methods, this work emphasizes minimal overhead and high relevance by using transformer based embeddings and cosine similarity. By providing a paper title and abstract, it generates relevant keywords, fetches relevant papers from open access repository, and ranks them based on their semantic closeness to the input. Three embedding models were evaluated. A statistical thresholding approach is then applied to filter relevant papers, enabling an effective literature review pipeline. Despite the absence of heuristic feedback or ground truth relevance labels, the proposed system shows promise as a scalable and practical tool for preliminary research and exploratory analysis.

## 🔍 Abstract (한글 번역)

arXiv:2509.15292v1 발표 유형: 신규  
초록: 우리는 의미적 유사성을 사용하여 문헌 리뷰를 수행하는 자동화된 파이프라인을 제안합니다. 전통적인 체계적 리뷰 시스템이나 최적화 기반 방법과 달리, 이 연구는 트랜스포머 기반 임베딩과 코사인 유사성을 사용하여 최소한의 오버헤드와 높은 관련성을 강조합니다. 논문 제목과 초록을 제공함으로써 관련 키워드를 생성하고, 오픈 액세스 저장소에서 관련 논문을 가져오며, 입력과의 의미적 근접성에 따라 이를 순위화합니다. 세 가지 임베딩 모델이 평가되었습니다. 그런 다음 통계적 임계값 접근법을 적용하여 관련 논문을 필터링하여 효과적인 문헌 리뷰 파이프라인을 가능하게 합니다. 휴리스틱 피드백이나 실제 관련성 레이블이 없는 상황에서도, 제안된 시스템은 예비 연구 및 탐색적 분석을 위한 확장 가능하고 실용적인 도구로서의 가능성을 보여줍니다.

## 📝 요약

이 논문은 문헌 리뷰를 자동화하기 위한 새로운 파이프라인을 제안합니다. 전통적인 체계적 리뷰 시스템이나 최적화 기반 방법과 달리, 이 연구는 트랜스포머 기반 임베딩과 코사인 유사성을 활용하여 최소한의 오버헤드와 높은 관련성을 강조합니다. 논문 제목과 초록을 입력하면 관련 키워드를 생성하고, 오픈 액세스 저장소에서 관련 논문을 검색한 후 입력과의 의미적 유사성에 따라 논문을 순위화합니다. 세 가지 임베딩 모델을 평가했으며, 통계적 임계값 접근법을 사용해 관련 논문을 필터링합니다. 이 시스템은 휴리스틱 피드백이나 실제 관련성 레이블 없이도 예비 연구 및 탐색적 분석에 유용한 도구로서의 가능성을 보여줍니다.

## 🎯 주요 포인트

- 1. 본 연구는 문헌 리뷰를 자동화하기 위해 의미적 유사성을 활용한 파이프라인을 제안합니다.
- 2. 트랜스포머 기반 임베딩과 코사인 유사성을 사용하여 최소한의 오버헤드와 높은 관련성을 강조합니다.
- 3. 논문 제목과 초록을 입력하면 관련 키워드를 생성하고, 오픈 액세스 저장소에서 관련 논문을 검색 및 순위화합니다.
- 4. 세 가지 임베딩 모델을 평가하고, 통계적 임계값 설정 방법을 통해 관련 논문을 필터링합니다.
- 5. 제안된 시스템은 초기 연구 및 탐색적 분석에 유망한 도구로서의 가능성을 보여줍니다.


---

*Generated on 2025-09-23 08:40:36*