---
keywords:
  - Neural Collapse
  - Biased Classification
  - Shortcut Learning
  - Imbalanced Attributes
  - Generalization Capability
category: cs.LG
publish_date: 2025-09-22
arxiv_id: 2405.05587
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:14:17.301162",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Neural Collapse",
    "Biased Classification",
    "Shortcut Learning",
    "Imbalanced Attributes",
    "Generalization Capability"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Neural Collapse": 0.8,
    "Biased Classification": 0.78,
    "Shortcut Learning": 0.77,
    "Imbalanced Attributes": 0.75,
    "Generalization Capability": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Neural Collapse",
        "canonical": "Neural Collapse",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Neural Collapse is a novel concept explored in the paper, providing a unique perspective on feature space behavior in neural networks.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "biased classification",
        "canonical": "Biased Classification",
        "aliases": [
          "classification bias"
        ],
        "category": "specific_connectable",
        "rationale": "Biased classification is central to the paper's focus on overcoming shortcut learning, making it a key concept for linking.",
        "novelty_score": 0.7,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "shortcut learning",
        "canonical": "Shortcut Learning",
        "aliases": [
          "shortcut bias"
        ],
        "category": "specific_connectable",
        "rationale": "Shortcut learning is a critical challenge addressed by the proposed framework, relevant for discussions on model generalization.",
        "novelty_score": 0.68,
        "connectivity_score": 0.72,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      },
      {
        "surface": "imbalanced attributes",
        "canonical": "Imbalanced Attributes",
        "aliases": [
          "attribute imbalance"
        ],
        "category": "specific_connectable",
        "rationale": "Imbalanced attributes are a significant factor in the formation of biased feature spaces, crucial for understanding dataset challenges.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.78,
        "link_intent_score": 0.75
      },
      {
        "surface": "generalization capability",
        "canonical": "Generalization Capability",
        "aliases": [
          "model generalization"
        ],
        "category": "broad_technical",
        "rationale": "Generalization capability is a fundamental goal of machine learning models, relevant across various applications.",
        "novelty_score": 0.55,
        "connectivity_score": 0.85,
        "specificity_score": 0.6,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "experiment"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Neural Collapse",
      "resolved_canonical": "Neural Collapse",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "biased classification",
      "resolved_canonical": "Biased Classification",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "shortcut learning",
      "resolved_canonical": "Shortcut Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.72,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "imbalanced attributes",
      "resolved_canonical": "Imbalanced Attributes",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.78,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "generalization capability",
      "resolved_canonical": "Generalization Capability",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.85,
        "specificity": 0.6,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# Navigate Beyond Shortcuts: Debiased Learning through the Lens of Neural Collapse

**Korean Title:** ì§€ë¦„ê¸¸ì„ ë„˜ì–´ í•­í•´í•˜ê¸°: ì‹ ê²½ ë¶•ê´´ì˜ ê´€ì ì—ì„œ ë³¸ í¸í–¥ ì œê±° í•™ìŠµ

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2405.05587.pdf)
**Category**: cs.LG
**Published**: 2025-09-22
**ArXiv ID**: [2405.05587](https://arxiv.org/abs/2405.05587)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/Data coarse graining can improve model performance_20250918|Data coarse graining can improve model performance]] (82.2% similar)
- [[2025-09-22/Efficient Long-Tail Learning in Latent Space by sampling Synthetic Data_20250922|Efficient Long-Tail Learning in Latent Space by sampling Synthetic Data]] (81.7% similar)
- [[2025-09-22/Flavors of Margin_ Implicit Bias of Steepest Descent in Homogeneous Neural Networks_20250922|Flavors of Margin: Implicit Bias of Steepest Descent in Homogeneous Neural Networks]] (81.3% similar)
- [[2025-09-22/Negotiated Representations to Prevent Overfitting in Machine Learning Applications_20250922|Negotiated Representations to Prevent Overfitting in Machine Learning Applications]] (81.0% similar)
- [[2025-09-18/Probabilistic and nonlinear compressive sensing_20250918|Probabilistic and nonlinear compressive sensing]] (80.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Generalization Capability|Generalization Capability]]
**ğŸ”— Specific Connectable**: [[keywords/Biased Classification|Biased Classification]], [[keywords/Shortcut Learning|Shortcut Learning]], [[keywords/Imbalanced Attributes|Imbalanced Attributes]]
**âš¡ Unique Technical**: [[keywords/Neural Collapse|Neural Collapse]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2405.05587v2 Announce Type: replace-cross 
Abstract: Recent studies have noted an intriguing phenomenon termed Neural Collapse, that is, when the neural networks establish the right correlation between feature spaces and the training targets, their last-layer features, together with the classifier weights, will collapse into a stable and symmetric structure. In this paper, we extend the investigation of Neural Collapse to the biased datasets with imbalanced attributes. We observe that models will easily fall into the pitfall of shortcut learning and form a biased, non-collapsed feature space at the early period of training, which is hard to reverse and limits the generalization capability. To tackle the root cause of biased classification, we follow the recent inspiration of prime training, and propose an avoid-shortcut learning framework without additional training complexity. With well-designed shortcut primes based on Neural Collapse structure, the models are encouraged to skip the pursuit of simple shortcuts and naturally capture the intrinsic correlations. Experimental results demonstrate that our method induces better convergence properties during training, and achieves state-of-the-art generalization performance on both synthetic and real-world biased datasets. Our code is available at https://github.com/RachelWolowitz/Navigate-beyond-Shortcuts/tree/main.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2405.05587v2 ë°œí‘œ ìœ í˜•: êµì°¨ êµì²´  
ì´ˆë¡: ìµœê·¼ ì—°êµ¬ì—ì„œëŠ” ì‹ ê²½ ë¶•ê´´(Neural Collapse)ë¼ëŠ” í¥ë¯¸ë¡œìš´ í˜„ìƒì„ ì£¼ëª©í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ì‹ ê²½ë§ì´ íŠ¹ì§• ê³µê°„ê³¼ í•™ìŠµ ëª©í‘œ ê°„ì˜ ì˜¬ë°”ë¥¸ ìƒê´€ê´€ê³„ë¥¼ í™•ë¦½í•  ë•Œ, ë§ˆì§€ë§‰ ì¸µì˜ íŠ¹ì§•ê³¼ ë¶„ë¥˜ê¸° ê°€ì¤‘ì¹˜ê°€ ì•ˆì •ì ì´ê³  ëŒ€ì¹­ì ì¸ êµ¬ì¡°ë¡œ ë¶•ê´´ë˜ëŠ” í˜„ìƒì…ë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ë¶ˆê· í˜• ì†ì„±ì„ ê°€ì§„ í¸í–¥ëœ ë°ì´í„°ì…‹ì— ëŒ€í•œ ì‹ ê²½ ë¶•ê´´ì˜ ì¡°ì‚¬ë¥¼ í™•ì¥í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ëª¨ë¸ì´ í•™ìŠµ ì´ˆê¸°ì— ì‰½ê²Œ ì§€ë¦„ê¸¸ í•™ìŠµì˜ í•¨ì •ì— ë¹ ì ¸ í¸í–¥ë˜ê³  ë¶•ê´´ë˜ì§€ ì•Šì€ íŠ¹ì§• ê³µê°„ì„ í˜•ì„±í•˜ê²Œ ë˜ë©°, ì´ëŠ” ë˜ëŒë¦¬ê¸° ì–´ë µê³  ì¼ë°˜í™” ëŠ¥ë ¥ì„ ì œí•œí•œë‹¤ëŠ” ê²ƒì„ ê´€ì°°í–ˆìŠµë‹ˆë‹¤. í¸í–¥ëœ ë¶„ë¥˜ì˜ ê·¼ë³¸ ì›ì¸ì„ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ìµœê·¼ì˜ ì£¼ìš” í•™ìŠµ ì˜ê°ì„ ë”°ë¥´ê³ , ì¶”ê°€ì ì¸ í•™ìŠµ ë³µì¡ì„± ì—†ì´ ì§€ë¦„ê¸¸ íšŒí”¼ í•™ìŠµ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì‹ ê²½ ë¶•ê´´ êµ¬ì¡°ì— ê¸°ë°˜í•œ ì˜ ì„¤ê³„ëœ ì§€ë¦„ê¸¸ í”„ë¼ì„ì„ í†µí•´, ëª¨ë¸ì€ ë‹¨ìˆœí•œ ì§€ë¦„ê¸¸ ì¶”êµ¬ë¥¼ í”¼í•˜ê³  ë³¸ì§ˆì ì¸ ìƒê´€ê´€ê³„ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í¬ì°©í•˜ë„ë¡ ìœ ë„ë©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼ëŠ” ìš°ë¦¬ì˜ ë°©ë²•ì´ í•™ìŠµ ì¤‘ ë” ë‚˜ì€ ìˆ˜ë ´ íŠ¹ì„±ì„ ìœ ë„í•˜ë©°, í•©ì„± ë° ì‹¤ì œ í¸í–¥ëœ ë°ì´í„°ì…‹ ëª¨ë‘ì—ì„œ ìµœì²¨ë‹¨ ì¼ë°˜í™” ì„±ëŠ¥ì„ ë‹¬ì„±í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì½”ë“œëŠ” https://github.com/RachelWolowitz/Navigate-beyond-Shortcuts/tree/mainì—ì„œ ì´ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ Neural Collapse í˜„ìƒì„ ë¶ˆê· í˜• ì†ì„±ì„ ê°€ì§„ í¸í–¥ëœ ë°ì´í„°ì…‹ìœ¼ë¡œ í™•ì¥í•˜ì—¬ ì—°êµ¬í•©ë‹ˆë‹¤. ì´ˆê¸° í•™ìŠµ ë‹¨ê³„ì—ì„œ ëª¨ë¸ì´ í¸í–¥ëœ ë¹„ìˆ˜ë ´ íŠ¹ì§• ê³µê°„ì„ í˜•ì„±í•˜ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ì¶”ê°€ì ì¸ ë³µì¡ì„± ì—†ì´ ë‹¨ì¶• í•™ìŠµì„ í”¼í•˜ëŠ” í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. Neural Collapse êµ¬ì¡°ì— ê¸°ë°˜í•œ ì˜ ì„¤ê³„ëœ ë‹¨ì¶• í”„ë¼ì„ì„ í†µí•´ ëª¨ë¸ì´ ë³¸ì§ˆì ì¸ ìƒê´€ê´€ê³„ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í¬ì°©í•˜ë„ë¡ ìœ ë„í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì€ í•™ìŠµ ì¤‘ ë” ë‚˜ì€ ìˆ˜ë ´ íŠ¹ì„±ì„ ë³´ì´ë©°, í¸í–¥ëœ ë°ì´í„°ì…‹ì—ì„œ ìµœì²¨ë‹¨ ì¼ë°˜í™” ì„±ëŠ¥ì„ ë‹¬ì„±í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Neural CollapseëŠ” ì‹ ê²½ë§ì˜ ë§ˆì§€ë§‰ ì¸µ íŠ¹ì§•ê³¼ ë¶„ë¥˜ê¸° ê°€ì¤‘ì¹˜ê°€ ì•ˆì •ì ì´ê³  ëŒ€ì¹­ì ì¸ êµ¬ì¡°ë¡œ ìˆ˜ë ´í•˜ëŠ” í˜„ìƒì…ë‹ˆë‹¤.
- 2. í¸í–¥ëœ ë°ì´í„°ì…‹ì—ì„œ Neural Collapseë¥¼ ì¡°ì‚¬í•œ ê²°ê³¼, ëª¨ë¸ì´ ì´ˆê¸° í•™ìŠµ ë‹¨ê³„ì—ì„œ ë¹„ëŒ€ì¹­ì ì´ê³  ë¹„ìˆ˜ë ´ì ì¸ íŠ¹ì§• ê³µê°„ì„ í˜•ì„±í•˜ëŠ” ê²½í–¥ì´ ìˆìŒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.
- 3. í¸í–¥ëœ ë¶„ë¥˜ì˜ ê·¼ë³¸ ì›ì¸ì„ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ì¶”ê°€ì ì¸ í•™ìŠµ ë³µì¡ë„ ì—†ì´ ì§€ë¦„ê¸¸ í•™ìŠµì„ í”¼í•˜ëŠ” í•™ìŠµ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.
- 4. ì œì•ˆëœ ë°©ë²•ì€ Neural Collapse êµ¬ì¡°ì— ê¸°ë°˜í•œ ì§€ë¦„ê¸¸ í”„ë¼ì„ì„ í™œìš©í•˜ì—¬ ëª¨ë¸ì´ ë‹¨ìˆœí•œ ì§€ë¦„ê¸¸ì„ í”¼í•˜ê³  ë‚´ì¬ëœ ìƒê´€ê´€ê³„ë¥¼ í¬ì°©í•˜ë„ë¡ ìœ ë„í•©ë‹ˆë‹¤.
- 5. ì‹¤í—˜ ê²°ê³¼, ìš°ë¦¬ì˜ ë°©ë²•ì€ í•™ìŠµ ì¤‘ ë” ë‚˜ì€ ìˆ˜ë ´ íŠ¹ì„±ì„ ìœ ë„í•˜ê³ , í¸í–¥ëœ ë°ì´í„°ì…‹ì—ì„œ ìµœì²¨ë‹¨ ì¼ë°˜í™” ì„±ëŠ¥ì„ ë‹¬ì„±í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-23 11:14:17*