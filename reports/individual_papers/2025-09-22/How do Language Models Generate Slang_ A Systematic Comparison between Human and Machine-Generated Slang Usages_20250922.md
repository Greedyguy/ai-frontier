---
keywords:
  - Large Language Model
  - Slang Detection
  - Slang Interpretation
  - Machine-Generated Slang
  - Model Distillation
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2509.15518
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T09:02:20.680369",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Slang Detection",
    "Slang Interpretation",
    "Machine-Generated Slang",
    "Model Distillation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Slang Detection": 0.78,
    "Slang Interpretation": 0.75,
    "Machine-Generated Slang": 0.72,
    "Model Distillation": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Language Models"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's analysis, linking to a broad technical concept in NLP.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Slang Detection",
        "canonical": "Slang Detection",
        "aliases": [
          "Slang Identification"
        ],
        "category": "unique_technical",
        "rationale": "A specific task within NLP that the paper addresses, providing a unique link.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Slang Interpretation",
        "canonical": "Slang Interpretation",
        "aliases": [
          "Slang Understanding"
        ],
        "category": "unique_technical",
        "rationale": "Focuses on understanding slang, a unique aspect of language processing discussed in the paper.",
        "novelty_score": 0.65,
        "connectivity_score": 0.6,
        "specificity_score": 0.78,
        "link_intent_score": 0.75
      },
      {
        "surface": "Machine-Generated Slang",
        "canonical": "Machine-Generated Slang",
        "aliases": [
          "AI-Generated Slang"
        ],
        "category": "unique_technical",
        "rationale": "Highlights the comparison between human and machine outputs, a unique technical focus.",
        "novelty_score": 0.68,
        "connectivity_score": 0.55,
        "specificity_score": 0.85,
        "link_intent_score": 0.72
      },
      {
        "surface": "Model Distillation",
        "canonical": "Model Distillation",
        "aliases": [
          "Knowledge Distillation"
        ],
        "category": "specific_connectable",
        "rationale": "Relevant for linking to methods of transferring knowledge within models.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "slang usages",
      "human-attested"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Slang Detection",
      "resolved_canonical": "Slang Detection",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Slang Interpretation",
      "resolved_canonical": "Slang Interpretation",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.6,
        "specificity": 0.78,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Machine-Generated Slang",
      "resolved_canonical": "Machine-Generated Slang",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.55,
        "specificity": 0.85,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "Model Distillation",
      "resolved_canonical": "Model Distillation",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# How do Language Models Generate Slang: A Systematic Comparison between Human and Machine-Generated Slang Usages

**Korean Title:** 언어 모델은 어떻게 속어를 생성하는가: 인간과 기계 생성 속어 사용의 체계적 비교

## 📋 메타데이터

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15518.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2509.15518](https://arxiv.org/abs/2509.15518)

## 🔗 유사한 논문
- [[2025-09-22/A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages_20250922|A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages]] (88.3% similar)
- [[2025-09-17/Do Large Language Models Understand Word Senses?_20250917|Do Large Language Models Understand Word Senses?]] (87.5% similar)
- [[2025-09-19/Adding LLMs to the psycholinguistic norming toolbox_ A practical guide to getting the most out of human ratings_20250919|Adding LLMs to the psycholinguistic norming toolbox: A practical guide to getting the most out of human ratings]] (86.4% similar)
- [[2025-09-22/It Depends_ Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge_20250922|It Depends: Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge]] (86.1% similar)
- [[2025-09-18/Catch Me If You Can? Not Yet_ LLMs Still Struggle to Imitate the Implicit Writing Styles of Everyday Authors_20250918|Catch Me If You Can? Not Yet: LLMs Still Struggle to Imitate the Implicit Writing Styles of Everyday Authors]] (85.5% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Model Distillation|Model Distillation]]
**⚡ Unique Technical**: [[keywords/Slang Detection|Slang Detection]], [[keywords/Slang Interpretation|Slang Interpretation]], [[keywords/Machine-Generated Slang|Machine-Generated Slang]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.15518v1 Announce Type: cross 
Abstract: Slang is a commonly used type of informal language that poses a daunting challenge to NLP systems. Recent advances in large language models (LLMs), however, have made the problem more approachable. While LLM agents are becoming more widely applied to intermediary tasks such as slang detection and slang interpretation, their generalizability and reliability are heavily dependent on whether these models have captured structural knowledge about slang that align well with human attested slang usages. To answer this question, we contribute a systematic comparison between human and machine-generated slang usages. Our evaluative framework focuses on three core aspects: 1) Characteristics of the usages that reflect systematic biases in how machines perceive slang, 2) Creativity reflected by both lexical coinages and word reuses employed by the slang usages, and 3) Informativeness of the slang usages when used as gold-standard examples for model distillation. By comparing human-attested slang usages from the Online Slang Dictionary (OSD) and slang generated by GPT-4o and Llama-3, we find significant biases in how LLMs perceive slang. Our results suggest that while LLMs have captured significant knowledge about the creative aspects of slang, such knowledge does not align with humans sufficiently to enable LLMs for extrapolative tasks such as linguistic analyses.

## 🔍 Abstract (한글 번역)

arXiv:2509.15518v1 발표 유형: 교차  
초록: 속어는 비공식적인 언어의 한 유형으로, 자연어 처리(NLP) 시스템에 상당한 도전 과제를 제시합니다. 그러나 최근 대형 언어 모델(LLM)의 발전은 이 문제를 보다 접근 가능하게 만들었습니다. LLM 에이전트가 속어 감지 및 해석과 같은 중간 작업에 점점 더 널리 적용되고 있지만, 이러한 모델이 인간이 입증한 속어 사용과 잘 맞는 구조적 지식을 포착했는지 여부에 따라 그 일반화 가능성과 신뢰성이 크게 좌우됩니다. 이 질문에 답하기 위해, 우리는 인간과 기계 생성 속어 사용 간의 체계적인 비교를 제공합니다. 우리의 평가 프레임워크는 세 가지 핵심 측면에 중점을 둡니다: 1) 기계가 속어를 인식하는 방식에서 체계적인 편향을 반영하는 사용의 특성, 2) 속어 사용에 의해 사용된 어휘적 신조어와 단어 재사용에 의해 반영된 창의성, 3) 모델 증류를 위한 금표준 예로 사용될 때 속어 사용의 정보성. 온라인 속어 사전(OSD)에서 인간이 입증한 속어 사용과 GPT-4o 및 Llama-3에 의해 생성된 속어를 비교함으로써, 우리는 LLM이 속어를 인식하는 방식에서 상당한 편향을 발견합니다. 우리의 결과는 LLM이 속어의 창의적 측면에 대한 상당한 지식을 포착했지만, 그러한 지식이 언어 분석과 같은 외삽적 작업을 가능하게 할 만큼 인간과 충분히 일치하지 않는다는 것을 시사합니다.

## 📝 요약

이 논문은 대형 언어 모델(LLM)이 비공식 언어인 속어를 어떻게 이해하고 처리하는지를 분석합니다. 연구는 인간과 기계가 생성한 속어 사용을 비교하여 LLM의 일반화 및 신뢰성을 평가합니다. 주요 기여는 LLM이 속어의 창의적 측면을 어느 정도 이해하지만, 인간의 속어 사용과 충분히 일치하지 않아 언어 분석과 같은 확장적 작업에는 한계가 있음을 발견한 것입니다. 연구는 속어의 체계적 편향, 창의성, 정보성을 중심으로 평가를 진행하였으며, LLM이 속어의 창의성을 어느 정도 포착했으나 인간과의 불일치로 인해 한계가 존재함을 시사합니다.

## 🎯 주요 포인트

- 1. 속어는 NLP 시스템에 도전적인 과제를 제시하지만, 대형 언어 모델(LLM)의 발전으로 문제 해결이 더 접근 가능해졌다.
- 2. LLM 에이전트는 속어 탐지 및 해석과 같은 중간 작업에 널리 적용되고 있지만, 이들의 일반화 및 신뢰성은 인간의 속어 사용과 잘 맞는 구조적 지식을 포착했는지에 크게 의존한다.
- 3. 본 연구는 인간과 기계가 생성한 속어 사용을 체계적으로 비교하여, 기계가 속어를 인식하는 데 있어 체계적인 편향을 드러내는 사용의 특성, 속어 사용에서 나타나는 창의성, 그리고 모델 증류를 위한 금표준 예로서의 정보성을 평가한다.
- 4. 연구 결과, LLM은 속어의 창의적 측면에 대한 상당한 지식을 포착했지만, 인간과 충분히 일치하지 않아 언어 분석과 같은 외삽적 작업에는 적합하지 않음을 시사한다.


---

*Generated on 2025-09-23 09:02:20*