---
keywords:
  - Large Language Model
  - Low-Resource Languages
  - Synthetic Data Generation
  - Prompting Strategies
category: cs.CL
publish_date: 2025-09-22
arxiv_id: 2506.12158
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:48:51.861220",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Low-Resource Languages",
    "Synthetic Data Generation",
    "Prompting Strategies"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Low-Resource Languages": 0.7,
    "Synthetic Data Generation": 0.8,
    "Prompting Strategies": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Large Language Models"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's focus on data generation strategies, linking to broader discussions on LLMs.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "low-resource languages",
        "canonical": "Low-Resource Languages",
        "aliases": [
          "low-resource language",
          "under-resourced languages"
        ],
        "category": "unique_technical",
        "rationale": "Key focus of the study, enabling connections to research on language diversity and resource scarcity.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      },
      {
        "surface": "synthetic data generation",
        "canonical": "Synthetic Data Generation",
        "aliases": [
          "data synthesis",
          "synthetic data"
        ],
        "category": "specific_connectable",
        "rationale": "Crucial for understanding the paper's methodology and its implications for model training.",
        "novelty_score": 0.6,
        "connectivity_score": 0.78,
        "specificity_score": 0.75,
        "link_intent_score": 0.8
      },
      {
        "surface": "prompting strategies",
        "canonical": "Prompting Strategies",
        "aliases": [
          "prompt engineering",
          "prompt techniques"
        ],
        "category": "specific_connectable",
        "rationale": "Highlights a methodological aspect that can link to broader discussions on model prompting.",
        "novelty_score": 0.65,
        "connectivity_score": 0.72,
        "specificity_score": 0.7,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "low-resource languages",
      "resolved_canonical": "Low-Resource Languages",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "synthetic data generation",
      "resolved_canonical": "Synthetic Data Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.78,
        "specificity": 0.75,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "prompting strategies",
      "resolved_canonical": "Prompting Strategies",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.72,
        "specificity": 0.7,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages

**Korean Title:** ì €ìì›ì´ ë¶€ì¡±í•œ ì–¸ì–´ë¥¼ ìœ„í•œ LLM ë°ì´í„° ìƒì„± ì „ëµì— ëŒ€í•œ ì—„ë°€í•œ í‰ê°€

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2506.12158.pdf)
**Category**: cs.CL
**Published**: 2025-09-22
**ArXiv ID**: [2506.12158](https://arxiv.org/abs/2506.12158)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/How do Language Models Generate Slang_ A Systematic Comparison between Human and Machine-Generated Slang Usages_20250922|How do Language Models Generate Slang: A Systematic Comparison between Human and Machine-Generated Slang Usages]] (88.3% similar)
- [[2025-09-22/MUG-Eval_ A Proxy Evaluation Framework for Multilingual Generation Capabilities in Any Language_20250922|MUG-Eval: A Proxy Evaluation Framework for Multilingual Generation Capabilities in Any Language]] (87.9% similar)
- [[2025-09-22/Benchmark of stylistic variation in LLM-generated texts_20250922|Benchmark of stylistic variation in LLM-generated texts]] (87.7% similar)
- [[2025-09-22/SyGra_ A Unified Graph-Based Framework for Scalable Generation, Quality Tagging, and Management of Synthetic Data_20250922|SyGra: A Unified Graph-Based Framework for Scalable Generation, Quality Tagging, and Management of Synthetic Data]] (86.8% similar)
- [[2025-09-19/Adding LLMs to the psycholinguistic norming toolbox_ A practical guide to getting the most out of human ratings_20250919|Adding LLMs to the psycholinguistic norming toolbox: A practical guide to getting the most out of human ratings]] (86.4% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Synthetic Data Generation|Synthetic Data Generation]], [[keywords/Prompting Strategies|Prompting Strategies]]
**âš¡ Unique Technical**: [[keywords/Low-Resource Languages|Low-Resource Languages]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2506.12158v3 Announce Type: replace 
Abstract: Large Language Models (LLMs) are increasingly used to generate synthetic textual data for training smaller specialized models. However, a comparison of various generation strategies for low-resource language settings is lacking. While various prompting strategies have been proposed, such as demonstrations, label-based summaries, and self-revision, their comparative effectiveness remains unclear, especially for low-resource languages. In this paper, we systematically evaluate the performance of these generation strategies and their combinations across 11 typologically diverse languages, including several extremely low-resource ones. Using three NLP tasks and four open-source LLMs, we assess downstream model performance on generated versus gold-standard data. Our results show that strategic combinations of generation methods, particularly target-language demonstrations with LLM-based revisions, yield strong performance, narrowing the gap with real data to as little as 5% in some settings. We also find that smart prompting techniques can reduce the advantage of larger LLMs, highlighting efficient generation strategies for synthetic data generation in low-resource scenarios with smaller models.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2506.12158v3 ë°œí‘œ ìœ í˜•: êµì²´  
ì´ˆë¡: ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì€ ì ì  ë” ì‘ì€ íŠ¹í™” ëª¨ë¸ì„ í›ˆë ¨í•˜ê¸° ìœ„í•œ í•©ì„± í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ë° ì‚¬ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì €ìì› ì–¸ì–´ í™˜ê²½ì— ëŒ€í•œ ë‹¤ì–‘í•œ ìƒì„± ì „ëµì˜ ë¹„êµëŠ” ë¶€ì¡±í•©ë‹ˆë‹¤. ì‹œì—°, ë ˆì´ë¸” ê¸°ë°˜ ìš”ì•½, ìê¸° ìˆ˜ì •ê³¼ ê°™ì€ ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸ ì „ëµì´ ì œì•ˆë˜ì—ˆì§€ë§Œ, íŠ¹íˆ ì €ìì› ì–¸ì–´ì— ëŒ€í•œ ë¹„êµì  íš¨ê³¼ëŠ” ëª…í™•í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” 11ê°œì˜ ìœ í˜•í•™ì ìœ¼ë¡œ ë‹¤ì–‘í•œ ì–¸ì–´, íŠ¹íˆ ëª‡ëª‡ ê·¹íˆ ì €ìì› ì–¸ì–´ë¥¼ í¬í•¨í•˜ì—¬ ì´ëŸ¬í•œ ìƒì„± ì „ëµê³¼ ê·¸ ì¡°í•©ì˜ ì„±ëŠ¥ì„ ì²´ê³„ì ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤. ì„¸ ê°€ì§€ NLP ê³¼ì œì™€ ë„¤ ê°€ì§€ ì˜¤í”ˆ ì†ŒìŠ¤ LLMì„ ì‚¬ìš©í•˜ì—¬ ìƒì„±ëœ ë°ì´í„°ì™€ ê³¨ë“œ ìŠ¤íƒ ë‹¤ë“œ ë°ì´í„°ì— ëŒ€í•œ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ëª¨ë¸ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ê²°ê³¼ëŠ” ìƒì„± ë°©ë²•ì˜ ì „ëµì  ì¡°í•©, íŠ¹íˆ LLM ê¸°ë°˜ ìˆ˜ì •ê³¼ í•¨ê»˜ ëª©í‘œ ì–¸ì–´ ì‹œì—°ì´ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ë©°, ì¼ë¶€ í™˜ê²½ì—ì„œëŠ” ì‹¤ì œ ë°ì´í„°ì™€ì˜ ê²©ì°¨ë¥¼ 5%ê¹Œì§€ ì¤„ì¼ ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë˜í•œ ìŠ¤ë§ˆíŠ¸ í”„ë¡¬í”„íŠ¸ ê¸°ìˆ ì´ ë” í° LLMì˜ ì¥ì ì„ ì¤„ì¼ ìˆ˜ ìˆìŒì„ ë°œê²¬í•˜ì—¬, ì €ìì› ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì‘ì€ ëª¨ë¸ë¡œ í•©ì„± ë°ì´í„° ìƒì„±ì„ ìœ„í•œ íš¨ìœ¨ì ì¸ ìƒì„± ì „ëµì„ ê°•ì¡°í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ í™œìš©í•˜ì—¬ ì €ìì› ì–¸ì–´ í™˜ê²½ì—ì„œì˜ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ë‹¤ì–‘í•œ ì „ëµì„ ë¹„êµ í‰ê°€í•©ë‹ˆë‹¤. 11ê°œì˜ ë‹¤ì–‘í•œ ì–¸ì–´ë¥¼ ëŒ€ìƒìœ¼ë¡œ, ì‹œì—°, ë ˆì´ë¸” ê¸°ë°˜ ìš”ì•½, ìê¸° ìˆ˜ì • ë“±ì˜ í”„ë¡¬í”„íŠ¸ ì „ëµì„ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í–ˆìŠµë‹ˆë‹¤. ì„¸ ê°€ì§€ NLP ì‘ì—…ê³¼ ë„¤ ê°œì˜ ì˜¤í”ˆì†ŒìŠ¤ LLMì„ ì‚¬ìš©í•˜ì—¬ ìƒì„±ëœ ë°ì´í„°ì™€ ì‹¤ì œ ë°ì´í„°ì˜ ì„±ëŠ¥ì„ ë¹„êµí•œ ê²°ê³¼, ëª©í‘œ ì–¸ì–´ ì‹œì—°ê³¼ LLM ê¸°ë°˜ ìˆ˜ì •ì˜ ì¡°í•©ì´ ì‹¤ì œ ë°ì´í„°ì™€ì˜ ì„±ëŠ¥ ê²©ì°¨ë¥¼ ìµœëŒ€ 5%ê¹Œì§€ ì¤„ì¼ ìˆ˜ ìˆìŒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, ìŠ¤ë§ˆíŠ¸ í”„ë¡¬í”„íŠ¸ ê¸°ìˆ ì´ ëŒ€í˜• LLMì˜ ìš°ìœ„ë¥¼ ì¤„ì¼ ìˆ˜ ìˆìŒì„ ë³´ì—¬ì£¼ì–´, ì €ìì› ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ íš¨ìœ¨ì ì¸ ë°ì´í„° ìƒì„± ì „ëµì„ ì œì‹œí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë‹¤ì–‘í•œ ìƒì„± ì „ëµì˜ ë¹„êµ ì—°êµ¬ê°€ ë¶€ì¡±í•œ ì €ìì› ì–¸ì–´ í™˜ê²½ì—ì„œ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì˜ ì„±ëŠ¥ì„ ì²´ê³„ì ìœ¼ë¡œ í‰ê°€í–ˆìŠµë‹ˆë‹¤.
- 2. 11ê°œì˜ ë‹¤ì–‘í•œ ì–¸ì–´ì—ì„œ ëª©í‘œ ì–¸ì–´ ì‹œì—°ê³¼ LLM ê¸°ë°˜ ìˆ˜ì •ì˜ ì „ëµì  ì¡°í•©ì´ ì‹¤ì œ ë°ì´í„°ì™€ì˜ ì„±ëŠ¥ ì°¨ì´ë¥¼ 5%ê¹Œì§€ ì¤„ì¼ ìˆ˜ ìˆìŒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.
- 3. ìŠ¤ë§ˆíŠ¸ í”„ë¡¬í”„íŠ¸ ê¸°ë²•ì´ ë” í° LLMì˜ ì¥ì ì„ ì¤„ì¼ ìˆ˜ ìˆìŒì„ ë³´ì—¬ì£¼ë©°, ì €ìì› ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì‘ì€ ëª¨ë¸ì„ ìœ„í•œ íš¨ìœ¨ì ì¸ í•©ì„± ë°ì´í„° ìƒì„± ì „ëµì„ ê°•ì¡°í•©ë‹ˆë‹¤.
- 4. ì„¸ ê°€ì§€ NLP ê³¼ì œì™€ ë„¤ ê°œì˜ ì˜¤í”ˆ ì†ŒìŠ¤ LLMì„ ì‚¬ìš©í•˜ì—¬ ìƒì„±ëœ ë°ì´í„°ì™€ ê³¨ë“œ ìŠ¤íƒ ë‹¤ë“œ ë°ì´í„° ê°„ì˜ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ëª¨ë¸ ì„±ëŠ¥ì„ í‰ê°€í–ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-23 11:48:51*