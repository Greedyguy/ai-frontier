---
keywords:
  - Vision-Language Model
  - Remote Sensing
  - Quality Assessment
  - Reinforcement Learning
  - Best-of-N Scaling
category: cs.CV
publish_date: 2025-09-22
arxiv_id: 2503.00743
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T12:31:28.940266",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Vision-Language Model",
    "Remote Sensing",
    "Quality Assessment",
    "Reinforcement Learning",
    "Best-of-N Scaling"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Vision-Language Model": 0.85,
    "Remote Sensing": 0.78,
    "Quality Assessment": 0.7,
    "Reinforcement Learning": 0.8,
    "Best-of-N Scaling": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Vision-Language Models",
        "canonical": "Vision-Language Model",
        "aliases": [
          "VLM",
          "Vision-Language"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-Language Models are central to the paper's focus and connect well with multimodal learning trends.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Remote Sensing",
        "canonical": "Remote Sensing",
        "aliases": [
          "RS"
        ],
        "category": "unique_technical",
        "rationale": "Remote Sensing is a specific domain focus of the paper, providing a unique application context.",
        "novelty_score": 0.65,
        "connectivity_score": 0.72,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Quality Assessment",
        "canonical": "Quality Assessment",
        "aliases": [
          "QA"
        ],
        "category": "unique_technical",
        "rationale": "Quality Assessment is a novel aspect of the paper's methodology, focusing on data curation.",
        "novelty_score": 0.68,
        "connectivity_score": 0.6,
        "specificity_score": 0.75,
        "link_intent_score": 0.7
      },
      {
        "surface": "Reinforcement Learning",
        "canonical": "Reinforcement Learning",
        "aliases": [
          "RL"
        ],
        "category": "broad_technical",
        "rationale": "Reinforcement Learning is used in the paper for training models, linking to broader machine learning techniques.",
        "novelty_score": 0.4,
        "connectivity_score": 0.85,
        "specificity_score": 0.65,
        "link_intent_score": 0.8
      },
      {
        "surface": "Best-of-N Scaling",
        "canonical": "Best-of-N Scaling",
        "aliases": [
          "BoN"
        ],
        "category": "unique_technical",
        "rationale": "Best-of-N Scaling is a specific technique highlighted in the paper for improving model performance.",
        "novelty_score": 0.7,
        "connectivity_score": 0.55,
        "specificity_score": 0.78,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "data synthesis",
      "semantic relationships"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Vision-Language Models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Remote Sensing",
      "resolved_canonical": "Remote Sensing",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.72,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Quality Assessment",
      "resolved_canonical": "Quality Assessment",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.6,
        "specificity": 0.75,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Reinforcement Learning",
      "resolved_canonical": "Reinforcement Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.85,
        "specificity": 0.65,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Best-of-N Scaling",
      "resolved_canonical": "Best-of-N Scaling",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.55,
        "specificity": 0.78,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# Quality-Driven Curation of Remote Sensing Vision-Language Data via Learned Scoring Models

**Korean Title:** ì›ê²© ê°ì§€ ë¹„ì „-ì–¸ì–´ ë°ì´í„°ì˜ í’ˆì§ˆ ì¤‘ì‹¬ íë ˆì´ì…˜ì„ ìœ„í•œ í•™ìŠµëœ ìŠ¤ì½”ì–´ë§ ëª¨ë¸ í™œìš©

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2503.00743.pdf)
**Category**: cs.CV
**Published**: 2025-09-22
**ArXiv ID**: [2503.00743](https://arxiv.org/abs/2503.00743)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Vision-Language Models as Differentiable Semantic and Spatial Rewards for Text-to-3D Generation_20250922|Vision-Language Models as Differentiable Semantic and Spatial Rewards for Text-to-3D Generation]] (85.8% similar)
- [[2025-09-19/QuizRank_ Picking Images by Quizzing VLMs_20250919|QuizRank: Picking Images by Quizzing VLMs]] (84.5% similar)
- [[2025-09-22/Robust Vision-Language Models via Tensor Decomposition_ A Defense Against Adversarial Attacks_20250922|Robust Vision-Language Models via Tensor Decomposition: A Defense Against Adversarial Attacks]] (84.4% similar)
- [[2025-09-22/SAR-TEXT_ A Large-Scale SAR Image-Text Dataset Built with SAR-Narrator and Progressive Transfer Learning_20250922|SAR-TEXT: A Large-Scale SAR Image-Text Dataset Built with SAR-Narrator and Progressive Transfer Learning]] (84.2% similar)
- [[2025-09-19/UnifiedVisual_ A Framework for Constructing Unified Vision-Language Datasets_20250919|UnifiedVisual: A Framework for Constructing Unified Vision-Language Datasets]] (84.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Reinforcement Learning|Reinforcement Learning]]
**âš¡ Unique Technical**: [[keywords/Remote Sensing|Remote Sensing]], [[keywords/Quality Assessment|Quality Assessment]], [[keywords/Best-of-N Scaling|Best-of-N Scaling]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2503.00743v2 Announce Type: replace 
Abstract: Vision-Language Models (VLMs) have demonstrated great potential in interpreting remote sensing (RS) images through language-guided semantic. However, the effectiveness of these VLMs critically depends on high-quality image-text training data that captures rich semantic relationships between visual content and language descriptions. Unlike natural images, RS lacks large-scale interleaved image-text pairs from web data, making data collection challenging. While current approaches rely primarily on rule-based methods or flagship VLMs for data synthesis, a systematic framework for automated quality assessment of such synthetically generated RS vision-language data is notably absent. To fill this gap, we propose a novel score model trained on large-scale RS vision-language preference data for automated quality assessment. Our empirical results demonstrate that fine-tuning CLIP or advanced VLMs (e.g., Qwen2-VL) with the top 30% of data ranked by our score model achieves superior accuracy compared to both full-data fine-tuning and CLIP-score-based ranking approaches. Furthermore, we demonstrate applications of our scoring model for reinforcement learning (RL) training and best-of-N (BoN) test-time scaling, enabling significant improvements in VLM performance for RS tasks. Our code, model, and dataset are publicly available

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2503.00743v2 ë°œí‘œ ìœ í˜•: êµì²´  
ì´ˆë¡: ë¹„ì „-ì–¸ì–´ ëª¨ë¸(VLMs)ì€ ì–¸ì–´ë¡œ ìœ ë„ëœ ì˜ë¯¸ë¡ ì„ í†µí•´ ì›ê²© ê°ì§€(RS) ì´ë¯¸ì§€ë¥¼ í•´ì„í•˜ëŠ” ë° ìˆì–´ í° ì ì¬ë ¥ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ëŸ¬í•œ VLMsì˜ íš¨ê³¼ëŠ” ì‹œê°ì  ì½˜í…ì¸ ì™€ ì–¸ì–´ ì„¤ëª… ê°„ì˜ í’ë¶€í•œ ì˜ë¯¸ ê´€ê³„ë¥¼ í¬ì°©í•˜ëŠ” ê³ í’ˆì§ˆ ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ í•™ìŠµ ë°ì´í„°ì— í¬ê²Œ ì˜ì¡´í•©ë‹ˆë‹¤. ìì—° ì´ë¯¸ì§€ì™€ ë‹¬ë¦¬, RSëŠ” ì›¹ ë°ì´í„°ì—ì„œ ëŒ€ê·œëª¨ë¡œ ì–½íŒ ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ìŒì´ ë¶€ì¡±í•˜ì—¬ ë°ì´í„° ìˆ˜ì§‘ì´ ì–´ë µìŠµë‹ˆë‹¤. í˜„ì¬ì˜ ì ‘ê·¼ ë°©ì‹ì€ ì£¼ë¡œ ê·œì¹™ ê¸°ë°˜ ë°©ë²•ì´ë‚˜ ì£¼ë ¥ VLMsì— ì˜ì¡´í•˜ì—¬ ë°ì´í„°ë¥¼ í•©ì„±í•˜ì§€ë§Œ, ì´ëŸ¬í•œ í•©ì„±ëœ RS ë¹„ì „-ì–¸ì–´ ë°ì´í„°ì˜ ìë™ í’ˆì§ˆ í‰ê°€ë¥¼ ìœ„í•œ ì²´ê³„ì ì¸ í”„ë ˆì„ì›Œí¬ëŠ” ëˆˆì— ë„ê²Œ ë¶€ì¡±í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ê²©ì°¨ë¥¼ ë©”ìš°ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ëŒ€ê·œëª¨ RS ë¹„ì „-ì–¸ì–´ ì„ í˜¸ ë°ì´í„°ì— ëŒ€í•´ í•™ìŠµëœ ìƒˆë¡œìš´ ì ìˆ˜ ëª¨ë¸ì„ ì œì•ˆí•˜ì—¬ ìë™ í’ˆì§ˆ í‰ê°€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì‹¤í—˜ ê²°ê³¼ëŠ” ì ìˆ˜ ëª¨ë¸ì— ì˜í•´ ìƒìœ„ 30%ë¡œ ìˆœìœ„ê°€ ë§¤ê²¨ì§„ ë°ì´í„°ë¡œ CLIP ë˜ëŠ” ê³ ê¸‰ VLMs(ì˜ˆ: Qwen2-VL)ë¥¼ ë¯¸ì„¸ ì¡°ì •í•˜ë©´ ì „ì²´ ë°ì´í„° ë¯¸ì„¸ ì¡°ì • ë° CLIP ì ìˆ˜ ê¸°ë°˜ ìˆœìœ„ ì ‘ê·¼ ë°©ì‹ë³´ë‹¤ ìš°ìˆ˜í•œ ì •í™•ë„ë¥¼ ë‹¬ì„±í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë˜í•œ, ìš°ë¦¬ëŠ” ê°•í™” í•™ìŠµ(RL) í›ˆë ¨ ë° ë² ìŠ¤íŠ¸ ì˜¤ë¸Œ N(BoN) í…ŒìŠ¤íŠ¸ ì‹œê°„ í™•ì¥ì„ ìœ„í•œ ì ìˆ˜ ëª¨ë¸ì˜ ì‘ìš©ì„ ì‹œì—°í•˜ì—¬ RS ì‘ì—…ì— ëŒ€í•œ VLM ì„±ëŠ¥ì˜ ìƒë‹¹í•œ ê°œì„ ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì½”ë“œ, ëª¨ë¸ ë° ë°ì´í„°ì…‹ì€ ê³µê°œì ìœ¼ë¡œ ì´ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì›ê²© íƒì‚¬(RS) ì´ë¯¸ì§€ì˜ ì–¸ì–´ ê¸°ë°˜ ì˜ë¯¸ í•´ì„ì„ ìœ„í•œ ë¹„ì „-ì–¸ì–´ ëª¨ë¸(VLMs)ì˜ íš¨ê³¼ì ì¸ í™œìš©ì„ ìœ„í•´ ê³ í’ˆì§ˆ ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ë°ì´í„°ì˜ í•„ìš”ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤. RS ë¶„ì•¼ì—ì„œëŠ” ëŒ€ê·œëª¨ ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ìŒì´ ë¶€ì¡±í•˜ì—¬ ë°ì´í„° ìˆ˜ì§‘ì´ ì–´ë µìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ì €ìë“¤ì€ ëŒ€ê·œëª¨ RS ë¹„ì „-ì–¸ì–´ ì„ í˜¸ ë°ì´í„°ë¡œ í›ˆë ¨ëœ ìƒˆë¡œìš´ ìŠ¤ì½”ì–´ ëª¨ë¸ì„ ì œì•ˆí•˜ì—¬ ìë™ í’ˆì§ˆ í‰ê°€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì´ ìŠ¤ì½”ì–´ ëª¨ë¸ë¡œ ìƒìœ„ 30% ë°ì´í„°ë¥¼ ì„ ë³„í•˜ì—¬ CLIP ë˜ëŠ” ê³ ê¸‰ VLMsë¥¼ ë¯¸ì„¸ ì¡°ì •í•˜ë©´ ì „ì²´ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°ë³´ë‹¤ ë” ë†’ì€ ì •í™•ë„ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, ì´ ìŠ¤ì½”ì–´ ëª¨ë¸ì€ ê°•í™” í•™ìŠµ(RL) í›ˆë ¨ê³¼ í…ŒìŠ¤íŠ¸ ì‹œ í™•ì¥ì— í™œìš©ë˜ì–´ RS ì‘ì—…ì—ì„œ VLM ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤. ì½”ë“œ, ëª¨ë¸, ë°ì´í„°ì…‹ì€ ê³µê°œë˜ì–´ ìˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì›ê²© ê°ì§€(RS) ì´ë¯¸ì§€ í•´ì„ì„ ìœ„í•œ ë¹„ì „-ì–¸ì–´ ëª¨ë¸(VLM)ì˜ íš¨ê³¼ëŠ” ê³ í’ˆì§ˆ ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ í›ˆë ¨ ë°ì´í„°ì— í¬ê²Œ ì˜ì¡´í•©ë‹ˆë‹¤.
- 2. RSëŠ” ì›¹ ë°ì´í„°ì—ì„œ ëŒ€ê·œëª¨ ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ìŒì´ ë¶€ì¡±í•˜ì—¬ ë°ì´í„° ìˆ˜ì§‘ì´ ì–´ë µìŠµë‹ˆë‹¤.
- 3. ë³¸ ì—°êµ¬ì—ì„œëŠ” ìë™ í’ˆì§ˆ í‰ê°€ë¥¼ ìœ„í•œ ìƒˆë¡œìš´ ì ìˆ˜ ëª¨ë¸ì„ ì œì•ˆí•˜ì—¬, ìƒìœ„ 30% ë°ì´í„°ë¡œ ë¯¸ì„¸ ì¡°ì • ì‹œ ë†’ì€ ì •í™•ë„ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.
- 4. ì œì•ˆëœ ì ìˆ˜ ëª¨ë¸ì€ ê°•í™” í•™ìŠµ(RL) í›ˆë ¨ ë° í…ŒìŠ¤íŠ¸ ì‹œ ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ ë‹¤ì–‘í•œ ì‘ìš©ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
- 5. ì—°êµ¬ì˜ ì½”ë“œ, ëª¨ë¸, ë°ì´í„°ì…‹ì€ ê³µê°œë˜ì–´ ìˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-23 12:31:28*