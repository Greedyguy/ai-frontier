---
keywords:
  - Vision-Language Model
  - Navigation-Aware Pruning
  - Multimodal Learning
  - Large Language Model
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2509.15250
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T08:49:20.694929",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Vision-Language Model",
    "Navigation-Aware Pruning",
    "Multimodal Learning",
    "Large Language Model"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Vision-Language Model": 0.85,
    "Navigation-Aware Pruning": 0.78,
    "Multimodal Learning": 0.81,
    "Large Language Model": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Vision-and-Language Navigation",
        "canonical": "Vision-Language Model",
        "aliases": [
          "VLN"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-and-Language Navigation is a specific application of Vision-Language Models, which are trending and relevant for linking.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.82,
        "link_intent_score": 0.85
      },
      {
        "surface": "Navigation-Aware Pruning",
        "canonical": "Navigation-Aware Pruning",
        "aliases": [
          "NAP"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel technique introduced in the paper, offering a unique linking opportunity.",
        "novelty_score": 0.9,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.78
      },
      {
        "surface": "Multimodal Token Pruning",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Token Pruning"
        ],
        "category": "specific_connectable",
        "rationale": "Token pruning in multimodal contexts is a specific technique that can connect to broader multimodal learning discussions.",
        "novelty_score": 0.7,
        "connectivity_score": 0.8,
        "specificity_score": 0.75,
        "link_intent_score": 0.81
      },
      {
        "surface": "Large Language Model",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are foundational in modern AI research, providing strong connectivity across topics.",
        "novelty_score": 0.4,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "efficiency",
      "performance",
      "method"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Vision-and-Language Navigation",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.82,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Navigation-Aware Pruning",
      "resolved_canonical": "Navigation-Aware Pruning",
      "decision": "linked",
      "scores": {
        "novelty": 0.9,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Multimodal Token Pruning",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.8,
        "specificity": 0.75,
        "link_intent": 0.81
      }
    },
    {
      "candidate_surface": "Large Language Model",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# Walk and Read Less: Improving the Efficiency of Vision-and-Language Navigation via Tuning-Free Multimodal Token Pruning

**Korean Title:** ê±·ê³  ëœ ì½ê¸°: ì¡°ì •ì´ í•„ìš” ì—†ëŠ” ë©€í‹°ëª¨ë‹¬ í† í° ê°€ì§€ì¹˜ê¸°ë¥¼ í†µí•œ ì‹œê°-ì–¸ì–´ ë‚´ë¹„ê²Œì´ì…˜ì˜ íš¨ìœ¨ì„± í–¥ìƒ

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15250.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2509.15250](https://arxiv.org/abs/2509.15250)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Training-Free Pyramid Token Pruning for Efficient Large Vision-Language Models via Region, Token, and Instruction-Guided Importance_20250922|Training-Free Pyramid Token Pruning for Efficient Large Vision-Language Models via Region, Token, and Instruction-Guided Importance]] (87.0% similar)
- [[2025-09-17/NIRVANA_ Structured pruning reimagined for large language models compression_20250917|NIRVANA: Structured pruning reimagined for large language models compression]] (85.8% similar)
- [[2025-09-18/Embodied Navigation Foundation Model_20250918|Embodied Navigation Foundation Model]] (83.4% similar)
- [[2025-09-19/T-araVLN_ Translator for Agricultural Robotic Agents on Vision-and-Language Navigation_20250919|T-araVLN: Translator for Agricultural Robotic Agents on Vision-and-Language Navigation]] (82.4% similar)
- [[2025-09-18/FSR-VLN_ Fast and Slow Reasoning for Vision-Language Navigation with Hierarchical Multi-modal Scene Graph_20250918|FSR-VLN: Fast and Slow Reasoning for Vision-Language Navigation with Hierarchical Multi-modal Scene Graph]] (82.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**âš¡ Unique Technical**: [[keywords/Navigation-Aware Pruning|Navigation-Aware Pruning]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15250v1 Announce Type: cross 
Abstract: Large models achieve strong performance on Vision-and-Language Navigation (VLN) tasks, but are costly to run in resource-limited environments. Token pruning offers appealing tradeoffs for efficiency with minimal performance loss by reducing model input size, but prior work overlooks VLN-specific challenges. For example, information loss from pruning can effectively increase computational cost due to longer walks. Thus, the inability to identify uninformative tokens undermines the supposed efficiency gains from pruning. To address this, we propose Navigation-Aware Pruning (NAP), which uses navigation-specific traits to simplify the pruning process by pre-filtering tokens into foreground and background. For example, image views are filtered based on whether the agent can navigate in that direction. We also extract navigation-relevant instructions using a Large Language Model. After filtering, we focus pruning on background tokens, minimizing information loss. To further help avoid increases in navigation length, we discourage backtracking by removing low-importance navigation nodes. Experiments on standard VLN benchmarks show NAP significantly outperforms prior work, preserving higher success rates while saving more than 50% FLOPS.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15250v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ëŒ€í˜• ëª¨ë¸ì€ ë¹„ì „-ì–¸ì–´ ë‚´ë¹„ê²Œì´ì…˜(VLN) ì‘ì—…ì—ì„œ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ì§€ë§Œ, ìì›ì´ ì œí•œëœ í™˜ê²½ì—ì„œëŠ” ì‹¤í–‰ ë¹„ìš©ì´ ë§ì´ ë“­ë‹ˆë‹¤. í† í° ê°€ì§€ì¹˜ê¸°ëŠ” ëª¨ë¸ ì…ë ¥ í¬ê¸°ë¥¼ ì¤„ì—¬ ì„±ëŠ¥ ì†ì‹¤ì„ ìµœì†Œí™”í•˜ë©´ì„œ íš¨ìœ¨ì„±ì„ ìœ„í•œ ë§¤ë ¥ì ì¸ ì ˆì¶©ì•ˆì„ ì œê³µí•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ì „ ì—°êµ¬ëŠ” VLNì— íŠ¹í™”ëœ ë„ì „ ê³¼ì œë¥¼ ê°„ê³¼í–ˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê°€ì§€ì¹˜ê¸°ë¡œ ì¸í•œ ì •ë³´ ì†ì‹¤ì€ ë” ê¸´ ê²½ë¡œë¡œ ì¸í•´ ê³„ì‚° ë¹„ìš©ì„ íš¨ê³¼ì ìœ¼ë¡œ ì¦ê°€ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ë¹„ì •ë³´ì„± í† í°ì„ ì‹ë³„í•˜ì§€ ëª»í•˜ë©´ ê°€ì§€ì¹˜ê¸°ë¡œ ì¸í•œ íš¨ìœ¨ì„± í–¥ìƒì´ ì €í•´ë©ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ìš°ë¦¬ëŠ” ë‚´ë¹„ê²Œì´ì…˜ ì¸ì‹ ê°€ì§€ì¹˜ê¸°(NAP)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ëŠ” ë‚´ë¹„ê²Œì´ì…˜ íŠ¹ìœ ì˜ íŠ¹ì„±ì„ ì‚¬ìš©í•˜ì—¬ í† í°ì„ ì „ê²½ê³¼ ë°°ê²½ìœ¼ë¡œ ì‚¬ì „ í•„í„°ë§í•˜ì—¬ ê°€ì§€ì¹˜ê¸° ê³¼ì •ì„ ë‹¨ìˆœí™”í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì—ì´ì „íŠ¸ê°€ í•´ë‹¹ ë°©í–¥ìœ¼ë¡œ ì´ë™í•  ìˆ˜ ìˆëŠ”ì§€ ì—¬ë¶€ì— ë”°ë¼ ì´ë¯¸ì§€ ë·°ë¥¼ í•„í„°ë§í•©ë‹ˆë‹¤. ë˜í•œ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë‚´ë¹„ê²Œì´ì…˜ ê´€ë ¨ ì§€ì¹¨ì„ ì¶”ì¶œí•©ë‹ˆë‹¤. í•„í„°ë§ í›„, ìš°ë¦¬ëŠ” ì •ë³´ ì†ì‹¤ì„ ìµœì†Œí™”í•˜ê¸° ìœ„í•´ ë°°ê²½ í† í°ì— ê°€ì§€ì¹˜ê¸°ë¥¼ ì§‘ì¤‘í•©ë‹ˆë‹¤. ë‚´ë¹„ê²Œì´ì…˜ ê¸¸ì´ ì¦ê°€ë¥¼ í”¼í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ì¤‘ìš”ë„ê°€ ë‚®ì€ ë‚´ë¹„ê²Œì´ì…˜ ë…¸ë“œë¥¼ ì œê±°í•˜ì—¬ ì—­ì¶”ì ì„ ì–µì œí•©ë‹ˆë‹¤. í‘œì¤€ VLN ë²¤ì¹˜ë§ˆí¬ ì‹¤í—˜ì—ì„œ NAPëŠ” ì´ì „ ì—°êµ¬ë³´ë‹¤ í›¨ì”¬ ë›°ì–´ë‚œ ì„±ê³¼ë¥¼ ë³´ì—¬ì£¼ë©°, ì„±ê³µë¥ ì„ ë” ë†’ê²Œ ìœ ì§€í•˜ë©´ì„œ 50% ì´ìƒì˜ FLOPSë¥¼ ì ˆì•½í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ Vision-and-Language Navigation(VLN) ì‘ì—…ì—ì„œ íš¨ìœ¨ì„±ì„ ë†’ì´ê¸° ìœ„í•´ ì œì•ˆëœ Navigation-Aware Pruning(NAP) ë°©ë²•ë¡ ì„ ì†Œê°œí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ í† í° ê°€ì§€ì¹˜ê¸° ê¸°ë²•ì€ ì •ë³´ ì†ì‹¤ë¡œ ì¸í•´ ì˜¤íˆë ¤ ê³„ì‚° ë¹„ìš©ì„ ì¦ê°€ì‹œí‚¬ ìˆ˜ ìˆëŠ” ë¬¸ì œë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. NAPëŠ” ë‚´ë¹„ê²Œì´ì…˜ì— íŠ¹í™”ëœ íŠ¹ì§•ì„ í™œìš©í•˜ì—¬ í† í°ì„ ì „ê²½ê³¼ ë°°ê²½ìœ¼ë¡œ ì‚¬ì „ í•„í„°ë§í•˜ê³ , ë°°ê²½ í† í°ì— ì§‘ì¤‘í•˜ì—¬ ê°€ì§€ì¹˜ê¸°ë¥¼ ìˆ˜í–‰í•¨ìœ¼ë¡œì¨ ì •ë³´ ì†ì‹¤ì„ ìµœì†Œí™”í•©ë‹ˆë‹¤. ë˜í•œ, ì¤‘ìš”ë„ê°€ ë‚®ì€ ë‚´ë¹„ê²Œì´ì…˜ ë…¸ë“œë¥¼ ì œê±°í•˜ì—¬ ê²½ë¡œ ê¸¸ì´ ì¦ê°€ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, NAPëŠ” ê¸°ì¡´ ë°©ë²•ë³´ë‹¤ ë†’ì€ ì„±ê³µë¥ ì„ ìœ ì§€í•˜ë©´ì„œë„ 50% ì´ìƒì˜ FLOPSë¥¼ ì ˆê°í•˜ëŠ” ì„±ê³¼ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ëª¨ë¸ì€ Vision-and-Language Navigation (VLN) ì‘ì—…ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ì§€ë§Œ, ìì›ì´ ì œí•œëœ í™˜ê²½ì—ì„œëŠ” ì‹¤í–‰ ë¹„ìš©ì´ ë†’ìŠµë‹ˆë‹¤.
- 2. í† í° í”„ë£¨ë‹ì€ ëª¨ë¸ ì…ë ¥ í¬ê¸°ë¥¼ ì¤„ì—¬ íš¨ìœ¨ì„±ì„ ë†’ì´ëŠ” ë™ì‹œì— ì„±ëŠ¥ ì†ì‹¤ì„ ìµœì†Œí™”í•˜ëŠ” ë§¤ë ¥ì ì¸ ë°©ë²•ì´ì§€ë§Œ, ê¸°ì¡´ ì—°êµ¬ëŠ” VLN íŠ¹ìœ ì˜ ë¬¸ì œë¥¼ ê°„ê³¼í–ˆìŠµë‹ˆë‹¤.
- 3. Navigation-Aware Pruning (NAP)ì€ ë„¤ë¹„ê²Œì´ì…˜ íŠ¹ì„±ì„ í™œìš©í•˜ì—¬ í† í°ì„ ì „ê²½ê³¼ ë°°ê²½ìœ¼ë¡œ ì‚¬ì „ í•„í„°ë§í•˜ì—¬ í”„ë£¨ë‹ ê³¼ì •ì„ ë‹¨ìˆœí™”í•©ë‹ˆë‹¤.
- 4. NAPëŠ” ë°°ê²½ í† í°ì— í”„ë£¨ë‹ì„ ì§‘ì¤‘í•˜ì—¬ ì •ë³´ ì†ì‹¤ì„ ìµœì†Œí™”í•˜ê³ , ì¤‘ìš”ë„ê°€ ë‚®ì€ ë„¤ë¹„ê²Œì´ì…˜ ë…¸ë“œë¥¼ ì œê±°í•˜ì—¬ ê²½ë¡œ ê¸¸ì´ ì¦ê°€ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
- 5. ì‹¤í—˜ ê²°ê³¼, NAPëŠ” ê¸°ì¡´ ì—°êµ¬ë³´ë‹¤ ë†’ì€ ì„±ê³µë¥ ì„ ìœ ì§€í•˜ë©´ì„œë„ 50% ì´ìƒì˜ FLOPSë¥¼ ì ˆì•½í•˜ëŠ” ë° ì„±ê³µí–ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-23 08:49:20*