# Walk and Read Less: Improving the Efficiency of Vision-and-Language Navigation via Tuning-Free Multimodal Token Pruning

**Korean Title:** ê±·ê¸°ì™€ ì½ê¸° ì¤„ì´ê¸°: ì¡°ì •ì´ í•„ìš” ì—†ëŠ” ë‹¤ì¤‘ ëª¨ë‹¬ í† í° ê°€ì§€ì¹˜ê¸°ë¥¼ í†µí•œ ì‹œê°-ì–¸ì–´ ë‚´ë¹„ê²Œì´ì…˜ì˜ íš¨ìœ¨ì„± í–¥ìƒ

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Navigation Specific Traits

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-17/NIRVANA_ Structured pruning reimagined for large language models compression_20250917|NIRVANA Structured pruning reimagined for large language models compression]] (85.8% similar)
- [[2025-09-18/Embodied Navigation Foundation Model_20250918|Embodied Navigation Foundation Model]] (83.4% similar)
- [[2025-09-19/T-araVLN_ Translator for Agricultural Robotic Agents on Vision-and-Language Navigation_20250919|T-araVLN Translator for Agricultural Robotic Agents on Vision-and-Language Navigation]] (82.4% similar)
- [[2025-09-18/FSR-VLN_ Fast and Slow Reasoning for Vision-Language Navigation with Hierarchical Multi-modal Scene Graph_20250918|FSR-VLN Fast and Slow Reasoning for Vision-Language Navigation with Hierarchical Multi-modal Scene Graph]] (82.0% similar)
- [[2025-09-19/Handle Object Navigation as Weighted Traveling Repairman Problem_20250919|Handle Object Navigation as Weighted Traveling Repairman Problem]] (80.5% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15250v1 Announce Type: cross 
Abstract: Large models achieve strong performance on Vision-and-Language Navigation (VLN) tasks, but are costly to run in resource-limited environments. Token pruning offers appealing tradeoffs for efficiency with minimal performance loss by reducing model input size, but prior work overlooks VLN-specific challenges. For example, information loss from pruning can effectively increase computational cost due to longer walks. Thus, the inability to identify uninformative tokens undermines the supposed efficiency gains from pruning. To address this, we propose Navigation-Aware Pruning (NAP), which uses navigation-specific traits to simplify the pruning process by pre-filtering tokens into foreground and background. For example, image views are filtered based on whether the agent can navigate in that direction. We also extract navigation-relevant instructions using a Large Language Model. After filtering, we focus pruning on background tokens, minimizing information loss. To further help avoid increases in navigation length, we discourage backtracking by removing low-importance navigation nodes. Experiments on standard VLN benchmarks show NAP significantly outperforms prior work, preserving higher success rates while saving more than 50% FLOPS.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15250v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ëŒ€í˜• ëª¨ë¸ì€ ì‹œê° ë° ì–¸ì–´ ë‚´ë¹„ê²Œì´ì…˜(VLN) ê³¼ì œì—ì„œ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ì§€ë§Œ, ìì›ì´ ì œí•œëœ í™˜ê²½ì—ì„œëŠ” ì‹¤í–‰ ë¹„ìš©ì´ ë§ì´ ë“­ë‹ˆë‹¤. í† í° ê°€ì§€ì¹˜ê¸°ëŠ” ëª¨ë¸ ì…ë ¥ í¬ê¸°ë¥¼ ì¤„ì—¬ ì„±ëŠ¥ ì†ì‹¤ì„ ìµœì†Œí™”í•˜ë©´ì„œ íš¨ìœ¨ì„±ì„ ìœ„í•œ ë§¤ë ¥ì ì¸ ì ˆì¶©ì•ˆì„ ì œê³µí•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ì „ ì—°êµ¬ëŠ” VLNì— íŠ¹í™”ëœ ë„ì „ ê³¼ì œë¥¼ ê°„ê³¼í–ˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê°€ì§€ì¹˜ê¸°ë¡œ ì¸í•œ ì •ë³´ ì†ì‹¤ì€ ë” ê¸´ ê²½ë¡œë¡œ ì¸í•´ ê³„ì‚° ë¹„ìš©ì„ íš¨ê³¼ì ìœ¼ë¡œ ì¦ê°€ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ë¹„ì •ë³´ì„± í† í°ì„ ì‹ë³„í•˜ì§€ ëª»í•˜ë©´ ê°€ì§€ì¹˜ê¸°ë¡œ ì¸í•œ íš¨ìœ¨ì„± í–¥ìƒì´ ì €í•´ë©ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ë‚´ë¹„ê²Œì´ì…˜ ì¸ì‹ ê°€ì§€ì¹˜ê¸°(NAP)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ëŠ” ë‚´ë¹„ê²Œì´ì…˜ íŠ¹í™” íŠ¹ì„±ì„ ì‚¬ìš©í•˜ì—¬ í† í°ì„ ì „ê²½ê³¼ ë°°ê²½ìœ¼ë¡œ ì‚¬ì „ í•„í„°ë§í•˜ì—¬ ê°€ì§€ì¹˜ê¸° ê³¼ì •ì„ ë‹¨ìˆœí™”í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì—ì´ì „íŠ¸ê°€ í•´ë‹¹ ë°©í–¥ìœ¼ë¡œ ì´ë™í•  ìˆ˜ ìˆëŠ”ì§€ ì—¬ë¶€ì— ë”°ë¼ ì´ë¯¸ì§€ ë·°ê°€ í•„í„°ë§ë©ë‹ˆë‹¤. ë˜í•œ, ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë‚´ë¹„ê²Œì´ì…˜ ê´€ë ¨ ì§€ì‹œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. í•„í„°ë§ í›„, ìš°ë¦¬ëŠ” ì •ë³´ ì†ì‹¤ì„ ìµœì†Œí™”í•˜ê¸° ìœ„í•´ ë°°ê²½ í† í°ì— ê°€ì§€ì¹˜ê¸°ë¥¼ ì§‘ì¤‘í•©ë‹ˆë‹¤. ë‚´ë¹„ê²Œì´ì…˜ ê¸¸ì´ ì¦ê°€ë¥¼ í”¼í•˜ê¸° ìœ„í•´, ì¤‘ìš”ë„ê°€ ë‚®ì€ ë‚´ë¹„ê²Œì´ì…˜ ë…¸ë“œë¥¼ ì œê±°í•˜ì—¬ í›„í‡´ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤. í‘œì¤€ VLN ë²¤ì¹˜ë§ˆí¬ì— ëŒ€í•œ ì‹¤í—˜ ê²°ê³¼, NAPëŠ” ì´ì „ ì—°êµ¬ë³´ë‹¤ ìœ ì˜ë¯¸í•˜ê²Œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì´ë©°, ì„±ê³µë¥ ì„ ë†’ê²Œ ìœ ì§€í•˜ë©´ì„œë„ 50% ì´ìƒì˜ FLOPSë¥¼ ì ˆì•½í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ Vision-and-Language Navigation(VLN) ì‘ì—…ì—ì„œ ëŒ€ê·œëª¨ ëª¨ë¸ì˜ íš¨ìœ¨ì„±ì„ ë†’ì´ê¸° ìœ„í•´ ì œì•ˆëœ Navigation-Aware Pruning(NAP) ë°©ë²•ë¡ ì„ ì†Œê°œí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ í† í° í”„ë£¨ë‹ ê¸°ë²•ì€ ì •ë³´ ì†ì‹¤ë¡œ ì¸í•´ ì˜¤íˆë ¤ ê³„ì‚° ë¹„ìš©ì„ ì¦ê°€ì‹œí‚¬ ìˆ˜ ìˆëŠ” ë¬¸ì œë¥¼ ê°€ì§€ê³  ìˆì—ˆìŠµë‹ˆë‹¤. NAPëŠ” ë‚´ë¹„ê²Œì´ì…˜ì— íŠ¹í™”ëœ íŠ¹ì„±ì„ í™œìš©í•˜ì—¬ í† í°ì„ ì „ê²½ê³¼ ë°°ê²½ìœ¼ë¡œ ì‚¬ì „ í•„í„°ë§í•˜ê³ , ë°°ê²½ í† í°ì— ì§‘ì¤‘í•˜ì—¬ ì •ë³´ ì†ì‹¤ì„ ìµœì†Œí™”í•©ë‹ˆë‹¤. ë˜í•œ, ì¤‘ìš”ë„ê°€ ë‚®ì€ ë‚´ë¹„ê²Œì´ì…˜ ë…¸ë“œë¥¼ ì œê±°í•˜ì—¬ ê²½ë¡œ ê¸¸ì´ ì¦ê°€ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, NAPëŠ” ê¸°ì¡´ ë°©ë²•ë³´ë‹¤ ë†’ì€ ì„±ê³µë¥ ì„ ìœ ì§€í•˜ë©´ì„œë„ 50% ì´ìƒì˜ FLOPSë¥¼ ì ˆì•½í•˜ëŠ” ì„±ê³¼ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ëª¨ë¸ì€ Vision-and-Language Navigation (VLN) ì‘ì—…ì—ì„œ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì´ì§€ë§Œ, ìì›ì´ ì œí•œëœ í™˜ê²½ì—ì„œëŠ” ì‹¤í–‰ ë¹„ìš©ì´ ë†’ìŠµë‹ˆë‹¤.

- 2. í† í° í”„ë£¨ë‹ì€ ëª¨ë¸ ì…ë ¥ í¬ê¸°ë¥¼ ì¤„ì—¬ íš¨ìœ¨ì„±ì„ ë†’ì´ëŠ” ë™ì‹œì— ì„±ëŠ¥ ì†ì‹¤ì„ ìµœì†Œí™”í•˜ëŠ” ë§¤ë ¥ì ì¸ ë°©ë²•ì…ë‹ˆë‹¤.

- 3. ê¸°ì¡´ ì—°êµ¬ëŠ” VLNì˜ íŠ¹ìˆ˜í•œ ë„ì „ ê³¼ì œë¥¼ ê°„ê³¼í–ˆìœ¼ë©°, ì •ë³´ ì†ì‹¤ì€ ì˜¤íˆë ¤ ê³„ì‚° ë¹„ìš©ì„ ì¦ê°€ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- 4. Navigation-Aware Pruning (NAP)ì€ ë‚´ë¹„ê²Œì´ì…˜ íŠ¹ì„±ì„ í™œìš©í•˜ì—¬ í† í°ì„ ì „ê²½ê³¼ ë°°ê²½ìœ¼ë¡œ ì‚¬ì „ í•„í„°ë§í•˜ì—¬ í”„ë£¨ë‹ ê³¼ì •ì„ ë‹¨ìˆœí™”í•©ë‹ˆë‹¤.

- 5. NAPëŠ” í‘œì¤€ VLN ë²¤ì¹˜ë§ˆí¬ ì‹¤í—˜ì—ì„œ ì´ì „ ì—°êµ¬ë³´ë‹¤ ë†’ì€ ì„±ê³µë¥ ì„ ìœ ì§€í•˜ë©´ì„œë„ 50% ì´ìƒì˜ FLOPSë¥¼ ì ˆì•½í•©ë‹ˆë‹¤.

---

*Generated on 2025-09-22 13:49:35*