---
keywords:
  - Vision-Language Model
  - Cache of Thought
  - Master-Apprentice Framework
  - Multimodal Learning
  - Few-Shot Learning
category: cs.LG
publish_date: 2025-09-22
arxiv_id: 2502.20587
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:04:59.570545",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Vision-Language Model",
    "Cache of Thought",
    "Master-Apprentice Framework",
    "Multimodal Learning",
    "Few-Shot Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Vision-Language Model": 0.91,
    "Cache of Thought": 0.89,
    "Master-Apprentice Framework": 0.85,
    "Multimodal Learning": 0.83,
    "Few-Shot Learning": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Vision Language Models",
        "canonical": "Vision-Language Model",
        "aliases": [
          "VLMs"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-Language Models are central to the paper's framework and connect to the broader trend of multimodal AI research.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.82,
        "link_intent_score": 0.91
      },
      {
        "surface": "Cache of Thought",
        "canonical": "Cache of Thought",
        "aliases": [
          "CoT"
        ],
        "category": "unique_technical",
        "rationale": "Cache of Thought is a unique framework introduced in the paper, offering a novel approach to collaborative inference.",
        "novelty_score": 0.92,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.89
      },
      {
        "surface": "Master Apprentice Framework",
        "canonical": "Master-Apprentice Framework",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "The Master-Apprentice Framework is a novel concept in the paper, facilitating the interaction between large and small VLMs.",
        "novelty_score": 0.87,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.85
      },
      {
        "surface": "Multimodal Retrieval",
        "canonical": "Multimodal Learning",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Multimodal Retrieval is a key component of the proposed framework, aligning with the trending concept of Multimodal Learning.",
        "novelty_score": 0.55,
        "connectivity_score": 0.78,
        "specificity_score": 0.76,
        "link_intent_score": 0.83
      },
      {
        "surface": "In-Context Learning",
        "canonical": "Few-Shot Learning",
        "aliases": [
          "Contextual Learning"
        ],
        "category": "specific_connectable",
        "rationale": "In-Context Learning is related to Few-Shot Learning, enhancing the performance of smaller models in the framework.",
        "novelty_score": 0.6,
        "connectivity_score": 0.75,
        "specificity_score": 0.79,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "response quality",
      "query results",
      "general reasoning benchmarks"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Vision Language Models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.82,
        "link_intent": 0.91
      }
    },
    {
      "candidate_surface": "Cache of Thought",
      "resolved_canonical": "Cache of Thought",
      "decision": "linked",
      "scores": {
        "novelty": 0.92,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.89
      }
    },
    {
      "candidate_surface": "Master Apprentice Framework",
      "resolved_canonical": "Master-Apprentice Framework",
      "decision": "linked",
      "scores": {
        "novelty": 0.87,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Multimodal Retrieval",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.78,
        "specificity": 0.76,
        "link_intent": 0.83
      }
    },
    {
      "candidate_surface": "In-Context Learning",
      "resolved_canonical": "Few-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.75,
        "specificity": 0.79,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# Cache-of-Thought: Master-Apprentice Framework for Cost-Effective Vision Language Model Reasoning

**Korean Title:** "사고의 캐시: 비용 효율적인 비전 언어 모델 추론을 위한 마스터-견습생 프레임워크"

## 📋 메타데이터

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2502.20587.pdf)
**Category**: cs.LG
**Published**: 2025-09-22
**ArXiv ID**: [2502.20587](https://arxiv.org/abs/2502.20587)

## 🔗 유사한 논문
- [[2025-09-18/Uni-cot_ Towards Unified Chain-of-Thought Reasoning Across Text and Vision_20250918|Uni-cot: Towards Unified Chain-of-Thought Reasoning Across Text and Vision]] (85.6% similar)
- [[2025-09-19/ThinkAct_ Vision-Language-Action Reasoning via Reinforced Visual Latent Planning_20250919|ThinkAct: Vision-Language-Action Reasoning via Reinforced Visual Latent Planning]] (84.3% similar)
- [[2025-09-18/Early Stopping Chain-of-thoughts in Large Language Models_20250918|Early Stopping Chain-of-thoughts in Large Language Models]] (84.1% similar)
- [[2025-09-22/ORCA_ Agentic Reasoning For Hallucination and Adversarial Robustness in Vision-Language Models_20250922|ORCA: Agentic Reasoning For Hallucination and Adversarial Robustness in Vision-Language Models]] (84.1% similar)
- [[2025-09-19/ASCoT_ An Adaptive Self-Correction Chain-of-Thought Method for Late-Stage Fragility in LLMs_20250919|ASCoT: An Adaptive Self-Correction Chain-of-Thought Method for Late-Stage Fragility in LLMs]] (83.9% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]], [[keywords/Few-Shot Learning|Few-Shot Learning]]
**⚡ Unique Technical**: [[keywords/Cache of Thought|Cache of Thought]], [[keywords/Master-Apprentice Framework|Master-Apprentice Framework]]
**🚀 Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2502.20587v2 Announce Type: replace 
Abstract: Vision Language Models (VLMs) have achieved remarkable success in a wide range of vision applications of increasing complexity and scales, yet choosing the right VLM model size involves a trade-off between response quality and cost. While smaller VLMs are cheaper to run, they typically produce responses only marginally better than random guessing on benchmarks such as MMMU.
  In this paper, we propose Cache of Thought (CoT), a master apprentice framework for collaborative inference between large and small VLMs. CoT manages high quality query results from large VLMs (master) in a cache, which are then selected via a novel multi modal retrieval and in-context learning to aid the performance of small VLMs (apprentice). We extensively evaluate CoT on various widely recognized and challenging general reasoning benchmarks, and show that CoT increases overall reasoning performance by up to 7.7% under the same budget, and specifically boosts the performance of apprentice VLMs by up to 36.6%. Our code is available at https://github.com/UIUC-MONET/Cache-of-Thoughts

## 🔍 Abstract (한글 번역)

arXiv:2502.20587v2 발표 유형: 교체  
초록: 비전 언어 모델(Vision Language Models, VLMs)은 점점 더 복잡하고 규모가 커지는 다양한 비전 응용 분야에서 놀라운 성공을 거두었지만, 적절한 VLM 모델 크기를 선택하는 것은 응답 품질과 비용 간의 균형을 필요로 합니다. 작은 VLM은 운영 비용이 저렴하지만, 일반적으로 MMMU와 같은 벤치마크에서 무작위 추측보다 약간 더 나은 응답을 생성합니다.  
이 논문에서는 대형 및 소형 VLM 간의 협력적 추론을 위한 마스터 견습생 프레임워크인 Cache of Thought (CoT)를 제안합니다. CoT는 대형 VLM(마스터)의 고품질 쿼리 결과를 캐시에 저장하고, 이를 통해 소형 VLM(견습생)의 성능을 향상시키기 위해 새로운 다중 모달 검색 및 맥락 내 학습을 통해 선택합니다. 우리는 CoT를 다양한 널리 인정받는 도전적인 일반 추론 벤치마크에서 광범위하게 평가하였으며, 동일한 예산 하에서 전체 추론 성능을 최대 7.7% 향상시키고, 특히 견습생 VLM의 성능을 최대 36.6% 향상시킴을 보여줍니다. 우리의 코드는 https://github.com/UIUC-MONET/Cache-of-Thoughts에서 확인할 수 있습니다.

## 📝 요약

이 논문에서는 대형 및 소형 비전 언어 모델(VLM) 간의 협력 추론을 위한 Cache of Thought(CoT)라는 프레임워크를 제안합니다. CoT는 대형 VLM(마스터)의 고품질 쿼리 결과를 캐시에 저장하고, 이를 소형 VLM(견습생)의 성능 향상을 위해 다중 모달 검색 및 컨텍스트 학습을 통해 선택합니다. 다양한 일반 추론 벤치마크에서 CoT를 평가한 결과, 동일한 예산 하에 전체 추론 성능이 최대 7.7% 향상되었으며, 특히 소형 VLM의 성능이 최대 36.6% 증가했습니다.

## 🎯 주요 포인트

- 1. Vision Language Models (VLMs)는 다양한 비전 애플리케이션에서 뛰어난 성과를 보였으나, 모델 크기 선택 시 응답 품질과 비용 사이의 균형이 필요합니다.
- 2. Cache of Thought (CoT)는 대형 VLM(마스터)과 소형 VLM(견습생) 간의 협력 추론을 위한 프레임워크로, 대형 VLM의 고품질 쿼리 결과를 캐시에 저장하고 이를 통해 소형 VLM의 성능을 향상시킵니다.
- 3. CoT는 다양한 일반 추론 벤치마크에서 최대 7.7%의 성능 향상을 보여주며, 특히 소형 VLM의 성능을 최대 36.6%까지 향상시킵니다.
- 4. CoT는 새로운 다중 모달 검색 및 컨텍스트 학습을 통해 소형 VLM의 성능을 지원합니다.
- 5. CoT의 코드는 https://github.com/UIUC-MONET/Cache-of-Thoughts에서 제공됩니다.


---

*Generated on 2025-09-23 11:04:59*