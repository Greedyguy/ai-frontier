---
keywords:
  - Reinforcement Learning
  - Multimodal Learning
  - Personalized Image Captioning
  - Supervised Fine-Tuning
category: cs.CV
publish_date: 2025-09-22
arxiv_id: 2506.18369
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T12:37:00.223257",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Reinforcement Learning",
    "Multimodal Learning",
    "Personalized Image Captioning",
    "Supervised Fine-Tuning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Reinforcement Learning": 0.8,
    "Multimodal Learning": 0.82,
    "Personalized Image Captioning": 0.78,
    "Supervised Fine-Tuning": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Reinforcement Learning",
        "canonical": "Reinforcement Learning",
        "aliases": [
          "RL"
        ],
        "category": "broad_technical",
        "rationale": "Reinforcement Learning is central to the proposed post-training framework, enhancing personalization capabilities.",
        "novelty_score": 0.55,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Multi-Modal Large Language Models",
        "canonical": "Multimodal Learning",
        "aliases": [
          "MLLMs"
        ],
        "category": "specific_connectable",
        "rationale": "Multimodal Learning is a key aspect of the study, focusing on integrating multiple data types for language models.",
        "novelty_score": 0.65,
        "connectivity_score": 0.88,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "Personalized Image Captioning",
        "canonical": "Personalized Image Captioning",
        "aliases": [
          "Custom Image Descriptions"
        ],
        "category": "unique_technical",
        "rationale": "This is the unique application focus of the paper, highlighting the personalization aspect of image captioning.",
        "novelty_score": 0.7,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Supervised Fine-Tuning",
        "canonical": "Supervised Fine-Tuning",
        "aliases": [
          "SFT"
        ],
        "category": "specific_connectable",
        "rationale": "Supervised Fine-Tuning is a common method referenced as a baseline, important for understanding the paper's context.",
        "novelty_score": 0.5,
        "connectivity_score": 0.8,
        "specificity_score": 0.65,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "method",
      "approach",
      "task"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Reinforcement Learning",
      "resolved_canonical": "Reinforcement Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Multi-Modal Large Language Models",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.88,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Personalized Image Captioning",
      "resolved_canonical": "Personalized Image Captioning",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Supervised Fine-Tuning",
      "resolved_canonical": "Supervised Fine-Tuning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.8,
        "specificity": 0.65,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# RePIC: Reinforced Post-Training for Personalizing Multi-Modal Language Models

**Korean Title:** RePIC: ë‹¤ì¤‘ ëª¨ë‹¬ ì–¸ì–´ ëª¨ë¸ ê°œì¸í™”ë¥¼ ìœ„í•œ ê°•í™”ëœ ì‚¬í›„ í›ˆë ¨

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2506.18369.pdf)
**Category**: cs.CV
**Published**: 2025-09-22
**ArXiv ID**: [2506.18369](https://arxiv.org/abs/2506.18369)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Perception-R1_ Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward_20250922|Perception-R1: Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward]] (86.6% similar)
- [[2025-09-22/Pointing to a Llama and Call it a Camel_ On the Sycophancy of Multimodal Large Language Models_20250922|Pointing to a Llama and Call it a Camel: On the Sycophancy of Multimodal Large Language Models]] (85.6% similar)
- [[2025-09-19/Modular Machine Learning_ An Indispensable Path towards New-Generation Large Language Models_20250919|Modular Machine Learning: An Indispensable Path towards New-Generation Large Language Models]] (84.5% similar)
- [[2025-09-19/Decoupled Proxy Alignment_ Mitigating Language Prior Conflict for Multimodal Alignment in MLLM_20250919|Decoupled Proxy Alignment: Mitigating Language Prior Conflict for Multimodal Alignment in MLLM]] (84.2% similar)
- [[2025-09-19/Generalizable Geometric Image Caption Synthesis_20250919|Generalizable Geometric Image Caption Synthesis]] (84.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Reinforcement Learning|Reinforcement Learning]]
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]], [[keywords/Supervised Fine-Tuning|Supervised Fine-Tuning]]
**âš¡ Unique Technical**: [[keywords/Personalized Image Captioning|Personalized Image Captioning]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2506.18369v2 Announce Type: replace 
Abstract: Recent multi-modal large language models (MLLMs) often struggle to generate personalized image captions, even when trained on high-quality captions. In this work, we observe that such limitations persist in existing post-training-based MLLM personalization methods. Specifically, despite being post-tuned with large-scale caption data through supervised fine-tuning (SFT), these models frequently fail to produce faithful descriptions in real-world scenarios, such as multi-concept image captioning. However, acquiring large-scale, high-quality captions for such complex settings is both costly and difficult. To address the data-centric nature of SFT, we propose a reinforcement learning (RL)-based post-training framework. To the best of our knowledge, this is the first RL-based approach to post-train MLLMs for personalized image captioning. Our method significantly enhances both visual recognition and personalized generation capabilities of MLLMs, and consistently outperforms existing SFT-based baselines, especially in the challenging multi-concept image captioning task.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2506.18369v2 ë°œí‘œ ìœ í˜•: êµì²´  
ì´ˆë¡: ìµœê·¼ì˜ ë‹¤ì¤‘ ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(MLLMs)ì€ ê³ í’ˆì§ˆ ìº¡ì…˜ìœ¼ë¡œ í•™ìŠµë˜ì—ˆìŒì—ë„ ë¶ˆêµ¬í•˜ê³  ê°œì¸í™”ëœ ì´ë¯¸ì§€ ìº¡ì…˜ì„ ìƒì„±í•˜ëŠ” ë° ì¢…ì¢… ì–´ë ¤ì›€ì„ ê²ªìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” ì´ëŸ¬í•œ í•œê³„ê°€ ê¸°ì¡´ì˜ ì‚¬í›„ í•™ìŠµ ê¸°ë°˜ MLLM ê°œì¸í™” ë°©ë²•ì—ì„œë„ ì§€ì†ëœë‹¤ëŠ” ê²ƒì„ ê´€ì°°í–ˆìŠµë‹ˆë‹¤. êµ¬ì²´ì ìœ¼ë¡œ, ëŒ€ê·œëª¨ ìº¡ì…˜ ë°ì´í„°ë¥¼ í†µí•œ ì§€ë„ í•™ìŠµ(SFT)ìœ¼ë¡œ ì‚¬í›„ íŠœë‹ë˜ì—ˆìŒì—ë„ ë¶ˆêµ¬í•˜ê³ , ì´ëŸ¬í•œ ëª¨ë¸ë“¤ì€ ì‹¤ì œ í™˜ê²½ì—ì„œ, ì˜ˆë¥¼ ë“¤ì–´ ë‹¤ì¤‘ ê°œë… ì´ë¯¸ì§€ ìº¡ì…˜ ì‘ì—…ì—ì„œ ìì£¼ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì„¤ëª…ì„ ìƒì„±í•˜ëŠ” ë° ì‹¤íŒ¨í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ëŸ¬í•œ ë³µì¡í•œ ì„¤ì •ì— ëŒ€í•œ ëŒ€ê·œëª¨ ê³ í’ˆì§ˆ ìº¡ì…˜ì„ í™•ë³´í•˜ëŠ” ê²ƒì€ ë¹„ìš©ì´ ë§ì´ ë“¤ê³  ì–´ë µìŠµë‹ˆë‹¤. SFTì˜ ë°ì´í„° ì¤‘ì‹¬ì  íŠ¹ì„±ì„ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ê°•í™” í•™ìŠµ(RL) ê¸°ë°˜ì˜ ì‚¬í›„ í•™ìŠµ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ìš°ë¦¬ê°€ ì•„ëŠ” í•œ, ì´ëŠ” ê°œì¸í™”ëœ ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„±ì„ ìœ„í•´ MLLMsì„ ì‚¬í›„ í•™ìŠµí•˜ëŠ” ìµœì´ˆì˜ RL ê¸°ë°˜ ì ‘ê·¼ë²•ì…ë‹ˆë‹¤. ìš°ë¦¬ì˜ ë°©ë²•ì€ MLLMsì˜ ì‹œê°ì  ì¸ì‹ê³¼ ê°œì¸í™”ëœ ìƒì„± ëŠ¥ë ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚¤ë©°, íŠ¹íˆ ë„ì „ì ì¸ ë‹¤ì¤‘ ê°œë… ì´ë¯¸ì§€ ìº¡ì…˜ ì‘ì—…ì—ì„œ ê¸°ì¡´ì˜ SFT ê¸°ë°˜ ê¸°ì¤€ì„ ì¼ê´€ë˜ê²Œ ëŠ¥ê°€í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ìµœê·¼ ë‹¤ì¤‘ ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(MLLM)ì€ ê°œì¸í™”ëœ ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„±ì— ì–´ë ¤ì›€ì„ ê²ªê³  ìˆìŠµë‹ˆë‹¤. ê¸°ì¡´ì˜ ì‚¬í›„ í›ˆë ¨ ê¸°ë°˜ ê°œì¸í™” ë°©ë²•ë„ ì´ëŸ¬í•œ í•œê³„ë¥¼ ê·¹ë³µí•˜ì§€ ëª»í•˜ê³  ìˆìŠµë‹ˆë‹¤. ëŒ€ê·œëª¨ ìº¡ì…˜ ë°ì´í„°ë¥¼ í™œìš©í•œ ì§€ë„ í•™ìŠµ(SFT) í›„ì—ë„ ì‹¤ì œ í™˜ê²½ì—ì„œ ì •í™•í•œ ì„¤ëª…ì„ ìƒì„±í•˜ì§€ ëª»í•˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. ë³µì¡í•œ ì„¤ì •ì— ëŒ€í•œ ê³ í’ˆì§ˆ ìº¡ì…˜ì„ í™•ë³´í•˜ëŠ” ê²ƒì€ ë¹„ìš©ì´ ë§ì´ ë“¤ê³  ì–´ë µê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ê°•í™” í•™ìŠµ(RL)ì„ í™œìš©í•œ ì‚¬í›„ í›ˆë ¨ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ëŠ” ê°œì¸í™”ëœ ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„±ì„ ìœ„í•´ MLLMì„ ì‚¬í›„ í›ˆë ¨í•˜ëŠ” ìµœì´ˆì˜ RL ê¸°ë°˜ ì ‘ê·¼ë²•ì…ë‹ˆë‹¤. ì œì•ˆëœ ë°©ë²•ì€ MLLMì˜ ì‹œê°ì  ì¸ì‹ ë° ê°œì¸í™”ëœ ìƒì„± ëŠ¥ë ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚¤ë©°, íŠ¹íˆ ë‹¤ì¤‘ ê°œë… ì´ë¯¸ì§€ ìº¡ì…˜ ì‘ì—…ì—ì„œ ê¸°ì¡´ SFT ê¸°ë°˜ ë°©ë²•ë“¤ì„ ëŠ¥ê°€í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ìµœê·¼ ë‹¤ì¤‘ ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(MLLMs)ì€ ê³ í’ˆì§ˆ ìº¡ì…˜ìœ¼ë¡œ í›ˆë ¨ë˜ì—ˆìŒì—ë„ ë¶ˆêµ¬í•˜ê³  ê°œì¸í™”ëœ ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„±ì— ì–´ë ¤ì›€ì„ ê²ªê³  ìˆìŠµë‹ˆë‹¤.
- 2. ê¸°ì¡´ì˜ ì‚¬í›„ í›ˆë ¨ ê¸°ë°˜ MLLM ê°œì¸í™” ë°©ë²•ì—ì„œë„ ì´ëŸ¬í•œ í•œê³„ê°€ ì§€ì†ë˜ë©°, ëŒ€ê·œëª¨ ìº¡ì…˜ ë°ì´í„°ë¡œ ê°ë…ëœ ë¯¸ì„¸ ì¡°ì •ì„ ê±°ì³ë„ ì‹¤ì œ ìƒí™©ì—ì„œ ì¶©ì‹¤í•œ ì„¤ëª…ì„ ìƒì„±í•˜ì§€ ëª»í•˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.
- 3. ë³µì¡í•œ ì„¤ì •ì— ëŒ€í•œ ëŒ€ê·œëª¨ ê³ í’ˆì§ˆ ìº¡ì…˜ì„ íšë“í•˜ëŠ” ê²ƒì€ ë¹„ìš©ì´ ë§ì´ ë“¤ê³  ì–´ë µìŠµë‹ˆë‹¤.
- 4. ë°ì´í„° ì¤‘ì‹¬ì˜ SFT ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ê°•í™” í•™ìŠµ(RL) ê¸°ë°˜ì˜ ì‚¬í›„ í›ˆë ¨ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.
- 5. ì œì•ˆëœ ë°©ë²•ì€ ì‹œê°ì  ì¸ì‹ê³¼ ê°œì¸í™”ëœ ìƒì„± ëŠ¥ë ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚¤ë©°, íŠ¹íˆ ë‹¤ì¤‘ ê°œë… ì´ë¯¸ì§€ ìº¡ì…˜ ì‘ì—…ì—ì„œ ê¸°ì¡´ì˜ SFT ê¸°ë°˜ ê¸°ì¤€ì„ ê¾¸ì¤€íˆ ëŠ¥ê°€í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-23 12:37:00*