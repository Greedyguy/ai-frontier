---
keywords:
  - Deep Learning
  - Wav2Vec2
  - Gated Recurrent Unit
  - Mel-Frequency Cepstral Coefficients
  - Exertion-Level Classification
category: cs.LG
publish_date: 2025-09-22
arxiv_id: 2509.15473
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T10:49:07.624219",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Deep Learning",
    "Wav2Vec2",
    "Gated Recurrent Unit",
    "Mel-Frequency Cepstral Coefficients",
    "Exertion-Level Classification"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Deep Learning": 0.85,
    "Wav2Vec2": 0.8,
    "Gated Recurrent Unit": 0.82,
    "Mel-Frequency Cepstral Coefficients": 0.78,
    "Exertion-Level Classification": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Deep Learning",
        "canonical": "Deep Learning",
        "aliases": [],
        "category": "broad_technical",
        "rationale": "Deep Learning is a fundamental technique used in the study, linking it to a wide array of related research.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Wav2Vec2",
        "canonical": "Wav2Vec2",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Wav2Vec2 is a specific model used for feature extraction in the study, offering a unique connection to self-supervised learning.",
        "novelty_score": 0.75,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "GRU",
        "canonical": "Gated Recurrent Unit",
        "aliases": [
          "GRU"
        ],
        "category": "specific_connectable",
        "rationale": "GRU is a specific neural network architecture used in the study, relevant for linking to other temporal sequence modeling research.",
        "novelty_score": 0.5,
        "connectivity_score": 0.78,
        "specificity_score": 0.8,
        "link_intent_score": 0.82
      },
      {
        "surface": "MFCC",
        "canonical": "Mel-Frequency Cepstral Coefficients",
        "aliases": [
          "MFCC"
        ],
        "category": "specific_connectable",
        "rationale": "MFCC is a widely used feature in speech processing, connecting this study to broader audio analysis research.",
        "novelty_score": 0.45,
        "connectivity_score": 0.85,
        "specificity_score": 0.75,
        "link_intent_score": 0.78
      },
      {
        "surface": "Exertion-Level Classification",
        "canonical": "Exertion-Level Classification",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This is a unique application of classification in the study, offering a novel link to physiological analysis.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.88,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "post-exercise",
      "semantic pauses",
      "breathing pauses",
      "combined pauses",
      "audio and respiration signals"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Deep Learning",
      "resolved_canonical": "Deep Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Wav2Vec2",
      "resolved_canonical": "Wav2Vec2",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "GRU",
      "resolved_canonical": "Gated Recurrent Unit",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.78,
        "specificity": 0.8,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "MFCC",
      "resolved_canonical": "Mel-Frequency Cepstral Coefficients",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.85,
        "specificity": 0.75,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Exertion-Level Classification",
      "resolved_canonical": "Exertion-Level Classification",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.88,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Breathing and Semantic Pause Detection and Exertion-Level Classification in Post-Exercise Speech

**Korean Title:** ìš´ë™ í›„ ë°œí™”ì—ì„œ í˜¸í¡ ë° ì˜ë¯¸ì  íœ´ì§€ íƒì§€ì™€ ìš´ë™ ê°•ë„ ë¶„ë¥˜

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15473.pdf)
**Category**: cs.LG
**Published**: 2025-09-22
**ArXiv ID**: [2509.15473](https://arxiv.org/abs/2509.15473)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/Multimodal signal fusion for stress detection using deep neural networks_ a novel approach for converting 1D signals to unified 2D images_20250918|Multimodal signal fusion for stress detection using deep neural networks: a novel approach for converting 1D signals to unified 2D images]] (78.9% similar)
- [[2025-09-18/Estimating Respiratory Effort from Nocturnal Breathing Sounds for Obstructive Sleep Apnoea Screening_20250918|Estimating Respiratory Effort from Nocturnal Breathing Sounds for Obstructive Sleep Apnoea Screening]] (78.2% similar)
- [[2025-09-22/mucAI at BAREC Shared Task 2025_ Towards Uncertainty Aware Arabic Readability Assessment_20250922|mucAI at BAREC Shared Task 2025: Towards Uncertainty Aware Arabic Readability Assessment]] (77.8% similar)
- [[2025-09-17/Personalization on a Budget_ Minimally-Labeled Continual Learning for Resource-Efficient Seizure Detection_20250917|Personalization on a Budget: Minimally-Labeled Continual Learning for Resource-Efficient Seizure Detection]] (77.2% similar)
- [[2025-09-18/HD3C_ Efficient Medical Data Classification for Embedded Devices_20250918|HD3C: Efficient Medical Data Classification for Embedded Devices]] (77.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Deep Learning|Deep Learning]]
**ğŸ”— Specific Connectable**: [[keywords/Gated Recurrent Unit|Gated Recurrent Unit]], [[keywords/Mel-Frequency Cepstral Coefficients|Mel-Frequency Cepstral Coefficients]]
**âš¡ Unique Technical**: [[keywords/Wav2Vec2|Wav2Vec2]], [[keywords/Exertion-Level Classification|Exertion-Level Classification]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15473v1 Announce Type: cross 
Abstract: Post-exercise speech contains rich physiological and linguistic cues, often marked by semantic pauses, breathing pauses, and combined breathing-semantic pauses. Detecting these events enables assessment of recovery rate, lung function, and exertion-related abnormalities. However, existing works on identifying and distinguishing different types of pauses in this context are limited. In this work, building on a recently released dataset with synchronized audio and respiration signals, we provide systematic annotations of pause types. Using these annotations, we systematically conduct exploratory breathing and semantic pause detection and exertion-level classification across deep learning models (GRU, 1D CNN-LSTM, AlexNet, VGG16), acoustic features (MFCC, MFB), and layer-stratified Wav2Vec2 representations. We evaluate three setups-single feature, feature fusion, and a two-stage detection-classification cascade-under both classification and regression formulations. Results show per-type detection accuracy up to 89$\%$ for semantic, 55$\%$ for breathing, 86$\%$ for combined pauses, and 73$\%$overall, while exertion-level classification achieves 90.5$\%$ accuracy, outperformin prior work.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15473v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ìš´ë™ í›„ ë°œí™”ëŠ” í’ë¶€í•œ ìƒë¦¬ì  ë° ì–¸ì–´ì  ë‹¨ì„œë¥¼ í¬í•¨í•˜ê³  ìˆìœ¼ë©°, ì¢…ì¢… ì˜ë¯¸ì  ë©ˆì¶¤, í˜¸í¡ ë©ˆì¶¤, ê·¸ë¦¬ê³  í˜¸í¡-ì˜ë¯¸ ê²°í•© ë©ˆì¶¤ìœ¼ë¡œ íŠ¹ì§•ì§€ì–´ì§‘ë‹ˆë‹¤. ì´ëŸ¬í•œ ì‚¬ê±´ì„ ê°ì§€í•˜ë©´ íšŒë³µ ì†ë„, í ê¸°ëŠ¥ ë° ìš´ë™ ê´€ë ¨ ì´ìƒì„ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ ë§¥ë½ì—ì„œ ë‹¤ì–‘í•œ ìœ í˜•ì˜ ë©ˆì¶¤ì„ ì‹ë³„í•˜ê³  êµ¬ë³„í•˜ëŠ” ê¸°ì¡´ ì—°êµ¬ëŠ” ì œí•œì ì…ë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” ìµœê·¼ì— ë°œí‘œëœ ì˜¤ë””ì˜¤ì™€ í˜¸í¡ ì‹ í˜¸ê°€ ë™ê¸°í™”ëœ ë°ì´í„°ì…‹ì„ ê¸°ë°˜ìœ¼ë¡œ ë©ˆì¶¤ ìœ í˜•ì— ëŒ€í•œ ì²´ê³„ì ì¸ ì£¼ì„ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì£¼ì„ì„ ì‚¬ìš©í•˜ì—¬ ìš°ë¦¬ëŠ” ì‹¬ì¸µ í•™ìŠµ ëª¨ë¸(GRU, 1D CNN-LSTM, AlexNet, VGG16), ìŒí–¥ íŠ¹ì§•(MFCC, MFB), ê·¸ë¦¬ê³  ì¸µë³„ Wav2Vec2 í‘œí˜„ì„ í†µí•´ íƒìƒ‰ì  í˜¸í¡ ë° ì˜ë¯¸ì  ë©ˆì¶¤ ê°ì§€ì™€ ìš´ë™ ìˆ˜ì¤€ ë¶„ë¥˜ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ìˆ˜í–‰í•©ë‹ˆë‹¤. ë¶„ë¥˜ ë° íšŒê·€ í˜•ì‹ ëª¨ë‘ì—ì„œ ë‹¨ì¼ íŠ¹ì§•, íŠ¹ì§• ìœµí•©, ê·¸ë¦¬ê³  2ë‹¨ê³„ ê°ì§€-ë¶„ë¥˜ ì—°ì‡„ë¼ëŠ” ì„¸ ê°€ì§€ ì„¤ì •ì„ í‰ê°€í•©ë‹ˆë‹¤. ê²°ê³¼ëŠ” ì˜ë¯¸ì  ë©ˆì¶¤ì— ëŒ€í•´ ìµœëŒ€ 89$\%$, í˜¸í¡ ë©ˆì¶¤ì— ëŒ€í•´ 55$\%$, ê²°í•© ë©ˆì¶¤ì— ëŒ€í•´ 86$\%$, ì „ì²´ì ìœ¼ë¡œ 73$\%$ì˜ ìœ í˜•ë³„ ê°ì§€ ì •í™•ë„ë¥¼ ë³´ì—¬ì£¼ë©°, ìš´ë™ ìˆ˜ì¤€ ë¶„ë¥˜ëŠ” 90.5$\%$ì˜ ì •í™•ë„ë¥¼ ë‹¬ì„±í•˜ì—¬ ì´ì „ ì—°êµ¬ë³´ë‹¤ ë›°ì–´ë‚œ ì„±ê³¼ë¥¼ ë³´ì…ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” ìš´ë™ í›„ ë°œí™”ì—ì„œ ë‚˜íƒ€ë‚˜ëŠ” ë‹¤ì–‘í•œ ìœ í˜•ì˜ ë©ˆì¶¤ì„ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ê³  ë¶„ë¥˜í•˜ëŠ” ë°©ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤. ìµœê·¼ ê³µê°œëœ ë™ê¸°í™”ëœ ì˜¤ë””ì˜¤ ë° í˜¸í¡ ì‹ í˜¸ ë°ì´í„°ì…‹ì„ ê¸°ë°˜ìœ¼ë¡œ, ì—°êµ¬ì§„ì€ ë©ˆì¶¤ ìœ í˜•ì— ëŒ€í•œ ì²´ê³„ì ì¸ ì£¼ì„ì„ ì œê³µí•˜ê³ , ì´ë¥¼ í™œìš©í•˜ì—¬ ì‹¬ì¸µ í•™ìŠµ ëª¨ë¸(GRU, 1D CNN-LSTM, AlexNet, VGG16), ìŒí–¥ íŠ¹ì§•(MFCC, MFB), Wav2Vec2 í‘œí˜„ì„ í†µí•´ í˜¸í¡ ë° ì˜ë¯¸ì  ë©ˆì¶¤ íƒì§€ì™€ ìš´ë™ ê°•ë„ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. ì—°êµ¬ ê²°ê³¼, ì˜ë¯¸ì  ë©ˆì¶¤ì€ 89%, í˜¸í¡ ë©ˆì¶¤ì€ 55%, ê²°í•© ë©ˆì¶¤ì€ 86%ì˜ íƒì§€ ì •í™•ë„ë¥¼ ë³´ì˜€ìœ¼ë©°, ìš´ë™ ê°•ë„ ë¶„ë¥˜ì—ì„œëŠ” 90.5%ì˜ ì •í™•ë„ë¥¼ ê¸°ë¡í•˜ì—¬ ê¸°ì¡´ ì—°êµ¬ë¥¼ ëŠ¥ê°€í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ìš´ë™ í›„ ë°œí™”ì—ëŠ” ì˜ë¯¸ì , í˜¸í¡ì , ê²°í•©ëœ í˜¸í¡-ì˜ë¯¸ì  íœ´ì§€ì™€ ê°™ì€ ë‹¤ì–‘í•œ ìƒë¦¬ì  ë° ì–¸ì–´ì  ë‹¨ì„œê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©°, ì´ëŸ¬í•œ ì´ë²¤íŠ¸ë¥¼ ê°ì§€í•˜ë©´ íšŒë³µ ì†ë„, í ê¸°ëŠ¥ ë° ìš´ë™ ê´€ë ¨ ì´ìƒì„ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- 2. ìµœê·¼ì— ë°œí‘œëœ ë™ê¸°í™”ëœ ì˜¤ë””ì˜¤ ë° í˜¸í¡ ì‹ í˜¸ ë°ì´í„°ì…‹ì„ ê¸°ë°˜ìœ¼ë¡œ íœ´ì§€ ìœ í˜•ì— ëŒ€í•œ ì²´ê³„ì ì¸ ì£¼ì„ì„ ì œê³µí•©ë‹ˆë‹¤.
- 3. GRU, 1D CNN-LSTM, AlexNet, VGG16ê³¼ ê°™ì€ ë”¥ëŸ¬ë‹ ëª¨ë¸ê³¼ MFCC, MFBì™€ ê°™ì€ ìŒí–¥ íŠ¹ì§•, ê·¸ë¦¬ê³  ì¸µë³„ Wav2Vec2 í‘œí˜„ì„ ì‚¬ìš©í•˜ì—¬ í˜¸í¡ ë° ì˜ë¯¸ì  íœ´ì§€ ê°ì§€ì™€ ìš´ë™ ìˆ˜ì¤€ ë¶„ë¥˜ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ìˆ˜í–‰í•©ë‹ˆë‹¤.
- 4. ë‹¨ì¼ íŠ¹ì§•, íŠ¹ì§• ìœµí•©, 2ë‹¨ê³„ ê°ì§€-ë¶„ë¥˜ ìºìŠ¤ì¼€ì´ë“œì˜ ì„¸ ê°€ì§€ ì„¤ì •ì„ í‰ê°€í•˜ë©°, ë¶„ë¥˜ ë° íšŒê·€ ê³µì‹ì—ì„œ 89%ì˜ ì˜ë¯¸ì , 55%ì˜ í˜¸í¡ì , 86%ì˜ ê²°í•©ëœ íœ´ì§€ ê°ì§€ ì •í™•ë„ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.
- 5. ìš´ë™ ìˆ˜ì¤€ ë¶„ë¥˜ëŠ” 90.5%ì˜ ì •í™•ë„ë¥¼ ë‹¬ì„±í•˜ì—¬ ì´ì „ ì—°êµ¬ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-23 10:49:07*