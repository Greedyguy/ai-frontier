---
keywords:
  - Hybrid Knowledge Distillation
  - Speech-Driven 3D Facial Animation
  - Pre-trained Speech Encoders
  - On-Device Inference
category: cs.LG
publish_date: 2025-09-22
arxiv_id: 2507.18352
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:21:51.346021",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Hybrid Knowledge Distillation",
    "Speech-Driven 3D Facial Animation",
    "Pre-trained Speech Encoders",
    "On-Device Inference"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Hybrid Knowledge Distillation": 0.78,
    "Speech-Driven 3D Facial Animation": 0.8,
    "Pre-trained Speech Encoders": 0.79,
    "On-Device Inference": 0.82
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "hybrid knowledge distillation",
        "canonical": "Hybrid Knowledge Distillation",
        "aliases": [
          "knowledge distillation",
          "distillation"
        ],
        "category": "unique_technical",
        "rationale": "This technique is central to the paper's approach for training small models, offering a unique angle for linking.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.82,
        "link_intent_score": 0.78
      },
      {
        "surface": "speech-driven 3D facial animation",
        "canonical": "Speech-Driven 3D Facial Animation",
        "aliases": [
          "3D facial animation",
          "facial animation"
        ],
        "category": "unique_technical",
        "rationale": "The paper focuses on this specific application, which is crucial for understanding its context and contributions.",
        "novelty_score": 0.7,
        "connectivity_score": 0.72,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "pre-trained speech encoders",
        "canonical": "Pre-trained Speech Encoders",
        "aliases": [
          "speech encoders",
          "pre-trained encoders"
        ],
        "category": "broad_technical",
        "rationale": "These encoders are a key component in the field of speech processing, providing a broad technical context.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.79
      },
      {
        "surface": "on-device inference",
        "canonical": "On-Device Inference",
        "aliases": [
          "device inference",
          "real-time inference"
        ],
        "category": "specific_connectable",
        "rationale": "This concept is essential for understanding the paper's contribution to making models usable in real-time applications.",
        "novelty_score": 0.68,
        "connectivity_score": 0.75,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "hybrid knowledge distillation",
      "resolved_canonical": "Hybrid Knowledge Distillation",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.82,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "speech-driven 3D facial animation",
      "resolved_canonical": "Speech-Driven 3D Facial Animation",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.72,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "pre-trained speech encoders",
      "resolved_canonical": "Pre-trained Speech Encoders",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "on-device inference",
      "resolved_canonical": "On-Device Inference",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.75,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    }
  ]
}
-->

# Tiny is not small enough: High-quality, low-resource facial animation models through hybrid knowledge distillation

**Korean Title:** 작다는 충분히 작지 않다: 하이브리드 지식 증류를 통한 고품질, 저자원 얼굴 애니메이션 모델

## 📋 메타데이터

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2507.18352.pdf)
**Category**: cs.LG
**Published**: 2025-09-22
**ArXiv ID**: [2507.18352](https://arxiv.org/abs/2507.18352)

## 🔗 유사한 논문
- [[2025-09-19/FMGS-Avatar_ Mesh-Guided 2D Gaussian Splatting with Foundation Model Priors for 3D Monocular Avatar Reconstruction_20250919|FMGS-Avatar: Mesh-Guided 2D Gaussian Splatting with Foundation Model Priors for 3D Monocular Avatar Reconstruction]] (81.0% similar)
- [[2025-09-18/Low-rank surrogate modeling and stochastic zero-order optimization for training of neural networks with black-box layers_20250918|Low-rank surrogate modeling and stochastic zero-order optimization for training of neural networks with black-box layers]] (81.0% similar)
- [[2025-09-19/Hybrid Autoregressive-Diffusion Model for Real-Time Sign Language Production_20250919|Hybrid Autoregressive-Diffusion Model for Real-Time Sign Language Production]] (80.9% similar)
- [[2025-09-19/Multimodal Knowledge Distillation for Egocentric Action Recognition Robust to Missing Modalities_20250919|Multimodal Knowledge Distillation for Egocentric Action Recognition Robust to Missing Modalities]] (80.5% similar)
- [[2025-09-22/Combo_ Co-speech holistic 3D human motion generation and efficient customizable adaptation in harmony_20250922|Combo: Co-speech holistic 3D human motion generation and efficient customizable adaptation in harmony]] (79.7% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Pre-trained Speech Encoders|Pre-trained Speech Encoders]]
**🔗 Specific Connectable**: [[keywords/On-Device Inference|On-Device Inference]]
**⚡ Unique Technical**: [[keywords/Hybrid Knowledge Distillation|Hybrid Knowledge Distillation]], [[keywords/Speech-Driven 3D Facial Animation|Speech-Driven 3D Facial Animation]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2507.18352v2 Announce Type: replace-cross 
Abstract: The training of high-quality, robust machine learning models for speech-driven 3D facial animation requires a large, diverse dataset of high-quality audio-animation pairs. To overcome the lack of such a dataset, recent work has introduced large pre-trained speech encoders that are robust to variations in the input audio and, therefore, enable the facial animation model to generalize across speakers, audio quality, and languages. However, the resulting facial animation models are prohibitively large and lend themselves only to offline inference on a dedicated machine. In this work, we explore on-device, real-time facial animation models in the context of game development. We overcome the lack of large datasets by using hybrid knowledge distillation with pseudo-labeling. Given a large audio dataset, we employ a high-performing teacher model to train very small student models. In contrast to the pre-trained speech encoders, our student models only consist of convolutional and fully-connected layers, removing the need for attention context or recurrent updates. In our experiments, we demonstrate that we can reduce the memory footprint to up to 3.4 MB and required future audio context to up to 81 ms while maintaining high-quality animations. This paves the way for on-device inference, an important step towards realistic, model-driven digital characters.

## 🔍 Abstract (한글 번역)

arXiv:2507.18352v2 발표 유형: 교차 대체  
초록: 고품질의 견고한 음성 기반 3D 얼굴 애니메이션 모델을 훈련하기 위해서는 고품질의 오디오-애니메이션 쌍으로 이루어진 대규모의 다양한 데이터셋이 필요합니다. 이러한 데이터셋의 부족을 극복하기 위해 최근 연구에서는 입력 오디오의 변이에 강인한 대규모 사전 학습된 음성 인코더를 도입하여 얼굴 애니메이션 모델이 화자, 오디오 품질, 언어에 걸쳐 일반화할 수 있도록 했습니다. 그러나 결과적으로 생성된 얼굴 애니메이션 모델은 지나치게 크며 전용 기기에서의 오프라인 추론에만 적합합니다. 본 연구에서는 게임 개발의 맥락에서 디바이스 상에서 실시간으로 동작하는 얼굴 애니메이션 모델을 탐구합니다. 우리는 하이브리드 지식 증류와 의사 레이블링을 사용하여 대규모 데이터셋의 부족 문제를 해결합니다. 대규모 오디오 데이터셋을 기반으로, 성능이 우수한 교사 모델을 사용하여 매우 작은 학생 모델을 훈련합니다. 사전 학습된 음성 인코더와 달리, 우리의 학생 모델은 컨볼루션 및 완전 연결층으로만 구성되어 주의 컨텍스트나 순환 업데이트가 필요하지 않습니다. 실험 결과, 메모리 사용량을 최대 3.4 MB로 줄이고, 필요한 미래 오디오 컨텍스트를 최대 81 ms로 줄이면서도 고품질의 애니메이션을 유지할 수 있음을 입증했습니다. 이는 디바이스 상에서의 추론을 가능하게 하며, 현실적이고 모델 기반의 디지털 캐릭터를 향한 중요한 단계입니다.

## 📝 요약

이 논문은 게임 개발에서 실시간으로 작동하는 기기 내 3D 얼굴 애니메이션 모델을 제안합니다. 기존의 대규모 데이터셋 부족 문제를 해결하기 위해 하이브리드 지식 증류와 가짜 레이블링을 사용하여, 고성능 교사 모델로 작은 학생 모델을 훈련합니다. 학생 모델은 합성곱 및 완전 연결 층만으로 구성되어 메모리 사용량을 3.4MB까지 줄이고, 81ms의 오디오 컨텍스트만 필요로 하면서도 높은 품질의 애니메이션을 유지합니다. 이 접근법은 현실적인 디지털 캐릭터 구현을 위한 기기 내 추론의 가능성을 열어줍니다.

## 🎯 주요 포인트

- 1. 고품질의 음성 기반 3D 얼굴 애니메이션 모델 훈련에는 다양한 고품질 오디오-애니메이션 쌍 데이터셋이 필요합니다.
- 2. 대규모 사전 학습된 음성 인코더는 입력 오디오의 변동에 강하며, 다양한 화자, 오디오 품질, 언어에 걸쳐 일반화할 수 있는 얼굴 애니메이션 모델을 가능하게 합니다.
- 3. 본 연구에서는 게임 개발 맥락에서 기기 내 실시간 얼굴 애니메이션 모델을 탐구하며, 하이브리드 지식 증류와 의사 레이블링을 사용하여 대규모 데이터셋 부족 문제를 해결합니다.
- 4. 실험 결과, 메모리 사용량을 최대 3.4 MB로 줄이고, 필요한 미래 오디오 컨텍스트를 최대 81 ms로 줄이면서도 고품질 애니메이션을 유지할 수 있음을 보여줍니다.
- 5. 이는 현실적이고 모델 기반의 디지털 캐릭터를 위한 기기 내 추론의 중요한 진전을 의미합니다.


---

*Generated on 2025-09-23 11:21:51*