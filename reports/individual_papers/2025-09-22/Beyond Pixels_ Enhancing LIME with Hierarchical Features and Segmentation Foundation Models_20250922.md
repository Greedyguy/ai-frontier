---
keywords:
  - Local Interpretable Model-agnostic Explanations
  - DSEG-LIME
  - Image Segmentation
  - Foundation Models
  - Human-Recognized Concepts
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2403.07733
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T09:42:50.645884",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Local Interpretable Model-agnostic Explanations",
    "DSEG-LIME",
    "Image Segmentation",
    "Foundation Models",
    "Human-Recognized Concepts"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Local Interpretable Model-agnostic Explanations": 0.8,
    "DSEG-LIME": 0.85,
    "Image Segmentation": 0.75,
    "Foundation Models": 0.7,
    "Human-Recognized Concepts": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "LIME",
        "canonical": "Local Interpretable Model-agnostic Explanations",
        "aliases": [
          "LIME"
        ],
        "category": "unique_technical",
        "rationale": "LIME is a foundational technique in explainable AI, crucial for linking discussions on model interpretability.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "DSEG-LIME",
        "canonical": "DSEG-LIME",
        "aliases": [
          "Data-Driven Segmentation LIME"
        ],
        "category": "unique_technical",
        "rationale": "DSEG-LIME represents a novel enhancement to LIME, providing a new approach to segmentation in explainable AI.",
        "novelty_score": 0.9,
        "connectivity_score": 0.6,
        "specificity_score": 0.9,
        "link_intent_score": 0.85
      },
      {
        "surface": "Image Segmentation",
        "canonical": "Image Segmentation",
        "aliases": [
          "Segmentation"
        ],
        "category": "broad_technical",
        "rationale": "Image Segmentation is a core technique in computer vision, relevant for linking various segmentation-based methodologies.",
        "novelty_score": 0.4,
        "connectivity_score": 0.8,
        "specificity_score": 0.7,
        "link_intent_score": 0.75
      },
      {
        "surface": "Foundation Models",
        "canonical": "Foundation Models",
        "aliases": [
          "Base Models"
        ],
        "category": "evolved_concepts",
        "rationale": "Foundation Models are increasingly central in AI, offering a basis for integrating various advanced techniques.",
        "novelty_score": 0.6,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      },
      {
        "surface": "Human-Recognized Concepts",
        "canonical": "Human-Recognized Concepts",
        "aliases": [
          "Human Concepts"
        ],
        "category": "specific_connectable",
        "rationale": "Linking to human-recognized concepts is vital for enhancing the interpretability of AI models.",
        "novelty_score": 0.5,
        "connectivity_score": 0.75,
        "specificity_score": 0.75,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "experiment"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "LIME",
      "resolved_canonical": "Local Interpretable Model-agnostic Explanations",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "DSEG-LIME",
      "resolved_canonical": "DSEG-LIME",
      "decision": "linked",
      "scores": {
        "novelty": 0.9,
        "connectivity": 0.6,
        "specificity": 0.9,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Image Segmentation",
      "resolved_canonical": "Image Segmentation",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.8,
        "specificity": 0.7,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Foundation Models",
      "resolved_canonical": "Foundation Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Human-Recognized Concepts",
      "resolved_canonical": "Human-Recognized Concepts",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.75,
        "specificity": 0.75,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# Beyond Pixels: Enhancing LIME with Hierarchical Features and Segmentation Foundation Models

**Korean Title:** 픽셀을 넘어: 계층적 특징 및 세분화 기반 모델을 활용한 LIME 향상

## 📋 메타데이터

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2403.07733.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2403.07733](https://arxiv.org/abs/2403.07733)

## 🔗 유사한 논문
- [[2025-09-18/LLM-I_ LLMs are Naturally Interleaved Multimodal Creators_20250918|LLM-I: LLMs are Naturally Interleaved Multimodal Creators]] (82.0% similar)
- [[2025-09-19/DiffCut_ Catalyzing Zero-Shot Semantic Segmentation with Diffusion Features and Recursive Normalized Cut_20250919|DiffCut: Catalyzing Zero-Shot Semantic Segmentation with Diffusion Features and Recursive Normalized Cut]] (81.2% similar)
- [[2025-09-22/Multi-Modal Interpretability for Enhanced Localization in Vision-Language Models_20250922|Multi-Modal Interpretability for Enhanced Localization in Vision-Language Models]] (80.8% similar)
- [[2025-09-19/V-SEAM_ Visual Semantic Editing and Attention Modulating for Causal Interpretability of Vision-Language Models_20250919|V-SEAM: Visual Semantic Editing and Attention Modulating for Causal Interpretability of Vision-Language Models]] (80.8% similar)
- [[2025-09-19/SMARTER_ A Data-efficient Framework to Improve Toxicity Detection with Explanation via Self-augmenting Large Language Models_20250919|SMARTER: A Data-efficient Framework to Improve Toxicity Detection with Explanation via Self-augmenting Large Language Models]] (80.6% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Image Segmentation|Image Segmentation]]
**🔗 Specific Connectable**: [[keywords/Human-Recognized Concepts|Human-Recognized Concepts]]
**⚡ Unique Technical**: [[keywords/Local Interpretable Model-agnostic Explanations|Local Interpretable Model-agnostic Explanations]], [[keywords/DSEG-LIME|DSEG-LIME]]
**🚀 Evolved Concepts**: [[keywords/Foundation Models|Foundation Models]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2403.07733v5 Announce Type: replace-cross 
Abstract: LIME (Local Interpretable Model-agnostic Explanations) is a popular XAI framework for unraveling decision-making processes in vision machine-learning models. The technique utilizes image segmentation methods to identify fixed regions for calculating feature importance scores as explanations. Therefore, poor segmentation can weaken the explanation and reduce the importance of segments, ultimately affecting the overall clarity of interpretation. To address these challenges, we introduce the DSEG-LIME (Data-Driven Segmentation LIME) framework, featuring: i) a data-driven segmentation for human-recognized feature generation by foundation model integration, and ii) a user-steered granularity in the hierarchical segmentation procedure through composition. Our findings demonstrate that DSEG outperforms on several XAI metrics on pre-trained ImageNet models and improves the alignment of explanations with human-recognized concepts. The code is available under: https://github. com/patrick-knab/DSEG-LIME

## 🔍 Abstract (한글 번역)

arXiv:2403.07733v5 발표 유형: 교차 대체  
초록: LIME (Local Interpretable Model-agnostic Explanations)는 비전 머신러닝 모델의 의사결정 과정을 해석하는 데 널리 사용되는 XAI 프레임워크입니다. 이 기법은 이미지 분할 방법을 활용하여 설명으로서의 특징 중요도 점수를 계산하기 위한 고정된 영역을 식별합니다. 따라서, 부적절한 분할은 설명의 질을 약화시키고 세그먼트의 중요성을 감소시켜, 궁극적으로 해석의 전반적인 명확성에 영향을 미칠 수 있습니다. 이러한 문제를 해결하기 위해, 우리는 DSEG-LIME (Data-Driven Segmentation LIME) 프레임워크를 도입합니다. 이 프레임워크는 i) 기초 모델 통합을 통한 인간이 인식할 수 있는 특징 생성의 데이터 기반 분할과 ii) 구성에 의한 계층적 분할 절차에서 사용자가 조정할 수 있는 세분성을 특징으로 합니다. 우리의 연구 결과는 DSEG가 사전 학습된 ImageNet 모델에서 여러 XAI 지표에서 우수한 성능을 보이며, 설명이 인간이 인식하는 개념과의 일치성을 향상시킴을 보여줍니다. 코드는 다음에서 확인할 수 있습니다: https://github.com/patrick-knab/DSEG-LIME

## 📝 요약

이 논문은 LIME의 한계를 극복하기 위해 DSEG-LIME 프레임워크를 제안합니다. LIME은 이미지 분할을 통해 특징 중요도를 설명하지만, 부정확한 분할은 설명의 명확성을 저하시킬 수 있습니다. DSEG-LIME은 데이터 기반 분할을 통해 인간이 인식할 수 있는 특징을 생성하고, 사용자가 분할의 세분화를 조정할 수 있도록 합니다. 연구 결과, DSEG-LIME은 ImageNet 모델에서 여러 XAI 지표에서 우수한 성능을 보였으며, 설명이 인간이 인식하는 개념과 더 잘 일치함을 확인했습니다.

## 🎯 주요 포인트

- 1. LIME은 시각적 머신러닝 모델의 의사결정 과정을 해석하기 위한 인기 있는 XAI 프레임워크입니다.
- 2. 이미지 분할 방법을 활용하여 고정된 영역을 식별하고, 이를 통해 특징 중요도 점수를 계산하여 설명을 제공합니다.
- 3. DSEG-LIME은 데이터 기반 분할을 통해 인간이 인식할 수 있는 특징을 생성하고, 사용자가 계층적 분할 절차의 세분성을 조정할 수 있도록 합니다.
- 4. DSEG-LIME은 사전 학습된 ImageNet 모델에서 여러 XAI 지표에서 우수한 성능을 보이며, 설명이 인간이 인식하는 개념과의 정렬을 개선합니다.
- 5. DSEG-LIME의 코드는 GitHub에서 제공됩니다.


---

*Generated on 2025-09-23 09:42:50*