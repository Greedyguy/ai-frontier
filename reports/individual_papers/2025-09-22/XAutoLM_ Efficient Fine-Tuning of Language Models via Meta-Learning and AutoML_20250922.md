---
keywords:
  - Meta-Learning
  - Automated Machine Learning
  - Fine-Tuning
  - Green AI
  - Zero-Shot Learning
category: cs.CL
publish_date: 2025-09-22
arxiv_id: 2508.00924
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:49:58.639956",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Meta-Learning",
    "Automated Machine Learning",
    "Fine-Tuning",
    "Green AI",
    "Zero-Shot Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Meta-Learning": 0.82,
    "Automated Machine Learning": 0.79,
    "Fine-Tuning": 0.78,
    "Green AI": 0.8,
    "Zero-Shot Learning": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "meta-learning",
        "canonical": "Meta-Learning",
        "aliases": [
          "meta learning"
        ],
        "category": "specific_connectable",
        "rationale": "Meta-learning is a key technique in optimizing language model fine-tuning, enhancing connectivity with other learning paradigms.",
        "novelty_score": 0.65,
        "connectivity_score": 0.85,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "AutoML",
        "canonical": "Automated Machine Learning",
        "aliases": [
          "Auto ML"
        ],
        "category": "specific_connectable",
        "rationale": "AutoML frameworks are crucial for efficient model selection and hyperparameter optimization, linking to broader AI automation efforts.",
        "novelty_score": 0.6,
        "connectivity_score": 0.88,
        "specificity_score": 0.8,
        "link_intent_score": 0.79
      },
      {
        "surface": "fine-tuning",
        "canonical": "Fine-Tuning",
        "aliases": [
          "model fine-tuning"
        ],
        "category": "broad_technical",
        "rationale": "Fine-tuning is a fundamental process in adapting language models, connecting to various model optimization techniques.",
        "novelty_score": 0.55,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.78
      },
      {
        "surface": "Green AI",
        "canonical": "Green AI",
        "aliases": [
          "sustainable AI"
        ],
        "category": "evolved_concepts",
        "rationale": "Green AI emphasizes resource-efficient computing, which is increasingly relevant in sustainable AI practices.",
        "novelty_score": 0.72,
        "connectivity_score": 0.75,
        "specificity_score": 0.82,
        "link_intent_score": 0.8
      },
      {
        "surface": "zero-shot optimizer",
        "canonical": "Zero-Shot Learning",
        "aliases": [
          "zero shot"
        ],
        "category": "specific_connectable",
        "rationale": "Zero-shot learning is an emerging concept in model evaluation and optimization, enhancing connections with learning strategies.",
        "novelty_score": 0.68,
        "connectivity_score": 0.84,
        "specificity_score": 0.76,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "model selection",
      "hyperparameter optimization",
      "resource allocation"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "meta-learning",
      "resolved_canonical": "Meta-Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.85,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "AutoML",
      "resolved_canonical": "Automated Machine Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.88,
        "specificity": 0.8,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "fine-tuning",
      "resolved_canonical": "Fine-Tuning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Green AI",
      "resolved_canonical": "Green AI",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.75,
        "specificity": 0.82,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "zero-shot optimizer",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.84,
        "specificity": 0.76,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# XAutoLM: Efficient Fine-Tuning of Language Models via Meta-Learning and AutoML

**Korean Title:** XAutoLM: 메타러닝과 AutoML을 통한 언어 모델의 효율적인 미세 조정

## 📋 메타데이터

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2508.00924.pdf)
**Category**: cs.CL
**Published**: 2025-09-22
**ArXiv ID**: [2508.00924](https://arxiv.org/abs/2508.00924)

## 🔗 유사한 논문
- [[2025-09-19/Middo_ Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning_20250919|Middo: Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning]] (83.9% similar)
- [[2025-09-19/MedVAL_ Toward Expert-Level Medical Text Validation with Language Models_20250919|MedVAL: Toward Expert-Level Medical Text Validation with Language Models]] (83.5% similar)
- [[2025-09-19/SMARTER_ A Data-efficient Framework to Improve Toxicity Detection with Explanation via Self-augmenting Large Language Models_20250919|SMARTER: A Data-efficient Framework to Improve Toxicity Detection with Explanation via Self-augmenting Large Language Models]] (83.1% similar)
- [[2025-09-22/Adaptive Self-improvement LLM Agentic System for ML Library Development_20250922|Adaptive Self-improvement LLM Agentic System for ML Library Development]] (82.8% similar)
- [[2025-09-22/Subjective Behaviors and Preferences in LLM_ Language of Browsing_20250922|Subjective Behaviors and Preferences in LLM: Language of Browsing]] (81.8% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Fine-Tuning|Fine-Tuning]]
**🔗 Specific Connectable**: [[keywords/Meta-Learning|Meta-Learning]], [[keywords/Automated Machine Learning|Automated Machine Learning]], [[keywords/Zero-Shot Learning|Zero-Shot Learning]]
**🚀 Evolved Concepts**: [[keywords/Green AI|Green AI]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2508.00924v2 Announce Type: replace 
Abstract: Experts in machine learning leverage domain knowledge to navigate decisions in model selection, hyperparameter optimization, and resource allocation. This is particularly critical for fine-tuning language models (LMs), where repeated trials incur substantial computational overhead and environmental impact. However, no existing automated framework simultaneously tackles the entire model selection and hyperparameter optimization (HPO) task for resource-efficient LM fine-tuning. We introduce XAutoLM, a meta-learning-augmented AutoML framework that reuses past experiences to optimize discriminative and generative LM fine-tuning pipelines efficiently. XAutoLM learns from stored successes and failures by extracting task- and system-level meta-features to bias its sampling toward valuable configurations and away from costly dead ends. On four text classification and two question-answering benchmarks, XAutoLM surpasses zero-shot optimizer's peak F1 on five of six tasks, cuts mean evaluation time of pipelines by up to 4.5x, reduces search error ratios by up to sevenfold, and uncovers up to 50% more pipelines above the zero-shot Pareto front. In contrast, simpler memory-based baselines suffer negative transfer. We release XAutoLM and our experience store to catalyze resource-efficient, Green AI fine-tuning in the NLP community.

## 🔍 Abstract (한글 번역)

arXiv:2508.00924v2 발표 유형: 교체  
초록: 머신러닝 전문가들은 모델 선택, 하이퍼파라미터 최적화, 자원 할당에서 의사결정을 내리기 위해 도메인 지식을 활용합니다. 이는 특히 언어 모델(LM)의 미세 조정에서 중요하며, 반복적인 실험은 상당한 계산 비용과 환경적 영향을 초래합니다. 그러나 현재 존재하는 자동화된 프레임워크 중 자원 효율적인 LM 미세 조정을 위해 모델 선택과 하이퍼파라미터 최적화(HPO) 작업을 동시에 해결하는 것은 없습니다. 우리는 XAutoLM을 소개합니다. 이는 과거의 경험을 재사용하여 판별적 및 생성적 LM 미세 조정 파이프라인을 효율적으로 최적화하는 메타러닝 보강 AutoML 프레임워크입니다. XAutoLM은 저장된 성공과 실패로부터 학습하여, 작업 및 시스템 수준의 메타 특징을 추출하여 유용한 구성으로의 샘플링을 편향시키고 비용이 많이 드는 막다른 골목을 피합니다. 네 가지 텍스트 분류 및 두 가지 질문-응답 벤치마크에서, XAutoLM은 여섯 가지 작업 중 다섯 가지에서 제로샷 최적화의 최고 F1을 능가하며, 파이프라인의 평균 평가 시간을 최대 4.5배 단축하고, 검색 오류 비율을 최대 7배 줄이며, 제로샷 파레토 전선 위의 파이프라인을 최대 50% 더 많이 발견합니다. 반면, 단순한 메모리 기반 기준선은 부정적 전이를 겪습니다. 우리는 NLP 커뮤니티에서 자원 효율적이고 친환경적인 AI 미세 조정을 촉진하기 위해 XAutoLM과 우리의 경험 저장소를 공개합니다.

## 📝 요약

XAutoLM은 메타러닝을 활용한 AutoML 프레임워크로, 과거의 경험을 재사용하여 언어 모델(LM) 미세 조정의 모델 선택과 하이퍼파라미터 최적화를 효율적으로 수행합니다. 이 프레임워크는 성공과 실패 사례에서 추출한 메타 특징을 활용하여 유망한 구성으로 샘플링을 유도합니다. XAutoLM은 텍스트 분류와 질문 응답 벤치마크에서 기존의 제로샷 최적화 기법보다 뛰어난 성능을 보이며, 평균 평가 시간을 최대 4.5배 단축하고, 검색 오류 비율을 최대 7배 줄이며, 제로샷 파레토 전선보다 최대 50% 더 많은 파이프라인을 발견합니다. 이 연구는 NLP 커뮤니티에서 자원 효율적이고 환경 친화적인 AI 미세 조정을 촉진하기 위해 XAutoLM과 경험 저장소를 공개합니다.

## 🎯 주요 포인트

- 1. XAutoLM은 메타러닝을 활용한 AutoML 프레임워크로, 과거의 경험을 재사용하여 효율적으로 언어 모델의 미세 조정 파이프라인을 최적화합니다.
- 2. XAutoLM은 작업 및 시스템 수준의 메타 특징을 추출하여 가치 있는 구성으로 샘플링을 유도하고, 불필요한 경로를 피합니다.
- 3. XAutoLM은 텍스트 분류 및 질의응답 벤치마크에서 평균 평가 시간을 최대 4.5배 단축하고, 검색 오류 비율을 최대 7배 감소시킵니다.
- 4. XAutoLM은 제로샷 최적화기의 최고 F1 점수를 6개 중 5개의 작업에서 초과하며, 제로샷 파레토 전선 위의 파이프라인을 최대 50% 더 많이 발견합니다.
- 5. XAutoLM과 경험 저장소는 NLP 커뮤니티에서 자원 효율적이고 환경 친화적인 AI 미세 조정을 촉진하기 위해 공개됩니다.


---

*Generated on 2025-09-23 11:49:58*