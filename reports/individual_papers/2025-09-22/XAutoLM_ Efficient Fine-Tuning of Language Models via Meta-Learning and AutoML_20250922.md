---
keywords:
  - Meta-Learning
  - Automated Machine Learning
  - Fine-Tuning
  - Green AI
  - Zero-Shot Learning
category: cs.CL
publish_date: 2025-09-22
arxiv_id: 2508.00924
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:49:58.639956",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Meta-Learning",
    "Automated Machine Learning",
    "Fine-Tuning",
    "Green AI",
    "Zero-Shot Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Meta-Learning": 0.82,
    "Automated Machine Learning": 0.79,
    "Fine-Tuning": 0.78,
    "Green AI": 0.8,
    "Zero-Shot Learning": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "meta-learning",
        "canonical": "Meta-Learning",
        "aliases": [
          "meta learning"
        ],
        "category": "specific_connectable",
        "rationale": "Meta-learning is a key technique in optimizing language model fine-tuning, enhancing connectivity with other learning paradigms.",
        "novelty_score": 0.65,
        "connectivity_score": 0.85,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "AutoML",
        "canonical": "Automated Machine Learning",
        "aliases": [
          "Auto ML"
        ],
        "category": "specific_connectable",
        "rationale": "AutoML frameworks are crucial for efficient model selection and hyperparameter optimization, linking to broader AI automation efforts.",
        "novelty_score": 0.6,
        "connectivity_score": 0.88,
        "specificity_score": 0.8,
        "link_intent_score": 0.79
      },
      {
        "surface": "fine-tuning",
        "canonical": "Fine-Tuning",
        "aliases": [
          "model fine-tuning"
        ],
        "category": "broad_technical",
        "rationale": "Fine-tuning is a fundamental process in adapting language models, connecting to various model optimization techniques.",
        "novelty_score": 0.55,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.78
      },
      {
        "surface": "Green AI",
        "canonical": "Green AI",
        "aliases": [
          "sustainable AI"
        ],
        "category": "evolved_concepts",
        "rationale": "Green AI emphasizes resource-efficient computing, which is increasingly relevant in sustainable AI practices.",
        "novelty_score": 0.72,
        "connectivity_score": 0.75,
        "specificity_score": 0.82,
        "link_intent_score": 0.8
      },
      {
        "surface": "zero-shot optimizer",
        "canonical": "Zero-Shot Learning",
        "aliases": [
          "zero shot"
        ],
        "category": "specific_connectable",
        "rationale": "Zero-shot learning is an emerging concept in model evaluation and optimization, enhancing connections with learning strategies.",
        "novelty_score": 0.68,
        "connectivity_score": 0.84,
        "specificity_score": 0.76,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "model selection",
      "hyperparameter optimization",
      "resource allocation"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "meta-learning",
      "resolved_canonical": "Meta-Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.85,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "AutoML",
      "resolved_canonical": "Automated Machine Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.88,
        "specificity": 0.8,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "fine-tuning",
      "resolved_canonical": "Fine-Tuning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Green AI",
      "resolved_canonical": "Green AI",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.75,
        "specificity": 0.82,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "zero-shot optimizer",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.84,
        "specificity": 0.76,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# XAutoLM: Efficient Fine-Tuning of Language Models via Meta-Learning and AutoML

**Korean Title:** XAutoLM: ë©”íƒ€ëŸ¬ë‹ê³¼ AutoMLì„ í†µí•œ ì–¸ì–´ ëª¨ë¸ì˜ íš¨ìœ¨ì ì¸ ë¯¸ì„¸ ì¡°ì •

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2508.00924.pdf)
**Category**: cs.CL
**Published**: 2025-09-22
**ArXiv ID**: [2508.00924](https://arxiv.org/abs/2508.00924)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Middo_ Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning_20250919|Middo: Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning]] (83.9% similar)
- [[2025-09-19/MedVAL_ Toward Expert-Level Medical Text Validation with Language Models_20250919|MedVAL: Toward Expert-Level Medical Text Validation with Language Models]] (83.5% similar)
- [[2025-09-19/SMARTER_ A Data-efficient Framework to Improve Toxicity Detection with Explanation via Self-augmenting Large Language Models_20250919|SMARTER: A Data-efficient Framework to Improve Toxicity Detection with Explanation via Self-augmenting Large Language Models]] (83.1% similar)
- [[2025-09-22/Adaptive Self-improvement LLM Agentic System for ML Library Development_20250922|Adaptive Self-improvement LLM Agentic System for ML Library Development]] (82.8% similar)
- [[2025-09-22/Subjective Behaviors and Preferences in LLM_ Language of Browsing_20250922|Subjective Behaviors and Preferences in LLM: Language of Browsing]] (81.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Fine-Tuning|Fine-Tuning]]
**ğŸ”— Specific Connectable**: [[keywords/Meta-Learning|Meta-Learning]], [[keywords/Automated Machine Learning|Automated Machine Learning]], [[keywords/Zero-Shot Learning|Zero-Shot Learning]]
**ğŸš€ Evolved Concepts**: [[keywords/Green AI|Green AI]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2508.00924v2 Announce Type: replace 
Abstract: Experts in machine learning leverage domain knowledge to navigate decisions in model selection, hyperparameter optimization, and resource allocation. This is particularly critical for fine-tuning language models (LMs), where repeated trials incur substantial computational overhead and environmental impact. However, no existing automated framework simultaneously tackles the entire model selection and hyperparameter optimization (HPO) task for resource-efficient LM fine-tuning. We introduce XAutoLM, a meta-learning-augmented AutoML framework that reuses past experiences to optimize discriminative and generative LM fine-tuning pipelines efficiently. XAutoLM learns from stored successes and failures by extracting task- and system-level meta-features to bias its sampling toward valuable configurations and away from costly dead ends. On four text classification and two question-answering benchmarks, XAutoLM surpasses zero-shot optimizer's peak F1 on five of six tasks, cuts mean evaluation time of pipelines by up to 4.5x, reduces search error ratios by up to sevenfold, and uncovers up to 50% more pipelines above the zero-shot Pareto front. In contrast, simpler memory-based baselines suffer negative transfer. We release XAutoLM and our experience store to catalyze resource-efficient, Green AI fine-tuning in the NLP community.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2508.00924v2 ë°œí‘œ ìœ í˜•: êµì²´  
ì´ˆë¡: ë¨¸ì‹ ëŸ¬ë‹ ì „ë¬¸ê°€ë“¤ì€ ëª¨ë¸ ì„ íƒ, í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”, ìì› í• ë‹¹ì—ì„œ ì˜ì‚¬ê²°ì •ì„ ë‚´ë¦¬ê¸° ìœ„í•´ ë„ë©”ì¸ ì§€ì‹ì„ í™œìš©í•©ë‹ˆë‹¤. ì´ëŠ” íŠ¹íˆ ì–¸ì–´ ëª¨ë¸(LM)ì˜ ë¯¸ì„¸ ì¡°ì •ì—ì„œ ì¤‘ìš”í•˜ë©°, ë°˜ë³µì ì¸ ì‹¤í—˜ì€ ìƒë‹¹í•œ ê³„ì‚° ë¹„ìš©ê³¼ í™˜ê²½ì  ì˜í–¥ì„ ì´ˆë˜í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ í˜„ì¬ ì¡´ì¬í•˜ëŠ” ìë™í™”ëœ í”„ë ˆì„ì›Œí¬ ì¤‘ ìì› íš¨ìœ¨ì ì¸ LM ë¯¸ì„¸ ì¡°ì •ì„ ìœ„í•´ ëª¨ë¸ ì„ íƒê³¼ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”(HPO) ì‘ì—…ì„ ë™ì‹œì— í•´ê²°í•˜ëŠ” ê²ƒì€ ì—†ìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” XAutoLMì„ ì†Œê°œí•©ë‹ˆë‹¤. ì´ëŠ” ê³¼ê±°ì˜ ê²½í—˜ì„ ì¬ì‚¬ìš©í•˜ì—¬ íŒë³„ì  ë° ìƒì„±ì  LM ë¯¸ì„¸ ì¡°ì • íŒŒì´í”„ë¼ì¸ì„ íš¨ìœ¨ì ìœ¼ë¡œ ìµœì í™”í•˜ëŠ” ë©”íƒ€ëŸ¬ë‹ ë³´ê°• AutoML í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. XAutoLMì€ ì €ì¥ëœ ì„±ê³µê³¼ ì‹¤íŒ¨ë¡œë¶€í„° í•™ìŠµí•˜ì—¬, ì‘ì—… ë° ì‹œìŠ¤í…œ ìˆ˜ì¤€ì˜ ë©”íƒ€ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ì—¬ ìœ ìš©í•œ êµ¬ì„±ìœ¼ë¡œì˜ ìƒ˜í”Œë§ì„ í¸í–¥ì‹œí‚¤ê³  ë¹„ìš©ì´ ë§ì´ ë“œëŠ” ë§‰ë‹¤ë¥¸ ê³¨ëª©ì„ í”¼í•©ë‹ˆë‹¤. ë„¤ ê°€ì§€ í…ìŠ¤íŠ¸ ë¶„ë¥˜ ë° ë‘ ê°€ì§€ ì§ˆë¬¸-ì‘ë‹µ ë²¤ì¹˜ë§ˆí¬ì—ì„œ, XAutoLMì€ ì—¬ì„¯ ê°€ì§€ ì‘ì—… ì¤‘ ë‹¤ì„¯ ê°€ì§€ì—ì„œ ì œë¡œìƒ· ìµœì í™”ì˜ ìµœê³  F1ì„ ëŠ¥ê°€í•˜ë©°, íŒŒì´í”„ë¼ì¸ì˜ í‰ê·  í‰ê°€ ì‹œê°„ì„ ìµœëŒ€ 4.5ë°° ë‹¨ì¶•í•˜ê³ , ê²€ìƒ‰ ì˜¤ë¥˜ ë¹„ìœ¨ì„ ìµœëŒ€ 7ë°° ì¤„ì´ë©°, ì œë¡œìƒ· íŒŒë ˆí†  ì „ì„  ìœ„ì˜ íŒŒì´í”„ë¼ì¸ì„ ìµœëŒ€ 50% ë” ë§ì´ ë°œê²¬í•©ë‹ˆë‹¤. ë°˜ë©´, ë‹¨ìˆœí•œ ë©”ëª¨ë¦¬ ê¸°ë°˜ ê¸°ì¤€ì„ ì€ ë¶€ì •ì  ì „ì´ë¥¼ ê²ªìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” NLP ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ìì› íš¨ìœ¨ì ì´ê³  ì¹œí™˜ê²½ì ì¸ AI ë¯¸ì„¸ ì¡°ì •ì„ ì´‰ì§„í•˜ê¸° ìœ„í•´ XAutoLMê³¼ ìš°ë¦¬ì˜ ê²½í—˜ ì €ì¥ì†Œë¥¼ ê³µê°œí•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

XAutoLMì€ ë©”íƒ€ëŸ¬ë‹ì„ í™œìš©í•œ AutoML í”„ë ˆì„ì›Œí¬ë¡œ, ê³¼ê±°ì˜ ê²½í—˜ì„ ì¬ì‚¬ìš©í•˜ì—¬ ì–¸ì–´ ëª¨ë¸(LM) ë¯¸ì„¸ ì¡°ì •ì˜ ëª¨ë¸ ì„ íƒê³¼ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ì„±ê³µê³¼ ì‹¤íŒ¨ ì‚¬ë¡€ì—ì„œ ì¶”ì¶œí•œ ë©”íƒ€ íŠ¹ì§•ì„ í™œìš©í•˜ì—¬ ìœ ë§í•œ êµ¬ì„±ìœ¼ë¡œ ìƒ˜í”Œë§ì„ ìœ ë„í•©ë‹ˆë‹¤. XAutoLMì€ í…ìŠ¤íŠ¸ ë¶„ë¥˜ì™€ ì§ˆë¬¸ ì‘ë‹µ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ê¸°ì¡´ì˜ ì œë¡œìƒ· ìµœì í™” ê¸°ë²•ë³´ë‹¤ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì´ë©°, í‰ê·  í‰ê°€ ì‹œê°„ì„ ìµœëŒ€ 4.5ë°° ë‹¨ì¶•í•˜ê³ , ê²€ìƒ‰ ì˜¤ë¥˜ ë¹„ìœ¨ì„ ìµœëŒ€ 7ë°° ì¤„ì´ë©°, ì œë¡œìƒ· íŒŒë ˆí†  ì „ì„ ë³´ë‹¤ ìµœëŒ€ 50% ë” ë§ì€ íŒŒì´í”„ë¼ì¸ì„ ë°œê²¬í•©ë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” NLP ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ìì› íš¨ìœ¨ì ì´ê³  í™˜ê²½ ì¹œí™”ì ì¸ AI ë¯¸ì„¸ ì¡°ì •ì„ ì´‰ì§„í•˜ê¸° ìœ„í•´ XAutoLMê³¼ ê²½í—˜ ì €ì¥ì†Œë¥¼ ê³µê°œí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. XAutoLMì€ ë©”íƒ€ëŸ¬ë‹ì„ í™œìš©í•œ AutoML í”„ë ˆì„ì›Œí¬ë¡œ, ê³¼ê±°ì˜ ê²½í—˜ì„ ì¬ì‚¬ìš©í•˜ì—¬ íš¨ìœ¨ì ìœ¼ë¡œ ì–¸ì–´ ëª¨ë¸ì˜ ë¯¸ì„¸ ì¡°ì • íŒŒì´í”„ë¼ì¸ì„ ìµœì í™”í•©ë‹ˆë‹¤.
- 2. XAutoLMì€ ì‘ì—… ë° ì‹œìŠ¤í…œ ìˆ˜ì¤€ì˜ ë©”íƒ€ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ì—¬ ê°€ì¹˜ ìˆëŠ” êµ¬ì„±ìœ¼ë¡œ ìƒ˜í”Œë§ì„ ìœ ë„í•˜ê³ , ë¶ˆí•„ìš”í•œ ê²½ë¡œë¥¼ í”¼í•©ë‹ˆë‹¤.
- 3. XAutoLMì€ í…ìŠ¤íŠ¸ ë¶„ë¥˜ ë° ì§ˆì˜ì‘ë‹µ ë²¤ì¹˜ë§ˆí¬ì—ì„œ í‰ê·  í‰ê°€ ì‹œê°„ì„ ìµœëŒ€ 4.5ë°° ë‹¨ì¶•í•˜ê³ , ê²€ìƒ‰ ì˜¤ë¥˜ ë¹„ìœ¨ì„ ìµœëŒ€ 7ë°° ê°ì†Œì‹œí‚µë‹ˆë‹¤.
- 4. XAutoLMì€ ì œë¡œìƒ· ìµœì í™”ê¸°ì˜ ìµœê³  F1 ì ìˆ˜ë¥¼ 6ê°œ ì¤‘ 5ê°œì˜ ì‘ì—…ì—ì„œ ì´ˆê³¼í•˜ë©°, ì œë¡œìƒ· íŒŒë ˆí†  ì „ì„  ìœ„ì˜ íŒŒì´í”„ë¼ì¸ì„ ìµœëŒ€ 50% ë” ë§ì´ ë°œê²¬í•©ë‹ˆë‹¤.
- 5. XAutoLMê³¼ ê²½í—˜ ì €ì¥ì†ŒëŠ” NLP ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ìì› íš¨ìœ¨ì ì´ê³  í™˜ê²½ ì¹œí™”ì ì¸ AI ë¯¸ì„¸ ì¡°ì •ì„ ì´‰ì§„í•˜ê¸° ìœ„í•´ ê³µê°œë©ë‹ˆë‹¤.


---

*Generated on 2025-09-23 11:49:58*