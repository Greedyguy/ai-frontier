---
keywords:
  - Thermodynamic Computer
  - Gradient Descent
  - Neural Network
  - Finite-Time Dynamics
category: cs.LG
publish_date: 2025-09-22
arxiv_id: 2509.15324
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T10:47:35.822950",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Thermodynamic Computer",
    "Gradient Descent",
    "Neural Network",
    "Finite-Time Dynamics"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Thermodynamic Computer": 0.78,
    "Gradient Descent": 0.85,
    "Neural Network": 0.88,
    "Finite-Time Dynamics": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "thermodynamic computer",
        "canonical": "Thermodynamic Computer",
        "aliases": [
          "thermodynamic computing device"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel concept in computing that links thermodynamics with computation.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.78
      },
      {
        "surface": "gradient descent",
        "canonical": "Gradient Descent",
        "aliases": [
          "gradient optimization"
        ],
        "category": "broad_technical",
        "rationale": "A fundamental optimization technique widely used in machine learning.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "neural network",
        "canonical": "Neural Network",
        "aliases": [
          "NN"
        ],
        "category": "broad_technical",
        "rationale": "Core component of the described computation, linking to machine learning.",
        "novelty_score": 0.2,
        "connectivity_score": 0.95,
        "specificity_score": 0.7,
        "link_intent_score": 0.88
      },
      {
        "surface": "finite-time dynamics",
        "canonical": "Finite-Time Dynamics",
        "aliases": [
          "finite time behavior"
        ],
        "category": "unique_technical",
        "rationale": "Describes a specific behavior of the thermodynamic computer relevant to computation.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "method",
      "computation",
      "probability",
      "parameters"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "thermodynamic computer",
      "resolved_canonical": "Thermodynamic Computer",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "gradient descent",
      "resolved_canonical": "Gradient Descent",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "neural network",
      "resolved_canonical": "Neural Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.2,
        "connectivity": 0.95,
        "specificity": 0.7,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "finite-time dynamics",
      "resolved_canonical": "Finite-Time Dynamics",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# Training thermodynamic computers by gradient descent

**Korean Title:** ì—´ì—­í•™ ì»´í“¨í„°ì˜ ê²½ì‚¬ í•˜ê°•ë²•ì„ í†µí•œ í›ˆë ¨

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15324.pdf)
**Category**: cs.LG
**Published**: 2025-09-22
**ArXiv ID**: [2509.15324](https://arxiv.org/abs/2509.15324)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/Low-rank surrogate modeling and stochastic zero-order optimization for training of neural networks with black-box layers_20250918|Low-rank surrogate modeling and stochastic zero-order optimization for training of neural networks with black-box layers]] (83.4% similar)
- [[2025-09-22/Analog In-memory Training on General Non-ideal Resistive Elements_ The Impact of Response Functions_20250922|Analog In-memory Training on General Non-ideal Resistive Elements: The Impact of Response Functions]] (81.9% similar)
- [[2025-09-19/Trainability of Quantum Models Beyond Known Classical Simulability_20250919|Trainability of Quantum Models Beyond Known Classical Simulability]] (80.7% similar)
- [[2025-09-22/Double descent in quantum kernel methods_20250922|Double descent in quantum kernel methods]] (80.4% similar)
- [[2025-09-18/Data coarse graining can improve model performance_20250918|Data coarse graining can improve model performance]] (80.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Gradient Descent|Gradient Descent]], [[keywords/Neural Network|Neural Network]]
**âš¡ Unique Technical**: [[keywords/Thermodynamic Computer|Thermodynamic Computer]], [[keywords/Finite-Time Dynamics|Finite-Time Dynamics]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15324v1 Announce Type: cross 
Abstract: We show how to adjust the parameters of a thermodynamic computer by gradient descent in order to perform a desired computation at a specified observation time. Within a digital simulation of a thermodynamic computer, training proceeds by maximizing the probability with which the computer would generate an idealized dynamical trajectory. The idealized trajectory is designed to reproduce the activations of a neural network trained to perform the desired computation. This teacher-student scheme results in a thermodynamic computer whose finite-time dynamics enacts a computation analogous to that of the neural network. The parameters identified in this way can be implemented in the hardware realization of the thermodynamic computer, which will perform the desired computation automatically, driven by thermal noise. We demonstrate the method on a standard image-classification task, and estimate the thermodynamic advantage -- the ratio of energy costs of the digital and thermodynamic implementations -- to exceed seven orders of magnitude. Our results establish gradient descent as a viable training method for thermodynamic computing, enabling application of the core methodology of machine learning to this emerging field.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15324v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ìš°ë¦¬ëŠ” ì§€ì •ëœ ê´€ì°° ì‹œê°„ì— ì›í•˜ëŠ” ê³„ì‚°ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ ì—´ì—­í•™ì  ì»´í“¨í„°ì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ê²½ì‚¬ í•˜ê°•ë²•ìœ¼ë¡œ ì¡°ì •í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì—´ì—­í•™ì  ì»´í“¨í„°ì˜ ë””ì§€í„¸ ì‹œë®¬ë ˆì´ì…˜ ë‚´ì—ì„œ í›ˆë ¨ì€ ì»´í“¨í„°ê°€ ì´ìƒí™”ëœ ë™ì  ê¶¤ì ì„ ìƒì„±í•  í™•ë¥ ì„ ìµœëŒ€í™”í•¨ìœ¼ë¡œì¨ ì§„í–‰ë©ë‹ˆë‹¤. ì´ìƒí™”ëœ ê¶¤ì ì€ ì›í•˜ëŠ” ê³„ì‚°ì„ ìˆ˜í–‰í•˜ë„ë¡ í›ˆë ¨ëœ ì‹ ê²½ë§ì˜ í™œì„±í™”ë¥¼ ì¬í˜„í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ êµì‚¬-í•™ìƒ ë°©ì‹ì€ ìœ í•œ ì‹œê°„ ë™ì—­í•™ì´ ì‹ ê²½ë§ì˜ ê³„ì‚°ê³¼ ìœ ì‚¬í•œ ê³„ì‚°ì„ ìˆ˜í–‰í•˜ëŠ” ì—´ì—­í•™ì  ì»´í“¨í„°ë¥¼ ê²°ê³¼ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤. ì´ì™€ ê°™ì´ ì‹ë³„ëœ ë§¤ê°œë³€ìˆ˜ëŠ” ì—´ì—­í•™ì  ì»´í“¨í„°ì˜ í•˜ë“œì›¨ì–´ êµ¬í˜„ì— ì ìš©ë  ìˆ˜ ìˆìœ¼ë©°, ì´ëŠ” ì—´ ì¡ìŒì— ì˜í•´ ìë™ìœ¼ë¡œ ì›í•˜ëŠ” ê³„ì‚°ì„ ìˆ˜í–‰í•  ê²ƒì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” í‘œì¤€ ì´ë¯¸ì§€ ë¶„ë¥˜ ì‘ì—…ì— ì´ ë°©ë²•ì„ ì‹œì—°í•˜ê³ , ë””ì§€í„¸ ë° ì—´ì—­í•™ì  êµ¬í˜„ì˜ ì—ë„ˆì§€ ë¹„ìš© ë¹„ìœ¨ì¸ ì—´ì—­í•™ì  ì´ì ì„ 7ì°¨ ì´ìƒì˜ í¬ê¸°ë¡œ ì´ˆê³¼í•œë‹¤ê³  ì¶”ì •í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ê²°ê³¼ëŠ” ì—´ì—­í•™ì  ì»´í“¨íŒ…ì„ ìœ„í•œ ìœ íš¨í•œ í›ˆë ¨ ë°©ë²•ìœ¼ë¡œì„œ ê²½ì‚¬ í•˜ê°•ë²•ì„ í™•ë¦½í•˜ë©°, ì´ ì‹ í¥ ë¶„ì•¼ì— ê¸°ê³„ í•™ìŠµì˜ í•µì‹¬ ë°©ë²•ë¡ ì„ ì ìš©í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì—´ì—­í•™ì  ì»´í“¨í„°ì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ê²½ì‚¬ í•˜ê°•ë²•ì„ í†µí•´ ì¡°ì •í•˜ì—¬ ì›í•˜ëŠ” ê³„ì‚°ì„ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ë””ì§€í„¸ ì‹œë®¬ë ˆì´ì…˜ ë‚´ì—ì„œ, ì´ìƒì ì¸ ë™ì  ê¶¤ì ì„ ìƒì„±í•  í™•ë¥ ì„ ìµœëŒ€í™”í•˜ì—¬ ì»´í“¨í„°ë¥¼ í›ˆë ¨í•©ë‹ˆë‹¤. ì´ ê¶¤ì ì€ ì‹ ê²½ë§ì˜ í™œì„±í™”ë¥¼ ì¬í˜„í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ë°©ë²•ì€ ì—´ì—­í•™ì  ì»´í“¨í„°ê°€ ì‹ ê²½ë§ê³¼ ìœ ì‚¬í•œ ê³„ì‚°ì„ ìˆ˜í–‰í•˜ë„ë¡ í•©ë‹ˆë‹¤. í•˜ë“œì›¨ì–´ êµ¬í˜„ ì‹œ, ì—´ ì¡ìŒì— ì˜í•´ ìë™ìœ¼ë¡œ ì›í•˜ëŠ” ê³„ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì´ë¯¸ì§€ ë¶„ë¥˜ ì‘ì—…ì— ì´ ë°©ë²•ì„ ì ìš©í•œ ê²°ê³¼, ë””ì§€í„¸ êµ¬í˜„ ëŒ€ë¹„ ì—ë„ˆì§€ ë¹„ìš©ì´ 7ìë¦¿ìˆ˜ ì´ìƒ ì ˆê°ë˜ëŠ” ì—´ì—­í•™ì  ì´ì ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ì—´ì—­í•™ì  ì»´í“¨íŒ…ì—ì„œ ê²½ì‚¬ í•˜ê°•ë²•ì´ ìœ íš¨í•œ í›ˆë ¨ ë°©ë²•ì„ì„ ì…ì¦í•˜ë©°, ê¸°ê³„ í•™ìŠµì˜ í•µì‹¬ ë°©ë²•ë¡ ì„ ì´ ë¶„ì•¼ì— ì ìš©í•  ìˆ˜ ìˆëŠ” ê°€ëŠ¥ì„±ì„ ì—´ì—ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì—´ì—­í•™ì  ì»´í“¨í„°ì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ê²½ì‚¬ í•˜ê°•ë²•ìœ¼ë¡œ ì¡°ì •í•˜ì—¬ ì›í•˜ëŠ” ê³„ì‚°ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ë°©ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤.
- 2. ë””ì§€í„¸ ì‹œë®¬ë ˆì´ì…˜ ë‚´ì—ì„œ ì´ìƒì ì¸ ë™ì  ê¶¤ì ì„ ìƒì„±í•  í™•ë¥ ì„ ìµœëŒ€í™”í•˜ì—¬ í›ˆë ¨ì„ ì§„í–‰í•©ë‹ˆë‹¤.
- 3. ì‹ ê²½ë§ì˜ í™œì„±í™”ë¥¼ ì¬í˜„í•˜ë„ë¡ ì„¤ê³„ëœ ì´ìƒì ì¸ ê¶¤ì ì„ í†µí•´ ì—´ì—­í•™ì  ì»´í“¨í„°ê°€ ìœ í•œ ì‹œê°„ ë‚´ì— ì‹ ê²½ë§ê³¼ ìœ ì‚¬í•œ ê³„ì‚°ì„ ìˆ˜í–‰í•˜ê²Œ í•©ë‹ˆë‹¤.
- 4. ì—´ì—­í•™ì  êµ¬í˜„ì˜ ì—ë„ˆì§€ ë¹„ìš©ì´ ë””ì§€í„¸ êµ¬í˜„ë³´ë‹¤ 7ìë¦¿ìˆ˜ ì´ìƒ ìš°ì›”í•˜ë‹¤ëŠ” ì—´ì—­í•™ì  ì´ì ì„ ì¶”ì •í•©ë‹ˆë‹¤.
- 5. ê²½ì‚¬ í•˜ê°•ë²•ì´ ì—´ì—­í•™ì  ì»´í“¨íŒ…ì„ ìœ„í•œ ìœ íš¨í•œ í›ˆë ¨ ë°©ë²•ì„ì„ ì…ì¦í•˜ì—¬ ê¸°ê³„ í•™ìŠµì˜ í•µì‹¬ ë°©ë²•ë¡ ì„ ì´ ìƒˆë¡œìš´ ë¶„ì•¼ì— ì ìš©í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-23 10:47:35*