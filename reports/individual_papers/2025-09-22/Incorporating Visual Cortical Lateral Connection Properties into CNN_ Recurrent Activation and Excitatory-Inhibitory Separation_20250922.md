---
keywords:
  - Neural Network
  - Lateral Connections
  - Recurrent Activation
  - Excitatory-Inhibitory Separation
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2509.15460
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T08:59:47.540821",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Neural Network",
    "Lateral Connections",
    "Recurrent Activation",
    "Excitatory-Inhibitory Separation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Neural Network": 0.85,
    "Lateral Connections": 0.78,
    "Recurrent Activation": 0.8,
    "Excitatory-Inhibitory Separation": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Convolutional Neural Networks",
        "canonical": "Neural Network",
        "aliases": [
          "CNN",
          "Convolutional Networks"
        ],
        "category": "broad_technical",
        "rationale": "CNNs are a foundational concept in deep learning and computer vision, linking to a wide range of related research.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Visual Cortical Lateral Connections",
        "canonical": "Lateral Connections",
        "aliases": [
          "Horizontal Connections"
        ],
        "category": "unique_technical",
        "rationale": "This concept is central to the paper's contribution and connects to biological neural network studies.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Recurrent Activation",
        "canonical": "Recurrent Activation",
        "aliases": [
          "Recurrent Processing"
        ],
        "category": "unique_technical",
        "rationale": "Recurrent activation is a specific mechanism explored in the paper, linking to studies on temporal dynamics in neural networks.",
        "novelty_score": 0.68,
        "connectivity_score": 0.7,
        "specificity_score": 0.75,
        "link_intent_score": 0.8
      },
      {
        "surface": "Excitatory-Inhibitory Separation",
        "canonical": "Excitatory-Inhibitory Separation",
        "aliases": [
          "E-I Separation"
        ],
        "category": "unique_technical",
        "rationale": "This separation is a novel architectural feature proposed in the paper, relevant to neural computation studies.",
        "novelty_score": 0.72,
        "connectivity_score": 0.6,
        "specificity_score": 0.78,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Convolutional Neural Networks",
      "resolved_canonical": "Neural Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Visual Cortical Lateral Connections",
      "resolved_canonical": "Lateral Connections",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Recurrent Activation",
      "resolved_canonical": "Recurrent Activation",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.7,
        "specificity": 0.75,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Excitatory-Inhibitory Separation",
      "resolved_canonical": "Excitatory-Inhibitory Separation",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.6,
        "specificity": 0.78,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Incorporating Visual Cortical Lateral Connection Properties into CNN: Recurrent Activation and Excitatory-Inhibitory Separation

**Korean Title:** ì‹œê° í”¼ì§ˆì˜ ì¸¡ë©´ ì—°ê²° íŠ¹ì„±ì„ CNNì— í†µí•©í•˜ê¸°: ìˆœí™˜ í™œì„±í™”ì™€ í¥ë¶„-ì–µì œ ë¶„ë¦¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15460.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2509.15460](https://arxiv.org/abs/2509.15460)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Modeling the Human Visual System_ Comparative Insights from Response-Optimized and Task-Optimized Vision Models, Language Models, and different Readout Mechanisms_20250922|Modeling the Human Visual System: Comparative Insights from Response-Optimized and Task-Optimized Vision Models, Language Models, and different Readout Mechanisms]] (80.3% similar)
- [[2025-09-22/Deformable Dynamic Convolution for Accurate yet Efficient Spatio-Temporal Traffic Prediction_20250922|Deformable Dynamic Convolution for Accurate yet Efficient Spatio-Temporal Traffic Prediction]] (79.8% similar)
- [[2025-09-19/Leveraging Geometric Visual Illusions as Perceptual Inductive Biases for Vision Models_20250919|Leveraging Geometric Visual Illusions as Perceptual Inductive Biases for Vision Models]] (79.5% similar)
- [[2025-09-22/Uncertainty-Gated Deformable Network for Breast Tumor Segmentation in MR Images_20250922|Uncertainty-Gated Deformable Network for Breast Tumor Segmentation in MR Images]] (78.6% similar)
- [[2025-09-22/Emulating Human-like Adaptive Vision for Efficient and Flexible Machine Visual Perception_20250922|Emulating Human-like Adaptive Vision for Efficient and Flexible Machine Visual Perception]] (78.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Neural Network|Neural Network]]
**âš¡ Unique Technical**: [[keywords/Lateral Connections|Lateral Connections]], [[keywords/Recurrent Activation|Recurrent Activation]], [[keywords/Excitatory-Inhibitory Separation|Excitatory-Inhibitory Separation]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15460v1 Announce Type: cross 
Abstract: The original Convolutional Neural Networks (CNNs) and their modern updates such as the ResNet are heavily inspired by the mammalian visual system. These models include afferent connections (retina and LGN to the visual cortex) and long-range projections (connections across different visual cortical areas). However, in the mammalian visual system, there are connections within each visual cortical area, known as lateral (or horizontal) connections. These would roughly correspond to connections within CNN feature maps, and this important architectural feature is missing in current CNN models. In this paper, we present how such lateral connections can be modeled within the standard CNN framework, and test its benefits and analyze its emergent properties in relation to the biological visual system. We will focus on two main architectural features of lateral connections: (1) recurrent activation and (2) separation of excitatory and inhibitory connections. We show that recurrent CNN using weight sharing is equivalent to lateral connections, and propose a custom loss function to separate excitatory and inhibitory weights. The addition of these two leads to increased classification accuracy, and importantly, the activation properties and connection properties of the resulting model show properties similar to those observed in the biological visual system. We expect our approach to help align CNN closer to its biological counterpart and better understand the principles of visual cortical computation.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15460v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ì›ë˜ì˜ í•©ì„±ê³± ì‹ ê²½ë§(CNN)ê³¼ ResNetê³¼ ê°™ì€ í˜„ëŒ€ì  ì—…ë°ì´íŠ¸ëŠ” í¬ìœ ë¥˜ì˜ ì‹œê° ì‹œìŠ¤í…œì—ì„œ í¬ê²Œ ì˜ê°ì„ ë°›ì•˜ìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ëª¨ë¸ì€ êµ¬ì‹¬ì„± ì—°ê²°(ë§ë§‰ê³¼ ì‹œìƒ LGNì—ì„œ ì‹œê° í”¼ì§ˆë¡œ)ê³¼ ì¥ê±°ë¦¬ íˆ¬ì‚¬(ë‹¤ì–‘í•œ ì‹œê° í”¼ì§ˆ ì˜ì—­ ê°„ì˜ ì—°ê²°)ë¥¼ í¬í•¨í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ í¬ìœ ë¥˜ì˜ ì‹œê° ì‹œìŠ¤í…œì—ì„œëŠ” ê° ì‹œê° í”¼ì§ˆ ì˜ì—­ ë‚´ì— ìˆëŠ” ì—°ê²°, ì¦‰ ì¸¡ë©´(ë˜ëŠ” ìˆ˜í‰) ì—°ê²°ì´ ì¡´ì¬í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì—°ê²°ì€ ëŒ€ëµì ìœ¼ë¡œ CNN íŠ¹ì§• ë§µ ë‚´ì˜ ì—°ê²°ì— í•´ë‹¹í•˜ë©°, ì´ ì¤‘ìš”í•œ êµ¬ì¡°ì  íŠ¹ì§•ì€ í˜„ì¬ì˜ CNN ëª¨ë¸ì—ì„œ ëˆ„ë½ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ ë…¼ë¬¸ì—ì„œëŠ” í‘œì¤€ CNN í”„ë ˆì„ì›Œí¬ ë‚´ì—ì„œ ì´ëŸ¬í•œ ì¸¡ë©´ ì—°ê²°ì„ ì–´ë–»ê²Œ ëª¨ë¸ë§í•  ìˆ˜ ìˆëŠ”ì§€ ì œì‹œí•˜ê³ , ê·¸ ì´ì ê³¼ ìƒë¬¼í•™ì  ì‹œê° ì‹œìŠ¤í…œê³¼ì˜ ê´€ê³„ì—ì„œ ë°œìƒí•˜ëŠ” íŠ¹ì„±ì„ ë¶„ì„í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì¸¡ë©´ ì—°ê²°ì˜ ë‘ ê°€ì§€ ì£¼ìš” êµ¬ì¡°ì  íŠ¹ì§•ì— ì¤‘ì ì„ ë‘˜ ê²ƒì…ë‹ˆë‹¤: (1) ì¬ê·€ì  í™œì„±í™”ì™€ (2) í¥ë¶„ì„± ë° ì–µì œì„± ì—°ê²°ì˜ ë¶„ë¦¬. ìš°ë¦¬ëŠ” ê°€ì¤‘ì¹˜ ê³µìœ ë¥¼ ì‚¬ìš©í•˜ëŠ” ì¬ê·€ì  CNNì´ ì¸¡ë©´ ì—°ê²°ê³¼ ë™ë“±í•˜ë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì£¼ê³ , í¥ë¶„ì„± ë° ì–µì œì„± ê°€ì¤‘ì¹˜ë¥¼ ë¶„ë¦¬í•˜ê¸° ìœ„í•œ ë§ì¶¤í˜• ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ë‘ ê°€ì§€ë¥¼ ì¶”ê°€í•˜ë©´ ë¶„ë¥˜ ì •í™•ë„ê°€ ì¦ê°€í•˜ê³ , ê²°ê³¼ ëª¨ë¸ì˜ í™œì„±í™” íŠ¹ì„±ê³¼ ì—°ê²° íŠ¹ì„±ì€ ìƒë¬¼í•™ì  ì‹œê° ì‹œìŠ¤í…œì—ì„œ ê´€ì°°ë˜ëŠ” íŠ¹ì„±ê³¼ ìœ ì‚¬í•œ íŠ¹ì„±ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ìš°ë¦¬ì˜ ì ‘ê·¼ ë°©ì‹ì´ CNNì„ ìƒë¬¼í•™ì  ëŒ€ì‘ë¬¼ì— ë” ê°€ê¹ê²Œ ì •ë ¬í•˜ê³  ì‹œê° í”¼ì§ˆ ê³„ì‚°ì˜ ì›ë¦¬ë¥¼ ë” ì˜ ì´í•´í•˜ëŠ” ë° ë„ì›€ì´ ë˜ê¸°ë¥¼ ê¸°ëŒ€í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ê¸°ì¡´ì˜ CNN ëª¨ë¸ì— ê²°ì—¬ëœ ì¸¡ë©´ ì—°ê²°(lateral connections)ì„ ë„ì…í•˜ì—¬ ìƒë¬¼í•™ì  ì‹œê° ì‹œìŠ¤í…œê³¼ì˜ ìœ ì‚¬ì„±ì„ ë†’ì´ê³ ì í•©ë‹ˆë‹¤. ì €ìë“¤ì€ CNN ë‚´ì—ì„œ ì¸¡ë©´ ì—°ê²°ì„ ëª¨ë¸ë§í•˜ê³ , ê·¸ ì´ì ì„ ì‹¤í—˜ì ìœ¼ë¡œ ë¶„ì„í–ˆìŠµë‹ˆë‹¤. ì£¼ìš” ë°©ë²•ë¡ ì€ (1) ì¬ê·€ì  í™œì„±í™”ì™€ (2) í¥ë¶„ì„± ë° ì–µì œì„± ì—°ê²°ì˜ ë¶„ë¦¬ë¥¼ í¬í•¨í•©ë‹ˆë‹¤. ì¬ê·€ì  CNNì€ ê°€ì¤‘ì¹˜ ê³µìœ ë¥¼ í†µí•´ ì¸¡ë©´ ì—°ê²°ê³¼ ë™ë“±í•˜ê²Œ êµ¬í˜„ë˜ë©°, ë§ì¶¤í˜• ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ í¥ë¶„ì„± ë° ì–µì œì„± ê°€ì¤‘ì¹˜ë¥¼ ë¶„ë¦¬í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì ‘ê·¼ì€ ë¶„ë¥˜ ì •í™•ë„ë¥¼ í–¥ìƒì‹œí‚¤ê³ , ëª¨ë¸ì˜ í™œì„±í™” ë° ì—°ê²° íŠ¹ì„±ì´ ìƒë¬¼í•™ì  ì‹œê° ì‹œìŠ¤í…œê³¼ ìœ ì‚¬í•œ íŠ¹ì„±ì„ ë³´ì„ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” CNNì„ ìƒë¬¼í•™ì  ì‹œê° ì‹œìŠ¤í…œì— ë” ê°€ê¹ê²Œ ë§ì¶”ê³ , ì‹œê° í”¼ì§ˆ ê³„ì‚°ì˜ ì›ë¦¬ë¥¼ ì´í•´í•˜ëŠ” ë° ê¸°ì—¬í•  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ê¸°ì¡´ì˜ CNN ëª¨ë¸ì€ í¬ìœ ë¥˜ì˜ ì‹œê° ì‹œìŠ¤í…œì—ì„œ ì˜ê°ì„ ë°›ì•„ ì„¤ê³„ë˜ì—ˆìœ¼ë‚˜, ì‹œê° í”¼ì§ˆ ë‚´ì˜ ê°€ë¡œ ì—°ê²°ì´ ë¶€ì¡±í•˜ë‹¤.
- 2. ë…¼ë¬¸ì—ì„œëŠ” CNN í”„ë ˆì„ì›Œí¬ ë‚´ì—ì„œ ê°€ë¡œ ì—°ê²°ì„ ëª¨ë¸ë§í•˜ëŠ” ë°©ë²•ì„ ì œì‹œí•˜ê³ , ê·¸ ì´ì ì„ í…ŒìŠ¤íŠ¸í•˜ê³  ë¶„ì„í•œë‹¤.
- 3. ê°€ë¡œ ì—°ê²°ì˜ ì£¼ìš” íŠ¹ì§•ìœ¼ë¡œëŠ” ì¬ê·€ì  í™œì„±í™”ì™€ í¥ë¶„ì„± ë° ì–µì œì„± ì—°ê²°ì˜ ë¶„ë¦¬ê°€ ìˆë‹¤.
- 4. ì œì•ˆëœ ëª¨ë¸ì€ ë¶„ë¥˜ ì •í™•ë„ë¥¼ ë†’ì´ê³ , ìƒë¬¼í•™ì  ì‹œê° ì‹œìŠ¤í…œê³¼ ìœ ì‚¬í•œ í™œì„±í™” ë° ì—°ê²° íŠ¹ì„±ì„ ë³´ì¸ë‹¤.
- 5. ì´ ì ‘ê·¼ë²•ì€ CNNì„ ìƒë¬¼í•™ì  ì‹œê° ì‹œìŠ¤í…œì— ë” ê°€ê¹ê²Œ ì •ë ¬í•˜ê³  ì‹œê° í”¼ì§ˆ ê³„ì‚°ì˜ ì›ë¦¬ë¥¼ ì´í•´í•˜ëŠ” ë° ë„ì›€ì„ ì¤„ ê²ƒìœ¼ë¡œ ê¸°ëŒ€ëœë‹¤.


---

*Generated on 2025-09-23 08:59:47*