---
keywords:
  - Algorithmic Fairness
  - Artificial Intelligence
  - Machine Learning
  - Intersectional Contexts
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2506.12556
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T10:03:31.253440",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Algorithmic Fairness",
    "Artificial Intelligence",
    "Machine Learning",
    "Intersectional Contexts"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Algorithmic Fairness": 0.9,
    "Artificial Intelligence": 0.8,
    "Machine Learning": 0.8,
    "Intersectional Contexts": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "algorithmic fairness",
        "canonical": "Algorithmic Fairness",
        "aliases": [
          "fairness in AI",
          "AI fairness"
        ],
        "category": "unique_technical",
        "rationale": "Algorithmic Fairness is central to the paper's discussion and connects socio-technical aspects with AI deployment.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.9
      },
      {
        "surface": "artificial intelligence",
        "canonical": "Artificial Intelligence",
        "aliases": [
          "AI"
        ],
        "category": "broad_technical",
        "rationale": "Artificial Intelligence is a foundational concept that underpins the entire discussion of fairness in socio-technical systems.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.8
      },
      {
        "surface": "machine learning",
        "canonical": "Machine Learning",
        "aliases": [
          "ML"
        ],
        "category": "broad_technical",
        "rationale": "Machine Learning is a key area where fairness issues are being actively researched and addressed.",
        "novelty_score": 0.3,
        "connectivity_score": 0.85,
        "specificity_score": 0.6,
        "link_intent_score": 0.8
      },
      {
        "surface": "intersectional contexts",
        "canonical": "Intersectional Contexts",
        "aliases": [
          "intersectionality in AI"
        ],
        "category": "unique_technical",
        "rationale": "Intersectional Contexts highlight the complexity of fairness issues beyond binary group settings, crucial for nuanced discussions.",
        "novelty_score": 0.65,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "trustworthiness",
      "mathematical definitions",
      "empirical illustrations"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "algorithmic fairness",
      "resolved_canonical": "Algorithmic Fairness",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.9
      }
    },
    {
      "candidate_surface": "artificial intelligence",
      "resolved_canonical": "Artificial Intelligence",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "machine learning",
      "resolved_canonical": "Machine Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.85,
        "specificity": 0.6,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "intersectional contexts",
      "resolved_canonical": "Intersectional Contexts",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# Algorithmic Fairness: Not a Purely Technical but Socio-Technical Property

**Korean Title:** ì•Œê³ ë¦¬ì¦˜ ê³µì •ì„±: ìˆœìˆ˜í•œ ê¸°ìˆ ì  ì†ì„±ì´ ì•„ë‹Œ ì‚¬íšŒ-ê¸°ìˆ ì  ì†ì„±

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2506.12556.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2506.12556](https://arxiv.org/abs/2506.12556)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Where Fact Ends and Fairness Begins_ Redefining AI Bias Evaluation through Cognitive Biases_20250922|Where Fact Ends and Fairness Begins: Redefining AI Bias Evaluation through Cognitive Biases]] (85.5% similar)
- [[2025-09-22/AI for Scientific Discovery is a Social Problem_20250922|AI for Scientific Discovery is a Social Problem]] (84.2% similar)
- [[2025-09-17/APFEx_ Adaptive Pareto Front Explorer for Intersectional Fairness_20250917|APFEx: Adaptive Pareto Front Explorer for Intersectional Fairness]] (83.1% similar)
- [[2025-09-22/Fairness-in-the-Workflow_ How Machine Learning Practitioners at Big Tech Companies Approach Fairness in Recommender Systems_20250922|Fairness-in-the-Workflow: How Machine Learning Practitioners at Big Tech Companies Approach Fairness in Recommender Systems]] (82.9% similar)
- [[2025-09-22/Who is Responsible When AI Fails? Mapping Causes, Entities, and Consequences of AI Privacy and Ethical Incidents_20250922|Who is Responsible When AI Fails? Mapping Causes, Entities, and Consequences of AI Privacy and Ethical Incidents]] (82.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Artificial Intelligence|Artificial Intelligence]], [[keywords/Machine Learning|Machine Learning]]
**âš¡ Unique Technical**: [[keywords/Algorithmic Fairness|Algorithmic Fairness]], [[keywords/Intersectional Contexts|Intersectional Contexts]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2506.12556v2 Announce Type: replace-cross 
Abstract: The rapid trend of deploying artificial intelligence (AI) and machine learning (ML) systems in socially consequential domains has raised growing concerns about their trustworthiness, including potential discriminatory behaviours. Research in algorithmic fairness has generated a proliferation of mathematical definitions and metrics, yet persistent misconceptions and limitations -- both within and beyond the fairness community -- limit their effectiveness, such as an unreached consensus on its understanding, prevailing measures primarily tailored to binary group settings, and superficial handling for intersectional contexts. Here we critically remark on these misconceptions and argue that fairness cannot be reduced to purely technical constraints on models; we also examine the limitations of existing fairness measures through conceptual analysis and empirical illustrations, showing their limited applicability in the face of complex real-world scenarios, challenging prevailing views on the incompatibility between accuracy and fairness as well as that among fairness measures themselves, and outlining three worth-considering principles in the design of fairness measures. We believe these findings will help bridge the gap between technical formalisation and social realities and meet the challenges of real-world AI/ML deployment.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2506.12556v2 ë°œí‘œ ìœ í˜•: êµì°¨ êµì²´  
ì´ˆë¡: ì‚¬íšŒì ìœ¼ë¡œ ì¤‘ìš”í•œ ë¶„ì•¼ì— ì¸ê³µì§€ëŠ¥(AI) ë° ê¸°ê³„ í•™ìŠµ(ML) ì‹œìŠ¤í…œì„ ë°°ì¹˜í•˜ëŠ” ê¸‰ì†í•œ ì¶”ì„¸ëŠ” ì ì¬ì ì¸ ì°¨ë³„ì  í–‰ë™ì„ í¬í•¨í•˜ì—¬ ì´ë“¤ì˜ ì‹ ë¢°ì„±ì— ëŒ€í•œ ìš°ë ¤ë¥¼ ì¦ê°€ì‹œì¼°ìŠµë‹ˆë‹¤. ì•Œê³ ë¦¬ì¦˜ ê³µì •ì„± ì—°êµ¬ëŠ” ìˆ˜í•™ì  ì •ì˜ì™€ ì§€í‘œì˜ í™•ì‚°ì„ ê°€ì ¸ì™”ì§€ë§Œ, ê³µì •ì„± ì»¤ë®¤ë‹ˆí‹° ë‚´ì™¸ë¶€ì—ì„œì˜ ì§€ì†ì ì¸ ì˜¤í•´ì™€ í•œê³„ëŠ” ê·¸ íš¨ê³¼ì„±ì„ ì œí•œí•˜ê³  ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê³µì •ì„±ì— ëŒ€í•œ ì´í•´ì— ëŒ€í•œ í•©ì˜ê°€ ì´ë£¨ì–´ì§€ì§€ ì•Šì•˜ê³ , ê¸°ì¡´ì˜ ì¸¡ì • ë°©ë²•ì€ ì£¼ë¡œ ì´ì§„ ê·¸ë£¹ ì„¤ì •ì— ë§ì¶°ì ¸ ìˆìœ¼ë©°, êµì°¨ì  ë§¥ë½ì— ëŒ€í•œ í”¼ìƒì ì¸ ì²˜ë¦¬ê°€ ì´ë£¨ì–´ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œ ìš°ë¦¬ëŠ” ì´ëŸ¬í•œ ì˜¤í•´ë¥¼ ë¹„íŒì ìœ¼ë¡œ ì§€ì í•˜ê³ , ê³µì •ì„±ì´ ëª¨ë¸ì— ëŒ€í•œ ìˆœìˆ˜í•œ ê¸°ìˆ ì  ì œì•½ìœ¼ë¡œ ì¶•ì†Œë  ìˆ˜ ì—†ìŒì„ ì£¼ì¥í•©ë‹ˆë‹¤. ë˜í•œ ê¸°ì¡´ ê³µì •ì„± ì¸¡ì •ì˜ í•œê³„ë¥¼ ê°œë…ì  ë¶„ì„ê³¼ ì‹¤ì¦ì  ì˜ˆì‹œë¥¼ í†µí•´ ê²€í† í•˜ë©°, ë³µì¡í•œ í˜„ì‹¤ ì„¸ê³„ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œì˜ ì œí•œëœ ì ìš© ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì£¼ê³ , ì •í™•ì„±ê³¼ ê³µì •ì„± ê°„ì˜ ë¹„í˜¸í™˜ì„± ë° ê³µì •ì„± ì¸¡ì • ê°„ì˜ ë¹„í˜¸í™˜ì„±ì— ëŒ€í•œ ê¸°ì¡´ì˜ ê²¬í•´ì— ë„ì „í•˜ë©°, ê³µì •ì„± ì¸¡ì • ì„¤ê³„ì—ì„œ ê³ ë ¤í•  ê°€ì¹˜ê°€ ìˆëŠ” ì„¸ ê°€ì§€ ì›ì¹™ì„ ì œì‹œí•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì´ëŸ¬í•œ ë°œê²¬ì´ ê¸°ìˆ ì  í˜•ì‹í™”ì™€ ì‚¬íšŒì  í˜„ì‹¤ ê°„ì˜ ê²©ì°¨ë¥¼ ì¤„ì´ê³ , í˜„ì‹¤ ì„¸ê³„ì˜ AI/ML ë°°í¬ì˜ ë„ì „ì— ëŒ€ì‘í•˜ëŠ” ë° ë„ì›€ì´ ë  ê²ƒì´ë¼ê³  ë¯¿ìŠµë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì¸ê³µì§€ëŠ¥(AI)ê³¼ ê¸°ê³„ í•™ìŠµ(ML) ì‹œìŠ¤í…œì˜ ì‹ ë¢°ì„±, íŠ¹íˆ ì°¨ë³„ì  í–‰ë™ì— ëŒ€í•œ ìš°ë ¤ê°€ ì¦ê°€í•˜ëŠ” ê°€ìš´ë°, ì•Œê³ ë¦¬ì¦˜ ê³µì •ì„± ì—°êµ¬ì˜ í•œê³„ë¥¼ ë¹„íŒì ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ê³µì •ì„± ì¸¡ì • ë°©ë²•ë“¤ì´ ì´ì§„ ê·¸ë£¹ ì„¤ì •ì— ì£¼ë¡œ ë§ì¶°ì ¸ ìˆê³ , êµì°¨ì„± ë§¥ë½ì„ í”¼ìƒì ìœ¼ë¡œ ë‹¤ë£¨ëŠ” ë¬¸ì œë¥¼ ì§€ì í•˜ë©°, ê³µì •ì„±ì´ ë‹¨ìˆœí•œ ê¸°ìˆ ì  ì œì•½ìœ¼ë¡œ í™˜ì›ë  ìˆ˜ ì—†ìŒì„ ì£¼ì¥í•©ë‹ˆë‹¤. ë˜í•œ, ì •í™•ì„±ê³¼ ê³µì •ì„± ê°„ì˜ ë¶ˆì¼ì¹˜ì— ëŒ€í•œ ê¸°ì¡´ ê´€ì ì„ ë„ì „í•˜ê³ , ê³µì •ì„± ì¸¡ì • ì„¤ê³„ ì‹œ ê³ ë ¤í•´ì•¼ í•  ì„¸ ê°€ì§€ ì›ì¹™ì„ ì œì‹œí•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ë°œê²¬ì€ ê¸°ìˆ ì  í˜•ì‹í™”ì™€ ì‚¬íšŒì  í˜„ì‹¤ ê°„ì˜ ê²©ì°¨ë¥¼ ì¤„ì´ëŠ” ë° ê¸°ì—¬í•  ê²ƒì…ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì¸ê³µì§€ëŠ¥ ë° ê¸°ê³„ í•™ìŠµ ì‹œìŠ¤í…œì˜ ì‹ ë¢°ì„± ë¬¸ì œ, íŠ¹íˆ ì°¨ë³„ì  í–‰ë™ì— ëŒ€í•œ ìš°ë ¤ê°€ ì¦ê°€í•˜ê³  ìˆë‹¤.
- 2. ì•Œê³ ë¦¬ì¦˜ ê³µì •ì„± ì—°êµ¬ëŠ” ìˆ˜ë§ì€ ìˆ˜í•™ì  ì •ì˜ì™€ ì§€í‘œë¥¼ ìƒì„±í–ˆì§€ë§Œ, ì—¬ì „íˆ ì˜¤í•´ì™€ í•œê³„ê°€ ì¡´ì¬í•œë‹¤.
- 3. ê³µì •ì„±ì€ ë‹¨ìˆœíˆ ëª¨ë¸ì— ëŒ€í•œ ê¸°ìˆ ì  ì œì•½ìœ¼ë¡œ ì¶•ì†Œë  ìˆ˜ ì—†ìœ¼ë©°, ê¸°ì¡´ ê³µì •ì„± ì¸¡ì • ë°©ë²•ì˜ í•œê³„ë¥¼ ë¹„íŒì ìœ¼ë¡œ ë¶„ì„í•œë‹¤.
- 4. ì •í™•ì„±ê³¼ ê³µì •ì„± ê°„ì˜ ë¹„í˜¸í™˜ì„± ë° ê³µì •ì„± ì¸¡ì • ê°„ì˜ ë¹„í˜¸í™˜ì„±ì— ëŒ€í•œ ê¸°ì¡´ ê´€ì ì„ ë„ì „í•œë‹¤.
- 5. ê³µì •ì„± ì¸¡ì • ì„¤ê³„ì—ì„œ ê³ ë ¤í•  ê°€ì¹˜ê°€ ìˆëŠ” ì„¸ ê°€ì§€ ì›ì¹™ì„ ì œì‹œí•˜ë©°, ê¸°ìˆ ì  í˜•ì‹í™”ì™€ ì‚¬íšŒì  í˜„ì‹¤ ê°„ì˜ ê²©ì°¨ë¥¼ ì¤„ì´ëŠ” ë° ê¸°ì—¬í•˜ê³ ì í•œë‹¤.


---

*Generated on 2025-09-23 10:03:31*