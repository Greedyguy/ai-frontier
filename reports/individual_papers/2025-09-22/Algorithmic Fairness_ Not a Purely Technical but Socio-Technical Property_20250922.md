---
keywords:
  - Algorithmic Fairness
  - Artificial Intelligence
  - Machine Learning
  - Intersectional Contexts
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2506.12556
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T10:03:31.253440",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Algorithmic Fairness",
    "Artificial Intelligence",
    "Machine Learning",
    "Intersectional Contexts"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Algorithmic Fairness": 0.9,
    "Artificial Intelligence": 0.8,
    "Machine Learning": 0.8,
    "Intersectional Contexts": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "algorithmic fairness",
        "canonical": "Algorithmic Fairness",
        "aliases": [
          "fairness in AI",
          "AI fairness"
        ],
        "category": "unique_technical",
        "rationale": "Algorithmic Fairness is central to the paper's discussion and connects socio-technical aspects with AI deployment.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.9
      },
      {
        "surface": "artificial intelligence",
        "canonical": "Artificial Intelligence",
        "aliases": [
          "AI"
        ],
        "category": "broad_technical",
        "rationale": "Artificial Intelligence is a foundational concept that underpins the entire discussion of fairness in socio-technical systems.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.8
      },
      {
        "surface": "machine learning",
        "canonical": "Machine Learning",
        "aliases": [
          "ML"
        ],
        "category": "broad_technical",
        "rationale": "Machine Learning is a key area where fairness issues are being actively researched and addressed.",
        "novelty_score": 0.3,
        "connectivity_score": 0.85,
        "specificity_score": 0.6,
        "link_intent_score": 0.8
      },
      {
        "surface": "intersectional contexts",
        "canonical": "Intersectional Contexts",
        "aliases": [
          "intersectionality in AI"
        ],
        "category": "unique_technical",
        "rationale": "Intersectional Contexts highlight the complexity of fairness issues beyond binary group settings, crucial for nuanced discussions.",
        "novelty_score": 0.65,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "trustworthiness",
      "mathematical definitions",
      "empirical illustrations"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "algorithmic fairness",
      "resolved_canonical": "Algorithmic Fairness",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.9
      }
    },
    {
      "candidate_surface": "artificial intelligence",
      "resolved_canonical": "Artificial Intelligence",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "machine learning",
      "resolved_canonical": "Machine Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.85,
        "specificity": 0.6,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "intersectional contexts",
      "resolved_canonical": "Intersectional Contexts",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# Algorithmic Fairness: Not a Purely Technical but Socio-Technical Property

**Korean Title:** 알고리즘 공정성: 순수한 기술적 속성이 아닌 사회-기술적 속성

## 📋 메타데이터

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2506.12556.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2506.12556](https://arxiv.org/abs/2506.12556)

## 🔗 유사한 논문
- [[2025-09-22/Where Fact Ends and Fairness Begins_ Redefining AI Bias Evaluation through Cognitive Biases_20250922|Where Fact Ends and Fairness Begins: Redefining AI Bias Evaluation through Cognitive Biases]] (85.5% similar)
- [[2025-09-22/AI for Scientific Discovery is a Social Problem_20250922|AI for Scientific Discovery is a Social Problem]] (84.2% similar)
- [[2025-09-17/APFEx_ Adaptive Pareto Front Explorer for Intersectional Fairness_20250917|APFEx: Adaptive Pareto Front Explorer for Intersectional Fairness]] (83.1% similar)
- [[2025-09-22/Fairness-in-the-Workflow_ How Machine Learning Practitioners at Big Tech Companies Approach Fairness in Recommender Systems_20250922|Fairness-in-the-Workflow: How Machine Learning Practitioners at Big Tech Companies Approach Fairness in Recommender Systems]] (82.9% similar)
- [[2025-09-22/Who is Responsible When AI Fails? Mapping Causes, Entities, and Consequences of AI Privacy and Ethical Incidents_20250922|Who is Responsible When AI Fails? Mapping Causes, Entities, and Consequences of AI Privacy and Ethical Incidents]] (82.3% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Artificial Intelligence|Artificial Intelligence]], [[keywords/Machine Learning|Machine Learning]]
**⚡ Unique Technical**: [[keywords/Algorithmic Fairness|Algorithmic Fairness]], [[keywords/Intersectional Contexts|Intersectional Contexts]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2506.12556v2 Announce Type: replace-cross 
Abstract: The rapid trend of deploying artificial intelligence (AI) and machine learning (ML) systems in socially consequential domains has raised growing concerns about their trustworthiness, including potential discriminatory behaviours. Research in algorithmic fairness has generated a proliferation of mathematical definitions and metrics, yet persistent misconceptions and limitations -- both within and beyond the fairness community -- limit their effectiveness, such as an unreached consensus on its understanding, prevailing measures primarily tailored to binary group settings, and superficial handling for intersectional contexts. Here we critically remark on these misconceptions and argue that fairness cannot be reduced to purely technical constraints on models; we also examine the limitations of existing fairness measures through conceptual analysis and empirical illustrations, showing their limited applicability in the face of complex real-world scenarios, challenging prevailing views on the incompatibility between accuracy and fairness as well as that among fairness measures themselves, and outlining three worth-considering principles in the design of fairness measures. We believe these findings will help bridge the gap between technical formalisation and social realities and meet the challenges of real-world AI/ML deployment.

## 🔍 Abstract (한글 번역)

arXiv:2506.12556v2 발표 유형: 교차 교체  
초록: 사회적으로 중요한 분야에 인공지능(AI) 및 기계 학습(ML) 시스템을 배치하는 급속한 추세는 잠재적인 차별적 행동을 포함하여 이들의 신뢰성에 대한 우려를 증가시켰습니다. 알고리즘 공정성 연구는 수학적 정의와 지표의 확산을 가져왔지만, 공정성 커뮤니티 내외부에서의 지속적인 오해와 한계는 그 효과성을 제한하고 있습니다. 예를 들어, 공정성에 대한 이해에 대한 합의가 이루어지지 않았고, 기존의 측정 방법은 주로 이진 그룹 설정에 맞춰져 있으며, 교차적 맥락에 대한 피상적인 처리가 이루어지고 있습니다. 여기서 우리는 이러한 오해를 비판적으로 지적하고, 공정성이 모델에 대한 순수한 기술적 제약으로 축소될 수 없음을 주장합니다. 또한 기존 공정성 측정의 한계를 개념적 분석과 실증적 예시를 통해 검토하며, 복잡한 현실 세계 시나리오에서의 제한된 적용 가능성을 보여주고, 정확성과 공정성 간의 비호환성 및 공정성 측정 간의 비호환성에 대한 기존의 견해에 도전하며, 공정성 측정 설계에서 고려할 가치가 있는 세 가지 원칙을 제시합니다. 우리는 이러한 발견이 기술적 형식화와 사회적 현실 간의 격차를 줄이고, 현실 세계의 AI/ML 배포의 도전에 대응하는 데 도움이 될 것이라고 믿습니다.

## 📝 요약

이 논문은 인공지능(AI)과 기계 학습(ML) 시스템의 신뢰성, 특히 차별적 행동에 대한 우려가 증가하는 가운데, 알고리즘 공정성 연구의 한계를 비판적으로 분석합니다. 기존의 공정성 측정 방법들이 이진 그룹 설정에 주로 맞춰져 있고, 교차성 맥락을 피상적으로 다루는 문제를 지적하며, 공정성이 단순한 기술적 제약으로 환원될 수 없음을 주장합니다. 또한, 정확성과 공정성 간의 불일치에 대한 기존 관점을 도전하고, 공정성 측정 설계 시 고려해야 할 세 가지 원칙을 제시합니다. 이러한 발견은 기술적 형식화와 사회적 현실 간의 격차를 줄이는 데 기여할 것입니다.

## 🎯 주요 포인트

- 1. 인공지능 및 기계 학습 시스템의 신뢰성 문제, 특히 차별적 행동에 대한 우려가 증가하고 있다.
- 2. 알고리즘 공정성 연구는 수많은 수학적 정의와 지표를 생성했지만, 여전히 오해와 한계가 존재한다.
- 3. 공정성은 단순히 모델에 대한 기술적 제약으로 축소될 수 없으며, 기존 공정성 측정 방법의 한계를 비판적으로 분석한다.
- 4. 정확성과 공정성 간의 비호환성 및 공정성 측정 간의 비호환성에 대한 기존 관점을 도전한다.
- 5. 공정성 측정 설계에서 고려할 가치가 있는 세 가지 원칙을 제시하며, 기술적 형식화와 사회적 현실 간의 격차를 줄이는 데 기여하고자 한다.


---

*Generated on 2025-09-23 10:03:31*