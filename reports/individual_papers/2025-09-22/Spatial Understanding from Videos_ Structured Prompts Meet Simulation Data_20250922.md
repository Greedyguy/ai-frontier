---
keywords:
  - Vision-Language Model
  - 3D Spatial Reasoning
  - Structured Prompting
  - Simulation Data
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2506.03642
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T10:01:51.342652",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Vision-Language Model",
    "3D Spatial Reasoning",
    "Structured Prompting",
    "Simulation Data"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Vision-Language Model": 0.85,
    "3D Spatial Reasoning": 0.79,
    "Structured Prompting": 0.82,
    "Simulation Data": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Vision-Language Models",
        "canonical": "Vision-Language Model",
        "aliases": [
          "VLMs"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-Language Models are central to the paper's discussion on enhancing 3D spatial reasoning, linking to recent trends in multimodal AI.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.72,
        "link_intent_score": 0.85
      },
      {
        "surface": "3D Spatial Reasoning",
        "canonical": "3D Spatial Reasoning",
        "aliases": [
          "3D Spatial Understanding"
        ],
        "category": "unique_technical",
        "rationale": "The paper focuses on improving 3D spatial reasoning capabilities, a unique technical aspect not commonly addressed in existing vocabularies.",
        "novelty_score": 0.68,
        "connectivity_score": 0.75,
        "specificity_score": 0.81,
        "link_intent_score": 0.79
      },
      {
        "surface": "Structured Prompting",
        "canonical": "Structured Prompting",
        "aliases": [
          "SpatialMind"
        ],
        "category": "unique_technical",
        "rationale": "Structured prompting is a novel approach introduced in the paper, crucial for decomposing complex scenes for better spatial reasoning.",
        "novelty_score": 0.71,
        "connectivity_score": 0.7,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "Simulation Data",
        "canonical": "Simulation Data",
        "aliases": [
          "3D Simulation Scenes"
        ],
        "category": "broad_technical",
        "rationale": "Simulation data is essential for training and testing the proposed framework, offering a broad technical link to data-driven AI research.",
        "novelty_score": 0.5,
        "connectivity_score": 0.8,
        "specificity_score": 0.65,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "robotic navigation",
      "embodied interaction",
      "fine-tuning strategies"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Vision-Language Models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.72,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "3D Spatial Reasoning",
      "resolved_canonical": "3D Spatial Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.75,
        "specificity": 0.81,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Structured Prompting",
      "resolved_canonical": "Structured Prompting",
      "decision": "linked",
      "scores": {
        "novelty": 0.71,
        "connectivity": 0.7,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Simulation Data",
      "resolved_canonical": "Simulation Data",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.8,
        "specificity": 0.65,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# Spatial Understanding from Videos: Structured Prompts Meet Simulation Data

**Korean Title:** ë¹„ë””ì˜¤ë¡œë¶€í„°ì˜ ê³µê°„ ì´í•´: êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ì™€ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ì˜ ë§Œë‚¨

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2506.03642.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2506.03642](https://arxiv.org/abs/2506.03642)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/See&Trek_ Training-Free Spatial Prompting for Multimodal Large Language Model_20250922|See&Trek: Training-Free Spatial Prompting for Multimodal Large Language Model]] (85.3% similar)
- [[2025-09-22/GRE Suite_ Geo-localization Inference via Fine-Tuned Vision-Language Models and Enhanced Reasoning Chains_20250922|GRE Suite: Geo-localization Inference via Fine-Tuned Vision-Language Models and Enhanced Reasoning Chains]] (84.7% similar)
- [[2025-09-22/Vision-Language Models as Differentiable Semantic and Spatial Rewards for Text-to-3D Generation_20250922|Vision-Language Models as Differentiable Semantic and Spatial Rewards for Text-to-3D Generation]] (84.1% similar)
- [[2025-09-19/SPATIALGEN_ Layout-guided 3D Indoor Scene Generation_20250919|SPATIALGEN: Layout-guided 3D Indoor Scene Generation]] (83.1% similar)
- [[2025-09-19/V-SEAM_ Visual Semantic Editing and Attention Modulating for Causal Interpretability of Vision-Language Models_20250919|V-SEAM: Visual Semantic Editing and Attention Modulating for Causal Interpretability of Vision-Language Models]] (83.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Simulation Data|Simulation Data]]
**âš¡ Unique Technical**: [[keywords/3D Spatial Reasoning|3D Spatial Reasoning]], [[keywords/Structured Prompting|Structured Prompting]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2506.03642v2 Announce Type: replace-cross 
Abstract: Visual-spatial understanding, the ability to infer object relationships and layouts from visual input, is fundamental to downstream tasks such as robotic navigation and embodied interaction. However, existing methods face spatial uncertainty and data scarcity, limiting the 3D spatial reasoning capability of pre-trained vision-language models (VLMs). To address these challenges, we present a unified framework for enhancing 3D spatial reasoning in pre-trained VLMs without modifying their architecture. This framework combines SpatialMind, a structured prompting strategy that decomposes complex scenes and questions into interpretable reasoning steps, with ScanForgeQA, a scalable question-answering dataset built from diverse 3D simulation scenes through an automated construction process designed for fine-tuning. Extensive experiments across multiple benchmarks demonstrate the individual and combined effectiveness of our prompting and fine-tuning strategies, and yield insights that may inspire future research on visual-spatial understanding.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2506.03642v2 ë°œí‘œ ìœ í˜•: êµì²´-êµì°¨  
ì´ˆë¡: ì‹œê°-ê³µê°„ì  ì´í•´, ì¦‰ ì‹œê°ì  ì…ë ¥ìœ¼ë¡œë¶€í„° ê°ì²´ ê´€ê³„ì™€ ë°°ì¹˜ë¥¼ ì¶”ë¡ í•˜ëŠ” ëŠ¥ë ¥ì€ ë¡œë´‡ ë‚´ë¹„ê²Œì´ì…˜ ë° êµ¬í˜„ëœ ìƒí˜¸ì‘ìš©ê³¼ ê°™ì€ í›„ì† ì‘ì—…ì— í•„ìˆ˜ì ì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê¸°ì¡´ ë°©ë²•ë“¤ì€ ê³µê°„ì  ë¶ˆí™•ì‹¤ì„±ê³¼ ë°ì´í„° ë¶€ì¡±ì— ì§ë©´í•˜ì—¬ ì‚¬ì „ í•™ìŠµëœ ë¹„ì „-ì–¸ì–´ ëª¨ë¸(VLMs)ì˜ 3D ê³µê°„ ì¶”ë¡  ëŠ¥ë ¥ì„ ì œí•œí•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ì‚¬ì „ í•™ìŠµëœ VLMsì˜ ì•„í‚¤í…ì²˜ë¥¼ ìˆ˜ì •í•˜ì§€ ì•Šê³  3D ê³µê°„ ì¶”ë¡ ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ í†µí•© í”„ë ˆì„ì›Œí¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ë³µì¡í•œ ì¥ë©´ê³¼ ì§ˆë¬¸ì„ í•´ì„ ê°€ëŠ¥í•œ ì¶”ë¡  ë‹¨ê³„ë¡œ ë¶„í•´í•˜ëŠ” êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ ì „ëµì¸ SpatialMindì™€, ë‹¤ì–‘í•œ 3D ì‹œë®¬ë ˆì´ì…˜ ì¥ë©´ì—ì„œ ìë™í™”ëœ êµ¬ì¶• ê³¼ì •ì„ í†µí•´ ê°œë°œëœ í™•ì¥ ê°€ëŠ¥í•œ ì§ˆë¬¸-ì‘ë‹µ ë°ì´í„°ì…‹ì¸ ScanForgeQAë¥¼ ê²°í•©í•©ë‹ˆë‹¤. ì—¬ëŸ¬ ë²¤ì¹˜ë§ˆí¬ì— ê±¸ì¹œ ê´‘ë²”ìœ„í•œ ì‹¤í—˜ì€ ìš°ë¦¬ì˜ í”„ë¡¬í”„íŠ¸ ë° ë¯¸ì„¸ ì¡°ì • ì „ëµì˜ ê°œë³„ì  ë° ê²°í•©ëœ íš¨ê³¼ë¥¼ ì…ì¦í•˜ë©°, ì‹œê°-ê³µê°„ì  ì´í•´ì— ëŒ€í•œ í–¥í›„ ì—°êµ¬ì— ì˜ê°ì„ ì¤„ ìˆ˜ ìˆëŠ” í†µì°°ë ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì‚¬ì „ í•™ìŠµëœ ë¹„ì „-ì–¸ì–´ ëª¨ë¸(VLM)ì˜ 3D ê³µê°„ ì¶”ë¡  ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ í†µí•© í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ ë°©ë²•ë“¤ì´ ê³µê°„ ë¶ˆí™•ì‹¤ì„±ê³¼ ë°ì´í„° ë¶€ì¡± ë¬¸ì œë¥¼ ê²ªëŠ” ê²ƒì— ë°˜í•´, ì´ ì—°êµ¬ëŠ” VLMì˜ ì•„í‚¤í…ì²˜ë¥¼ ìˆ˜ì •í•˜ì§€ ì•Šê³ ë„ ì„±ëŠ¥ì„ ê°œì„ í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤. ì£¼ìš” ê¸°ì—¬ë¡œëŠ” ë³µì¡í•œ ì¥ë©´ê³¼ ì§ˆë¬¸ì„ í•´ì„ ê°€ëŠ¥í•œ ì¶”ë¡  ë‹¨ê³„ë¡œ ë¶„í•´í•˜ëŠ” êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ ì „ëµì¸ SpatialMindì™€ ë‹¤ì–‘í•œ 3D ì‹œë®¬ë ˆì´ì…˜ ì¥ë©´ì—ì„œ ìë™ìœ¼ë¡œ êµ¬ì¶•ëœ ëŒ€ê·œëª¨ ì§ˆë¬¸-ì‘ë‹µ ë°ì´í„°ì…‹ì¸ ScanForgeQAê°€ ìˆìŠµë‹ˆë‹¤. ì—¬ëŸ¬ ë²¤ì¹˜ë§ˆí¬ ì‹¤í—˜ì„ í†µí•´ ì´ í”„ë ˆì„ì›Œí¬ì˜ íš¨ê³¼ê°€ ì…ì¦ë˜ì—ˆìœ¼ë©°, ì´ëŠ” í–¥í›„ ì‹œê°-ê³µê°„ ì´í•´ ì—°êµ¬ì— ì˜ê°ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì‹œê°ì -ê³µê°„ì  ì´í•´ëŠ” ë¡œë´‡ ë‚´ë¹„ê²Œì´ì…˜ ë° êµ¬í˜„ëœ ìƒí˜¸ì‘ìš©ê³¼ ê°™ì€ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—…ì— í•„ìˆ˜ì ì…ë‹ˆë‹¤.
- 2. ê¸°ì¡´ ë°©ë²•ë“¤ì€ ê³µê°„ì  ë¶ˆí™•ì‹¤ì„±ê³¼ ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ì¸í•´ ì‚¬ì „ í•™ìŠµëœ ë¹„ì „-ì–¸ì–´ ëª¨ë¸ì˜ 3D ê³µê°„ ì¶”ë¡  ëŠ¥ë ¥ì´ ì œí•œë©ë‹ˆë‹¤.
- 3. SpatialMindì™€ ScanForgeQAë¥¼ ê²°í•©í•œ í†µí•© í”„ë ˆì„ì›Œí¬ëŠ” ëª¨ë¸ ì•„í‚¤í…ì²˜ë¥¼ ìˆ˜ì •í•˜ì§€ ì•Šê³  3D ê³µê°„ ì¶”ë¡ ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
- 4. ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ ì‹¤í—˜ì„ í†µí•´ í”„ë¡¬í”„íŠ¸ ì „ëµê³¼ ë¯¸ì„¸ ì¡°ì • ì „ëµì˜ ê°œë³„ ë° ê²°í•© íš¨ê³¼ê°€ ì…ì¦ë˜ì—ˆìŠµë‹ˆë‹¤.
- 5. ì—°êµ¬ ê²°ê³¼ëŠ” ì‹œê°ì -ê³µê°„ì  ì´í•´ì— ëŒ€í•œ í–¥í›„ ì—°êµ¬ì— ì˜ê°ì„ ì¤„ ìˆ˜ ìˆëŠ” í†µì°°ë ¥ì„ ì œê³µí•©ë‹ˆë‹¤.


---

*Generated on 2025-09-23 10:01:51*