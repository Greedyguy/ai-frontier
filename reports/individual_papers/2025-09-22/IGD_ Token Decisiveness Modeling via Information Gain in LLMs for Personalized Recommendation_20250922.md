---
keywords:
  - Large Language Model
  - Information Gain
  - Token Decisiveness
  - Personalized Recommendation
category: cs.CL
publish_date: 2025-09-22
arxiv_id: 2506.13229
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:49:12.128226",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Information Gain",
    "Token Decisiveness",
    "Personalized Recommendation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.8,
    "Information Gain": 0.78,
    "Token Decisiveness": 0.74,
    "Personalized Recommendation": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are central to the paper's methodology and connect well with existing research in language processing.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.8
      },
      {
        "surface": "Information Gain",
        "canonical": "Information Gain",
        "aliases": [
          "IG"
        ],
        "category": "unique_technical",
        "rationale": "Information Gain is a unique concept introduced in the paper to quantify token decisiveness, offering a novel perspective.",
        "novelty_score": 0.72,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Token Decisiveness",
        "canonical": "Token Decisiveness",
        "aliases": [
          "Decisiveness of Tokens"
        ],
        "category": "unique_technical",
        "rationale": "Token Decisiveness is a novel concept that underpins the paper's approach to improving recommendation accuracy.",
        "novelty_score": 0.68,
        "connectivity_score": 0.65,
        "specificity_score": 0.77,
        "link_intent_score": 0.74
      },
      {
        "surface": "Personalized Recommendation",
        "canonical": "Personalized Recommendation",
        "aliases": [
          "Recommendation Systems"
        ],
        "category": "specific_connectable",
        "rationale": "Personalized Recommendation is a key application area for the proposed method, linking it to broader research in recommendation systems.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Information Gain",
      "resolved_canonical": "Information Gain",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Token Decisiveness",
      "resolved_canonical": "Token Decisiveness",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.65,
        "specificity": 0.77,
        "link_intent": 0.74
      }
    },
    {
      "candidate_surface": "Personalized Recommendation",
      "resolved_canonical": "Personalized Recommendation",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# IGD: Token Decisiveness Modeling via Information Gain in LLMs for Personalized Recommendation

**Korean Title:** IGD: ê°œì¸í™” ì¶”ì²œì„ ìœ„í•œ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì—ì„œ ì •ë³´ ì´ë“ì„ í†µí•œ í† í° ê²°ì •ì„± ëª¨ë¸ë§

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2506.13229.pdf)
**Category**: cs.CL
**Published**: 2025-09-22
**ArXiv ID**: [2506.13229](https://arxiv.org/abs/2506.13229)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Bias Beware_ The Impact of Cognitive Biases on LLM-Driven Product Recommendations_20250922|Bias Beware: The Impact of Cognitive Biases on LLM-Driven Product Recommendations]] (85.3% similar)
- [[2025-09-22/Subjective Behaviors and Preferences in LLM_ Language of Browsing_20250922|Subjective Behaviors and Preferences in LLM: Language of Browsing]] (84.7% similar)
- [[2025-09-19/DetectAnyLLM_ Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models_20250919|DetectAnyLLM: Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models]] (83.8% similar)
- [[2025-09-22/Benchmarking Debiasing Methods for LLM-based Parameter Estimates_20250922|Benchmarking Debiasing Methods for LLM-based Parameter Estimates]] (83.7% similar)
- [[2025-09-22/It Depends_ Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge_20250922|It Depends: Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge]] (83.7% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Personalized Recommendation|Personalized Recommendation]]
**âš¡ Unique Technical**: [[keywords/Information Gain|Information Gain]], [[keywords/Token Decisiveness|Token Decisiveness]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2506.13229v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) have shown strong potential for recommendation by framing item prediction as a token-by-token language generation task. However, existing methods treat all item tokens equally, simply pursuing likelihood maximization during both optimization and decoding. This overlooks crucial token-level differences in decisiveness-many tokens contribute little to item discrimination yet can dominate optimization or decoding. To quantify token decisiveness, we propose a novel perspective that models item generation as a decision process, measuring token decisiveness by the Information Gain (IG) each token provides in reducing uncertainty about the generated item. Our empirical analysis reveals that most tokens have low IG but often correspond to high logits, disproportionately influencing training loss and decoding, which may impair model performance. Building on these insights, we introduce an Information Gain-based Decisiveness-aware Token handling (IGD) strategy that integrates token decisiveness into both tuning and decoding. Specifically, IGD downweights low-IG tokens during tuning and rebalances decoding to emphasize tokens with high IG. In this way, IGD moves beyond pure likelihood maximization, effectively prioritizing high-decisiveness tokens. Extensive experiments on four benchmark datasets with two LLM backbones demonstrate that IGD consistently improves recommendation accuracy, achieving significant gains on widely used ranking metrics compared to strong baselines.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2506.13229v2 ë°œí‘œ ìœ í˜•: êµì²´  
ì´ˆë¡: ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì€ ì•„ì´í…œ ì˜ˆì¸¡ì„ í† í°ë³„ ì–¸ì–´ ìƒì„± ì‘ì—…ìœ¼ë¡œ í”„ë ˆì´ë°í•˜ì—¬ ì¶”ì²œì— ëŒ€í•œ ê°•ë ¥í•œ ì ì¬ë ¥ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê¸°ì¡´ ë°©ë²•ë“¤ì€ ëª¨ë“  ì•„ì´í…œ í† í°ì„ ë™ì¼í•˜ê²Œ ì·¨ê¸‰í•˜ë©°, ìµœì í™”ì™€ ë””ì½”ë”© ê³¼ì •ì—ì„œ ë‹¨ìˆœíˆ ê°€ëŠ¥ì„± ìµœëŒ€í™”ë¥¼ ì¶”êµ¬í•©ë‹ˆë‹¤. ì´ëŠ” ê²°ì •ë ¥ì—ì„œì˜ ì¤‘ìš”í•œ í† í° ìˆ˜ì¤€ì˜ ì°¨ì´ë¥¼ ê°„ê³¼í•˜ëŠ”ë°, ë§ì€ í† í°ì´ ì•„ì´í…œ êµ¬ë³„ì— ê±°ì˜ ê¸°ì—¬í•˜ì§€ ì•Šìœ¼ë©´ì„œë„ ìµœì í™”ë‚˜ ë””ì½”ë”©ì„ ì§€ë°°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í† í° ê²°ì •ë ¥ì„ ì •ëŸ‰í™”í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ì•„ì´í…œ ìƒì„±ì„ ì˜ì‚¬ ê²°ì • ê³¼ì •ìœ¼ë¡œ ëª¨ë¸ë§í•˜ëŠ” ìƒˆë¡œìš´ ê´€ì ì„ ì œì•ˆí•˜ë©°, ìƒì„±ëœ ì•„ì´í…œì— ëŒ€í•œ ë¶ˆí™•ì‹¤ì„±ì„ ì¤„ì´ëŠ” ë° ê° í† í°ì´ ì œê³µí•˜ëŠ” ì •ë³´ ì´ë“(IG)ì„ í†µí•´ í† í° ê²°ì •ë ¥ì„ ì¸¡ì •í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì‹¤ì¦ ë¶„ì„ì€ ëŒ€ë¶€ë¶„ì˜ í† í°ì´ ë‚®ì€ IGë¥¼ ê°€ì§€ê³  ìˆì§€ë§Œ ì¢…ì¢… ë†’ì€ ë¡œì§“ì— í•´ë‹¹í•˜ì—¬, í›ˆë ¨ ì†ì‹¤ê³¼ ë””ì½”ë”©ì— ë¶ˆê· í˜•ì ìœ¼ë¡œ ì˜í–¥ì„ ë¯¸ì³ ëª¨ë¸ ì„±ëŠ¥ì„ ì €í•˜ì‹œí‚¬ ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŸ¬í•œ í†µì°°ì„ ë°”íƒ•ìœ¼ë¡œ, ìš°ë¦¬ëŠ” ì¡°ì •ê³¼ ë””ì½”ë”© ëª¨ë‘ì— í† í° ê²°ì •ë ¥ì„ í†µí•©í•˜ëŠ” ì •ë³´ ì´ë“ ê¸°ë°˜ ê²°ì •ë ¥ ì¸ì‹ í† í° ì²˜ë¦¬(IGD) ì „ëµì„ ì†Œê°œí•©ë‹ˆë‹¤. êµ¬ì²´ì ìœ¼ë¡œ, IGDëŠ” ì¡°ì • ê³¼ì •ì—ì„œ ë‚®ì€ IG í† í°ì˜ ê°€ì¤‘ì¹˜ë¥¼ ë‚®ì¶”ê³ , ë””ì½”ë”©ì„ ì¬ì¡°ì •í•˜ì—¬ ë†’ì€ IG í† í°ì„ ê°•ì¡°í•©ë‹ˆë‹¤. ì´ë ‡ê²Œ í•¨ìœ¼ë¡œì¨, IGDëŠ” ìˆœìˆ˜í•œ ê°€ëŠ¥ì„± ìµœëŒ€í™”ë¥¼ ë„˜ì–´, ë†’ì€ ê²°ì •ë ¥ì˜ í† í°ì„ íš¨ê³¼ì ìœ¼ë¡œ ìš°ì„ ì‹œí•©ë‹ˆë‹¤. ë‘ ê°œì˜ LLM ë°±ë³¸ì„ ì‚¬ìš©í•œ ë„¤ ê°œì˜ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì— ëŒ€í•œ ê´‘ë²”ìœ„í•œ ì‹¤í—˜ì€ IGDê°€ ê°•ë ¥í•œ ê¸°ì¤€ì„ ê³¼ ë¹„êµí•˜ì—¬ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ìˆœìœ„ ë©”íŠ¸ë¦­ì—ì„œ ìœ ì˜ë¯¸í•œ í–¥ìƒì„ ë‹¬ì„±í•˜ë©°, ì¶”ì²œ ì •í™•ë„ë¥¼ ì§€ì†ì ìœ¼ë¡œ í–¥ìƒì‹œí‚´ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì€ ì•„ì´í…œ ì˜ˆì¸¡ì„ ì–¸ì–´ ìƒì„± ì‘ì—…ìœ¼ë¡œ í”„ë ˆì´ë°í•˜ì—¬ ì¶”ì²œ ì‹œìŠ¤í…œì—ì„œ ê°•ë ¥í•œ ì ì¬ë ¥ì„ ë³´ì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê¸°ì¡´ ë°©ë²•ë“¤ì€ ëª¨ë“  ì•„ì´í…œ í† í°ì„ ë™ì¼í•˜ê²Œ ì·¨ê¸‰í•˜ì—¬ ìµœì í™”ì™€ ë””ì½”ë”© ì‹œ ë‹¨ìˆœíˆ ê°€ëŠ¥ì„± ìµœëŒ€í™”ë¥¼ ì¶”êµ¬í•©ë‹ˆë‹¤. ì´ëŠ” ê²°ì •ë ¥ ìˆëŠ” í† í°ì˜ ì°¨ì´ë¥¼ ê°„ê³¼í•˜ëŠ”ë°, ë§ì€ í† í°ì´ ì•„ì´í…œ êµ¬ë³„ì— ê±°ì˜ ê¸°ì—¬í•˜ì§€ ì•Šìœ¼ë©´ì„œë„ ìµœì í™”ë‚˜ ë””ì½”ë”©ì— ê³¼ë„í•œ ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ì •ë³´ ì´ë“(IG)ì„ í†µí•´ ê° í† í°ì´ ìƒì„±ëœ ì•„ì´í…œì˜ ë¶ˆí™•ì‹¤ì„±ì„ ì¤„ì´ëŠ” ë° ê¸°ì—¬í•˜ëŠ” ì •ë„ë¥¼ ì¸¡ì •í•˜ì—¬ í† í° ê²°ì •ë ¥ì„ í‰ê°€í•˜ëŠ” ìƒˆë¡œìš´ ê´€ì ì„ ì œì•ˆí•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì‹¤ì¦ ë¶„ì„ì— ë”°ë¥´ë©´ ëŒ€ë¶€ë¶„ì˜ í† í°ì€ ë‚®ì€ IGë¥¼ ê°€ì§€ì§€ë§Œ ë†’ì€ ë¡œì§“ê³¼ ì—°ê´€ë˜ì–´ ìˆì–´ ëª¨ë¸ ì„±ëŠ¥ì„ ì €í•˜ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ í†µì°°ì„ ë°”íƒ•ìœ¼ë¡œ, ìš°ë¦¬ëŠ” ì •ë³´ ì´ë“ ê¸°ë°˜ì˜ ê²°ì •ë ¥ ì¸ì‹ í† í° ì²˜ë¦¬(IGD) ì „ëµì„ ë„ì…í•˜ì—¬ í† í° ê²°ì •ë ¥ì„ íŠœë‹ê³¼ ë””ì½”ë”©ì— í†µí•©í•©ë‹ˆë‹¤. IGDëŠ” íŠœë‹ ì‹œ ë‚®ì€ IG í† í°ì˜ ê°€ì¤‘ì¹˜ë¥¼ ë‚®ì¶”ê³ , ë””ì½”ë”© ì‹œ ë†’ì€ IG í† í°ì„ ê°•ì¡°í•˜ì—¬ ìˆœìˆ˜í•œ ê°€ëŠ¥ì„± ìµœëŒ€í™”ì—ì„œ ë²—ì–´ë‚©ë‹ˆë‹¤. ë„¤ ê°€ì§€ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ê³¼ ë‘ ê°€ì§€ LLM ë°±ë³¸ì„ ì‚¬ìš©í•œ ì‹¤í—˜ì—ì„œ IGDëŠ” ì¶”ì²œ ì •í™•ë„ë¥¼ ì§€ì†ì ìœ¼ë¡œ í–¥ìƒì‹œì¼°ìœ¼ë©°, ê°•ë ¥í•œ ê¸°ì¤€ì„ ê³¼ ë¹„êµí•˜ì—¬ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ìˆœìœ„ ë§¤íŠ¸ë¦­ìŠ¤ì—ì„œ ìœ ì˜ë¯¸í•œ ì„±ê³¼ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì€ ì•„ì´í…œ ì˜ˆì¸¡ì„ í† í° ë‹¨ìœ„ì˜ ì–¸ì–´ ìƒì„± ì‘ì—…ìœ¼ë¡œ í”„ë ˆì´ë°í•˜ì—¬ ì¶”ì²œ ë¶„ì•¼ì—ì„œ ê°•ë ¥í•œ ì ì¬ë ¥ì„ ë³´ì—¬ì£¼ì—ˆë‹¤.
- 2. ê¸°ì¡´ ë°©ë²•ì€ ëª¨ë“  ì•„ì´í…œ í† í°ì„ ë™ì¼í•˜ê²Œ ì·¨ê¸‰í•˜ì—¬ ìµœì í™” ë° ë””ì½”ë”© ì‹œ ë‹¨ìˆœíˆ ê°€ëŠ¥ì„± ìµœëŒ€í™”ë¥¼ ì¶”êµ¬í•œë‹¤.
- 3. ìš°ë¦¬ëŠ” ì •ë³´ ì´ë“(IG)ì„ í†µí•´ ê° í† í°ì´ ìƒì„±ëœ ì•„ì´í…œì˜ ë¶ˆí™•ì‹¤ì„±ì„ ì¤„ì´ëŠ” ë° ê¸°ì—¬í•˜ëŠ” ì •ë„ë¥¼ ì¸¡ì •í•˜ì—¬ í† í° ê²°ì •ì„±ì„ ì •ëŸ‰í™”í•˜ëŠ” ìƒˆë¡œìš´ ê´€ì ì„ ì œì•ˆí•œë‹¤.
- 4. ì •ë³´ ì´ë“ ê¸°ë°˜ ê²°ì •ì„± ì¸ì‹ í† í° ì²˜ë¦¬(IGD) ì „ëµì€ íŠœë‹ê³¼ ë””ì½”ë”© ëª¨ë‘ì— í† í° ê²°ì •ì„±ì„ í†µí•©í•˜ì—¬, ë‚®ì€ IG í† í°ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì¤„ì´ê³  ë†’ì€ IG í† í°ì„ ê°•ì¡°í•œë‹¤.
- 5. IGDëŠ” ë„¤ ê°€ì§€ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ê³¼ ë‘ ê°€ì§€ LLM ë°±ë³¸ì—ì„œ ì¶”ì²œ ì •í™•ë„ë¥¼ ì§€ì†ì ìœ¼ë¡œ í–¥ìƒì‹œì¼œ ê°•ë ¥í•œ ê¸°ì¤€ì„ ê³¼ ë¹„êµí•˜ì—¬ ìˆœìœ„ ë§¤íŠ¸ë¦­ìŠ¤ì—ì„œ ìœ ì˜ë¯¸í•œ ì„±ê³¼ í–¥ìƒì„ ë‹¬ì„±í–ˆë‹¤.


---

*Generated on 2025-09-23 11:49:12*