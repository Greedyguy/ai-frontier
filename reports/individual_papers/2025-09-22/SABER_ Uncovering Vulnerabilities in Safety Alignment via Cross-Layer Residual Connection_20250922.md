---
keywords:
  - Large Language Model
  - Safety Alignment
  - Jailbreak Attack
  - Residual Connection
  - HarmBench
category: cs.LG
publish_date: 2025-09-22
arxiv_id: 2509.16060
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T10:41:21.367397",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Safety Alignment",
    "Jailbreak Attack",
    "Residual Connection",
    "HarmBench"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Safety Alignment": 0.78,
    "Jailbreak Attack": 0.8,
    "Residual Connection": 0.77,
    "HarmBench": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Large Language Models"
        ],
        "category": "broad_technical",
        "rationale": "As a fundamental technology, it connects to a wide range of studies in natural language processing and AI safety.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "safety alignment",
        "canonical": "Safety Alignment",
        "aliases": [
          "safety-alignment training"
        ],
        "category": "unique_technical",
        "rationale": "This concept is central to the paper's focus on vulnerabilities and is a specific area of interest in AI ethics and safety.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "jailbreak attacks",
        "canonical": "Jailbreak Attack",
        "aliases": [
          "jailbreak",
          "jailbreaks"
        ],
        "category": "unique_technical",
        "rationale": "Understanding jailbreak attacks is crucial for linking studies on AI vulnerabilities and security.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.75,
        "link_intent_score": 0.8
      },
      {
        "surface": "residual connection",
        "canonical": "Residual Connection",
        "aliases": [
          "residual connections"
        ],
        "category": "specific_connectable",
        "rationale": "This is a key mechanism in neural networks that enhances model performance and is relevant to the paper's methodology.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.65,
        "link_intent_score": 0.77
      },
      {
        "surface": "HarmBench test set",
        "canonical": "HarmBench",
        "aliases": [
          "HarmBench validation set"
        ],
        "category": "unique_technical",
        "rationale": "HarmBench is a specific benchmark used to evaluate the effectiveness of safety mechanisms in AI models.",
        "novelty_score": 0.68,
        "connectivity_score": 0.6,
        "specificity_score": 0.72,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "source code"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "safety alignment",
      "resolved_canonical": "Safety Alignment",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "jailbreak attacks",
      "resolved_canonical": "Jailbreak Attack",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.75,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "residual connection",
      "resolved_canonical": "Residual Connection",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.65,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "HarmBench test set",
      "resolved_canonical": "HarmBench",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.6,
        "specificity": 0.72,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# SABER: Uncovering Vulnerabilities in Safety Alignment via Cross-Layer Residual Connection

**Korean Title:** SABER: êµì°¨ ê³„ì¸µ ì”ì—¬ ì—°ê²°ì„ í†µí•œ ì•ˆì „ ì •ë ¬ì˜ ì·¨ì•½ì  ë°œê²¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16060.pdf)
**Category**: cs.LG
**Published**: 2025-09-22
**ArXiv ID**: [2509.16060](https://arxiv.org/abs/2509.16060)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/AdaSteer_ Your Aligned LLM is Inherently an Adaptive Jailbreak Defender_20250922|AdaSteer: Your Aligned LLM is Inherently an Adaptive Jailbreak Defender]] (86.8% similar)
- [[2025-09-22/Toxicity Red-Teaming_ Benchmarking LLM Safety in Singapore's Low-Resource Languages_20250922|Toxicity Red-Teaming: Benchmarking LLM Safety in Singapore's Low-Resource Languages]] (85.2% similar)
- [[2025-09-22/From Judgment to Interference_ Early Stopping LLM Harmful Outputs via Streaming Content Monitoring_20250922|From Judgment to Interference: Early Stopping LLM Harmful Outputs via Streaming Content Monitoring]] (84.7% similar)
- [[2025-09-22/Activation Space Interventions Can Be Transferred Between Large Language Models_20250922|Activation Space Interventions Can Be Transferred Between Large Language Models]] (84.2% similar)
- [[2025-09-19/Decoupled Proxy Alignment_ Mitigating Language Prior Conflict for Multimodal Alignment in MLLM_20250919|Decoupled Proxy Alignment: Mitigating Language Prior Conflict for Multimodal Alignment in MLLM]] (83.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Residual Connection|Residual Connection]]
**âš¡ Unique Technical**: [[keywords/Safety Alignment|Safety Alignment]], [[keywords/Jailbreak Attack|Jailbreak Attack]], [[keywords/HarmBench|HarmBench]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16060v1 Announce Type: new 
Abstract: Large Language Models (LLMs) with safe-alignment training are powerful instruments with robust language comprehension capabilities. These models typically undergo meticulous alignment procedures involving human feedback to ensure the acceptance of safe inputs while rejecting harmful or unsafe ones. However, despite their massive scale and alignment efforts, LLMs remain vulnerable to jailbreak attacks, where malicious users manipulate the model to produce harmful outputs that it was explicitly trained to avoid. In this study, we find that the safety mechanisms in LLMs are predominantly embedded in the middle-to-late layers. Building on this insight, we introduce a novel white-box jailbreak method, SABER (Safety Alignment Bypass via Extra Residuals), which connects two intermediate layers $s$ and $e$ such that $s < e$, through a residual connection. Our approach achieves a 51% improvement over the best-performing baseline on the HarmBench test set. Furthermore, SABER induces only a marginal shift in perplexity when evaluated on the HarmBench validation set. The source code is publicly available at https://github.com/PalGitts/SABER.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.16060v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: ì•ˆì „ ì •ë ¬ í›ˆë ¨ì„ ë°›ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ ê°•ë ¥í•œ ì–¸ì–´ ì´í•´ ëŠ¥ë ¥ì„ ê°€ì§„ ë„êµ¬ì…ë‹ˆë‹¤. ì´ëŸ¬í•œ ëª¨ë¸ì€ ì¼ë°˜ì ìœ¼ë¡œ ì•ˆì „í•œ ì…ë ¥ì„ ìˆ˜ìš©í•˜ê³  ìœ í•´í•˜ê±°ë‚˜ ì•ˆì „í•˜ì§€ ì•Šì€ ì…ë ¥ì„ ê±°ë¶€í•˜ë„ë¡ ì¸ê°„ì˜ í”¼ë“œë°±ì„ í¬í•¨í•œ ì„¸ì‹¬í•œ ì •ë ¬ ì ˆì°¨ë¥¼ ê±°ì¹©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ëŒ€ê·œëª¨ì™€ ì •ë ¬ ë…¸ë ¥ì—ë„ ë¶ˆêµ¬í•˜ê³ , LLMì€ ì•…ì˜ì ì¸ ì‚¬ìš©ìê°€ ëª¨ë¸ì„ ì¡°ì‘í•˜ì—¬ ëª…ì‹œì ìœ¼ë¡œ íšŒí”¼í•˜ë„ë¡ í›ˆë ¨ëœ ìœ í•´í•œ ì¶œë ¥ì„ ìƒì„±í•˜ê²Œ í•˜ëŠ” íƒˆì˜¥ ê³µê²©ì— ì·¨ì•½í•©ë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” LLMì˜ ì•ˆì „ ë©”ì»¤ë‹ˆì¦˜ì´ ì£¼ë¡œ ì¤‘ê°„ì—ì„œ í›„ë°˜ ë ˆì´ì–´ì— ë‚´ì¥ë˜ì–´ ìˆìŒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ì´ í†µì°°ì„ ë°”íƒ•ìœ¼ë¡œ, ìš°ë¦¬ëŠ” ìƒˆë¡œìš´ í™”ì´íŠ¸ë°•ìŠ¤ íƒˆì˜¥ ë°©ë²•ì¸ SABER(Safety Alignment Bypass via Extra Residuals)ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ì´ëŠ” ì”ì—¬ ì—°ê²°ì„ í†µí•´ ë‘ ê°œì˜ ì¤‘ê°„ ë ˆì´ì–´ $s$ì™€ $e$ë¥¼ ì—°ê²°í•˜ì—¬ $s < e$ê°€ ë˜ë„ë¡ í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì ‘ê·¼ë²•ì€ HarmBench í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì€ ê¸°ì¤€ì„  ëŒ€ë¹„ 51%ì˜ ê°œì„ ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, SABERëŠ” HarmBench ê²€ì¦ ì„¸íŠ¸ì—ì„œ í‰ê°€í•  ë•Œ ë‹¹í˜¹ë„ì˜ ë³€í™”ê°€ ê±°ì˜ ì—†ìŠµë‹ˆë‹¤. ì†ŒìŠ¤ ì½”ë“œëŠ” https://github.com/PalGitts/SABERì—ì„œ ê³µê°œì ìœ¼ë¡œ ì´ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” ì•ˆì „ ì •ë ¬ í›ˆë ¨ì„ ë°›ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì´ ì—¬ì „íˆ ì•…ì˜ì ì¸ ì‚¬ìš©ìê°€ ëª¨ë¸ì„ ì¡°ì‘í•˜ì—¬ ìœ í•´í•œ ì¶œë ¥ì„ ìƒì„±í•˜ëŠ” 'jailbreak' ê³µê²©ì— ì·¨ì•½í•˜ë‹¤ëŠ” ì ì„ ë°í™ë‹ˆë‹¤. ì—°êµ¬ì§„ì€ LLMì˜ ì•ˆì „ ë©”ì»¤ë‹ˆì¦˜ì´ ì£¼ë¡œ ì¤‘ê°„ì—ì„œ í›„ë°˜ë¶€ ë ˆì´ì–´ì— ë‚´ì¬ë˜ì–´ ìˆìŒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì¤‘ê°„ ë ˆì´ì–´ $s$ì™€ $e$ë¥¼ ì‰ì—¬ ì—°ê²°ë¡œ ì—°ê²°í•˜ëŠ” ìƒˆë¡œìš´ í™”ì´íŠ¸ë°•ìŠ¤ jailbreak ë°©ë²•ì¸ SABERë¥¼ ì œì•ˆí–ˆìŠµë‹ˆë‹¤. SABERëŠ” HarmBench í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ ê¸°ì¡´ ìµœê³  ì„±ëŠ¥ ëŒ€ë¹„ 51% ê°œì„ ëœ ê²°ê³¼ë¥¼ ë³´ì˜€ìœ¼ë©°, ê²€ì¦ ì„¸íŠ¸ì—ì„œ í˜¼ë€ë„(perplexity) ë³€í™”ëŠ” ë¯¸ë¯¸í–ˆìŠµë‹ˆë‹¤. ì†ŒìŠ¤ ì½”ë“œëŠ” ê³µê°œë˜ì–´ ìˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ ì•ˆì „í•œ ì…ë ¥ì„ ìˆ˜ìš©í•˜ê³  ìœ í•´í•œ ì…ë ¥ì„ ê±°ë¶€í•˜ë„ë¡ ì¸ê°„ í”¼ë“œë°±ì„ í†µí•´ ì •ë ¬ ì ˆì°¨ë¥¼ ê±°ì¹œë‹¤.
- 2. LLMì€ ì •ë ¬ ë…¸ë ¥ì—ë„ ë¶ˆêµ¬í•˜ê³  ì•…ì˜ì ì¸ ì‚¬ìš©ìê°€ ëª¨ë¸ì„ ì¡°ì‘í•˜ì—¬ ìœ í•´í•œ ì¶œë ¥ì„ ìƒì„±í•˜ëŠ” íƒˆì˜¥ ê³µê²©ì— ì·¨ì•½í•˜ë‹¤.
- 3. ì•ˆì „ ë©”ì»¤ë‹ˆì¦˜ì€ ì£¼ë¡œ LLMì˜ ì¤‘ê°„ì—ì„œ í›„ë°˜ ë ˆì´ì–´ì— ë‚´ì¥ë˜ì–´ ìˆë‹¤.
- 4. SABERë¼ëŠ” ìƒˆë¡œìš´ í™”ì´íŠ¸ë°•ìŠ¤ íƒˆì˜¥ ë°©ë²•ì„ ë„ì…í•˜ì—¬ ì¤‘ê°„ ë ˆì´ì–´ ì‚¬ì´ì— ì”ì—¬ ì—°ê²°ì„ í†µí•´ ì•ˆì „ ì •ë ¬ì„ ìš°íšŒí•œë‹¤.
- 5. SABERëŠ” HarmBench í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ ê¸°ì¡´ ìµœê³  ì„±ëŠ¥ ëŒ€ë¹„ 51% ê°œì„ ì„ ë‹¬ì„±í–ˆë‹¤.


---

*Generated on 2025-09-23 10:41:21*