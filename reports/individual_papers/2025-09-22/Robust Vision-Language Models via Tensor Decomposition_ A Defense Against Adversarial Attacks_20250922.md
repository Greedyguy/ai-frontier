---
keywords:
  - Vision-Language Model
  - Tensor Decomposition
  - Adversarial Attack
  - CLIP
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2509.16163
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T09:30:08.274893",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Vision-Language Model",
    "Tensor Decomposition",
    "Adversarial Attack",
    "CLIP"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Vision-Language Model": 0.85,
    "Tensor Decomposition": 0.78,
    "Adversarial Attack": 0.82,
    "CLIP": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Vision language models",
        "canonical": "Vision-Language Model",
        "aliases": [
          "VLM",
          "Vision-Language"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-Language Models are central to the paper's focus on multimodal understanding and adversarial defense.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.78,
        "link_intent_score": 0.85
      },
      {
        "surface": "Tensor decomposition",
        "canonical": "Tensor Decomposition",
        "aliases": [
          "Tensor Train",
          "TT"
        ],
        "category": "unique_technical",
        "rationale": "Tensor decomposition is the novel technique proposed for enhancing model robustness against adversarial attacks.",
        "novelty_score": 0.72,
        "connectivity_score": 0.67,
        "specificity_score": 0.82,
        "link_intent_score": 0.78
      },
      {
        "surface": "Adversarial attacks",
        "canonical": "Adversarial Attack",
        "aliases": [
          "Adversarial Noise"
        ],
        "category": "specific_connectable",
        "rationale": "Understanding adversarial attacks is crucial for linking defense strategies in vision-language models.",
        "novelty_score": 0.48,
        "connectivity_score": 0.85,
        "specificity_score": 0.8,
        "link_intent_score": 0.82
      },
      {
        "surface": "CLIP",
        "canonical": "CLIP",
        "aliases": [
          "Contrastive Languageâ€“Image Pretraining"
        ],
        "category": "specific_connectable",
        "rationale": "CLIP is a key model used in experiments, relevant for linking multimodal model performance.",
        "novelty_score": 0.5,
        "connectivity_score": 0.77,
        "specificity_score": 0.75,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "experiment"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Vision language models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.78,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Tensor decomposition",
      "resolved_canonical": "Tensor Decomposition",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.67,
        "specificity": 0.82,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Adversarial attacks",
      "resolved_canonical": "Adversarial Attack",
      "decision": "linked",
      "scores": {
        "novelty": 0.48,
        "connectivity": 0.85,
        "specificity": 0.8,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "CLIP",
      "resolved_canonical": "CLIP",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.77,
        "specificity": 0.75,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Robust Vision-Language Models via Tensor Decomposition: A Defense Against Adversarial Attacks

**Korean Title:** í…ì„œ ë¶„í•´ë¥¼ í†µí•œ ê°•ê±´í•œ ë¹„ì „-ì–¸ì–´ ëª¨ë¸: ì ëŒ€ì  ê³µê²©ì— ëŒ€í•œ ë°©ì–´

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16163.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2509.16163](https://arxiv.org/abs/2509.16163)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/LLMs Can Compensate for Deficiencies in Visual Representations_20250922|LLMs Can Compensate for Deficiencies in Visual Representations]] (87.4% similar)
- [[2025-09-22/Training-Free Pyramid Token Pruning for Efficient Large Vision-Language Models via Region, Token, and Instruction-Guided Importance_20250922|Training-Free Pyramid Token Pruning for Efficient Large Vision-Language Models via Region, Token, and Instruction-Guided Importance]] (85.2% similar)
- [[2025-09-22/ORCA_ Agentic Reasoning For Hallucination and Adversarial Robustness in Vision-Language Models_20250922|ORCA: Agentic Reasoning For Hallucination and Adversarial Robustness in Vision-Language Models]] (84.6% similar)
- [[2025-09-22/Quality-Driven Curation of Remote Sensing Vision-Language Data via Learned Scoring Models_20250922|Quality-Driven Curation of Remote Sensing Vision-Language Data via Learned Scoring Models]] (84.4% similar)
- [[2025-09-22/CLIPTTA_ Robust Contrastive Vision-Language Test-Time Adaptation_20250922|CLIPTTA: Robust Contrastive Vision-Language Test-Time Adaptation]] (84.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Adversarial Attack|Adversarial Attack]], [[keywords/CLIP|CLIP]]
**âš¡ Unique Technical**: [[keywords/Tensor Decomposition|Tensor Decomposition]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16163v1 Announce Type: cross 
Abstract: Vision language models (VLMs) excel in multimodal understanding but are prone to adversarial attacks. Existing defenses often demand costly retraining or significant architecture changes. We introduce a lightweight defense using tensor decomposition suitable for any pre-trained VLM, requiring no retraining. By decomposing and reconstructing vision encoder representations, it filters adversarial noise while preserving meaning. Experiments with CLIP on COCO and Flickr30K show improved robustness. On Flickr30K, it restores 12.3\% performance lost to attacks, raising Recall@1 accuracy from 7.5\% to 19.8\%. On COCO, it recovers 8.1\% performance, improving accuracy from 3.8\% to 11.9\%. Analysis shows Tensor Train decomposition with low rank (8-32) and low residual strength ($\alpha=0.1-0.2$) is optimal. This method is a practical, plug-and-play solution with minimal overhead for existing VLMs.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.16163v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ë¹„ì „ ì–¸ì–´ ëª¨ë¸(VLMs)ì€ ë‹¤ì¤‘ ëª¨ë‹¬ ì´í•´ì—ì„œ ë›°ì–´ë‚˜ì§€ë§Œ, ì ëŒ€ì  ê³µê²©ì— ì·¨ì•½í•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë°©ì–´ ë°©ë²•ì€ ì¢…ì¢… ë¹„ìš©ì´ ë§ì´ ë“œëŠ” ì¬í›ˆë ¨ì´ë‚˜ ìƒë‹¹í•œ ì•„í‚¤í…ì²˜ ë³€ê²½ì„ ìš”êµ¬í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì‚¬ì „ í›ˆë ¨ëœ VLMì— ì í•©í•˜ë©° ì¬í›ˆë ¨ì´ í•„ìš” ì—†ëŠ” í…ì„œ ë¶„í•´ë¥¼ ì‚¬ìš©í•œ ê²½ëŸ‰ ë°©ì–´ ê¸°ë²•ì„ ì†Œê°œí•©ë‹ˆë‹¤. ë¹„ì „ ì¸ì½”ë” í‘œí˜„ì„ ë¶„í•´í•˜ê³  ì¬êµ¬ì„±í•¨ìœ¼ë¡œì¨, ì˜ë¯¸ë¥¼ ë³´ì¡´í•˜ë©´ì„œ ì ëŒ€ì  ë…¸ì´ì¦ˆë¥¼ í•„í„°ë§í•©ë‹ˆë‹¤. COCOì™€ Flickr30Kì—ì„œ CLIPì„ ì‚¬ìš©í•œ ì‹¤í—˜ì€ í–¥ìƒëœ ê°•ì¸ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. Flickr30Kì—ì„œëŠ” ê³µê²©ìœ¼ë¡œ ì¸í•´ ì†ì‹¤ëœ ì„±ëŠ¥ì˜ 12.3%ë¥¼ ë³µêµ¬í•˜ì—¬ Recall@1 ì •í™•ë„ë¥¼ 7.5%ì—ì„œ 19.8%ë¡œ í–¥ìƒì‹œí‚µë‹ˆë‹¤. COCOì—ì„œëŠ” 8.1%ì˜ ì„±ëŠ¥ì„ íšŒë³µí•˜ì—¬ ì •í™•ë„ë¥¼ 3.8%ì—ì„œ 11.9%ë¡œ ê°œì„ í•©ë‹ˆë‹¤. ë¶„ì„ ê²°ê³¼, ë‚®ì€ ë­í¬(8-32)ì™€ ë‚®ì€ ì”ì—¬ ê°•ë„($\alpha=0.1-0.2$)ë¥¼ ê°€ì§„ í…ì„œ íŠ¸ë ˆì¸ ë¶„í•´ê°€ ìµœì ì„ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ê¸°ì¡´ VLMì— ìµœì†Œí•œì˜ ì˜¤ë²„í—¤ë“œë¡œ ì ìš© ê°€ëŠ¥í•œ ì‹¤ìš©ì ì´ê³  í”ŒëŸ¬ê·¸ ì•¤ í”Œë ˆì´ ì†”ë£¨ì…˜ì…ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë¹„ì „ ì–¸ì–´ ëª¨ë¸(VLM)ì˜ ì ëŒ€ì  ê³µê²©ì— ëŒ€í•œ ê²½ëŸ‰ ë°©ì–´ ê¸°ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ ë°©ì–´ë²•ì€ ì¬í›ˆë ¨ì´ë‚˜ ì•„í‚¤í…ì²˜ ë³€ê²½ì´ í•„ìš”í•˜ì§€ë§Œ, ì´ ë°©ë²•ì€ í…ì„œ ë¶„í•´ë¥¼ í™œìš©í•˜ì—¬ ì‚¬ì „ í›ˆë ¨ëœ VLMì— ì ìš© ê°€ëŠ¥í•˜ë©° ì¬í›ˆë ¨ì´ í•„ìš” ì—†ìŠµë‹ˆë‹¤. ë¹„ì „ ì¸ì½”ë” í‘œí˜„ì„ ë¶„í•´í•˜ê³  ì¬êµ¬ì„±í•˜ì—¬ ì ëŒ€ì  ë…¸ì´ì¦ˆë¥¼ ê±¸ëŸ¬ë‚´ë©´ì„œ ì˜ë¯¸ë¥¼ ë³´ì¡´í•©ë‹ˆë‹¤. CLIP ëª¨ë¸ì„ COCOì™€ Flickr30K ë°ì´í„°ì…‹ì—ì„œ ì‹¤í—˜í•œ ê²°ê³¼, Flickr30Kì—ì„œ Recall@1 ì •í™•ë„ë¥¼ 7.5%ì—ì„œ 19.8%ë¡œ, COCOì—ì„œëŠ” 3.8%ì—ì„œ 11.9%ë¡œ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤. ë¶„ì„ ê²°ê³¼, ë‚®ì€ ë­í¬(8-32)ì™€ ë‚®ì€ ì”ì—¬ ê°•ë„(Î±=0.1-0.2)ì˜ í…ì„œ íŠ¸ë ˆì¸ ë¶„í•´ê°€ ìµœì ì„ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ì´ ë°©ë²•ì€ ê¸°ì¡´ VLMì— ìµœì†Œí•œì˜ ì˜¤ë²„í—¤ë“œë¡œ ì ìš© ê°€ëŠ¥í•œ ì‹¤ìš©ì ì¸ ì†”ë£¨ì…˜ì…ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë¹„ì „ ì–¸ì–´ ëª¨ë¸(VLM)ì€ ë©€í‹°ëª¨ë‹¬ ì´í•´ì— ë›°ì–´ë‚˜ì§€ë§Œ ì ëŒ€ì  ê³µê²©ì— ì·¨ì•½í•˜ë‹¤.
- 2. ê¸°ì¡´ ë°©ì–´ ë°©ë²•ì€ ì¬í›ˆë ¨ì´ë‚˜ ì•„í‚¤í…ì²˜ ë³€ê²½ì´ í•„ìš”í•˜ì§€ë§Œ, ë³¸ ì—°êµ¬ì—ì„œëŠ” í…ì„œ ë¶„í•´ë¥¼ í™œìš©í•œ ê²½ëŸ‰ ë°©ì–´ ë°©ë²•ì„ ì œì•ˆí•œë‹¤.
- 3. ì œì•ˆëœ ë°©ë²•ì€ ì‚¬ì „ í›ˆë ¨ëœ VLMì— ì ìš© ê°€ëŠ¥í•˜ë©°, ì¬í›ˆë ¨ ì—†ì´ ì ëŒ€ì  ë…¸ì´ì¦ˆë¥¼ í•„í„°ë§í•˜ë©´ì„œ ì˜ë¯¸ë¥¼ ë³´ì¡´í•œë‹¤.
- 4. CLIP ëª¨ë¸ì„ COCOì™€ Flickr30K ë°ì´í„°ì…‹ì— ì ìš©í•œ ê²°ê³¼, Flickr30Kì—ì„œëŠ” ì„±ëŠ¥ì„ 12.3% íšŒë³µí•˜ê³  COCOì—ì„œëŠ” 8.1% íšŒë³µí–ˆë‹¤.
- 5. í…ì„œ íŠ¸ë ˆì¸ ë¶„í•´ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‚®ì€ ë­í¬(8-32)ì™€ ë‚®ì€ ì”ì—¬ ê°•ë„($\alpha=0.1-0.2$)ê°€ ìµœì ì„ì„ í™•ì¸í–ˆë‹¤.


---

*Generated on 2025-09-23 09:30:08*