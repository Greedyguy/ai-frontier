---
keywords:
  - Latent Diffusion Models
  - Spatial Audio
  - First-Order Ambisonics
  - Text-to-Audio Generation
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2507.07318
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T10:04:59.229559",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Latent Diffusion Models",
    "Spatial Audio",
    "First-Order Ambisonics",
    "Text-to-Audio Generation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Latent Diffusion Models": 0.78,
    "Spatial Audio": 0.82,
    "First-Order Ambisonics": 0.75,
    "Text-to-Audio Generation": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "latent diffusion models",
        "canonical": "Latent Diffusion Models",
        "aliases": [
          "LDM"
        ],
        "category": "unique_technical",
        "rationale": "Latent diffusion models are central to the paper's methodology and are a novel approach in audio generation.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "spatial audio",
        "canonical": "Spatial Audio",
        "aliases": [
          "3D audio",
          "immersive audio"
        ],
        "category": "specific_connectable",
        "rationale": "Spatial audio is a key concept in immersive applications and connects to broader research in audio technologies.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.82
      },
      {
        "surface": "first-order Ambisonics",
        "canonical": "First-Order Ambisonics",
        "aliases": [
          "FOA"
        ],
        "category": "unique_technical",
        "rationale": "First-order Ambisonics is a specific technical term relevant to the paper's focus on 3D audio localization.",
        "novelty_score": 0.68,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      },
      {
        "surface": "text-to-audio generation",
        "canonical": "Text-to-Audio Generation",
        "aliases": [
          "TTA"
        ],
        "category": "specific_connectable",
        "rationale": "Text-to-audio generation is a growing field that bridges natural language processing and audio synthesis.",
        "novelty_score": 0.6,
        "connectivity_score": 0.85,
        "specificity_score": 0.75,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "VR/AR",
      "cinema",
      "music"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "latent diffusion models",
      "resolved_canonical": "Latent Diffusion Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "spatial audio",
      "resolved_canonical": "Spatial Audio",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "first-order Ambisonics",
      "resolved_canonical": "First-Order Ambisonics",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "text-to-audio generation",
      "resolved_canonical": "Text-to-Audio Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.85,
        "specificity": 0.75,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Generating Moving 3D Soundscapes with Latent Diffusion Models

**Korean Title:** ì ì¬ í™•ì‚° ëª¨ë¸ì„ ì‚¬ìš©í•œ ì´ë™ 3D ì‚¬ìš´ë“œìŠ¤ì¼€ì´í”„ ìƒì„±

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2507.07318.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2507.07318](https://arxiv.org/abs/2507.07318)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/Spatial Audio Motion Understanding and Reasoning_20250918|Spatial Audio Motion Understanding and Reasoning]] (84.6% similar)
- [[2025-09-22/FLOAT_ Generative Motion Latent Flow Matching for Audio-driven Talking Portrait_20250922|FLOAT: Generative Motion Latent Flow Matching for Audio-driven Talking Portrait]] (83.0% similar)
- [[2025-09-17/RFM-Editing_ Rectified Flow Matching for Text-guided Audio Editing_20250917|RFM-Editing: Rectified Flow Matching for Text-guided Audio Editing]] (82.3% similar)
- [[2025-09-19/Explicit Context-Driven Neural Acoustic Modeling for High-Fidelity RIR Generation_20250919|Explicit Context-Driven Neural Acoustic Modeling for High-Fidelity RIR Generation]] (81.2% similar)
- [[2025-09-17/DSpAST_ Disentangled Representations for Spatial Audio Reasoning with Large Language Models_20250917|DSpAST: Disentangled Representations for Spatial Audio Reasoning with Large Language Models]] (80.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Spatial Audio|Spatial Audio]], [[keywords/Text-to-Audio Generation|Text-to-Audio Generation]]
**âš¡ Unique Technical**: [[keywords/Latent Diffusion Models|Latent Diffusion Models]], [[keywords/First-Order Ambisonics|First-Order Ambisonics]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2507.07318v2 Announce Type: replace-cross 
Abstract: Spatial audio has become central to immersive applications such as VR/AR, cinema, and music. Existing generative audio models are largely limited to mono or stereo formats and cannot capture the full 3D localization cues available in first-order Ambisonics (FOA). Recent FOA models extend text-to-audio generation but remain restricted to static sources. In this work, we introduce SonicMotion, the first end-to-end latent diffusion framework capable of generating FOA audio with explicit control over moving sound sources. SonicMotion is implemented in two variations: 1) a descriptive model conditioned on natural language prompts, and 2) a parametric model conditioned on both text and spatial trajectory parameters for higher precision. To support training and evaluation, we construct a new dataset of over one million simulated FOA caption pairs that include both static and dynamic sources with annotated azimuth, elevation, and motion attributes. Experiments show that SonicMotion achieves state-of-the-art semantic alignment and perceptual quality comparable to leading text-to-audio systems, while uniquely attaining low spatial localization error.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2507.07318v2 ë°œí‘œ ìœ í˜•: êµì°¨ ëŒ€ì²´  
ì´ˆë¡: ê³µê°„ ì˜¤ë””ì˜¤ëŠ” VR/AR, ì˜í™”, ìŒì•…ê³¼ ê°™ì€ ëª°ì…í˜• ì‘ìš© í”„ë¡œê·¸ë¨ì—ì„œ ì¤‘ì‹¬ì ì¸ ì—­í• ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê¸°ì¡´ì˜ ìƒì„± ì˜¤ë””ì˜¤ ëª¨ë¸ì€ ì£¼ë¡œ ëª¨ë…¸ ë˜ëŠ” ìŠ¤í…Œë ˆì˜¤ í˜•ì‹ì— ì œí•œë˜ì–´ ìˆìœ¼ë©°, 1ì°¨ ì•°ë¹„ì†Œë‹‰ìŠ¤(FOA)ì—ì„œ ì œê³µë˜ëŠ” ì™„ì „í•œ 3D ìœ„ì¹˜ ë‹¨ì„œë¥¼ í¬ì°©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìµœê·¼ì˜ FOA ëª¨ë¸ì€ í…ìŠ¤íŠ¸-ì˜¤ë””ì˜¤ ìƒì„±ìœ¼ë¡œ í™•ì¥ë˜ì—ˆì§€ë§Œ, ì—¬ì „íˆ ì •ì  ì†ŒìŠ¤ì— ì œí•œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ì—ì„œëŠ” SonicMotionì„ ì†Œê°œí•©ë‹ˆë‹¤. ì´ëŠ” ì´ë™í•˜ëŠ” ì†Œë¦¬ì˜ ì†ŒìŠ¤ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì œì–´í•  ìˆ˜ ìˆëŠ” FOA ì˜¤ë””ì˜¤ë¥¼ ìƒì„±í•  ìˆ˜ ìˆëŠ” ìµœì´ˆì˜ ì—”ë“œ íˆ¬ ì—”ë“œ ì ì¬ í™•ì‚° í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. SonicMotionì€ ë‘ ê°€ì§€ ë³€í˜•ìœ¼ë¡œ êµ¬í˜„ë©ë‹ˆë‹¤: 1) ìì—°ì–´ í”„ë¡¬í”„íŠ¸ì— ì¡°ê±´í™”ëœ ì„¤ëª…ì  ëª¨ë¸, 2) ë” ë†’ì€ ì •ë°€ë„ë¥¼ ìœ„í•´ í…ìŠ¤íŠ¸ì™€ ê³µê°„ ê¶¤ì  ë§¤ê°œë³€ìˆ˜ ëª¨ë‘ì— ì¡°ê±´í™”ëœ íŒŒë¼ë©”íŠ¸ë¦­ ëª¨ë¸. í›ˆë ¨ê³¼ í‰ê°€ë¥¼ ì§€ì›í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ì •ì  ë° ë™ì  ì†ŒìŠ¤ë¥¼ í¬í•¨í•œ 100ë§Œ ê°œ ì´ìƒì˜ ì‹œë®¬ë ˆì´ì…˜ëœ FOA ìº¡ì…˜ ìŒì„ í¬í•¨í•˜ëŠ” ìƒˆë¡œìš´ ë°ì´í„°ì…‹ì„ êµ¬ì¶•í•˜ì˜€ìœ¼ë©°, ì—¬ê¸°ì—ëŠ” ë°©ìœ„ê°, ê³ ë„, ìš´ë™ ì†ì„±ì— ëŒ€í•œ ì£¼ì„ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, SonicMotionì€ ìµœì²¨ë‹¨ì˜ ì˜ë¯¸ì  ì •ë ¬ê³¼ ì§€ê°ì  í’ˆì§ˆì„ ë‹¬ì„±í•˜ë©°, ë…ì°½ì ìœ¼ë¡œ ë‚®ì€ ê³µê°„ ìœ„ì¹˜ ì˜¤ë¥˜ë¥¼ ë‹¬ì„±í•˜ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ SonicMotionì´ë¼ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¥¼ ì†Œê°œí•˜ë©°, ì´ëŠ” ìµœì´ˆë¡œ ì›€ì§ì´ëŠ” ìŒì›ì— ëŒ€í•œ ëª…ì‹œì  ì œì–´ê°€ ê°€ëŠ¥í•œ FOA(First-Order Ambisonics) ì˜¤ë””ì˜¤ ìƒì„± ëª¨ë¸ì…ë‹ˆë‹¤. SonicMotionì€ ìì—°ì–´ í”„ë¡¬í”„íŠ¸ì— ê¸°ë°˜í•œ ê¸°ìˆ ì  ëª¨ë¸ê³¼ í…ìŠ¤íŠ¸ ë° ê³µê°„ ê¶¤ì  ë§¤ê°œë³€ìˆ˜ì— ê¸°ë°˜í•œ íŒŒë¼ë©”íŠ¸ë¦­ ëª¨ë¸ ë‘ ê°€ì§€ë¡œ êµ¬í˜„ë©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ì •ì  ë° ë™ì  ìŒì›ì— ëŒ€í•œ ë°©ìœ„ê°, ê³ ë„, ì›€ì§ì„ ì†ì„±ì„ í¬í•¨í•œ ë°±ë§Œ ê°œ ì´ìƒì˜ FOA ìº¡ì…˜ ìŒì„ í¬í•¨í•˜ëŠ” ìƒˆë¡œìš´ ë°ì´í„°ì…‹ì„ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, SonicMotionì€ ìµœì²¨ë‹¨ ì˜ë¯¸ì  ì •ë ¬ê³¼ ì§€ê°ì  í’ˆì§ˆì„ ë‹¬ì„±í•˜ë©°, íŠ¹íˆ ë‚®ì€ ê³µê°„ì  ìœ„ì¹˜ ì˜¤ì°¨ë¥¼ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. SonicMotionì€ ìµœì´ˆë¡œ ì›€ì§ì´ëŠ” ìŒì›ì— ëŒ€í•œ ëª…ì‹œì  ì œì–´ê°€ ê°€ëŠ¥í•œ FOA ì˜¤ë””ì˜¤ ìƒì„± í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.
- 2. SonicMotionì€ ìì—°ì–´ í”„ë¡¬í”„íŠ¸ì— ì¡°ê±´ì„ ë‘ëŠ” ì„¤ëª…ì  ëª¨ë¸ê³¼ í…ìŠ¤íŠ¸ ë° ê³µê°„ ê¶¤ì  ë§¤ê°œë³€ìˆ˜ì— ì¡°ê±´ì„ ë‘ëŠ” íŒŒë¼ë©”íŠ¸ë¦­ ëª¨ë¸ë¡œ êµ¬í˜„ë©ë‹ˆë‹¤.
- 3. ìƒˆë¡œìš´ ë°ì´í„°ì…‹ì€ ì •ì  ë° ë™ì  ì†ŒìŠ¤ì™€ ì£¼ì„ì´ ë‹¬ë¦° ë°©ìœ„ê°, ê³ ë„, ìš´ë™ ì†ì„±ì„ í¬í•¨í•˜ì—¬ ë°±ë§Œ ê°œ ì´ìƒì˜ ì‹œë®¬ë ˆì´ì…˜ëœ FOA ìº¡ì…˜ ìŒìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.
- 4. SonicMotionì€ ìµœì²¨ë‹¨ ì˜ë¯¸ ì •ë ¬ê³¼ ì§€ê°ì  í’ˆì§ˆì„ ë‹¬ì„±í•˜ë©°, íŠ¹íˆ ë‚®ì€ ê³µê°„ì  ìœ„ì¹˜ ì˜¤ë¥˜ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.


---

*Generated on 2025-09-23 10:04:59*