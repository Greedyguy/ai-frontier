---
keywords:
  - Large Language Model
  - Retrieval-Augmented Code Completion
  - Multi-path Code Retrieval
  - BestFit Reranking
  - Retrieval Augmented Generation
category: cs.CL
publish_date: 2025-09-22
arxiv_id: 2509.16112
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:36:22.496369",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Retrieval-Augmented Code Completion",
    "Multi-path Code Retrieval",
    "BestFit Reranking",
    "Retrieval Augmented Generation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.82,
    "Retrieval-Augmented Code Completion": 0.78,
    "Multi-path Code Retrieval": 0.75,
    "BestFit Reranking": 0.73,
    "Retrieval Augmented Generation": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Code Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "Code LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are central to the paper's discussion on code completion, providing a strong link to existing research in machine learning.",
        "novelty_score": 0.45,
        "connectivity_score": 0.87,
        "specificity_score": 0.68,
        "link_intent_score": 0.82
      },
      {
        "surface": "Retrieval-Augmented Repository-Level Code Completion",
        "canonical": "Retrieval-Augmented Code Completion",
        "aliases": [
          "Repository-Level Code Completion"
        ],
        "category": "unique_technical",
        "rationale": "This concept is unique to the paper and represents a novel approach to code completion, enhancing its novelty and specificity.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.81,
        "link_intent_score": 0.78
      },
      {
        "surface": "Multi-path Code Retrieval",
        "canonical": "Multi-path Code Retrieval",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This technique addresses specific issues in code retrieval, offering a unique method that can be linked to improvements in code completion.",
        "novelty_score": 0.68,
        "connectivity_score": 0.72,
        "specificity_score": 0.79,
        "link_intent_score": 0.75
      },
      {
        "surface": "Preference-aligned BestFit Reranking",
        "canonical": "BestFit Reranking",
        "aliases": [
          "Preference-aligned Reranking"
        ],
        "category": "unique_technical",
        "rationale": "This reranking method is a novel contribution of the paper, enhancing the specificity and novelty of the retrieval process.",
        "novelty_score": 0.7,
        "connectivity_score": 0.68,
        "specificity_score": 0.77,
        "link_intent_score": 0.73
      },
      {
        "surface": "Retrieval Augmented Generation",
        "canonical": "Retrieval Augmented Generation",
        "aliases": [
          "RAG"
        ],
        "category": "specific_connectable",
        "rationale": "RAG is a trending concept that connects well with the retrieval-augmented methods discussed in the paper.",
        "novelty_score": 0.55,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Code Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.87,
        "specificity": 0.68,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Retrieval-Augmented Repository-Level Code Completion",
      "resolved_canonical": "Retrieval-Augmented Code Completion",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.81,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Multi-path Code Retrieval",
      "resolved_canonical": "Multi-path Code Retrieval",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.72,
        "specificity": 0.79,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Preference-aligned BestFit Reranking",
      "resolved_canonical": "BestFit Reranking",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.68,
        "specificity": 0.77,
        "link_intent": 0.73
      }
    },
    {
      "candidate_surface": "Retrieval Augmented Generation",
      "resolved_canonical": "Retrieval Augmented Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# CodeRAG: Finding Relevant and Necessary Knowledge for Retrieval-Augmented Repository-Level Code Completion

**Korean Title:** CodeRAG: ê²€ìƒ‰ ì¦ê°• ì €ì¥ì†Œ ìˆ˜ì¤€ ì½”ë“œ ì™„ì„±ì„ ìœ„í•œ ê´€ë ¨ ë° í•„ìˆ˜ ì§€ì‹ ì°¾ê¸°

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16112.pdf)
**Category**: cs.CL
**Published**: 2025-09-22
**ArXiv ID**: [2509.16112](https://arxiv.org/abs/2509.16112)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Enhancing Retrieval Augmentation via Adversarial Collaboration_20250919|Enhancing Retrieval Augmentation via Adversarial Collaboration]] (86.0% similar)
- [[2025-09-22/CORE-RAG_ Lossless Compression for Retrieval-Augmented LLMs via Reinforcement Learning_20250922|CORE-RAG: Lossless Compression for Retrieval-Augmented LLMs via Reinforcement Learning]] (85.7% similar)
- [[2025-09-22/RPG_ A Repository Planning Graph for Unified and Scalable Codebase Generation_20250922|RPG: A Repository Planning Graph for Unified and Scalable Codebase Generation]] (84.1% similar)
- [[2025-09-19/Engineering RAG Systems for Real-World Applications_ Design, Development, and Evaluation_20250919|Engineering RAG Systems for Real-World Applications: Design, Development, and Evaluation]] (84.1% similar)
- [[2025-09-18/KGCompass_ Knowledge Graph Enhanced Repository-Level Software Repair_20250918|KGCompass: Knowledge Graph Enhanced Repository-Level Software Repair]] (83.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Retrieval Augmented Generation|Retrieval Augmented Generation]]
**âš¡ Unique Technical**: [[keywords/Retrieval-Augmented Code Completion|Retrieval-Augmented Code Completion]], [[keywords/Multi-path Code Retrieval|Multi-path Code Retrieval]], [[keywords/BestFit Reranking|BestFit Reranking]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16112v1 Announce Type: new 
Abstract: Repository-level code completion automatically predicts the unfinished code based on the broader information from the repository. Recent strides in Code Large Language Models (code LLMs) have spurred the development of repository-level code completion methods, yielding promising results. Nevertheless, they suffer from issues such as inappropriate query construction, single-path code retrieval, and misalignment between code retriever and code LLM. To address these problems, we introduce CodeRAG, a framework tailored to identify relevant and necessary knowledge for retrieval-augmented repository-level code completion. Its core components include log probability guided query construction, multi-path code retrieval, and preference-aligned BestFit reranking. Extensive experiments on benchmarks ReccEval and CCEval demonstrate that CodeRAG significantly and consistently outperforms state-of-the-art methods. The implementation of CodeRAG is available at https://github.com/KDEGroup/CodeRAG.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.16112v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: ì €ì¥ì†Œ ìˆ˜ì¤€ì˜ ì½”ë“œ ì™„ì„±ì€ ì €ì¥ì†Œì˜ ê´‘ë²”ìœ„í•œ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¯¸ì™„ì„± ì½”ë“œë¥¼ ìë™ìœ¼ë¡œ ì˜ˆì¸¡í•©ë‹ˆë‹¤. ìµœê·¼ ì½”ë“œ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(Code LLMs)ì˜ ë°œì „ì€ ì €ì¥ì†Œ ìˆ˜ì¤€ì˜ ì½”ë“œ ì™„ì„± ë°©ë²• ê°œë°œì„ ì´‰ì§„í•˜ì—¬ ìœ ë§í•œ ê²°ê³¼ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤. ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³ , ë¶€ì ì ˆí•œ ì¿¼ë¦¬ êµ¬ì„±, ë‹¨ì¼ ê²½ë¡œ ì½”ë“œ ê²€ìƒ‰, ì½”ë“œ ê²€ìƒ‰ê¸°ì™€ ì½”ë“œ LLM ê°„ì˜ ë¶ˆì¼ì¹˜ì™€ ê°™ì€ ë¬¸ì œë¥¼ ê²ªê³  ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ê²€ìƒ‰ ë³´ê°• ì €ì¥ì†Œ ìˆ˜ì¤€ ì½”ë“œ ì™„ì„±ì„ ìœ„í•œ ê´€ë ¨ ë° í•„ìˆ˜ ì§€ì‹ì„ ì‹ë³„í•˜ë„ë¡ ì„¤ê³„ëœ í”„ë ˆì„ì›Œí¬ì¸ CodeRAGë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. CodeRAGì˜ í•µì‹¬ êµ¬ì„± ìš”ì†ŒëŠ” ë¡œê·¸ í™•ë¥  ê¸°ë°˜ ì¿¼ë¦¬ êµ¬ì„±, ë‹¤ì¤‘ ê²½ë¡œ ì½”ë“œ ê²€ìƒ‰, ê·¸ë¦¬ê³  ì„ í˜¸ë„ì— ë§ì¶˜ BestFit ì¬ì •ë ¬ì„ í¬í•¨í•©ë‹ˆë‹¤. ReccEvalê³¼ CCEval ë²¤ì¹˜ë§ˆí¬ì— ëŒ€í•œ ê´‘ë²”ìœ„í•œ ì‹¤í—˜ì€ CodeRAGê°€ ìµœì²¨ë‹¨ ë°©ë²•ë“¤ì„ ìƒë‹¹íˆ ê·¸ë¦¬ê³  ì¼ê´€ë˜ê²Œ ëŠ¥ê°€í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. CodeRAGì˜ êµ¬í˜„ì€ https://github.com/KDEGroup/CodeRAGì—ì„œ ì´ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì €ì¥ì†Œ ìˆ˜ì¤€ì˜ ì½”ë“œ ìë™ ì™„ì„±ì„ ìœ„í•œ ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ì¸ CodeRAGë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ì½”ë“œ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(Code LLMs)ì€ ë¶€ì ì ˆí•œ ì¿¼ë¦¬ êµ¬ì„±, ë‹¨ì¼ ê²½ë¡œ ì½”ë“œ ê²€ìƒ‰, ì½”ë“œ ê²€ìƒ‰ê¸°ì™€ ì½”ë“œ LLM ê°„ì˜ ë¶ˆì¼ì¹˜ ë¬¸ì œë¥¼ ê°€ì§€ê³  ìˆì—ˆìŠµë‹ˆë‹¤. CodeRAGëŠ” ë¡œê·¸ í™•ë¥  ê¸°ë°˜ ì¿¼ë¦¬ êµ¬ì„±, ë‹¤ì¤‘ ê²½ë¡œ ì½”ë“œ ê²€ìƒ‰, ì„ í˜¸ë„ ì •ë ¬ BestFit ì¬ì •ë ¬ì„ í†µí•´ ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, CodeRAGëŠ” ReccEval ë° CCEval ë²¤ì¹˜ë§ˆí¬ì—ì„œ ê¸°ì¡´ ìµœì²¨ë‹¨ ë°©ë²•ë“¤ì„ ë›°ì–´ë„˜ëŠ” ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. CodeRAGì˜ êµ¬í˜„ì€ GitHubì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. CodeRAGëŠ” ì €ì¥ì†Œ ìˆ˜ì¤€ì˜ ì½”ë“œ ì™„ì„±ì„ ìœ„í•œ ê²€ìƒ‰ ë³´ê°• í”„ë ˆì„ì›Œí¬ë¡œ, ê´€ë ¨ ì§€ì‹ ì‹ë³„ì— ì¤‘ì ì„ ë‘¡ë‹ˆë‹¤.
- 2. CodeRAGëŠ” ë¡œê·¸ í™•ë¥  ê¸°ë°˜ ì¿¼ë¦¬ ìƒì„±, ë‹¤ì¤‘ ê²½ë¡œ ì½”ë“œ ê²€ìƒ‰, ì„ í˜¸ë„ ì •ë ¬ BestFit ì¬ì •ë ¬ì„ í•µì‹¬ êµ¬ì„± ìš”ì†Œë¡œ í¬í•¨í•©ë‹ˆë‹¤.
- 3. ReccEval ë° CCEval ë²¤ì¹˜ë§ˆí¬ ì‹¤í—˜ì—ì„œ CodeRAGëŠ” ìµœì‹  ë°©ë²•ë“¤ì„ ëŠ¥ê°€í•˜ëŠ” ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
- 4. CodeRAGì˜ êµ¬í˜„ ì½”ë“œëŠ” https://github.com/KDEGroup/CodeRAGì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-23 11:36:22*