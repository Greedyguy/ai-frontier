# Large Vision Models Can Solve Mental Rotation Problems

**Korean Title:** 대형 비전 모델은 정신 회전 문제를 해결할 수 있다.

## 📋 메타데이터

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Self-supervised Learning

## 🔗 유사한 논문
- [[2025-09-19/Leveraging Geometric Visual Illusions as Perceptual Inductive Biases for Vision Models_20250919|Leveraging Geometric Visual Illusions as Perceptual Inductive Biases for Vision Models]] (82.2% similar)
- [[2025-09-19/Learning Discrete Abstractions for Visual Rearrangement Tasks Using Vision-Guided Graph Coloring_20250919|Learning Discrete Abstractions for Visual Rearrangement Tasks Using Vision-Guided Graph Coloring]] (80.8% similar)
- [[2025-09-18/TrajBooster_ Boosting Humanoid Whole-Body Manipulation via Trajectory-Centric Learning_20250918|TrajBooster Boosting Humanoid Whole-Body Manipulation via Trajectory-Centric Learning]] (80.0% similar)
- [[2025-09-18/Embodied Navigation Foundation Model_20250918|Embodied Navigation Foundation Model]] (79.5% similar)
- [[2025-09-19/VLM-E2E_ Enhancing End-to-End Autonomous Driving with Multimodal Driver Attention Fusion_20250919|VLM-E2E Enhancing End-to-End Autonomous Driving with Multimodal Driver Attention Fusion]] (78.8% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.15271v1 Announce Type: cross 
Abstract: Mental rotation is a key test of spatial reasoning in humans and has been central to understanding how perception supports cognition. Despite the success of modern vision transformers, it is still unclear how well these models develop similar abilities. In this work, we present a systematic evaluation of ViT, CLIP, DINOv2, and DINOv3 across a range of mental-rotation tasks, from simple block structures similar to those used by Shepard and Metzler to study human cognition, to more complex block figures, three types of text, and photo-realistic objects. By probing model representations layer by layer, we examine where and how these networks succeed. We find that i) self-supervised ViTs capture geometric structure better than supervised ViTs; ii) intermediate layers perform better than final layers; iii) task difficulty increases with rotation complexity and occlusion, mirroring human reaction times and suggesting similar constraints in embedding space representations.

## 🔍 Abstract (한글 번역)

arXiv:2509.15271v1 발표 유형: 교차  
초록: 정신적 회전은 인간의 공간 추론을 평가하는 중요한 시험이며, 지각이 인지를 어떻게 지원하는지를 이해하는 데 중심적인 역할을 해왔습니다. 현대의 비전 트랜스포머가 성공을 거두었음에도 불구하고, 이러한 모델들이 유사한 능력을 얼마나 잘 개발하는지는 여전히 불분명합니다. 본 연구에서는 ViT, CLIP, DINOv2, DINOv3를 대상으로 Shepard와 Metzler가 인간 인지를 연구하기 위해 사용한 단순한 블록 구조에서부터 복잡한 블록 도형, 세 가지 유형의 텍스트, 그리고 사진 실사 객체에 이르기까지 다양한 정신적 회전 과제를 체계적으로 평가합니다. 모델 표현을 층별로 탐색하여, 이러한 네트워크들이 어디에서 어떻게 성공하는지를 조사합니다. 우리는 i) 자가 지도 학습된 ViT가 지도 학습된 ViT보다 기하학적 구조를 더 잘 포착한다는 것; ii) 중간 층이 최종 층보다 더 잘 수행한다는 것; iii) 회전 복잡성과 가림 현상이 증가함에 따라 과제 난이도가 증가하며, 이는 인간의 반응 시간과 유사한 제약을 임베딩 공간 표현에서 암시한다는 것을 발견했습니다.

## 📝 요약

이 논문은 인간의 공간 추론을 평가하는 정신 회전 과제를 통해 최신 비전 트랜스포머(ViT, CLIP, DINOv2, DINOv3)의 능력을 체계적으로 평가합니다. 연구 결과, 자기 지도 학습된 ViT가 지도 학습된 ViT보다 기하학적 구조를 더 잘 포착하며, 중간 계층이 최종 계층보다 성능이 우수함을 발견했습니다. 또한, 회전 복잡성과 가림 현상이 증가할수록 과제 난이도가 높아져 인간의 반응 시간과 유사한 제약을 나타냅니다. 이 연구는 비전 트랜스포머의 인지적 능력을 이해하는 데 기여합니다.

## 🎯 주요 포인트

- 1. 자기 지도 학습된 비전 트랜스포머(ViT)는 지도 학습된 ViT보다 기하학적 구조를 더 잘 포착한다.

- 2. 중간 계층이 최종 계층보다 정신 회전 과제에서 더 나은 성능을 보인다.

- 3. 회전 복잡성과 가림 현상이 증가할수록 과제 난이도가 높아지며, 이는 인간의 반응 시간과 유사한 제약을 나타낸다.

---

*Generated on 2025-09-22 13:52:21*