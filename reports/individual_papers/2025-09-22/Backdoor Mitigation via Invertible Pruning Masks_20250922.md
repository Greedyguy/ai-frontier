---
keywords:
  - Backdoor Attacks
  - Model Pruning
  - Invertible Pruning Mask
  - Bi-level Optimization
  - Backdoor Mitigation
category: cs.CV
publish_date: 2025-09-22
arxiv_id: 2509.15497
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:59:02.266302",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Backdoor Attacks",
    "Model Pruning",
    "Invertible Pruning Mask",
    "Bi-level Optimization",
    "Backdoor Mitigation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Backdoor Attacks": 0.78,
    "Model Pruning": 0.77,
    "Invertible Pruning Mask": 0.72,
    "Bi-level Optimization": 0.75,
    "Backdoor Mitigation": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "backdoor attacks",
        "canonical": "Backdoor Attacks",
        "aliases": [
          "backdoor threats",
          "backdoor vulnerabilities"
        ],
        "category": "specific_connectable",
        "rationale": "Backdoor attacks are a critical concern in deep learning security, making them a key point for linking related research.",
        "novelty_score": 0.58,
        "connectivity_score": 0.85,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "model pruning",
        "canonical": "Model Pruning",
        "aliases": [
          "pruning techniques",
          "pruning methods"
        ],
        "category": "specific_connectable",
        "rationale": "Model pruning is a widely used technique in deep learning, relevant for optimizing models and mitigating backdoor attacks.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.77
      },
      {
        "surface": "invertible pruning mask",
        "canonical": "Invertible Pruning Mask",
        "aliases": [
          "reversible pruning mask"
        ],
        "category": "unique_technical",
        "rationale": "This novel concept introduces a reversible mechanism in pruning, offering a new dimension to model optimization and security.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.72
      },
      {
        "surface": "bi-level optimization",
        "canonical": "Bi-level Optimization",
        "aliases": [
          "hierarchical optimization"
        ],
        "category": "specific_connectable",
        "rationale": "Bi-level optimization is a sophisticated mathematical approach that can be linked to various optimization problems in machine learning.",
        "novelty_score": 0.6,
        "connectivity_score": 0.82,
        "specificity_score": 0.78,
        "link_intent_score": 0.75
      },
      {
        "surface": "backdoor mitigation",
        "canonical": "Backdoor Mitigation",
        "aliases": [
          "backdoor defense",
          "backdoor neutralization"
        ],
        "category": "specific_connectable",
        "rationale": "Mitigating backdoor threats is a crucial aspect of enhancing model security, making it a strong link candidate.",
        "novelty_score": 0.57,
        "connectivity_score": 0.84,
        "specificity_score": 0.76,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "fine-tuning",
      "performance",
      "experiment"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "backdoor attacks",
      "resolved_canonical": "Backdoor Attacks",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.85,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "model pruning",
      "resolved_canonical": "Model Pruning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "invertible pruning mask",
      "resolved_canonical": "Invertible Pruning Mask",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "bi-level optimization",
      "resolved_canonical": "Bi-level Optimization",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.82,
        "specificity": 0.78,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "backdoor mitigation",
      "resolved_canonical": "Backdoor Mitigation",
      "decision": "linked",
      "scores": {
        "novelty": 0.57,
        "connectivity": 0.84,
        "specificity": 0.76,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Backdoor Mitigation via Invertible Pruning Masks

**Korean Title:** 백도어 완화를 위한 가역적 가지치기 마스크 사용

## 📋 메타데이터

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15497.pdf)
**Category**: cs.CV
**Published**: 2025-09-22
**ArXiv ID**: [2509.15497](https://arxiv.org/abs/2509.15497)

## 🔗 유사한 논문
- [[2025-09-22/Inverting Trojans in LLMs_20250922|Inverting Trojans in LLMs]] (84.4% similar)
- [[2025-09-22/Activation Space Interventions Can Be Transferred Between Large Language Models_20250922|Activation Space Interventions Can Be Transferred Between Large Language Models]] (83.9% similar)
- [[2025-09-19/Decoupled Proxy Alignment_ Mitigating Language Prior Conflict for Multimodal Alignment in MLLM_20250919|Decoupled Proxy Alignment: Mitigating Language Prior Conflict for Multimodal Alignment in MLLM]] (81.3% similar)
- [[2025-09-22/Beyond Spurious Signals_ Debiasing Multimodal Large Language Models via Counterfactual Inference and Adaptive Expert Routing_20250922|Beyond Spurious Signals: Debiasing Multimodal Large Language Models via Counterfactual Inference and Adaptive Expert Routing]] (80.8% similar)
- [[2025-09-22/Robust Vision-Language Models via Tensor Decomposition_ A Defense Against Adversarial Attacks_20250922|Robust Vision-Language Models via Tensor Decomposition: A Defense Against Adversarial Attacks]] (80.8% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Backdoor Attacks|Backdoor Attacks]], [[keywords/Model Pruning|Model Pruning]], [[keywords/Bi-level Optimization|Bi-level Optimization]], [[keywords/Backdoor Mitigation|Backdoor Mitigation]]
**⚡ Unique Technical**: [[keywords/Invertible Pruning Mask|Invertible Pruning Mask]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.15497v1 Announce Type: new 
Abstract: Model pruning has gained traction as a promising defense strategy against backdoor attacks in deep learning. However, existing pruning-based approaches often fall short in accurately identifying and removing the specific parameters responsible for inducing backdoor behaviors. Despite the dominance of fine-tuning-based defenses in recent literature, largely due to their superior performance, pruning remains a compelling alternative, offering greater interpretability and improved robustness in low-data regimes. In this paper, we propose a novel pruning approach featuring a learned \emph{selection} mechanism to identify parameters critical to both main and backdoor tasks, along with an \emph{invertible} pruning mask designed to simultaneously achieve two complementary goals: eliminating the backdoor task while preserving it through the inverse mask. We formulate this as a bi-level optimization problem that jointly learns selection variables, a sparse invertible mask, and sample-specific backdoor perturbations derived from clean data. The inner problem synthesizes candidate triggers using the inverse mask, while the outer problem refines the mask to suppress backdoor behavior without impairing clean-task accuracy. Extensive experiments demonstrate that our approach outperforms existing pruning-based backdoor mitigation approaches, maintains strong performance under limited data conditions, and achieves competitive results compared to state-of-the-art fine-tuning approaches. Notably, the proposed approach is particularly effective in restoring correct predictions for compromised samples after successful backdoor mitigation.

## 🔍 Abstract (한글 번역)

arXiv:2509.15497v1 발표 유형: 신규  
초록: 모델 가지치기는 딥러닝에서 백도어 공격에 대한 유망한 방어 전략으로 주목받고 있습니다. 그러나 기존의 가지치기 기반 접근법은 백도어 행동을 유발하는 특정 매개변수를 정확하게 식별하고 제거하는 데 종종 부족합니다. 최근 문헌에서 미세 조정 기반 방어가 우세한 이유는 주로 그 우수한 성능 때문이지만, 가지치기는 해석 가능성과 적은 데이터 환경에서의 향상된 견고성을 제공하는 매력적인 대안으로 남아 있습니다. 본 논문에서는 주 및 백도어 작업 모두에 중요한 매개변수를 식별하기 위한 학습된 \emph{선택} 메커니즘과, 백도어 작업을 제거하면서 동시에 역 마스크를 통해 이를 보존하는 두 가지 상호 보완적인 목표를 달성하기 위해 설계된 \emph{가역} 가지치기 마스크를 특징으로 하는 새로운 가지치기 접근법을 제안합니다. 우리는 이를 선택 변수, 희소 가역 마스크, 그리고 깨끗한 데이터에서 파생된 샘플 특유의 백도어 변형을 공동으로 학습하는 이중 최적화 문제로 공식화합니다. 내부 문제는 역 마스크를 사용하여 후보 트리거를 합성하고, 외부 문제는 깨끗한 작업의 정확도를 손상시키지 않으면서 백도어 행동을 억제하기 위해 마스크를 정제합니다. 광범위한 실험을 통해 우리의 접근법이 기존의 가지치기 기반 백도어 완화 접근법을 능가하고, 제한된 데이터 조건에서도 강력한 성능을 유지하며, 최신 미세 조정 접근법과 비교하여 경쟁력 있는 결과를 달성함을 보여줍니다. 특히, 제안된 접근법은 성공적인 백도어 완화 후 손상된 샘플에 대한 올바른 예측을 복원하는 데 매우 효과적입니다.

## 📝 요약

이 논문은 딥러닝에서 백도어 공격을 방어하기 위한 모델 프루닝 기법을 제안합니다. 기존의 프루닝 기법은 백도어 행동을 유발하는 특정 파라미터를 정확히 식별하고 제거하는 데 한계가 있습니다. 본 연구는 학습된 선택 메커니즘과 가역적인 프루닝 마스크를 사용하여 주요 작업과 백도어 작업에 중요한 파라미터를 식별하고, 백도어 작업을 제거하면서도 이를 보존할 수 있는 방법을 제시합니다. 이 방법은 이중 최적화 문제로 구성되어 있으며, 실험 결과 제한된 데이터 상황에서도 강력한 성능을 유지하고, 최신의 파인튜닝 기법과 비교해 경쟁력 있는 결과를 보여줍니다. 특히, 백도어 공격이 성공적으로 완화된 후 손상된 샘플에 대한 올바른 예측을 복원하는 데 효과적입니다.

## 🎯 주요 포인트

- 1. 모델 가지치기는 딥러닝에서 백도어 공격에 대한 유망한 방어 전략으로 주목받고 있다.
- 2. 기존의 가지치기 기반 방법들은 백도어 행동을 유도하는 특정 파라미터를 정확히 식별하고 제거하는 데 한계가 있다.
- 3. 본 논문에서는 주요 및 백도어 작업에 중요한 파라미터를 식별하는 학습된 선택 메커니즘과 역가역적인 가지치기 마스크를 특징으로 하는 새로운 가지치기 접근법을 제안한다.
- 4. 제안된 방법은 제한된 데이터 조건에서도 강력한 성능을 유지하며, 최신 미세 조정 방법과 비교하여 경쟁력 있는 결과를 달성한다.
- 5. 특히, 제안된 접근법은 성공적인 백도어 완화 후 손상된 샘플에 대한 올바른 예측을 복원하는 데 효과적이다.


---

*Generated on 2025-09-23 11:59:02*