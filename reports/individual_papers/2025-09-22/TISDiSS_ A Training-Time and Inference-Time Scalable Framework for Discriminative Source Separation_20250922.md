---
keywords:
  - Source Separation
  - TISDiSS Framework
  - Dynamic Inference
  - Parameter Sharing
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2509.15666
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T09:09:16.351099",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Source Separation",
    "TISDiSS Framework",
    "Dynamic Inference",
    "Parameter Sharing"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Source Separation": 0.85,
    "TISDiSS Framework": 0.8,
    "Dynamic Inference": 0.78,
    "Parameter Sharing": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "source separation",
        "canonical": "Source Separation",
        "aliases": [
          "audio separation",
          "speech separation"
        ],
        "category": "specific_connectable",
        "rationale": "Source separation is a key task in audio processing, linking to various applications in speech and music.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "TISDiSS",
        "canonical": "TISDiSS Framework",
        "aliases": [
          "Training-Time and Inference-Time Scalable Discriminative Source Separation"
        ],
        "category": "unique_technical",
        "rationale": "TISDiSS is a novel framework introduced in the paper, offering a scalable solution for source separation.",
        "novelty_score": 0.95,
        "connectivity_score": 0.6,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "dynamic inference repetitions",
        "canonical": "Dynamic Inference",
        "aliases": [
          "adaptive inference",
          "scalable inference"
        ],
        "category": "evolved_concepts",
        "rationale": "Dynamic inference is an evolving concept that allows flexible performance adjustments, relevant to adaptive systems.",
        "novelty_score": 0.7,
        "connectivity_score": 0.75,
        "specificity_score": 0.78,
        "link_intent_score": 0.78
      },
      {
        "surface": "shared-parameter design",
        "canonical": "Parameter Sharing",
        "aliases": [
          "shared parameters",
          "parameter reuse"
        ],
        "category": "specific_connectable",
        "rationale": "Parameter sharing is a technique that enhances model efficiency, relevant to network design discussions.",
        "novelty_score": 0.55,
        "connectivity_score": 0.82,
        "specificity_score": 0.65,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "training",
      "performance",
      "experiment"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "source separation",
      "resolved_canonical": "Source Separation",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "TISDiSS",
      "resolved_canonical": "TISDiSS Framework",
      "decision": "linked",
      "scores": {
        "novelty": 0.95,
        "connectivity": 0.6,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "dynamic inference repetitions",
      "resolved_canonical": "Dynamic Inference",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.75,
        "specificity": 0.78,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "shared-parameter design",
      "resolved_canonical": "Parameter Sharing",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.82,
        "specificity": 0.65,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# TISDiSS: A Training-Time and Inference-Time Scalable Framework for Discriminative Source Separation

**Korean Title:** TISDiSS: íŒë³„ì  ì†ŒìŠ¤ ë¶„ë¦¬ë¥¼ ìœ„í•œ í•™ìŠµ ì‹œ ë° ì¶”ë¡  ì‹œ í™•ì¥ ê°€ëŠ¥í•œ í”„ë ˆì„ì›Œí¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15666.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2509.15666](https://arxiv.org/abs/2509.15666)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/SpeechOp_ Inference-Time Task Composition for Generative Speech Processing_20250919|SpeechOp: Inference-Time Task Composition for Generative Speech Processing]] (81.8% similar)
- [[2025-09-19/Diffusion-Based Unsupervised Audio-Visual Speech Separation in Noisy Environments with Noise Prior_20250919|Diffusion-Based Unsupervised Audio-Visual Speech Separation in Noisy Environments with Noise Prior]] (81.6% similar)
- [[2025-09-22/SETrLUSI_ Stochastic Ensemble Multi-Source Transfer Learning Using Statistical Invariant_20250922|SETrLUSI: Stochastic Ensemble Multi-Source Transfer Learning Using Statistical Invariant]] (80.5% similar)
- [[2025-09-22/Time-adaptive SympNets for separable Hamiltonian systems_20250922|Time-adaptive SympNets for separable Hamiltonian systems]] (78.9% similar)
- [[2025-09-17/Slim-SC_ Thought Pruning for Efficient Scaling with Self-Consistency_20250917|Slim-SC: Thought Pruning for Efficient Scaling with Self-Consistency]] (78.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Source Separation|Source Separation]], [[keywords/Parameter Sharing|Parameter Sharing]]
**âš¡ Unique Technical**: [[keywords/TISDiSS Framework|TISDiSS Framework]]
**ğŸš€ Evolved Concepts**: [[keywords/Dynamic Inference|Dynamic Inference]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15666v1 Announce Type: cross 
Abstract: Source separation is a fundamental task in speech, music, and audio processing, and it also provides cleaner and larger data for training generative models. However, improving separation performance in practice often depends on increasingly large networks, inflating training and deployment costs. Motivated by recent advances in inference-time scaling for generative modeling, we propose Training-Time and Inference-Time Scalable Discriminative Source Separation (TISDiSS), a unified framework that integrates early-split multi-loss supervision, shared-parameter design, and dynamic inference repetitions. TISDiSS enables flexible speed-performance trade-offs by adjusting inference depth without retraining additional models. We further provide systematic analyses of architectural and training choices and show that training with more inference repetitions improves shallow-inference performance, benefiting low-latency applications. Experiments on standard speech separation benchmarks demonstrate state-of-the-art performance with a reduced parameter count, establishing TISDiSS as a scalable and practical framework for adaptive source separation.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15666v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ì†ŒìŠ¤ ë¶„ë¦¬ëŠ” ìŒì„±, ìŒì•… ë° ì˜¤ë””ì˜¤ ì²˜ë¦¬ì—ì„œ ê¸°ë³¸ì ì¸ ì‘ì—…ì´ë©°, ìƒì„± ëª¨ë¸ì„ í›ˆë ¨í•˜ê¸° ìœ„í•œ ë” ê¹¨ë—í•˜ê³  í° ë°ì´í„°ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì‹¤ì œë¡œ ë¶„ë¦¬ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê²ƒì€ ì¢…ì¢… ì ì  ë” í° ë„¤íŠ¸ì›Œí¬ì— ì˜ì¡´í•˜ê²Œ ë˜ì–´ í›ˆë ¨ ë° ë°°í¬ ë¹„ìš©ì´ ì¦ê°€í•©ë‹ˆë‹¤. ìƒì„± ëª¨ë¸ë§ì„ ìœ„í•œ ì¶”ë¡  ì‹œê°„ í™•ì¥ì˜ ìµœê·¼ ë°œì „ì— ì˜ê°ì„ ë°›ì•„, ìš°ë¦¬ëŠ” í›ˆë ¨ ì‹œê°„ ë° ì¶”ë¡  ì‹œê°„ í™•ì¥ ê°€ëŠ¥í•œ íŒë³„ ì†ŒìŠ¤ ë¶„ë¦¬(TISDiSS)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ëŠ” ì´ˆê¸° ë¶„í•  ë‹¤ì¤‘ ì†ì‹¤ ê°ë…, ê³µìœ  ë§¤ê°œë³€ìˆ˜ ì„¤ê³„ ë° ë™ì  ì¶”ë¡  ë°˜ë³µì„ í†µí•©í•˜ëŠ” í†µí•© í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. TISDiSSëŠ” ì¶”ê°€ ëª¨ë¸ì„ ì¬í›ˆë ¨í•˜ì§€ ì•Šê³ ë„ ì¶”ë¡  ê¹Šì´ë¥¼ ì¡°ì •í•˜ì—¬ ìœ ì—°í•œ ì†ë„-ì„±ëŠ¥ ì ˆì¶©ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ë˜í•œ êµ¬ì¡°ì  ë° í›ˆë ¨ ì„ íƒì— ëŒ€í•œ ì²´ê³„ì ì¸ ë¶„ì„ì„ ì œê³µí•˜ê³ , ë” ë§ì€ ì¶”ë¡  ë°˜ë³µìœ¼ë¡œ í›ˆë ¨í•  ë•Œ ì–•ì€ ì¶”ë¡  ì„±ëŠ¥ì´ í–¥ìƒë˜ì–´ ì €ì§€ì—° ì‘ìš© í”„ë¡œê·¸ë¨ì— ì´ì ì„ ì œê³µí•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. í‘œì¤€ ìŒì„± ë¶„ë¦¬ ë²¤ì¹˜ë§ˆí¬ì— ëŒ€í•œ ì‹¤í—˜ì€ ë§¤ê°œë³€ìˆ˜ ìˆ˜ë¥¼ ì¤„ì´ë©´ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ì…ì¦í•˜ì—¬ TISDiSSë¥¼ ì ì‘í˜• ì†ŒìŠ¤ ë¶„ë¦¬ë¥¼ ìœ„í•œ í™•ì¥ ê°€ëŠ¥í•˜ê³  ì‹¤ìš©ì ì¸ í”„ë ˆì„ì›Œí¬ë¡œ í™•ë¦½í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ìŒì„± ë° ìŒì•… ì²˜ë¦¬ì—ì„œì˜ ì†ŒìŠ¤ ë¶„ë¦¬ë¥¼ ê°œì„ í•˜ê¸° ìœ„í•œ TISDiSSë¼ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. TISDiSSëŠ” í›ˆë ¨ ë° ì¶”ë¡  ì‹œ í™•ì¥ ê°€ëŠ¥í•œ êµ¬ì¡°ë¡œ, ì´ˆê¸° ë¶„í•  ë‹¤ì¤‘ ì†ì‹¤ ê°ë…, íŒŒë¼ë¯¸í„° ê³µìœ  ì„¤ê³„, ë™ì  ì¶”ë¡  ë°˜ë³µì„ í†µí•©í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì¶”ê°€ ëª¨ë¸ ì¬í›ˆë ¨ ì—†ì´ ì¶”ë¡  ê¹Šì´ë¥¼ ì¡°ì ˆí•˜ì—¬ ì†ë„ì™€ ì„±ëŠ¥ ê°„ì˜ ìœ ì—°í•œ ê· í˜•ì„ ì œê³µí•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, TISDiSSëŠ” ì ì€ íŒŒë¼ë¯¸í„°ë¡œë„ ìµœì‹  ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ë©°, ë‚®ì€ ëŒ€ê¸° ì‹œê°„ ì‘ìš©ì— ìœ ë¦¬í•œ ì–•ì€ ì¶”ë¡  ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. TISDiSSëŠ” í›ˆë ¨ ë° ì¶”ë¡  ì‹œ í™•ì¥ ê°€ëŠ¥í•œ ì°¨ë³„ì  ì†ŒìŠ¤ ë¶„ë¦¬ë¥¼ ìœ„í•œ í†µí•© í”„ë ˆì„ì›Œí¬ë¡œ, ì´ˆê¸° ë¶„í•  ë‹¤ì¤‘ ì†ì‹¤ ê°ë…, ê³µìœ  ë§¤ê°œë³€ìˆ˜ ì„¤ê³„, ë™ì  ì¶”ë¡  ë°˜ë³µì„ í†µí•©í•©ë‹ˆë‹¤.
- 2. TISDiSSëŠ” ì¶”ê°€ ëª¨ë¸ ì¬í›ˆë ¨ ì—†ì´ ì¶”ë¡  ê¹Šì´ë¥¼ ì¡°ì •í•˜ì—¬ ìœ ì—°í•œ ì†ë„-ì„±ëŠ¥ ì ˆì¶©ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
- 3. ë” ë§ì€ ì¶”ë¡  ë°˜ë³µì„ í†µí•œ í›ˆë ¨ì€ ì–•ì€ ì¶”ë¡  ì„±ëŠ¥ì„ ê°œì„ í•˜ì—¬ ì €ì§€ì—° ì‘ìš© í”„ë¡œê·¸ë¨ì— ì´ì ì„ ì œê³µí•©ë‹ˆë‹¤.
- 4. í‘œì¤€ ìŒì„± ë¶„ë¦¬ ë²¤ì¹˜ë§ˆí¬ ì‹¤í—˜ì—ì„œ TISDiSSëŠ” ë§¤ê°œë³€ìˆ˜ ìˆ˜ë¥¼ ì¤„ì´ë©´ì„œë„ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.
- 5. TISDiSSëŠ” ì ì‘í˜• ì†ŒìŠ¤ ë¶„ë¦¬ë¥¼ ìœ„í•œ í™•ì¥ ê°€ëŠ¥í•˜ê³  ì‹¤ìš©ì ì¸ í”„ë ˆì„ì›Œí¬ë¡œ ìë¦¬ ì¡ì•˜ìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-23 09:09:16*