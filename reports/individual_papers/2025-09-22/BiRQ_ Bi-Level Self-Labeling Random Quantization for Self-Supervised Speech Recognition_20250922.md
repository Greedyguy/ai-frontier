---
keywords:
  - Self-supervised Learning
  - Bi-level Optimization
  - Random Quantization
  - Pseudo-label Generation
  - Label Refinement
category: cs.CL
publish_date: 2025-09-22
arxiv_id: 2509.15430
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:28:22.493711",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Self-supervised Learning",
    "Bi-level Optimization",
    "Random Quantization",
    "Pseudo-label Generation",
    "Label Refinement"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Self-supervised Learning": 0.85,
    "Bi-level Optimization": 0.78,
    "Random Quantization": 0.72,
    "Pseudo-label Generation": 0.8,
    "Label Refinement": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Self-supervised learning",
        "canonical": "Self-supervised Learning",
        "aliases": [
          "SSL"
        ],
        "category": "specific_connectable",
        "rationale": "Central to the paper's methodology, linking it to broader discussions on self-supervised approaches.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Bi-level optimization",
        "canonical": "Bi-level Optimization",
        "aliases": [
          "Bilevel optimization"
        ],
        "category": "unique_technical",
        "rationale": "A unique methodological approach in the paper, offering a distinct link to optimization techniques.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Random quantization",
        "canonical": "Random Quantization",
        "aliases": [
          "Random-projection quantizer"
        ],
        "category": "unique_technical",
        "rationale": "A specific technique used in the paper, relevant for discussions on quantization methods.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.75,
        "link_intent_score": 0.72
      },
      {
        "surface": "Pseudo-label generation",
        "canonical": "Pseudo-label Generation",
        "aliases": [
          "Pseudo-labeling"
        ],
        "category": "specific_connectable",
        "rationale": "Key to the paper's approach, connecting to broader themes in label generation strategies.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.68,
        "link_intent_score": 0.8
      },
      {
        "surface": "Label refinement",
        "canonical": "Label Refinement",
        "aliases": [
          "Label enhancement"
        ],
        "category": "specific_connectable",
        "rationale": "Important for understanding iterative improvement in labeling, linking to similar refinement processes.",
        "novelty_score": 0.5,
        "connectivity_score": 0.7,
        "specificity_score": 0.65,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "experiment"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Self-supervised learning",
      "resolved_canonical": "Self-supervised Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Bi-level optimization",
      "resolved_canonical": "Bi-level Optimization",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Random quantization",
      "resolved_canonical": "Random Quantization",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.75,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "Pseudo-label generation",
      "resolved_canonical": "Pseudo-label Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.68,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Label refinement",
      "resolved_canonical": "Label Refinement",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.7,
        "specificity": 0.65,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# BiRQ: Bi-Level Self-Labeling Random Quantization for Self-Supervised Speech Recognition

**Korean Title:** BiRQ: ìê¸° ì§€ë„ ìŒì„± ì¸ì‹ì„ ìœ„í•œ ì´ì¤‘ ìˆ˜ì¤€ ìê¸° ë¼ë²¨ë§ ëœë¤ ì–‘ìí™”

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15430.pdf)
**Category**: cs.CL
**Published**: 2025-09-22
**ArXiv ID**: [2509.15430](https://arxiv.org/abs/2509.15430)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Chunk Based Speech Pre-training with High Resolution Finite Scalar Quantization_20250922|Chunk Based Speech Pre-training with High Resolution Finite Scalar Quantization]] (81.6% similar)
- [[2025-09-17/Quantum Reinforcement Learning-Guided Diffusion Model for Image Synthesis via Hybrid Quantum-Classical Generative Model Architectures_20250917|Quantum Reinforcement Learning-Guided Diffusion Model for Image Synthesis via Hybrid Quantum-Classical Generative Model Architectures]] (80.6% similar)
- [[2025-09-18/Evolving Language Models without Labels_ Majority Drives Selection, Novelty Promotes Variation_20250918|Evolving Language Models without Labels: Majority Drives Selection, Novelty Promotes Variation]] (80.4% similar)
- [[2025-09-18/BabyHuBERT_ Multilingual Self-Supervised Learning for Segmenting Speakers in Child-Centered Long-Form Recordings_20250918|BabyHuBERT: Multilingual Self-Supervised Learning for Segmenting Speakers in Child-Centered Long-Form Recordings]] (80.2% similar)
- [[2025-09-22/MEC-Quant_ Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training_20250922|MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training]] (80.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Self-supervised Learning|Self-supervised Learning]], [[keywords/Pseudo-label Generation|Pseudo-label Generation]], [[keywords/Label Refinement|Label Refinement]]
**âš¡ Unique Technical**: [[keywords/Bi-level Optimization|Bi-level Optimization]], [[keywords/Random Quantization|Random Quantization]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15430v1 Announce Type: new 
Abstract: Speech is a rich signal, and labeled audio-text pairs are costly, making self-supervised learning essential for scalable representation learning. A core challenge in speech SSL is generating pseudo-labels that are both informative and efficient: strong labels, such as those used in HuBERT, improve downstream performance but rely on external encoders and multi-stage pipelines, while efficient methods like BEST-RQ achieve simplicity at the cost of weaker labels. We propose BiRQ, a bilevel SSL framework that combines the efficiency of BEST-RQ with the refinement benefits of HuBERT-style label enhancement. The key idea is to reuse part of the model itself as a pseudo-label generator: intermediate representations are discretized by a random-projection quantizer to produce enhanced labels, while anchoring labels derived directly from the raw input stabilize training and prevent collapse. Training is formulated as an efficient first-order bilevel optimization problem, solved end-to-end with differentiable Gumbel-softmax selection. This design eliminates the need for external label encoders, reduces memory cost, and enables iterative label refinement in an end-to-end fashion. BiRQ consistently improves over BEST-RQ while maintaining low complexity and computational efficiency. We validate our method on various datasets, including 960-hour LibriSpeech, 150-hour AMI meetings and 5,000-hour YODAS, demonstrating consistent gains over BEST-RQ.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15430v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: ìŒì„±ì€ í’ë¶€í•œ ì‹ í˜¸ì´ë©°, ë ˆì´ë¸”ì´ ìˆëŠ” ì˜¤ë””ì˜¤-í…ìŠ¤íŠ¸ ìŒì€ ë¹„ìš©ì´ ë§ì´ ë“¤ê¸° ë•Œë¬¸ì—, í™•ì¥ ê°€ëŠ¥í•œ í‘œí˜„ í•™ìŠµì„ ìœ„í•´ ìê¸° ì§€ë„ í•™ìŠµ(self-supervised learning, SSL)ì´ í•„ìˆ˜ì ì…ë‹ˆë‹¤. ìŒì„± SSLì˜ í•µì‹¬ ê³¼ì œëŠ” ì •ë³´ê°€ í’ë¶€í•˜ë©´ì„œë„ íš¨ìœ¨ì ì¸ ì˜ì‚¬ ë ˆì´ë¸”ì„ ìƒì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. HuBERTì—ì„œ ì‚¬ìš©ë˜ëŠ” ê°•ë ¥í•œ ë ˆì´ë¸”ì€ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ì§€ë§Œ, ì™¸ë¶€ ì¸ì½”ë”ì™€ ë‹¤ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ì— ì˜ì¡´í•©ë‹ˆë‹¤. ë°˜ë©´, BEST-RQì™€ ê°™ì€ íš¨ìœ¨ì ì¸ ë°©ë²•ì€ ë‹¨ìˆœì„±ì„ ìœ ì§€í•˜ì§€ë§Œ ì•½í•œ ë ˆì´ë¸”ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” BEST-RQì˜ íš¨ìœ¨ì„±ê³¼ HuBERT ìŠ¤íƒ€ì¼ì˜ ë ˆì´ë¸” ê°œì„ ì˜ ì´ì ì„ ê²°í•©í•œ ì´ì¤‘ ìˆ˜ì¤€(bilevel) SSL í”„ë ˆì„ì›Œí¬ì¸ BiRQë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. í•µì‹¬ ì•„ì´ë””ì–´ëŠ” ëª¨ë¸ì˜ ì¼ë¶€ë¥¼ ì˜ì‚¬ ë ˆì´ë¸” ìƒì„±ê¸°ë¡œ ì¬ì‚¬ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤: ì¤‘ê°„ í‘œí˜„ì€ ëœë¤ í”„ë¡œì ì…˜ ì–‘ìí™”ê¸°ë¥¼ í†µí•´ ì´ì‚°í™”ë˜ì–´ í–¥ìƒëœ ë ˆì´ë¸”ì„ ìƒì„±í•˜ë©°, ì›ì‹œ ì…ë ¥ì—ì„œ ì§ì ‘ íŒŒìƒëœ ì•µì»¤ ë ˆì´ë¸”ì€ í›ˆë ¨ì„ ì•ˆì •í™”í•˜ê³  ë¶•ê´´ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤. í›ˆë ¨ì€ íš¨ìœ¨ì ì¸ 1ì°¨ ì´ì¤‘ ìˆ˜ì¤€ ìµœì í™” ë¬¸ì œë¡œ ê³µì‹í™”ë˜ì–´, ë¯¸ë¶„ ê°€ëŠ¥í•œ Gumbel-softmax ì„ íƒì„ í†µí•´ ì¢…ë‹¨ ê°„(end-to-end)ìœ¼ë¡œ í•´ê²°ë©ë‹ˆë‹¤. ì´ ì„¤ê³„ëŠ” ì™¸ë¶€ ë ˆì´ë¸” ì¸ì½”ë”ì˜ í•„ìš”ì„±ì„ ì œê±°í•˜ê³ , ë©”ëª¨ë¦¬ ë¹„ìš©ì„ ì¤„ì´ë©°, ì¢…ë‹¨ ê°„ ë°©ì‹ìœ¼ë¡œ ë°˜ë³µì ì¸ ë ˆì´ë¸” ê°œì„ ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. BiRQëŠ” ë‚®ì€ ë³µì¡ì„±ê³¼ ê³„ì‚° íš¨ìœ¨ì„±ì„ ìœ ì§€í•˜ë©´ì„œ BEST-RQë³´ë‹¤ ì¼ê´€ë˜ê²Œ í–¥ìƒëœ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ìš°ë¦¬ëŠ” 960ì‹œê°„ì˜ LibriSpeech, 150ì‹œê°„ì˜ AMI íšŒì˜, 5,000ì‹œê°„ì˜ YODASë¥¼ í¬í•¨í•œ ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ì—ì„œ ìš°ë¦¬ì˜ ë°©ë²•ì„ ê²€ì¦í•˜ì—¬ BEST-RQ ëŒ€ë¹„ ì¼ê´€ëœ ì„±ëŠ¥ í–¥ìƒì„ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ìŒì„± ìê¸° ì§€ë„ í•™ìŠµ(SSL)ì—ì„œ íš¨ìœ¨ì ì´ê³  ì •ë³´ê°€ í’ë¶€í•œ ì˜ì‚¬ ë ˆì´ë¸” ìƒì„±ì˜ ì¤‘ìš”ì„±ì„ ë‹¤ë£¹ë‹ˆë‹¤. ê¸°ì¡´ì˜ HuBERTëŠ” ê°•ë ¥í•œ ë ˆì´ë¸”ì„ ì‚¬ìš©í•˜ì§€ë§Œ ì™¸ë¶€ ì¸ì½”ë”ì™€ ë³µì¡í•œ íŒŒì´í”„ë¼ì¸ì´ í•„ìš”í•˜ë©°, BEST-RQëŠ” ê°„ë‹¨í•˜ì§€ë§Œ ì•½í•œ ë ˆì´ë¸”ì„ ìƒì„±í•©ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì œì•ˆëœ BiRQëŠ” BEST-RQì˜ íš¨ìœ¨ì„±ê³¼ HuBERT ìŠ¤íƒ€ì¼ì˜ ë ˆì´ë¸” ê°œì„ ì„ ê²°í•©í•œ ì´ì¤‘ ìˆ˜ì¤€ SSL í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ëª¨ë¸ì˜ ì¼ë¶€ë¥¼ ì˜ì‚¬ ë ˆì´ë¸” ìƒì„±ê¸°ë¡œ ì¬ì‚¬ìš©í•˜ì—¬ ì¤‘ê°„ í‘œí˜„ì„ ë¬´ì‘ìœ„ íˆ¬ì˜ ì–‘ìí™”ê¸°ë¥¼ í†µí•´ ê°œì„ ëœ ë ˆì´ë¸”ë¡œ ë³€í™˜í•˜ê³ , ì›ì‹œ ì…ë ¥ì—ì„œ ì§ì ‘ íŒŒìƒëœ ì•µì»¤ ë ˆì´ë¸”ë¡œ í›ˆë ¨ì„ ì•ˆì •í™”í•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ì™¸ë¶€ ë ˆì´ë¸” ì¸ì½”ë”ê°€ í•„ìš” ì—†ìœ¼ë©°, ë©”ëª¨ë¦¬ ë¹„ìš©ì„ ì¤„ì´ê³ , ë ˆì´ë¸”ì„ ë°˜ë³µì ìœ¼ë¡œ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. BiRQëŠ” BEST-RQë³´ë‹¤ ì¼ê´€ë˜ê²Œ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ë©°, LibriSpeech, AMI, YODAS ë“± ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ì—ì„œ ê·¸ íš¨ê³¼ë¥¼ ê²€ì¦í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. BiRQëŠ” BEST-RQì˜ íš¨ìœ¨ì„±ê³¼ HuBERT ìŠ¤íƒ€ì¼ì˜ ë¼ë²¨ ê°œì„  ì´ì ì„ ê²°í•©í•œ ì´ì¤‘ ìˆ˜ì¤€ì˜ ìê¸° ì§€ë„ í•™ìŠµ(SSL) í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.
- 2. ëª¨ë¸ì˜ ì¼ë¶€ë¥¼ ì˜ì‚¬ ë¼ë²¨ ìƒì„±ê¸°ë¡œ ì¬ì‚¬ìš©í•˜ì—¬ ì¤‘ê°„ í‘œí˜„ì„ ë¬´ì‘ìœ„ íˆ¬ì˜ ì–‘ìí™”ê¸°ë¡œ ì´ì‚°í™”í•˜ì—¬ ê°œì„ ëœ ë¼ë²¨ì„ ìƒì„±í•©ë‹ˆë‹¤.
- 3. í›ˆë ¨ì€ íš¨ìœ¨ì ì¸ 1ì°¨ ì´ì¤‘ ìˆ˜ì¤€ ìµœì í™” ë¬¸ì œë¡œ ê³µì‹í™”ë˜ì–´, ì™¸ë¶€ ë¼ë²¨ ì¸ì½”ë”ì˜ í•„ìš”ì„±ì„ ì œê±°í•˜ê³  ë©”ëª¨ë¦¬ ë¹„ìš©ì„ ì¤„ì…ë‹ˆë‹¤.
- 4. BiRQëŠ” BEST-RQë³´ë‹¤ ì¼ê´€ë˜ê²Œ ì„±ëŠ¥ì„ ê°œì„ í•˜ë©´ì„œë„ ë‚®ì€ ë³µì¡ì„±ê³¼ ê³„ì‚° íš¨ìœ¨ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤.
- 5. ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ì—ì„œ BiRQì˜ ì„±ëŠ¥ì„ ê²€ì¦í•˜ì—¬ BEST-RQ ëŒ€ë¹„ ì¼ê´€ëœ ì„±ëŠ¥ í–¥ìƒì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-23 11:28:22*