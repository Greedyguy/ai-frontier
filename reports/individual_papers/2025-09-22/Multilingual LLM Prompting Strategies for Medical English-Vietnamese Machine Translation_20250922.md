---
keywords:
  - Large Language Model
  - Zero-Shot Learning
  - Few-Shot Learning
  - Medical English-Vietnamese Machine Translation
  - Terminology-aware Cues
category: cs.CL
publish_date: 2025-09-22
arxiv_id: 2509.15640
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:31:58.961592",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Zero-Shot Learning",
    "Few-Shot Learning",
    "Medical English-Vietnamese Machine Translation",
    "Terminology-aware Cues"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Zero-Shot Learning": 0.82,
    "Few-Shot Learning": 0.8,
    "Medical English-Vietnamese Machine Translation": 0.78,
    "Terminology-aware Cues": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Large Language Models"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are central to the study and connect to various NLP and machine learning concepts.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Zero-Shot",
        "canonical": "Zero-Shot Learning",
        "aliases": [
          "Zero-Shot"
        ],
        "category": "specific_connectable",
        "rationale": "Zero-Shot Learning is a trending approach in machine translation and connects to learning paradigms.",
        "novelty_score": 0.52,
        "connectivity_score": 0.79,
        "specificity_score": 0.72,
        "link_intent_score": 0.82
      },
      {
        "surface": "Few-Shot",
        "canonical": "Few-Shot Learning",
        "aliases": [
          "Few-Shot"
        ],
        "category": "specific_connectable",
        "rationale": "Few-Shot Learning is a key method evaluated in the paper, relevant to model training strategies.",
        "novelty_score": 0.5,
        "connectivity_score": 0.77,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Medical English-Vietnamese Machine Translation",
        "canonical": "Medical English-Vietnamese Machine Translation",
        "aliases": [
          "En-Vi MT"
        ],
        "category": "unique_technical",
        "rationale": "This is a unique application focus of the study, providing specific context for translation research.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Terminology-aware Cues",
        "canonical": "Terminology-aware Cues",
        "aliases": [
          "Terminology-aware Prompts"
        ],
        "category": "unique_technical",
        "rationale": "This concept is crucial for improving domain-specific translation, highlighting a novel prompting strategy.",
        "novelty_score": 0.68,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "model scale",
      "performance",
      "healthcare access"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Zero-Shot",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.52,
        "connectivity": 0.79,
        "specificity": 0.72,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Few-Shot",
      "resolved_canonical": "Few-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.77,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Medical English-Vietnamese Machine Translation",
      "resolved_canonical": "Medical English-Vietnamese Machine Translation",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Terminology-aware Cues",
      "resolved_canonical": "Terminology-aware Cues",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Multilingual LLM Prompting Strategies for Medical English-Vietnamese Machine Translation

**Korean Title:** 의료 영어-베트남어 기계 번역을 위한 다국어 LLM 프롬프트 전략

## 📋 메타데이터

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15640.pdf)
**Category**: cs.CL
**Published**: 2025-09-22
**ArXiv ID**: [2509.15640](https://arxiv.org/abs/2509.15640)

## 🔗 유사한 논문
- [[2025-09-19/MedVAL_ Toward Expert-Level Medical Text Validation with Language Models_20250919|MedVAL: Toward Expert-Level Medical Text Validation with Language Models]] (82.3% similar)
- [[2025-09-22/MedCOD_ Enhancing English-to-Spanish Medical Translation of Large Language Models Using Enriched Chain-of-Dictionary Framework_20250922|MedCOD: Enhancing English-to-Spanish Medical Translation of Large Language Models Using Enriched Chain-of-Dictionary Framework]] (81.8% similar)
- [[2025-09-22/A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages_20250922|A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages]] (81.4% similar)
- [[2025-09-22/The Effect of Language Diversity When Fine-Tuning Large Language Models for Translation_20250922|The Effect of Language Diversity When Fine-Tuning Large Language Models for Translation]] (81.1% similar)
- [[2025-09-22/EHR-MCP_ Real-world Evaluation of Clinical Information Retrieval by Large Language Models via Model Context Protocol_20250922|EHR-MCP: Real-world Evaluation of Clinical Information Retrieval by Large Language Models via Model Context Protocol]] (81.0% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Zero-Shot Learning|Zero-Shot Learning]], [[keywords/Few-Shot Learning|Few-Shot Learning]]
**⚡ Unique Technical**: [[keywords/Medical English-Vietnamese Machine Translation|Medical English-Vietnamese Machine Translation]], [[keywords/Terminology-aware Cues|Terminology-aware Cues]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.15640v1 Announce Type: new 
Abstract: Medical English-Vietnamese machine translation (En-Vi MT) is essential for healthcare access and communication in Vietnam, yet Vietnamese remains a low-resource and under-studied language. We systematically evaluate prompting strategies for six multilingual LLMs (0.5B-9B parameters) on the MedEV dataset, comparing zero-shot, few-shot, and dictionary-augmented prompting with Meddict, an English-Vietnamese medical lexicon. Results show that model scale is the primary driver of performance: larger LLMs achieve strong zero-shot results, while few-shot prompting yields only marginal improvements. In contrast, terminology-aware cues and embedding-based example retrieval consistently improve domain-specific translation. These findings underscore both the promise and the current limitations of multilingual LLMs for medical En-Vi MT.

## 🔍 Abstract (한글 번역)

arXiv:2509.15640v1 발표 유형: 신규  
초록: 의료 영어-베트남어 기계 번역(En-Vi MT)은 베트남에서 의료 접근성과 의사소통에 필수적이지만, 베트남어는 여전히 자원이 부족하고 연구가 덜 된 언어입니다. 우리는 MedEV 데이터셋에서 여섯 개의 다국어 대형 언어 모델(0.5B-9B 매개변수)에 대한 프롬프트 전략을 체계적으로 평가하며, Meddict라는 영어-베트남어 의료 어휘집을 사용한 제로샷, 퓨샷, 사전 보강 프롬프트를 비교합니다. 결과는 모델의 규모가 성능의 주요 요인임을 보여줍니다: 더 큰 대형 언어 모델은 강력한 제로샷 결과를 달성하는 반면, 퓨샷 프롬프트는 약간의 개선만을 가져옵니다. 반면, 용어 인식 큐와 임베딩 기반 예제 검색은 일관되게 도메인 특화 번역을 개선합니다. 이러한 결과는 의료 En-Vi MT를 위한 다국어 대형 언어 모델의 가능성과 현재의 한계를 모두 강조합니다.

## 📝 요약

이 논문은 베트남의 의료 접근성과 의사소통을 위해 중요한 영어-베트남어 기계 번역(En-Vi MT)을 다룹니다. 연구에서는 6개의 다국어 대형 언어 모델(LLM)을 사용하여 MedEV 데이터셋에서 제로샷, 퓨샷, 사전 사전(Meddict)을 활용한 프롬프트 전략을 평가했습니다. 결과에 따르면, 모델의 규모가 성능에 가장 큰 영향을 미치며, 큰 LLM은 강력한 제로샷 결과를 보였습니다. 퓨샷 프롬프트는 약간의 개선만을 가져왔지만, 용어 인식 큐와 임베딩 기반 예제 검색은 도메인 특화 번역을 꾸준히 향상시켰습니다. 이 연구는 의료 En-Vi MT에서 다국어 LLM의 가능성과 한계를 강조합니다.

## 🎯 주요 포인트

- 1. 의료 영어-베트남어 기계 번역은 베트남의 의료 접근성과 의사소통에 필수적이지만, 베트남어는 여전히 저자원 언어로 연구가 부족하다.
- 2. 여섯 개의 다국어 대형 언어 모델(LLMs)을 대상으로 MedEV 데이터셋에서 제로샷, 퓨샷, 사전 사전 지식 활용 프롬프트 전략을 체계적으로 평가하였다.
- 3. 모델의 규모가 성능의 주요 요인으로 작용하며, 대형 LLM은 강력한 제로샷 결과를 달성하지만, 퓨샷 프롬프트는 미미한 개선만을 보인다.
- 4. 용어 인식 큐와 임베딩 기반 예제 검색은 도메인 특화 번역을 일관되게 개선한다.
- 5. 다국어 LLM이 의료 영어-베트남어 기계 번역에 대해 가진 가능성과 현재의 한계를 강조한다.


---

*Generated on 2025-09-23 11:31:58*