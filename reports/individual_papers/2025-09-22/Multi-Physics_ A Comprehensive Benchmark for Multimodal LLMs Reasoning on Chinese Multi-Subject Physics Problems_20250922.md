---
keywords:
  - Multimodal Learning
  - Physics Reasoning
  - Chain-of-Thought Reasoning
  - Vision-Language Model
category: cs.CL
publish_date: 2025-09-22
arxiv_id: 2509.15839
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:35:00.439203",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multimodal Learning",
    "Physics Reasoning",
    "Chain-of-Thought Reasoning",
    "Vision-Language Model"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multimodal Learning": 0.8,
    "Physics Reasoning": 0.72,
    "Chain-of-Thought Reasoning": 0.78,
    "Vision-Language Model": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multimodal LLMs",
        "canonical": "Multimodal Learning",
        "aliases": [
          "MLLMs"
        ],
        "category": "specific_connectable",
        "rationale": "Multimodal Learning is crucial for linking various modalities in language models, enhancing understanding across different data types.",
        "novelty_score": 0.55,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Chinese physics reasoning",
        "canonical": "Physics Reasoning",
        "aliases": [
          "Chinese Physics"
        ],
        "category": "unique_technical",
        "rationale": "This term is specific to the paper's focus on evaluating reasoning in physics, particularly in a Chinese context.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.78,
        "link_intent_score": 0.72
      },
      {
        "surface": "Chain-of-thought",
        "canonical": "Chain-of-Thought Reasoning",
        "aliases": [
          "Step-by-step reasoning"
        ],
        "category": "specific_connectable",
        "rationale": "Chain-of-Thought Reasoning is a key concept for understanding the logical process in multimodal models.",
        "novelty_score": 0.65,
        "connectivity_score": 0.82,
        "specificity_score": 0.76,
        "link_intent_score": 0.78
      },
      {
        "surface": "Visual information",
        "canonical": "Vision-Language Model",
        "aliases": [
          "Visual Data"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-Language Models are central to integrating visual information with language processing, a core aspect of the study.",
        "novelty_score": 0.6,
        "connectivity_score": 0.88,
        "specificity_score": 0.72,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "evaluation benchmarks",
      "difficulty levels",
      "final answer accuracy"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multimodal LLMs",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Chinese physics reasoning",
      "resolved_canonical": "Physics Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.78,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "Chain-of-thought",
      "resolved_canonical": "Chain-of-Thought Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.82,
        "specificity": 0.76,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Visual information",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.88,
        "specificity": 0.72,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Multi-Physics: A Comprehensive Benchmark for Multimodal LLMs Reasoning on Chinese Multi-Subject Physics Problems

**Korean Title:** ë©€í‹° ë¬¼ë¦¬í•™: ì¤‘êµ­ì˜ ë‹¤ì¤‘ ê³¼ëª© ë¬¼ë¦¬ ë¬¸ì œì— ëŒ€í•œ ë‹¤ì¤‘ ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì¶”ë¡ ì„ ìœ„í•œ ì¢…í•© ë²¤ì¹˜ë§ˆí¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15839.pdf)
**Category**: cs.CL
**Published**: 2025-09-22
**ArXiv ID**: [2509.15839](https://arxiv.org/abs/2509.15839)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Perception-R1_ Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward_20250922|Perception-R1: Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward]] (84.8% similar)
- [[2025-09-22/HiPhO_ How Far Are (M)LLMs from Humans in the Latest High School Physics Olympiad Benchmark?_20250922|HiPhO: How Far Are (M)LLMs from Humans in the Latest High School Physics Olympiad Benchmark?]] (84.7% similar)
- [[2025-09-22/How Good are Foundation Models in Step-by-Step Embodied Reasoning?_20250922|How Good are Foundation Models in Step-by-Step Embodied Reasoning?]] (84.3% similar)
- [[2025-09-22/DivLogicEval_ A Framework for Benchmarking Logical Reasoning Evaluation in Large Language Models_20250922|DivLogicEval: A Framework for Benchmarking Logical Reasoning Evaluation in Large Language Models]] (84.2% similar)
- [[2025-09-19/A Multi-To-One Interview Paradigm for Efficient MLLM Evaluation_20250919|A Multi-To-One Interview Paradigm for Efficient MLLM Evaluation]] (82.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]], [[keywords/Chain-of-Thought Reasoning|Chain-of-Thought Reasoning]]
**âš¡ Unique Technical**: [[keywords/Physics Reasoning|Physics Reasoning]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15839v1 Announce Type: new 
Abstract: While multimodal LLMs (MLLMs) demonstrate remarkable reasoning progress, their application in specialized scientific domains like physics reveals significant gaps in current evaluation benchmarks. Specifically, existing benchmarks often lack fine-grained subject coverage, neglect the step-by-step reasoning process, and are predominantly English-centric, failing to systematically evaluate the role of visual information. Therefore, we introduce \textbf {Multi-Physics} for Chinese physics reasoning, a comprehensive benchmark that includes 5 difficulty levels, featuring 1,412 image-associated, multiple-choice questions spanning 11 high-school physics subjects. We employ a dual evaluation framework to evaluate 20 different MLLMs, analyzing both final answer accuracy and the step-by-step integrity of their chain-of-thought. Furthermore, we systematically study the impact of difficulty level and visual information by comparing the model performance before and after changing the input mode. Our work provides not only a fine-grained resource for the community but also offers a robust methodology for dissecting the multimodal reasoning process of state-of-the-art MLLMs, and our dataset and code have been open-sourced: https://github.com/luozhongze/Multi-Physics.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15839v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: ë‹¤ì¤‘ ëª¨ë“œ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(Multimodal LLMs, MLLMs)ì´ ë†€ë¼ìš´ ì¶”ë¡  ë°œì „ì„ ë³´ì—¬ì£¼ê³  ìˆì§€ë§Œ, ë¬¼ë¦¬í•™ê³¼ ê°™ì€ ì „ë¬¸ ê³¼í•™ ë¶„ì•¼ì—ì„œì˜ ì ìš©ì€ í˜„ì¬ í‰ê°€ ê¸°ì¤€ì—ì„œ ìƒë‹¹í•œ ê²©ì°¨ë¥¼ ë“œëŸ¬ëƒ…ë‹ˆë‹¤. íŠ¹íˆ, ê¸°ì¡´ì˜ ë²¤ì¹˜ë§ˆí¬ëŠ” ì¢…ì¢… ì„¸ë¶€ì ì¸ ì£¼ì œ ë²”ìœ„ê°€ ë¶€ì¡±í•˜ê³ , ë‹¨ê³„ë³„ ì¶”ë¡  ê³¼ì •ì„ ê°„ê³¼í•˜ë©°, ì£¼ë¡œ ì˜ì–´ ì¤‘ì‹¬ì ì´ì–´ì„œ ì‹œê° ì •ë³´ì˜ ì—­í• ì„ ì²´ê³„ì ìœ¼ë¡œ í‰ê°€í•˜ì§€ ëª»í•©ë‹ˆë‹¤. ë”°ë¼ì„œ ìš°ë¦¬ëŠ” ì¤‘êµ­ ë¬¼ë¦¬í•™ ì¶”ë¡ ì„ ìœ„í•œ í¬ê´„ì ì¸ ë²¤ì¹˜ë§ˆí¬ì¸ \textbf{Multi-Physics}ë¥¼ ë„ì…í•©ë‹ˆë‹¤. ì´ëŠ” 5ë‹¨ê³„ì˜ ë‚œì´ë„ë¥¼ í¬í•¨í•˜ë©°, 11ê°œì˜ ê³ ë“±í•™êµ ë¬¼ë¦¬í•™ ê³¼ëª©ì— ê±¸ì³ 1,412ê°œì˜ ì´ë¯¸ì§€ ê´€ë ¨ ê°ê´€ì‹ ì§ˆë¬¸ì„ íŠ¹ì§•ìœ¼ë¡œ í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” 20ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ MLLMsë¥¼ í‰ê°€í•˜ê¸° ìœ„í•´ ì´ì¤‘ í‰ê°€ í”„ë ˆì„ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì¢… ë‹µë³€ì˜ ì •í™•ì„±ê³¼ ë‹¨ê³„ë³„ ì‚¬ê³  ê³¼ì •ì˜ ì¼ê´€ì„±ì„ ë¶„ì„í•©ë‹ˆë‹¤. ë˜í•œ, ì…ë ¥ ëª¨ë“œë¥¼ ë³€ê²½í•˜ê¸° ì „í›„ì˜ ëª¨ë¸ ì„±ëŠ¥ì„ ë¹„êµí•˜ì—¬ ë‚œì´ë„ ìˆ˜ì¤€ê³¼ ì‹œê° ì •ë³´ì˜ ì˜í–¥ì„ ì²´ê³„ì ìœ¼ë¡œ ì—°êµ¬í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì—°êµ¬ëŠ” ì»¤ë®¤ë‹ˆí‹°ì— ì„¸ë¶€ì ì¸ ìì›ì„ ì œê³µí•  ë¿ë§Œ ì•„ë‹ˆë¼ ìµœì²¨ë‹¨ MLLMsì˜ ë‹¤ì¤‘ ëª¨ë“œ ì¶”ë¡  ê³¼ì •ì„ í•´ë¶€í•˜ê¸° ìœ„í•œ ê°•ë ¥í•œ ë°©ë²•ë¡ ì„ ì œê³µí•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ë°ì´í„°ì…‹ê³¼ ì½”ë“œëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ë¡œ ê³µê°œë˜ì—ˆìŠµë‹ˆë‹¤: https://github.com/luozhongze/Multi-Physics.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë¬¼ë¦¬í•™ ë¶„ì•¼ì—ì„œ ë©€í‹°ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(MLLM)ì˜ í‰ê°€ ê¸°ì¤€ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ì¤‘êµ­ ë¬¼ë¦¬í•™ ì¶”ë¡ ì„ ìœ„í•œ \textbf{Multi-Physics}ë¼ëŠ” í¬ê´„ì ì¸ ë²¤ì¹˜ë§ˆí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ë²¤ì¹˜ë§ˆí¬ëŠ” 11ê°œì˜ ê³ ë“±í•™êµ ë¬¼ë¦¬í•™ ê³¼ëª©ì— ê±¸ì³ 1,412ê°œì˜ ì´ë¯¸ì§€ ì—°ê´€ ë‹¤ì§€ì„ ë‹¤í˜• ì§ˆë¬¸ì„ í¬í•¨í•˜ë©°, 5ë‹¨ê³„ì˜ ë‚œì´ë„ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. 20ê°œì˜ MLLMì„ ëŒ€ìƒìœ¼ë¡œ ìµœì¢… ë‹µë³€ ì •í™•ì„±ê³¼ ë‹¨ê³„ë³„ ì‚¬ê³  ê³¼ì •ì˜ ì¼ê´€ì„±ì„ í‰ê°€í•˜ëŠ” ì´ì¤‘ í‰ê°€ ì²´ê³„ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ë˜í•œ, ì…ë ¥ ëª¨ë“œ ë³€ê²½ ì „í›„ì˜ ëª¨ë¸ ì„±ëŠ¥ì„ ë¹„êµí•˜ì—¬ ë‚œì´ë„ì™€ ì‹œê° ì •ë³´ì˜ ì˜í–¥ì„ ì²´ê³„ì ìœ¼ë¡œ ì—°êµ¬í•©ë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ì»¤ë®¤ë‹ˆí‹°ì— ì„¸ë¶€ì ì¸ ìì›ì„ ì œê³µí•˜ê³  ìµœì‹  MLLMì˜ ë©€í‹°ëª¨ë‹¬ ì¶”ë¡  ê³¼ì •ì„ ë¶„ì„í•  ìˆ˜ ìˆëŠ” ê°•ë ¥í•œ ë°©ë²•ë¡ ì„ ì œì‹œí•©ë‹ˆë‹¤. ë°ì´í„°ì…‹ê³¼ ì½”ë“œëŠ” ê³µê°œë˜ì–´ ìˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ê¸°ì¡´ í‰ê°€ ë²¤ì¹˜ë§ˆí¬ëŠ” ì„¸ë¶€ì ì¸ ì£¼ì œ ë²”ìœ„ì™€ ë‹¨ê³„ë³„ ì¶”ë¡  ê³¼ì •ì„ ê°„ê³¼í•˜ë©°, ì£¼ë¡œ ì˜ì–´ ì¤‘ì‹¬ìœ¼ë¡œ ì‹œê° ì •ë³´ì˜ ì—­í• ì„ ì²´ê³„ì ìœ¼ë¡œ í‰ê°€í•˜ì§€ ëª»í•œë‹¤.
- 2. 'Multi-Physics'ëŠ” ì¤‘êµ­ì–´ ë¬¼ë¦¬í•™ ì¶”ë¡ ì„ ìœ„í•œ í¬ê´„ì ì¸ ë²¤ì¹˜ë§ˆí¬ë¡œ, 5ë‹¨ê³„ ë‚œì´ë„ì˜ 1,412ê°œì˜ ì´ë¯¸ì§€ ì—°ê´€ ë‹¤ì§€ì„ ë‹¤í˜• ì§ˆë¬¸ì„ í¬í•¨í•˜ê³  ìˆë‹¤.
- 3. 20ê°œì˜ ë‹¤ì–‘í•œ MLLMì„ í‰ê°€í•˜ê¸° ìœ„í•´ ìµœì¢… ë‹µë³€ ì •í™•ë„ì™€ ë‹¨ê³„ë³„ ì‚¬ê³  ê³¼ì •ì˜ ì¼ê´€ì„±ì„ ë¶„ì„í•˜ëŠ” ì´ì¤‘ í‰ê°€ í”„ë ˆì„ì›Œí¬ë¥¼ ì‚¬ìš©í•œë‹¤.
- 4. ë‚œì´ë„ ìˆ˜ì¤€ê³¼ ì‹œê° ì •ë³´ì˜ ì˜í–¥ì„ ì²´ê³„ì ìœ¼ë¡œ ì—°êµ¬í•˜ì—¬ ì…ë ¥ ëª¨ë“œë¥¼ ë³€ê²½í•˜ê¸° ì „í›„ì˜ ëª¨ë¸ ì„±ëŠ¥ì„ ë¹„êµí•œë‹¤.
- 5. ë³¸ ì—°êµ¬ëŠ” ì»¤ë®¤ë‹ˆí‹°ì— ì„¸ë¶€ì ì¸ ìì›ì„ ì œê³µí•  ë¿ë§Œ ì•„ë‹ˆë¼, ìµœì‹  MLLMì˜ ë‹¤ì¤‘ ëª¨ë‹¬ ì¶”ë¡  ê³¼ì •ì„ ë¶„ì„í•˜ê¸° ìœ„í•œ ê²¬ê³ í•œ ë°©ë²•ë¡ ì„ ì œì‹œí•œë‹¤.


---

*Generated on 2025-09-23 11:35:00*