---
keywords:
  - Pose Estimation
  - Energy-based Model
  - Sim-to-real Transfer
  - Render-compare Architecture
category: cs.LG
publish_date: 2025-09-22
arxiv_id: 2509.15934
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T10:38:50.072286",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Pose Estimation",
    "Energy-based Model",
    "Sim-to-real Transfer",
    "Render-compare Architecture"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Pose Estimation": 0.82,
    "Energy-based Model": 0.75,
    "Sim-to-real Transfer": 0.77,
    "Render-compare Architecture": 0.74
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "In-hand Pose Estimation",
        "canonical": "Pose Estimation",
        "aliases": [
          "Object Pose Estimation"
        ],
        "category": "specific_connectable",
        "rationale": "Pose estimation is a crucial task in robotics and computer vision, facilitating connections to related techniques and applications.",
        "novelty_score": 0.55,
        "connectivity_score": 0.85,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "Energy-based Diffusion Model",
        "canonical": "Energy-based Model",
        "aliases": [
          "Diffusion Model"
        ],
        "category": "unique_technical",
        "rationale": "This model type is central to the paper's methodology, offering a unique approach to pose estimation.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      },
      {
        "surface": "Sim-to-real Performance",
        "canonical": "Sim-to-real Transfer",
        "aliases": [
          "Simulation to Real World"
        ],
        "category": "specific_connectable",
        "rationale": "Sim-to-real transfer is a key challenge in robotics, linking to broader discussions on model generalization.",
        "novelty_score": 0.6,
        "connectivity_score": 0.78,
        "specificity_score": 0.72,
        "link_intent_score": 0.77
      },
      {
        "surface": "Render-compare Architecture",
        "canonical": "Render-compare Architecture",
        "aliases": [
          "Render and Compare"
        ],
        "category": "unique_technical",
        "rationale": "This architecture is a novel contribution that enhances model performance, relevant for linking to visualization techniques.",
        "novelty_score": 0.68,
        "connectivity_score": 0.65,
        "specificity_score": 0.79,
        "link_intent_score": 0.74
      }
    ],
    "ban_list_suggestions": [
      "Regression",
      "Matching",
      "Registration Techniques"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "In-hand Pose Estimation",
      "resolved_canonical": "Pose Estimation",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.85,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Energy-based Diffusion Model",
      "resolved_canonical": "Energy-based Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Sim-to-real Performance",
      "resolved_canonical": "Sim-to-real Transfer",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.78,
        "specificity": 0.72,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Render-compare Architecture",
      "resolved_canonical": "Render-compare Architecture",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.65,
        "specificity": 0.79,
        "link_intent": 0.74
      }
    }
  ]
}
-->

# UniTac2Pose: A Unified Approach Learned in Simulation for Category-level Visuotactile In-hand Pose Estimation

**Korean Title:** UniTac2Pose: ë²”ì£¼ ìˆ˜ì¤€ì˜ ì‹œê°ì´‰ê° ì¸í•¸ë“œ ìì„¸ ì¶”ì •ì„ ìœ„í•œ ì‹œë®¬ë ˆì´ì…˜ì—ì„œ í•™ìŠµëœ í†µí•© ì ‘ê·¼ë²•

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15934.pdf)
**Category**: cs.LG
**Published**: 2025-09-22
**ArXiv ID**: [2509.15934](https://arxiv.org/abs/2509.15934)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/GenCAD-3D_ CAD Program Generation using Multimodal Latent Space Alignment and Synthetic Dataset Balancing_20250922|GenCAD-3D: CAD Program Generation using Multimodal Latent Space Alignment and Synthetic Dataset Balancing]] (81.4% similar)
- [[2025-09-22/cadrille_ Multi-modal CAD Reconstruction with Online Reinforcement Learning_20250922|cadrille: Multi-modal CAD Reconstruction with Online Reinforcement Learning]] (81.1% similar)
- [[2025-09-22/Recovering Parametric Scenes from Very Few Time-of-Flight Pixels_20250922|Recovering Parametric Scenes from Very Few Time-of-Flight Pixels]] (81.0% similar)
- [[2025-09-22/A re-calibration method for object detection with multi-modal alignment bias in autonomous driving_20250922|A re-calibration method for object detection with multi-modal alignment bias in autonomous driving]] (80.9% similar)
- [[2025-09-22/PAN_ Pillars-Attention-Based Network for 3D Object Detection_20250922|PAN: Pillars-Attention-Based Network for 3D Object Detection]] (80.4% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Pose Estimation|Pose Estimation]], [[keywords/Sim-to-real Transfer|Sim-to-real Transfer]]
**âš¡ Unique Technical**: [[keywords/Energy-based Model|Energy-based Model]], [[keywords/Render-compare Architecture|Render-compare Architecture]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15934v1 Announce Type: new 
Abstract: Accurate estimation of the in-hand pose of an object based on its CAD model is crucial in both industrial applications and everyday tasks, ranging from positioning workpieces and assembling components to seamlessly inserting devices like USB connectors. While existing methods often rely on regression, feature matching, or registration techniques, achieving high precision and generalizability to unseen CAD models remains a significant challenge. In this paper, we propose a novel three-stage framework for in-hand pose estimation. The first stage involves sampling and pre-ranking pose candidates, followed by iterative refinement of these candidates in the second stage. In the final stage, post-ranking is applied to identify the most likely pose candidates. These stages are governed by a unified energy-based diffusion model, which is trained solely on simulated data. This energy model simultaneously generates gradients to refine pose estimates and produces an energy scalar that quantifies the quality of the pose estimates. Additionally, borrowing the idea from the computer vision domain, we incorporate a render-compare architecture within the energy-based score network to significantly enhance sim-to-real performance, as demonstrated by our ablation studies. We conduct comprehensive experiments to show that our method outperforms conventional baselines based on regression, matching, and registration techniques, while also exhibiting strong intra-category generalization to previously unseen CAD models. Moreover, our approach integrates tactile object pose estimation, pose tracking, and uncertainty estimation into a unified framework, enabling robust performance across a variety of real-world conditions.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15934v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: CAD ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ë¬¼ì²´ì˜ ì†ì•ˆì—ì„œì˜ ìì„¸ë¥¼ ì •í™•í•˜ê²Œ ì¶”ì •í•˜ëŠ” ê²ƒì€ ì‚°ì—… ì‘ìš©ê³¼ ì¼ìƒì ì¸ ì‘ì—…ì—ì„œ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤. ì´ëŠ” ì‘ì—…ë¬¼ì˜ ìœ„ì¹˜ë¥¼ ì •í•˜ê³ , ë¶€í’ˆì„ ì¡°ë¦½í•˜ë©°, USB ì»¤ë„¥í„°ì™€ ê°™ì€ ì¥ì¹˜ë¥¼ ë§¤ë„ëŸ½ê²Œ ì‚½ì…í•˜ëŠ” ê²ƒì— ì´ë¥´ê¸°ê¹Œì§€ ë‹¤ì–‘í•©ë‹ˆë‹¤. ê¸°ì¡´ ë°©ë²•ë“¤ì€ ì£¼ë¡œ íšŒê·€, íŠ¹ì§• ë§¤ì¹­, ë˜ëŠ” ì •í•© ê¸°ë²•ì— ì˜ì¡´í•˜ì§€ë§Œ, ë†’ì€ ì •ë°€ë„ì™€ ë³´ì§€ ëª»í•œ CAD ëª¨ë¸ì— ëŒ€í•œ ì¼ë°˜í™”ë¥¼ ë‹¬ì„±í•˜ëŠ” ê²ƒì€ ì—¬ì „íˆ í° ë„ì „ ê³¼ì œì…ë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì†ì•ˆì—ì„œì˜ ìì„¸ ì¶”ì •ì„ ìœ„í•œ ìƒˆë¡œìš´ 3ë‹¨ê³„ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì²« ë²ˆì§¸ ë‹¨ê³„ì—ì„œëŠ” ìì„¸ í›„ë³´ë¥¼ ìƒ˜í”Œë§í•˜ê³  ì‚¬ì „ ìˆœìœ„ë¥¼ ë§¤ê¸°ë©°, ë‘ ë²ˆì§¸ ë‹¨ê³„ì—ì„œëŠ” ì´ëŸ¬í•œ í›„ë³´ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ì •ì œí•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ ë‹¨ê³„ì—ì„œëŠ” ì‚¬í›„ ìˆœìœ„ë¥¼ ì ìš©í•˜ì—¬ ê°€ì¥ ê°€ëŠ¥ì„± ìˆëŠ” ìì„¸ í›„ë³´ë¥¼ ì‹ë³„í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ë‹¨ê³„ë“¤ì€ í†µí•©ëœ ì—ë„ˆì§€ ê¸°ë°˜ í™•ì‚° ëª¨ë¸ì— ì˜í•´ ê´€ë¦¬ë˜ë©°, ì´ ëª¨ë¸ì€ ì˜¤ë¡œì§€ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¡œë§Œ í›ˆë ¨ë©ë‹ˆë‹¤. ì´ ì—ë„ˆì§€ ëª¨ë¸ì€ ìì„¸ ì¶”ì •ì„ ì •ì œí•˜ê¸° ìœ„í•œ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ë™ì‹œì— ìì„¸ ì¶”ì •ì˜ í’ˆì§ˆì„ ì •ëŸ‰í™”í•˜ëŠ” ì—ë„ˆì§€ ìŠ¤ì¹¼ë¼ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ë˜í•œ, ì»´í“¨í„° ë¹„ì „ ë¶„ì•¼ì˜ ì•„ì´ë””ì–´ë¥¼ ì°¨ìš©í•˜ì—¬ ì—ë„ˆì§€ ê¸°ë°˜ ì ìˆ˜ ë„¤íŠ¸ì›Œí¬ ë‚´ì— ë Œë”-ë¹„êµ ì•„í‚¤í…ì²˜ë¥¼ í†µí•©í•˜ì—¬, ìš°ë¦¬ì˜ ì ˆë‹¨ ì—°êµ¬ì—ì„œ ì…ì¦ëœ ë°”ì™€ ê°™ì´ ì‹œë®¬ë ˆì´ì…˜ì—ì„œ ì‹¤ì œë¡œì˜ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ìš°ë¦¬ëŠ” í¬ê´„ì ì¸ ì‹¤í—˜ì„ í†µí•´ ìš°ë¦¬ì˜ ë°©ë²•ì´ íšŒê·€, ë§¤ì¹­, ì •í•© ê¸°ë²•ì— ê¸°ë°˜í•œ ê¸°ì¡´ì˜ ê¸°ì¤€ì„ ì„ ëŠ¥ê°€í•˜ë©°, ì´ì „ì— ë³´ì§€ ëª»í•œ CAD ëª¨ë¸ì— ëŒ€í•œ ê°•ë ¥í•œ ë²”ì£¼ ë‚´ ì¼ë°˜í™”ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ë”ìš±ì´, ìš°ë¦¬ì˜ ì ‘ê·¼ë²•ì€ ì´‰ê° ë¬¼ì²´ ìì„¸ ì¶”ì •, ìì„¸ ì¶”ì , ë¶ˆí™•ì‹¤ì„± ì¶”ì •ì„ í†µí•©ëœ í”„ë ˆì„ì›Œí¬ë¡œ í†µí•©í•˜ì—¬ ë‹¤ì–‘í•œ ì‹¤ì œ ì¡°ê±´ì—ì„œ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ CAD ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ë¬¼ì²´ì˜ ì† ì•ˆì—ì„œì˜ ìì„¸ë¥¼ ì •í™•íˆ ì¶”ì •í•˜ëŠ” ìƒˆë¡œìš´ 3ë‹¨ê³„ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì²« ë²ˆì§¸ ë‹¨ê³„ì—ì„œëŠ” ìì„¸ í›„ë³´ë¥¼ ìƒ˜í”Œë§í•˜ê³  ì‚¬ì „ ìˆœìœ„ë¥¼ ë§¤ê¸°ë©°, ë‘ ë²ˆì§¸ ë‹¨ê³„ì—ì„œëŠ” í›„ë³´ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ì •ì œí•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ ë‹¨ê³„ì—ì„œëŠ” í›„ë³´ì˜ ì‚¬í›„ ìˆœìœ„ë¥¼ ë§¤ê²¨ ê°€ì¥ ê°€ëŠ¥ì„±ì´ ë†’ì€ ìì„¸ë¥¼ ì‹ë³„í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì€ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¡œë§Œ í›ˆë ¨ëœ í†µí•© ì—ë„ˆì§€ ê¸°ë°˜ í™•ì‚° ëª¨ë¸ì— ì˜í•´ ì¡°ì •ë©ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ìì„¸ ì¶”ì •ì„ ì •ì œí•˜ëŠ” ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ìƒì„±í•˜ê³ , ìì„¸ ì¶”ì •ì˜ í’ˆì§ˆì„ ì •ëŸ‰í™”í•˜ëŠ” ì—ë„ˆì§€ ìŠ¤ì¹¼ë¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ë˜í•œ, ì»´í“¨í„° ë¹„ì „ ë¶„ì•¼ì˜ ë Œë”-ë¹„êµ ì•„í‚¤í…ì²˜ë¥¼ ë„ì…í•˜ì—¬ ì‹œë®¬ë ˆì´ì…˜ì—ì„œ ì‹¤ì œë¡œì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì€ ê¸°ì¡´ì˜ íšŒê·€, ë§¤ì¹­, ë“±ë¡ ê¸°ë²•ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ë°©ë²•ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë©°, ìƒˆë¡œìš´ CAD ëª¨ë¸ì— ëŒ€í•œ ê°•ë ¥í•œ ì¼ë°˜í™” ëŠ¥ë ¥ì„ ë‚˜íƒ€ëƒˆìŠµë‹ˆë‹¤. ì¶”ê°€ì ìœ¼ë¡œ, ì´‰ê° ê¸°ë°˜ì˜ ë¬¼ì²´ ìì„¸ ì¶”ì •, ìì„¸ ì¶”ì , ë¶ˆí™•ì‹¤ì„± ì¶”ì •ì„ í†µí•©í•˜ì—¬ ë‹¤ì–‘í•œ ì‹¤ì œ ì¡°ê±´ì—ì„œ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë°œíœ˜í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. CAD ëª¨ë¸ ê¸°ë°˜ì˜ ë¬¼ì²´ì˜ ì¸í•¸ë“œ ìì„¸ ì¶”ì •ì€ ì‚°ì—… ë° ì¼ìƒ ì‘ì—…ì—ì„œ ì¤‘ìš”í•œ ì—­í• ì„ í•œë‹¤.
- 2. ë³¸ ë…¼ë¬¸ì€ ì¸í•¸ë“œ ìì„¸ ì¶”ì •ì„ ìœ„í•œ ìƒˆë¡œìš´ 3ë‹¨ê³„ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•œë‹¤.
- 3. ì œì•ˆëœ í”„ë ˆì„ì›Œí¬ëŠ” ì—ë„ˆì§€ ê¸°ë°˜ í™•ì‚° ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìì„¸ í›„ë³´ë¥¼ ìƒ˜í”Œë§, ì •ì œ, í›„ìˆœìœ„í™”í•œë‹¤.
- 4. ë Œë”-ë¹„êµ ì•„í‚¤í…ì²˜ë¥¼ í†µí•©í•˜ì—¬ ì‹œë®¬ë ˆì´ì…˜ì—ì„œ ì‹¤ì œ í™˜ê²½ìœ¼ë¡œì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œì¼°ë‹¤.
- 5. ì œì•ˆëœ ë°©ë²•ì€ ê¸°ì¡´ì˜ íšŒê·€, ë§¤ì¹­, ë“±ë¡ ê¸°ë²•ì„ ëŠ¥ê°€í•˜ë©°, ìƒˆë¡œìš´ CAD ëª¨ë¸ì— ëŒ€í•œ ì¼ë°˜í™” ëŠ¥ë ¥ì„ ë³´ì¸ë‹¤.


---

*Generated on 2025-09-23 10:38:50*