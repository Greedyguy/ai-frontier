---
keywords:
  - Vision-Language-Action-Critic Model
  - Vision-Language Model
  - Real-World Reinforcement Learning
  - Human-in-the-Loop Learning
  - InternVL
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2509.15937
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T09:21:45.031013",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Vision-Language-Action-Critic Model",
    "Vision-Language Model",
    "Real-World Reinforcement Learning",
    "Human-in-the-Loop Learning",
    "InternVL"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Vision-Language-Action-Critic Model": 0.78,
    "Vision-Language Model": 0.85,
    "Real-World Reinforcement Learning": 0.82,
    "Human-in-the-Loop Learning": 0.8,
    "InternVL": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Vision-Language-Action-Critic",
        "canonical": "Vision-Language-Action-Critic Model",
        "aliases": [
          "VLAC"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel model introduced in the paper, central to the study's findings.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.78
      },
      {
        "surface": "Vision-Language",
        "canonical": "Vision-Language Model",
        "aliases": [
          "VLM"
        ],
        "category": "evolved_concepts",
        "rationale": "Connects to the broader concept of multimodal learning, crucial for understanding the paper's context.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Real-World Reinforcement Learning",
        "canonical": "Real-World Reinforcement Learning",
        "aliases": [
          "Real-World RL"
        ],
        "category": "specific_connectable",
        "rationale": "Highlights the application domain, linking to practical implementations of RL.",
        "novelty_score": 0.55,
        "connectivity_score": 0.8,
        "specificity_score": 0.75,
        "link_intent_score": 0.82
      },
      {
        "surface": "Human-in-the-Loop",
        "canonical": "Human-in-the-Loop Learning",
        "aliases": [
          "HITL"
        ],
        "category": "specific_connectable",
        "rationale": "Emphasizes the interactive learning approach, relevant for linking with human-computer interaction studies.",
        "novelty_score": 0.6,
        "connectivity_score": 0.78,
        "specificity_score": 0.72,
        "link_intent_score": 0.8
      },
      {
        "surface": "InternVL",
        "canonical": "InternVL",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "A specific model referenced in the study, crucial for understanding the technical foundation.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "Sparse Rewards",
      "Task-Specific Reward Engineering"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Vision-Language-Action-Critic",
      "resolved_canonical": "Vision-Language-Action-Critic Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Vision-Language",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Real-World Reinforcement Learning",
      "resolved_canonical": "Real-World Reinforcement Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.8,
        "specificity": 0.75,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Human-in-the-Loop",
      "resolved_canonical": "Human-in-the-Loop Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.78,
        "specificity": 0.72,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "InternVL",
      "resolved_canonical": "InternVL",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# A Vision-Language-Action-Critic Model for Robotic Real-World Reinforcement Learning

**Korean Title:** ë¡œë´‡ì˜ ì‹¤ì œ í™˜ê²½ ê°•í™” í•™ìŠµì„ ìœ„í•œ ë¹„ì „-ì–¸ì–´-ì•¡ì…˜-ë¹„í‰ ëª¨ë¸

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15937.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2509.15937](https://arxiv.org/abs/2509.15937)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/CollabVLA_ Self-Reflective Vision-Language-Action Model Dreaming Together with Human_20250919|CollabVLA: Self-Reflective Vision-Language-Action Model Dreaming Together with Human]] (88.2% similar)
- [[2025-09-19/ThinkAct_ Vision-Language-Action Reasoning via Reinforced Visual Latent Planning_20250919|ThinkAct: Vision-Language-Action Reasoning via Reinforced Visual Latent Planning]] (86.5% similar)
- [[2025-09-18/CLAW_ A Vision-Language-Action Framework for Weight-Aware Robotic Grasping_20250918|CLAW: A Vision-Language-Action Framework for Weight-Aware Robotic Grasping]] (85.9% similar)
- [[2025-09-18/Robot Control Stack_ A Lean Ecosystem for Robot Learning at Scale_20250918|Robot Control Stack: A Lean Ecosystem for Robot Learning at Scale]] (85.8% similar)
- [[2025-09-19/ForceVLA_ Enhancing VLA Models with a Force-aware MoE for Contact-rich Manipulation_20250919|ForceVLA: Enhancing VLA Models with a Force-aware MoE for Contact-rich Manipulation]] (85.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Real-World Reinforcement Learning|Real-World Reinforcement Learning]], [[keywords/Human-in-the-Loop Learning|Human-in-the-Loop Learning]]
**âš¡ Unique Technical**: [[keywords/Vision-Language-Action-Critic Model|Vision-Language-Action-Critic Model]], [[keywords/InternVL|InternVL]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15937v1 Announce Type: cross 
Abstract: Robotic real-world reinforcement learning (RL) with vision-language-action (VLA) models is bottlenecked by sparse, handcrafted rewards and inefficient exploration. We introduce VLAC, a general process reward model built upon InternVL and trained on large scale heterogeneous datasets. Given pairwise observations and a language goal, it outputs dense progress delta and done signal, eliminating task-specific reward engineering, and supports one-shot in-context transfer to unseen tasks and environments. VLAC is trained on vision-language datasets to strengthen perception, dialogic and reasoning capabilities, together with robot and human trajectories data that ground action generation and progress estimation, and additionally strengthened to reject irrelevant prompts as well as detect regression or stagnation by constructing large numbers of negative and semantically mismatched samples. With prompt control, a single VLAC model alternately generating reward and action tokens, unifying critic and policy. Deployed inside an asynchronous real-world RL loop, we layer a graded human-in-the-loop protocol (offline demonstration replay, return and explore, human guided explore) that accelerates exploration and stabilizes early learning. Across four distinct real-world manipulation tasks, VLAC lifts success rates from about 30\% to about 90\% within 200 real-world interaction episodes; incorporating human-in-the-loop interventions yields a further 50% improvement in sample efficiency and achieves up to 100% final success.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15937v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ë¹„ì „-ì–¸ì–´-í–‰ë™(VLA) ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ë¡œë´‡ì˜ ì‹¤ì œ ê°•í™” í•™ìŠµ(RL)ì€ í¬ì†Œí•˜ê³  ìˆ˜ì‘ì—…ìœ¼ë¡œ ì„¤ê³„ëœ ë³´ìƒê³¼ ë¹„íš¨ìœ¨ì ì¸ íƒìƒ‰ìœ¼ë¡œ ì¸í•´ ë³‘ëª© í˜„ìƒì´ ë°œìƒí•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” InternVLì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ê³  ëŒ€ê·œëª¨ ì´ì§ˆì  ë°ì´í„°ì…‹ì—ì„œ í•™ìŠµëœ ì¼ë°˜ì ì¸ í”„ë¡œì„¸ìŠ¤ ë³´ìƒ ëª¨ë¸ì¸ VLACì„ ì†Œê°œí•©ë‹ˆë‹¤. ìŒìœ¼ë¡œ ì´ë£¨ì–´ì§„ ê´€ì°°ê³¼ ì–¸ì–´ ëª©í‘œê°€ ì£¼ì–´ì§€ë©´, ì´ëŠ” ì¡°ë°€í•œ ì§„í–‰ ë¸íƒ€ì™€ ì™„ë£Œ ì‹ í˜¸ë¥¼ ì¶œë ¥í•˜ì—¬ ê³¼ì œë³„ ë³´ìƒ ì„¤ê³„ë¥¼ ì œê±°í•˜ê³ , ë³´ì§€ ëª»í•œ ê³¼ì œì™€ í™˜ê²½ì— ëŒ€í•œ í•œ ë²ˆì˜ ë§¥ë½ ë‚´ ì „ì´ë¥¼ ì§€ì›í•©ë‹ˆë‹¤. VLACì€ ì‹œê°-ì–¸ì–´ ë°ì´í„°ì…‹ì—ì„œ í•™ìŠµë˜ì–´ ì¸ì‹, ëŒ€í™” ë° ì¶”ë¡  ëŠ¥ë ¥ì„ ê°•í™”í•˜ë©°, ë¡œë´‡ ë° ì¸ê°„ì˜ ê¶¤ì  ë°ì´í„°ë¥¼ í†µí•´ í–‰ë™ ìƒì„±ê³¼ ì§„í–‰ ì¶”ì •ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ë©°, ê´€ë ¨ ì—†ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ê±°ë¶€í•˜ê³  íšŒê·€ ë˜ëŠ” ì •ì²´ë¥¼ ê°ì§€í•  ìˆ˜ ìˆë„ë¡ ëŒ€ëŸ‰ì˜ ë¶€ì •ì ì´ê³  ì˜ë¯¸ì ìœ¼ë¡œ ë¶ˆì¼ì¹˜í•˜ëŠ” ìƒ˜í”Œì„ êµ¬ì„±í•˜ì—¬ ì¶”ê°€ë¡œ ê°•í™”ë©ë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ ì œì–´ë¥¼ í†µí•´ ë‹¨ì¼ VLAC ëª¨ë¸ì€ ë³´ìƒ ë° í–‰ë™ í† í°ì„ ë²ˆê°ˆì•„ ìƒì„±í•˜ì—¬ ë¹„í‰ê°€ì™€ ì •ì±…ì„ í†µí•©í•©ë‹ˆë‹¤. ë¹„ë™ê¸°ì ì¸ ì‹¤ì œ RL ë£¨í”„ ë‚´ì— ë°°ì¹˜ë˜ì–´, ìš°ë¦¬ëŠ” íƒìƒ‰ì„ ê°€ì†í™”í•˜ê³  ì´ˆê¸° í•™ìŠµì„ ì•ˆì •í™”í•˜ëŠ” ë“±ê¸‰í™”ëœ ì¸ê°„-ì°¸ì—¬ í”„ë¡œí† ì½œ(ì˜¤í”„ë¼ì¸ ì‹œì—° ì¬ìƒ, ë°˜í™˜ ë° íƒìƒ‰, ì¸ê°„ ì•ˆë‚´ íƒìƒ‰)ì„ ê³„ì¸µí™”í•©ë‹ˆë‹¤. ë„¤ ê°€ì§€ ì„œë¡œ ë‹¤ë¥¸ ì‹¤ì œ ì¡°ì‘ ì‘ì—…ì—ì„œ VLACì€ ì•½ 30%ì—ì„œ ì•½ 90%ë¡œ ì„±ê³µë¥ ì„ í–¥ìƒì‹œí‚¤ë©°, ì¸ê°„-ì°¸ì—¬ ê°œì…ì„ í†µí•©í•˜ë©´ ìƒ˜í”Œ íš¨ìœ¨ì„±ì´ 50% ë” í–¥ìƒë˜ê³  ìµœëŒ€ 100%ì˜ ìµœì¢… ì„±ê³µì„ ë‹¬ì„±í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë¡œë´‡ì˜ ì‹¤ì œ ê°•í™” í•™ìŠµì—ì„œ ì‹œê°-ì–¸ì–´-í–‰ë™(VLA) ëª¨ë¸ì˜ ë¬¸ì œì ì„ í•´ê²°í•˜ê¸° ìœ„í•´ VLACë¼ëŠ” ì¼ë°˜ì ì¸ ë³´ìƒ ëª¨ë¸ì„ ì œì•ˆí•©ë‹ˆë‹¤. VLACëŠ” InternVLì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ì—¬ ëŒ€ê·œëª¨ ì´ì§ˆì  ë°ì´í„°ì…‹ì—ì„œ í›ˆë ¨ë˜ë©°, ì–¸ì–´ ëª©í‘œì™€ ìŒìœ¼ë¡œ ëœ ê´€ì°°ì„ í†µí•´ ë°€ë„ ìˆëŠ” ì§„í–‰ ìƒí™©ê³¼ ì™„ë£Œ ì‹ í˜¸ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ì´ëŠ” ê³¼ì œë³„ ë³´ìƒ ì„¤ê³„ë¥¼ ì œê±°í•˜ê³  ìƒˆë¡œìš´ ê³¼ì œì™€ í™˜ê²½ì— ëŒ€í•œ ì›ìƒ· ì „ì´ë¥¼ ì§€ì›í•©ë‹ˆë‹¤. VLACëŠ” ì‹œê°-ì–¸ì–´ ë°ì´í„°ì…‹ê³¼ ë¡œë´‡ ë° ì¸ê°„ ê²½ë¡œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¸ì‹, ëŒ€í™” ë° ì¶”ë¡  ëŠ¥ë ¥ì„ ê°•í™”í•˜ê³ , ë¶€ì ì ˆí•œ í”„ë¡¬í”„íŠ¸ë¥¼ ê±°ë¶€í•˜ê³  í‡´ë³´ë‚˜ ì •ì²´ë¥¼ ê°ì§€í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ë¹„ë™ê¸° ì‹¤ì œ RL ë£¨í”„ì— ë°°ì¹˜ë˜ì–´ ì¸ê°„ì˜ ê°œì…ì„ í†µí•´ íƒìƒ‰ì„ ê°€ì†í™”í•˜ê³  ì´ˆê¸° í•™ìŠµì„ ì•ˆì •í™”í•©ë‹ˆë‹¤. ë„¤ ê°€ì§€ ì‹¤ì œ ì¡°ì‘ ì‘ì—…ì—ì„œ VLACëŠ” ì„±ê³µë¥ ì„ ì•½ 30%ì—ì„œ 90%ë¡œ í–¥ìƒì‹œí‚¤ë©°, ì¸ê°„ì˜ ê°œì…ì„ í†µí•´ ìƒ˜í”Œ íš¨ìœ¨ì„±ì„ 50% ë” ê°œì„ í•˜ê³  ìµœëŒ€ 100%ì˜ ìµœì¢… ì„±ê³µë¥ ì„ ë‹¬ì„±í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. VLACëŠ” InternVLì„ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¶•ëœ ì¼ë°˜ì ì¸ í”„ë¡œì„¸ìŠ¤ ë³´ìƒ ëª¨ë¸ë¡œ, ëŒ€ê·œëª¨ ì´ì§ˆì  ë°ì´í„°ì…‹ì—ì„œ í•™ìŠµë˜ì–´ ì‘ì—…ë³„ ë³´ìƒ ì—”ì§€ë‹ˆì–´ë§ì„ ì œê±°í•©ë‹ˆë‹¤.
- 2. VLACëŠ” ì‹œê°-ì–¸ì–´ ë°ì´í„°ì…‹ì„ í†µí•´ ì¸ì‹, ëŒ€í™” ë° ì¶”ë¡  ëŠ¥ë ¥ì„ ê°•í™”í•˜ë©°, ë¡œë´‡ ë° ì¸ê°„ ê²½ë¡œ ë°ì´í„°ë¥¼ í†µí•´ í–‰ë™ ìƒì„± ë° ì§„í–‰ ì¶”ì •ì„ ì§€ì›í•©ë‹ˆë‹¤.
- 3. VLACëŠ” ë¶€ì ì ˆí•œ í”„ë¡¬í”„íŠ¸ë¥¼ ê±°ë¶€í•˜ê³  íšŒê·€ ë˜ëŠ” ì •ì²´ë¥¼ ê°ì§€í•  ìˆ˜ ìˆë„ë¡ ë§ì€ ìˆ˜ì˜ ë¶€ì •ì  ë° ì˜ë¯¸ì ìœ¼ë¡œ ë¶ˆì¼ì¹˜í•˜ëŠ” ìƒ˜í”Œì„ êµ¬ì„±í•˜ì—¬ ê°•í™”ë©ë‹ˆë‹¤.
- 4. VLACëŠ” ë¹„ë™ê¸° ì‹¤ì„¸ê³„ ê°•í™” í•™ìŠµ ë£¨í”„ ë‚´ì— ë°°ì¹˜ë˜ì–´ ì¸ê°„ ì°¸ì—¬ í”„ë¡œí† ì½œì„ í†µí•´ íƒìƒ‰ì„ ê°€ì†í™”í•˜ê³  ì´ˆê¸° í•™ìŠµì„ ì•ˆì •í™”í•©ë‹ˆë‹¤.
- 5. ë„¤ ê°€ì§€ ì‹¤ì„¸ê³„ ì¡°ì‘ ì‘ì—…ì—ì„œ VLACëŠ” ì„±ê³µë¥ ì„ ì•½ 30%ì—ì„œ ì•½ 90%ë¡œ í–¥ìƒì‹œí‚¤ë©°, ì¸ê°„ ì°¸ì—¬ ê°œì…ì„ í†µí•´ ìƒ˜í”Œ íš¨ìœ¨ì„±ì„ 50% ë” ê°œì„ í•˜ê³  ìµœëŒ€ 100%ì˜ ìµœì¢… ì„±ê³µì„ ë‹¬ì„±í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-23 09:21:45*