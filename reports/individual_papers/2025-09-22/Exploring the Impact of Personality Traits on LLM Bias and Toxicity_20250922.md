---
keywords:
  - Large Language Model
  - HEXACO Personality Framework
  - Bias and Toxicity
  - Content Safety
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2502.12566
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T09:35:27.661033",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "HEXACO Personality Framework",
    "Bias and Toxicity",
    "Content Safety"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "HEXACO Personality Framework": 0.8,
    "Bias and Toxicity": 0.78,
    "Content Safety": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Language Models"
        ],
        "category": "broad_technical",
        "rationale": "Central to the study, linking to foundational concepts in AI.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "HEXACO personality framework",
        "canonical": "HEXACO Personality Framework",
        "aliases": [
          "HEXACO"
        ],
        "category": "unique_technical",
        "rationale": "Key framework used in the study for assessing personality traits.",
        "novelty_score": 0.75,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "bias and toxicity",
        "canonical": "Bias and Toxicity",
        "aliases": [
          "bias",
          "toxicity"
        ],
        "category": "specific_connectable",
        "rationale": "Critical aspects of LLM outputs being examined.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.72,
        "link_intent_score": 0.78
      },
      {
        "surface": "content safety",
        "canonical": "Content Safety",
        "aliases": [
          "safety",
          "content moderation"
        ],
        "category": "specific_connectable",
        "rationale": "Important consideration for LLM deployment and research.",
        "novelty_score": 0.55,
        "connectivity_score": 0.82,
        "specificity_score": 0.7,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "HEXACO personality framework",
      "resolved_canonical": "HEXACO Personality Framework",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "bias and toxicity",
      "resolved_canonical": "Bias and Toxicity",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.72,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "content safety",
      "resolved_canonical": "Content Safety",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.82,
        "specificity": 0.7,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Exploring the Impact of Personality Traits on LLM Bias and Toxicity

**Korean Title:** ì„±ê²© íŠ¹ì„±ì´ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ í¸í–¥ì„±ê³¼ ìœ í•´ì„±ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ íƒêµ¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2502.12566.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2502.12566](https://arxiv.org/abs/2502.12566)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/Do LLMs Align Human Values Regarding Social Biases? Judging and Explaining Social Biases with LLMs_20250918|Do LLMs Align Human Values Regarding Social Biases? Judging and Explaining Social Biases with LLMs]] (86.5% similar)
- [[2025-09-17/Simulating a Bias Mitigation Scenario in Large Language Models_20250917|Simulating a Bias Mitigation Scenario in Large Language Models]] (86.4% similar)
- [[2025-09-22/Bias Beware_ The Impact of Cognitive Biases on LLM-Driven Product Recommendations_20250922|Bias Beware: The Impact of Cognitive Biases on LLM-Driven Product Recommendations]] (86.0% similar)
- [[2025-09-19/Adding LLMs to the psycholinguistic norming toolbox_ A practical guide to getting the most out of human ratings_20250919|Adding LLMs to the psycholinguistic norming toolbox: A practical guide to getting the most out of human ratings]] (85.3% similar)
- [[2025-09-22/Subjective Behaviors and Preferences in LLM_ Language of Browsing_20250922|Subjective Behaviors and Preferences in LLM: Language of Browsing]] (85.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Bias and Toxicity|Bias and Toxicity]], [[keywords/Content Safety|Content Safety]]
**âš¡ Unique Technical**: [[keywords/HEXACO Personality Framework|HEXACO Personality Framework]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2502.12566v3 Announce Type: replace 
Abstract: With the different roles that AI is expected to play in human life, imbuing large language models (LLMs) with different personalities has attracted increasing research interests. While the "personification" enhances human experiences of interactivity and adaptability of LLMs, it gives rise to critical concerns about content safety, particularly regarding bias, sentiment and toxicity of LLM generation. This study explores how assigning different personality traits to LLMs affects the toxicity and biases of their outputs. Leveraging the widely accepted HEXACO personality framework developed in social psychology, we design experimentally sound prompts to test three LLMs' performance on three toxic and bias benchmarks. The findings demonstrate the sensitivity of all three models to HEXACO personality traits and, more importantly, a consistent variation in the biases, negative sentiment and toxicity of their output. In particular, adjusting the levels of several personality traits can effectively reduce bias and toxicity in model performance, similar to humans' correlations between personality traits and toxic behaviors. The findings highlight the additional need to examine content safety besides the efficiency of training or fine-tuning methods for LLM personification. They also suggest a potential for the adjustment of personalities to be a simple and low-cost method to conduct controlled text generation.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2502.12566v3 ë°œí‘œ ìœ í˜•: êµì²´  
ì´ˆë¡: ì¸ê³µì§€ëŠ¥ì´ ì¸ê°„ ìƒí™œì—ì„œ ë‹¤ì–‘í•œ ì—­í• ì„ ìˆ˜í–‰í•  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë¨ì— ë”°ë¼, ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì— ë‹¤ì–‘í•œ ì„±ê²©ì„ ë¶€ì—¬í•˜ëŠ” ê²ƒì´ ì ì  ë” ë§ì€ ì—°êµ¬ ê´€ì‹¬ì„ ëŒê³  ìˆìŠµë‹ˆë‹¤. "ì¸ê²©í™”"ëŠ” LLMì˜ ìƒí˜¸ì‘ìš©ì„±ê³¼ ì ì‘ì„±ì„ í–¥ìƒì‹œí‚¤ì§€ë§Œ, LLM ìƒì„±ì˜ í¸í–¥, ê°ì • ë° ìœ í•´ì„±ì— ê´€í•œ ì½˜í…ì¸  ì•ˆì „ì„±ì— ëŒ€í•œ ì¤‘ìš”í•œ ìš°ë ¤ë¥¼ ì•¼ê¸°í•©ë‹ˆë‹¤. ë³¸ ì—°êµ¬ëŠ” LLMì— ë‹¤ì–‘í•œ ì„±ê²© íŠ¹ì„±ì„ ë¶€ì—¬í•˜ëŠ” ê²ƒì´ ê·¸ë“¤ì˜ ì¶œë ¥ë¬¼ì˜ ìœ í•´ì„±ê³¼ í¸í–¥ì— ì–´ë–»ê²Œ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ë¥¼ íƒêµ¬í•©ë‹ˆë‹¤. ì‚¬íšŒì‹¬ë¦¬í•™ì—ì„œ ê°œë°œëœ ë„ë¦¬ ì¸ì •ë°›ëŠ” HEXACO ì„±ê²© í”„ë ˆì„ì›Œí¬ë¥¼ í™œìš©í•˜ì—¬, ì„¸ ê°€ì§€ ìœ í•´ì„±ê³¼ í¸í–¥ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ì„¸ ê°€ì§€ LLMì˜ ì„±ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•˜ê¸° ìœ„í•œ ì‹¤í—˜ì ìœ¼ë¡œ íƒ€ë‹¹í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ì„¤ê³„í•©ë‹ˆë‹¤. ì—°êµ¬ ê²°ê³¼ëŠ” ì„¸ ëª¨ë¸ ëª¨ë‘ê°€ HEXACO ì„±ê²© íŠ¹ì„±ì— ë¯¼ê°í•˜ë©°, ë” ì¤‘ìš”í•˜ê²ŒëŠ” ê·¸ë“¤ì˜ ì¶œë ¥ë¬¼ì˜ í¸í–¥, ë¶€ì •ì  ê°ì • ë° ìœ í•´ì„±ì—ì„œ ì¼ê´€ëœ ë³€í™”ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. íŠ¹íˆ, ì—¬ëŸ¬ ì„±ê²© íŠ¹ì„±ì˜ ìˆ˜ì¤€ì„ ì¡°ì •í•˜ëŠ” ê²ƒì´ ëª¨ë¸ ì„±ëŠ¥ì˜ í¸í–¥ê³¼ ìœ í•´ì„±ì„ íš¨ê³¼ì ìœ¼ë¡œ ì¤„ì¼ ìˆ˜ ìˆìœ¼ë©°, ì´ëŠ” ì¸ê°„ì˜ ì„±ê²© íŠ¹ì„±ê³¼ ìœ í•´ í–‰ë™ ê°„ì˜ ìƒê´€ê´€ê³„ì™€ ìœ ì‚¬í•©ë‹ˆë‹¤. ì´ ì—°êµ¬ ê²°ê³¼ëŠ” LLM ì¸ê²©í™”ë¥¼ ìœ„í•œ í›ˆë ¨ ë˜ëŠ” ë¯¸ì„¸ ì¡°ì • ë°©ë²•ì˜ íš¨ìœ¨ì„± ì™¸ì—ë„ ì½˜í…ì¸  ì•ˆì „ì„±ì„ ê²€í† í•  ì¶”ê°€ì ì¸ í•„ìš”ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤. ë˜í•œ, ì„±ê²© ì¡°ì •ì´ í†µì œëœ í…ìŠ¤íŠ¸ ìƒì„±ì„ ìˆ˜í–‰í•˜ëŠ” ê°„ë‹¨í•˜ê³  ì €ë¹„ìš©ì˜ ë°©ë²•ì´ ë  ê°€ëŠ¥ì„±ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì— ë‹¤ì–‘í•œ ì„±ê²© íŠ¹ì„±ì„ ë¶€ì—¬í•˜ëŠ” ê²ƒì´ ëª¨ë¸ì˜ í¸í–¥ì„±ê³¼ ìœ í•´ì„±ì— ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ë¥¼ íƒêµ¬í•©ë‹ˆë‹¤. ì‚¬íšŒì‹¬ë¦¬í•™ì—ì„œ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” HEXACO ì„±ê²© í”„ë ˆì„ì›Œí¬ë¥¼ í™œìš©í•˜ì—¬, ì„¸ ê°€ì§€ LLMì˜ ì„±ëŠ¥ì„ ì„¸ ê°€ì§€ ìœ í•´ì„±ê³¼ í¸í–¥ì„± ê¸°ì¤€ìœ¼ë¡œ ì‹¤í—˜ì ìœ¼ë¡œ í‰ê°€í–ˆìŠµë‹ˆë‹¤. ì—°êµ¬ ê²°ê³¼, ëª¨ë“  ëª¨ë¸ì´ HEXACO ì„±ê²© íŠ¹ì„±ì— ë¯¼ê°í•˜ë©°, ì„±ê²© íŠ¹ì„±ì„ ì¡°ì •í•¨ìœ¼ë¡œì¨ í¸í–¥ì„±ê³¼ ìœ í•´ì„±ì„ íš¨ê³¼ì ìœ¼ë¡œ ì¤„ì¼ ìˆ˜ ìˆìŒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” LLMì˜ ì„±ê²©í™”ì—ì„œ ì½˜í…ì¸  ì•ˆì „ì„±ì„ ê³ ë ¤í•´ì•¼ í•  í•„ìš”ì„±ì„ ê°•ì¡°í•˜ë©°, ì„±ê²© ì¡°ì •ì´ í†µì œëœ í…ìŠ¤íŠ¸ ìƒì„±ì„ ìœ„í•œ ê°„ë‹¨í•˜ê³  ì €ë¹„ìš©ì˜ ë°©ë²•ì´ ë  ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì— ë‹¤ì–‘í•œ ì„±ê²©ì„ ë¶€ì—¬í•˜ëŠ” ê²ƒì€ ìƒí˜¸ì‘ìš©ì„±ê³¼ ì ì‘ì„±ì„ ë†’ì´ëŠ” ë™ì‹œì— í¸í–¥, ê°ì • ë° ë…ì„±ì— ëŒ€í•œ ìš°ë ¤ë¥¼ ë¶ˆëŸ¬ì¼ìœ¼í‚µë‹ˆë‹¤.
- 2. ì—°êµ¬ëŠ” HEXACO ì„±ê²© ëª¨ë¸ì„ í™œìš©í•˜ì—¬ LLMì˜ ì„±ê²© íŠ¹ì„±ì´ ì¶œë ¥ì˜ ë…ì„±ê³¼ í¸í–¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì¡°ì‚¬í•˜ì˜€ìŠµë‹ˆë‹¤.
- 3. ì‹¤í—˜ ê²°ê³¼, LLMì˜ ì„±ê²© íŠ¹ì„±ì„ ì¡°ì •í•¨ìœ¼ë¡œì¨ í¸í–¥ê³¼ ë…ì„±ì„ íš¨ê³¼ì ìœ¼ë¡œ ì¤„ì¼ ìˆ˜ ìˆìŒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.
- 4. ì—°êµ¬ëŠ” LLMì˜ ì¸ê²©í™”ì—ì„œ í›ˆë ¨ íš¨ìœ¨ì„± ì™¸ì—ë„ ì½˜í…ì¸  ì•ˆì „ì„±ì„ ê²€í† í•  í•„ìš”ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤.
- 5. ì„±ê²© ì¡°ì •ì´ í†µì œëœ í…ìŠ¤íŠ¸ ìƒì„±ì„ ìœ„í•œ ê°„ë‹¨í•˜ê³  ì €ë¹„ìš©ì˜ ë°©ë²•ì´ ë  ê°€ëŠ¥ì„±ì„ ì œì•ˆí•©ë‹ˆë‹¤.


---

*Generated on 2025-09-23 09:35:27*