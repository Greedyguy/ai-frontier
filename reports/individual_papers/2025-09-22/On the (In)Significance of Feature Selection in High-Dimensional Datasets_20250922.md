---
keywords:
  - Feature Selection
  - High-Dimensional Data
  - Computational Genomics
  - Predictive Modeling
category: cs.LG
publish_date: 2025-09-22
arxiv_id: 2508.03593
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:10:17.373677",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Feature Selection",
    "High-Dimensional Data",
    "Computational Genomics",
    "Predictive Modeling"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Feature Selection": 0.78,
    "High-Dimensional Data": 0.72,
    "Computational Genomics": 0.77,
    "Predictive Modeling": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Feature Selection",
        "canonical": "Feature Selection",
        "aliases": [
          "FS"
        ],
        "category": "unique_technical",
        "rationale": "Feature Selection is central to the paper's argument and challenges existing assumptions, making it a unique technical focus.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "High-Dimensional Datasets",
        "canonical": "High-Dimensional Data",
        "aliases": [
          "High-Dimensional Datasets"
        ],
        "category": "broad_technical",
        "rationale": "High-Dimensional Data is a fundamental concept in machine learning, relevant to understanding the paper's context.",
        "novelty_score": 0.55,
        "connectivity_score": 0.8,
        "specificity_score": 0.7,
        "link_intent_score": 0.72
      },
      {
        "surface": "Computational Genomics",
        "canonical": "Computational Genomics",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Computational Genomics is a key application area mentioned, linking the paper to a specific domain.",
        "novelty_score": 0.6,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      },
      {
        "surface": "Predictive Performance",
        "canonical": "Predictive Modeling",
        "aliases": [
          "Predictive Performance"
        ],
        "category": "broad_technical",
        "rationale": "Predictive Modeling is a core concept in evaluating feature selection methods, relevant across datasets.",
        "novelty_score": 0.5,
        "connectivity_score": 0.78,
        "specificity_score": 0.65,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "microarray",
      "mass spectrometry",
      "imaging"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Feature Selection",
      "resolved_canonical": "Feature Selection",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "High-Dimensional Datasets",
      "resolved_canonical": "High-Dimensional Data",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.8,
        "specificity": 0.7,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "Computational Genomics",
      "resolved_canonical": "Computational Genomics",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Predictive Performance",
      "resolved_canonical": "Predictive Modeling",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.78,
        "specificity": 0.65,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# On the (In)Significance of Feature Selection in High-Dimensional Datasets

**Korean Title:** ê³ ì°¨ì› ë°ì´í„°ì…‹ì—ì„œ íŠ¹ì§• ì„ íƒì˜ (ë¹„)ì¤‘ìš”ì„±ì— ê´€í•˜ì—¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2508.03593.pdf)
**Category**: cs.LG
**Published**: 2025-09-22
**ArXiv ID**: [2508.03593](https://arxiv.org/abs/2508.03593)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Nonconvex Regularization for Feature Selection in Reinforcement Learning_20250922|Nonconvex Regularization for Feature Selection in Reinforcement Learning]] (79.2% similar)
- [[2025-09-22/Top-$k$ Feature Importance Ranking_20250922|Top-$k$ Feature Importance Ranking]] (78.9% similar)
- [[2025-09-17/Beyond Correlation_ Causal Multi-View Unsupervised Feature Selection Learning_20250917|Beyond Correlation: Causal Multi-View Unsupervised Feature Selection Learning]] (78.7% similar)
- [[2025-09-22/IEFS-GMB_ Gradient Memory Bank-Guided Feature Selection Based on Information Entropy for EEG Classification of Neurological Disorders_20250922|IEFS-GMB: Gradient Memory Bank-Guided Feature Selection Based on Information Entropy for EEG Classification of Neurological Disorders]] (78.5% similar)
- [[2025-09-18/Data coarse graining can improve model performance_20250918|Data coarse graining can improve model performance]] (77.4% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/High-Dimensional Data|High-Dimensional Data]], [[keywords/Predictive Modeling|Predictive Modeling]]
**ğŸ”— Specific Connectable**: [[keywords/Computational Genomics|Computational Genomics]]
**âš¡ Unique Technical**: [[keywords/Feature Selection|Feature Selection]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2508.03593v2 Announce Type: replace 
Abstract: Feature selection (FS) is assumed to improve predictive performance and identify meaningful features in high-dimensional datasets. Surprisingly, small random subsets of features (0.02-1%) match or outperform the predictive performance of both full feature sets and FS across 28 out of 30 diverse datasets (microarray, bulk and single-cell RNA-Seq, mass spectrometry, imaging, etc.). In short, any arbitrary set of features is as good as any other (with surprisingly low variance in results) - so how can a particular set of selected features be "important" if they perform no better than an arbitrary set? These results challenge the assumption that computationally selected features reliably capture meaningful signals, emphasizing the importance of rigorous validation before interpreting selected features as actionable, particularly in computational genomics.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2508.03593v2 ë°œí‘œ ìœ í˜•: êµì²´  
ì´ˆë¡: íŠ¹ì§• ì„ íƒ(FS)ì€ ì˜ˆì¸¡ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê³  ê³ ì°¨ì› ë°ì´í„°ì…‹ì—ì„œ ì˜ë¯¸ ìˆëŠ” íŠ¹ì§•ì„ ì‹ë³„í•  ìˆ˜ ìˆë‹¤ê³  ê°€ì •ë©ë‹ˆë‹¤. ë†€ëê²Œë„, ì‘ì€ ë¬´ì‘ìœ„ íŠ¹ì§• í•˜ìœ„ ì§‘í•©(0.02-1%)ì´ ì „ì²´ íŠ¹ì§• ì§‘í•©ê³¼ FSì˜ ì˜ˆì¸¡ ì„±ëŠ¥ì„ 30ê°œì˜ ë‹¤ì–‘í•œ ë°ì´í„°ì…‹(ë§ˆì´í¬ë¡œì–´ë ˆì´, ë²Œí¬ ë° ë‹¨ì¼ ì„¸í¬ RNA-Seq, ì§ˆëŸ‰ ë¶„ì„, ì´ë¯¸ì§€ ë“±) ì¤‘ 28ê°œì—ì„œ ë§ì¶”ê±°ë‚˜ ëŠ¥ê°€í•©ë‹ˆë‹¤. ìš”ì»¨ëŒ€, ì„ì˜ì˜ íŠ¹ì§• ì§‘í•©ì€ ë‹¤ë¥¸ ì–´ë–¤ ê²ƒê³¼ë„ ë§ˆì°¬ê°€ì§€ë¡œ ì¢‹ìŠµë‹ˆë‹¤(ê²°ê³¼ì˜ ë¶„ì‚°ì´ ë†€ë¼ìš¸ ì •ë„ë¡œ ë‚®ìŒ) - ê·¸ë ‡ë‹¤ë©´ íŠ¹ì • ì„ íƒëœ íŠ¹ì§• ì§‘í•©ì´ "ì¤‘ìš”í•˜ë‹¤"ê³  í•  ìˆ˜ ìˆëŠ” ì´ìœ ëŠ” ë¬´ì—‡ì…ë‹ˆê¹Œ, ì„ì˜ì˜ ì§‘í•©ë³´ë‹¤ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì´ì§€ ì•ŠëŠ”ë‹¤ë©´? ì´ëŸ¬í•œ ê²°ê³¼ëŠ” ê³„ì‚°ì ìœ¼ë¡œ ì„ íƒëœ íŠ¹ì§•ì´ ì˜ë¯¸ ìˆëŠ” ì‹ í˜¸ë¥¼ ì‹ ë¢°ì„± ìˆê²Œ í¬ì°©í•œë‹¤ëŠ” ê°€ì •ì„ ë„ì „í•˜ë©°, íŠ¹íˆ ê³„ì‚° ìœ ì „ì²´í•™ì—ì„œ ì„ íƒëœ íŠ¹ì§•ì„ ì‹¤í–‰ ê°€ëŠ¥í•œ ê²ƒìœ¼ë¡œ í•´ì„í•˜ê¸° ì „ì— ì—„ê²©í•œ ê²€ì¦ì˜ ì¤‘ìš”ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ê³ ì°¨ì› ë°ì´í„°ì…‹ì—ì„œ íŠ¹ì§• ì„ íƒ(FS)ì´ ì˜ˆì¸¡ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê³  ì˜ë¯¸ ìˆëŠ” íŠ¹ì§•ì„ ì‹ë³„í•œë‹¤ê³  ê°€ì •í•˜ì§€ë§Œ, ì‹¤ì œë¡œëŠ” ë¬´ì‘ìœ„ë¡œ ì„ íƒëœ ì†Œê·œëª¨ íŠ¹ì§• ì§‘í•©(0.02-1%)ì´ ì „ì²´ íŠ¹ì§• ì§‘í•©ì´ë‚˜ FSì˜ ì˜ˆì¸¡ ì„±ëŠ¥ì„ ëŠ¥ê°€í•˜ê±°ë‚˜ ë™ë“±í•˜ë‹¤ëŠ” ê²ƒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. 30ê°œì˜ ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ ì¤‘ 28ê°œì—ì„œ ì´ëŸ¬í•œ ê²°ê³¼ê°€ ë‚˜íƒ€ë‚¬ìœ¼ë©°, ì´ëŠ” íŠ¹ì • íŠ¹ì§• ì§‘í•©ì´ ì„ì˜ì˜ ì§‘í•©ë³´ë‹¤ ì¤‘ìš”í•˜ë‹¤ê³  í•´ì„í•˜ê¸° ì–´ë µê²Œ ë§Œë“­ë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ê³„ì‚°ì ìœ¼ë¡œ ì„ íƒëœ íŠ¹ì§•ì´ ì˜ë¯¸ ìˆëŠ” ì‹ í˜¸ë¥¼ í¬ì°©í•œë‹¤ëŠ” ê°€ì •ì„ ì¬ê³ í•  í•„ìš”ì„±ì„ ì œê¸°í•˜ë©°, íŠ¹íˆ ê³„ì‚° ìœ ì „ì²´í•™ì—ì„œ ì„ íƒëœ íŠ¹ì§•ì„ í•´ì„í•˜ê¸° ì „ì— ì—„ê²©í•œ ê²€ì¦ì´ í•„ìš”í•¨ì„ ê°•ì¡°í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ê³ ì°¨ì› ë°ì´í„°ì…‹ì—ì„œ íŠ¹ì§• ì„ íƒì€ ì˜ˆì¸¡ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê³  ì˜ë¯¸ ìˆëŠ” íŠ¹ì§•ì„ ì‹ë³„í•˜ëŠ” ê²ƒìœ¼ë¡œ ê°€ì •ëœë‹¤.
- 2. 30ê°œì˜ ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ ì¤‘ 28ê°œì—ì„œ ì‘ì€ ë¬´ì‘ìœ„ íŠ¹ì§• í•˜ìœ„ ì§‘í•©ì´ ì „ì²´ íŠ¹ì§• ì§‘í•©ê³¼ íŠ¹ì§• ì„ íƒì„ ëŠ¥ê°€í•˜ê±°ë‚˜ ë™ë“±í•œ ì˜ˆì¸¡ ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤.
- 3. ì„ì˜ì˜ íŠ¹ì§• ì§‘í•©ì´ ì„ íƒëœ íŠ¹ì§• ì§‘í•©ê³¼ ë™ë“±í•œ ì„±ëŠ¥ì„ ë³´ì´ë¯€ë¡œ, íŠ¹ì • íŠ¹ì§• ì§‘í•©ì˜ ì¤‘ìš”ì„±ì„ ì£¼ì¥í•˜ê¸° ì–´ë µë‹¤.
- 4. ì´ ê²°ê³¼ëŠ” ê³„ì‚°ì ìœ¼ë¡œ ì„ íƒëœ íŠ¹ì§•ì´ ì˜ë¯¸ ìˆëŠ” ì‹ í˜¸ë¥¼ í¬ì°©í•œë‹¤ëŠ” ê°€ì •ì„ ë„ì „í•˜ë©°, ì„ íƒëœ íŠ¹ì§•ì„ ì‹¤í–‰ ê°€ëŠ¥í•œ ê²ƒìœ¼ë¡œ í•´ì„í•˜ê¸° ì „ì— ì—„ê²©í•œ ê²€ì¦ì˜ ì¤‘ìš”ì„±ì„ ê°•ì¡°í•œë‹¤.
- 5. íŠ¹íˆ ê³„ì‚° ìœ ì „ì²´í•™ì—ì„œ ì„ íƒëœ íŠ¹ì§•ì„ í•´ì„í•˜ê¸° ì „ì— ì² ì €í•œ ê²€ì¦ì´ í•„ìš”í•˜ë‹¤.


---

*Generated on 2025-09-23 11:10:17*