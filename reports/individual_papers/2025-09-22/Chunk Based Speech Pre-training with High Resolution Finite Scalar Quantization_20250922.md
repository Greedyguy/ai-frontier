---
keywords:
  - Self-supervised Learning
  - Finite Scalar Quantization
  - Chunk-based Self-supervised Learning
  - Speech Recognition
  - Masked Prediction Loss
category: cs.CL
publish_date: 2025-09-22
arxiv_id: 2509.15579
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:31:08.881407",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Self-supervised Learning",
    "Finite Scalar Quantization",
    "Chunk-based Self-supervised Learning",
    "Speech Recognition",
    "Masked Prediction Loss"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Self-supervised Learning": 0.85,
    "Finite Scalar Quantization": 0.7,
    "Chunk-based Self-supervised Learning": 0.78,
    "Speech Recognition": 0.65,
    "Masked Prediction Loss": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "self-supervised learning",
        "canonical": "Self-supervised Learning",
        "aliases": [
          "SSL"
        ],
        "category": "specific_connectable",
        "rationale": "This is a key technique driving advancements in speech technology, linking well with existing knowledge in machine learning.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.8,
        "link_intent_score": 0.85
      },
      {
        "surface": "finite scalar quantization",
        "canonical": "Finite Scalar Quantization",
        "aliases": [
          "FSQ"
        ],
        "category": "unique_technical",
        "rationale": "This is a unique method proposed in the paper, crucial for understanding the novel approach to speech pre-training.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.7
      },
      {
        "surface": "chunk based self-supervised learning",
        "canonical": "Chunk-based Self-supervised Learning",
        "aliases": [
          "Chunk SSL"
        ],
        "category": "unique_technical",
        "rationale": "This represents a novel adaptation of self-supervised learning for streaming applications, enhancing understanding of the paper's contributions.",
        "novelty_score": 0.8,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.78
      },
      {
        "surface": "speech recognition",
        "canonical": "Speech Recognition",
        "aliases": [],
        "category": "broad_technical",
        "rationale": "A fundamental application area for the proposed methods, linking to broader speech processing research.",
        "novelty_score": 0.3,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.65
      },
      {
        "surface": "masked prediction loss",
        "canonical": "Masked Prediction Loss",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "This loss function is central to the paper's methodology, connecting to similar techniques in machine learning.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "low latency",
      "streaming applications"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "self-supervised learning",
      "resolved_canonical": "Self-supervised Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.8,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "finite scalar quantization",
      "resolved_canonical": "Finite Scalar Quantization",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "chunk based self-supervised learning",
      "resolved_canonical": "Chunk-based Self-supervised Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "speech recognition",
      "resolved_canonical": "Speech Recognition",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.65
      }
    },
    {
      "candidate_surface": "masked prediction loss",
      "resolved_canonical": "Masked Prediction Loss",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# Chunk Based Speech Pre-training with High Resolution Finite Scalar Quantization

**Korean Title:** ê³ í•´ìƒë„ ìœ í•œ ìŠ¤ì¹¼ë¼ ì–‘ìí™”ë¥¼ ì´ìš©í•œ ì²­í¬ ê¸°ë°˜ ìŒì„± ì‚¬ì „ í›ˆë ¨

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15579.pdf)
**Category**: cs.CL
**Published**: 2025-09-22
**ArXiv ID**: [2509.15579](https://arxiv.org/abs/2509.15579)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Fed-PISA_ Federated Voice Cloning via Personalized Identity-Style Adaptation_20250922|Fed-PISA: Federated Voice Cloning via Personalized Identity-Style Adaptation]] (82.1% similar)
- [[2025-09-22/Direct Simultaneous Translation Activation for Large Audio-Language Models_20250922|Direct Simultaneous Translation Activation for Large Audio-Language Models]] (82.0% similar)
- [[2025-09-22/BiRQ_ Bi-Level Self-Labeling Random Quantization for Self-Supervised Speech Recognition_20250922|BiRQ: Bi-Level Self-Labeling Random Quantization for Self-Supervised Speech Recognition]] (81.6% similar)
- [[2025-09-22/LESS_ Large Language Model Enhanced Semi-Supervised Learning for Speech Foundational Models Using in-the-wild Data_20250922|LESS: Large Language Model Enhanced Semi-Supervised Learning for Speech Foundational Models Using in-the-wild Data]] (81.4% similar)
- [[2025-09-22/Session-Level Spoken Language Assessment with a Multimodal Foundation Model via Multi-Target Learning_20250922|Session-Level Spoken Language Assessment with a Multimodal Foundation Model via Multi-Target Learning]] (81.4% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Speech Recognition|Speech Recognition]]
**ğŸ”— Specific Connectable**: [[keywords/Self-supervised Learning|Self-supervised Learning]], [[keywords/Masked Prediction Loss|Masked Prediction Loss]]
**âš¡ Unique Technical**: [[keywords/Finite Scalar Quantization|Finite Scalar Quantization]], [[keywords/Chunk-based Self-supervised Learning|Chunk-based Self-supervised Learning]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15579v1 Announce Type: new 
Abstract: Low latency speech human-machine communication is becoming increasingly necessary as speech technology advances quickly in the last decade. One of the primary factors behind the advancement of speech technology is self-supervised learning. Most self-supervised learning algorithms are designed with full utterance assumption and compromises have to made if partial utterances are presented, which are common in the streaming applications. In this work, we propose a chunk based self-supervised learning (Chunk SSL) algorithm as an unified solution for both streaming and offline speech pre-training. Chunk SSL is optimized with the masked prediction loss and an acoustic encoder is encouraged to restore indices of those masked speech frames with help from unmasked frames in the same chunk and preceding chunks. A copy and append data augmentation approach is proposed to conduct efficient chunk based pre-training. Chunk SSL utilizes a finite scalar quantization (FSQ) module to discretize input speech features and our study shows a high resolution FSQ codebook, i.e., a codebook with vocabulary size up to a few millions, is beneficial to transfer knowledge from the pre-training task to the downstream tasks. A group masked prediction loss is employed during pre-training to alleviate the high memory and computation cost introduced by the large codebook. The proposed approach is examined in two speech to text tasks, i.e., speech recognition and speech translation. Experimental results on the \textsc{Librispeech} and \textsc{Must-C} datasets show that the proposed method could achieve very competitive results for speech to text tasks at both streaming and offline modes.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15579v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: ì§€ë‚œ 10ë…„ê°„ ìŒì„± ê¸°ìˆ ì´ ë¹ ë¥´ê²Œ ë°œì „í•¨ì— ë”°ë¼ ì €ì§€ì—° ìŒì„± ì¸ê°„-ê¸°ê³„ í†µì‹ ì´ ì ì  ë” í•„ìš”í•´ì§€ê³  ìˆìŠµë‹ˆë‹¤. ìŒì„± ê¸°ìˆ  ë°œì „ì˜ ì£¼ìš” ìš”ì¸ ì¤‘ í•˜ë‚˜ëŠ” ìê°€ ì§€ë„ í•™ìŠµ(self-supervised learning)ì…ë‹ˆë‹¤. ëŒ€ë¶€ë¶„ì˜ ìê°€ ì§€ë„ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì€ ì „ì²´ ë°œí™”(utterance)ë¥¼ ê°€ì •í•˜ì—¬ ì„¤ê³„ë˜ì—ˆìœ¼ë©°, ìŠ¤íŠ¸ë¦¬ë° ì‘ìš© í”„ë¡œê·¸ë¨ì—ì„œ í”íˆ ë°œìƒí•˜ëŠ” ë¶€ë¶„ ë°œí™”ê°€ ì œì‹œë  ê²½ìš° íƒ€í˜‘ì´ í•„ìš”í•©ë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” ìŠ¤íŠ¸ë¦¬ë° ë° ì˜¤í”„ë¼ì¸ ìŒì„± ì‚¬ì „ í›ˆë ¨ ëª¨ë‘ì— ëŒ€í•œ í†µí•© ì†”ë£¨ì…˜ìœ¼ë¡œ ì²­í¬ ê¸°ë°˜ ìê°€ ì§€ë„ í•™ìŠµ(Chunk SSL) ì•Œê³ ë¦¬ì¦˜ì„ ì œì•ˆí•©ë‹ˆë‹¤. Chunk SSLì€ ë§ˆìŠ¤í¬ ì˜ˆì¸¡ ì†ì‹¤(masked prediction loss)ë¡œ ìµœì í™”ë˜ë©°, ìŒí–¥ ì¸ì½”ë”ëŠ” ë™ì¼í•œ ì²­í¬ ë° ì´ì „ ì²­í¬ì—ì„œ ë§ˆìŠ¤í¬ë˜ì§€ ì•Šì€ í”„ë ˆì„ì˜ ë„ì›€ì„ ë°›ì•„ ë§ˆìŠ¤í¬ëœ ìŒì„± í”„ë ˆì„ì˜ ì¸ë±ìŠ¤ë¥¼ ë³µì›í•˜ë„ë¡ ìœ ë„ë©ë‹ˆë‹¤. íš¨ìœ¨ì ì¸ ì²­í¬ ê¸°ë°˜ ì‚¬ì „ í›ˆë ¨ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ ë³µì‚¬ ë° ì¶”ê°€ ë°ì´í„° ì¦ê°• ë°©ë²•ì´ ì œì•ˆë©ë‹ˆë‹¤. Chunk SSLì€ ìœ í•œ ìŠ¤ì¹¼ë¼ ì–‘ìí™”(FSQ) ëª¨ë“ˆì„ í™œìš©í•˜ì—¬ ì…ë ¥ ìŒì„± íŠ¹ì§•ì„ ì´ì‚°í™”í•˜ë©°, ìš°ë¦¬ì˜ ì—°êµ¬ëŠ” ìˆ˜ë°±ë§Œ ê°œì˜ ì–´íœ˜ í¬ê¸°ë¥¼ ê°–ëŠ” ê³ í•´ìƒë„ FSQ ì½”ë“œë¶ì´ ì‚¬ì „ í›ˆë ¨ ì‘ì—…ì—ì„œ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—…ìœ¼ë¡œ ì§€ì‹ì„ ì „ì´í•˜ëŠ” ë° ìœ ìµí•˜ë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ëŒ€ê·œëª¨ ì½”ë“œë¶ì´ ë„ì…í•˜ëŠ” ë†’ì€ ë©”ëª¨ë¦¬ ë° ê³„ì‚° ë¹„ìš©ì„ ì™„í™”í•˜ê¸° ìœ„í•´ ê·¸ë£¹ ë§ˆìŠ¤í¬ ì˜ˆì¸¡ ì†ì‹¤ì´ ì‚¬ì „ í›ˆë ¨ ë™ì•ˆ ì‚¬ìš©ë©ë‹ˆë‹¤. ì œì•ˆëœ ì ‘ê·¼ë²•ì€ ìŒì„± ì¸ì‹ ë° ìŒì„± ë²ˆì—­ì´ë¼ëŠ” ë‘ ê°€ì§€ ìŒì„±-í…ìŠ¤íŠ¸ ì‘ì—…ì—ì„œ ê²€ì¦ë˜ì—ˆìŠµë‹ˆë‹¤. \textsc{Librispeech} ë° \textsc{Must-C} ë°ì´í„°ì…‹ì— ëŒ€í•œ ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì´ ìŠ¤íŠ¸ë¦¬ë° ë° ì˜¤í”„ë¼ì¸ ëª¨ë“œ ëª¨ë‘ì—ì„œ ìŒì„±-í…ìŠ¤íŠ¸ ì‘ì—…ì— ëŒ€í•´ ë§¤ìš° ê²½ìŸë ¥ ìˆëŠ” ê²°ê³¼ë¥¼ ë‹¬ì„±í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ìŠ¤íŠ¸ë¦¬ë° ë° ì˜¤í”„ë¼ì¸ ìŒì„± ì „ì²˜ë¦¬ì— ëª¨ë‘ ì ìš© ê°€ëŠ¥í•œ ì²­í¬ ê¸°ë°˜ ìê°€ ì§€ë„ í•™ìŠµ(Chunk SSL) ì•Œê³ ë¦¬ì¦˜ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ë§ˆìŠ¤í¬ ì˜ˆì¸¡ ì†ì‹¤ì„ ìµœì í™”í•˜ì—¬, ë§ˆìŠ¤í¬ëœ ìŒì„± í”„ë ˆì„ì˜ ì¸ë±ìŠ¤ë¥¼ ë³µì›í•˜ë„ë¡ ìŒí–¥ ì¸ì½”ë”ë¥¼ ìœ ë„í•©ë‹ˆë‹¤. ë˜í•œ, íš¨ìœ¨ì ì¸ ì²­í¬ ê¸°ë°˜ ì „ì²˜ë¦¬ë¥¼ ìœ„í•´ ë³µì‚¬ ë° ì²¨ë¶€ ë°ì´í„° ì¦ê°• ë°©ë²•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì…ë ¥ ìŒì„± íŠ¹ì§•ì„ ì´ì‚°í™”í•˜ê¸° ìœ„í•´ ìœ í•œ ìŠ¤ì¹¼ë¼ ì–‘ìí™”(FSQ) ëª¨ë“ˆì„ í™œìš©í•˜ë©°, ëŒ€ê·œëª¨ ì½”ë“œë¶ì„ í†µí•´ ì‚¬ì „ í•™ìŠµ íƒœìŠ¤í¬ì—ì„œ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ íƒœìŠ¤í¬ë¡œì˜ ì§€ì‹ ì „ì´ê°€ ê°€ëŠ¥í•¨ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ì œì•ˆëœ ë°©ë²•ì€ ìŒì„± ì¸ì‹ ë° ìŒì„± ë²ˆì—­ íƒœìŠ¤í¬ì—ì„œ ê²½ìŸë ¥ ìˆëŠ” ì„±ëŠ¥ì„ ë³´ì´ë©°, \textsc{Librispeech}ì™€ \textsc{Must-C} ë°ì´í„°ì…‹ ì‹¤í—˜ ê²°ê³¼ì—ì„œ ìŠ¤íŠ¸ë¦¬ë° ë° ì˜¤í”„ë¼ì¸ ëª¨ë“œ ëª¨ë‘ì—ì„œ ìš°ìˆ˜í•œ ì„±ê³¼ë¥¼ ë‚˜íƒ€ëƒˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì €ì§€ì—° ìŒì„± ì¸ê°„-ê¸°ê³„ í†µì‹ ì˜ í•„ìš”ì„±ì´ ì¦ê°€í•¨ì— ë”°ë¼, ì²­í¬ ê¸°ë°˜ ìê°€ ì§€ë„ í•™ìŠµ(Chunk SSL) ì•Œê³ ë¦¬ì¦˜ì„ ì œì•ˆí•˜ì—¬ ìŠ¤íŠ¸ë¦¬ë° ë° ì˜¤í”„ë¼ì¸ ìŒì„± ì‚¬ì „ í›ˆë ¨ì— ëŒ€í•œ í†µí•© ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.
- 2. Chunk SSLì€ ë§ˆìŠ¤í¬ ì˜ˆì¸¡ ì†ì‹¤ì„ ìµœì í™”í•˜ì—¬ ë§ˆìŠ¤í¬ëœ ìŒì„± í”„ë ˆì„ì˜ ì¸ë±ìŠ¤ë¥¼ ë³µì›í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìœ¼ë©°, ë™ì¼í•œ ì²­í¬ ë° ì´ì „ ì²­í¬ì˜ ë§ˆìŠ¤í¬ë˜ì§€ ì•Šì€ í”„ë ˆì„ì˜ ë„ì›€ì„ ë°›ìŠµë‹ˆë‹¤.
- 3. íš¨ìœ¨ì ì¸ ì²­í¬ ê¸°ë°˜ ì‚¬ì „ í›ˆë ¨ì„ ìœ„í•´ ë³µì‚¬ ë° ì¶”ê°€ ë°ì´í„° ì¦ê°• ì ‘ê·¼ë²•ì„ ì œì•ˆí•˜ì˜€ìœ¼ë©°, ê³ í•´ìƒë„ ìœ í•œ ìŠ¤ì¹¼ë¼ ì–‘ìí™”(FSQ) ëª¨ë“ˆì„ ì‚¬ìš©í•˜ì—¬ ì…ë ¥ ìŒì„± íŠ¹ì§•ì„ ì´ì‚°í™”í•©ë‹ˆë‹¤.
- 4. ëŒ€ê·œëª¨ ì½”ë“œë¶ìœ¼ë¡œ ì¸í•œ ë†’ì€ ë©”ëª¨ë¦¬ ë° ê³„ì‚° ë¹„ìš©ì„ ì¤„ì´ê¸° ìœ„í•´ ê·¸ë£¹ ë§ˆìŠ¤í¬ ì˜ˆì¸¡ ì†ì‹¤ì„ ì‚¬ì „ í›ˆë ¨ ì¤‘ì— ì‚¬ìš©í•©ë‹ˆë‹¤.
- 5. ì œì•ˆëœ ë°©ë²•ì€ Librispeech ë° Must-C ë°ì´í„°ì…‹ì—ì„œì˜ ì‹¤í—˜ ê²°ê³¼, ìŠ¤íŠ¸ë¦¬ë° ë° ì˜¤í”„ë¼ì¸ ëª¨ë“œ ëª¨ë‘ì—ì„œ ìŒì„± ì¸ì‹ ë° ìŒì„± ë²ˆì—­ ì‘ì—…ì— ëŒ€í•´ ë§¤ìš° ê²½ìŸë ¥ ìˆëŠ” ê²°ê³¼ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-23 11:31:08*