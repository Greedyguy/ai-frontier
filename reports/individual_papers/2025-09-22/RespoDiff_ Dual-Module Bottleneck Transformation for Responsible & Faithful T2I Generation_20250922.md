---
keywords:
  - Diffusion Models
  - Text-to-Image Generation
  - Responsible AI
  - Semantic Alignment
  - Score-Matching Objective
category: cs.LG
publish_date: 2025-09-22
arxiv_id: 2509.15257
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T10:46:30.580826",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Diffusion Models",
    "Text-to-Image Generation",
    "Responsible AI",
    "Semantic Alignment",
    "Score-Matching Objective"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Diffusion Models": 0.85,
    "Text-to-Image Generation": 0.8,
    "Responsible AI": 0.78,
    "Semantic Alignment": 0.77,
    "Score-Matching Objective": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Diffusion Models",
        "canonical": "Diffusion Models",
        "aliases": [
          "Diffusion Model"
        ],
        "category": "broad_technical",
        "rationale": "Diffusion models are central to the paper's methodology and are a key concept in generative models.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Text-to-Image Generation",
        "canonical": "Text-to-Image Generation",
        "aliases": [
          "T2I Generation"
        ],
        "category": "specific_connectable",
        "rationale": "This is the primary application focus of the paper, linking it to the broader field of generative AI.",
        "novelty_score": 0.55,
        "connectivity_score": 0.82,
        "specificity_score": 0.78,
        "link_intent_score": 0.8
      },
      {
        "surface": "Responsible AI",
        "canonical": "Responsible AI",
        "aliases": [
          "Fair AI",
          "Safe AI"
        ],
        "category": "evolved_concepts",
        "rationale": "The paper emphasizes responsible AI practices, which are crucial for ethical AI development.",
        "novelty_score": 0.6,
        "connectivity_score": 0.75,
        "specificity_score": 0.72,
        "link_intent_score": 0.78
      },
      {
        "surface": "Semantic Alignment",
        "canonical": "Semantic Alignment",
        "aliases": [
          "Semantic Coherence"
        ],
        "category": "unique_technical",
        "rationale": "Semantic alignment is a unique technical challenge addressed by the paper, enhancing its novelty.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      },
      {
        "surface": "Score-Matching Objective",
        "canonical": "Score-Matching Objective",
        "aliases": [
          "Score Matching"
        ],
        "category": "unique_technical",
        "rationale": "This novel objective function is a technical innovation that differentiates the proposed method.",
        "novelty_score": 0.7,
        "connectivity_score": 0.68,
        "specificity_score": 0.75,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "method",
      "approach",
      "framework",
      "process",
      "technique"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Diffusion Models",
      "resolved_canonical": "Diffusion Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Text-to-Image Generation",
      "resolved_canonical": "Text-to-Image Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.82,
        "specificity": 0.78,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Responsible AI",
      "resolved_canonical": "Responsible AI",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.75,
        "specificity": 0.72,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Semantic Alignment",
      "resolved_canonical": "Semantic Alignment",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Score-Matching Objective",
      "resolved_canonical": "Score-Matching Objective",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.68,
        "specificity": 0.75,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# RespoDiff: Dual-Module Bottleneck Transformation for Responsible & Faithful T2I Generation

**Korean Title:** ì±…ì„ ìˆê³  ì¶©ì‹¤í•œ í…ìŠ¤íŠ¸-íˆ¬-ì´ë¯¸ì§€(T2I) ìƒì„±ì— ëŒ€í•œ ì´ì¤‘ ëª¨ë“ˆ ë³‘ëª© ë³€í™˜: RespoDiff

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15257.pdf)
**Category**: cs.LG
**Published**: 2025-09-22
**ArXiv ID**: [2509.15257](https://arxiv.org/abs/2509.15257)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/MaskAttn-SDXL_ Controllable Region-Level Text-To-Image Generation_20250922|MaskAttn-SDXL: Controllable Region-Level Text-To-Image Generation]] (85.4% similar)
- [[2025-09-22/LowDiff_ Efficient Diffusion Sampling with Low-Resolution Condition_20250922|LowDiff: Efficient Diffusion Sampling with Low-Resolution Condition]] (85.3% similar)
- [[2025-09-18/Iterative Prompt Refinement for Safer Text-to-Image Generation_20250918|Iterative Prompt Refinement for Safer Text-to-Image Generation]] (85.2% similar)
- [[2025-09-19/TIDE_ Achieving Balanced Subject-Driven Image Generation via Target-Instructed Diffusion Enhancement_20250919|TIDE: Achieving Balanced Subject-Driven Image Generation via Target-Instructed Diffusion Enhancement]] (84.2% similar)
- [[2025-09-22/OSPO_ Object-centric Self-improving Preference Optimization for Text-to-Image Generation_20250922|OSPO: Object-centric Self-improving Preference Optimization for Text-to-Image Generation]] (83.7% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Diffusion Models|Diffusion Models]]
**ğŸ”— Specific Connectable**: [[keywords/Text-to-Image Generation|Text-to-Image Generation]]
**âš¡ Unique Technical**: [[keywords/Semantic Alignment|Semantic Alignment]], [[keywords/Score-Matching Objective|Score-Matching Objective]]
**ğŸš€ Evolved Concepts**: [[keywords/Responsible AI|Responsible AI]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15257v1 Announce Type: cross 
Abstract: The rapid advancement of diffusion models has enabled high-fidelity and semantically rich text-to-image generation; however, ensuring fairness and safety remains an open challenge. Existing methods typically improve fairness and safety at the expense of semantic fidelity and image quality. In this work, we propose RespoDiff, a novel framework for responsible text-to-image generation that incorporates a dual-module transformation on the intermediate bottleneck representations of diffusion models. Our approach introduces two distinct learnable modules: one focused on capturing and enforcing responsible concepts, such as fairness and safety, and the other dedicated to maintaining semantic alignment with neutral prompts. To facilitate the dual learning process, we introduce a novel score-matching objective that enables effective coordination between the modules. Our method outperforms state-of-the-art methods in responsible generation by ensuring semantic alignment while optimizing both objectives without compromising image fidelity. Our approach improves responsible and semantically coherent generation by 20% across diverse, unseen prompts. Moreover, it integrates seamlessly into large-scale models like SDXL, enhancing fairness and safety. Code will be released upon acceptance.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15257v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: í™•ì‚° ëª¨ë¸ì˜ ê¸‰ì†í•œ ë°œì „ì€ ê³ í’ˆì§ˆì˜ ì˜ë¯¸ì ìœ¼ë¡œ í’ë¶€í•œ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ìƒì„±ì´ ê°€ëŠ¥í•˜ê²Œ í–ˆì§€ë§Œ, ê³µì •ì„±ê³¼ ì•ˆì „ì„±ì„ ë³´ì¥í•˜ëŠ” ê²ƒì€ ì—¬ì „íˆ í•´ê²°ë˜ì§€ ì•Šì€ ê³¼ì œì…ë‹ˆë‹¤. ê¸°ì¡´ ë°©ë²•ë“¤ì€ ì¼ë°˜ì ìœ¼ë¡œ ì˜ë¯¸ì  ì¶©ì‹¤ë„ì™€ ì´ë¯¸ì§€ í’ˆì§ˆì„ í¬ìƒí•˜ì—¬ ê³µì •ì„±ê³¼ ì•ˆì „ì„±ì„ ê°œì„ í•©ë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” í™•ì‚° ëª¨ë¸ì˜ ì¤‘ê°„ ë³‘ëª© í‘œí˜„ì— ì´ì¤‘ ëª¨ë“ˆ ë³€í™˜ì„ í†µí•©í•œ ì±…ì„ ìˆëŠ” í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•œ ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ì¸ RespoDiffë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì ‘ê·¼ ë°©ì‹ì€ ë‘ ê°€ì§€ êµ¬ë³„ë˜ëŠ” í•™ìŠµ ê°€ëŠ¥í•œ ëª¨ë“ˆì„ ë„ì…í•©ë‹ˆë‹¤: í•˜ë‚˜ëŠ” ê³µì •ì„±ê³¼ ì•ˆì „ì„± ê°™ì€ ì±…ì„ ìˆëŠ” ê°œë…ì„ í¬ì°©í•˜ê³  ì‹œí–‰í•˜ëŠ” ë° ì¤‘ì ì„ ë‘ê³ , ë‹¤ë¥¸ í•˜ë‚˜ëŠ” ì¤‘ë¦½ì ì¸ í”„ë¡¬í”„íŠ¸ì™€ì˜ ì˜ë¯¸ì  ì •ë ¬ì„ ìœ ì§€í•˜ëŠ” ë° ì „ë…í•©ë‹ˆë‹¤. ì´ì¤‘ í•™ìŠµ ê³¼ì •ì„ ì´‰ì§„í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ëª¨ë“ˆ ê°„ì˜ íš¨ê³¼ì ì¸ ì¡°ì •ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ìƒˆë¡œìš´ ì ìˆ˜ ì¼ì¹˜ ëª©í‘œë¥¼ ë„ì…í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ë°©ë²•ì€ ì´ë¯¸ì§€ ì¶©ì‹¤ë„ë¥¼ ì†ìƒì‹œí‚¤ì§€ ì•Šê³  ë‘ ëª©í‘œë¥¼ ìµœì í™”í•˜ë©´ì„œ ì˜ë¯¸ì  ì •ë ¬ì„ ë³´ì¥í•˜ì—¬ ì±…ì„ ìˆëŠ” ìƒì„±ì—ì„œ ìµœì²¨ë‹¨ ë°©ë²•ì„ ëŠ¥ê°€í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì ‘ê·¼ ë°©ì‹ì€ ë‹¤ì–‘í•œ, ë³´ì§€ ëª»í•œ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•´ ì±…ì„ ìˆê³  ì˜ë¯¸ì ìœ¼ë¡œ ì¼ê´€ëœ ìƒì„±ì„ 20% ê°œì„ í•©ë‹ˆë‹¤. ê²Œë‹¤ê°€, SDXLê³¼ ê°™ì€ ëŒ€ê·œëª¨ ëª¨ë¸ì— ì›í™œí•˜ê²Œ í†µí•©ë˜ì–´ ê³µì •ì„±ê³¼ ì•ˆì „ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì½”ë“œëŠ” ìŠ¹ì¸ ì‹œ ê³µê°œë  ì˜ˆì •ì…ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì—ì„œëŠ” ê³µì •ì„±ê³¼ ì•ˆì „ì„±ì„ ë³´ì¥í•˜ë©´ì„œë„ ë†’ì€ ì´ë¯¸ì§€ í’ˆì§ˆê³¼ ì˜ë¯¸ì  ì¶©ì‹¤ë„ë¥¼ ìœ ì§€í•˜ëŠ” í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ìƒì„± ë°©ë²•ë¡ ì¸ RespoDiffë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. RespoDiffëŠ” í™•ì‚° ëª¨ë¸ì˜ ì¤‘ê°„ í‘œí˜„ì— ì´ì¤‘ ëª¨ë“ˆ ë³€í™˜ì„ ì ìš©í•˜ì—¬, í•˜ë‚˜ì˜ ëª¨ë“ˆì€ ê³µì •ì„±ê³¼ ì•ˆì „ì„± ê°™ì€ ì±…ì„ ìˆëŠ” ê°œë…ì„ í¬ì°©í•˜ê³  ê°•í™”í•˜ë©°, ë‹¤ë¥¸ ëª¨ë“ˆì€ ì¤‘ë¦½ì ì¸ í”„ë¡¬í”„íŠ¸ì™€ì˜ ì˜ë¯¸ì  ì •ë ¬ì„ ìœ ì§€í•©ë‹ˆë‹¤. ì´ì¤‘ í•™ìŠµì„ ì´‰ì§„í•˜ê¸° ìœ„í•´ ìƒˆë¡œìš´ ìŠ¤ì½”ì–´ ë§¤ì¹­ ëª©í‘œë¥¼ ë„ì…í•˜ì—¬ ëª¨ë“ˆ ê°„ì˜ íš¨ê³¼ì ì¸ ì¡°ì •ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. RespoDiffëŠ” ì´ë¯¸ì§€ ì¶©ì‹¤ë„ë¥¼ ì €í•˜ì‹œí‚¤ì§€ ì•Šìœ¼ë©´ì„œë„ ì˜ë¯¸ì  ì •ë ¬ì„ ë³´ì¥í•˜ì—¬, ë‹¤ì–‘í•œ ë¯¸ì§€ì˜ í”„ë¡¬í”„íŠ¸ì—ì„œ ì±…ì„ ìˆëŠ” ìƒì„± ëŠ¥ë ¥ì„ 20% í–¥ìƒì‹œí‚µë‹ˆë‹¤. ë˜í•œ, ëŒ€ê·œëª¨ ëª¨ë¸ì— ì›í™œí•˜ê²Œ í†µí•©ë˜ì–´ ê³µì •ì„±ê³¼ ì•ˆì „ì„±ì„ ê°•í™”í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. RespoDiffëŠ” í™•ì‚° ëª¨ë¸ì˜ ì¤‘ê°„ ë³‘ëª© í‘œí˜„ì— ì´ì¤‘ ëª¨ë“ˆ ë³€í™˜ì„ ì ìš©í•˜ì—¬ ì±…ì„ ìˆëŠ” í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ìƒì„±ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
- 2. ë‘ ê°œì˜ í•™ìŠµ ê°€ëŠ¥í•œ ëª¨ë“ˆì„ ë„ì…í•˜ì—¬ í•˜ë‚˜ëŠ” ê³µì •ì„±ê³¼ ì•ˆì „ì„± ê°™ì€ ì±…ì„ ìˆëŠ” ê°œë…ì„ í¬ì°©í•˜ê³  ê°•í™”í•˜ë©°, ë‹¤ë¥¸ í•˜ë‚˜ëŠ” ì¤‘ë¦½ì ì¸ í”„ë¡¬í”„íŠ¸ì™€ì˜ ì˜ë¯¸ì  ì •ë ¬ì„ ìœ ì§€í•©ë‹ˆë‹¤.
- 3. ìƒˆë¡œìš´ ìŠ¤ì½”ì–´ ë§¤ì¹­ ëª©í‘œë¥¼ ë„ì…í•˜ì—¬ ë‘ ëª¨ë“ˆ ê°„ì˜ íš¨ê³¼ì ì¸ ì¡°ì •ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
- 4. ì œì•ˆëœ ë°©ë²•ì€ ì´ë¯¸ì§€ ì¶©ì‹¤ë„ë¥¼ ì†ìƒì‹œí‚¤ì§€ ì•Šìœ¼ë©´ì„œ ì˜ë¯¸ì  ì •ë ¬ê³¼ ì±…ì„ ìˆëŠ” ìƒì„±ì„ ë™ì‹œì— ìµœì í™”í•˜ì—¬ ìµœì²¨ë‹¨ ë°©ë²•ë³´ë‹¤ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.
- 5. RespoDiffëŠ” ëŒ€ê·œëª¨ ëª¨ë¸ì— ì›í™œí•˜ê²Œ í†µí•©ë˜ì–´ ê³µì •ì„±ê³¼ ì•ˆì „ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.


---

*Generated on 2025-09-23 10:46:30*