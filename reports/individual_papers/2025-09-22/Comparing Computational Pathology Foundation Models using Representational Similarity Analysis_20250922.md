# Comparing Computational Pathology Foundation Models using Representational Similarity Analysis

**Korean Title:** ì»´í“¨íŒ… ë³‘ë¦¬í•™ ê¸°ì´ˆ ëª¨ë¸ì„ í‘œí˜„ ìœ ì‚¬ì„± ë¶„ì„ì„ í†µí•´ ë¹„êµí•˜ê¸°

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Vision Language Contrastive Learning

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Ensemble of Pathology Foundation Models for MIDOG 2025 Track 2_ Atypical Mitosis Classification_20250919|Ensemble of Pathology Foundation Models for MIDOG 2025 Track 2 Atypical Mitosis Classification]] (82.7% similar)
- [[2025-09-17/Consistent View Alignment Improves Foundation Models for 3D Medical Image Segmentation_20250917|Consistent View Alignment Improves Foundation Models for 3D Medical Image Segmentation]] (79.3% similar)
- [[2025-09-22/Self-supervised learning of imaging and clinical signatures using a multimodal joint-embedding predictive architecture_20250922|Self-supervised learning of imaging and clinical signatures using a multimodal joint-embedding predictive architecture]] (78.1% similar)
- [[2025-09-17/PhenoGnet_ A Graph-Based Contrastive Learning Framework for Disease Similarity Prediction_20250917|PhenoGnet A Graph-Based Contrastive Learning Framework for Disease Similarity Prediction]] (78.0% similar)
- [[2025-09-18/Generative AI for Misalignment-Resistant Virtual Staining to Accelerate Histopathology Workflows_20250918|Generative AI for Misalignment-Resistant Virtual Staining to Accelerate Histopathology Workflows]] (77.6% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15482v1 Announce Type: cross 
Abstract: Foundation models are increasingly developed in computational pathology (CPath) given their promise in facilitating many downstream tasks. While recent studies have evaluated task performance across models, less is known about the structure and variability of their learned representations. Here, we systematically analyze the representational spaces of six CPath foundation models using techniques popularized in computational neuroscience. The models analyzed span vision-language contrastive learning (CONCH, PLIP, KEEP) and self-distillation (UNI (v2), Virchow (v2), Prov-GigaPath) approaches. Through representational similarity analysis using H&amp;E image patches from TCGA, we find that UNI2 and Virchow2 have the most distinct representational structures, whereas Prov-Gigapath has the highest average similarity across models. Having the same training paradigm (vision-only vs. vision-language) did not guarantee higher representational similarity. The representations of all models showed a high slide-dependence, but relatively low disease-dependence. Stain normalization decreased slide-dependence for all models by a range of 5.5% (CONCH) to 20.5% (PLIP). In terms of intrinsic dimensionality, vision-language models demonstrated relatively compact representations, compared to the more distributed representations of vision-only models. These findings highlight opportunities to improve robustness to slide-specific features, inform model ensembling strategies, and provide insights into how training paradigms shape model representations. Our framework is extendable across medical imaging domains, where probing the internal representations of foundation models can help ensure effective development and deployment.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15482v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ê¸°ì´ˆ ëª¨ë¸ì€ ë§ì€ í›„ì† ì‘ì—…ì„ ì´‰ì§„í•  ìˆ˜ ìˆëŠ” ê°€ëŠ¥ì„± ë•Œë¬¸ì— ê³„ì‚° ë³‘ë¦¬í•™(CPath)ì—ì„œ ì ì  ë” ê°œë°œë˜ê³  ìˆìŠµë‹ˆë‹¤. ìµœê·¼ ì—°êµ¬ì—ì„œëŠ” ëª¨ë¸ ê°„ì˜ ì‘ì—… ì„±ëŠ¥ì„ í‰ê°€í–ˆì§€ë§Œ, í•™ìŠµëœ í‘œí˜„ì˜ êµ¬ì¡°ì™€ ë³€ë™ì„±ì— ëŒ€í•´ì„œëŠ” ì˜ ì•Œë ¤ì ¸ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ì—¬ê¸°ì—ì„œëŠ” ê³„ì‚° ì‹ ê²½ê³¼í•™ì—ì„œ ëŒ€ì¤‘í™”ëœ ê¸°ë²•ì„ ì‚¬ìš©í•˜ì—¬ 6ê°œì˜ CPath ê¸°ì´ˆ ëª¨ë¸ì˜ í‘œí˜„ ê³µê°„ì„ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤. ë¶„ì„ëœ ëª¨ë¸ì€ ë¹„ì „-ì–¸ì–´ ëŒ€ì¡° í•™ìŠµ(CONCH, PLIP, KEEP)ê³¼ ìê¸° ì¦ë¥˜(UNI (v2), Virchow (v2), Prov-GigaPath) ì ‘ê·¼ ë°©ì‹ì„ í¬í•¨í•©ë‹ˆë‹¤. TCGAì˜ H&E ì´ë¯¸ì§€ íŒ¨ì¹˜ë¥¼ ì‚¬ìš©í•œ í‘œí˜„ ìœ ì‚¬ì„± ë¶„ì„ì„ í†µí•´, UNI2ì™€ Virchow2ê°€ ê°€ì¥ ë…íŠ¹í•œ í‘œí˜„ êµ¬ì¡°ë¥¼ ê°€ì§€ê³  ìˆëŠ” ë°˜ë©´, Prov-GigapathëŠ” ëª¨ë¸ ê°„ í‰ê·  ìœ ì‚¬ì„±ì´ ê°€ì¥ ë†’ë‹¤ëŠ” ê²ƒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ë™ì¼í•œ í›ˆë ¨ íŒ¨ëŸ¬ë‹¤ì„(ë¹„ì „ ì „ìš© ëŒ€ ë¹„ì „-ì–¸ì–´)ì´ ë” ë†’ì€ í‘œí˜„ ìœ ì‚¬ì„±ì„ ë³´ì¥í•˜ì§€ëŠ” ì•Šì•˜ìŠµë‹ˆë‹¤. ëª¨ë“  ëª¨ë¸ì˜ í‘œí˜„ì€ ìŠ¬ë¼ì´ë“œ ì˜ì¡´ì„±ì´ ë†’ì•˜ì§€ë§Œ, ì§ˆë³‘ ì˜ì¡´ì„±ì€ ìƒëŒ€ì ìœ¼ë¡œ ë‚®ì•˜ìŠµë‹ˆë‹¤. ì—¼ìƒ‰ ì •ê·œí™”ëŠ” ëª¨ë“  ëª¨ë¸ì—ì„œ ìŠ¬ë¼ì´ë“œ ì˜ì¡´ì„±ì„ 5.5%(CONCH)ì—ì„œ 20.5%(PLIP)ê¹Œì§€ ê°ì†Œì‹œì¼°ìŠµë‹ˆë‹¤. ë‚´ì¬ì  ì°¨ì›ì„± ì¸¡ë©´ì—ì„œ, ë¹„ì „-ì–¸ì–´ ëª¨ë¸ì€ ë¹„ì „ ì „ìš© ëª¨ë¸ì˜ ë” ë¶„ì‚°ëœ í‘œí˜„ì— ë¹„í•´ ìƒëŒ€ì ìœ¼ë¡œ ì••ì¶•ëœ í‘œí˜„ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë°œê²¬ì€ ìŠ¬ë¼ì´ë“œ íŠ¹ì • íŠ¹ì§•ì— ëŒ€í•œ ê°•ê±´ì„±ì„ í–¥ìƒì‹œí‚¬ ê¸°íšŒë¥¼ ê°•ì¡°í•˜ê³ , ëª¨ë¸ ì•™ìƒë¸” ì „ëµì„ ì•ˆë‚´í•˜ë©°, í›ˆë ¨ íŒ¨ëŸ¬ë‹¤ì„ì´ ëª¨ë¸ í‘œí˜„ì„ ì–´ë–»ê²Œ í˜•ì„±í•˜ëŠ”ì§€ì— ëŒ€í•œ í†µì°°ë ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ í”„ë ˆì„ì›Œí¬ëŠ” ê¸°ì´ˆ ëª¨ë¸ì˜ ë‚´ë¶€ í‘œí˜„ì„ íƒìƒ‰í•˜ì—¬ íš¨ê³¼ì ì¸ ê°œë°œ ë° ë°°í¬ë¥¼ ë³´ì¥í•  ìˆ˜ ìˆëŠ” ì˜ë£Œ ì˜ìƒ ë„ë©”ì¸ ì „ë°˜ì— ê±¸ì³ í™•ì¥ ê°€ëŠ¥í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì»´í“¨íŒ… ë³‘ë¦¬í•™(CPath)ì—ì„œ ì‚¬ìš©ë˜ëŠ” ì—¬ì„¯ ê°€ì§€ ê¸°ì´ˆ ëª¨ë¸ì˜ í‘œí˜„ ê³µê°„ì„ ë¶„ì„í•©ë‹ˆë‹¤. ì—°êµ¬ëŠ” ë¹„ì „-ì–¸ì–´ ëŒ€ì¡° í•™ìŠµ(CONCH, PLIP, KEEP)ê³¼ ìê¸° ì¦ë¥˜(UNI (v2), Virchow (v2), Prov-GigaPath) ì ‘ê·¼ ë°©ì‹ì„ í¬í•¨í•©ë‹ˆë‹¤. H&E ì´ë¯¸ì§€ íŒ¨ì¹˜ë¥¼ ì‚¬ìš©í•œ í‘œí˜„ ìœ ì‚¬ì„± ë¶„ì„ ê²°ê³¼, UNI2ì™€ Virchow2ëŠ” ê°€ì¥ ë…íŠ¹í•œ í‘œí˜„ êµ¬ì¡°ë¥¼ ê°€ì§€ë©°, Prov-GigapathëŠ” ëª¨ë¸ ê°„ í‰ê·  ìœ ì‚¬ì„±ì´ ê°€ì¥ ë†’ì•˜ìŠµë‹ˆë‹¤. ë¹„ì „-ì–¸ì–´ ëª¨ë¸ì€ ë¹„êµì  ì••ì¶•ëœ í‘œí˜„ì„ ë³´ì˜€ê³ , ì—¼ìƒ‰ ì •ê·œí™”ëŠ” ëª¨ë“  ëª¨ë¸ì˜ ìŠ¬ë¼ì´ë“œ ì˜ì¡´ì„±ì„ ê°ì†Œì‹œì¼°ìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ìŠ¬ë¼ì´ë“œ íŠ¹ì„±ì— ëŒ€í•œ ê°•ì¸ì„±ì„ ê°œì„ í•˜ê³ , ëª¨ë¸ ì•™ìƒë¸” ì „ëµì„ ìˆ˜ë¦½í•˜ë©°, í›ˆë ¨ íŒ¨ëŸ¬ë‹¤ì„ì´ ëª¨ë¸ í‘œí˜„ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì´í•´í•˜ëŠ” ë° ê¸°ì—¬í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì—¬ì„¯ ê°œì˜ CPath ê¸°ì´ˆ ëª¨ë¸ì˜ í‘œí˜„ ê³µê°„ì„ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ UNI2ì™€ Virchow2ê°€ ê°€ì¥ ë…íŠ¹í•œ í‘œí˜„ êµ¬ì¡°ë¥¼ ê°€ì¡ŒìŒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.

- 2. ê°™ì€ í›ˆë ¨ íŒ¨ëŸ¬ë‹¤ì„ì„ ê³µìœ í•œë‹¤ê³  í•´ì„œ ë” ë†’ì€ í‘œí˜„ ìœ ì‚¬ì„±ì„ ë³´ì¥í•˜ì§€ëŠ” ì•Šì•˜ìŠµë‹ˆë‹¤.

- 3. ëª¨ë“  ëª¨ë¸ì˜ í‘œí˜„ì€ ìŠ¬ë¼ì´ë“œ ì˜ì¡´ì„±ì´ ë†’ì•˜ìœ¼ë‚˜, ì§ˆë³‘ ì˜ì¡´ì„±ì€ ìƒëŒ€ì ìœ¼ë¡œ ë‚®ì•˜ìŠµë‹ˆë‹¤.

- 4. ì—¼ìƒ‰ ì •ê·œí™”ëŠ” ëª¨ë“  ëª¨ë¸ì—ì„œ ìŠ¬ë¼ì´ë“œ ì˜ì¡´ì„±ì„ 5.5%ì—ì„œ 20.5%ê¹Œì§€ ê°ì†Œì‹œì¼°ìŠµë‹ˆë‹¤.

- 5. ë¹„ì „-ì–¸ì–´ ëª¨ë¸ì€ ë¹„ì „ ì „ìš© ëª¨ë¸ì— ë¹„í•´ ìƒëŒ€ì ìœ¼ë¡œ ì••ì¶•ëœ í‘œí˜„ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤.

---

*Generated on 2025-09-22 13:58:58*