---
keywords:
  - Large Language Model
  - Vision-Language Model
  - Mother-Child Framework
  - Advertisement Compliance
category: cs.CL
publish_date: 2025-09-22
arxiv_id: 2509.15241
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:38:14.700938",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Vision-Language Model",
    "Mother-Child Framework",
    "Advertisement Compliance"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Vision-Language Model": 0.82,
    "Mother-Child Framework": 0.78,
    "Advertisement Compliance": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multimodal Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "MLLMs"
        ],
        "category": "broad_technical",
        "rationale": "Links to the broader concept of language models that integrate multiple modalities, enhancing connectivity across multimodal research.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Vision-Language Inputs",
        "canonical": "Vision-Language Model",
        "aliases": [
          "Vision-Language"
        ],
        "category": "evolved_concepts",
        "rationale": "Represents a critical intersection of vision and language processing, facilitating connections in multimodal research.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.72,
        "link_intent_score": 0.82
      },
      {
        "surface": "Mother-Child Framework",
        "canonical": "Mother-Child Framework",
        "aliases": [
          "Mother-Child MLLM"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel hierarchical model setup that could inspire new research directions and frameworks.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Advertisement Compliance",
        "canonical": "Advertisement Compliance",
        "aliases": [
          "Ad Compliance"
        ],
        "category": "specific_connectable",
        "rationale": "A specific application area that can connect with legal and ethical compliance research in AI.",
        "novelty_score": 0.6,
        "connectivity_score": 0.7,
        "specificity_score": 0.78,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "compliance standards",
      "operational overhead",
      "dynamic guidelines"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multimodal Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Vision-Language Inputs",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.72,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Mother-Child Framework",
      "resolved_canonical": "Mother-Child Framework",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Advertisement Compliance",
      "resolved_canonical": "Advertisement Compliance",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.7,
        "specificity": 0.78,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# M-PACE: Mother Child Framework for Multimodal Compliance

**Korean Title:** M-PACE: 다중 모달 준수를 위한 모자(母子) 프레임워크

## 📋 메타데이터

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15241.pdf)
**Category**: cs.CL
**Published**: 2025-09-22
**ArXiv ID**: [2509.15241](https://arxiv.org/abs/2509.15241)

## 🔗 유사한 논문
- [[2025-09-19/Internalizing Self-Consistency in Language Models_ Multi-Agent Consensus Alignment_20250919|Internalizing Self-Consistency in Language Models: Multi-Agent Consensus Alignment]] (83.5% similar)
- [[2025-09-19/A Multi-To-One Interview Paradigm for Efficient MLLM Evaluation_20250919|A Multi-To-One Interview Paradigm for Efficient MLLM Evaluation]] (83.1% similar)
- [[2025-09-22/Towards Robust Visual Continual Learning with Multi-Prototype Supervision_20250922|Towards Robust Visual Continual Learning with Multi-Prototype Supervision]] (82.7% similar)
- [[2025-09-18/LLM-I_ LLMs are Naturally Interleaved Multimodal Creators_20250918|LLM-I: LLMs are Naturally Interleaved Multimodal Creators]] (82.7% similar)
- [[2025-09-19/SMARTER_ A Data-efficient Framework to Improve Toxicity Detection with Explanation via Self-augmenting Large Language Models_20250919|SMARTER: A Data-efficient Framework to Improve Toxicity Detection with Explanation via Self-augmenting Large Language Models]] (82.4% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Advertisement Compliance|Advertisement Compliance]]
**⚡ Unique Technical**: [[keywords/Mother-Child Framework|Mother-Child Framework]]
**🚀 Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.15241v1 Announce Type: cross 
Abstract: Ensuring that multi-modal content adheres to brand, legal, or platform-specific compliance standards is an increasingly complex challenge across domains. Traditional compliance frameworks typically rely on disjointed, multi-stage pipelines that integrate separate modules for image classification, text extraction, audio transcription, hand-crafted checks, and rule-based merges. This architectural fragmentation increases operational overhead, hampers scalability, and hinders the ability to adapt to dynamic guidelines efficiently. With the emergence of Multimodal Large Language Models (MLLMs), there is growing potential to unify these workflows under a single, general-purpose framework capable of jointly processing visual and textual content. In light of this, we propose Multimodal Parameter Agnostic Compliance Engine (M-PACE), a framework designed for assessing attributes across vision-language inputs in a single pass. As a representative use case, we apply M-PACE to advertisement compliance, demonstrating its ability to evaluate over 15 compliance-related attributes. To support structured evaluation, we introduce a human-annotated benchmark enriched with augmented samples that simulate challenging real-world conditions, including visual obstructions and profanity injection. M-PACE employs a mother-child MLLM setup, demonstrating that a stronger parent MLLM evaluating the outputs of smaller child models can significantly reduce dependence on human reviewers, thereby automating quality control. Our analysis reveals that inference costs reduce by over 31 times, with the most efficient models (Gemini 2.0 Flash as child MLLM selected by mother MLLM) operating at 0.0005 per image, compared to 0.0159 for Gemini 2.5 Pro with comparable accuracy, highlighting the trade-off between cost and output quality achieved in real time by M-PACE in real life deployment over advertising data.

## 🔍 Abstract (한글 번역)

arXiv:2509.15241v1 발표 유형: 교차  
초록: 다중 모드 콘텐츠가 브랜드, 법률, 또는 플랫폼별 준수 기준을 충족하는지 보장하는 것은 여러 분야에서 점점 더 복잡한 과제가 되고 있습니다. 전통적인 준수 프레임워크는 일반적으로 이미지 분류, 텍스트 추출, 오디오 전사, 수작업 검사, 규칙 기반 병합을 위한 별도의 모듈을 통합하는 분리된 다단계 파이프라인에 의존합니다. 이러한 아키텍처의 분열은 운영 비용을 증가시키고, 확장성을 저해하며, 동적인 지침에 효율적으로 적응하는 능력을 방해합니다. 다중 모드 대형 언어 모델(Multimodal Large Language Models, MLLMs)의 출현으로, 시각적 및 텍스트 콘텐츠를 공동으로 처리할 수 있는 단일 범용 프레임워크 하에 이러한 워크플로를 통합할 수 있는 잠재력이 커지고 있습니다. 이에 따라 우리는 시각-언어 입력의 속성을 단일 패스로 평가하기 위해 설계된 프레임워크인 다중 모드 매개변수 비인식 준수 엔진(Multimodal Parameter Agnostic Compliance Engine, M-PACE)을 제안합니다. 대표적인 사용 사례로서, 우리는 M-PACE를 광고 준수에 적용하여 15개 이상의 준수 관련 속성을 평가할 수 있는 능력을 입증합니다. 구조화된 평가를 지원하기 위해, 시각적 장애물 및 욕설 삽입을 포함한 도전적인 실제 조건을 시뮬레이션하는 증강 샘플로 풍부해진 인간 주석 벤치마크를 도입합니다. M-PACE는 모자 관계의 MLLM 설정을 사용하여, 더 강력한 부모 MLLM이 더 작은 자식 모델의 출력을 평가함으로써 인간 검토자에 대한 의존도를 크게 줄이고 품질 관리를 자동화할 수 있음을 보여줍니다. 우리의 분석에 따르면, 추론 비용이 31배 이상 감소하며, 가장 효율적인 모델(모자 MLLM에 의해 선택된 Gemini 2.0 Flash가 자식 MLLM으로 작동)이 이미지당 0.0005로 운영되는 반면, 유사한 정확도를 가진 Gemini 2.5 Pro는 0.0159로 운영되어, 광고 데이터에 대한 실제 배포에서 M-PACE가 실시간으로 달성한 비용과 출력 품질 간의 균형을 강조합니다.

## 📝 요약

이 논문은 브랜드, 법적, 플랫폼별 준수 기준을 충족하기 위한 멀티모달 콘텐츠의 복잡한 문제를 해결하기 위해 제안된 M-PACE라는 프레임워크를 소개합니다. 기존의 분리된 모듈 기반의 준수 프레임워크와 달리, M-PACE는 시각 및 언어 입력을 단일 프로세스로 평가할 수 있는 통합된 접근 방식을 제공합니다. 광고 준수를 사례로 하여 15개 이상의 준수 관련 속성을 평가하며, 인간 주석 데이터셋을 통해 구조적 평가를 지원합니다. M-PACE는 모자 관계의 멀티모달 대형 언어 모델(MLLM)을 활용하여 인간 검토자의 의존도를 줄이고 품질 관리를 자동화합니다. 분석 결과, 추론 비용이 31배 이상 감소하며, Gemini 2.0 Flash 모델을 사용할 경우 이미지당 비용이 0.0005로 감소하여 비용과 품질의 균형을 실시간으로 달성함을 보여줍니다.

## 🎯 주요 포인트

- 1. 전통적인 준수 프레임워크는 이미지 분류, 텍스트 추출, 오디오 전사 등 여러 모듈을 통합하는 단절된 다단계 파이프라인에 의존하여 운영 비용을 증가시키고 확장성을 저해합니다.
- 2. 다중 모달 대형 언어 모델(MLLM)의 등장은 시각 및 텍스트 콘텐츠를 통합적으로 처리할 수 있는 단일 프레임워크의 가능성을 열어줍니다.
- 3. M-PACE는 광고 준수 평가에 적용되어 15개 이상의 준수 관련 속성을 평가할 수 있으며, 시각적 장애물 및 비속어 삽입 등 실제 조건을 시뮬레이션한 샘플로 구성된 벤치마크를 제공합니다.
- 4. M-PACE는 모자 관계의 MLLM 설정을 사용하여, 강력한 모형이 작은 자식 모델의 출력을 평가함으로써 인간 검토자에 대한 의존도를 크게 줄이고 품질 관리를 자동화합니다.
- 5. M-PACE는 광고 데이터의 실제 배포에서 비용과 출력 품질 간의 실시간 절충을 통해 추론 비용을 31배 이상 줄이며, 가장 효율적인 모델은 이미지당 0.0005의 비용으로 운영됩니다.


---

*Generated on 2025-09-23 11:38:14*