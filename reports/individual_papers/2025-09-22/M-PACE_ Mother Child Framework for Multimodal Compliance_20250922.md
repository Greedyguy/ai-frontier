---
keywords:
  - Large Language Model
  - Vision-Language Model
  - Mother-Child Framework
  - Advertisement Compliance
category: cs.CL
publish_date: 2025-09-22
arxiv_id: 2509.15241
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:38:14.700938",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Vision-Language Model",
    "Mother-Child Framework",
    "Advertisement Compliance"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Vision-Language Model": 0.82,
    "Mother-Child Framework": 0.78,
    "Advertisement Compliance": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multimodal Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "MLLMs"
        ],
        "category": "broad_technical",
        "rationale": "Links to the broader concept of language models that integrate multiple modalities, enhancing connectivity across multimodal research.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Vision-Language Inputs",
        "canonical": "Vision-Language Model",
        "aliases": [
          "Vision-Language"
        ],
        "category": "evolved_concepts",
        "rationale": "Represents a critical intersection of vision and language processing, facilitating connections in multimodal research.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.72,
        "link_intent_score": 0.82
      },
      {
        "surface": "Mother-Child Framework",
        "canonical": "Mother-Child Framework",
        "aliases": [
          "Mother-Child MLLM"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel hierarchical model setup that could inspire new research directions and frameworks.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Advertisement Compliance",
        "canonical": "Advertisement Compliance",
        "aliases": [
          "Ad Compliance"
        ],
        "category": "specific_connectable",
        "rationale": "A specific application area that can connect with legal and ethical compliance research in AI.",
        "novelty_score": 0.6,
        "connectivity_score": 0.7,
        "specificity_score": 0.78,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "compliance standards",
      "operational overhead",
      "dynamic guidelines"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multimodal Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Vision-Language Inputs",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.72,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Mother-Child Framework",
      "resolved_canonical": "Mother-Child Framework",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Advertisement Compliance",
      "resolved_canonical": "Advertisement Compliance",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.7,
        "specificity": 0.78,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# M-PACE: Mother Child Framework for Multimodal Compliance

**Korean Title:** M-PACE: ë‹¤ì¤‘ ëª¨ë‹¬ ì¤€ìˆ˜ë¥¼ ìœ„í•œ ëª¨ì(æ¯å­) í”„ë ˆì„ì›Œí¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15241.pdf)
**Category**: cs.CL
**Published**: 2025-09-22
**ArXiv ID**: [2509.15241](https://arxiv.org/abs/2509.15241)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Internalizing Self-Consistency in Language Models_ Multi-Agent Consensus Alignment_20250919|Internalizing Self-Consistency in Language Models: Multi-Agent Consensus Alignment]] (83.5% similar)
- [[2025-09-19/A Multi-To-One Interview Paradigm for Efficient MLLM Evaluation_20250919|A Multi-To-One Interview Paradigm for Efficient MLLM Evaluation]] (83.1% similar)
- [[2025-09-22/Towards Robust Visual Continual Learning with Multi-Prototype Supervision_20250922|Towards Robust Visual Continual Learning with Multi-Prototype Supervision]] (82.7% similar)
- [[2025-09-18/LLM-I_ LLMs are Naturally Interleaved Multimodal Creators_20250918|LLM-I: LLMs are Naturally Interleaved Multimodal Creators]] (82.7% similar)
- [[2025-09-19/SMARTER_ A Data-efficient Framework to Improve Toxicity Detection with Explanation via Self-augmenting Large Language Models_20250919|SMARTER: A Data-efficient Framework to Improve Toxicity Detection with Explanation via Self-augmenting Large Language Models]] (82.4% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Advertisement Compliance|Advertisement Compliance]]
**âš¡ Unique Technical**: [[keywords/Mother-Child Framework|Mother-Child Framework]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15241v1 Announce Type: cross 
Abstract: Ensuring that multi-modal content adheres to brand, legal, or platform-specific compliance standards is an increasingly complex challenge across domains. Traditional compliance frameworks typically rely on disjointed, multi-stage pipelines that integrate separate modules for image classification, text extraction, audio transcription, hand-crafted checks, and rule-based merges. This architectural fragmentation increases operational overhead, hampers scalability, and hinders the ability to adapt to dynamic guidelines efficiently. With the emergence of Multimodal Large Language Models (MLLMs), there is growing potential to unify these workflows under a single, general-purpose framework capable of jointly processing visual and textual content. In light of this, we propose Multimodal Parameter Agnostic Compliance Engine (M-PACE), a framework designed for assessing attributes across vision-language inputs in a single pass. As a representative use case, we apply M-PACE to advertisement compliance, demonstrating its ability to evaluate over 15 compliance-related attributes. To support structured evaluation, we introduce a human-annotated benchmark enriched with augmented samples that simulate challenging real-world conditions, including visual obstructions and profanity injection. M-PACE employs a mother-child MLLM setup, demonstrating that a stronger parent MLLM evaluating the outputs of smaller child models can significantly reduce dependence on human reviewers, thereby automating quality control. Our analysis reveals that inference costs reduce by over 31 times, with the most efficient models (Gemini 2.0 Flash as child MLLM selected by mother MLLM) operating at 0.0005 per image, compared to 0.0159 for Gemini 2.5 Pro with comparable accuracy, highlighting the trade-off between cost and output quality achieved in real time by M-PACE in real life deployment over advertising data.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15241v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ë‹¤ì¤‘ ëª¨ë“œ ì½˜í…ì¸ ê°€ ë¸Œëœë“œ, ë²•ë¥ , ë˜ëŠ” í”Œë«í¼ë³„ ì¤€ìˆ˜ ê¸°ì¤€ì„ ì¶©ì¡±í•˜ëŠ”ì§€ ë³´ì¥í•˜ëŠ” ê²ƒì€ ì—¬ëŸ¬ ë¶„ì•¼ì—ì„œ ì ì  ë” ë³µì¡í•œ ê³¼ì œê°€ ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì „í†µì ì¸ ì¤€ìˆ˜ í”„ë ˆì„ì›Œí¬ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì´ë¯¸ì§€ ë¶„ë¥˜, í…ìŠ¤íŠ¸ ì¶”ì¶œ, ì˜¤ë””ì˜¤ ì „ì‚¬, ìˆ˜ì‘ì—… ê²€ì‚¬, ê·œì¹™ ê¸°ë°˜ ë³‘í•©ì„ ìœ„í•œ ë³„ë„ì˜ ëª¨ë“ˆì„ í†µí•©í•˜ëŠ” ë¶„ë¦¬ëœ ë‹¤ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ì— ì˜ì¡´í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì•„í‚¤í…ì²˜ì˜ ë¶„ì—´ì€ ìš´ì˜ ë¹„ìš©ì„ ì¦ê°€ì‹œí‚¤ê³ , í™•ì¥ì„±ì„ ì €í•´í•˜ë©°, ë™ì ì¸ ì§€ì¹¨ì— íš¨ìœ¨ì ìœ¼ë¡œ ì ì‘í•˜ëŠ” ëŠ¥ë ¥ì„ ë°©í•´í•©ë‹ˆë‹¤. ë‹¤ì¤‘ ëª¨ë“œ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(Multimodal Large Language Models, MLLMs)ì˜ ì¶œí˜„ìœ¼ë¡œ, ì‹œê°ì  ë° í…ìŠ¤íŠ¸ ì½˜í…ì¸ ë¥¼ ê³µë™ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ë‹¨ì¼ ë²”ìš© í”„ë ˆì„ì›Œí¬ í•˜ì— ì´ëŸ¬í•œ ì›Œí¬í”Œë¡œë¥¼ í†µí•©í•  ìˆ˜ ìˆëŠ” ì ì¬ë ¥ì´ ì»¤ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì´ì— ë”°ë¼ ìš°ë¦¬ëŠ” ì‹œê°-ì–¸ì–´ ì…ë ¥ì˜ ì†ì„±ì„ ë‹¨ì¼ íŒ¨ìŠ¤ë¡œ í‰ê°€í•˜ê¸° ìœ„í•´ ì„¤ê³„ëœ í”„ë ˆì„ì›Œí¬ì¸ ë‹¤ì¤‘ ëª¨ë“œ ë§¤ê°œë³€ìˆ˜ ë¹„ì¸ì‹ ì¤€ìˆ˜ ì—”ì§„(Multimodal Parameter Agnostic Compliance Engine, M-PACE)ì„ ì œì•ˆí•©ë‹ˆë‹¤. ëŒ€í‘œì ì¸ ì‚¬ìš© ì‚¬ë¡€ë¡œì„œ, ìš°ë¦¬ëŠ” M-PACEë¥¼ ê´‘ê³  ì¤€ìˆ˜ì— ì ìš©í•˜ì—¬ 15ê°œ ì´ìƒì˜ ì¤€ìˆ˜ ê´€ë ¨ ì†ì„±ì„ í‰ê°€í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ì…ì¦í•©ë‹ˆë‹¤. êµ¬ì¡°í™”ëœ í‰ê°€ë¥¼ ì§€ì›í•˜ê¸° ìœ„í•´, ì‹œê°ì  ì¥ì• ë¬¼ ë° ìš•ì„¤ ì‚½ì…ì„ í¬í•¨í•œ ë„ì „ì ì¸ ì‹¤ì œ ì¡°ê±´ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ëŠ” ì¦ê°• ìƒ˜í”Œë¡œ í’ë¶€í•´ì§„ ì¸ê°„ ì£¼ì„ ë²¤ì¹˜ë§ˆí¬ë¥¼ ë„ì…í•©ë‹ˆë‹¤. M-PACEëŠ” ëª¨ì ê´€ê³„ì˜ MLLM ì„¤ì •ì„ ì‚¬ìš©í•˜ì—¬, ë” ê°•ë ¥í•œ ë¶€ëª¨ MLLMì´ ë” ì‘ì€ ìì‹ ëª¨ë¸ì˜ ì¶œë ¥ì„ í‰ê°€í•¨ìœ¼ë¡œì¨ ì¸ê°„ ê²€í† ìì— ëŒ€í•œ ì˜ì¡´ë„ë¥¼ í¬ê²Œ ì¤„ì´ê³  í’ˆì§ˆ ê´€ë¦¬ë¥¼ ìë™í™”í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ìš°ë¦¬ì˜ ë¶„ì„ì— ë”°ë¥´ë©´, ì¶”ë¡  ë¹„ìš©ì´ 31ë°° ì´ìƒ ê°ì†Œí•˜ë©°, ê°€ì¥ íš¨ìœ¨ì ì¸ ëª¨ë¸(ëª¨ì MLLMì— ì˜í•´ ì„ íƒëœ Gemini 2.0 Flashê°€ ìì‹ MLLMìœ¼ë¡œ ì‘ë™)ì´ ì´ë¯¸ì§€ë‹¹ 0.0005ë¡œ ìš´ì˜ë˜ëŠ” ë°˜ë©´, ìœ ì‚¬í•œ ì •í™•ë„ë¥¼ ê°€ì§„ Gemini 2.5 ProëŠ” 0.0159ë¡œ ìš´ì˜ë˜ì–´, ê´‘ê³  ë°ì´í„°ì— ëŒ€í•œ ì‹¤ì œ ë°°í¬ì—ì„œ M-PACEê°€ ì‹¤ì‹œê°„ìœ¼ë¡œ ë‹¬ì„±í•œ ë¹„ìš©ê³¼ ì¶œë ¥ í’ˆì§ˆ ê°„ì˜ ê· í˜•ì„ ê°•ì¡°í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë¸Œëœë“œ, ë²•ì , í”Œë«í¼ë³„ ì¤€ìˆ˜ ê¸°ì¤€ì„ ì¶©ì¡±í•˜ê¸° ìœ„í•œ ë©€í‹°ëª¨ë‹¬ ì½˜í…ì¸ ì˜ ë³µì¡í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì œì•ˆëœ M-PACEë¼ëŠ” í”„ë ˆì„ì›Œí¬ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë¶„ë¦¬ëœ ëª¨ë“ˆ ê¸°ë°˜ì˜ ì¤€ìˆ˜ í”„ë ˆì„ì›Œí¬ì™€ ë‹¬ë¦¬, M-PACEëŠ” ì‹œê° ë° ì–¸ì–´ ì…ë ¥ì„ ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ë¡œ í‰ê°€í•  ìˆ˜ ìˆëŠ” í†µí•©ëœ ì ‘ê·¼ ë°©ì‹ì„ ì œê³µí•©ë‹ˆë‹¤. ê´‘ê³  ì¤€ìˆ˜ë¥¼ ì‚¬ë¡€ë¡œ í•˜ì—¬ 15ê°œ ì´ìƒì˜ ì¤€ìˆ˜ ê´€ë ¨ ì†ì„±ì„ í‰ê°€í•˜ë©°, ì¸ê°„ ì£¼ì„ ë°ì´í„°ì…‹ì„ í†µí•´ êµ¬ì¡°ì  í‰ê°€ë¥¼ ì§€ì›í•©ë‹ˆë‹¤. M-PACEëŠ” ëª¨ì ê´€ê³„ì˜ ë©€í‹°ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(MLLM)ì„ í™œìš©í•˜ì—¬ ì¸ê°„ ê²€í† ìì˜ ì˜ì¡´ë„ë¥¼ ì¤„ì´ê³  í’ˆì§ˆ ê´€ë¦¬ë¥¼ ìë™í™”í•©ë‹ˆë‹¤. ë¶„ì„ ê²°ê³¼, ì¶”ë¡  ë¹„ìš©ì´ 31ë°° ì´ìƒ ê°ì†Œí•˜ë©°, Gemini 2.0 Flash ëª¨ë¸ì„ ì‚¬ìš©í•  ê²½ìš° ì´ë¯¸ì§€ë‹¹ ë¹„ìš©ì´ 0.0005ë¡œ ê°ì†Œí•˜ì—¬ ë¹„ìš©ê³¼ í’ˆì§ˆì˜ ê· í˜•ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ë‹¬ì„±í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì „í†µì ì¸ ì¤€ìˆ˜ í”„ë ˆì„ì›Œí¬ëŠ” ì´ë¯¸ì§€ ë¶„ë¥˜, í…ìŠ¤íŠ¸ ì¶”ì¶œ, ì˜¤ë””ì˜¤ ì „ì‚¬ ë“± ì—¬ëŸ¬ ëª¨ë“ˆì„ í†µí•©í•˜ëŠ” ë‹¨ì ˆëœ ë‹¤ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ì— ì˜ì¡´í•˜ì—¬ ìš´ì˜ ë¹„ìš©ì„ ì¦ê°€ì‹œí‚¤ê³  í™•ì¥ì„±ì„ ì €í•´í•©ë‹ˆë‹¤.
- 2. ë‹¤ì¤‘ ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(MLLM)ì˜ ë“±ì¥ì€ ì‹œê° ë° í…ìŠ¤íŠ¸ ì½˜í…ì¸ ë¥¼ í†µí•©ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ë‹¨ì¼ í”„ë ˆì„ì›Œí¬ì˜ ê°€ëŠ¥ì„±ì„ ì—´ì–´ì¤ë‹ˆë‹¤.
- 3. M-PACEëŠ” ê´‘ê³  ì¤€ìˆ˜ í‰ê°€ì— ì ìš©ë˜ì–´ 15ê°œ ì´ìƒì˜ ì¤€ìˆ˜ ê´€ë ¨ ì†ì„±ì„ í‰ê°€í•  ìˆ˜ ìˆìœ¼ë©°, ì‹œê°ì  ì¥ì• ë¬¼ ë° ë¹„ì†ì–´ ì‚½ì… ë“± ì‹¤ì œ ì¡°ê±´ì„ ì‹œë®¬ë ˆì´ì…˜í•œ ìƒ˜í”Œë¡œ êµ¬ì„±ëœ ë²¤ì¹˜ë§ˆí¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
- 4. M-PACEëŠ” ëª¨ì ê´€ê³„ì˜ MLLM ì„¤ì •ì„ ì‚¬ìš©í•˜ì—¬, ê°•ë ¥í•œ ëª¨í˜•ì´ ì‘ì€ ìì‹ ëª¨ë¸ì˜ ì¶œë ¥ì„ í‰ê°€í•¨ìœ¼ë¡œì¨ ì¸ê°„ ê²€í† ìì— ëŒ€í•œ ì˜ì¡´ë„ë¥¼ í¬ê²Œ ì¤„ì´ê³  í’ˆì§ˆ ê´€ë¦¬ë¥¼ ìë™í™”í•©ë‹ˆë‹¤.
- 5. M-PACEëŠ” ê´‘ê³  ë°ì´í„°ì˜ ì‹¤ì œ ë°°í¬ì—ì„œ ë¹„ìš©ê³¼ ì¶œë ¥ í’ˆì§ˆ ê°„ì˜ ì‹¤ì‹œê°„ ì ˆì¶©ì„ í†µí•´ ì¶”ë¡  ë¹„ìš©ì„ 31ë°° ì´ìƒ ì¤„ì´ë©°, ê°€ì¥ íš¨ìœ¨ì ì¸ ëª¨ë¸ì€ ì´ë¯¸ì§€ë‹¹ 0.0005ì˜ ë¹„ìš©ìœ¼ë¡œ ìš´ì˜ë©ë‹ˆë‹¤.


---

*Generated on 2025-09-23 11:38:14*