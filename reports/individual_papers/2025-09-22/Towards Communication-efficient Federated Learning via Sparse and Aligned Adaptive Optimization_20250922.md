---
keywords:
  - Federated Learning
  - Adaptive Moment Estimation
  - Sparse Federated Adam
  - Convergence Rate
category: cs.LG
publish_date: 2025-09-22
arxiv_id: 2405.17932
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:00:32.512361",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Federated Learning",
    "Adaptive Moment Estimation",
    "Sparse Federated Adam",
    "Convergence Rate"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Federated Learning": 0.85,
    "Adaptive Moment Estimation": 0.78,
    "Sparse Federated Adam": 0.82,
    "Convergence Rate": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Federated Learning",
        "canonical": "Federated Learning",
        "aliases": [
          "FL"
        ],
        "category": "broad_technical",
        "rationale": "Federated Learning is a central theme of the paper and connects with various distributed machine learning discussions.",
        "novelty_score": 0.45,
        "connectivity_score": 0.89,
        "specificity_score": 0.68,
        "link_intent_score": 0.85
      },
      {
        "surface": "Adaptive Moment Estimation",
        "canonical": "Adaptive Moment Estimation",
        "aliases": [
          "Adam"
        ],
        "category": "unique_technical",
        "rationale": "Adaptive Moment Estimation is a key optimization technique discussed in the paper, relevant to optimization strategies in machine learning.",
        "novelty_score": 0.62,
        "connectivity_score": 0.76,
        "specificity_score": 0.82,
        "link_intent_score": 0.78
      },
      {
        "surface": "Sparse FedAdam",
        "canonical": "Sparse Federated Adam",
        "aliases": [
          "FedAdam-SSM"
        ],
        "category": "unique_technical",
        "rationale": "Sparse FedAdam is a novel algorithm introduced in the paper, enhancing federated learning efficiency.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.82
      },
      {
        "surface": "Convergence Rate",
        "canonical": "Convergence Rate",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Convergence Rate is a critical metric for evaluating the performance of optimization algorithms in federated learning.",
        "novelty_score": 0.5,
        "connectivity_score": 0.78,
        "specificity_score": 0.7,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "uplink communication",
      "local model updates",
      "test accuracy"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Federated Learning",
      "resolved_canonical": "Federated Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.89,
        "specificity": 0.68,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Adaptive Moment Estimation",
      "resolved_canonical": "Adaptive Moment Estimation",
      "decision": "linked",
      "scores": {
        "novelty": 0.62,
        "connectivity": 0.76,
        "specificity": 0.82,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Sparse FedAdam",
      "resolved_canonical": "Sparse Federated Adam",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Convergence Rate",
      "resolved_canonical": "Convergence Rate",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.78,
        "specificity": 0.7,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Towards Communication-efficient Federated Learning via Sparse and Aligned Adaptive Optimization

**Korean Title:** ì˜ì‚¬ì†Œí†µ íš¨ìœ¨ì ì¸ ì—°í•© í•™ìŠµì„ ìœ„í•œ í¬ì†Œí•˜ê³  ì •ë ¬ëœ ì ì‘ ìµœì í™” ë°©ì•ˆ

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2405.17932.pdf)
**Category**: cs.LG
**Published**: 2025-09-22
**ArXiv ID**: [2405.17932](https://arxiv.org/abs/2405.17932)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/FedAVOT_ Exact Distribution Alignment in Federated Learning via Masked Optimal Transport_20250919|FedAVOT: Exact Distribution Alignment in Federated Learning via Masked Optimal Transport]] (83.8% similar)
- [[2025-09-17/FedSSG_ Expectation-Gated and History-Aware Drift Alignment for Federated Learning_20250917|FedSSG: Expectation-Gated and History-Aware Drift Alignment for Federated Learning]] (83.5% similar)
- [[2025-09-19/Hierarchical Federated Learning for Social Network with Mobility_20250919|Hierarchical Federated Learning for Social Network with Mobility]] (82.3% similar)
- [[2025-09-22/Adaptive Algorithms with Sharp Convergence Rates for Stochastic Hierarchical Optimization_20250922|Adaptive Algorithms with Sharp Convergence Rates for Stochastic Hierarchical Optimization]] (80.2% similar)
- [[2025-09-19/Who to Trust? Aggregating Client Knowledge in Logit-Based Federated Learning_20250919|Who to Trust? Aggregating Client Knowledge in Logit-Based Federated Learning]] (80.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Federated Learning|Federated Learning]]
**ğŸ”— Specific Connectable**: [[keywords/Convergence Rate|Convergence Rate]]
**âš¡ Unique Technical**: [[keywords/Adaptive Moment Estimation|Adaptive Moment Estimation]], [[keywords/Sparse Federated Adam|Sparse Federated Adam]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2405.17932v2 Announce Type: replace 
Abstract: Adaptive moment estimation (Adam), as a Stochastic Gradient Descent (SGD) variant, has gained widespread popularity in federated learning (FL) due to its fast convergence. However, federated Adam (FedAdam) algorithms suffer from a threefold increase in uplink communication overhead compared to federated SGD (FedSGD) algorithms, which arises from the necessity to transmit both local model updates and first and second moment estimates from distributed devices to the centralized server for aggregation. Driven by this issue, we propose a novel sparse FedAdam algorithm called FedAdam-SSM, wherein distributed devices sparsify the updates of local model parameters and moment estimates and subsequently upload the sparse representations to the centralized server. To further reduce the communication overhead, the updates of local model parameters and moment estimates incorporate a shared sparse mask (SSM) into the sparsification process, eliminating the need for three separate sparse masks. Theoretically, we develop an upper bound on the divergence between the local model trained by FedAdam-SSM and the desired model trained by centralized Adam, which is related to sparsification error and imbalanced data distribution. By minimizing the divergence bound between the model trained by FedAdam-SSM and centralized Adam, we optimize the SSM to mitigate the learning performance degradation caused by sparsification error. Additionally, we provide convergence bounds for FedAdam-SSM in both convex and non-convex objective function settings, and investigate the impact of local epoch, learning rate and sparsification ratio on the convergence rate of FedAdam-SSM. Experimental results show that FedAdam-SSM outperforms baselines in terms of convergence rate (over 1.1$\times$ faster than the sparse FedAdam baselines) and test accuracy (over 14.5\% ahead of the quantized FedAdam baselines).

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2405.17932v2 ë°œí‘œ ìœ í˜•: êµì²´

ì´ˆë¡: ì ì‘ì  ëª¨ë©˜íŠ¸ ì¶”ì •(Adam)ì€ í™•ë¥ ì  ê²½ì‚¬ í•˜ê°•ë²•(SGD)ì˜ ë³€í˜•ìœ¼ë¡œ, ë¹ ë¥¸ ìˆ˜ë ´ ì†ë„ë¡œ ì¸í•´ ì—°í•© í•™ìŠµ(FL)ì—ì„œ ë„ë¦¬ ì¸ê¸°ë¥¼ ì–»ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì—°í•© Adam(FedAdam) ì•Œê³ ë¦¬ì¦˜ì€ ì—°í•© SGD(FedSGD) ì•Œê³ ë¦¬ì¦˜ì— ë¹„í•´ ì—…ë§í¬ í†µì‹  ì˜¤ë²„í—¤ë“œê°€ ì„¸ ë°° ì¦ê°€í•˜ëŠ” ë¬¸ì œë¥¼ ê²ªê³  ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ë¶„ì‚°ëœ ì¥ì¹˜ì—ì„œ ì¤‘ì•™ ì„œë²„ë¡œ ë¡œì»¬ ëª¨ë¸ ì—…ë°ì´íŠ¸ì™€ 1ì°¨ ë° 2ì°¨ ëª¨ë©˜íŠ¸ ì¶”ì •ì„ ëª¨ë‘ ì „ì†¡í•´ì•¼ í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” FedAdam-SSMì´ë¼ëŠ” ìƒˆë¡œìš´ í¬ì†Œ FedAdam ì•Œê³ ë¦¬ì¦˜ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ì•Œê³ ë¦¬ì¦˜ì—ì„œëŠ” ë¶„ì‚°ëœ ì¥ì¹˜ê°€ ë¡œì»¬ ëª¨ë¸ íŒŒë¼ë¯¸í„°ì™€ ëª¨ë©˜íŠ¸ ì¶”ì •ì˜ ì—…ë°ì´íŠ¸ë¥¼ í¬ì†Œí™”í•˜ì—¬ í¬ì†Œ í‘œí˜„ì„ ì¤‘ì•™ ì„œë²„ë¡œ ì—…ë¡œë“œí•©ë‹ˆë‹¤. í†µì‹  ì˜¤ë²„í—¤ë“œë¥¼ ë”ìš± ì¤„ì´ê¸° ìœ„í•´, ë¡œì»¬ ëª¨ë¸ íŒŒë¼ë¯¸í„°ì™€ ëª¨ë©˜íŠ¸ ì¶”ì •ì˜ ì—…ë°ì´íŠ¸ëŠ” í¬ì†Œí™” ê³¼ì •ì— ê³µìœ  í¬ì†Œ ë§ˆìŠ¤í¬(SSM)ë¥¼ í¬í•¨ì‹œì¼œ ì„¸ ê°œì˜ ë³„ë„ í¬ì†Œ ë§ˆìŠ¤í¬ê°€ í•„ìš”í•˜ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤. ì´ë¡ ì ìœ¼ë¡œ, ìš°ë¦¬ëŠ” FedAdam-SSMì— ì˜í•´ í›ˆë ¨ëœ ë¡œì»¬ ëª¨ë¸ê³¼ ì¤‘ì•™ ì§‘ì¤‘ì‹ Adamì— ì˜í•´ í›ˆë ¨ëœ ëª©í‘œ ëª¨ë¸ ê°„ì˜ ë°œì‚°ì— ëŒ€í•œ ìƒí•œì„ ê°œë°œí•˜ì˜€ìœ¼ë©°, ì´ëŠ” í¬ì†Œí™” ì˜¤ë¥˜ì™€ ë¶ˆê· í˜•í•œ ë°ì´í„° ë¶„í¬ì™€ ê´€ë ¨ì´ ìˆìŠµë‹ˆë‹¤. FedAdam-SSMì— ì˜í•´ í›ˆë ¨ëœ ëª¨ë¸ê³¼ ì¤‘ì•™ ì§‘ì¤‘ì‹ Adam ê°„ì˜ ë°œì‚° ê²½ê³„ë¥¼ ìµœì†Œí™”í•¨ìœ¼ë¡œì¨, ìš°ë¦¬ëŠ” í¬ì†Œí™” ì˜¤ë¥˜ë¡œ ì¸í•œ í•™ìŠµ ì„±ëŠ¥ ì €í•˜ë¥¼ ì™„í™”í•˜ê¸° ìœ„í•´ SSMì„ ìµœì í™”í•©ë‹ˆë‹¤. ë˜í•œ, ìš°ë¦¬ëŠ” ë³¼ë¡ ë° ë¹„ë³¼ë¡ ëª©ì  í•¨ìˆ˜ ì„¤ì •ì—ì„œ FedAdam-SSMì˜ ìˆ˜ë ´ ê²½ê³„ë¥¼ ì œê³µí•˜ê³ , ë¡œì»¬ ì—í­, í•™ìŠµë¥  ë° í¬ì†Œí™” ë¹„ìœ¨ì´ FedAdam-SSMì˜ ìˆ˜ë ´ ì†ë„ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì¡°ì‚¬í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, FedAdam-SSMì€ ìˆ˜ë ´ ì†ë„(í¬ì†Œ FedAdam ê¸°ì¤€ì„ ë³´ë‹¤ 1.1ë°° ì´ìƒ ë¹ ë¦„)ì™€ í…ŒìŠ¤íŠ¸ ì •í™•ë„(ì–‘ìí™”ëœ FedAdam ê¸°ì¤€ì„ ë³´ë‹¤ 14.5% ì´ìƒ ì•ì„¬) ì¸¡ë©´ì—ì„œ ê¸°ì¤€ì„ ì„ ëŠ¥ê°€í•˜ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì—°í•© í•™ìŠµì—ì„œì˜ ì ì‘ ëª¨ë©˜íŠ¸ ì¶”ì •(Adam) ì•Œê³ ë¦¬ì¦˜ì˜ í†µì‹  ì˜¤ë²„í—¤ë“œë¥¼ ì¤„ì´ê¸° ìœ„í•´ ìƒˆë¡œìš´ í¬ì†Œ FedAdam ì•Œê³ ë¦¬ì¦˜ì¸ FedAdam-SSMì„ ì œì•ˆí•©ë‹ˆë‹¤. FedAdam-SSMì€ ë¡œì»¬ ëª¨ë¸ ì—…ë°ì´íŠ¸ì™€ ëª¨ë©˜íŠ¸ ì¶”ì •ì¹˜ë¥¼ í¬ì†Œí™”í•˜ì—¬ ì¤‘ì•™ ì„œë²„ë¡œ ì „ì†¡í•˜ë©°, ê³µìœ  í¬ì†Œ ë§ˆìŠ¤í¬(SSM)ë¥¼ ì‚¬ìš©í•´ í†µì‹  ì˜¤ë²„í—¤ë“œë¥¼ ì¤„ì…ë‹ˆë‹¤. ì´ ë°©ë²•ë¡ ì€ í¬ì†Œí™” ì˜¤ë¥˜ì™€ ë¶ˆê· í˜• ë°ì´í„° ë¶„í¬ë¡œ ì¸í•œ ëª¨ë¸ ê°„ì˜ ë°œì‚°ì„ ì´ë¡ ì ìœ¼ë¡œ ë¶„ì„í•˜ê³ , FedAdam-SSMì˜ ìˆ˜ë ´ ê²½ê³„ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, FedAdam-SSMì€ ìˆ˜ë ´ ì†ë„ì™€ í…ŒìŠ¤íŠ¸ ì •í™•ë„ì—ì„œ ê¸°ì¡´ ë°©ë²•ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. FedAdam ì•Œê³ ë¦¬ì¦˜ì€ FedSGDì— ë¹„í•´ 3ë°°ì˜ ì—…ë§í¬ í†µì‹  ì˜¤ë²„í—¤ë“œê°€ ë°œìƒí•©ë‹ˆë‹¤.
- 2. FedAdam-SSM ì•Œê³ ë¦¬ì¦˜ì€ ë¡œì»¬ ëª¨ë¸ íŒŒë¼ë¯¸í„°ì™€ ëª¨ë©˜íŠ¸ ì¶”ì •ì¹˜ë¥¼ í¬ì†Œí™”í•˜ì—¬ í†µì‹  ì˜¤ë²„í—¤ë“œë¥¼ ì¤„ì…ë‹ˆë‹¤.
- 3. ê³µìœ  í¬ì†Œ ë§ˆìŠ¤í¬(SSM)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„¸ ê°œì˜ ë³„ë„ í¬ì†Œ ë§ˆìŠ¤í¬ í•„ìš”ì„±ì„ ì œê±°í•©ë‹ˆë‹¤.
- 4. FedAdam-SSMì˜ ìˆ˜ë ´ ê²½ê³„ëŠ” ë³¼ë¡ ë° ë¹„ë³¼ë¡ ëª©ì  í•¨ìˆ˜ ì„¤ì •ì—ì„œ ì œê³µë©ë‹ˆë‹¤.
- 5. ì‹¤í—˜ ê²°ê³¼, FedAdam-SSMì€ ìˆ˜ë ´ ì†ë„ì™€ í…ŒìŠ¤íŠ¸ ì •í™•ë„ì—ì„œ ê¸°ì¡´ ë°©ë²•ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.


---

*Generated on 2025-09-23 11:00:32*