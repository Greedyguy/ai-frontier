---
keywords:
  - Multi-Agent Reinforcement Learning
  - Vulnerable Agent Identification
  - Hierarchical Adversarial Decentralized Mean Field Control
  - Mean-Field Bellman Operator
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2509.15103
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T10:18:24.994056",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multi-Agent Reinforcement Learning",
    "Vulnerable Agent Identification",
    "Hierarchical Adversarial Decentralized Mean Field Control",
    "Mean-Field Bellman Operator"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multi-Agent Reinforcement Learning": 0.9,
    "Vulnerable Agent Identification": 0.7,
    "Hierarchical Adversarial Decentralized Mean Field Control": 0.75,
    "Mean-Field Bellman Operator": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multi-Agent Reinforcement Learning",
        "canonical": "Multi-Agent Reinforcement Learning",
        "aliases": [
          "MARL"
        ],
        "category": "broad_technical",
        "rationale": "This is a core concept in the paper, linking to broader discussions on reinforcement learning in multi-agent systems.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.9
      },
      {
        "surface": "Vulnerable Agent Identification",
        "canonical": "Vulnerable Agent Identification",
        "aliases": [
          "VAI"
        ],
        "category": "unique_technical",
        "rationale": "This is a unique technical term introduced in the paper, crucial for understanding the specific problem addressed.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.7
      },
      {
        "surface": "Hierarchical Adversarial Decentralized Mean Field Control",
        "canonical": "Hierarchical Adversarial Decentralized Mean Field Control",
        "aliases": [
          "HAD-MFC"
        ],
        "category": "unique_technical",
        "rationale": "This term represents a novel approach proposed in the paper, essential for linking the methodology discussed.",
        "novelty_score": 0.9,
        "connectivity_score": 0.55,
        "specificity_score": 0.9,
        "link_intent_score": 0.75
      },
      {
        "surface": "Mean-Field Bellman Operator",
        "canonical": "Mean-Field Bellman Operator",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "This concept is central to the paper's methodology, allowing connections to reinforcement learning optimization techniques.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "agent",
      "failure",
      "system",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multi-Agent Reinforcement Learning",
      "resolved_canonical": "Multi-Agent Reinforcement Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.9
      }
    },
    {
      "candidate_surface": "Vulnerable Agent Identification",
      "resolved_canonical": "Vulnerable Agent Identification",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Hierarchical Adversarial Decentralized Mean Field Control",
      "resolved_canonical": "Hierarchical Adversarial Decentralized Mean Field Control",
      "decision": "linked",
      "scores": {
        "novelty": 0.9,
        "connectivity": 0.55,
        "specificity": 0.9,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Mean-Field Bellman Operator",
      "resolved_canonical": "Mean-Field Bellman Operator",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# Vulnerable Agent Identification in Large-Scale Multi-Agent Reinforcement Learning

**Korean Title:** ëŒ€ê·œëª¨ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ê°•í™” í•™ìŠµì—ì„œ ì·¨ì•½ ì—ì´ì „íŠ¸ ì‹ë³„

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15103.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2509.15103](https://arxiv.org/abs/2509.15103)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/LEED_ A Highly Efficient and Scalable LLM-Empowered Expert Demonstrations Framework for Multi-Agent Reinforcement Learning_20250919|LEED: A Highly Efficient and Scalable LLM-Empowered Expert Demonstrations Framework for Multi-Agent Reinforcement Learning]] (84.8% similar)
- [[2025-09-19/Local-Canonicalization Equivariant Graph Neural Networks for Sample-Efficient and Generalizable Swarm Robot Control_20250919|Local-Canonicalization Equivariant Graph Neural Networks for Sample-Efficient and Generalizable Swarm Robot Control]] (84.8% similar)
- [[2025-09-22/Hierarchical Reinforcement Learning with Low-Level MPC for Multi-Agent Control_20250922|Hierarchical Reinforcement Learning with Low-Level MPC for Multi-Agent Control]] (82.9% similar)
- [[2025-09-19/Continuous-Time Value Iteration for Multi-Agent Reinforcement Learning_20250919|Continuous-Time Value Iteration for Multi-Agent Reinforcement Learning]] (82.0% similar)
- [[2025-09-22/Diagnostics of cognitive failures in multi-agent expert systems using dynamic evaluation protocols and subsequent mutation of the processing context_20250922|Diagnostics of cognitive failures in multi-agent expert systems using dynamic evaluation protocols and subsequent mutation of the processing context]] (81.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Multi-Agent Reinforcement Learning|Multi-Agent Reinforcement Learning]]
**ğŸ”— Specific Connectable**: [[keywords/Mean-Field Bellman Operator|Mean-Field Bellman Operator]]
**âš¡ Unique Technical**: [[keywords/Vulnerable Agent Identification|Vulnerable Agent Identification]], [[keywords/Hierarchical Adversarial Decentralized Mean Field Control|Hierarchical Adversarial Decentralized Mean Field Control]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15103v2 Announce Type: replace-cross 
Abstract: Partial agent failure becomes inevitable when systems scale up, making it crucial to identify the subset of agents whose compromise would most severely degrade overall performance. In this paper, we study this Vulnerable Agent Identification (VAI) problem in large-scale multi-agent reinforcement learning (MARL). We frame VAI as a Hierarchical Adversarial Decentralized Mean Field Control (HAD-MFC), where the upper level involves an NP-hard combinatorial task of selecting the most vulnerable agents, and the lower level learns worst-case adversarial policies for these agents using mean-field MARL. The two problems are coupled together, making HAD-MFC difficult to solve. To solve this, we first decouple the hierarchical process by Fenchel-Rockafellar transform, resulting a regularized mean-field Bellman operator for upper level that enables independent learning at each level, thus reducing computational complexity. We then reformulate the upper-level combinatorial problem as a MDP with dense rewards from our regularized mean-field Bellman operator, enabling us to sequentially identify the most vulnerable agents by greedy and RL algorithms. This decomposition provably preserves the optimal solution of the original HAD-MFC. Experiments show our method effectively identifies more vulnerable agents in large-scale MARL and the rule-based system, fooling system into worse failures, and learns a value function that reveals the vulnerability of each agent.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15103v2 ë°œí‘œ ìœ í˜•: êµì°¨ êµì²´  
ì´ˆë¡: ì‹œìŠ¤í…œì´ í™•ì¥ë¨ì— ë”°ë¼ ë¶€ë¶„ì ì¸ ì—ì´ì „íŠ¸ ì‹¤íŒ¨ëŠ” ë¶ˆê°€í”¼í•´ì§€ë©°, ì „ì²´ ì„±ëŠ¥ì„ ê°€ì¥ ì‹¬ê°í•˜ê²Œ ì €í•˜ì‹œí‚¬ ìˆ˜ ìˆëŠ” ì—ì´ì „íŠ¸ì˜ í•˜ìœ„ ì§‘í•©ì„ ì‹ë³„í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•´ì§‘ë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ëŒ€ê·œëª¨ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ê°•í™” í•™ìŠµ(MARL)ì—ì„œ ì´ ì·¨ì•½ ì—ì´ì „íŠ¸ ì‹ë³„(VAI) ë¬¸ì œë¥¼ ì—°êµ¬í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” VAIë¥¼ ê³„ì¸µì  ì ëŒ€ì  ë¶„ì‚° í‰ê· ì¥ ì œì–´(HAD-MFC)ë¡œ êµ¬ì„±í•˜ë©°, ìƒìœ„ ìˆ˜ì¤€ì—ì„œëŠ” ê°€ì¥ ì·¨ì•½í•œ ì—ì´ì „íŠ¸ë¥¼ ì„ íƒí•˜ëŠ” NP-ë‚œí•´í•œ ì¡°í•© ê³¼ì œê°€ í¬í•¨ë˜ê³ , í•˜ìœ„ ìˆ˜ì¤€ì—ì„œëŠ” í‰ê· ì¥ MARLì„ ì‚¬ìš©í•˜ì—¬ ì´ëŸ¬í•œ ì—ì´ì „íŠ¸ì— ëŒ€í•œ ìµœì•…ì˜ ì ëŒ€ì  ì •ì±…ì„ í•™ìŠµí•©ë‹ˆë‹¤. ì´ ë‘ ë¬¸ì œëŠ” ì„œë¡œ ê²°í•©ë˜ì–´ ìˆì–´ HAD-MFCë¥¼ í•´ê²°í•˜ê¸° ì–´ë µê²Œ ë§Œë“­ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ë¨¼ì € Fenchel-Rockafellar ë³€í™˜ì„ í†µí•´ ê³„ì¸µì  í”„ë¡œì„¸ìŠ¤ë¥¼ ë¶„ë¦¬í•˜ì—¬ ìƒìœ„ ìˆ˜ì¤€ì— ëŒ€í•œ ì •ê·œí™”ëœ í‰ê· ì¥ ë²¨ë§Œ ì—°ì‚°ìë¥¼ ë„ì¶œí•˜ê³ , ê° ìˆ˜ì¤€ì—ì„œ ë…ë¦½ì ì¸ í•™ìŠµì„ ê°€ëŠ¥í•˜ê²Œ í•˜ì—¬ ê³„ì‚° ë³µì¡ì„±ì„ ì¤„ì…ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ ìƒìœ„ ìˆ˜ì¤€ì˜ ì¡°í•© ë¬¸ì œë¥¼ ìš°ë¦¬ì˜ ì •ê·œí™”ëœ í‰ê· ì¥ ë²¨ë§Œ ì—°ì‚°ìë¡œë¶€í„°ì˜ ë°€ì§‘ ë³´ìƒì„ ê°–ëŠ” MDPë¡œ ì¬êµ¬ì„±í•˜ì—¬, íƒìš•ì  ë° RL ì•Œê³ ë¦¬ì¦˜ì„ í†µí•´ ê°€ì¥ ì·¨ì•½í•œ ì—ì´ì „íŠ¸ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹ë³„í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤. ì´ ë¶„í•´ëŠ” ì›ë˜ HAD-MFCì˜ ìµœì  ì†”ë£¨ì…˜ì„ ë³´ì¡´í•¨ì„ ì¦ëª…í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ìš°ë¦¬ì˜ ë°©ë²•ì€ ëŒ€ê·œëª¨ MARL ë° ê·œì¹™ ê¸°ë°˜ ì‹œìŠ¤í…œì—ì„œ ë” ë§ì€ ì·¨ì•½ ì—ì´ì „íŠ¸ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì‹ë³„í•˜ì—¬ ì‹œìŠ¤í…œì„ ë” ì‹¬ê°í•œ ì‹¤íŒ¨ë¡œ ìœ ë„í•˜ê³ , ê° ì—ì´ì „íŠ¸ì˜ ì·¨ì•½ì„±ì„ ë“œëŸ¬ë‚´ëŠ” ê°€ì¹˜ í•¨ìˆ˜ë¥¼ í•™ìŠµí•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€ê·œëª¨ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ê°•í™” í•™ìŠµ(MARL)ì—ì„œ ì¼ë¶€ ì—ì´ì „íŠ¸ì˜ ì‹¤íŒ¨ê°€ ì‹œìŠ¤í…œ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ìµœì†Œí™”í•˜ê¸° ìœ„í•œ ì·¨ì•½ ì—ì´ì „íŠ¸ ì‹ë³„(VAI) ë¬¸ì œë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. VAI ë¬¸ì œë¥¼ ê³„ì¸µì  ì ëŒ€ì  ë¶„ì‚° í‰ê· ì¥ ì œì–´(HAD-MFC)ë¡œ ì„¤ì •í•˜ê³ , ìƒìœ„ ë‹¨ê³„ì—ì„œ ì·¨ì•½í•œ ì—ì´ì „íŠ¸ë¥¼ ì„ íƒí•˜ëŠ” NP-ë‚œí•´í•œ ì¡°í•© ë¬¸ì œë¥¼ í•´ê²°í•˜ë©°, í•˜ìœ„ ë‹¨ê³„ì—ì„œëŠ” í‰ê· ì¥ MARLì„ í†µí•´ ìµœì•…ì˜ ì ëŒ€ì  ì •ì±…ì„ í•™ìŠµí•©ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ Fenchel-Rockafellar ë³€í™˜ì„ ì‚¬ìš©í•´ ê³„ì¸µì  ê³¼ì •ì„ ë¶„ë¦¬í•˜ê³ , ìƒìœ„ ë‹¨ê³„ì—ì„œ ì •ê·œí™”ëœ í‰ê· ì¥ ë²¨ë§Œ ì—°ì‚°ìë¥¼ ë„ì…í•˜ì—¬ ê° ë‹¨ê³„ì—ì„œ ë…ë¦½ì ì¸ í•™ìŠµì´ ê°€ëŠ¥í•˜ê²Œ í•˜ì—¬ ê³„ì‚° ë³µì¡ì„±ì„ ì¤„ì˜€ìŠµë‹ˆë‹¤. ìƒìœ„ ë‹¨ê³„ì˜ ì¡°í•© ë¬¸ì œë¥¼ MDPë¡œ ì¬êµ¬ì„±í•˜ì—¬ íƒìš•ì  ë° RL ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ì·¨ì•½í•œ ì—ì´ì „íŠ¸ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹ë³„í•  ìˆ˜ ìˆê²Œ í–ˆìŠµë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì´ ëŒ€ê·œëª¨ MARLì—ì„œ ë” ë§ì€ ì·¨ì•½ ì—ì´ì „íŠ¸ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì‹ë³„í•˜ê³ , ì‹œìŠ¤í…œì„ ë” ì‹¬ê°í•œ ì‹¤íŒ¨ë¡œ ìœ ë„í•˜ë©°, ê° ì—ì´ì „íŠ¸ì˜ ì·¨ì•½ì„±ì„ ë“œëŸ¬ë‚´ëŠ” ê°€ì¹˜ í•¨ìˆ˜ë¥¼ í•™ìŠµí•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€ê·œëª¨ ì‹œìŠ¤í…œì—ì„œ ë¶€ë¶„ì ì¸ ì—ì´ì „íŠ¸ ì‹¤íŒ¨ëŠ” ë¶ˆê°€í”¼í•˜ë©°, ê°€ì¥ ì·¨ì•½í•œ ì—ì´ì „íŠ¸ë¥¼ ì‹ë³„í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.
- 2. ì·¨ì•½ ì—ì´ì „íŠ¸ ì‹ë³„ ë¬¸ì œë¥¼ ê³„ì¸µì  ì ëŒ€ì  ë¶„ì‚° í‰ê· ì¥ ì œì–´(HAD-MFC)ë¡œ ì •ì˜í•˜ì˜€ìŠµë‹ˆë‹¤.
- 3. Fenchel-Rockafellar ë³€í™˜ì„ ì‚¬ìš©í•˜ì—¬ ê³„ì¸µì  ê³¼ì •ì„ ë¶„ë¦¬í•˜ê³ , ê° ë ˆë²¨ì—ì„œ ë…ë¦½ì ì¸ í•™ìŠµì„ ê°€ëŠ¥í•˜ê²Œ í•˜ì—¬ ê³„ì‚° ë³µì¡ì„±ì„ ì¤„ì˜€ìŠµë‹ˆë‹¤.
- 4. ìƒìœ„ ë ˆë²¨ì˜ ì¡°í•© ë¬¸ì œë¥¼ MDPë¡œ ì¬êµ¬ì„±í•˜ì—¬, íƒìš•ì  ë° ê°•í™” í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ê°€ì¥ ì·¨ì•½í•œ ì—ì´ì „íŠ¸ë¥¼ ì‹ë³„í•  ìˆ˜ ìˆê²Œ í•˜ì˜€ìŠµë‹ˆë‹¤.
- 5. ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì´ ëŒ€ê·œëª¨ MARLì—ì„œ ë” ë§ì€ ì·¨ì•½ ì—ì´ì „íŠ¸ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì‹ë³„í•˜ê³ , ì‹œìŠ¤í…œì„ ë” í° ì‹¤íŒ¨ë¡œ ìœ ë„í•¨ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-23 10:18:24*