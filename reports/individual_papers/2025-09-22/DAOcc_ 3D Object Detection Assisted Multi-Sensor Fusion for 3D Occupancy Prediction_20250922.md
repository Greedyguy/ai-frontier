---
keywords:
  - 3D Object Detection
  - Multimodal Learning
  - Autonomous Driving
  - BEV View Range Extension
category: cs.CV
publish_date: 2025-09-22
arxiv_id: 2409.19972
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T12:28:31.810505",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "3D Object Detection",
    "Multimodal Learning",
    "Autonomous Driving",
    "BEV View Range Extension"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "3D Object Detection": 0.78,
    "Multimodal Learning": 0.82,
    "Autonomous Driving": 0.77,
    "BEV View Range Extension": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "3D Object Detection",
        "canonical": "3D Object Detection",
        "aliases": [
          "3D Detection"
        ],
        "category": "specific_connectable",
        "rationale": "3D Object Detection is crucial for understanding spatial environments in autonomous systems, linking well with topics in robotics and computer vision.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Multi-sensor Fusion",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Sensor Fusion"
        ],
        "category": "specific_connectable",
        "rationale": "Multi-sensor fusion is a key aspect of multimodal learning, enhancing connectivity with other sensor-based approaches.",
        "novelty_score": 0.58,
        "connectivity_score": 0.87,
        "specificity_score": 0.8,
        "link_intent_score": 0.82
      },
      {
        "surface": "Autonomous Driving",
        "canonical": "Autonomous Driving",
        "aliases": [
          "Self-driving Cars"
        ],
        "category": "unique_technical",
        "rationale": "Autonomous driving is a unique application domain that connects various AI and robotics research areas.",
        "novelty_score": 0.65,
        "connectivity_score": 0.75,
        "specificity_score": 0.9,
        "link_intent_score": 0.77
      },
      {
        "surface": "BEV View Range Extension",
        "canonical": "BEV View Range Extension",
        "aliases": [
          "Bird's Eye View Extension"
        ],
        "category": "unique_technical",
        "rationale": "This technique is specific to enhancing perception in lower-resolution settings, relevant for linking to perception strategies.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "performance",
      "method"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "3D Object Detection",
      "resolved_canonical": "3D Object Detection",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Multi-sensor Fusion",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.87,
        "specificity": 0.8,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Autonomous Driving",
      "resolved_canonical": "Autonomous Driving",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.75,
        "specificity": 0.9,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "BEV View Range Extension",
      "resolved_canonical": "BEV View Range Extension",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# DAOcc: 3D Object Detection Assisted Multi-Sensor Fusion for 3D Occupancy Prediction

**Korean Title:** DAOcc: 3D ì ìœ  ì˜ˆì¸¡ì„ ìœ„í•œ 3D ê°ì²´ íƒì§€ ì§€ì› ë‹¤ì¤‘ ì„¼ì„œ ìœµí•©

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2409.19972.pdf)
**Category**: cs.CV
**Published**: 2025-09-22
**ArXiv ID**: [2409.19972](https://arxiv.org/abs/2409.19972)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/PAN_ Pillars-Attention-Based Network for 3D Object Detection_20250922|PAN: Pillars-Attention-Based Network for 3D Object Detection]] (84.7% similar)
- [[2025-09-22/Sparse Multiview Open-Vocabulary 3D Detection_20250922|Sparse Multiview Open-Vocabulary 3D Detection]] (83.2% similar)
- [[2025-09-18/Performance Optimization of YOLO-FEDER FusionNet for Robust Drone Detection in Visually Complex Environments_20250918|Performance Optimization of YOLO-FEDER FusionNet for Robust Drone Detection in Visually Complex Environments]] (82.8% similar)
- [[2025-09-18/BEVUDA++_ Geometric-aware Unsupervised Domain Adaptation for Multi-View 3D Object Detection_20250918|BEVUDA++: Geometric-aware Unsupervised Domain Adaptation for Multi-View 3D Object Detection]] (82.7% similar)
- [[2025-09-22/A re-calibration method for object detection with multi-modal alignment bias in autonomous driving_20250922|A re-calibration method for object detection with multi-modal alignment bias in autonomous driving]] (81.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/3D Object Detection|3D Object Detection]], [[keywords/Multimodal Learning|Multimodal Learning]]
**âš¡ Unique Technical**: [[keywords/Autonomous Driving|Autonomous Driving]], [[keywords/BEV View Range Extension|BEV View Range Extension]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2409.19972v4 Announce Type: replace 
Abstract: Multi-sensor fusion significantly enhances the accuracy and robustness of 3D semantic occupancy prediction, which is crucial for autonomous driving and robotics. However, most existing approaches depend on high-resolution images and complex networks to achieve top performance, hindering their deployment in practical scenarios. Moreover, current multi-sensor fusion approaches mainly focus on improving feature fusion while largely neglecting effective supervision strategies for those features. To address these issues, we propose DAOcc, a novel multi-modal occupancy prediction framework that leverages 3D object detection supervision to assist in achieving superior performance, while using a deployment-friendly image backbone and practical input resolution. In addition, we introduce a BEV View Range Extension strategy to mitigate performance degradation caused by lower image resolution. Extensive experiments demonstrate that DAOcc achieves new state-of-the-art results on both the Occ3D-nuScenes and Occ3D-Waymo benchmarks, and outperforms previous state-of-the-art methods by a significant margin using only a ResNet-50 backbone and 256*704 input resolution. With TensorRT optimization, DAOcc reaches 104.9 FPS while maintaining 54.2 mIoU on an NVIDIA RTX 4090 GPU. Code is available at https://github.com/AlphaPlusTT/DAOcc.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2409.19972v4 ë°œí‘œ ìœ í˜•: êµì²´  
ì´ˆë¡: ë‹¤ì¤‘ ì„¼ì„œ ìœµí•©ì€ ììœ¨ ì£¼í–‰ ë° ë¡œë´‡ ê³µí•™ì— ìˆì–´ ì¤‘ìš”í•œ 3D ì˜ë¯¸ ì ìœ  ì˜ˆì¸¡ì˜ ì •í™•ì„±ê³¼ ê²¬ê³ ì„±ì„ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ëŒ€ë¶€ë¶„ì˜ ê¸°ì¡´ ì ‘ê·¼ ë°©ì‹ì€ ìµœê³  ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ê¸° ìœ„í•´ ê³ í•´ìƒë„ ì´ë¯¸ì§€ì™€ ë³µì¡í•œ ë„¤íŠ¸ì›Œí¬ì— ì˜ì¡´í•˜ì—¬ ì‹¤ì œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œì˜ ë°°í¬ë¥¼ ë°©í•´í•©ë‹ˆë‹¤. ê²Œë‹¤ê°€, í˜„ì¬ì˜ ë‹¤ì¤‘ ì„¼ì„œ ìœµí•© ì ‘ê·¼ ë°©ì‹ì€ ì£¼ë¡œ íŠ¹ì§• ìœµí•©ì˜ ê°œì„ ì— ì´ˆì ì„ ë§ì¶”ê³  ìˆìœ¼ë©°, ì´ëŸ¬í•œ íŠ¹ì§•ì— ëŒ€í•œ íš¨ê³¼ì ì¸ ê°ë… ì „ëµì„ í¬ê²Œ ê°„ê³¼í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” 3D ê°ì²´ íƒì§€ ê°ë…ì„ í™œìš©í•˜ì—¬ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ë„ë¡ ë•ëŠ” ìƒˆë¡œìš´ ë‹¤ì¤‘ ëª¨ë‹¬ ì ìœ  ì˜ˆì¸¡ í”„ë ˆì„ì›Œí¬ì¸ DAOccë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ë°°í¬ ì¹œí™”ì ì¸ ì´ë¯¸ì§€ ë°±ë³¸ê³¼ ì‹¤ìš©ì ì¸ ì…ë ¥ í•´ìƒë„ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ë˜í•œ, ë‚®ì€ ì´ë¯¸ì§€ í•´ìƒë„ë¡œ ì¸í•œ ì„±ëŠ¥ ì €í•˜ë¥¼ ì™„í™”í•˜ê¸° ìœ„í•´ BEV View Range Extension ì „ëµì„ ë„ì…í•©ë‹ˆë‹¤. ê´‘ë²”ìœ„í•œ ì‹¤í—˜ì„ í†µí•´ DAOccê°€ Occ3D-nuScenesì™€ Occ3D-Waymo ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìƒˆë¡œìš´ ìµœì²¨ë‹¨ ê²°ê³¼ë¥¼ ë‹¬ì„±í•˜ê³ , ResNet-50 ë°±ë³¸ê³¼ 256*704 ì…ë ¥ í•´ìƒë„ë§Œì„ ì‚¬ìš©í•˜ì—¬ ì´ì „ ìµœì²¨ë‹¨ ë°©ë²•ë“¤ì„ ìƒë‹¹í•œ ì°¨ì´ë¡œ ëŠ¥ê°€í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. TensorRT ìµœì í™”ë¥¼ í†µí•´ DAOccëŠ” NVIDIA RTX 4090 GPUì—ì„œ 104.9 FPSë¥¼ ë‹¬ì„±í•˜ë©´ì„œë„ 54.2 mIoUë¥¼ ìœ ì§€í•©ë‹ˆë‹¤. ì½”ë“œëŠ” https://github.com/AlphaPlusTT/DAOccì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

DAOccëŠ” 3D ê°ì²´ íƒì§€ ê°ë…ì„ í™œìš©í•˜ì—¬ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ìƒˆë¡œìš´ ë©€í‹°ëª¨ë‹¬ ì ìœ  ì˜ˆì¸¡ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ì´ëŠ” ì‹¤ìš©ì ì¸ ì´ë¯¸ì§€ ë°±ë³¸ê³¼ ì…ë ¥ í•´ìƒë„ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°°í¬ ê°€ëŠ¥ì„±ì„ ë†’ì˜€ìŠµë‹ˆë‹¤. ë˜í•œ, BEV View Range Extension ì „ëµì„ ë„ì…í•˜ì—¬ ë‚®ì€ ì´ë¯¸ì§€ í•´ìƒë„ë¡œ ì¸í•œ ì„±ëŠ¥ ì €í•˜ë¥¼ ì™„í™”í•©ë‹ˆë‹¤. DAOccëŠ” Occ3D-nuScenesì™€ Occ3D-Waymo ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìµœì²¨ë‹¨ ì„±ê³¼ë¥¼ ë‹¬ì„±í–ˆìœ¼ë©°, ResNet-50 ë°±ë³¸ê³¼ 256x704 ì…ë ¥ í•´ìƒë„ë§Œìœ¼ë¡œë„ ì´ì „ ë°©ë²•ë“¤ì„ ëŠ¥ê°€í•©ë‹ˆë‹¤. TensorRT ìµœì í™”ë¥¼ í†µí•´ NVIDIA RTX 4090 GPUì—ì„œ 104.9 FPSì™€ 54.2 mIoUë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. DAOccëŠ” 3D ê°ì²´ íƒì§€ ê°ë…ì„ í™œìš©í•˜ì—¬ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ìƒˆë¡œìš´ ë©€í‹°ëª¨ë‹¬ ì ìœ  ì˜ˆì¸¡ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.
- 2. ì‹¤ìš©ì ì¸ ì…ë ¥ í•´ìƒë„ì™€ ë°°í¬ ì¹œí™”ì ì¸ ì´ë¯¸ì§€ ë°±ë³¸ì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ì‹œë‚˜ë¦¬ì˜¤ì— ì í•©í•œ ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.
- 3. BEV View Range Extension ì „ëµì„ ë„ì…í•˜ì—¬ ë‚®ì€ ì´ë¯¸ì§€ í•´ìƒë„ë¡œ ì¸í•œ ì„±ëŠ¥ ì €í•˜ë¥¼ ì™„í™”í•©ë‹ˆë‹¤.
- 4. DAOccëŠ” Occ3D-nuScenes ë° Occ3D-Waymo ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìƒˆë¡œìš´ ìµœì²¨ë‹¨ ê²°ê³¼ë¥¼ ë‹¬ì„±í•˜ë©°, ResNet-50 ë°±ë³¸ê³¼ 256*704 ì…ë ¥ í•´ìƒë„ë§Œìœ¼ë¡œ ì´ì „ ë°©ë²•ë“¤ì„ ëŠ¥ê°€í•©ë‹ˆë‹¤.
- 5. TensorRT ìµœì í™”ë¥¼ í†µí•´ NVIDIA RTX 4090 GPUì—ì„œ 104.9 FPSë¥¼ ìœ ì§€í•˜ë©´ì„œ 54.2 mIoUë¥¼ ë‹¬ì„±í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-23 12:28:31*