---
keywords:
  - Machine Learning
  - Printed Electronics
  - Multiplier-less Execution
  - Architecture-aware Training
category: cs.LG
publish_date: 2025-09-22
arxiv_id: 2509.15316
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T10:20:16.869909",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Machine Learning",
    "Printed Electronics",
    "Multiplier-less Execution",
    "Architecture-aware Training"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Machine Learning": 0.85,
    "Printed Electronics": 0.7,
    "Multiplier-less Execution": 0.78,
    "Architecture-aware Training": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Machine Learning",
        "canonical": "Machine Learning",
        "aliases": [
          "ML"
        ],
        "category": "broad_technical",
        "rationale": "Machine Learning is a fundamental concept that connects this work to a broad range of related research.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.5,
        "link_intent_score": 0.85
      },
      {
        "surface": "Printed Electronics",
        "canonical": "Printed Electronics",
        "aliases": [
          "PE"
        ],
        "category": "unique_technical",
        "rationale": "Printed Electronics is a unique aspect of this research, offering a novel approach to circuit design.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      },
      {
        "surface": "Multiplier-less execution",
        "canonical": "Multiplier-less Execution",
        "aliases": [
          "Multiplier-free Execution"
        ],
        "category": "unique_technical",
        "rationale": "This concept is central to the paper's innovation, enabling efficient computation in ML classifiers.",
        "novelty_score": 0.8,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Architecture-aware training",
        "canonical": "Architecture-aware Training",
        "aliases": [
          "Hardware-aware Training"
        ],
        "category": "unique_technical",
        "rationale": "This training method is tailored to the hardware design, enhancing efficiency and performance.",
        "novelty_score": 0.7,
        "connectivity_score": 0.68,
        "specificity_score": 0.75,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "circuit design",
      "classifier complexity"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Machine Learning",
      "resolved_canonical": "Machine Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.5,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Printed Electronics",
      "resolved_canonical": "Printed Electronics",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Multiplier-less execution",
      "resolved_canonical": "Multiplier-less Execution",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Architecture-aware training",
      "resolved_canonical": "Architecture-aware Training",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.68,
        "specificity": 0.75,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# Hybrid unary-binary design for multiplier-less printed Machine Learning classifiers

**Korean Title:** í•˜ì´ë¸Œë¦¬ë“œ ë‹¨í•­-ì´í•­ ì„¤ê³„: ê³±ì…ˆê¸° ì—†ëŠ” ì¸ì‡„í˜• ë¨¸ì‹ ëŸ¬ë‹ ë¶„ë¥˜ê¸°

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15316.pdf)
**Category**: cs.LG
**Published**: 2025-09-22
**ArXiv ID**: [2509.15316](https://arxiv.org/abs/2509.15316)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/Low-rank surrogate modeling and stochastic zero-order optimization for training of neural networks with black-box layers_20250918|Low-rank surrogate modeling and stochastic zero-order optimization for training of neural networks with black-box layers]] (83.3% similar)
- [[2025-09-18/The Energy-Efficient Hierarchical Neural Network with Fast FPGA-Based Incremental Learning_20250918|The Energy-Efficient Hierarchical Neural Network with Fast FPGA-Based Incremental Learning]] (81.7% similar)
- [[2025-09-22/Characterizing the Efficiency of Distributed Training_ A Power, Performance, and Thermal Perspective_20250922|Characterizing the Efficiency of Distributed Training: A Power, Performance, and Thermal Perspective]] (80.7% similar)
- [[2025-09-19/MaRVIn_ A Cross-Layer Mixed-Precision RISC-V Framework for DNN Inference, from ISA Extension to Hardware Acceleration_20250919|MaRVIn: A Cross-Layer Mixed-Precision RISC-V Framework for DNN Inference, from ISA Extension to Hardware Acceleration]] (80.0% similar)
- [[2025-09-22/Small LLMs with Expert Blocks Are Good Enough for Hyperparamter Tuning_20250922|Small LLMs with Expert Blocks Are Good Enough for Hyperparamter Tuning]] (79.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Machine Learning|Machine Learning]]
**âš¡ Unique Technical**: [[keywords/Printed Electronics|Printed Electronics]], [[keywords/Multiplier-less Execution|Multiplier-less Execution]], [[keywords/Architecture-aware Training|Architecture-aware Training]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15316v1 Announce Type: new 
Abstract: Printed Electronics (PE) provide a flexible, cost-efficient alternative to silicon for implementing machine learning (ML) circuits, but their large feature sizes limit classifier complexity. Leveraging PE's low fabrication and NRE costs, designers can tailor hardware to specific ML models, simplifying circuit design. This work explores alternative arithmetic and proposes a hybrid unary-binary architecture that removes costly encoders and enables efficient, multiplier-less execution of MLP classifiers. We also introduce architecture-aware training to further improve area and power efficiency. Evaluation on six datasets shows average reductions of 46% in area and 39% in power, with minimal accuracy loss, surpassing other state-of-the-art MLP designs.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15316v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: ì¸ì‡„ ì „ì(Printed Electronics, PE)ëŠ” ê¸°ê³„ í•™ìŠµ(ML) íšŒë¡œ êµ¬í˜„ì„ ìœ„í•œ ì‹¤ë¦¬ì½˜ì˜ ìœ ì—°í•˜ê³  ë¹„ìš© íš¨ìœ¨ì ì¸ ëŒ€ì•ˆì„ ì œê³µí•˜ì§€ë§Œ, í° íŠ¹ì§• í¬ê¸°ë¡œ ì¸í•´ ë¶„ë¥˜ê¸° ë³µì¡ì„±ì´ ì œí•œë©ë‹ˆë‹¤. PEì˜ ë‚®ì€ ì œì¡° ë° ë¹„ë°˜ë³µ ë¹„ìš©ì„ í™œìš©í•˜ì—¬ ì„¤ê³„ìëŠ” íŠ¹ì • ML ëª¨ë¸ì— í•˜ë“œì›¨ì–´ë¥¼ ë§ì¶¤í™”í•  ìˆ˜ ìˆìœ¼ë©°, ì´ë¥¼ í†µí•´ íšŒë¡œ ì„¤ê³„ê°€ ë‹¨ìˆœí™”ë©ë‹ˆë‹¤. ë³¸ ì—°êµ¬ëŠ” ëŒ€ì²´ ì‚°ìˆ ì„ íƒêµ¬í•˜ê³  ë¹„ìš©ì´ ë§ì´ ë“œëŠ” ì¸ì½”ë”ë¥¼ ì œê±°í•˜ê³  MLP ë¶„ë¥˜ê¸°ì˜ íš¨ìœ¨ì ì´ê³  ê³±ì…ˆê¸° ì—†ëŠ” ì‹¤í–‰ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” í•˜ì´ë¸Œë¦¬ë“œ ìœ ë‹ˆì–´ë¦¬-ë°”ì´ë„ˆë¦¬ ì•„í‚¤í…ì²˜ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ë˜í•œ ì˜ì—­ ë° ì „ë ¥ íš¨ìœ¨ì„±ì„ ë”ìš± í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ì•„í‚¤í…ì²˜ ì¸ì‹ í›ˆë ¨ì„ ë„ì…í•©ë‹ˆë‹¤. ì—¬ì„¯ ê°œì˜ ë°ì´í„°ì…‹ì— ëŒ€í•œ í‰ê°€ ê²°ê³¼, í‰ê· ì ìœ¼ë¡œ ì˜ì—­ì€ 46%, ì „ë ¥ì€ 39% ê°ì†Œí–ˆìœ¼ë©°, ì •í™•ë„ ì†ì‹¤ì€ ìµœì†Œí™”ë˜ì–´ ë‹¤ë¥¸ ìµœì²¨ë‹¨ MLP ì„¤ê³„ë¥¼ ëŠ¥ê°€í–ˆìŠµë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì¸ì‡„ ì „ì(PE)ë¥¼ í™œìš©í•˜ì—¬ ê¸°ê³„ í•™ìŠµ(ML) íšŒë¡œë¥¼ êµ¬í˜„í•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. PEëŠ” ì‹¤ë¦¬ì½˜ì— ë¹„í•´ ìœ ì—°í•˜ê³  ë¹„ìš© íš¨ìœ¨ì ì´ì§€ë§Œ, í° íŠ¹ì§• í¬ê¸° ë•Œë¬¸ì— ë¶„ë¥˜ê¸° ë³µì¡ì„±ì´ ì œí•œë©ë‹ˆë‹¤. ì €ìë“¤ì€ PEì˜ ë‚®ì€ ì œì‘ ë¹„ìš©ê³¼ ë¹„ë°˜ë³µ ë¹„ìš©ì„ í™œìš©í•˜ì—¬ íŠ¹ì • ML ëª¨ë¸ì— ë§ì¶˜ í•˜ë“œì›¨ì–´ ì„¤ê³„ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ì—°êµ¬ì—ì„œëŠ” ê³ ê°€ì˜ ì¸ì½”ë”ë¥¼ ì œê±°í•˜ê³  ê³±ì…ˆê¸° ì—†ì´ MLP ë¶„ë¥˜ê¸°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” í•˜ì´ë¸Œë¦¬ë“œ ìœ ë‹ˆì–´ë¦¬-ë°”ì´ë„ˆë¦¬ ì•„í‚¤í…ì²˜ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ë˜í•œ, ì•„í‚¤í…ì²˜ ì¸ì‹ í›ˆë ¨ì„ ë„ì…í•˜ì—¬ ë©´ì ê³¼ ì „ë ¥ íš¨ìœ¨ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì—¬ì„¯ ê°œì˜ ë°ì´í„°ì…‹ í‰ê°€ ê²°ê³¼, í‰ê· ì ìœ¼ë¡œ ë©´ì ì€ 46%, ì „ë ¥ì€ 39% ê°ì†Œí•˜ë©´ì„œë„ ì •í™•ë„ ì†ì‹¤ì€ ìµœì†Œí™”í•˜ì—¬, ê¸°ì¡´ ìµœì²¨ë‹¨ MLP ì„¤ê³„ë¥¼ ëŠ¥ê°€í•˜ëŠ” ì„±ê³¼ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì¸ì‡„ ì „ì ê¸°ìˆ ì€ ì‹¤ë¦¬ì½˜ë³´ë‹¤ ìœ ì—°í•˜ê³  ë¹„ìš© íš¨ìœ¨ì ì¸ ë¨¸ì‹  ëŸ¬ë‹ íšŒë¡œ êµ¬í˜„ ëŒ€ì•ˆì´ì§€ë§Œ, í° íŠ¹ì§• í¬ê¸°ê°€ ë¶„ë¥˜ê¸° ë³µì¡ì„±ì„ ì œí•œí•©ë‹ˆë‹¤.
- 2. ì¸ì‡„ ì „ìì˜ ë‚®ì€ ì œì‘ ë° ë¹„ë°˜ë³µ ë¹„ìš©ì„ í™œìš©í•˜ì—¬ íŠ¹ì • ë¨¸ì‹  ëŸ¬ë‹ ëª¨ë¸ì— ë§ì¶˜ í•˜ë“œì›¨ì–´ ì„¤ê³„ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.
- 3. í•˜ì´ë¸Œë¦¬ë“œ ìœ ë‹ˆì–´ë¦¬-ë°”ì´ë„ˆë¦¬ ì•„í‚¤í…ì²˜ë¥¼ ì œì•ˆí•˜ì—¬ ë¹„ìš©ì´ ë§ì´ ë“œëŠ” ì¸ì½”ë”ë¥¼ ì œê±°í•˜ê³  ê³±ì…ˆê¸° ì—†ëŠ” MLP ë¶„ë¥˜ê¸° ì‹¤í–‰ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
- 4. ì•„í‚¤í…ì²˜ ì¸ì‹ í›ˆë ¨ì„ ë„ì…í•˜ì—¬ ë©´ì ê³¼ ì „ë ¥ íš¨ìœ¨ì„±ì„ ë”ìš± í–¥ìƒì‹œí‚µë‹ˆë‹¤.
- 5. ì—¬ì„¯ ê°œì˜ ë°ì´í„°ì…‹ í‰ê°€ì—ì„œ í‰ê·  46%ì˜ ë©´ì  ê°ì†Œì™€ 39%ì˜ ì „ë ¥ ê°ì†Œë¥¼ ë‹¬ì„±í•˜ë©°, ì •í™•ë„ ì†ì‹¤ì€ ìµœì†Œí™”ë˜ì–´ ë‹¤ë¥¸ ìµœì‹  MLP ì„¤ê³„ë¥¼ ëŠ¥ê°€í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-23 10:20:16*