---
keywords:
  - Overfitting
  - Negotiation Paradigm
  - Classification Accuracy
  - CIFAR-10
  - Continual Learning
category: cs.LG
publish_date: 2025-09-22
arxiv_id: 2311.11410
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T10:59:29.084948",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Overfitting",
    "Negotiation Paradigm",
    "Classification Accuracy",
    "CIFAR-10",
    "Continual Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Overfitting": 0.8,
    "Negotiation Paradigm": 0.78,
    "Classification Accuracy": 0.75,
    "CIFAR-10": 0.7,
    "Continual Learning": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "overfitting",
        "canonical": "Overfitting",
        "aliases": [
          "model overfitting",
          "overfit"
        ],
        "category": "broad_technical",
        "rationale": "Overfitting is a fundamental issue in machine learning, relevant across various models and datasets.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.8
      },
      {
        "surface": "negotiation paradigm",
        "canonical": "Negotiation Paradigm",
        "aliases": [
          "negotiated representations",
          "negotiation approach"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel approach introduced in the paper, offering a unique method to mitigate overfitting.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "classification accuracy",
        "canonical": "Classification Accuracy",
        "aliases": [
          "accuracy improvement",
          "classification performance"
        ],
        "category": "specific_connectable",
        "rationale": "Improving classification accuracy is a key goal in machine learning, linking to performance evaluation.",
        "novelty_score": 0.4,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.75
      },
      {
        "surface": "CIFAR 10",
        "canonical": "CIFAR-10",
        "aliases": [
          "CIFAR10"
        ],
        "category": "specific_connectable",
        "rationale": "CIFAR-10 is a widely used dataset in machine learning, relevant for benchmarking and experimentation.",
        "novelty_score": 0.3,
        "connectivity_score": 0.85,
        "specificity_score": 0.75,
        "link_intent_score": 0.7
      },
      {
        "surface": "continual learning",
        "canonical": "Continual Learning",
        "aliases": [
          "lifelong learning",
          "incremental learning"
        ],
        "category": "evolved_concepts",
        "rationale": "Continual learning is an emerging field that benefits from the negotiation paradigm to address learning challenges.",
        "novelty_score": 0.65,
        "connectivity_score": 0.78,
        "specificity_score": 0.82,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "model",
      "data set",
      "experimental results"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "overfitting",
      "resolved_canonical": "Overfitting",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "negotiation paradigm",
      "resolved_canonical": "Negotiation Paradigm",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "classification accuracy",
      "resolved_canonical": "Classification Accuracy",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "CIFAR 10",
      "resolved_canonical": "CIFAR-10",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.85,
        "specificity": 0.75,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "continual learning",
      "resolved_canonical": "Continual Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.78,
        "specificity": 0.82,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Negotiated Representations to Prevent Overfitting in Machine Learning Applications

**Korean Title:** 기계 학습 응용에서 과적합을 방지하기 위한 협상된 표현

## 📋 메타데이터

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2311.11410.pdf)
**Category**: cs.LG
**Published**: 2025-09-22
**ArXiv ID**: [2311.11410](https://arxiv.org/abs/2311.11410)

## 🔗 유사한 논문
- [[2025-09-22/Efficient Long-Tail Learning in Latent Space by sampling Synthetic Data_20250922|Efficient Long-Tail Learning in Latent Space by sampling Synthetic Data]] (83.8% similar)
- [[2025-09-18/Data coarse graining can improve model performance_20250918|Data coarse graining can improve model performance]] (82.8% similar)
- [[2025-09-19/Superpose Task-specific Features for Model Merging_20250919|Superpose Task-specific Features for Model Merging]] (82.4% similar)
- [[2025-09-22/Mind the Gap_ Data Rewriting for Stable Off-Policy Supervised Fine-Tuning_20250922|Mind the Gap: Data Rewriting for Stable Off-Policy Supervised Fine-Tuning]] (81.6% similar)
- [[2025-09-19/Communication-Efficient and Privacy-Adaptable Mechanism for Federated Learning_20250919|Communication-Efficient and Privacy-Adaptable Mechanism for Federated Learning]] (81.2% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Overfitting|Overfitting]]
**🔗 Specific Connectable**: [[keywords/Classification Accuracy|Classification Accuracy]], [[keywords/CIFAR-10|CIFAR-10]]
**⚡ Unique Technical**: [[keywords/Negotiation Paradigm|Negotiation Paradigm]]
**🚀 Evolved Concepts**: [[keywords/Continual Learning|Continual Learning]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2311.11410v2 Announce Type: replace 
Abstract: Overfitting is a phenomenon that occurs when a machine learning model is trained for too long and focused too much on the exact fitness of the training samples to the provided training labels and cannot keep track of the predictive rules that would be useful on the test data. This phenomenon is commonly attributed to memorization of particular samples, memorization of the noise, and forced fitness into a data set of limited samples by using a high number of neurons. While it is true that the model encodes various peculiarities as the training process continues, we argue that most of the overfitting occurs in the process of reconciling sharply defined membership ratios. In this study, we present an approach that increases the classification accuracy of machine learning models by allowing the model to negotiate output representations of the samples with previously determined class labels. By setting up a negotiation between the models interpretation of the inputs and the provided labels, we not only increased average classification accuracy but also decreased the rate of overfitting without applying any other regularization tricks. By implementing our negotiation paradigm approach to several low regime machine learning problems by generating overfitting scenarios from publicly available data sets such as CIFAR 10, CIFAR 100, and MNIST we have demonstrated that the proposed paradigm has more capacity than its intended purpose. We are sharing the experimental results and inviting the machine learning community to explore the limits of the proposed paradigm. We also aim to incentive the community to exploit the negotiation paradigm to overcome the learning related challenges in other research fields such as continual learning. The Python code of the experimental setup is uploaded to GitHub.

## 🔍 Abstract (한글 번역)

arXiv:2311.11410v2 발표 유형: 교체  
초록: 과적합은 기계 학습 모델이 너무 오랫동안 훈련되어 제공된 훈련 레이블에 대한 훈련 샘플의 정확한 적합성에 지나치게 집중하여 테스트 데이터에 유용한 예측 규칙을 추적할 수 없을 때 발생하는 현상입니다. 이 현상은 일반적으로 특정 샘플의 암기, 노이즈의 암기, 많은 수의 뉴런을 사용하여 제한된 샘플의 데이터 세트에 강제로 적합시키는 것에 기인한다고 여겨집니다. 훈련 과정이 계속됨에 따라 모델이 다양한 특이성을 인코딩하는 것은 사실이지만, 우리는 대부분의 과적합이 명확하게 정의된 멤버십 비율을 조정하는 과정에서 발생한다고 주장합니다. 본 연구에서는 모델이 이전에 결정된 클래스 레이블과 샘플의 출력 표현을 협상할 수 있게 함으로써 기계 학습 모델의 분류 정확도를 높이는 접근법을 제시합니다. 입력에 대한 모델의 해석과 제공된 레이블 간의 협상을 설정함으로써, 우리는 평균 분류 정확도를 높였을 뿐만 아니라 다른 정규화 기법을 적용하지 않고도 과적합률을 줄였습니다. CIFAR 10, CIFAR 100, MNIST와 같은 공개 데이터 세트에서 과적합 시나리오를 생성하여 여러 저레짐 기계 학습 문제에 우리의 협상 패러다임 접근법을 구현함으로써, 제안된 패러다임이 의도된 목적보다 더 많은 역량을 가지고 있음을 입증했습니다. 우리는 실험 결과를 공유하고 기계 학습 커뮤니티가 제안된 패러다임의 한계를 탐구하도록 초대합니다. 또한, 지속 학습과 같은 다른 연구 분야에서 학습 관련 문제를 극복하기 위해 협상 패러다임을 활용하도록 커뮤니티에 동기를 부여하는 것을 목표로 합니다. 실험 설정의 Python 코드는 GitHub에 업로드되었습니다.

## 📝 요약

이 연구는 머신러닝 모델의 과적합 문제를 해결하기 위한 새로운 접근법을 제안합니다. 과적합은 모델이 훈련 데이터에 지나치게 맞춰져 테스트 데이터에 유용한 예측 규칙을 놓치는 현상입니다. 연구진은 모델이 입력과 주어진 레이블 간의 '협상'을 통해 출력 표현을 조정하도록 하여, 평균 분류 정확도를 높이고 과적합을 줄였습니다. 이 방법은 추가적인 정규화 기법 없이도 효과적이며, CIFAR 10, CIFAR 100, MNIST 데이터셋을 통해 검증되었습니다. 연구 결과는 GitHub에 공개되어 있으며, 지속 학습 등 다른 연구 분야에도 적용 가능성을 제시합니다.

## 🎯 주요 포인트

- 1. 과적합은 모델이 훈련 데이터에 지나치게 집중하여 테스트 데이터에 유용한 예측 규칙을 유지하지 못하는 현상이다.
- 2. 본 연구는 모델이 입력과 제공된 레이블 간의 협상을 통해 분류 정확도를 높이는 접근법을 제시한다.
- 3. 제안된 협상 패러다임은 과적합을 줄이고 평균 분류 정확도를 높이는 데 효과적이었다.
- 4. CIFAR 10, CIFAR 100, MNIST와 같은 데이터 세트를 통해 제안된 패러다임의 효과를 입증하였다.
- 5. 연구 커뮤니티가 제안된 패러다임을 다른 연구 분야의 학습 관련 문제 해결에 활용하도록 장려하고자 한다.


---

*Generated on 2025-09-23 10:59:29*