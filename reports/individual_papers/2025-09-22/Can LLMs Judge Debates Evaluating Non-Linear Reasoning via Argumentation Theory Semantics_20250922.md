---
keywords:
  - Large Language Model
  - Computational Argumentation Theory
  - Quantitative Argumentation Debate
  - Chain-of-Thought
  - In-Context Learning
category: cs.CL
publish_date: 2025-09-22
arxiv_id: 2509.15739
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:33:48.205895",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Computational Argumentation Theory",
    "Quantitative Argumentation Debate",
    "Chain-of-Thought",
    "In-Context Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.8,
    "Computational Argumentation Theory": 0.78,
    "Quantitative Argumentation Debate": 0.82,
    "Chain-of-Thought": 0.77,
    "In-Context Learning": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are central to the paper's exploration of reasoning capabilities.",
        "novelty_score": 0.45,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Computational Argumentation Theory",
        "canonical": "Computational Argumentation Theory",
        "aliases": [
          "CAT"
        ],
        "category": "unique_technical",
        "rationale": "This is a specific framework used to evaluate LLMs in the context of argumentation.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Quantitative Argumentation Debate semantics",
        "canonical": "Quantitative Argumentation Debate",
        "aliases": [
          "QuAD semantics"
        ],
        "category": "unique_technical",
        "rationale": "QuAD semantics is a novel method for evaluating argument acceptability, central to the paper's methodology.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.88,
        "link_intent_score": 0.82
      },
      {
        "surface": "Chain-of-Thought",
        "canonical": "Chain-of-Thought",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Chain-of-Thought is a prompting strategy that enhances LLM reasoning, relevant for linking to advanced instruction strategies.",
        "novelty_score": 0.5,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.77
      },
      {
        "surface": "In-Context Learning",
        "canonical": "In-Context Learning",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "In-Context Learning is a key strategy for improving LLM performance, relevant for linking to learning methodologies.",
        "novelty_score": 0.55,
        "connectivity_score": 0.78,
        "specificity_score": 0.72,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "debate",
      "dialogue",
      "discourse flow"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Computational Argumentation Theory",
      "resolved_canonical": "Computational Argumentation Theory",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Quantitative Argumentation Debate semantics",
      "resolved_canonical": "Quantitative Argumentation Debate",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.88,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Chain-of-Thought",
      "resolved_canonical": "Chain-of-Thought",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "In-Context Learning",
      "resolved_canonical": "In-Context Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.78,
        "specificity": 0.72,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Can LLMs Judge Debates? Evaluating Non-Linear Reasoning via Argumentation Theory Semantics

**Korean Title:** LLMì´ í† ë¡ ì„ í‰ê°€í•  ìˆ˜ ìˆëŠ”ê°€? ë…¼ì¦ ì´ë¡  ì˜ë¯¸ë¡ ì„ í†µí•œ ë¹„ì„ í˜• ì¶”ë¡  í‰ê°€

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15739.pdf)
**Category**: cs.CL
**Published**: 2025-09-22
**ArXiv ID**: [2509.15739](https://arxiv.org/abs/2509.15739)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Are LLMs Better Formalizers than Solvers on Complex Problems?_20250922|Are LLMs Better Formalizers than Solvers on Complex Problems?]] (86.7% similar)
- [[2025-09-22/It Depends_ Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge_20250922|It Depends: Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge]] (86.1% similar)
- [[2025-09-22/Can Large Language Models Infer Causal Relationships from Real-World Text?_20250922|Can Large Language Models Infer Causal Relationships from Real-World Text?]] (85.4% similar)
- [[2025-09-19/CLEAR_ A Comprehensive Linguistic Evaluation of Argument Rewriting by Large Language Models_20250919|CLEAR: A Comprehensive Linguistic Evaluation of Argument Rewriting by Large Language Models]] (85.4% similar)
- [[2025-09-19/Enhancing Logical Reasoning in Language Models via Symbolically-Guided Monte Carlo Process Supervision_20250919|Enhancing Logical Reasoning in Language Models via Symbolically-Guided Monte Carlo Process Supervision]] (85.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Chain-of-Thought|Chain-of-Thought]], [[keywords/In-Context Learning|In-Context Learning]]
**âš¡ Unique Technical**: [[keywords/Computational Argumentation Theory|Computational Argumentation Theory]], [[keywords/Quantitative Argumentation Debate|Quantitative Argumentation Debate]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15739v1 Announce Type: new 
Abstract: Large Language Models (LLMs) excel at linear reasoning tasks but remain underexplored on non-linear structures such as those found in natural debates, which are best expressed as argument graphs. We evaluate whether LLMs can approximate structured reasoning from Computational Argumentation Theory (CAT). Specifically, we use Quantitative Argumentation Debate (QuAD) semantics, which assigns acceptability scores to arguments based on their attack and support relations. Given only dialogue-formatted debates from two NoDE datasets, models are prompted to rank arguments without access to the underlying graph. We test several LLMs under advanced instruction strategies, including Chain-of-Thought and In-Context Learning. While models show moderate alignment with QuAD rankings, performance degrades with longer inputs or disrupted discourse flow. Advanced prompting helps mitigate these effects by reducing biases related to argument length and position. Our findings highlight both the promise and limitations of LLMs in modeling formal argumentation semantics and motivate future work on graph-aware reasoning.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15739v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì€ ì„ í˜• ì¶”ë¡  ì‘ì—…ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì´ì§€ë§Œ, ìì—° í† ë¡ ì—ì„œ ë°œê²¬ë˜ëŠ” ë¹„ì„ í˜• êµ¬ì¡°ì— ëŒ€í•´ì„œëŠ” ì•„ì§ ì¶©ë¶„íˆ íƒêµ¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë¹„ì„ í˜• êµ¬ì¡°ëŠ” ì£¼ë¡œ ë…¼ì¦ ê·¸ë˜í”„ë¡œ í‘œí˜„ë©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” LLMsê°€ ê³„ì‚° ë…¼ì¦ ì´ë¡ (CAT)ì—ì„œì˜ êµ¬ì¡°ì  ì¶”ë¡ ì„ ê·¼ì‚¬í•  ìˆ˜ ìˆëŠ”ì§€ë¥¼ í‰ê°€í•©ë‹ˆë‹¤. êµ¬ì²´ì ìœ¼ë¡œ, ê³µê²© ë° ì§€ì› ê´€ê³„ì— ê¸°ë°˜í•˜ì—¬ ë…¼ì¦ì˜ ìˆ˜ìš© ê°€ëŠ¥ì„± ì ìˆ˜ë¥¼ í• ë‹¹í•˜ëŠ” ì •ëŸ‰ì  ë…¼ì¦ í† ë¡ (QuAD) ì˜ë¯¸ë¡ ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ë‘ ê°œì˜ NoDE ë°ì´í„°ì…‹ì—ì„œ ëŒ€í™” í˜•ì‹ì˜ í† ë¡ ë§Œì„ ì œê³µë°›ì€ ìƒíƒœì—ì„œ, ëª¨ë¸ë“¤ì€ ê¸°ë³¸ ê·¸ë˜í”„ì— ì ‘ê·¼í•˜ì§€ ì•Šê³  ë…¼ì¦ì„ ìˆœìœ„í™”í•˜ë„ë¡ ìš”ì²­ë°›ìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì—°ì‡„ ì‚¬ê³ (Chain-of-Thought) ë° ë§¥ë½ ë‚´ í•™ìŠµ(In-Context Learning)ê³¼ ê°™ì€ ê³ ê¸‰ ì§€ì‹œ ì „ëµ í•˜ì— ì—¬ëŸ¬ LLMsë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤. ëª¨ë¸ë“¤ì€ QuAD ìˆœìœ„ì™€ ì¤‘ê°„ ì •ë„ì˜ ì¼ì¹˜ë¥¼ ë³´ì´ì§€ë§Œ, ì…ë ¥ì´ ê¸¸ì–´ì§€ê±°ë‚˜ ë‹´í™” íë¦„ì´ ë°©í•´ë°›ì„ ê²½ìš° ì„±ëŠ¥ì´ ì €í•˜ë©ë‹ˆë‹¤. ê³ ê¸‰ í”„ë¡¬í”„íŠ¸ëŠ” ë…¼ì¦ ê¸¸ì´ì™€ ìœ„ì¹˜ì— ê´€ë ¨ëœ í¸í–¥ì„ ì¤„ì„ìœ¼ë¡œì¨ ì´ëŸ¬í•œ íš¨ê³¼ë¥¼ ì™„í™”í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì—°êµ¬ ê²°ê³¼ëŠ” LLMsê°€ í˜•ì‹ì  ë…¼ì¦ ì˜ë¯¸ë¡ ì„ ëª¨ë¸ë§í•˜ëŠ” ë° ìˆì–´ ê°€ëŠ¥ì„±ê³¼ í•œê³„ë¥¼ ëª¨ë‘ ê°•ì¡°í•˜ë©°, ê·¸ë˜í”„ ì¸ì‹ ì¶”ë¡ ì— ëŒ€í•œ í–¥í›„ ì—°êµ¬ë¥¼ ì´‰ì§„í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ ì„ í˜• ì¶”ë¡  ì‘ì—…ì— ë›°ì–´ë‚˜ì§€ë§Œ, ìì—° í† ë¡ ì—ì„œ ë°œê²¬ë˜ëŠ” ë¹„ì„ í˜• êµ¬ì¡°, íŠ¹íˆ ë…¼ì¦ ê·¸ë˜í”„ì— ëŒ€í•œ íƒêµ¬ëŠ” ë¶€ì¡±í•©ë‹ˆë‹¤. ë³¸ ì—°êµ¬ëŠ” LLMì´ ê³„ì‚° ë…¼ì¦ ì´ë¡ (CAT)ì˜ êµ¬ì¡°ì  ì¶”ë¡ ì„ ê·¼ì‚¬í•  ìˆ˜ ìˆëŠ”ì§€ë¥¼ í‰ê°€í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” QuAD ì˜ë¯¸ë¡ ì„ ì‚¬ìš©í•˜ì—¬ ë…¼ì¦ì˜ ê³µê²© ë° ì§€ì› ê´€ê³„ì— ë”°ë¼ ìˆ˜ìš© ê°€ëŠ¥ì„± ì ìˆ˜ë¥¼ í• ë‹¹í•©ë‹ˆë‹¤. ë‘ ê°œì˜ NoDE ë°ì´í„°ì…‹ì—ì„œ ëŒ€í™” í˜•ì‹ì˜ í† ë¡ ë§Œì„ ì œê³µë°›ì•„, ëª¨ë¸ì´ ê¸°ì € ê·¸ë˜í”„ ì—†ì´ ë…¼ì¦ì„ ìˆœìœ„í™”í•˜ë„ë¡ í•©ë‹ˆë‹¤. ì—¬ëŸ¬ LLMì„ ì²´ì¸ ì˜¤ë¸Œ ì˜íŠ¸(Chain-of-Thought) ë° ì¸ì»¨í…ìŠ¤íŠ¸ ëŸ¬ë‹(In-Context Learning)ê³¼ ê°™ì€ ê³ ê¸‰ ì§€ì‹œ ì „ëµ í•˜ì— í…ŒìŠ¤íŠ¸í–ˆìŠµë‹ˆë‹¤. ëª¨ë¸ì€ QuAD ìˆœìœ„ì™€ ì¤‘ê°„ ì •ë„ì˜ ì¼ì¹˜ë¥¼ ë³´ì˜€ìœ¼ë‚˜, ì…ë ¥ì´ ê¸¸ì–´ì§€ê±°ë‚˜ ë‹´ë¡  íë¦„ì´ ë°©í•´ë°›ì„ ë•Œ ì„±ëŠ¥ì´ ì €í•˜ë˜ì—ˆìŠµë‹ˆë‹¤. ê³ ê¸‰ í”„ë¡¬í”„íŠ¸ëŠ” ë…¼ì¦ ê¸¸ì´ì™€ ìœ„ì¹˜ì— ê´€ë ¨ëœ í¸í–¥ì„ ì¤„ì—¬ ì´ëŸ¬í•œ íš¨ê³¼ë¥¼ ì™„í™”í–ˆìŠµë‹ˆë‹¤. ì—°êµ¬ ê²°ê³¼ëŠ” LLMì´ í˜•ì‹ ë…¼ì¦ ì˜ë¯¸ë¡ ì„ ëª¨ë¸ë§í•˜ëŠ” ë° ìˆì–´ ê°€ëŠ¥ì„±ê³¼ í•œê³„ë¥¼ ëª¨ë‘ ë³´ì—¬ì£¼ë©°, ê·¸ë˜í”„ ì¸ì‹ ì¶”ë¡ ì— ëŒ€í•œ í–¥í›„ ì—°êµ¬ë¥¼ ì´‰ì§„í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ ìì—° í† ë¡ ê³¼ ê°™ì€ ë¹„ì„ í˜• êµ¬ì¡°ì—ì„œì˜ ì„±ëŠ¥ì´ ì¶©ë¶„íˆ íƒêµ¬ë˜ì§€ ì•Šì•˜ë‹¤.
- 2. ì—°êµ¬ëŠ” LLMì´ Computational Argumentation Theory(CAT)ì˜ êµ¬ì¡°ì  ì¶”ë¡ ì„ ê·¼ì‚¬í•  ìˆ˜ ìˆëŠ”ì§€ë¥¼ í‰ê°€í•œë‹¤.
- 3. Quantitative Argumentation Debate(QuAD) ì˜ë¯¸ë¡ ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì´ ê·¸ë˜í”„ ì—†ì´ ë…¼ìŸì„ ìˆœìœ„ ë§¤ê¸°ëŠ” ëŠ¥ë ¥ì„ í…ŒìŠ¤íŠ¸í–ˆë‹¤.
- 4. ê³ ê¸‰ í”„ë¡¬í”„íŠ¸ ì „ëµì„ ì‚¬ìš©í•˜ì—¬ LLMì˜ ì„±ëŠ¥ì„ ê°œì„ í•˜ë ¤ í–ˆìœ¼ë‚˜ ê¸´ ì…ë ¥ì´ë‚˜ íë¦„ì´ ëŠê¸´ ê²½ìš° ì„±ëŠ¥ì´ ì €í•˜ë˜ì—ˆë‹¤.
- 5. ì—°êµ¬ ê²°ê³¼ëŠ” LLMì´ í˜•ì‹ì  ë…¼ì¦ ì˜ë¯¸ë¡ ì„ ëª¨ë¸ë§í•˜ëŠ” ë° ìˆì–´ ê°€ëŠ¥ì„±ê³¼ í•œê³„ë¥¼ ëª¨ë‘ ë³´ì—¬ì¤€ë‹¤.


---

*Generated on 2025-09-23 11:33:48*