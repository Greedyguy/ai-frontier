---
keywords:
  - Transformer
  - Large Language Model
  - Contrastive Pre-training
  - Text Detection
category: cs.LG
publish_date: 2025-09-22
arxiv_id: 2509.12385
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:23:57.083258",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Transformer",
    "Large Language Model",
    "Contrastive Pre-training",
    "Text Detection"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Transformer": 0.85,
    "Large Language Model": 0.8,
    "Contrastive Pre-training": 0.78,
    "Text Detection": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Transformer",
        "canonical": "Transformer",
        "aliases": [],
        "category": "broad_technical",
        "rationale": "Transformers are a foundational architecture in modern NLP, linking to a wide range of related topics.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Large Language Model",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "LLMs are central to the paper's focus and connect to various applications and research in NLP.",
        "novelty_score": 0.4,
        "connectivity_score": 0.88,
        "specificity_score": 0.75,
        "link_intent_score": 0.8
      },
      {
        "surface": "Contrastive Pre-training",
        "canonical": "Contrastive Pre-training",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This technique is crucial for the model's training process and links to advanced learning methods.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Text Detection",
        "canonical": "Text Detection",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Text detection is a specific application area that connects to broader topics in NLP and AI safety.",
        "novelty_score": 0.5,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance",
      "dataset"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Transformer",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Large Language Model",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.88,
        "specificity": 0.75,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Contrastive Pre-training",
      "resolved_canonical": "Contrastive Pre-training",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Text Detection",
      "resolved_canonical": "Text Detection",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# SENTRA: Selected-Next-Token Transformer for LLM Text Detection

**Korean Title:** SENTRA: LLM í…ìŠ¤íŠ¸ íƒì§€ë¥¼ ìœ„í•œ ì„ íƒëœ ë‹¤ìŒ í† í° ë³€í™˜ê¸°

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.12385.pdf)
**Category**: cs.LG
**Published**: 2025-09-22
**ArXiv ID**: [2509.12385](https://arxiv.org/abs/2509.12385)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/DetectAnyLLM_ Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models_20250919|DetectAnyLLM: Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models]] (86.1% similar)
- [[2025-09-22/Tag&Tab_ Pretraining Data Detection in Large Language Models Using Keyword-Based Membership Inference Attack_20250922|Tag&Tab: Pretraining Data Detection in Large Language Models Using Keyword-Based Membership Inference Attack]] (83.8% similar)
- [[2025-09-22/A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages_20250922|A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages]] (83.8% similar)
- [[2025-09-22/DNA-DetectLLM_ Unveiling AI-Generated Text via a DNA-Inspired Mutation-Repair Paradigm_20250922|DNA-DetectLLM: Unveiling AI-Generated Text via a DNA-Inspired Mutation-Repair Paradigm]] (83.6% similar)
- [[2025-09-22/DynamicNER_ A Dynamic, Multilingual, and Fine-Grained Dataset for LLM-based Named Entity Recognition_20250922|DynamicNER: A Dynamic, Multilingual, and Fine-Grained Dataset for LLM-based Named Entity Recognition]] (83.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Transformer|Transformer]], [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Text Detection|Text Detection]]
**âš¡ Unique Technical**: [[keywords/Contrastive Pre-training|Contrastive Pre-training]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.12385v2 Announce Type: replace-cross 
Abstract: LLMs are becoming increasingly capable and widespread. Consequently, the potential and reality of their misuse is also growing. In this work, we address the problem of detecting LLM-generated text that is not explicitly declared as such. We present a novel, general-purpose, and supervised LLM text detector, SElected-Next-Token tRAnsformer (SENTRA). SENTRA is a Transformer-based encoder leveraging selected-next-token-probability sequences and utilizing contrastive pre-training on large amounts of unlabeled data. Our experiments on three popular public datasets across 24 domains of text demonstrate SENTRA is a general-purpose classifier that significantly outperforms popular baselines in the out-of-domain setting.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.12385v2 ë°œí‘œ ìœ í˜•: êµì°¨ êµì²´  
ì´ˆë¡: ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ ì ì  ë” ê°•ë ¥í•´ì§€ê³  ë„ë¦¬ ì‚¬ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ì— ë”°ë¼ ì´ëŸ¬í•œ ëª¨ë¸ì˜ ì˜¤ìš© ê°€ëŠ¥ì„±ê³¼ í˜„ì‹¤ë„ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” LLMì´ ìƒì„±í•œ í…ìŠ¤íŠ¸ê°€ ëª…ì‹œì ìœ¼ë¡œ ì„ ì–¸ë˜ì§€ ì•Šì€ ê²½ìš° ì´ë¥¼ ê°ì§€í•˜ëŠ” ë¬¸ì œë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ìƒˆë¡œìš´ ë²”ìš© ê°ë… í•™ìŠµ LLM í…ìŠ¤íŠ¸ íƒì§€ê¸°ì¸ SElected-Next-Token tRAnsformer (SENTRA)ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. SENTRAëŠ” ì„ íƒëœ ë‹¤ìŒ í† í° í™•ë¥  ì‹œí€€ìŠ¤ë¥¼ í™œìš©í•˜ê³  ëŒ€ëŸ‰ì˜ ë ˆì´ë¸”ì´ ì—†ëŠ” ë°ì´í„°ì— ëŒ€í•œ ëŒ€ì¡°ì  ì‚¬ì „ í•™ìŠµì„ í™œìš©í•˜ëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ ì¸ì½”ë”ì…ë‹ˆë‹¤. 24ê°œì˜ í…ìŠ¤íŠ¸ ë„ë©”ì¸ì— ê±¸ì³ ì„¸ ê°€ì§€ ì¸ê¸° ìˆëŠ” ê³µê°œ ë°ì´í„°ì…‹ì— ëŒ€í•œ ì‹¤í—˜ì—ì„œ SENTRAëŠ” ë²”ìš© ë¶„ë¥˜ê¸°ë¡œì„œ ë„ë©”ì¸ ì™¸ ì„¤ì •ì—ì„œ ì¸ê¸° ìˆëŠ” ê¸°ì¤€ ëª¨ë¸ì„ í¬ê²Œ ëŠ¥ê°€í•¨ì„ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëª…ì‹œë˜ì§€ ì•Šì€ LLM(ëŒ€í˜• ì–¸ì–´ ëª¨ë¸) ìƒì„± í…ìŠ¤íŠ¸ë¥¼ íƒì§€í•˜ëŠ” ë¬¸ì œë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. ì €ìë“¤ì€ ìƒˆë¡œìš´ ë²”ìš© ê°ë… í•™ìŠµ LLM í…ìŠ¤íŠ¸ íƒì§€ê¸°ì¸ SENTRAë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. SENTRAëŠ” ì„ íƒëœ ë‹¤ìŒ í† í° í™•ë¥  ì‹œí€€ìŠ¤ë¥¼ í™œìš©í•˜ëŠ” Transformer ê¸°ë°˜ ì¸ì½”ë”ë¡œ, ëŒ€ëŸ‰ì˜ ë¹„ë¼ë²¨ ë°ì´í„°ì— ëŒ€í•œ ëŒ€ì¡°ì  ì‚¬ì „ í•™ìŠµì„ ì‚¬ìš©í•©ë‹ˆë‹¤. 24ê°œ í…ìŠ¤íŠ¸ ë„ë©”ì¸ì— ê±¸ì¹œ ì„¸ ê°€ì§€ ì¸ê¸° ìˆëŠ” ê³µê°œ ë°ì´í„°ì…‹ì—ì„œì˜ ì‹¤í—˜ ê²°ê³¼, SENTRAëŠ” ë²”ìš© ë¶„ë¥˜ê¸°ë¡œì„œ ë„ë©”ì¸ ì™¸ ì„¤ì •ì—ì„œ ê¸°ì¡´ì˜ ì¸ê¸° ìˆëŠ” ê¸°ì¤€ ëª¨ë¸ë“¤ì„ í¬ê²Œ ëŠ¥ê°€í•˜ëŠ” ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. LLMì˜ ì˜¤ìš© ê°€ëŠ¥ì„±ê³¼ í˜„ì‹¤ì´ ì¦ê°€í•˜ê³  ìˆìœ¼ë©°, ì´ë¥¼ íƒì§€í•˜ëŠ” ë¬¸ì œë¥¼ ë‹¤ë£¨ê³  ìˆë‹¤.
- 2. LLMì´ ìƒì„±í•œ í…ìŠ¤íŠ¸ë¥¼ íƒì§€í•˜ê¸° ìœ„í•´ ìƒˆë¡œìš´ ë²”ìš© ê°ë… í•™ìŠµ ê¸°ë°˜ì˜ íƒì§€ê¸°ì¸ SENTRAë¥¼ ì œì•ˆí•œë‹¤.
- 3. SENTRAëŠ” ì„ íƒëœ ë‹¤ìŒ í† í° í™•ë¥  ì‹œí€€ìŠ¤ë¥¼ í™œìš©í•˜ëŠ” Transformer ê¸°ë°˜ì˜ ì¸ì½”ë”ì´ë‹¤.
- 4. ëŒ€ëŸ‰ì˜ ë¹„ë¼ë²¨ ë°ì´í„°ì— ëŒ€í•œ ëŒ€ì¡°ì  ì‚¬ì „ í•™ìŠµì„ í†µí•´ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¨ë‹¤.
- 5. 24ê°œ ë„ë©”ì¸ì˜ í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ ì„¸ ê°€ì§€ ì¸ê¸° ìˆëŠ” ê³µê°œ ë°ì´í„°ì…‹ì—ì„œ SENTRAëŠ” ë²”ìš© ë¶„ë¥˜ê¸°ë¡œì„œ ê¸°ì¡´ì˜ ì¸ê¸° ìˆëŠ” ê¸°ì¤€ì„ ì„ í¬ê²Œ ëŠ¥ê°€í•œë‹¤.


---

*Generated on 2025-09-23 11:23:57*