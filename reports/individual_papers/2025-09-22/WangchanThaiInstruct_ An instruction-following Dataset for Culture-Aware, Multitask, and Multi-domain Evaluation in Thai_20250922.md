---
keywords:
  - Large Language Model
  - Zero-Shot Learning
  - Instruction Tuning
  - Culturally Grounded Instruction Data
category: cs.CL
publish_date: 2025-09-22
arxiv_id: 2508.15239
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:50:23.904369",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Zero-Shot Learning",
    "Instruction Tuning",
    "Culturally Grounded Instruction Data"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Zero-Shot Learning": 0.8,
    "Instruction Tuning": 0.75,
    "Culturally Grounded Instruction Data": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Large Language Models"
        ],
        "category": "broad_technical",
        "rationale": "Connects to a broad range of studies in natural language processing and machine learning.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Zero-Shot Evaluation",
        "canonical": "Zero-Shot Learning",
        "aliases": [
          "Zero-Shot Evaluation"
        ],
        "category": "specific_connectable",
        "rationale": "Highlights the evaluation method used, which is a trending topic in machine learning.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.78,
        "link_intent_score": 0.8
      },
      {
        "surface": "Instruction Tuning",
        "canonical": "Instruction Tuning",
        "aliases": [
          "Instruction Fine-Tuning"
        ],
        "category": "unique_technical",
        "rationale": "Represents a unique approach to improving model alignment with specific tasks.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.75
      },
      {
        "surface": "Culturally Grounded Instruction Data",
        "canonical": "Culturally Grounded Instruction Data",
        "aliases": [
          "Cultural Instruction Data"
        ],
        "category": "unique_technical",
        "rationale": "Emphasizes the importance of cultural context in data for low-resource languages.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.9,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "performance",
      "method",
      "evaluation"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Zero-Shot Evaluation",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.78,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Instruction Tuning",
      "resolved_canonical": "Instruction Tuning",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Culturally Grounded Instruction Data",
      "resolved_canonical": "Culturally Grounded Instruction Data",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.9,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# WangchanThaiInstruct: An instruction-following Dataset for Culture-Aware, Multitask, and Multi-domain Evaluation in Thai

**Korean Title:** WangchanThaiInstruct: íƒœêµ­ì–´ì—ì„œ ë¬¸í™” ì¸ì‹ì„ ê³ ë ¤í•œ ë‹¤ì¤‘ ì‘ì—… ë° ë‹¤ì¤‘ ë„ë©”ì¸ í‰ê°€ë¥¼ ìœ„í•œ ì§€ì¹¨ ì¤€ìˆ˜ ë°ì´í„°ì…‹

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2508.15239.pdf)
**Category**: cs.CL
**Published**: 2025-09-22
**ArXiv ID**: [2508.15239](https://arxiv.org/abs/2508.15239)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/A method for improving multilingual quality and diversity of instruction fine-tuning datasets_20250922|A method for improving multilingual quality and diversity of instruction fine-tuning datasets]] (83.1% similar)
- [[2025-09-22/CultureScope_ A Dimensional Lens for Probing Cultural Understanding in LLMs_20250922|CultureScope: A Dimensional Lens for Probing Cultural Understanding in LLMs]] (82.8% similar)
- [[2025-09-22/Enhancing LLM Language Adaption through Cross-lingual In-Context Pre-training_20250922|Enhancing LLM Language Adaption through Cross-lingual In-Context Pre-training]] (81.7% similar)
- [[2025-09-19/Ticket-Bench_ A Kickoff for Multilingual and Regionalized Agent Evaluation_20250919|Ticket-Bench: A Kickoff for Multilingual and Regionalized Agent Evaluation]] (81.5% similar)
- [[2025-09-22/Toxicity Red-Teaming_ Benchmarking LLM Safety in Singapore's Low-Resource Languages_20250922|Toxicity Red-Teaming: Benchmarking LLM Safety in Singapore's Low-Resource Languages]] (81.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Zero-Shot Learning|Zero-Shot Learning]]
**âš¡ Unique Technical**: [[keywords/Instruction Tuning|Instruction Tuning]], [[keywords/Culturally Grounded Instruction Data|Culturally Grounded Instruction Data]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2508.15239v2 Announce Type: replace 
Abstract: Large language models excel at instruction-following in English, but their performance in low-resource languages like Thai remains underexplored. Existing benchmarks often rely on translations, missing cultural and domain-specific nuances needed for real-world use. We present WangchanThaiInstruct, a human-authored Thai dataset for evaluation and instruction tuning, covering four professional domains and seven task types. Created through a multi-stage quality control process with annotators, domain experts, and AI researchers, WangchanThaiInstruct supports two studies: (1) a zero-shot evaluation showing performance gaps on culturally and professionally specific tasks, and (2) an instruction tuning study with ablations isolating the effect of native supervision. Models fine-tuned on WangchanThaiInstruct outperform those using translated data in both in-domain and out-of-domain benchmarks. These findings underscore the need for culturally and professionally grounded instruction data to improve LLM alignment in low-resource, linguistically diverse settings.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2508.15239v2 ë°œí‘œ ìœ í˜•: êµì²´  
ì´ˆë¡: ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì€ ì˜ì–´ì—ì„œì˜ ì§€ì‹œ ìˆ˜í–‰ì— ë›°ì–´ë‚˜ì§€ë§Œ, íƒœêµ­ì–´ì™€ ê°™ì€ ìì›ì´ ë¶€ì¡±í•œ ì–¸ì–´ì—ì„œëŠ” ê·¸ ì„±ëŠ¥ì´ ì¶©ë¶„íˆ íƒêµ¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ì¡´ì˜ ë²¤ì¹˜ë§ˆí¬ëŠ” ì¢…ì¢… ë²ˆì—­ì— ì˜ì¡´í•˜ì—¬, ì‹¤ì œ ì‚¬ìš©ì— í•„ìš”í•œ ë¬¸í™”ì  ë° ë„ë©”ì¸ íŠ¹ìœ ì˜ ë‰˜ì•™ìŠ¤ë¥¼ ë†“ì¹˜ê³  ìˆìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” í‰ê°€ ë° ì§€ì‹œ ì¡°ì •ì„ ìœ„í•œ ì¸ê°„ ì‘ì„± íƒœêµ­ì–´ ë°ì´í„°ì…‹ì¸ WangchanThaiInstructë¥¼ ì œì‹œí•˜ë©°, ì´ëŠ” ë„¤ ê°€ì§€ ì „ë¬¸ ë„ë©”ì¸ê³¼ ì¼ê³± ê°€ì§€ ì‘ì—… ìœ í˜•ì„ í¬í•¨í•©ë‹ˆë‹¤. ì´ ë°ì´í„°ì…‹ì€ ì£¼ì„ì, ë„ë©”ì¸ ì „ë¬¸ê°€, AI ì—°êµ¬ìì™€ í•¨ê»˜ ë‹¤ë‹¨ê³„ í’ˆì§ˆ ê´€ë¦¬ ê³¼ì •ì„ í†µí•´ ì œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. WangchanThaiInstructëŠ” ë‘ ê°€ì§€ ì—°êµ¬ë¥¼ ì§€ì›í•©ë‹ˆë‹¤: (1) ë¬¸í™”ì  ë° ì „ë¬¸ì ìœ¼ë¡œ íŠ¹í™”ëœ ì‘ì—…ì—ì„œì˜ ì„±ëŠ¥ ê²©ì°¨ë¥¼ ë³´ì—¬ì£¼ëŠ” ì œë¡œìƒ· í‰ê°€, (2) ì›ì–´ ê°ë…ì˜ íš¨ê³¼ë¥¼ ë¶„ë¦¬í•˜ëŠ” ì†Œê±° ì—°êµ¬ë¥¼ í¬í•¨í•œ ì§€ì‹œ ì¡°ì • ì—°êµ¬. WangchanThaiInstructë¡œ ë¯¸ì„¸ ì¡°ì •ëœ ëª¨ë¸ì€ ë²ˆì—­ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸ë³´ë‹¤ ë„ë©”ì¸ ë‚´ ë° ë„ë©”ì¸ ì™¸ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë” ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤. ì´ëŸ¬í•œ ê²°ê³¼ëŠ” ìì›ì´ ë¶€ì¡±í•˜ê³  ì–¸ì–´ì ìœ¼ë¡œ ë‹¤ì–‘í•œ í™˜ê²½ì—ì„œ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ ì •ë ¬ì„ ê°œì„ í•˜ê¸° ìœ„í•´ ë¬¸í™”ì  ë° ì „ë¬¸ì ìœ¼ë¡œ ê¸°ë°˜ì´ ëœ ì§€ì‹œ ë°ì´í„°ì˜ í•„ìš”ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì´ ì˜ì–´ì—ì„œëŠ” ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì´ì§€ë§Œ, íƒœêµ­ì–´ì™€ ê°™ì€ ì €ìì› ì–¸ì–´ì—ì„œëŠ” ì„±ëŠ¥ì´ ë¶€ì¡±í•˜ë‹¤ëŠ” ì ì„ ì§€ì í•©ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ WangchanThaiInstructë¼ëŠ” íƒœêµ­ì–´ ë°ì´í„°ì…‹ì„ ê°œë°œí•˜ì˜€ìœ¼ë©°, ì´ëŠ” ë„¤ ê°€ì§€ ì „ë¬¸ ë¶„ì•¼ì™€ ì¼ê³± ê°€ì§€ ì‘ì—… ìœ í˜•ì„ í¬í•¨í•©ë‹ˆë‹¤. ë°ì´í„°ì…‹ì€ ë‹¤ë‹¨ê³„ í’ˆì§ˆ ê´€ë¦¬ ê³¼ì •ì„ í†µí•´ ì œì‘ë˜ì—ˆìœ¼ë©°, ë‘ ê°€ì§€ ì—°êµ¬ì— í™œìš©ë˜ì—ˆìŠµë‹ˆë‹¤. ì²«ì§¸, ë¬¸í™”ì  ë° ì „ë¬¸ì  íŠ¹ìˆ˜ì„±ì„ ë°˜ì˜í•œ ì‘ì—…ì—ì„œ ì„±ëŠ¥ ê²©ì°¨ë¥¼ ë³´ì—¬ì£¼ëŠ” ì œë¡œìƒ· í‰ê°€, ë‘˜ì§¸, ì›ì–´ ê°ë…ì˜ íš¨ê³¼ë¥¼ ë¶„ë¦¬í•œ ëª…ë ¹ì–´ íŠœë‹ ì—°êµ¬ì…ë‹ˆë‹¤. WangchanThaiInstructë¡œ ë¯¸ì„¸ ì¡°ì •ëœ ëª¨ë¸ì€ ë²ˆì—­ ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ ëª¨ë¸ë³´ë‹¤ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë©°, ì´ëŠ” ì €ìì› ì–¸ì–´ í™˜ê²½ì—ì„œ ë¬¸í™”ì , ì „ë¬¸ì  ë§¥ë½ì„ ë°˜ì˜í•œ ë°ì´í„°ì˜ í•„ìš”ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì€ ì˜ì–´ì—ì„œëŠ” ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì´ì§€ë§Œ, íƒœêµ­ì–´ì™€ ê°™ì€ ì €ìì› ì–¸ì–´ì—ì„œëŠ” ì„±ëŠ¥ì´ ì¶©ë¶„íˆ íƒêµ¬ë˜ì§€ ì•Šì•˜ë‹¤.
- 2. ê¸°ì¡´ ë²¤ì¹˜ë§ˆí¬ëŠ” ë²ˆì—­ì— ì˜ì¡´í•˜ì—¬ ì‹¤ì œ ì‚¬ìš©ì— í•„ìš”í•œ ë¬¸í™”ì , ë„ë©”ì¸ íŠ¹ìœ ì˜ ë‰˜ì•™ìŠ¤ë¥¼ ë†“ì¹˜ëŠ” ê²½ìš°ê°€ ë§ë‹¤.
- 3. WangchanThaiInstructëŠ” íƒœêµ­ì–´ í‰ê°€ ë° ì§€ì‹œ ì¡°ì •ì„ ìœ„í•œ ì¸ê°„ ì‘ì„± ë°ì´í„°ì…‹ìœ¼ë¡œ, ë„¤ ê°€ì§€ ì „ë¬¸ ë„ë©”ì¸ê³¼ ì¼ê³± ê°€ì§€ ì‘ì—… ìœ í˜•ì„ í¬í•¨í•œë‹¤.
- 4. WangchanThaiInstructë¡œ ë¯¸ì„¸ ì¡°ì •ëœ ëª¨ë¸ì€ ë²ˆì—­ ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ ëª¨ë¸ë³´ë‹¤ ë„ë©”ì¸ ë‚´ì™¸ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤.
- 5. ì—°êµ¬ ê²°ê³¼ëŠ” ì €ìì› ì–¸ì–´ í™˜ê²½ì—ì„œ ë¬¸í™”ì , ì „ë¬¸ì ìœ¼ë¡œ ê¸°ë°˜ì´ ëœ ì§€ì‹œ ë°ì´í„°ì˜ í•„ìš”ì„±ì„ ê°•ì¡°í•œë‹¤.


---

*Generated on 2025-09-23 11:50:23*