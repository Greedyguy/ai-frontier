---
keywords:
  - Zero-Shot Learning
  - Foundation Models
  - Context Parroting
  - Dynamical Systems
  - Fractal Dimension
category: cs.LG
publish_date: 2025-09-22
arxiv_id: 2505.11349
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:08:16.139145",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Zero-Shot Learning",
    "Foundation Models",
    "Context Parroting",
    "Dynamical Systems",
    "Fractal Dimension"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Zero-Shot Learning": 0.82,
    "Foundation Models": 0.78,
    "Context Parroting": 0.75,
    "Dynamical Systems": 0.7,
    "Fractal Dimension": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Zero-shot forecasting",
        "canonical": "Zero-Shot Learning",
        "aliases": [
          "Zero-shot prediction"
        ],
        "category": "specific_connectable",
        "rationale": "This term connects to the broader concept of zero-shot learning, which is a trending area in machine learning.",
        "novelty_score": 0.55,
        "connectivity_score": 0.85,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "Foundation models",
        "canonical": "Foundation Models",
        "aliases": [
          "Base models",
          "Core models"
        ],
        "category": "unique_technical",
        "rationale": "Foundation models are a key concept in modern AI, representing a new class of models that can be linked to various machine learning tasks.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Context parroting",
        "canonical": "Context Parroting",
        "aliases": [
          "Contextual parroting"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel strategy identified in the paper, offering a new perspective on model behavior.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.75
      },
      {
        "surface": "Dynamical systems",
        "canonical": "Dynamical Systems",
        "aliases": [
          "Dynamic systems"
        ],
        "category": "broad_technical",
        "rationale": "Dynamical systems are central to the paper's focus and connect to various scientific and engineering domains.",
        "novelty_score": 0.4,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.7
      },
      {
        "surface": "Fractal dimension",
        "canonical": "Fractal Dimension",
        "aliases": [
          "Fractal geometry"
        ],
        "category": "unique_technical",
        "rationale": "The concept of fractal dimension is used to explain scaling laws in the paper, providing a unique link to mathematical modeling.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "forecast accuracy",
      "computational cost",
      "performance gaps"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Zero-shot forecasting",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.85,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Foundation models",
      "resolved_canonical": "Foundation Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Context parroting",
      "resolved_canonical": "Context Parroting",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Dynamical systems",
      "resolved_canonical": "Dynamical Systems",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Fractal dimension",
      "resolved_canonical": "Fractal Dimension",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# Context parroting: A simple but tough-to-beat baseline for foundation models in scientific machine learning

**Korean Title:** 맥락 패로팅: 과학적 기계 학습에서 기초 모델을 위한 간단하지만 뛰어넘기 어려운 기준점

## 📋 메타데이터

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2505.11349.pdf)
**Category**: cs.LG
**Published**: 2025-09-22
**ArXiv ID**: [2505.11349](https://arxiv.org/abs/2505.11349)

## 🔗 유사한 논문
- [[2025-09-22/Deep Learning Foundation and Pattern Models_ Challenges in Hydrological Time Series_20250922|Deep Learning Foundation and Pattern Models: Challenges in Hydrological Time Series]] (81.3% similar)
- [[2025-09-22/StFT_ Spatio-temporal Fourier Transformer for Long-term Dynamics Prediction_20250922|StFT: Spatio-temporal Fourier Transformer for Long-term Dynamics Prediction]] (80.6% similar)
- [[2025-09-22/Foundation Models as World Models_ A Foundational Study in Text-Based GridWorlds_20250922|Foundation Models as World Models: A Foundational Study in Text-Based GridWorlds]] (80.3% similar)
- [[2025-09-17/Bridging Past and Future_ Distribution-Aware Alignment for Time Series Forecasting_20250917|Bridging Past and Future: Distribution-Aware Alignment for Time Series Forecasting]] (79.9% similar)
- [[2025-09-18/Super-Linear_ A Lightweight Pretrained Mixture of Linear Experts for Time Series Forecasting_20250918|Super-Linear: A Lightweight Pretrained Mixture of Linear Experts for Time Series Forecasting]] (79.9% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Dynamical Systems|Dynamical Systems]]
**🔗 Specific Connectable**: [[keywords/Zero-Shot Learning|Zero-Shot Learning]]
**⚡ Unique Technical**: [[keywords/Foundation Models|Foundation Models]], [[keywords/Context Parroting|Context Parroting]], [[keywords/Fractal Dimension|Fractal Dimension]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2505.11349v2 Announce Type: replace 
Abstract: Recent time-series foundation models exhibit strong abilities to predict physical systems. These abilities include zero-shot forecasting, in which a model forecasts future states of a system given only a short trajectory as context, without knowledge of the underlying physics. Here, we show that foundation models often forecast through a simple parroting strategy, and when they are not parroting they exhibit some shared failure modes such as converging to the mean. As a result, a naive context parroting model that copies directly from the context scores higher than leading time-series foundation models on predicting a diverse range of dynamical systems, including low-dimensional chaos, turbulence, coupled oscillators, and electrocardiograms -- and at a tiny fraction of the computational cost. We draw a parallel between context parroting and induction heads, which explains recent works showing that large language models can often be repurposed for time series forecasting. Our dynamical systems perspective also ties the scaling between forecast accuracy and context length to the fractal dimension of the underlying chaotic attractor, providing insight into previously observed in-context neural scaling laws. By revealing the performance gaps and failure modes of current time-series foundation models, context parroting can guide the design of future foundation models and help identify in-context learning strategies beyond parroting.

## 🔍 Abstract (한글 번역)

arXiv:2505.11349v2 발표 유형: 교체  
초록: 최근의 시계열 기초 모델들은 물리 시스템을 예측하는 데 강력한 능력을 보여줍니다. 이러한 능력에는 기저 물리학에 대한 지식 없이 짧은 궤적만을 맥락으로 제공받아 시스템의 미래 상태를 예측하는 제로샷 예측이 포함됩니다. 여기서 우리는 기초 모델들이 종종 단순한 앵무새 전략을 통해 예측하며, 앵무새 전략을 사용하지 않을 때는 평균으로 수렴하는 등 몇 가지 공통된 실패 모드를 보인다는 것을 보여줍니다. 그 결과, 맥락에서 직접 복사하는 단순한 맥락 앵무새 모델이 저차원 혼돈, 난류, 결합된 진동자, 심전도 등 다양한 동적 시스템을 예측하는 데 있어 선도적인 시계열 기초 모델보다 높은 점수를 얻으며, 계산 비용은 극히 적습니다. 우리는 맥락 앵무새와 귀납적 머리(induction heads) 사이의 유사성을 그려내며, 이는 대형 언어 모델이 시계열 예측에 종종 재사용될 수 있음을 보여주는 최근 연구를 설명합니다. 우리의 동적 시스템 관점은 예측 정확도와 맥락 길이 간의 스케일링을 기저 혼돈 끌개의 프랙탈 차원과 연결하여, 이전에 관찰된 맥락 내 신경 스케일링 법칙에 대한 통찰을 제공합니다. 현재 시계열 기초 모델의 성능 격차와 실패 모드를 드러냄으로써, 맥락 앵무새는 미래의 기초 모델 설계를 안내하고 앵무새를 넘어선 맥락 내 학습 전략을 식별하는 데 도움을 줄 수 있습니다.

## 📝 요약

최근 시계열 기반 모델들은 물리 시스템을 예측하는 데 뛰어난 능력을 보여주고 있습니다. 이 연구는 이러한 모델들이 종종 단순한 모방 전략을 통해 예측을 수행하며, 모방이 아닐 때는 평균으로 수렴하는 등의 공통적인 실패 패턴을 보인다는 것을 밝혀냈습니다. 단순한 모방 모델이 다양한 동적 시스템 예측에서 기존의 시계열 모델보다 더 높은 성능을 보였으며, 이는 적은 계산 비용으로 이루어졌습니다. 연구는 모방 전략과 유도 헤드 간의 유사성을 제시하며, 대형 언어 모델이 시계열 예측에 재활용될 수 있음을 설명합니다. 또한, 예측 정확도와 맥락 길이 간의 관계를 혼돈 매력자의 프랙탈 차원과 연결지어, 기존의 신경 스케일링 법칙에 대한 통찰을 제공합니다. 이 연구는 현재 시계열 모델의 성능 격차와 실패 패턴을 밝히며, 향후 모델 설계와 맥락 학습 전략 개발에 기여할 수 있습니다.

## 🎯 주요 포인트

- 1. 최근 시계열 기반 모델은 물리 시스템을 예측하는 강력한 능력을 보이며, 짧은 궤적만을 사용하여 물리적 지식 없이도 미래 상태를 예측할 수 있습니다.
- 2. 이러한 모델들은 종종 단순한 복사 전략을 사용하며, 복사를 하지 않을 때는 평균으로 수렴하는 등의 공통적인 실패 모드를 보입니다.
- 3. 단순한 문맥 복사 모델이 다양한 동적 시스템 예측에서 기존 시계열 모델보다 높은 성능을 보이며, 계산 비용도 훨씬 적게 듭니다.
- 4. 문맥 복사와 유도 헤드 간의 유사성을 통해 대형 언어 모델이 시계열 예측에 재활용될 수 있음을 설명합니다.
- 5. 문맥 복사는 현재 시계열 모델의 성능 격차와 실패 모드를 드러내며, 향후 모델 설계와 새로운 학습 전략 개발에 기여할 수 있습니다.


---

*Generated on 2025-09-23 11:08:16*