---
keywords:
  - Zero-Shot Learning
  - Foundation Models
  - Context Parroting
  - Dynamical Systems
  - Fractal Dimension
category: cs.LG
publish_date: 2025-09-22
arxiv_id: 2505.11349
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:08:16.139145",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Zero-Shot Learning",
    "Foundation Models",
    "Context Parroting",
    "Dynamical Systems",
    "Fractal Dimension"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Zero-Shot Learning": 0.82,
    "Foundation Models": 0.78,
    "Context Parroting": 0.75,
    "Dynamical Systems": 0.7,
    "Fractal Dimension": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Zero-shot forecasting",
        "canonical": "Zero-Shot Learning",
        "aliases": [
          "Zero-shot prediction"
        ],
        "category": "specific_connectable",
        "rationale": "This term connects to the broader concept of zero-shot learning, which is a trending area in machine learning.",
        "novelty_score": 0.55,
        "connectivity_score": 0.85,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "Foundation models",
        "canonical": "Foundation Models",
        "aliases": [
          "Base models",
          "Core models"
        ],
        "category": "unique_technical",
        "rationale": "Foundation models are a key concept in modern AI, representing a new class of models that can be linked to various machine learning tasks.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Context parroting",
        "canonical": "Context Parroting",
        "aliases": [
          "Contextual parroting"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel strategy identified in the paper, offering a new perspective on model behavior.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.75
      },
      {
        "surface": "Dynamical systems",
        "canonical": "Dynamical Systems",
        "aliases": [
          "Dynamic systems"
        ],
        "category": "broad_technical",
        "rationale": "Dynamical systems are central to the paper's focus and connect to various scientific and engineering domains.",
        "novelty_score": 0.4,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.7
      },
      {
        "surface": "Fractal dimension",
        "canonical": "Fractal Dimension",
        "aliases": [
          "Fractal geometry"
        ],
        "category": "unique_technical",
        "rationale": "The concept of fractal dimension is used to explain scaling laws in the paper, providing a unique link to mathematical modeling.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "forecast accuracy",
      "computational cost",
      "performance gaps"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Zero-shot forecasting",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.85,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Foundation models",
      "resolved_canonical": "Foundation Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Context parroting",
      "resolved_canonical": "Context Parroting",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Dynamical systems",
      "resolved_canonical": "Dynamical Systems",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Fractal dimension",
      "resolved_canonical": "Fractal Dimension",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# Context parroting: A simple but tough-to-beat baseline for foundation models in scientific machine learning

**Korean Title:** ë§¥ë½ íŒ¨ë¡œíŒ…: ê³¼í•™ì  ê¸°ê³„ í•™ìŠµì—ì„œ ê¸°ì´ˆ ëª¨ë¸ì„ ìœ„í•œ ê°„ë‹¨í•˜ì§€ë§Œ ë›°ì–´ë„˜ê¸° ì–´ë ¤ìš´ ê¸°ì¤€ì 

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2505.11349.pdf)
**Category**: cs.LG
**Published**: 2025-09-22
**ArXiv ID**: [2505.11349](https://arxiv.org/abs/2505.11349)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Deep Learning Foundation and Pattern Models_ Challenges in Hydrological Time Series_20250922|Deep Learning Foundation and Pattern Models: Challenges in Hydrological Time Series]] (81.3% similar)
- [[2025-09-22/StFT_ Spatio-temporal Fourier Transformer for Long-term Dynamics Prediction_20250922|StFT: Spatio-temporal Fourier Transformer for Long-term Dynamics Prediction]] (80.6% similar)
- [[2025-09-22/Foundation Models as World Models_ A Foundational Study in Text-Based GridWorlds_20250922|Foundation Models as World Models: A Foundational Study in Text-Based GridWorlds]] (80.3% similar)
- [[2025-09-17/Bridging Past and Future_ Distribution-Aware Alignment for Time Series Forecasting_20250917|Bridging Past and Future: Distribution-Aware Alignment for Time Series Forecasting]] (79.9% similar)
- [[2025-09-18/Super-Linear_ A Lightweight Pretrained Mixture of Linear Experts for Time Series Forecasting_20250918|Super-Linear: A Lightweight Pretrained Mixture of Linear Experts for Time Series Forecasting]] (79.9% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Dynamical Systems|Dynamical Systems]]
**ğŸ”— Specific Connectable**: [[keywords/Zero-Shot Learning|Zero-Shot Learning]]
**âš¡ Unique Technical**: [[keywords/Foundation Models|Foundation Models]], [[keywords/Context Parroting|Context Parroting]], [[keywords/Fractal Dimension|Fractal Dimension]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2505.11349v2 Announce Type: replace 
Abstract: Recent time-series foundation models exhibit strong abilities to predict physical systems. These abilities include zero-shot forecasting, in which a model forecasts future states of a system given only a short trajectory as context, without knowledge of the underlying physics. Here, we show that foundation models often forecast through a simple parroting strategy, and when they are not parroting they exhibit some shared failure modes such as converging to the mean. As a result, a naive context parroting model that copies directly from the context scores higher than leading time-series foundation models on predicting a diverse range of dynamical systems, including low-dimensional chaos, turbulence, coupled oscillators, and electrocardiograms -- and at a tiny fraction of the computational cost. We draw a parallel between context parroting and induction heads, which explains recent works showing that large language models can often be repurposed for time series forecasting. Our dynamical systems perspective also ties the scaling between forecast accuracy and context length to the fractal dimension of the underlying chaotic attractor, providing insight into previously observed in-context neural scaling laws. By revealing the performance gaps and failure modes of current time-series foundation models, context parroting can guide the design of future foundation models and help identify in-context learning strategies beyond parroting.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2505.11349v2 ë°œí‘œ ìœ í˜•: êµì²´  
ì´ˆë¡: ìµœê·¼ì˜ ì‹œê³„ì—´ ê¸°ì´ˆ ëª¨ë¸ë“¤ì€ ë¬¼ë¦¬ ì‹œìŠ¤í…œì„ ì˜ˆì¸¡í•˜ëŠ” ë° ê°•ë ¥í•œ ëŠ¥ë ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŸ¬í•œ ëŠ¥ë ¥ì—ëŠ” ê¸°ì € ë¬¼ë¦¬í•™ì— ëŒ€í•œ ì§€ì‹ ì—†ì´ ì§§ì€ ê¶¤ì ë§Œì„ ë§¥ë½ìœ¼ë¡œ ì œê³µë°›ì•„ ì‹œìŠ¤í…œì˜ ë¯¸ë˜ ìƒíƒœë¥¼ ì˜ˆì¸¡í•˜ëŠ” ì œë¡œìƒ· ì˜ˆì¸¡ì´ í¬í•¨ë©ë‹ˆë‹¤. ì—¬ê¸°ì„œ ìš°ë¦¬ëŠ” ê¸°ì´ˆ ëª¨ë¸ë“¤ì´ ì¢…ì¢… ë‹¨ìˆœí•œ ì•µë¬´ìƒˆ ì „ëµì„ í†µí•´ ì˜ˆì¸¡í•˜ë©°, ì•µë¬´ìƒˆ ì „ëµì„ ì‚¬ìš©í•˜ì§€ ì•Šì„ ë•ŒëŠ” í‰ê· ìœ¼ë¡œ ìˆ˜ë ´í•˜ëŠ” ë“± ëª‡ ê°€ì§€ ê³µí†µëœ ì‹¤íŒ¨ ëª¨ë“œë¥¼ ë³´ì¸ë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ê·¸ ê²°ê³¼, ë§¥ë½ì—ì„œ ì§ì ‘ ë³µì‚¬í•˜ëŠ” ë‹¨ìˆœí•œ ë§¥ë½ ì•µë¬´ìƒˆ ëª¨ë¸ì´ ì €ì°¨ì› í˜¼ëˆ, ë‚œë¥˜, ê²°í•©ëœ ì§„ë™ì, ì‹¬ì „ë„ ë“± ë‹¤ì–‘í•œ ë™ì  ì‹œìŠ¤í…œì„ ì˜ˆì¸¡í•˜ëŠ” ë° ìˆì–´ ì„ ë„ì ì¸ ì‹œê³„ì—´ ê¸°ì´ˆ ëª¨ë¸ë³´ë‹¤ ë†’ì€ ì ìˆ˜ë¥¼ ì–»ìœ¼ë©°, ê³„ì‚° ë¹„ìš©ì€ ê·¹íˆ ì ìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” ë§¥ë½ ì•µë¬´ìƒˆì™€ ê·€ë‚©ì  ë¨¸ë¦¬(induction heads) ì‚¬ì´ì˜ ìœ ì‚¬ì„±ì„ ê·¸ë ¤ë‚´ë©°, ì´ëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì´ ì‹œê³„ì—´ ì˜ˆì¸¡ì— ì¢…ì¢… ì¬ì‚¬ìš©ë  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì£¼ëŠ” ìµœê·¼ ì—°êµ¬ë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ë™ì  ì‹œìŠ¤í…œ ê´€ì ì€ ì˜ˆì¸¡ ì •í™•ë„ì™€ ë§¥ë½ ê¸¸ì´ ê°„ì˜ ìŠ¤ì¼€ì¼ë§ì„ ê¸°ì € í˜¼ëˆ ëŒê°œì˜ í”„ë™íƒˆ ì°¨ì›ê³¼ ì—°ê²°í•˜ì—¬, ì´ì „ì— ê´€ì°°ëœ ë§¥ë½ ë‚´ ì‹ ê²½ ìŠ¤ì¼€ì¼ë§ ë²•ì¹™ì— ëŒ€í•œ í†µì°°ì„ ì œê³µí•©ë‹ˆë‹¤. í˜„ì¬ ì‹œê³„ì—´ ê¸°ì´ˆ ëª¨ë¸ì˜ ì„±ëŠ¥ ê²©ì°¨ì™€ ì‹¤íŒ¨ ëª¨ë“œë¥¼ ë“œëŸ¬ëƒ„ìœ¼ë¡œì¨, ë§¥ë½ ì•µë¬´ìƒˆëŠ” ë¯¸ë˜ì˜ ê¸°ì´ˆ ëª¨ë¸ ì„¤ê³„ë¥¼ ì•ˆë‚´í•˜ê³  ì•µë¬´ìƒˆë¥¼ ë„˜ì–´ì„  ë§¥ë½ ë‚´ í•™ìŠµ ì „ëµì„ ì‹ë³„í•˜ëŠ” ë° ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ìµœê·¼ ì‹œê³„ì—´ ê¸°ë°˜ ëª¨ë¸ë“¤ì€ ë¬¼ë¦¬ ì‹œìŠ¤í…œì„ ì˜ˆì¸¡í•˜ëŠ” ë° ë›°ì–´ë‚œ ëŠ¥ë ¥ì„ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ì´ëŸ¬í•œ ëª¨ë¸ë“¤ì´ ì¢…ì¢… ë‹¨ìˆœí•œ ëª¨ë°© ì „ëµì„ í†µí•´ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ë©°, ëª¨ë°©ì´ ì•„ë‹ ë•ŒëŠ” í‰ê· ìœ¼ë¡œ ìˆ˜ë ´í•˜ëŠ” ë“±ì˜ ê³µí†µì ì¸ ì‹¤íŒ¨ íŒ¨í„´ì„ ë³´ì¸ë‹¤ëŠ” ê²ƒì„ ë°í˜€ëƒˆìŠµë‹ˆë‹¤. ë‹¨ìˆœí•œ ëª¨ë°© ëª¨ë¸ì´ ë‹¤ì–‘í•œ ë™ì  ì‹œìŠ¤í…œ ì˜ˆì¸¡ì—ì„œ ê¸°ì¡´ì˜ ì‹œê³„ì—´ ëª¨ë¸ë³´ë‹¤ ë” ë†’ì€ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë©°, ì´ëŠ” ì ì€ ê³„ì‚° ë¹„ìš©ìœ¼ë¡œ ì´ë£¨ì–´ì¡ŒìŠµë‹ˆë‹¤. ì—°êµ¬ëŠ” ëª¨ë°© ì „ëµê³¼ ìœ ë„ í—¤ë“œ ê°„ì˜ ìœ ì‚¬ì„±ì„ ì œì‹œí•˜ë©°, ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì´ ì‹œê³„ì—´ ì˜ˆì¸¡ì— ì¬í™œìš©ë  ìˆ˜ ìˆìŒì„ ì„¤ëª…í•©ë‹ˆë‹¤. ë˜í•œ, ì˜ˆì¸¡ ì •í™•ë„ì™€ ë§¥ë½ ê¸¸ì´ ê°„ì˜ ê´€ê³„ë¥¼ í˜¼ëˆ ë§¤ë ¥ìì˜ í”„ë™íƒˆ ì°¨ì›ê³¼ ì—°ê²°ì§€ì–´, ê¸°ì¡´ì˜ ì‹ ê²½ ìŠ¤ì¼€ì¼ë§ ë²•ì¹™ì— ëŒ€í•œ í†µì°°ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” í˜„ì¬ ì‹œê³„ì—´ ëª¨ë¸ì˜ ì„±ëŠ¥ ê²©ì°¨ì™€ ì‹¤íŒ¨ íŒ¨í„´ì„ ë°íˆë©°, í–¥í›„ ëª¨ë¸ ì„¤ê³„ì™€ ë§¥ë½ í•™ìŠµ ì „ëµ ê°œë°œì— ê¸°ì—¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ìµœê·¼ ì‹œê³„ì—´ ê¸°ë°˜ ëª¨ë¸ì€ ë¬¼ë¦¬ ì‹œìŠ¤í…œì„ ì˜ˆì¸¡í•˜ëŠ” ê°•ë ¥í•œ ëŠ¥ë ¥ì„ ë³´ì´ë©°, ì§§ì€ ê¶¤ì ë§Œì„ ì‚¬ìš©í•˜ì—¬ ë¬¼ë¦¬ì  ì§€ì‹ ì—†ì´ë„ ë¯¸ë˜ ìƒíƒœë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- 2. ì´ëŸ¬í•œ ëª¨ë¸ë“¤ì€ ì¢…ì¢… ë‹¨ìˆœí•œ ë³µì‚¬ ì „ëµì„ ì‚¬ìš©í•˜ë©°, ë³µì‚¬ë¥¼ í•˜ì§€ ì•Šì„ ë•ŒëŠ” í‰ê· ìœ¼ë¡œ ìˆ˜ë ´í•˜ëŠ” ë“±ì˜ ê³µí†µì ì¸ ì‹¤íŒ¨ ëª¨ë“œë¥¼ ë³´ì…ë‹ˆë‹¤.
- 3. ë‹¨ìˆœí•œ ë¬¸ë§¥ ë³µì‚¬ ëª¨ë¸ì´ ë‹¤ì–‘í•œ ë™ì  ì‹œìŠ¤í…œ ì˜ˆì¸¡ì—ì„œ ê¸°ì¡´ ì‹œê³„ì—´ ëª¨ë¸ë³´ë‹¤ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì´ë©°, ê³„ì‚° ë¹„ìš©ë„ í›¨ì”¬ ì ê²Œ ë“­ë‹ˆë‹¤.
- 4. ë¬¸ë§¥ ë³µì‚¬ì™€ ìœ ë„ í—¤ë“œ ê°„ì˜ ìœ ì‚¬ì„±ì„ í†µí•´ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì´ ì‹œê³„ì—´ ì˜ˆì¸¡ì— ì¬í™œìš©ë  ìˆ˜ ìˆìŒì„ ì„¤ëª…í•©ë‹ˆë‹¤.
- 5. ë¬¸ë§¥ ë³µì‚¬ëŠ” í˜„ì¬ ì‹œê³„ì—´ ëª¨ë¸ì˜ ì„±ëŠ¥ ê²©ì°¨ì™€ ì‹¤íŒ¨ ëª¨ë“œë¥¼ ë“œëŸ¬ë‚´ë©°, í–¥í›„ ëª¨ë¸ ì„¤ê³„ì™€ ìƒˆë¡œìš´ í•™ìŠµ ì „ëµ ê°œë°œì— ê¸°ì—¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-23 11:08:16*