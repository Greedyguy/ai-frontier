---
keywords:
  - Large Language Model
  - Automated Essay Scoring
  - Zero-Shot Learning
  - Dialectical Reasoning
  - Roundtable Essay Scoring
category: cs.CL
publish_date: 2025-09-22
arxiv_id: 2509.14834
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:51:24.415762",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Automated Essay Scoring",
    "Zero-Shot Learning",
    "Dialectical Reasoning",
    "Roundtable Essay Scoring"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Automated Essay Scoring": 0.78,
    "Zero-Shot Learning": 0.8,
    "Dialectical Reasoning": 0.77,
    "Roundtable Essay Scoring": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Large Language Models"
        ],
        "category": "broad_technical",
        "rationale": "LLMs are central to the proposed framework and connect to broader NLP advancements.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Automated Essay Scoring",
        "canonical": "Automated Essay Scoring",
        "aliases": [
          "AES"
        ],
        "category": "unique_technical",
        "rationale": "AES is a specific application discussed in the paper, providing a unique context for linking.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Zero-Shot Setting",
        "canonical": "Zero-Shot Learning",
        "aliases": [
          "Zero-Shot"
        ],
        "category": "specific_connectable",
        "rationale": "Zero-shot learning is a trending concept relevant to the paper's methodology.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.75,
        "link_intent_score": 0.8
      },
      {
        "surface": "Dialectical Reasoning",
        "canonical": "Dialectical Reasoning",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Dialectical reasoning is a unique methodological approach that enhances understanding of the framework.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      },
      {
        "surface": "Roundtable Essay Scoring",
        "canonical": "Roundtable Essay Scoring",
        "aliases": [
          "RES"
        ],
        "category": "unique_technical",
        "rationale": "RES is the core framework introduced in the paper, crucial for understanding its contributions.",
        "novelty_score": 0.8,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Automated Essay Scoring",
      "resolved_canonical": "Automated Essay Scoring",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Zero-Shot Setting",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.75,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Dialectical Reasoning",
      "resolved_canonical": "Dialectical Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Roundtable Essay Scoring",
      "resolved_canonical": "Roundtable Essay Scoring",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# LLM Agents at the Roundtable: A Multi-Perspective and Dialectical Reasoning Framework for Essay Scoring

**Korean Title:** 원탁의 LLM 에이전트: 에세이 채점을 위한 다중 관점 및 변증법적 추론 프레임워크

## 📋 메타데이터

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.14834.pdf)
**Category**: cs.CL
**Published**: 2025-09-22
**ArXiv ID**: [2509.14834](https://arxiv.org/abs/2509.14834)

## 🔗 유사한 논문
- [[2025-09-22/Beyond the Score_ Uncertainty-Calibrated LLMs for Automated Essay Assessment_20250922|Beyond the Score: Uncertainty-Calibrated LLMs for Automated Essay Assessment]] (85.3% similar)
- [[2025-09-22/MEDAL_ A Framework for Benchmarking LLMs as Multilingual Open-Domain Dialogue Evaluators_20250922|MEDAL: A Framework for Benchmarking LLMs as Multilingual Open-Domain Dialogue Evaluators]] (84.6% similar)
- [[2025-09-19/Opening the Black Box_ Interpretable LLMs via Semantic Resonance Architecture_20250919|Opening the Black Box: Interpretable LLMs via Semantic Resonance Architecture]] (84.3% similar)
- [[2025-09-19/An LLM-based multi-agent framework for agile effort estimation_20250919|An LLM-based multi-agent framework for agile effort estimation]] (83.3% similar)
- [[2025-09-22/Diagnostics of cognitive failures in multi-agent expert systems using dynamic evaluation protocols and subsequent mutation of the processing context_20250922|Diagnostics of cognitive failures in multi-agent expert systems using dynamic evaluation protocols and subsequent mutation of the processing context]] (83.3% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Zero-Shot Learning|Zero-Shot Learning]]
**⚡ Unique Technical**: [[keywords/Automated Essay Scoring|Automated Essay Scoring]], [[keywords/Dialectical Reasoning|Dialectical Reasoning]], [[keywords/Roundtable Essay Scoring|Roundtable Essay Scoring]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.14834v2 Announce Type: replace 
Abstract: The emergence of large language models (LLMs) has brought a new paradigm to automated essay scoring (AES), a long-standing and practical application of natural language processing in education. However, achieving human-level multi-perspective understanding and judgment remains a challenge. In this work, we propose Roundtable Essay Scoring (RES), a multi-agent evaluation framework designed to perform precise and human-aligned scoring under a zero-shot setting. RES constructs evaluator agents based on LLMs, each tailored to a specific prompt and topic context. Each agent independently generates a trait-based rubric and conducts a multi-perspective evaluation. Then, by simulating a roundtable-style discussion, RES consolidates individual evaluations through a dialectical reasoning process to produce a final holistic score that more closely aligns with human evaluation. By enabling collaboration and consensus among agents with diverse evaluation perspectives, RES outperforms prior zero-shot AES approaches. Experiments on the ASAP dataset using ChatGPT and Claude show that RES achieves up to a 34.86% improvement in average QWK over straightforward prompting (Vanilla) methods.

## 🔍 Abstract (한글 번역)

arXiv:2509.14834v2 발표 유형: 교체  
초록: 대형 언어 모델(LLMs)의 등장은 교육 분야의 자연어 처리의 오랜 실용적 응용인 자동 에세이 채점(AES)에 새로운 패러다임을 가져왔습니다. 그러나 인간 수준의 다각적 이해와 판단을 달성하는 것은 여전히 도전 과제로 남아 있습니다. 본 연구에서는 정밀하고 인간에 맞춘 채점을 수행하기 위해 설계된 다중 에이전트 평가 프레임워크인 라운드테이블 에세이 채점(RES)을 제안합니다. RES는 특정 프롬프트와 주제 맥락에 맞춰진 LLMs 기반의 평가 에이전트를 구성합니다. 각 에이전트는 독립적으로 특성 기반의 채점 기준을 생성하고 다각적 평가를 수행합니다. 그런 다음, 라운드테이블 스타일의 토론을 시뮬레이션하여, RES는 변증법적 추론 과정을 통해 개별 평가를 통합하여 인간 평가와 더 가깝게 일치하는 최종적인 전체 점수를 산출합니다. 다양한 평가 관점을 가진 에이전트 간의 협력과 합의를 가능하게 함으로써, RES는 이전의 제로샷 AES 접근법을 능가합니다. ChatGPT와 Claude를 사용한 ASAP 데이터셋 실험에서 RES는 단순한 프롬프트(Vanilla) 방법에 비해 평균 QWK에서 최대 34.86% 향상을 달성했습니다.

## 📝 요약

이 연구는 자동 에세이 평가(AES)에서 인간 수준의 다각적 이해와 판단을 목표로 하는 새로운 평가 프레임워크인 Roundtable Essay Scoring (RES)을 제안합니다. RES는 대형 언어 모델(LLM)을 기반으로 한 평가 에이전트를 구성하여 각기 다른 주제와 맥락에 맞춘 평가를 수행합니다. 각 에이전트는 독립적으로 평가 기준을 생성하고 다각적 평가를 진행한 후, 모의 원탁 토론을 통해 개별 평가를 통합하여 최종 점수를 도출합니다. 이는 인간 평가와 더 밀접하게 일치하는 점수를 제공합니다. 실험 결과, RES는 다양한 평가 관점을 가진 에이전트 간의 협업과 합의를 통해 기존의 제로샷 AES 방법보다 최대 34.86% 개선된 성능을 보였습니다.

## 🎯 주요 포인트

- 1. 대형 언어 모델(LLMs)의 출현은 자동 에세이 채점(AES)에 새로운 패러다임을 제시했다.
- 2. Roundtable Essay Scoring(RES)은 다중 에이전트 평가 프레임워크로, 인간과 유사한 채점을 목표로 한다.
- 3. RES는 각 에이전트가 독립적으로 특성 기반의 평가 기준을 생성하고 다각적인 평가를 수행한다.
- 4. RES는 다양한 평가 관점을 가진 에이전트 간의 협력과 합의를 통해 최종 점수를 도출한다.
- 5. 실험 결과, RES는 기존의 단순 프롬프트 방법에 비해 평균 QWK에서 최대 34.86%의 향상을 보였다.


---

*Generated on 2025-09-23 11:51:24*