---
keywords:
  - Large Language Model
  - Meeting Summarization
  - Semantic Enrichment
  - P-MESA
  - Reason-out-loud Protocol
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2509.15901
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T09:19:40.035930",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Meeting Summarization",
    "Semantic Enrichment",
    "P-MESA",
    "Reason-out-loud Protocol"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Meeting Summarization": 0.75,
    "Semantic Enrichment": 0.7,
    "P-MESA": 0.72,
    "Reason-out-loud Protocol": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Large Language Models"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's methodology, linking to existing research on language models.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Meeting Summarization",
        "canonical": "Meeting Summarization",
        "aliases": [
          "Meeting Summary",
          "Summarization of Meetings"
        ],
        "category": "unique_technical",
        "rationale": "Focus of the paper's application, providing a specific context for summarization research.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      },
      {
        "surface": "Semantic Enrichment",
        "canonical": "Semantic Enrichment",
        "aliases": [
          "Enrichment of Semantics"
        ],
        "category": "unique_technical",
        "rationale": "Describes a novel approach in the paper, enhancing the summarization process.",
        "novelty_score": 0.65,
        "connectivity_score": 0.55,
        "specificity_score": 0.78,
        "link_intent_score": 0.7
      },
      {
        "surface": "P-MESA",
        "canonical": "P-MESA",
        "aliases": [
          "P-MESA Framework"
        ],
        "category": "unique_technical",
        "rationale": "A new evaluation framework introduced in the paper, crucial for assessing summarization quality.",
        "novelty_score": 0.8,
        "connectivity_score": 0.5,
        "specificity_score": 0.85,
        "link_intent_score": 0.72
      },
      {
        "surface": "Reason-out-loud Protocol",
        "canonical": "Reason-out-loud Protocol",
        "aliases": [
          "Reasoning Protocol"
        ],
        "category": "unique_technical",
        "rationale": "Innovative method for improving personalization in summarization, central to the paper's contributions.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.82,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "hallucinations",
      "omissions",
      "irrelevancies"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Meeting Summarization",
      "resolved_canonical": "Meeting Summarization",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Semantic Enrichment",
      "resolved_canonical": "Semantic Enrichment",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.55,
        "specificity": 0.78,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "P-MESA",
      "resolved_canonical": "P-MESA",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.5,
        "specificity": 0.85,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "Reason-out-loud Protocol",
      "resolved_canonical": "Reason-out-loud Protocol",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.82,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# Re-FRAME the Meeting Summarization SCOPE: Fact-Based Summarization and Personalization via Questions

**Korean Title:** 회의 요약 범위 재구성: 질문을 통한 사실 기반 요약 및 개인화

## 📋 메타데이터

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15901.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2509.15901](https://arxiv.org/abs/2509.15901)

## 🔗 유사한 논문
- [[2025-09-22/REFER_ Mitigating Bias in Opinion Summarisation via Frequency Framed Prompting_20250922|REFER: Mitigating Bias in Opinion Summarisation via Frequency Framed Prompting]] (84.5% similar)
- [[2025-09-22/Capturing Polysemanticity with PRISM_ A Multi-Concept Feature Description Framework_20250922|Capturing Polysemanticity with PRISM: A Multi-Concept Feature Description Framework]] (82.5% similar)
- [[2025-09-22/ConCISE_ Confidence-guided Compression in Step-by-step Efficient Reasoning_20250922|ConCISE: Confidence-guided Compression in Step-by-step Efficient Reasoning]] (82.4% similar)
- [[2025-09-19/LLM Agents at the Roundtable_ A Multi-Perspective and Dialectical Reasoning Framework for Essay Scoring_20250919|LLM Agents at the Roundtable: A Multi-Perspective and Dialectical Reasoning Framework for Essay Scoring]] (82.3% similar)
- [[2025-09-22/Think, Verbalize, then Speak_ Bridging Complex Thoughts and Comprehensible Speech_20250922|Think, Verbalize, then Speak: Bridging Complex Thoughts and Comprehensible Speech]] (82.1% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**⚡ Unique Technical**: [[keywords/Meeting Summarization|Meeting Summarization]], [[keywords/Semantic Enrichment|Semantic Enrichment]], [[keywords/P-MESA|P-MESA]], [[keywords/Reason-out-loud Protocol|Reason-out-loud Protocol]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.15901v1 Announce Type: cross 
Abstract: Meeting summarization with large language models (LLMs) remains error-prone, often producing outputs with hallucinations, omissions, and irrelevancies. We present FRAME, a modular pipeline that reframes summarization as a semantic enrichment task. FRAME extracts and scores salient facts, organizes them thematically, and uses these to enrich an outline into an abstractive summary. To personalize summaries, we introduce SCOPE, a reason-out-loud protocol that has the model build a reasoning trace by answering nine questions before content selection. For evaluation, we propose P-MESA, a multi-dimensional, reference-free evaluation framework to assess if a summary fits a target reader. P-MESA reliably identifies error instances, achieving >= 89% balanced accuracy against human annotations and strongly aligns with human severity ratings (r >= 0.70). On QMSum and FAME, FRAME reduces hallucination and omission by 2 out of 5 points (measured with MESA), while SCOPE improves knowledge fit and goal alignment over prompt-only baselines. Our findings advocate for rethinking summarization to improve control, faithfulness, and personalization.

## 🔍 Abstract (한글 번역)

arXiv:2509.15901v1 발표 유형: 교차  
초록: 대형 언어 모델(LLMs)을 사용한 회의 요약은 여전히 오류가 발생하기 쉬우며, 종종 환각, 누락, 무관한 내용을 포함한 결과물을 생성합니다. 우리는 요약을 의미적 강화 작업으로 재구성하는 모듈형 파이프라인인 FRAME을 제시합니다. FRAME은 중요한 사실을 추출하고 점수를 매긴 후, 이를 주제별로 조직하여 개요를 풍부한 추상적 요약으로 발전시킵니다. 요약을 개인화하기 위해, 우리는 SCOPE라는 '소리 내어 이유를 설명하는' 프로토콜을 도입하여 모델이 콘텐츠 선택 전에 아홉 가지 질문에 답함으로써 추론 과정을 구축하도록 합니다. 평가를 위해, 우리는 목표 독자에게 적합한지를 평가하는 다차원, 참조 없는 평가 프레임워크인 P-MESA를 제안합니다. P-MESA는 오류 사례를 신뢰성 있게 식별하며, 인간 주석과 비교하여 89% 이상의 균형 정확도를 달성하고, 인간의 심각도 평가와 강하게 일치합니다 (r >= 0.70). QMSum과 FAME에서, FRAME은 환각과 누락을 5점 만점 중 2점 줄이며 (MESA로 측정), SCOPE는 프롬프트 기반 기준보다 지식 적합성과 목표 정렬을 개선합니다. 우리의 연구 결과는 요약에 대한 재고를 통해 제어, 신뢰성, 개인화를 개선할 것을 제안합니다.

## 📝 요약

이 논문은 대형 언어 모델(LLM)을 활용한 회의 요약의 문제점을 해결하기 위해 FRAME이라는 모듈형 파이프라인을 제안합니다. FRAME은 요약을 의미적 강화 작업으로 재구성하여 중요한 사실을 추출하고 이를 주제별로 조직하여 요약의 질을 높입니다. 또한, 개인화된 요약을 위해 SCOPE라는 프로토콜을 도입하여 모델이 콘텐츠 선택 전에 아홉 가지 질문에 답하도록 합니다. 평가를 위해 P-MESA라는 다차원 평가 프레임워크를 제안하여 요약의 적합성을 평가합니다. P-MESA는 인간 평가와 높은 일치도를 보이며, FRAME은 환각과 누락을 줄이고, SCOPE는 지식 적합성과 목표 정렬을 개선합니다. 연구 결과는 요약의 통제력, 신뢰성, 개인화를 개선할 필요성을 강조합니다.

## 🎯 주요 포인트

- 1. FRAME은 요약을 의미적 강화 작업으로 재구성하여 핵심 사실을 추출하고 주제별로 조직화하여 요약의 정확성을 높입니다.
- 2. SCOPE는 모델이 콘텐츠 선택 전에 아홉 가지 질문에 답변하여 추론 과정을 구축하는 프로토콜로, 요약의 개인화를 지원합니다.
- 3. P-MESA는 참조 없이 요약이 대상 독자에게 적합한지를 평가하는 다차원 평가 프레임워크로, 인간 평가와 강하게 일치합니다.
- 4. FRAME은 QMSum과 FAME 데이터셋에서 환각과 누락을 줄이며, SCOPE는 지식 적합성과 목표 정렬을 개선합니다.
- 5. 연구 결과는 요약의 통제력, 신뢰성, 개인화를 개선하기 위해 요약 방식을 재고할 필요성을 제안합니다.


---

*Generated on 2025-09-23 09:19:40*