---
keywords:
  - Large Language Model
  - Self-supervised Learning
  - Automatic Speech Recognition
  - Automatic Speech Translation
  - Word Error Rate
category: cs.CL
publish_date: 2025-09-22
arxiv_id: 2506.04586
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:47:48.951556",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Self-supervised Learning",
    "Automatic Speech Recognition",
    "Automatic Speech Translation",
    "Word Error Rate"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Self-supervised Learning": 0.8,
    "Automatic Speech Recognition": 0.78,
    "Automatic Speech Translation": 0.77,
    "Word Error Rate": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Model",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are pivotal in refining pseudo-labels, enhancing the connectivity with other language processing tasks.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Semi-Supervised Learning",
        "canonical": "Self-supervised Learning",
        "aliases": [
          "SSL"
        ],
        "category": "specific_connectable",
        "rationale": "The method aligns with Self-supervised Learning, facilitating connections with similar learning paradigms.",
        "novelty_score": 0.5,
        "connectivity_score": 0.83,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Automatic Speech Recognition",
        "canonical": "Automatic Speech Recognition",
        "aliases": [
          "ASR"
        ],
        "category": "unique_technical",
        "rationale": "ASR is a key component in the framework, linking it to speech processing technologies.",
        "novelty_score": 0.65,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Automatic Speech Translation",
        "canonical": "Automatic Speech Translation",
        "aliases": [
          "AST"
        ],
        "category": "unique_technical",
        "rationale": "AST extends the framework's application to multilingual contexts, enhancing its specificity.",
        "novelty_score": 0.68,
        "connectivity_score": 0.72,
        "specificity_score": 0.82,
        "link_intent_score": 0.77
      },
      {
        "surface": "Word Error Rate",
        "canonical": "Word Error Rate",
        "aliases": [
          "WER"
        ],
        "category": "unique_technical",
        "rationale": "WER is a critical metric for evaluating speech recognition accuracy, linking to performance assessment.",
        "novelty_score": 0.6,
        "connectivity_score": 0.7,
        "specificity_score": 0.78,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "experiment"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Model",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Semi-Supervised Learning",
      "resolved_canonical": "Self-supervised Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.83,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Automatic Speech Recognition",
      "resolved_canonical": "Automatic Speech Recognition",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Automatic Speech Translation",
      "resolved_canonical": "Automatic Speech Translation",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.72,
        "specificity": 0.82,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Word Error Rate",
      "resolved_canonical": "Word Error Rate",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.7,
        "specificity": 0.78,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# LESS: Large Language Model Enhanced Semi-Supervised Learning for Speech Foundational Models Using in-the-wild Data

**Korean Title:** LESS: 자연 환경 데이터를 활용한 음성 기초 모델을 위한 대형 언어 모델 강화 반지도 학습

## 📋 메타데이터

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2506.04586.pdf)
**Category**: cs.CL
**Published**: 2025-09-22
**ArXiv ID**: [2506.04586](https://arxiv.org/abs/2506.04586)

## 🔗 유사한 논문
- [[2025-09-22/Exploring Fine-Tuning of Large Audio Language Models for Spoken Language Understanding under Limited Speech data_20250922|Exploring Fine-Tuning of Large Audio Language Models for Spoken Language Understanding under Limited Speech data]] (84.8% similar)
- [[2025-09-22/A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages_20250922|A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages]] (83.1% similar)
- [[2025-09-19/Listening, Imagining \& Refining_ A Heuristic Optimized ASR Correction Framework with LLMs_20250919|Listening, Imagining \& Refining: A Heuristic Optimized ASR Correction Framework with LLMs]] (82.9% similar)
- [[2025-09-22/Session-Level Spoken Language Assessment with a Multimodal Foundation Model via Multi-Target Learning_20250922|Session-Level Spoken Language Assessment with a Multimodal Foundation Model via Multi-Target Learning]] (82.9% similar)
- [[2025-09-22/AS-ASR_ A Lightweight Framework for Aphasia-Specific Automatic Speech Recognition_20250922|AS-ASR: A Lightweight Framework for Aphasia-Specific Automatic Speech Recognition]] (82.5% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Self-supervised Learning|Self-supervised Learning]]
**⚡ Unique Technical**: [[keywords/Automatic Speech Recognition|Automatic Speech Recognition]], [[keywords/Automatic Speech Translation|Automatic Speech Translation]], [[keywords/Word Error Rate|Word Error Rate]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2506.04586v2 Announce Type: replace 
Abstract: Although state-of-the-art Speech Foundation Models can produce high-quality text pseudo-labels, applying Semi-Supervised Learning (SSL) for in-the-wild real-world data remains challenging due to its richer and more complex acoustics compared to curated datasets. To address the challenges, we introduce LESS (Large Language Model Enhanced Semi-supervised Learning), a versatile framework that uses Large Language Models (LLMs) to correct pseudo-labels generated on in-the-wild data. In the LESS framework, pseudo-labeled text from Automatic Speech Recognition (ASR) or Automatic Speech Translation (AST) of the unsupervised data is refined by an LLM, and further improved by a data filtering strategy. Across Mandarin ASR and Spanish-to-English AST evaluations, LESS delivers consistent gains, with an absolute Word Error Rate reduction of 3.8% on WenetSpeech, and BLEU score increase of 0.8 and 0.7, achieving 34.0 on Callhome and 64.7 on Fisher testsets respectively. These results highlight LESS's effectiveness across diverse languages, tasks, and domains. We have released the recipe as open source to facilitate further research in this area.

## 🔍 Abstract (한글 번역)

arXiv:2506.04586v2 발표 유형: 교체  
초록: 최첨단 음성 기초 모델은 고품질의 텍스트 의사 레이블을 생성할 수 있지만, 실제 환경의 복잡하고 풍부한 음향 특성 때문에 반지도 학습(SSL)을 적용하는 것은 여전히 도전적입니다. 이러한 문제를 해결하기 위해, 우리는 LESS(Large Language Model Enhanced Semi-supervised Learning)라는 다재다능한 프레임워크를 소개합니다. 이 프레임워크는 대형 언어 모델(LLM)을 사용하여 실제 환경 데이터에서 생성된 의사 레이블을 수정합니다. LESS 프레임워크에서는 비지도 데이터의 자동 음성 인식(ASR) 또는 자동 음성 번역(AST)에서 생성된 의사 레이블 텍스트가 LLM에 의해 정제되고, 데이터 필터링 전략을 통해 추가로 개선됩니다. 중국어 ASR 및 스페인어-영어 AST 평가에서 LESS는 일관된 성능 향상을 제공하며, WenetSpeech에서 3.8%의 절대 단어 오류율 감소와 Callhome 및 Fisher 테스트 세트에서 각각 34.0 및 64.7의 BLEU 점수 증가를 통해 0.8 및 0.7의 향상을 달성했습니다. 이러한 결과는 다양한 언어, 작업 및 도메인에서 LESS의 효과를 강조합니다. 우리는 이 분야의 추가 연구를 촉진하기 위해 이 레시피를 오픈 소스로 공개했습니다.

## 📝 요약

이 논문은 복잡한 음향 환경의 실제 데이터를 다루기 위한 반지도 학습(SSL) 기법인 LESS를 소개합니다. LESS는 대형 언어 모델(LLM)을 활용하여 자동 음성 인식(ASR) 및 자동 음성 번역(AST)에서 생성된 가짜 레이블을 수정하고, 데이터 필터링 전략을 통해 이를 개선합니다. 이 방법론은 만다린 ASR과 스페인어-영어 AST 평가에서 각각 3.8%의 단어 오류율 감소와 BLEU 점수 증가를 달성했습니다. 이러한 결과는 LESS가 다양한 언어, 작업 및 도메인에서 효과적임을 보여주며, 연구를 촉진하기 위해 오픈 소스로 공개되었습니다.

## 🎯 주요 포인트

- 1. LESS 프레임워크는 대형 언어 모델(LLM)을 사용하여 실세계 데이터에서 생성된 가짜 레이블을 수정하는 반지도 학습 기법을 제안합니다.
- 2. LESS는 자동 음성 인식(ASR) 및 자동 음성 번역(AST)에서 생성된 가짜 레이블을 LLM으로 정제하고 데이터 필터링 전략으로 추가 개선합니다.
- 3. LESS는 만다린 ASR과 스페인어-영어 AST 평가에서 일관된 성능 향상을 보여주며, WenetSpeech에서 3.8%의 절대 단어 오류율 감소를 달성했습니다.
- 4. Callhome 및 Fisher 테스트 세트에서 BLEU 점수가 각각 0.8 및 0.7 증가하여 34.0 및 64.7을 기록했습니다.
- 5. LESS의 효과는 다양한 언어, 작업 및 도메인에서 입증되었으며, 이 연구 분야의 추가 연구를 위해 오픈 소스로 공개되었습니다.


---

*Generated on 2025-09-23 11:47:48*