---
keywords:
  - Large Language Model
  - Knowledge-Driven Hallucination
  - Business Process Management
  - Process Modeling
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2509.15336
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T08:43:44.301837",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Knowledge-Driven Hallucination",
    "Business Process Management",
    "Process Modeling"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Knowledge-Driven Hallucination": 0.78,
    "Business Process Management": 0.8,
    "Process Modeling": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Language Model"
        ],
        "category": "broad_technical",
        "rationale": "Central to the study, providing a direct link to the broader field of language models.",
        "novelty_score": 0.4,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "knowledge-driven hallucination",
        "canonical": "Knowledge-Driven Hallucination",
        "aliases": [
          "hallucination",
          "model hallucination"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel concept specific to the study of LLMs and their reliability.",
        "novelty_score": 0.8,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Business Process Management",
        "canonical": "Business Process Management",
        "aliases": [
          "BPM"
        ],
        "category": "specific_connectable",
        "rationale": "Connects the study to the established domain of business processes, enhancing interdisciplinary links.",
        "novelty_score": 0.5,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "process modeling",
        "canonical": "Process Modeling",
        "aliases": [
          "business process modeling"
        ],
        "category": "specific_connectable",
        "rationale": "Key task in the study, linking to methodologies in business and computational modeling.",
        "novelty_score": 0.55,
        "connectivity_score": 0.78,
        "specificity_score": 0.72,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "analytical tasks",
      "source artifact",
      "standardized patterns"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "knowledge-driven hallucination",
      "resolved_canonical": "Knowledge-Driven Hallucination",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Business Process Management",
      "resolved_canonical": "Business Process Management",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "process modeling",
      "resolved_canonical": "Process Modeling",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.78,
        "specificity": 0.72,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Knowledge-Driven Hallucination in Large Language Models: An Empirical Study on Process Modeling

**Korean Title:** ì§€ì‹ ê¸°ë°˜ í™˜ê° í˜„ìƒ: í”„ë¡œì„¸ìŠ¤ ëª¨ë¸ë§ì— ê´€í•œ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ ê²½í—˜ì  ì—°êµ¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15336.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2509.15336](https://arxiv.org/abs/2509.15336)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-17/Simulating a Bias Mitigation Scenario in Large Language Models_20250917|Simulating a Bias Mitigation Scenario in Large Language Models]] (85.8% similar)
- [[2025-09-19/Enhancing Logical Reasoning in Language Models via Symbolically-Guided Monte Carlo Process Supervision_20250919|Enhancing Logical Reasoning in Language Models via Symbolically-Guided Monte Carlo Process Supervision]] (85.2% similar)
- [[2025-09-22/Quantifying Self-Awareness of Knowledge in Large Language Models_20250922|Quantifying Self-Awareness of Knowledge in Large Language Models]] (85.2% similar)
- [[2025-09-22/Natural Fingerprints of Large Language Models_20250922|Natural Fingerprints of Large Language Models]] (84.8% similar)
- [[2025-09-18/From Automation to Autonomy_ A Survey on Large Language Models in Scientific Discovery_20250918|From Automation to Autonomy: A Survey on Large Language Models in Scientific Discovery]] (84.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Business Process Management|Business Process Management]], [[keywords/Process Modeling|Process Modeling]]
**âš¡ Unique Technical**: [[keywords/Knowledge-Driven Hallucination|Knowledge-Driven Hallucination]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15336v1 Announce Type: new 
Abstract: The utility of Large Language Models (LLMs) in analytical tasks is rooted in their vast pre-trained knowledge, which allows them to interpret ambiguous inputs and infer missing information. However, this same capability introduces a critical risk of what we term knowledge-driven hallucination: a phenomenon where the model's output contradicts explicit source evidence because it is overridden by the model's generalized internal knowledge. This paper investigates this phenomenon by evaluating LLMs on the task of automated process modeling, where the goal is to generate a formal business process model from a given source artifact. The domain of Business Process Management (BPM) provides an ideal context for this study, as many core business processes follow standardized patterns, making it likely that LLMs possess strong pre-trained schemas for them. We conduct a controlled experiment designed to create scenarios with deliberate conflict between provided evidence and the LLM's background knowledge. We use inputs describing both standard and deliberately atypical process structures to measure the LLM's fidelity to the provided evidence. Our work provides a methodology for assessing this critical reliability issue and raises awareness of the need for rigorous validation of AI-generated artifacts in any evidence-based domain.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15336v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì˜ ë¶„ì„ ì‘ì—…ì—ì„œì˜ ìœ ìš©ì„±ì€ ë°©ëŒ€í•œ ì‚¬ì „ í•™ìŠµ ì§€ì‹ì— ê¸°ë°˜í•˜ì—¬ ëª¨í˜¸í•œ ì…ë ¥ì„ í•´ì„í•˜ê³  ëˆ„ë½ëœ ì •ë³´ë¥¼ ì¶”ë¡ í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì— ë¿Œë¦¬ë¥¼ ë‘ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ëŸ¬í•œ ëŠ¥ë ¥ì€ ëª¨ë¸ì˜ ì¼ë°˜í™”ëœ ë‚´ë¶€ ì§€ì‹ì— ì˜í•´ ëª…ì‹œì ì¸ ì¶œì²˜ ì¦ê±°ê°€ ë¬´ì‹œë˜ì–´ ëª¨ë¸ì˜ ì¶œë ¥ì´ ì´ë¥¼ ëª¨ìˆœë˜ê²Œ í•˜ëŠ” ì§€ì‹ ê¸°ë°˜ í™˜ê°ì´ë¼ëŠ” ì¤‘ìš”í•œ ìœ„í—˜ì„ ì´ˆë˜í•©ë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì€ ì£¼ì–´ì§„ ì†ŒìŠ¤ ì•„í‹°íŒ©íŠ¸ë¡œë¶€í„° í˜•ì‹ì ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ í”„ë¡œì„¸ìŠ¤ ëª¨ë¸ì„ ìƒì„±í•˜ëŠ” ìë™í™”ëœ í”„ë¡œì„¸ìŠ¤ ëª¨ë¸ë§ ì‘ì—…ì—ì„œ LLMì„ í‰ê°€í•˜ì—¬ ì´ í˜„ìƒì„ ì¡°ì‚¬í•©ë‹ˆë‹¤. ë¹„ì¦ˆë‹ˆìŠ¤ í”„ë¡œì„¸ìŠ¤ ê´€ë¦¬(BPM) ë¶„ì•¼ëŠ” ë§ì€ í•µì‹¬ ë¹„ì¦ˆë‹ˆìŠ¤ í”„ë¡œì„¸ìŠ¤ê°€ í‘œì¤€í™”ëœ íŒ¨í„´ì„ ë”°ë¥´ê¸° ë•Œë¬¸ì— LLMì´ ì´ì— ëŒ€í•œ ê°•ë ¥í•œ ì‚¬ì „ í•™ìŠµ ìŠ¤í‚¤ë§ˆë¥¼ ë³´ìœ í•  ê°€ëŠ¥ì„±ì´ ë†’ì•„ ë³¸ ì—°êµ¬ì— ì´ìƒì ì¸ ë§¥ë½ì„ ì œê³µí•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì œê³µëœ ì¦ê±°ì™€ LLMì˜ ë°°ê²½ ì§€ì‹ ê°„ì— ì˜ë„ì ì¸ ì¶©ëŒì„ ì¼ìœ¼í‚¤ëŠ” ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë§Œë“¤ê¸° ìœ„í•´ ì„¤ê³„ëœ í†µì œëœ ì‹¤í—˜ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. í‘œì¤€ì ì´ê±°ë‚˜ ì˜ë„ì ìœ¼ë¡œ ë¹„ì •í˜•ì ì¸ í”„ë¡œì„¸ìŠ¤ êµ¬ì¡°ë¥¼ ì„¤ëª…í•˜ëŠ” ì…ë ¥ì„ ì‚¬ìš©í•˜ì—¬ ì œê³µëœ ì¦ê±°ì— ëŒ€í•œ LLMì˜ ì¶©ì‹¤ë„ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì—°êµ¬ëŠ” ì´ ì¤‘ìš”í•œ ì‹ ë¢°ì„± ë¬¸ì œë¥¼ í‰ê°€í•˜ê¸° ìœ„í•œ ë°©ë²•ë¡ ì„ ì œê³µí•˜ë©°, ì¦ê±° ê¸°ë°˜ ë„ë©”ì¸ì—ì„œ AI ìƒì„± ì•„í‹°íŒ©íŠ¸ì˜ ì—„ê²©í•œ ê²€ì¦ í•„ìš”ì„±ì— ëŒ€í•œ ì¸ì‹ì„ ë†’ì…ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì´ ë¶„ì„ ì‘ì—…ì—ì„œ ìœ ìš©í•˜ì§€ë§Œ, ë‚´ì¬ëœ ì§€ì‹ìœ¼ë¡œ ì¸í•´ ëª…ì‹œì  ì¦ê±°ì™€ ìƒì¶©ë˜ëŠ” ì¶œë ¥ì„ ìƒì„±í•˜ëŠ” 'ì§€ì‹ ê¸°ë°˜ í™˜ê°' í˜„ìƒì„ ì´ˆë˜í•  ìˆ˜ ìˆìŒì„ ë‹¤ë£¹ë‹ˆë‹¤. ì—°êµ¬ëŠ” ìë™í™”ëœ í”„ë¡œì„¸ìŠ¤ ëª¨ë¸ë§ ì‘ì—…ì—ì„œ LLMì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ë©°, ë¹„ì¦ˆë‹ˆìŠ¤ í”„ë¡œì„¸ìŠ¤ ê´€ë¦¬(BPM) ë¶„ì•¼ë¥¼ ëŒ€ìƒìœ¼ë¡œ í•©ë‹ˆë‹¤. ì‹¤í—˜ì„ í†µí•´ ì œê³µëœ ì¦ê±°ì™€ LLMì˜ ë°°ê²½ ì§€ì‹ ê°„ì˜ ì¶©ëŒì„ ì˜ë„ì ìœ¼ë¡œ ì¡°ì„±í•˜ì—¬, ëª¨ë¸ì´ ì¦ê±°ì— ì–¼ë§ˆë‚˜ ì¶©ì‹¤í•œì§€ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” AI ìƒì„± ê²°ê³¼ë¬¼ì˜ ì‹ ë¢°ì„±ì„ í‰ê°€í•˜ëŠ” ë°©ë²•ë¡ ì„ ì œì‹œí•˜ê³ , ì¦ê±° ê¸°ë°˜ ë¶„ì•¼ì—ì„œì˜ ì—„ê²©í•œ ê²€ì¦ í•„ìš”ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì§€ì‹ ê¸°ë°˜ í™˜ê° í˜„ìƒì€ ëª…ì‹œì  ì¦ê±°ì™€ ëª¨ìˆœë˜ëŠ” ì¶œë ¥ì„ ìƒì„±í•˜ëŠ” ìœ„í—˜ì„ ë‚´í¬í•˜ê³  ìˆë‹¤.
- 2. ë³¸ ë…¼ë¬¸ì€ ìë™í™”ëœ í”„ë¡œì„¸ìŠ¤ ëª¨ë¸ë§ ì‘ì—…ì„ í†µí•´ LLMì˜ ì§€ì‹ ê¸°ë°˜ í™˜ê° í˜„ìƒì„ ì¡°ì‚¬í•œë‹¤.
- 3. ë¹„ì¦ˆë‹ˆìŠ¤ í”„ë¡œì„¸ìŠ¤ ê´€ë¦¬(BPM) ë¶„ì•¼ëŠ” ë§ì€ í•µì‹¬ ë¹„ì¦ˆë‹ˆìŠ¤ í”„ë¡œì„¸ìŠ¤ê°€ í‘œì¤€í™”ëœ íŒ¨í„´ì„ ë”°ë¥´ê¸° ë•Œë¬¸ì— LLMì˜ ì‚¬ì „ í•™ìŠµ ìŠ¤í‚¤ë§ˆê°€ ê°•ë ¥í•  ê°€ëŠ¥ì„±ì´ ë†’ë‹¤.
- 4. ì—°êµ¬ëŠ” ì œê³µëœ ì¦ê±°ì™€ LLMì˜ ë°°ê²½ ì§€ì‹ ê°„ì˜ ì˜ë„ì ì¸ ì¶©ëŒì„ í¬í•¨í•œ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ í†µí•´ LLMì˜ ì¦ê±° ì¶©ì‹¤ë„ë¥¼ ì¸¡ì •í•œë‹¤.
- 5. AI ìƒì„± ì•„í‹°íŒ©íŠ¸ì˜ ì—„ê²©í•œ ê²€ì¦ í•„ìš”ì„±ì„ ê°•ì¡°í•˜ë©°, ì¦ê±° ê¸°ë°˜ ë„ë©”ì¸ì—ì„œì˜ ì‹ ë¢°ì„± ë¬¸ì œë¥¼ í‰ê°€í•˜ëŠ” ë°©ë²•ë¡ ì„ ì œê³µí•œë‹¤.


---

*Generated on 2025-09-23 08:43:44*