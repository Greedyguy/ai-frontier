---
keywords:
  - Large Language Model
  - Multimodal Learning
  - Attention Mechanism
  - Speech-enabled Large Language Models
  - Automatic Speech Recognition
category: cs.CL
publish_date: 2025-09-22
arxiv_id: 2509.15667
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:32:38.905015",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Multimodal Learning",
    "Attention Mechanism",
    "Speech-enabled Large Language Models",
    "Automatic Speech Recognition"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Multimodal Learning": 0.88,
    "Attention Mechanism": 0.9,
    "Speech-enabled Large Language Models": 0.8,
    "Automatic Speech Recognition": 0.87
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Language Models"
        ],
        "category": "broad_technical",
        "rationale": "Connects to a wide range of topics in Natural Language Processing and Machine Learning.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Multimodal Fusion",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal Integration"
        ],
        "category": "specific_connectable",
        "rationale": "Links to the integration of multiple data types, a key aspect of the paper.",
        "novelty_score": 0.7,
        "connectivity_score": 0.8,
        "specificity_score": 0.78,
        "link_intent_score": 0.88
      },
      {
        "surface": "Cross-modal Attention",
        "canonical": "Attention Mechanism",
        "aliases": [
          "Cross-modal Attention Mechanism"
        ],
        "category": "specific_connectable",
        "rationale": "Highlights the use of attention mechanisms across different modalities.",
        "novelty_score": 0.65,
        "connectivity_score": 0.85,
        "specificity_score": 0.82,
        "link_intent_score": 0.9
      },
      {
        "surface": "Speech-enabled LLMs",
        "canonical": "Speech-enabled Large Language Models",
        "aliases": [
          "Speech LLMs"
        ],
        "category": "unique_technical",
        "rationale": "Represents a novel integration of speech capabilities into language models.",
        "novelty_score": 0.75,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Automatic Speech Recognition",
        "canonical": "Automatic Speech Recognition",
        "aliases": [
          "ASR"
        ],
        "category": "specific_connectable",
        "rationale": "A core application area that connects to both speech and language processing.",
        "novelty_score": 0.5,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.87
      }
    ],
    "ban_list_suggestions": [
      "method",
      "approach",
      "results"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Multimodal Fusion",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.8,
        "specificity": 0.78,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "Cross-modal Attention",
      "resolved_canonical": "Attention Mechanism",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.85,
        "specificity": 0.82,
        "link_intent": 0.9
      }
    },
    {
      "candidate_surface": "Speech-enabled LLMs",
      "resolved_canonical": "Speech-enabled Large Language Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Automatic Speech Recognition",
      "resolved_canonical": "Automatic Speech Recognition",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.87
      }
    }
  ]
}
-->

# VOX-KRIKRI: Unifying Speech and Language through Continuous Fusion

**Korean Title:** VOX-KRIKRI: ì—°ì†ì  ìœµí•©ì„ í†µí•œ ìŒì„±ê³¼ ì–¸ì–´ì˜ í†µí•©

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15667.pdf)
**Category**: cs.CL
**Published**: 2025-09-22
**ArXiv ID**: [2509.15667](https://arxiv.org/abs/2509.15667)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Speech Language Models for Under-Represented Languages_ Insights from Wolof_20250922|Speech Language Models for Under-Represented Languages: Insights from Wolof]] (81.3% similar)
- [[2025-09-22/GLip_ A Global-Local Integrated Progressive Framework for Robust Visual Speech Recognition_20250922|GLip: A Global-Local Integrated Progressive Framework for Robust Visual Speech Recognition]] (80.9% similar)
- [[2025-09-22/Think, Verbalize, then Speak_ Bridging Complex Thoughts and Comprehensible Speech_20250922|Think, Verbalize, then Speak: Bridging Complex Thoughts and Comprehensible Speech]] (80.8% similar)
- [[2025-09-19/Cross-Modal Knowledge Distillation for Speech Large Language Models_20250919|Cross-Modal Knowledge Distillation for Speech Large Language Models]] (80.5% similar)
- [[2025-09-22/Session-Level Spoken Language Assessment with a Multimodal Foundation Model via Multi-Target Learning_20250922|Session-Level Spoken Language Assessment with a Multimodal Foundation Model via Multi-Target Learning]] (80.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]], [[keywords/Attention Mechanism|Attention Mechanism]], [[keywords/Automatic Speech Recognition|Automatic Speech Recognition]]
**âš¡ Unique Technical**: [[keywords/Speech-enabled Large Language Models|Speech-enabled Large Language Models]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15667v1 Announce Type: new 
Abstract: We present a multimodal fusion framework that bridges pre-trained decoder-based large language models (LLM) and acoustic encoder-decoder architectures such as Whisper, with the aim of building speech-enabled LLMs. Instead of directly using audio embeddings, we explore an intermediate audio-conditioned text space as a more effective mechanism for alignment. Our method operates fully in continuous text representation spaces, fusing Whisper's hidden decoder states with those of an LLM through cross-modal attention, and supports both offline and streaming modes. We introduce \textit{VoxKrikri}, the first Greek speech LLM, and show through analysis that our approach effectively aligns representations across modalities. These results highlight continuous space fusion as a promising path for multilingual and low-resource speech LLMs, while achieving state-of-the-art results for Automatic Speech Recognition in Greek, providing an average $\sim20\%$ relative improvement across benchmarks.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15667v1 ë°œí‘œ ìœ í˜•: ìƒˆë¡œìš´  
ì´ˆë¡: ìš°ë¦¬ëŠ” ì‚¬ì „ í›ˆë ¨ëœ ë””ì½”ë” ê¸°ë°˜ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ê³¼ Whisperì™€ ê°™ì€ ìŒí–¥ ì¸ì½”ë”-ë””ì½”ë” ì•„í‚¤í…ì²˜ë¥¼ ì—°ê²°í•˜ëŠ” ë‹¤ì¤‘ ëª¨ë‹¬ ìœµí•© í”„ë ˆì„ì›Œí¬ë¥¼ ì œì‹œí•˜ë©°, ì´ë¥¼ í†µí•´ ìŒì„± ì§€ì› LLMì„ êµ¬ì¶•í•˜ê³ ì í•©ë‹ˆë‹¤. ì˜¤ë””ì˜¤ ì„ë² ë”©ì„ ì§ì ‘ ì‚¬ìš©í•˜ëŠ” ëŒ€ì‹ , ìš°ë¦¬ëŠ” ì •ë ¬ì„ ìœ„í•œ ë³´ë‹¤ íš¨ê³¼ì ì¸ ë©”ì»¤ë‹ˆì¦˜ìœ¼ë¡œ ì¤‘ê°„ ì˜¤ë””ì˜¤ ì¡°ê±´ í…ìŠ¤íŠ¸ ê³µê°„ì„ íƒìƒ‰í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ë°©ë²•ì€ ì—°ì†ì ì¸ í…ìŠ¤íŠ¸ í‘œí˜„ ê³µê°„ì—ì„œ ì™„ì „íˆ ì‘ë™í•˜ë©°, Whisperì˜ ìˆ¨ê²¨ì§„ ë””ì½”ë” ìƒíƒœë¥¼ LLMì˜ ìƒíƒœì™€ êµì°¨ ëª¨ë‹¬ ì£¼ì˜ë¥¼ í†µí•´ ìœµí•©í•˜ê³ , ì˜¤í”„ë¼ì¸ ë° ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œë¥¼ ëª¨ë‘ ì§€ì›í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” \textit{VoxKrikri}, ìµœì´ˆì˜ ê·¸ë¦¬ìŠ¤ì–´ ìŒì„± LLMì„ ì†Œê°œí•˜ë©°, ë¶„ì„ì„ í†µí•´ ìš°ë¦¬ì˜ ì ‘ê·¼ ë°©ì‹ì´ ëª¨ë‹¬ë¦¬í‹° ê°„ í‘œí˜„ì„ íš¨ê³¼ì ìœ¼ë¡œ ì •ë ¬í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŸ¬í•œ ê²°ê³¼ëŠ” ë‹¤êµ­ì–´ ë° ì €ìì› ìŒì„± LLMì„ ìœ„í•œ ìœ ë§í•œ ê²½ë¡œë¡œì„œ ì—°ì† ê³µê°„ ìœµí•©ì„ ê°•ì¡°í•˜ë©°, ê·¸ë¦¬ìŠ¤ì–´ ìë™ ìŒì„± ì¸ì‹ì—ì„œ ìµœì²¨ë‹¨ ê²°ê³¼ë¥¼ ë‹¬ì„±í•˜ì—¬ ë²¤ì¹˜ë§ˆí¬ ì „ë°˜ì— ê±¸ì³ í‰ê·  ì•½ 20%ì˜ ìƒëŒ€ì  ê°œì„ ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì‚¬ì „ í›ˆë ¨ëœ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ê³¼ ìŒì„± ì¸ì½”ë”-ë””ì½”ë” êµ¬ì¡°ë¥¼ ì—°ê²°í•˜ëŠ” ë‹¤ì¤‘ ëª¨ë‹¬ ìœµí•© í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì˜¤ë””ì˜¤ ì„ë² ë”© ëŒ€ì‹  ì˜¤ë””ì˜¤ ì¡°ê±´ë¶€ í…ìŠ¤íŠ¸ ê³µê°„ì„ í™œìš©í•˜ì—¬ ë” íš¨ê³¼ì ì¸ ì •ë ¬ì„ ì‹œë„í•©ë‹ˆë‹¤. Whisperì˜ ìˆ¨ê²¨ì§„ ë””ì½”ë” ìƒíƒœì™€ LLMì˜ ìƒíƒœë¥¼ êµì°¨ ëª¨ë‹¬ ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ìœ¼ë¡œ ê²°í•©í•˜ì—¬ ì—°ì†ì ì¸ í…ìŠ¤íŠ¸ í‘œí˜„ ê³µê°„ì—ì„œ ì‘ë™í•˜ë©°, ì˜¤í”„ë¼ì¸ ë° ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œë¥¼ ì§€ì›í•©ë‹ˆë‹¤. ì´ ë°©ë²•ë¡ ì„ í†µí•´ ìµœì´ˆì˜ ê·¸ë¦¬ìŠ¤ì–´ ìŒì„± LLMì¸ \textit{VoxKrikri}ë¥¼ ì†Œê°œí•˜ë©°, ë‹¤ì¤‘ ì–¸ì–´ ë° ì €ìì› ìŒì„± LLMì— ëŒ€í•œ ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ê·¸ë¦¬ìŠ¤ì–´ ìë™ ìŒì„± ì¸ì‹ì—ì„œ ìµœì²¨ë‹¨ ê²°ê³¼ë¥¼ ë‹¬ì„±í•˜ë©°, í‰ê·  ì•½ 20%ì˜ ìƒëŒ€ì  ì„±ëŠ¥ í–¥ìƒì„ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë³¸ ì—°êµ¬ëŠ” ì‚¬ì „ í›ˆë ¨ëœ ë””ì½”ë” ê¸°ë°˜ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ê³¼ Whisperì™€ ê°™ì€ ìŒí–¥ ì¸ì½”ë”-ë””ì½”ë” ì•„í‚¤í…ì²˜ë¥¼ ì—°ê²°í•˜ëŠ” ë‹¤ì¤‘ ëª¨ë‹¬ ìœµí•© í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.
- 2. ì˜¤ë””ì˜¤ ì„ë² ë”©ì„ ì§ì ‘ ì‚¬ìš©í•˜ì§€ ì•Šê³ , ì˜¤ë””ì˜¤ ì¡°ê±´ë¶€ í…ìŠ¤íŠ¸ ê³µê°„ì„ í†µí•´ ë” íš¨ê³¼ì ì¸ ì •ë ¬ ë©”ì»¤ë‹ˆì¦˜ì„ íƒìƒ‰í•©ë‹ˆë‹¤.
- 3. Whisperì˜ ìˆ¨ê²¨ì§„ ë””ì½”ë” ìƒíƒœì™€ LLMì˜ ìƒíƒœë¥¼ êµì°¨ ëª¨ë‹¬ ì£¼ì˜ë¥¼ í†µí•´ ìœµí•©í•˜ì—¬ ì—°ì† í…ìŠ¤íŠ¸ í‘œí˜„ ê³µê°„ì—ì„œ ì‘ë™í•˜ë©°, ì˜¤í”„ë¼ì¸ ë° ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œë¥¼ ì§€ì›í•©ë‹ˆë‹¤.
- 4. ìµœì´ˆì˜ ê·¸ë¦¬ìŠ¤ì–´ ìŒì„± LLMì¸ \textit{VoxKrikri}ë¥¼ ì†Œê°œí•˜ë©°, ì œì•ˆëœ ì ‘ê·¼ ë°©ì‹ì´ ëª¨ë‹¬ë¦¬í‹° ê°„ í‘œí˜„ì„ íš¨ê³¼ì ìœ¼ë¡œ ì •ë ¬í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
- 5. ë³¸ ì—°êµ¬ëŠ” ê·¸ë¦¬ìŠ¤ì–´ ìë™ ìŒì„± ì¸ì‹ì—ì„œ ìµœì²¨ë‹¨ ì„±ê³¼ë¥¼ ë‹¬ì„±í•˜ë©°, ë²¤ì¹˜ë§ˆí¬ ì „ë°˜ì— ê±¸ì³ í‰ê·  ì•½ 20%ì˜ ìƒëŒ€ì  ê°œì„ ì„ ì œê³µí•©ë‹ˆë‹¤.


---

*Generated on 2025-09-23 11:32:38*