---
keywords:
  - Speaker Embeddings
  - Voice Conversion
  - Prosodic Expressiveness
  - Sub-Center Modeling
category: cs.LG
publish_date: 2025-09-22
arxiv_id: 2407.04291
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:15:01.802202",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Speaker Embeddings",
    "Voice Conversion",
    "Prosodic Expressiveness",
    "Sub-Center Modeling"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Speaker Embeddings": 0.75,
    "Voice Conversion": 0.8,
    "Prosodic Expressiveness": 0.78,
    "Sub-Center Modeling": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Speaker Embeddings",
        "canonical": "Speaker Embeddings",
        "aliases": [
          "Speaker Representation",
          "Voice Embeddings"
        ],
        "category": "unique_technical",
        "rationale": "Speaker embeddings are central to the paper's approach and are unique in the context of speech generation.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      },
      {
        "surface": "Voice Conversion",
        "canonical": "Voice Conversion",
        "aliases": [
          "Speech Conversion",
          "Voice Transformation"
        ],
        "category": "specific_connectable",
        "rationale": "Voice conversion is a specific application area that links to broader speech synthesis research.",
        "novelty_score": 0.65,
        "connectivity_score": 0.78,
        "specificity_score": 0.72,
        "link_intent_score": 0.8
      },
      {
        "surface": "Prosodic Expressiveness",
        "canonical": "Prosodic Expressiveness",
        "aliases": [
          "Prosody Variations",
          "Speech Prosody"
        ],
        "category": "unique_technical",
        "rationale": "Prosodic expressiveness is a unique aspect of speech that the paper aims to enhance, crucial for naturalness in speech synthesis.",
        "novelty_score": 0.72,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Sub-Center Modeling",
        "canonical": "Sub-Center Modeling",
        "aliases": [
          "Multi-Center Embeddings",
          "Sub-Center Approach"
        ],
        "category": "unique_technical",
        "rationale": "Sub-center modeling is a novel approach proposed in the paper, enhancing the capturing of intra-speaker diversity.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.9,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "experiment"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Speaker Embeddings",
      "resolved_canonical": "Speaker Embeddings",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Voice Conversion",
      "resolved_canonical": "Voice Conversion",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.78,
        "specificity": 0.72,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Prosodic Expressiveness",
      "resolved_canonical": "Prosodic Expressiveness",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Sub-Center Modeling",
      "resolved_canonical": "Sub-Center Modeling",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.9,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Rethinking Speaker Embeddings for Speech Generation: Sub-Center Modeling for Capturing Intra-Speaker Diversity

**Korean Title:** í™”ì ì„ë² ë”©ì˜ ì¬ê³ ë¥¼ í†µí•œ ìŒì„± ìƒì„±: í™”ì ë‚´ ë‹¤ì–‘ì„±ì„ í¬ì°©í•˜ê¸° ìœ„í•œ ì„œë¸Œì„¼í„° ëª¨ë¸ë§

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2407.04291.pdf)
**Category**: cs.LG
**Published**: 2025-09-22
**ArXiv ID**: [2407.04291](https://arxiv.org/abs/2407.04291)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/Mitigating Intra-Speaker Variability in Diarization with Style-Controllable Speech Augmentation_20250918|Mitigating Intra-Speaker Variability in Diarization with Style-Controllable Speech Augmentation]] (84.9% similar)
- [[2025-09-19/Towards Human-like Multimodal Conversational Agent by Generating Engaging Speech_20250919|Towards Human-like Multimodal Conversational Agent by Generating Engaging Speech]] (81.0% similar)
- [[2025-09-22/The Impact of Automatic Speech Transcription on Speaker Attribution_20250922|The Impact of Automatic Speech Transcription on Speaker Attribution]] (80.0% similar)
- [[2025-09-22/Impact of Phonetics on Speaker Identity in Adversarial Voice Attack_20250922|Impact of Phonetics on Speaker Identity in Adversarial Voice Attack]] (79.8% similar)
- [[2025-09-22/P2VA_ Converting Persona Descriptions into Voice Attributes for Fair and Controllable Text-to-Speech_20250922|P2VA: Converting Persona Descriptions into Voice Attributes for Fair and Controllable Text-to-Speech]] (79.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Voice Conversion|Voice Conversion]]
**âš¡ Unique Technical**: [[keywords/Speaker Embeddings|Speaker Embeddings]], [[keywords/Prosodic Expressiveness|Prosodic Expressiveness]], [[keywords/Sub-Center Modeling|Sub-Center Modeling]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2407.04291v3 Announce Type: replace-cross 
Abstract: Modeling the rich prosodic variations inherent in human speech is essential for generating natural-sounding speech. While speaker embeddings are commonly used as conditioning inputs in personalized speech generation, they are typically optimized for speaker recognition, which encourages the loss of intra-speaker variation. This strategy makes them suboptimal for speech generation in terms of modeling the rich variations at the output speech distribution. In this work, we propose a novel speaker embedding network that employs multiple sub-centers per speaker class during training, instead of a single center as in conventional approaches. This sub-center modeling allows the embedding to capture a broader range of speaker-specific variations while maintaining speaker classification performance. We demonstrate the effectiveness of the proposed embeddings on a voice conversion task, showing improved naturalness and prosodic expressiveness in the synthesized speech.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2407.04291v3 ë°œí‘œ ìœ í˜•: êµì°¨ êµì²´  
ì´ˆë¡: ì¸ê°„ ìŒì„±ì— ë‚´ì¬ëœ í’ë¶€í•œ ìš´ìœ¨ ë³€í™”ë¥¼ ëª¨ë¸ë§í•˜ëŠ” ê²ƒì€ ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„±ì„ ìƒì„±í•˜ê¸° ìœ„í•´ í•„ìˆ˜ì ì…ë‹ˆë‹¤. í™”ì ì„ë² ë”©ì€ ê°œì¸í™”ëœ ìŒì„± ìƒì„±ì—ì„œ ì¡°ê±´ ì…ë ¥ìœ¼ë¡œ ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©ë˜ì§€ë§Œ, ì´ëŠ” ì¼ë°˜ì ìœ¼ë¡œ í™”ì ì¸ì‹ì„ ìœ„í•´ ìµœì í™”ë˜ì–´ ìˆì–´ í™”ì ë‚´ ë³€í™”ë¥¼ ìƒê²Œ ë§Œë“­ë‹ˆë‹¤. ì´ëŸ¬í•œ ì „ëµì€ ì¶œë ¥ ìŒì„± ë¶„í¬ì—ì„œì˜ í’ë¶€í•œ ë³€í™”ë¥¼ ëª¨ë¸ë§í•˜ëŠ” ì¸¡ë©´ì—ì„œ ìŒì„± ìƒì„±ì— ë¹„íš¨ìœ¨ì ì…ë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” ê¸°ì¡´ ì ‘ê·¼ ë°©ì‹ì—ì„œì˜ ë‹¨ì¼ ì¤‘ì‹¬ ëŒ€ì‹ , í›ˆë ¨ ì¤‘ í™”ì í´ë˜ìŠ¤ë‹¹ ì—¬ëŸ¬ í•˜ìœ„ ì¤‘ì‹¬ì„ ì‚¬ìš©í•˜ëŠ” ìƒˆë¡œìš´ í™”ì ì„ë² ë”© ë„¤íŠ¸ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ëŸ¬í•œ í•˜ìœ„ ì¤‘ì‹¬ ëª¨ë¸ë§ì€ í™”ì ë¶„ë¥˜ ì„±ëŠ¥ì„ ìœ ì§€í•˜ë©´ì„œë„ í™”ì ê³ ìœ ì˜ ë‹¤ì–‘í•œ ë³€í™”ë¥¼ í¬ì°©í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì œì•ˆëœ ì„ë² ë”©ì˜ íš¨ê³¼ë¥¼ ìŒì„± ë³€í™˜ ì‘ì—…ì—ì„œ ì…ì¦í•˜ì˜€ìœ¼ë©°, í•©ì„±ëœ ìŒì„±ì—ì„œ ìì—°ìŠ¤ëŸ¬ì›€ê³¼ ìš´ìœ¨ í‘œí˜„ë ¥ì´ í–¥ìƒë¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì¸ê°„ ìŒì„±ì˜ ë‹¤ì–‘í•œ ìš´ìœ¨ ë³€í™”ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ëª¨ë¸ë§í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ í™”ì ì„ë² ë”© ë„¤íŠ¸ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ í™”ì ì„ë² ë”©ì€ í™”ì ì¸ì‹ì— ìµœì í™”ë˜ì–´ ìˆì–´ í™”ì ë‚´ ë³€ì´ì„±ì„ ìƒê¸° ì‰½ìŠµë‹ˆë‹¤. ì´ë¥¼ ê°œì„ í•˜ê¸° ìœ„í•´, ë³¸ ì—°êµ¬ëŠ” í™”ì í´ë˜ìŠ¤ë‹¹ ì—¬ëŸ¬ í•˜ìœ„ ì¤‘ì‹¬ì„ ì‚¬ìš©í•˜ëŠ” ë„¤íŠ¸ì›Œí¬ë¥¼ ë„ì…í•˜ì—¬ ë” ë„“ì€ ë²”ìœ„ì˜ í™”ì íŠ¹ìœ  ë³€ì´ë¥¼ í¬ì°©í•©ë‹ˆë‹¤. ì œì•ˆëœ ì„ë² ë”©ì€ ìŒì„± ë³€í™˜ ì‘ì—…ì—ì„œ ìì—°ìŠ¤ëŸ¬ì›€ê³¼ ìš´ìœ¨ í‘œí˜„ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì¸ê°„ ìŒì„±ì˜ í’ë¶€í•œ ìš´ìœ¨ ë³€í™”ë¥¼ ëª¨ë¸ë§í•˜ëŠ” ê²ƒì€ ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„± ìƒì„±ì„ ìœ„í•´ í•„ìˆ˜ì ì´ë‹¤.
- 2. ê¸°ì¡´ì˜ í™”ì ì„ë² ë”©ì€ í™”ì ì¸ì‹ì„ ìœ„í•´ ìµœì í™”ë˜ì–´ ìˆì–´ í™”ì ë‚´ ë³€ì´ ì†ì‹¤ì„ ì´ˆë˜í•œë‹¤.
- 3. ë³¸ ì—°êµ¬ì—ì„œëŠ” í™”ì í´ë˜ìŠ¤ë‹¹ ì—¬ëŸ¬ ê°œì˜ í•˜ìœ„ ì¤‘ì‹¬ì„ ì‚¬ìš©í•˜ëŠ” ìƒˆë¡œìš´ í™”ì ì„ë² ë”© ë„¤íŠ¸ì›Œí¬ë¥¼ ì œì•ˆí•œë‹¤.
- 4. ì œì•ˆëœ ì„ë² ë”©ì€ í™”ì ë¶„ë¥˜ ì„±ëŠ¥ì„ ìœ ì§€í•˜ë©´ì„œ í™”ì íŠ¹ìœ ì˜ ë‹¤ì–‘í•œ ë³€ì´ë¥¼ í¬ì°©í•  ìˆ˜ ìˆë‹¤.
- 5. ìŒì„± ë³€í™˜ ì‘ì—…ì—ì„œ ì œì•ˆëœ ì„ë² ë”©ì˜ íš¨ê³¼ë¥¼ ì…ì¦í•˜ë©°, í•©ì„±ëœ ìŒì„±ì˜ ìì—°ìŠ¤ëŸ¬ì›€ê³¼ ìš´ìœ¨ í‘œí˜„ë ¥ì´ í–¥ìƒë˜ì—ˆë‹¤.


---

*Generated on 2025-09-23 11:15:01*