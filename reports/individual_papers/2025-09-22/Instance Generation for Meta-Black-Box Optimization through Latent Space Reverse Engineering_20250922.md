---
keywords:
  - Meta-Black-Box Optimization
  - Latent Space Reverse Engineering
  - Neural Network
  - Autoencoder
  - Genetic Programming
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2509.15810
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T09:16:13.737821",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Meta-Black-Box Optimization",
    "Latent Space Reverse Engineering",
    "Neural Network",
    "Autoencoder",
    "Genetic Programming"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Meta-Black-Box Optimization": 0.78,
    "Latent Space Reverse Engineering": 0.82,
    "Neural Network": 0.75,
    "Autoencoder": 0.7,
    "Genetic Programming": 0.68
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Meta-Black-Box Optimization",
        "canonical": "Meta-Black-Box Optimization",
        "aliases": [
          "MetaBBO"
        ],
        "category": "unique_technical",
        "rationale": "This is a specialized optimization approach central to the paper's methodology.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Latent Space Reverse Engineering",
        "canonical": "Latent Space Reverse Engineering",
        "aliases": [
          "LSRE"
        ],
        "category": "unique_technical",
        "rationale": "The paper introduces LSRE as a novel method for generating diverse problem instances.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.88,
        "link_intent_score": 0.82
      },
      {
        "surface": "Neural Network",
        "canonical": "Neural Network",
        "aliases": [],
        "category": "broad_technical",
        "rationale": "Neural networks are fundamental to the meta-learning approach discussed in the paper.",
        "novelty_score": 0.4,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.75
      },
      {
        "surface": "Autoencoder",
        "canonical": "Autoencoder",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Autoencoders are used for mapping problem features into latent space, crucial for LSRE.",
        "novelty_score": 0.55,
        "connectivity_score": 0.78,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      },
      {
        "surface": "Genetic Programming",
        "canonical": "Genetic Programming",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Genetic programming is employed to search function formulas, integral to the LSRE approach.",
        "novelty_score": 0.5,
        "connectivity_score": 0.72,
        "specificity_score": 0.75,
        "link_intent_score": 0.68
      }
    ],
    "ban_list_suggestions": [
      "benchmark suites",
      "training problem set",
      "generalization performances"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Meta-Black-Box Optimization",
      "resolved_canonical": "Meta-Black-Box Optimization",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Latent Space Reverse Engineering",
      "resolved_canonical": "Latent Space Reverse Engineering",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.88,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Neural Network",
      "resolved_canonical": "Neural Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Autoencoder",
      "resolved_canonical": "Autoencoder",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.78,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Genetic Programming",
      "resolved_canonical": "Genetic Programming",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.72,
        "specificity": 0.75,
        "link_intent": 0.68
      }
    }
  ]
}
-->

# Instance Generation for Meta-Black-Box Optimization through Latent Space Reverse Engineering

**Korean Title:** 잠재 공간 역공학을 통한 메타 블랙박스 최적화를 위한 인스턴스 생성

## 📋 메타데이터

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15810.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2509.15810](https://arxiv.org/abs/2509.15810)

## 🔗 유사한 논문
- [[2025-09-22/Creative Preference Optimization_20250922|Creative Preference Optimization]] (80.7% similar)
- [[2025-09-19/Constructive Conflict-Driven Multi-Agent Reinforcement Learning for Strategic Diversity_20250919|Constructive Conflict-Driven Multi-Agent Reinforcement Learning for Strategic Diversity]] (79.9% similar)
- [[2025-09-19/Multi-Fidelity Hybrid Reinforcement Learning via Information Gain Maximization_20250919|Multi-Fidelity Hybrid Reinforcement Learning via Information Gain Maximization]] (79.6% similar)
- [[2025-09-22/Deep Reinforcement Learning with Gradient Eligibility Traces_20250922|Deep Reinforcement Learning with Gradient Eligibility Traces]] (79.4% similar)
- [[2025-09-22/Nonconvex Regularization for Feature Selection in Reinforcement Learning_20250922|Nonconvex Regularization for Feature Selection in Reinforcement Learning]] (79.4% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Neural Network|Neural Network]]
**🔗 Specific Connectable**: [[keywords/Autoencoder|Autoencoder]], [[keywords/Genetic Programming|Genetic Programming]]
**⚡ Unique Technical**: [[keywords/Meta-Black-Box Optimization|Meta-Black-Box Optimization]], [[keywords/Latent Space Reverse Engineering|Latent Space Reverse Engineering]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.15810v1 Announce Type: cross 
Abstract: To relieve intensive human-expertise required to design optimization algorithms, recent Meta-Black-Box Optimization (MetaBBO) researches leverage generalization strength of meta-learning to train neural network-based algorithm design policies over a predefined training problem set, which automates the adaptability of the low-level optimizers on unseen problem instances. Currently, a common training problem set choice in existing MetaBBOs is well-known benchmark suites CoCo-BBOB. Although such choice facilitates the MetaBBO's development, problem instances in CoCo-BBOB are more or less limited in diversity, raising the risk of overfitting of MetaBBOs, which might further results in poor generalization. In this paper, we propose an instance generation approach, termed as \textbf{LSRE}, which could generate diverse training problem instances for MetaBBOs to learn more generalizable policies. LSRE first trains an autoencoder which maps high-dimensional problem features into a 2-dimensional latent space. Uniform-grid sampling in this latent space leads to hidden representations of problem instances with sufficient diversity. By leveraging a genetic-programming approach to search function formulas with minimal L2-distance to these hidden representations, LSRE reverse engineers a diversified problem set, termed as \textbf{Diverse-BBO}. We validate the effectiveness of LSRE by training various MetaBBOs on Diverse-BBO and observe their generalization performances on either synthetic or realistic scenarios. Extensive experimental results underscore the superiority of Diverse-BBO to existing training set choices in MetaBBOs. Further ablation studies not only demonstrate the effectiveness of design choices in LSRE, but also reveal interesting insights on instance diversity and MetaBBO's generalization.

## 🔍 Abstract (한글 번역)

arXiv:2509.15810v1 발표 유형: 교차  
초록: 최적화 알고리즘 설계에 필요한 집중적인 인간 전문 지식을 완화하기 위해, 최근의 메타 블랙박스 최적화(MetaBBO) 연구는 메타 학습의 일반화 능력을 활용하여 사전 정의된 훈련 문제 세트에서 신경망 기반 알고리즘 설계 정책을 훈련함으로써 미지의 문제 인스턴스에 대한 저수준 최적화기의 적응성을 자동화합니다. 현재 기존 MetaBBO에서 일반적인 훈련 문제 세트 선택은 잘 알려진 벤치마크 모음인 CoCo-BBOB입니다. 이러한 선택은 MetaBBO의 개발을 촉진하지만, CoCo-BBOB의 문제 인스턴스는 다양성이 다소 제한되어 있어 MetaBBO의 과적합 위험을 증가시키며, 이는 일반화 성능 저하로 이어질 수 있습니다. 본 논문에서는 MetaBBO가 보다 일반화 가능한 정책을 학습할 수 있도록 다양한 훈련 문제 인스턴스를 생성할 수 있는 \textbf{LSRE}라는 인스턴스 생성 접근 방식을 제안합니다. LSRE는 먼저 고차원 문제 특징을 2차원 잠재 공간으로 매핑하는 오토인코더를 훈련합니다. 이 잠재 공간에서의 균일 격자 샘플링은 충분한 다양성을 가진 문제 인스턴스의 숨겨진 표현을 이끌어냅니다. 유전 프로그래밍 접근 방식을 활용하여 이러한 숨겨진 표현과 최소 L2 거리의 함수 공식을 검색함으로써, LSRE는 \textbf{Diverse-BBO}라는 다양한 문제 세트를 역설계합니다. Diverse-BBO에서 다양한 MetaBBO를 훈련하고, 이를 통해 합성 또는 현실적인 시나리오에서의 일반화 성능을 관찰함으로써 LSRE의 효과를 검증합니다. 광범위한 실험 결과는 MetaBBO의 기존 훈련 세트 선택에 비해 Diverse-BBO의 우수성을 강조합니다. 추가적인 소거 연구는 LSRE의 설계 선택의 효과를 입증할 뿐만 아니라 인스턴스 다양성과 MetaBBO의 일반화에 대한 흥미로운 통찰을 제공합니다.

## 📝 요약

이 논문은 메타 블랙박스 최적화(MetaBBO) 알고리즘의 일반화 성능을 향상시키기 위해 다양한 문제 인스턴스를 생성하는 LSRE 방법을 제안합니다. 기존의 MetaBBO는 CoCo-BBOB 벤치마크를 사용하여 훈련하지만, 이는 다양성이 부족하여 과적합 위험이 있습니다. LSRE는 고차원 문제 특징을 2차원 잠재 공간으로 매핑하는 오토인코더를 사용해 다양한 문제 인스턴스를 생성합니다. 이 방법으로 생성된 Diverse-BBO 문제 세트는 다양한 MetaBBO 알고리즘의 일반화 성능을 향상시킵니다. 실험 결과, Diverse-BBO가 기존 훈련 세트보다 우수한 성능을 보였으며, LSRE의 설계 선택이 효과적임을 입증했습니다.

## 🎯 주요 포인트

- 1. MetaBBO는 메타러닝을 활용하여 신경망 기반 알고리즘 설계 정책을 훈련함으로써 새로운 문제에 대한 적응성을 자동화한다.
- 2. 기존 MetaBBO의 훈련 문제 세트는 CoCo-BBOB 벤치마크를 사용하지만, 이는 다양성이 제한되어 있어 과적합 위험이 있다.
- 3. LSRE는 문제 인스턴스를 다양하게 생성하여 MetaBBO가 일반화 가능한 정책을 학습할 수 있도록 돕는다.
- 4. LSRE는 고차원 문제 특징을 2차원 잠재 공간으로 매핑하는 오토인코더를 활용하여 다양한 문제 인스턴스를 생성한다.
- 5. 실험 결과, Diverse-BBO는 기존의 훈련 세트보다 MetaBBO의 일반화 성능을 향상시키는 데 효과적임을 보여준다.


---

*Generated on 2025-09-23 09:16:13*