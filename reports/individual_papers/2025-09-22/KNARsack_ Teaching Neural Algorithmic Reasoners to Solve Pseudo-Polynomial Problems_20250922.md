# KNARsack: Teaching Neural Algorithmic Reasoners to Solve Pseudo-Polynomial Problems

**Korean Title:** KNARsack: ì‹ ê²½ ì•Œê³ ë¦¬ì¦˜ ì¶”ë¡ ìë¥¼ ê°€ë¥´ì³ ì˜ì‚¬ë‹¤í•­ì‹ ë¬¸ì œ í•´ê²°í•˜ê¸°

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Pseudo-Polynomial Problem Solving

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/Polynomial-Time Approximation Schemes via Utility Alignment_ Unit-Demand Pricing and More_20250918|Polynomial-Time Approximation Schemes via Utility Alignment Unit-Demand Pricing and More]] (77.3% similar)
- [[2025-09-19/Scalable Multi-Objective Robot Reinforcement Learning through Gradient Conflict Resolution_20250919|Scalable Multi-Objective Robot Reinforcement Learning through Gradient Conflict Resolution]] (77.3% similar)
- [[2025-09-18/Data-Driven Distributed Optimization via Aggregative Tracking and Deep-Learning_20250918|Data-Driven Distributed Optimization via Aggregative Tracking and Deep-Learning]] (77.2% similar)
- [[2025-09-19/RationAnomaly_ Log Anomaly Detection with Rationality via Chain-of-Thought and Reinforcement Learning_20250919|RationAnomaly Log Anomaly Detection with Rationality via Chain-of-Thought and Reinforcement Learning]] (77.1% similar)
- [[2025-09-18/Stochastic Bilevel Optimization with Heavy-Tailed Noise_20250918|Stochastic Bilevel Optimization with Heavy-Tailed Noise]] (77.0% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15239v1 Announce Type: new 
Abstract: Neural algorithmic reasoning (NAR) is a growing field that aims to embed algorithmic logic into neural networks by imitating classical algorithms. In this extended abstract, we detail our attempt to build a neural algorithmic reasoner that can solve Knapsack, a pseudo-polynomial problem bridging classical algorithms and combinatorial optimisation, but omitted in standard NAR benchmarks. Our neural algorithmic reasoner is designed to closely follow the two-phase pipeline for the Knapsack problem, which involves first constructing the dynamic programming table and then reconstructing the solution from it. The approach, which models intermediate states through dynamic programming supervision, achieves better generalization to larger problem instances than a direct-prediction baseline that attempts to select the optimal subset only from the problem inputs.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15239v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: ì‹ ê²½ ì•Œê³ ë¦¬ì¦˜ì  ì¶”ë¡ (NAR)ì€ ê³ ì „ ì•Œê³ ë¦¬ì¦˜ì„ ëª¨ë°©í•˜ì—¬ ì•Œê³ ë¦¬ì¦˜ì  ë…¼ë¦¬ë¥¼ ì‹ ê²½ë§ì— ë‚´ì¬í™”í•˜ë ¤ëŠ” ì„±ì¥í•˜ëŠ” ë¶„ì•¼ì…ë‹ˆë‹¤. ì´ í™•ì¥ëœ ì´ˆë¡ì—ì„œëŠ” ê³ ì „ ì•Œê³ ë¦¬ì¦˜ê³¼ ì¡°í•© ìµœì í™”ë¥¼ ì—°ê²°í•˜ëŠ” ì˜ì‚¬ë‹¤í•­ì‹ ë¬¸ì œì¸ ë°°ë‚­ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆëŠ” ì‹ ê²½ ì•Œê³ ë¦¬ì¦˜ ì¶”ë¡ ê¸°ë¥¼ êµ¬ì¶•í•˜ë ¤ëŠ” ì‹œë„ë¥¼ ìì„¸íˆ ì„¤ëª…í•©ë‹ˆë‹¤. ì´ ë¬¸ì œëŠ” í‘œì¤€ NAR ë²¤ì¹˜ë§ˆí¬ì—ì„œëŠ” ìƒëµë˜ì—ˆìŠµë‹ˆë‹¤. ìš°ë¦¬ì˜ ì‹ ê²½ ì•Œê³ ë¦¬ì¦˜ ì¶”ë¡ ê¸°ëŠ” ë°°ë‚­ ë¬¸ì œì— ëŒ€í•œ ë‘ ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ì„ ë°€ì ‘í•˜ê²Œ ë”°ë¥´ë„ë¡ ì„¤ê³„ë˜ì—ˆìœ¼ë©°, ì—¬ê¸°ì—ëŠ” ë¨¼ì € ë™ì  í”„ë¡œê·¸ë˜ë° í…Œì´ë¸”ì„ êµ¬ì„±í•œ ë‹¤ìŒ ê·¸ë¡œë¶€í„° í•´ë¥¼ ì¬êµ¬ì„±í•˜ëŠ” ê³¼ì •ì´ í¬í•¨ë©ë‹ˆë‹¤. ì¤‘ê°„ ìƒíƒœë¥¼ ë™ì  í”„ë¡œê·¸ë˜ë° ê°ë…ì„ í†µí•´ ëª¨ë¸ë§í•˜ëŠ” ì´ ì ‘ê·¼ ë°©ì‹ì€ ë¬¸ì œ ì…ë ¥ì—ì„œ ìµœì ì˜ ë¶€ë¶„ ì§‘í•©ì„ ì„ íƒí•˜ë ¤ëŠ” ì§ì ‘ ì˜ˆì¸¡ ê¸°ì¤€ì„ ë³´ë‹¤ ë” í° ë¬¸ì œ ì¸ìŠ¤í„´ìŠ¤ì— ëŒ€í•œ ì¼ë°˜í™” ì„±ëŠ¥ì´ ë›°ì–´ë‚©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì‹ ê²½ ì•Œê³ ë¦¬ì¦˜ì  ì¶”ë¡ (NAR)ì„ í™œìš©í•˜ì—¬ ë°°ë‚­ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ì‹ ê²½ ì•Œê³ ë¦¬ì¦˜ ì¶”ë¡ ê¸°ë¥¼ ê°œë°œí•˜ëŠ” ì—°êµ¬ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. ë°°ë‚­ ë¬¸ì œëŠ” ì „í†µì ì¸ ì•Œê³ ë¦¬ì¦˜ê³¼ ì¡°í•© ìµœì í™” ë¬¸ì œë¥¼ ì—°ê²°í•˜ëŠ” ì˜ì‚¬ë‹¤í•­ì‹ ë¬¸ì œë¡œ, ê¸°ì¡´ NAR ë²¤ì¹˜ë§ˆí¬ì—ì„œëŠ” ë‹¤ë£¨ì–´ì§€ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì—°êµ¬ì§„ì€ ë°°ë‚­ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë™ì  í”„ë¡œê·¸ë˜ë° í…Œì´ë¸”ì„ êµ¬ì„±í•˜ê³  ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì†”ë£¨ì…˜ì„ ì¬êµ¬ì„±í•˜ëŠ” ë‘ ë‹¨ê³„ì˜ íŒŒì´í”„ë¼ì¸ì„ ë”°ë¥´ëŠ” ì‹ ê²½ ì•Œê³ ë¦¬ì¦˜ ì¶”ë¡ ê¸°ë¥¼ ì„¤ê³„í–ˆìŠµë‹ˆë‹¤. ì´ ë°©ë²•ë¡ ì€ ë¬¸ì œ ì…ë ¥ë§Œìœ¼ë¡œ ìµœì  ë¶€ë¶„ì§‘í•©ì„ ì„ íƒí•˜ë ¤ëŠ” ì§ì ‘ ì˜ˆì¸¡ ë°©ì‹ë³´ë‹¤ ë” í° ë¬¸ì œ ì‚¬ë¡€ì— ëŒ€í•œ ì¼ë°˜í™” ì„±ëŠ¥ì´ ìš°ìˆ˜í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì‹ ê²½ ì•Œê³ ë¦¬ì¦˜ì  ì¶”ë¡ (NAR)ì€ ê³ ì „ ì•Œê³ ë¦¬ì¦˜ì„ ëª¨ë°©í•˜ì—¬ ì•Œê³ ë¦¬ì¦˜ì  ë…¼ë¦¬ë¥¼ ì‹ ê²½ë§ì— ë‚´ì¬í™”í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•˜ëŠ” ì„±ì¥í•˜ëŠ” ë¶„ì•¼ì…ë‹ˆë‹¤.

- 2. ë³¸ ì—°êµ¬ì—ì„œëŠ” Knapsack ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆëŠ” ì‹ ê²½ ì•Œê³ ë¦¬ì¦˜ì  ì¶”ë¡ ê¸°ë¥¼ êµ¬ì¶•í•˜ë ¤ëŠ” ì‹œë„ë¥¼ ìƒì„¸íˆ ì„¤ëª…í•©ë‹ˆë‹¤.

- 3. ì œì•ˆëœ ì‹ ê²½ ì•Œê³ ë¦¬ì¦˜ì  ì¶”ë¡ ê¸°ëŠ” ë™ì  í”„ë¡œê·¸ë˜ë° í…Œì´ë¸”ì„ êµ¬ì„±í•˜ê³  ì´ë¥¼ í†µí•´ ì†”ë£¨ì…˜ì„ ì¬êµ¬ì„±í•˜ëŠ” ë‘ ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ì„ ë”°ë¦…ë‹ˆë‹¤.

- 4. ë™ì  í”„ë¡œê·¸ë˜ë° ê°ë…ì„ í†µí•´ ì¤‘ê°„ ìƒíƒœë¥¼ ëª¨ë¸ë§í•˜ëŠ” ì ‘ê·¼ ë°©ì‹ì€ ë¬¸ì œ ì…ë ¥ë§Œìœ¼ë¡œ ìµœì ì˜ ë¶€ë¶„ì§‘í•©ì„ ì„ íƒí•˜ë ¤ëŠ” ì§ì ‘ ì˜ˆì¸¡ ê¸°ì¤€ë³´ë‹¤ ë” í° ë¬¸ì œ ì¸ìŠ¤í„´ìŠ¤ì— ëŒ€í•œ ì¼ë°˜í™” ì„±ëŠ¥ì´ ë›°ì–´ë‚©ë‹ˆë‹¤.

---

*Generated on 2025-09-22 13:42:28*