---
keywords:
  - Multimodal Learning
  - Sarcasm Detection
  - Zero-Shot Learning
  - Few-Shot Learning
  - Collaborative Gating Fusion
category: cs.CL
publish_date: 2025-09-22
arxiv_id: 2509.15476
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:28:56.724408",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multimodal Learning",
    "Sarcasm Detection",
    "Zero-Shot Learning",
    "Few-Shot Learning",
    "Collaborative Gating Fusion"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multimodal Learning": 0.82,
    "Sarcasm Detection": 0.79,
    "Zero-Shot Learning": 0.78,
    "Few-Shot Learning": 0.75,
    "Collaborative Gating Fusion": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multimodal Large Language Models",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal LLMs"
        ],
        "category": "specific_connectable",
        "rationale": "This term bridges the gap between language models and multimodal data, enhancing cross-disciplinary connections.",
        "novelty_score": 0.65,
        "connectivity_score": 0.88,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "Sarcasm Detection",
        "canonical": "Sarcasm Detection",
        "aliases": [
          "Sarcasm Understanding"
        ],
        "category": "unique_technical",
        "rationale": "A specific task within natural language processing that connects to sentiment analysis and emotion recognition.",
        "novelty_score": 0.72,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.79
      },
      {
        "surface": "Zero-Shot Learning",
        "canonical": "Zero-Shot Learning",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "A trending approach that allows models to generalize to tasks without task-specific data, linking to transfer learning.",
        "novelty_score": 0.6,
        "connectivity_score": 0.85,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Few-Shot Learning",
        "canonical": "Few-Shot Learning",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "This method is crucial for understanding model performance with limited data, connecting to data efficiency techniques.",
        "novelty_score": 0.58,
        "connectivity_score": 0.83,
        "specificity_score": 0.77,
        "link_intent_score": 0.75
      },
      {
        "surface": "Collaborative Gating Fusion Module",
        "canonical": "Collaborative Gating Fusion",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "A novel approach for integrating multimodal representations, enhancing model architecture discussions.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.82,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "performance",
      "method",
      "experimental results"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multimodal Large Language Models",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.88,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Sarcasm Detection",
      "resolved_canonical": "Sarcasm Detection",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Zero-Shot Learning",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.85,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Few-Shot Learning",
      "resolved_canonical": "Few-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.83,
        "specificity": 0.77,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Collaborative Gating Fusion Module",
      "resolved_canonical": "Collaborative Gating Fusion",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.82,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# Evaluating Multimodal Large Language Models on Spoken Sarcasm Understanding

**Korean Title:** êµ¬ì–´ì  í’ìì˜ ì´í•´ì— ëŒ€í•œ ë‹¤ì¤‘ ëª¨ë“œ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ í‰ê°€

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15476.pdf)
**Category**: cs.CL
**Published**: 2025-09-22
**ArXiv ID**: [2509.15476](https://arxiv.org/abs/2509.15476)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/It Depends_ Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge_20250922|It Depends: Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge]] (85.4% similar)
- [[2025-09-22/Fine-Tuning Large Multimodal Models for Automatic Pronunciation Assessment_20250922|Fine-Tuning Large Multimodal Models for Automatic Pronunciation Assessment]] (85.2% similar)
- [[2025-09-22/Predicting Language Models' Success at Zero-Shot Probabilistic Prediction_20250922|Predicting Language Models' Success at Zero-Shot Probabilistic Prediction]] (84.7% similar)
- [[2025-09-22/Pointing to a Llama and Call it a Camel_ On the Sycophancy of Multimodal Large Language Models_20250922|Pointing to a Llama and Call it a Camel: On the Sycophancy of Multimodal Large Language Models]] (84.3% similar)
- [[2025-09-19/Large Multi-modal Models Can Interpret Features in Large Multi-modal Models_20250919|Large Multi-modal Models Can Interpret Features in Large Multi-modal Models]] (84.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]], [[keywords/Zero-Shot Learning|Zero-Shot Learning]], [[keywords/Few-Shot Learning|Few-Shot Learning]]
**âš¡ Unique Technical**: [[keywords/Sarcasm Detection|Sarcasm Detection]], [[keywords/Collaborative Gating Fusion|Collaborative Gating Fusion]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15476v1 Announce Type: new 
Abstract: Sarcasm detection remains a challenge in natural language understanding, as sarcastic intent often relies on subtle cross-modal cues spanning text, speech, and vision. While prior work has primarily focused on textual or visual-textual sarcasm, comprehensive audio-visual-textual sarcasm understanding remains underexplored. In this paper, we systematically evaluate large language models (LLMs) and multimodal LLMs for sarcasm detection on English (MUStARD++) and Chinese (MCSD 1.0) in zero-shot, few-shot, and LoRA fine-tuning settings. In addition to direct classification, we explore models as feature encoders, integrating their representations through a collaborative gating fusion module. Experimental results show that audio-based models achieve the strongest unimodal performance, while text-audio and audio-vision combinations outperform unimodal and trimodal models. Furthermore, MLLMs such as Qwen-Omni show competitive zero-shot and fine-tuned performance. Our findings highlight the potential of MLLMs for cross-lingual, audio-visual-textual sarcasm understanding.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15476v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: í’ì ê°ì§€(sarcasm detection)ëŠ” ìì—°ì–´ ì´í•´ì—ì„œ ì—¬ì „íˆ ë„ì „ ê³¼ì œë¡œ ë‚¨ì•„ ìˆìœ¼ë©°, í’ìì  ì˜ë„ëŠ” ì¢…ì¢… í…ìŠ¤íŠ¸, ìŒì„±, ì‹œê°ì„ ì•„ìš°ë¥´ëŠ” ë¯¸ë¬˜í•œ ë‹¤ì¤‘ ëª¨ë‹¬ ë‹¨ì„œì— ì˜ì¡´í•©ë‹ˆë‹¤. ì´ì „ ì—°êµ¬ëŠ” ì£¼ë¡œ í…ìŠ¤íŠ¸ ë˜ëŠ” ì‹œê°-í…ìŠ¤íŠ¸ í’ìì— ì´ˆì ì„ ë§ì·„ìœ¼ë‚˜, í¬ê´„ì ì¸ ì˜¤ë””ì˜¤-ë¹„ì£¼ì–¼-í…ìŠ¤íŠ¸ í’ì ì´í•´ëŠ” ì—¬ì „íˆ ì¶©ë¶„íˆ íƒêµ¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì˜ì–´(MUStARD++)ì™€ ì¤‘êµ­ì–´(MCSD 1.0)ì— ëŒ€í•´ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLMs)ê³¼ ë‹¤ì¤‘ ëª¨ë‹¬ LLMsì„ ì œë¡œìƒ·(zero-shot), ëª‡ ìƒ·(few-shot), LoRA ë¯¸ì„¸ ì¡°ì • ì„¤ì •ì—ì„œ í’ì ê°ì§€ë¥¼ ìœ„í•´ ì²´ê³„ì ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤. ì§ì ‘ì ì¸ ë¶„ë¥˜ ì™¸ì—ë„, ìš°ë¦¬ëŠ” ëª¨ë¸ì„ íŠ¹ì§• ì¸ì½”ë”ë¡œ í™œìš©í•˜ì—¬ í˜‘ë ¥ì  ê²Œì´íŒ… ìœµí•© ëª¨ë“ˆì„ í†µí•´ ê·¸ë“¤ì˜ í‘œí˜„ì„ í†µí•©í•˜ëŠ” ë°©ë²•ì„ íƒêµ¬í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì˜¤ë””ì˜¤ ê¸°ë°˜ ëª¨ë¸ì´ ê°€ì¥ ê°•ë ¥í•œ ë‹¨ì¼ ëª¨ë‹¬ ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìœ¼ë©°, í…ìŠ¤íŠ¸-ì˜¤ë””ì˜¤ ë° ì˜¤ë””ì˜¤-ë¹„ì „ ì¡°í•©ì´ ë‹¨ì¼ ëª¨ë‹¬ ë° ì‚¼ì¤‘ ëª¨ë‹¬ ëª¨ë¸ì„ ëŠ¥ê°€í•˜ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤. ë˜í•œ, Qwen-Omniì™€ ê°™ì€ MLLMsì€ ê²½ìŸë ¥ ìˆëŠ” ì œë¡œìƒ· ë° ë¯¸ì„¸ ì¡°ì • ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì—°êµ¬ ê²°ê³¼ëŠ” MLLMsì´ êµì°¨ ì–¸ì–´, ì˜¤ë””ì˜¤-ë¹„ì£¼ì–¼-í…ìŠ¤íŠ¸ í’ì ì´í•´ì— ì ì¬ë ¥ì„ ê°€ì§€ê³  ìˆìŒì„ ê°•ì¡°í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ìì—°ì–´ ì´í•´ì—ì„œì˜ í’ì ê°ì§€ ë¬¸ì œë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. ê¸°ì¡´ ì—°êµ¬ëŠ” ì£¼ë¡œ í…ìŠ¤íŠ¸ë‚˜ ì‹œê°-í…ìŠ¤íŠ¸ í’ìì— ì§‘ì¤‘í–ˆì§€ë§Œ, ì´ ë…¼ë¬¸ì€ ì˜¤ë””ì˜¤-ë¹„ì£¼ì–¼-í…ìŠ¤íŠ¸ í’ì ì´í•´ë¥¼ íƒêµ¬í•©ë‹ˆë‹¤. ì˜ì–´ì™€ ì¤‘êµ­ì–´ ë°ì´í„°ì…‹ì—ì„œ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ê³¼ ë©€í‹°ëª¨ë‹¬ LLMì„ ì‚¬ìš©í•˜ì—¬ ì œë¡œìƒ·, í“¨ìƒ·, LoRA ë¯¸ì„¸ ì¡°ì • ì„¤ì •ì—ì„œ í’ì ê°ì§€ë¥¼ í‰ê°€í–ˆìŠµë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì˜¤ë””ì˜¤ ê¸°ë°˜ ëª¨ë¸ì´ ë‹¨ì¼ ëª¨ë‹¬ ì„±ëŠ¥ì—ì„œ ê°€ì¥ ìš°ìˆ˜í–ˆìœ¼ë©°, í…ìŠ¤íŠ¸-ì˜¤ë””ì˜¤ ë° ì˜¤ë””ì˜¤-ë¹„ì „ ì¡°í•©ì´ ë‹¨ì¼ ëª¨ë‹¬ ë° ì‚¼ì¤‘ ëª¨ë‹¬ ëª¨ë¸ë³´ë‹¤ ë›°ì–´ë‚¬ìŠµë‹ˆë‹¤. ë˜í•œ, MLLMì¸ Qwen-OmniëŠ” ê²½ìŸë ¥ ìˆëŠ” ì œë¡œìƒ· ë° ë¯¸ì„¸ ì¡°ì • ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ì—°êµ¬ëŠ” MLLMì˜ ë‹¤êµ­ì–´, ì˜¤ë””ì˜¤-ë¹„ì£¼ì–¼-í…ìŠ¤íŠ¸ í’ì ì´í•´ ê°€ëŠ¥ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ìì—°ì–´ ì´í•´ì—ì„œ í’ì ê°ì§€ì˜ ì–´ë ¤ì›€ì€ í…ìŠ¤íŠ¸, ìŒì„±, ì‹œê°ì„ ì•„ìš°ë¥´ëŠ” ë¯¸ë¬˜í•œ ë‹¨ì„œì— ì˜ì¡´í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.
- 2. ê¸°ì¡´ ì—°êµ¬ëŠ” ì£¼ë¡œ í…ìŠ¤íŠ¸ ë˜ëŠ” ì‹œê°-í…ìŠ¤íŠ¸ í’ìì— ì§‘ì¤‘í–ˆì§€ë§Œ, ì¢…í•©ì ì¸ ìŒì„±-ì‹œê°-í…ìŠ¤íŠ¸ í’ì ì´í•´ëŠ” ì¶©ë¶„íˆ íƒêµ¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.
- 3. ë³¸ ë…¼ë¬¸ì€ ì˜ì–´ì™€ ì¤‘êµ­ì–´ì—ì„œ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ê³¼ ë‹¤ì¤‘ ëª¨ë‹¬ LLMì„ í™œìš©í•˜ì—¬ í’ì ê°ì§€ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.
- 4. ì‹¤í—˜ ê²°ê³¼, ìŒì„± ê¸°ë°˜ ëª¨ë¸ì´ ê°€ì¥ ê°•ë ¥í•œ ë‹¨ì¼ ëª¨ë‹¬ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë©°, í…ìŠ¤íŠ¸-ìŒì„± ë° ìŒì„±-ì‹œê° ì¡°í•©ì´ ë‹¨ì¼ ëª¨ë‹¬ ë° ì‚¼ì¤‘ ëª¨ë‹¬ ëª¨ë¸ì„ ëŠ¥ê°€í–ˆìŠµë‹ˆë‹¤.
- 5. MLLMì€ êµì°¨ ì–¸ì–´, ìŒì„±-ì‹œê°-í…ìŠ¤íŠ¸ í’ì ì´í•´ì— ì ì¬ë ¥ì´ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.


---

*Generated on 2025-09-23 11:28:56*