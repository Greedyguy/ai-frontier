---
keywords:
  - Multimodal Learning
  - Sycophantic Modality Gap
  - Sycophantic Reflective Tuning
  - Large Language Model
  - Vision-Language Model
category: cs.CV
publish_date: 2025-09-22
arxiv_id: 2509.16149
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T12:22:44.061792",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multimodal Learning",
    "Sycophantic Modality Gap",
    "Sycophantic Reflective Tuning",
    "Large Language Model",
    "Vision-Language Model"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multimodal Learning": 0.85,
    "Sycophantic Modality Gap": 0.78,
    "Sycophantic Reflective Tuning": 0.8,
    "Large Language Model": 0.7,
    "Vision-Language Model": 0.82
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multimodal large language models",
        "canonical": "Multimodal Learning",
        "aliases": [
          "MLLMs"
        ],
        "category": "specific_connectable",
        "rationale": "Multimodal Learning is a trending area that connects vision and language, relevant for linking with Vision-Language Models.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.72,
        "link_intent_score": 0.85
      },
      {
        "surface": "Sycophantic modality gap",
        "canonical": "Sycophantic Modality Gap",
        "aliases": [
          "visual sycophantic behavior"
        ],
        "category": "unique_technical",
        "rationale": "This is a unique concept introduced in the paper, highlighting a specific issue in multimodal models.",
        "novelty_score": 0.92,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Sycophantic Reflective Tuning",
        "canonical": "Sycophantic Reflective Tuning",
        "aliases": [
          "SRT"
        ],
        "category": "unique_technical",
        "rationale": "A novel method proposed in the paper to address sycophantic behavior, offering a new angle for research.",
        "novelty_score": 0.95,
        "connectivity_score": 0.65,
        "specificity_score": 0.88,
        "link_intent_score": 0.8
      },
      {
        "surface": "Large language models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Essential for linking discussions on language models and their behaviors.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.7
      },
      {
        "surface": "Vision-Language Models",
        "canonical": "Vision-Language Model",
        "aliases": [],
        "category": "evolved_concepts",
        "rationale": "A key concept in understanding the integration of visual and textual data, relevant for multimodal discussions.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.75,
        "link_intent_score": 0.82
      }
    ],
    "ban_list_suggestions": [
      "naive supervised fine-tuning",
      "corrective instructions"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multimodal large language models",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.72,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Sycophantic modality gap",
      "resolved_canonical": "Sycophantic Modality Gap",
      "decision": "linked",
      "scores": {
        "novelty": 0.92,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Sycophantic Reflective Tuning",
      "resolved_canonical": "Sycophantic Reflective Tuning",
      "decision": "linked",
      "scores": {
        "novelty": 0.95,
        "connectivity": 0.65,
        "specificity": 0.88,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Large language models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Vision-Language Models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.75,
        "link_intent": 0.82
      }
    }
  ]
}
-->

# Pointing to a Llama and Call it a Camel: On the Sycophancy of Multimodal Large Language Models

**Korean Title:** ë¼ë§ˆë¥¼ ê°€ë¦¬í‚¤ë©° ë‚™íƒ€ë¼ê³  ë¶€ë¥´ê¸°: ë‹¤ì¤‘ ëª¨ë“œ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ ì•„ì²¨ì— ê´€í•˜ì—¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16149.pdf)
**Category**: cs.CV
**Published**: 2025-09-22
**ArXiv ID**: [2509.16149](https://arxiv.org/abs/2509.16149)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Beyond Spurious Signals_ Debiasing Multimodal Large Language Models via Counterfactual Inference and Adaptive Expert Routing_20250922|Beyond Spurious Signals: Debiasing Multimodal Large Language Models via Counterfactual Inference and Adaptive Expert Routing]] (86.4% similar)
- [[2025-09-22/Perception-R1_ Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward_20250922|Perception-R1: Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward]] (86.1% similar)
- [[2025-09-22/It Depends_ Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge_20250922|It Depends: Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge]] (86.0% similar)
- [[2025-09-22/RePIC_ Reinforced Post-Training for Personalizing Multi-Modal Language Models_20250922|RePIC: Reinforced Post-Training for Personalizing Multi-Modal Language Models]] (85.6% similar)
- [[2025-09-19/Decoupled Proxy Alignment_ Mitigating Language Prior Conflict for Multimodal Alignment in MLLM_20250919|Decoupled Proxy Alignment: Mitigating Language Prior Conflict for Multimodal Alignment in MLLM]] (84.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**âš¡ Unique Technical**: [[keywords/Sycophantic Modality Gap|Sycophantic Modality Gap]], [[keywords/Sycophantic Reflective Tuning|Sycophantic Reflective Tuning]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16149v1 Announce Type: new 
Abstract: Multimodal large language models (MLLMs) have demonstrated extraordinary capabilities in conducting conversations based on image inputs. However, we observe that MLLMs exhibit a pronounced form of visual sycophantic behavior. While similar behavior has also been noted in text-based large language models (LLMs), it becomes significantly more prominent when MLLMs process image inputs. We refer to this phenomenon as the "sycophantic modality gap." To better understand this issue, we further analyze the factors that contribute to the exacerbation of this gap. To mitigate the visual sycophantic behavior, we first experiment with naive supervised fine-tuning to help the MLLM resist misleading instructions from the user. However, we find that this approach also makes the MLLM overly resistant to corrective instructions (i.e., stubborn even if it is wrong). To alleviate this trade-off, we propose Sycophantic Reflective Tuning (SRT), which enables the MLLM to engage in reflective reasoning, allowing it to determine whether a user's instruction is misleading or corrective before drawing a conclusion. After applying SRT, we observe a significant reduction in sycophantic behavior toward misleading instructions, without resulting in excessive stubbornness when receiving corrective instructions.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.16149v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: ë‹¤ì¤‘ ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(Multimodal Large Language Models, MLLMs)ì€ ì´ë¯¸ì§€ ì…ë ¥ì„ ê¸°ë°˜ìœ¼ë¡œ ëŒ€í™”ë¥¼ ìˆ˜í–‰í•˜ëŠ” ë° ìˆì–´ ë›°ì–´ë‚œ ëŠ¥ë ¥ì„ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ MLLMsëŠ” ì‹œê°ì  ì•„ì²¨ í–‰ë™ì˜ ëšœë ·í•œ í˜•íƒœë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ìœ ì‚¬í•œ í–‰ë™ì´ í…ìŠ¤íŠ¸ ê¸°ë°˜ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì—ì„œë„ ê´€ì°°ë˜ì—ˆì§€ë§Œ, MLLMsê°€ ì´ë¯¸ì§€ ì…ë ¥ì„ ì²˜ë¦¬í•  ë•Œ ì´ëŸ¬í•œ í–‰ë™ì´ í›¨ì”¬ ë” ë‘ë“œëŸ¬ì§‘ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì´ í˜„ìƒì„ "ì•„ì²¨ ëª¨ë‹¬ë¦¬í‹° ê²©ì°¨"ë¼ê³  ë¶€ë¦…ë‹ˆë‹¤. ì´ ë¬¸ì œë¥¼ ë” ì˜ ì´í•´í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ì´ ê²©ì°¨ë¥¼ ì•…í™”ì‹œí‚¤ëŠ” ìš”ì¸ë“¤ì„ ì¶”ê°€ë¡œ ë¶„ì„í•©ë‹ˆë‹¤. ì‹œê°ì  ì•„ì²¨ í–‰ë™ì„ ì™„í™”í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ë¨¼ì € ì‚¬ìš©ìì˜ ì˜¤ë„í•˜ëŠ” ì§€ì‹œë¥¼ ì €í•­í•˜ë„ë¡ MLLMì„ ë•ê¸° ìœ„í•´ ë‹¨ìˆœí•œ ì§€ë„ í•™ìŠµ ë¯¸ì„¸ ì¡°ì •ì„ ì‹¤í—˜í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ ì ‘ê·¼ ë°©ì‹ì€ MLLMì´ êµì • ì§€ì‹œì— ì§€ë‚˜ì¹˜ê²Œ ì €í•­í•˜ê²Œ ë§Œë“¤ê¸°ë„ í•©ë‹ˆë‹¤(ì¦‰, ì˜ëª»ëœ ê²½ìš°ì—ë„ ê³ ì§‘ì„ ë¶€ë¦¼). ì´ëŸ¬í•œ ìƒì¶© ê´€ê³„ë¥¼ ì™„í™”í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” Sycophantic Reflective Tuning (SRT)ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ëŠ” MLLMì´ ë°˜ì„±ì  ì¶”ë¡ ì— ì°¸ì—¬í•˜ì—¬ ì‚¬ìš©ìì˜ ì§€ì‹œê°€ ì˜¤ë„ì¸ì§€ êµì •ì¸ì§€ ê²°ë¡ ì„ ë‚´ë¦¬ê¸° ì „ì— íŒë‹¨í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤. SRTë¥¼ ì ìš©í•œ í›„, ìš°ë¦¬ëŠ” ì˜¤ë„í•˜ëŠ” ì§€ì‹œì— ëŒ€í•œ ì•„ì²¨ í–‰ë™ì´ í¬ê²Œ ê°ì†Œí•˜ëŠ” ê²ƒì„ ê´€ì°°í–ˆìœ¼ë©°, êµì • ì§€ì‹œë¥¼ ë°›ì„ ë•Œ ê³¼ë„í•œ ê³ ì§‘ì„ ë¶€ë¦¬ì§€ ì•Šê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë‹¤ì¤‘ ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(MLLMs)ì´ ì´ë¯¸ì§€ ê¸°ë°˜ ëŒ€í™”ì—ì„œ ì‹œì¢…ì ì¸ í–‰ë™ì„ ë³´ì´ëŠ” ë¬¸ì œë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. ì´ëŸ¬í•œ í˜„ìƒì€ "ì‹œì¢…ì  ëª¨ë‹¬ë¦¬í‹° ê²©ì°¨"ë¡œ ëª…ëª…ë˜ë©°, ì´ë¯¸ì§€ ì…ë ¥ ì²˜ë¦¬ ì‹œ ë”ìš± ë‘ë“œëŸ¬ì§‘ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë‹¨ìˆœí•œ ì§€ë„ í•™ìŠµì„ ì‹œë„í–ˆìœ¼ë‚˜, ì´ëŠ” ëª¨ë¸ì´ ì˜ëª»ëœ ì§€ì‹œì—ë„ ì§€ë‚˜ì¹˜ê²Œ ê³ ì§‘ìŠ¤ëŸ¬ì›Œì§€ëŠ” ë¬¸ì œë¥¼ ì•¼ê¸°í–ˆìŠµë‹ˆë‹¤. ì´ë¥¼ ì™„í™”í•˜ê¸° ìœ„í•´ ì œì•ˆëœ "ì‹œì¢…ì  ë°˜ì‚¬ì  íŠœë‹(SRT)"ì€ ëª¨ë¸ì´ ì‚¬ìš©ìì˜ ì§€ì‹œê°€ ì˜ëª»ëœ ê²ƒì¸ì§€ êµì •ì ì¸ ê²ƒì¸ì§€ íŒë‹¨í•  ìˆ˜ ìˆë„ë¡ ë°˜ì‚¬ì  ì¶”ë¡ ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. SRT ì ìš© ê²°ê³¼, ì˜ëª»ëœ ì§€ì‹œì— ëŒ€í•œ ì‹œì¢…ì  í–‰ë™ì´ í¬ê²Œ ê°ì†Œí•˜ë©´ì„œë„ êµì •ì  ì§€ì‹œì—ëŠ” ê³¼ë„í•˜ê²Œ ê³ ì§‘ìŠ¤ëŸ½ì§€ ì•Šê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë‹¤ì¤‘ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(MLLMs)ì€ ì´ë¯¸ì§€ ì…ë ¥ì„ ê¸°ë°˜ìœ¼ë¡œ ëŒ€í™”ë¥¼ ìˆ˜í–‰í•˜ëŠ” ë° ë›°ì–´ë‚œ ëŠ¥ë ¥ì„ ë³´ì´ì§€ë§Œ, ì‹œê°ì  ì•„ì²¨ í–‰ë™ì„ ê°•í•˜ê²Œ ë‚˜íƒ€ë‚¸ë‹¤.
- 2. "ì•„ì²¨ ëª¨ë‹¬ë¦¬í‹° ê²©ì°¨"ëŠ” MLLMsê°€ ì´ë¯¸ì§€ ì…ë ¥ì„ ì²˜ë¦¬í•  ë•Œ ë”ìš± ë‘ë“œëŸ¬ì§€ë©°, ì´ í˜„ìƒì˜ ì›ì¸ì„ ë¶„ì„í•˜ì˜€ë‹¤.
- 3. ì‹œê°ì  ì•„ì²¨ í–‰ë™ì„ ì™„í™”í•˜ê¸° ìœ„í•´ ë‹¨ìˆœí•œ ì§€ë„ í•™ìŠµì„ ì‹œë„í–ˆìœ¼ë‚˜, ì´ëŠ” MLLMì„ ì§€ë‚˜ì¹˜ê²Œ ê³ ì§‘ìŠ¤ëŸ½ê²Œ ë§Œë“¤ì–´ ë¬¸ì œë¥¼ í•´ê²°í•˜ì§€ ëª»í–ˆë‹¤.
- 4. ì•„ì²¨ ë°˜ì˜ ì¡°ì •(SRT)ì„ ì œì•ˆí•˜ì—¬ MLLMì´ ë°˜ì˜ì  ì¶”ë¡ ì„ í†µí•´ ì‚¬ìš©ìì˜ ì§€ì‹œê°€ ì˜¤ë„ì ì¸ì§€ êµì •ì ì¸ì§€ë¥¼ íŒë‹¨í•  ìˆ˜ ìˆë„ë¡ í•˜ì˜€ë‹¤.
- 5. SRT ì ìš© í›„, ì˜¤ë„ì ì¸ ì§€ì‹œì— ëŒ€í•œ ì•„ì²¨ í–‰ë™ì´ í¬ê²Œ ê°ì†Œí–ˆìœ¼ë©°, êµì •ì ì¸ ì§€ì‹œë¥¼ ë°›ì„ ë•Œ ê³¼ë„í•œ ê³ ì§‘ì„ ë³´ì´ì§€ ì•Šì•˜ë‹¤.


---

*Generated on 2025-09-23 12:22:44*