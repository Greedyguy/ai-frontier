# Generating Part-Based Global Explanations Via Correspondence

**Korean Title:** 부분 기반 글로벌 설명 생성: 대응 관계를 통한 접근

## 📋 메타데이터

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: User-Defined Part Labels

## 🔗 유사한 논문
- [[2025-09-18/Locally Explaining Prediction Behavior via Gradual Interventions and Measuring Property Gradients_20250918|Locally Explaining Prediction Behavior via Gradual Interventions and Measuring Property Gradients]] (83.6% similar)
- [[2025-09-19/SMARTER_ A Data-efficient Framework to Improve Toxicity Detection with Explanation via Self-augmenting Large Language Models_20250919|SMARTER A Data-efficient Framework to Improve Toxicity Detection with Explanation via Self-augmenting Large Language Models]] (79.3% similar)
- [[2025-09-19/Large Multi-modal Models Can Interpret Features in Large Multi-modal Models_20250919|Large Multi-modal Models Can Interpret Features in Large Multi-modal Models]] (79.1% similar)
- [[2025-09-19/Fine-tuning Vision Language Models with Graph-based Knowledge for Explainable Medical Image Analysis_20250919|Fine-tuning Vision Language Models with Graph-based Knowledge for Explainable Medical Image Analysis]] (78.7% similar)
- [[2025-09-18/Explaining deep learning for ECG using time-localized clusters_20250918|Explaining deep learning for ECG using time-localized clusters]] (78.6% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.15393v1 Announce Type: cross 
Abstract: Deep learning models are notoriously opaque. Existing explanation methods often focus on localized visual explanations for individual images. Concept-based explanations, while offering global insights, require extensive annotations, incurring significant labeling cost. We propose an approach that leverages user-defined part labels from a limited set of images and efficiently transfers them to a larger dataset. This enables the generation of global symbolic explanations by aggregating part-based local explanations, ultimately providing human-understandable explanations for model decisions on a large scale.

## 🔍 Abstract (한글 번역)

arXiv:2509.15393v1 발표 유형: 교차  
초록: 딥러닝 모델은 일반적으로 불투명합니다. 기존의 설명 방법은 종종 개별 이미지에 대한 국지적인 시각적 설명에 중점을 둡니다. 개념 기반 설명은 전반적인 통찰력을 제공하지만, 광범위한 주석이 필요하여 상당한 라벨링 비용이 발생합니다. 우리는 제한된 이미지 세트에서 사용자 정의 부품 라벨을 활용하고 이를 더 큰 데이터셋으로 효율적으로 전이하는 접근 방식을 제안합니다. 이를 통해 부품 기반의 국지적 설명을 집계하여 전역적인 상징적 설명을 생성할 수 있으며, 궁극적으로 대규모로 모델 결정에 대한 인간이 이해할 수 있는 설명을 제공합니다.

## 📝 요약

이 논문은 심층 학습 모델의 불투명성을 해결하기 위해 사용자가 정의한 일부 이미지의 부위 레이블을 활용하여 더 큰 데이터셋으로 효율적으로 전이하는 방법을 제안합니다. 이를 통해 부위 기반의 지역적 설명을 집계하여 전반적인 상징적 설명을 생성하고, 모델의 결정을 대규모로 인간이 이해할 수 있는 방식으로 설명할 수 있게 합니다. 이 접근법은 기존의 개념 기반 설명이 요구하는 방대한 주석 작업을 줄여 비용을 절감하면서도 전반적인 통찰을 제공합니다.

## 🎯 주요 포인트

- 1. 딥러닝 모델의 불투명성을 해결하기 위해 사용자 정의 부품 레이블을 활용하는 방법을 제안합니다.

- 2. 제한된 이미지 세트에서 사용자 정의 레이블을 대규모 데이터셋으로 효율적으로 전이할 수 있습니다.

- 3. 부품 기반의 지역적 설명을 집계하여 글로벌 상징적 설명을 생성합니다.

- 4. 제안된 방법은 모델 결정에 대한 인간이 이해할 수 있는 설명을 대규모로 제공합니다.

---

*Generated on 2025-09-22 13:54:44*