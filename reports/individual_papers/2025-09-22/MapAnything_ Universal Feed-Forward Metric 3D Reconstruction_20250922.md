---
keywords:
  - Transformer
  - 3D Scene Geometry
  - Camera Localization
  - Depth Estimation
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2509.13414
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T10:14:30.252716",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Transformer",
    "3D Scene Geometry",
    "Camera Localization",
    "Depth Estimation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Transformer": 0.85,
    "3D Scene Geometry": 0.78,
    "Camera Localization": 0.82,
    "Depth Estimation": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Transformer-based feed-forward model",
        "canonical": "Transformer",
        "aliases": [
          "Transformer model"
        ],
        "category": "broad_technical",
        "rationale": "Transformers are a foundational technology in modern machine learning, connecting to a wide range of related research.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Metric 3D scene geometry",
        "canonical": "3D Scene Geometry",
        "aliases": [
          "3D geometry",
          "Scene geometry"
        ],
        "category": "unique_technical",
        "rationale": "This term captures the unique focus on metric 3D reconstruction, linking to specialized 3D vision research.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Camera localization",
        "canonical": "Camera Localization",
        "aliases": [
          "Camera positioning"
        ],
        "category": "specific_connectable",
        "rationale": "Camera localization is a critical task in computer vision, connecting to research on spatial awareness and navigation.",
        "novelty_score": 0.5,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.82
      },
      {
        "surface": "Monocular depth estimation",
        "canonical": "Depth Estimation",
        "aliases": [
          "Monocular depth"
        ],
        "category": "specific_connectable",
        "rationale": "Depth estimation is a key component of 3D reconstruction, linking to various vision tasks and datasets.",
        "novelty_score": 0.55,
        "connectivity_score": 0.78,
        "specificity_score": 0.75,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "feed-forward",
      "model",
      "training"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Transformer-based feed-forward model",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Metric 3D scene geometry",
      "resolved_canonical": "3D Scene Geometry",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Camera localization",
      "resolved_canonical": "Camera Localization",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Monocular depth estimation",
      "resolved_canonical": "Depth Estimation",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.78,
        "specificity": 0.75,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# MapAnything: Universal Feed-Forward Metric 3D Reconstruction

**Korean Title:** MapAnything: ë²”ìš© í”¼ë“œí¬ì›Œë“œ ë©”íŠ¸ë¦­ 3D ì¬êµ¬ì„±

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.13414.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2509.13414](https://arxiv.org/abs/2509.13414)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Recovering Parametric Scenes from Very Few Time-of-Flight Pixels_20250922|Recovering Parametric Scenes from Very Few Time-of-Flight Pixels]] (81.3% similar)
- [[2025-09-18/Gaussian Alignment for Relative Camera Pose Estimation via Single-View Reconstruction_20250918|Gaussian Alignment for Relative Camera Pose Estimation via Single-View Reconstruction]] (81.3% similar)
- [[2025-09-19/Reconstruction Alignment Improves Unified Multimodal Models_20250919|Reconstruction Alignment Improves Unified Multimodal Models]] (80.9% similar)
- [[2025-09-19/Boost 3D Reconstruction using Diffusion-based Monocular Camera Calibration_20250919|Boost 3D Reconstruction using Diffusion-based Monocular Camera Calibration]] (80.4% similar)
- [[2025-09-18/GeoAware-VLA_ Implicit Geometry Aware Vision-Language-Action Model_20250918|GeoAware-VLA: Implicit Geometry Aware Vision-Language-Action Model]] (80.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Transformer|Transformer]]
**ğŸ”— Specific Connectable**: [[keywords/Camera Localization|Camera Localization]], [[keywords/Depth Estimation|Depth Estimation]]
**âš¡ Unique Technical**: [[keywords/3D Scene Geometry|3D Scene Geometry]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.13414v2 Announce Type: replace-cross 
Abstract: We introduce MapAnything, a unified transformer-based feed-forward model that ingests one or more images along with optional geometric inputs such as camera intrinsics, poses, depth, or partial reconstructions, and then directly regresses the metric 3D scene geometry and cameras. MapAnything leverages a factored representation of multi-view scene geometry, i.e., a collection of depth maps, local ray maps, camera poses, and a metric scale factor that effectively upgrades local reconstructions into a globally consistent metric frame. Standardizing the supervision and training across diverse datasets, along with flexible input augmentation, enables MapAnything to address a broad range of 3D vision tasks in a single feed-forward pass, including uncalibrated structure-from-motion, calibrated multi-view stereo, monocular depth estimation, camera localization, depth completion, and more. We provide extensive experimental analyses and model ablations demonstrating that MapAnything outperforms or matches specialist feed-forward models while offering more efficient joint training behavior, thus paving the way toward a universal 3D reconstruction backbone.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.13414v2 ë°œí‘œ ìœ í˜•: êµì°¨ êµì²´  
ì´ˆë¡: ìš°ë¦¬ëŠ” MapAnythingì„ ì†Œê°œí•©ë‹ˆë‹¤. ì´ëŠ” í•˜ë‚˜ ì´ìƒì˜ ì´ë¯¸ì§€ë¥¼ ì¹´ë©”ë¼ ë‚´ì¬ ë§¤ê°œë³€ìˆ˜, ìì„¸, ê¹Šì´ ë˜ëŠ” ë¶€ë¶„ ì¬êµ¬ì„±ê³¼ ê°™ì€ ì„ íƒì  ê¸°í•˜í•™ì  ì…ë ¥ê³¼ í•¨ê»˜ ìˆ˜ìš©í•œ í›„, ë©”íŠ¸ë¦­ 3D ì¥ë©´ ê¸°í•˜í•™ê³¼ ì¹´ë©”ë¼ë¥¼ ì§ì ‘ íšŒê·€í•˜ëŠ” í†µí•©ëœ íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ í”¼ë“œí¬ì›Œë“œ ëª¨ë¸ì…ë‹ˆë‹¤. MapAnythingì€ ë‹¤ì¤‘ ì‹œì  ì¥ë©´ ê¸°í•˜í•™ì˜ ë¶„í•´ëœ í‘œí˜„, ì¦‰ ê¹Šì´ ë§µ, êµ­ì†Œ ê´‘ì„  ë§µ, ì¹´ë©”ë¼ ìì„¸, ê·¸ë¦¬ê³  êµ­ì†Œ ì¬êµ¬ì„±ì„ ì „ì—­ì ìœ¼ë¡œ ì¼ê´€ëœ ë©”íŠ¸ë¦­ í”„ë ˆì„ìœ¼ë¡œ íš¨ê³¼ì ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œí•˜ëŠ” ë©”íŠ¸ë¦­ ìŠ¤ì¼€ì¼ íŒ©í„°ì˜ ì§‘í•©ì„ í™œìš©í•©ë‹ˆë‹¤. ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ì— ê±¸ì³ ê°ë…ê³¼ í›ˆë ¨ì„ í‘œì¤€í™”í•˜ê³  ìœ ì—°í•œ ì…ë ¥ ì¦ê°•ì„ í†µí•´ MapAnythingì€ ë¹„ë³´ì • êµ¬ì¡°-ì´ë™, ë³´ì •ëœ ë‹¤ì¤‘ ì‹œì  ìŠ¤í…Œë ˆì˜¤, ë‹¨ì•ˆ ê¹Šì´ ì¶”ì •, ì¹´ë©”ë¼ ìœ„ì¹˜ ì¶”ì •, ê¹Šì´ ì™„ì„± ë“± ë‹¨ì¼ í”¼ë“œí¬ì›Œë“œ íŒ¨ìŠ¤ë¡œ ê´‘ë²”ìœ„í•œ 3D ë¹„ì „ ì‘ì—…ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” MapAnythingì´ ì „ë¬¸ í”¼ë“œí¬ì›Œë“œ ëª¨ë¸ì„ ëŠ¥ê°€í•˜ê±°ë‚˜ ì¼ì¹˜í•˜ë©´ì„œë„ ë” íš¨ìœ¨ì ì¸ ê³µë™ í›ˆë ¨ í–‰ë™ì„ ì œê³µí•¨ì„ ë³´ì—¬ì£¼ëŠ” ê´‘ë²”ìœ„í•œ ì‹¤í—˜ ë¶„ì„ê³¼ ëª¨ë¸ ì†Œê±°ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì´ëŠ” ë³´í¸ì ì¸ 3D ì¬êµ¬ì„± ë°±ë³¸ìœ¼ë¡œ ë‚˜ì•„ê°€ëŠ” ê¸¸ì„ ì—´ì–´ì¤ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

MapAnythingëŠ” í•˜ë‚˜ ì´ìƒì˜ ì´ë¯¸ì§€ì™€ ì¹´ë©”ë¼ ë‚´ë¶€ ë§¤ê°œë³€ìˆ˜, ìì„¸, ê¹Šì´, ë¶€ë¶„ ì¬êµ¬ì„± ë“±ì˜ ê¸°í•˜í•™ì  ì…ë ¥ì„ ë°›ì•„ 3D ì¥ë©´ ê¸°í•˜í•™ê³¼ ì¹´ë©”ë¼ë¥¼ ì§ì ‘ ì˜ˆì¸¡í•˜ëŠ” í†µí•©ëœ íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ ëª¨ë¸ì…ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ë‹¤ì¤‘ ë·° ì¥ë©´ ê¸°í•˜í•™ì˜ ìš”ì†Œë³„ í‘œí˜„ì„ í™œìš©í•˜ì—¬, ì§€ì—­ì  ì¬êµ¬ì„±ì„ ì „ì—­ì ìœ¼ë¡œ ì¼ê´€ëœ ë©”íŠ¸ë¦­ í”„ë ˆì„ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œí•©ë‹ˆë‹¤. ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ì— ê±¸ì³ í‘œì¤€í™”ëœ ê°ë…ê³¼ í›ˆë ¨, ìœ ì—°í•œ ì…ë ¥ ë³´ê°•ì„ í†µí•´ MapAnythingì€ ë¹„ë³´ì • êµ¬ì¡°-ì´ë™, ë³´ì •ëœ ë‹¤ì¤‘ ë·° ìŠ¤í…Œë ˆì˜¤, ë‹¨ì•ˆ ê¹Šì´ ì¶”ì •, ì¹´ë©”ë¼ ìœ„ì¹˜ ì¶”ì •, ê¹Šì´ ë³´ì™„ ë“± ë‹¤ì–‘í•œ 3D ë¹„ì „ ì‘ì—…ì„ ë‹¨ì¼ í”¼ë“œí¬ì›Œë“œ íŒ¨ìŠ¤ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹¤í—˜ ë¶„ì„ê³¼ ëª¨ë¸ ì œê±° ì‹¤í—˜ì„ í†µí•´ MapAnythingì´ ì „ë¬¸ í”¼ë“œí¬ì›Œë“œ ëª¨ë¸ê³¼ ë™ë“±í•˜ê±°ë‚˜ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì´ë©°, íš¨ìœ¨ì ì¸ ê³µë™ í›ˆë ¨ì„ ê°€ëŠ¥í•˜ê²Œ í•¨ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ë²”ìš© 3D ì¬êµ¬ì„± ë°±ë³¸ìœ¼ë¡œì˜ ë°œì „ì„ ìœ„í•œ ê¸¸ì„ ì—´ì–´ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. MapAnythingëŠ” í•˜ë‚˜ ì´ìƒì˜ ì´ë¯¸ì§€ì™€ ì¹´ë©”ë¼ ë‚´ì¬ ë§¤ê°œë³€ìˆ˜, í¬ì¦ˆ, ê¹Šì´, ë¶€ë¶„ ì¬êµ¬ì„± ë“±ì˜ ê¸°í•˜í•™ì  ì…ë ¥ì„ ì²˜ë¦¬í•˜ì—¬ 3D ì¥ë©´ ê¸°í•˜í•™ê³¼ ì¹´ë©”ë¼ë¥¼ ì§ì ‘ íšŒê·€í•˜ëŠ” í†µí•©ëœ íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ ëª¨ë¸ì…ë‹ˆë‹¤.
- 2. ì´ ëª¨ë¸ì€ ë‹¤ì¤‘ ë·° ì¥ë©´ ê¸°í•˜í•™ì˜ ìš”ì†Œí™”ëœ í‘œí˜„ì„ í™œìš©í•˜ì—¬ ì§€ì—­ì  ì¬êµ¬ì„±ì„ ì „ì—­ì ìœ¼ë¡œ ì¼ê´€ëœ ë©”íŠ¸ë¦­ í”„ë ˆì„ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œí•©ë‹ˆë‹¤.
- 3. ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ì— ëŒ€í•œ í‘œì¤€í™”ëœ ê°ë…ê³¼ í›ˆë ¨, ìœ ì—°í•œ ì…ë ¥ ì¦ê°•ì„ í†µí•´ MapAnythingì€ ë‹¨ì¼ í”¼ë“œí¬ì›Œë“œ íŒ¨ìŠ¤ë¡œ ë‹¤ì–‘í•œ 3D ë¹„ì „ ì‘ì—…ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- 4. ì‹¤í—˜ ë¶„ì„ê³¼ ëª¨ë¸ ì†Œê±°ë¥¼ í†µí•´ MapAnythingì´ ì „ë¬¸ í”¼ë“œí¬ì›Œë“œ ëª¨ë¸ì„ ëŠ¥ê°€í•˜ê±°ë‚˜ ë™ë“±í•œ ì„±ëŠ¥ì„ ë³´ì´ë©´ì„œë„ ë” íš¨ìœ¨ì ì¸ ê³µë™ í›ˆë ¨ì„ ì œê³µí•¨ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.
- 5. MapAnythingì€ ë²”ìš© 3D ì¬êµ¬ì„± ë°±ë³¸ìœ¼ë¡œì˜ ë°œì „ ê°€ëŠ¥ì„±ì„ ì œì‹œí•©ë‹ˆë‹¤.


---

*Generated on 2025-09-23 10:14:30*