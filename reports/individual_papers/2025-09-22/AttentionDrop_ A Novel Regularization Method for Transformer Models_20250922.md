---
keywords:
  - AttentionDrop
  - Transformer
  - Attention Mechanism
  - Adversarial Robustness
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2504.12088
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T09:54:45.682589",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "AttentionDrop",
    "Transformer",
    "Attention Mechanism",
    "Adversarial Robustness"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "AttentionDrop": 0.78,
    "Transformer": 0.85,
    "Attention Mechanism": 0.8,
    "Adversarial Robustness": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "AttentionDrop",
        "canonical": "AttentionDrop",
        "aliases": [
          "Attention Drop"
        ],
        "category": "unique_technical",
        "rationale": "AttentionDrop is a novel regularization method specific to transformer models, offering new insights and connections in model optimization.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.78
      },
      {
        "surface": "Transformer",
        "canonical": "Transformer",
        "aliases": [
          "Transformer Model"
        ],
        "category": "broad_technical",
        "rationale": "Transformers are foundational to the discussed methods and provide a broad technical context for linking.",
        "novelty_score": 0.4,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Attention Mechanism",
        "canonical": "Attention Mechanism",
        "aliases": [
          "Self-Attention"
        ],
        "category": "specific_connectable",
        "rationale": "The paper's methods directly modify self-attention distributions, making this a key concept for linking.",
        "novelty_score": 0.5,
        "connectivity_score": 0.88,
        "specificity_score": 0.75,
        "link_intent_score": 0.8
      },
      {
        "surface": "Adversarial Robustness",
        "canonical": "Adversarial Robustness",
        "aliases": [
          "Robustness to Adversarial Attacks"
        ],
        "category": "specific_connectable",
        "rationale": "Improving adversarial robustness is a significant outcome of the proposed method, relevant for linking to security-focused research.",
        "novelty_score": 0.55,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "state-of-the-art",
      "performance",
      "results"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "AttentionDrop",
      "resolved_canonical": "AttentionDrop",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Transformer",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Attention Mechanism",
      "resolved_canonical": "Attention Mechanism",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.88,
        "specificity": 0.75,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Adversarial Robustness",
      "resolved_canonical": "Adversarial Robustness",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# AttentionDrop: A Novel Regularization Method for Transformer Models

**Korean Title:** ì–´í…ì…˜ë“œë¡­: íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì„ ìœ„í•œ ìƒˆë¡œìš´ ì •ê·œí™” ê¸°ë²•

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2504.12088.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2504.12088](https://arxiv.org/abs/2504.12088)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/MaskAttn-SDXL_ Controllable Region-Level Text-To-Image Generation_20250922|MaskAttn-SDXL: Controllable Region-Level Text-To-Image Generation]] (82.1% similar)
- [[2025-09-22/Attention Schema-based Attention Control (ASAC)_ A Cognitive-Inspired Approach for Attention Management in Transformers_20250922|Attention Schema-based Attention Control (ASAC): A Cognitive-Inspired Approach for Attention Management in Transformers]] (81.9% similar)
- [[2025-09-22/Hierarchical Self-Attention_ Generalizing Neural Attention Mechanics to Multi-Scale Problems_20250922|Hierarchical Self-Attention: Generalizing Neural Attention Mechanics to Multi-Scale Problems]] (81.0% similar)
- [[2025-09-22/reWordBench_ Benchmarking and Improving the Robustness of Reward Models with Transformed Inputs_20250922|reWordBench: Benchmarking and Improving the Robustness of Reward Models with Transformed Inputs]] (80.7% similar)
- [[2025-09-22/Mental Accounts for Actions_ EWA-Inspired Attention in Decision Transformers_20250922|Mental Accounts for Actions: EWA-Inspired Attention in Decision Transformers]] (80.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Transformer|Transformer]]
**ğŸ”— Specific Connectable**: [[keywords/Attention Mechanism|Attention Mechanism]], [[keywords/Adversarial Robustness|Adversarial Robustness]]
**âš¡ Unique Technical**: [[keywords/AttentionDrop|AttentionDrop]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2504.12088v2 Announce Type: replace-cross 
Abstract: Transformer-based architectures achieve state-of-the-art performance across a wide range of tasks in natural language processing, computer vision, and speech processing. However, their immense capacity often leads to overfitting, especially when training data is limited or noisy. In this research, a unified family of stochastic regularization techniques has been proposed, i.e. AttentionDrop with its three different variants, which operate directly on the self-attention distributions. Hard Attention Masking randomly zeroes out top-k attention logits per query to encourage diverse context utilization, Blurred Attention Smoothing applies a dynamic Gaussian convolution over attention logits to diffuse overly peaked distributions, and Consistency-Regularized AttentionDrop enforces output stability under multiple independent AttentionDrop perturbations via a KL-based consistency loss. Results achieved in the study demonstrate that AttentionDrop consistently improves accuracy, calibration, and adversarial robustness over standard Dropout, DropConnect, and R-Drop baselines

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2504.12088v2 ë°œí‘œ ìœ í˜•: êµì°¨ êµì²´  
ì´ˆë¡: íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ ì•„í‚¤í…ì²˜ëŠ” ìì—°ì–´ ì²˜ë¦¬, ì»´í“¨í„° ë¹„ì „, ìŒì„± ì²˜ë¦¬ ë“± ë‹¤ì–‘í•œ ì‘ì—…ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ëŸ¬í•œ ì•„í‚¤í…ì²˜ì˜ ë°©ëŒ€í•œ ìš©ëŸ‰ì€ ì¢…ì¢… ê³¼ì í•©ì„ ì´ˆë˜í•˜ë©°, íŠ¹íˆ í›ˆë ¨ ë°ì´í„°ê°€ ì œí•œì ì´ê±°ë‚˜ ë…¸ì´ì¦ˆê°€ ë§ì€ ê²½ìš°ì— ê·¸ë ‡ìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” ìê¸° ì£¼ì˜ ë¶„í¬ì— ì§ì ‘ ì‘ìš©í•˜ëŠ” ì£¼ì˜ ë“œë¡­(AttentionDrop)ê³¼ ê·¸ ì„¸ ê°€ì§€ ë³€í˜•ì„ í¬í•¨í•œ í†µí•©ëœ í™•ë¥ ì  ì •ê·œí™” ê¸°ë²•ì„ ì œì•ˆí•˜ì˜€ìŠµë‹ˆë‹¤. í•˜ë“œ ì£¼ì˜ ë§ˆìŠ¤í‚¹(Hard Attention Masking)ì€ ì¿¼ë¦¬ë‹¹ ìƒìœ„-k ì£¼ì˜ ë¡œì§“ì„ ë¬´ì‘ìœ„ë¡œ 0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ë‹¤ì–‘í•œ ë¬¸ë§¥ í™œìš©ì„ ì¥ë ¤í•˜ë©°, ë¸”ëŸ¬ë“œ ì£¼ì˜ ìŠ¤ë¬´ë”©(Blurred Attention Smoothing)ì€ ì£¼ì˜ ë¡œì§“ì— ë™ì  ê°€ìš°ì‹œì•ˆ ì»¨ë³¼ë£¨ì…˜ì„ ì ìš©í•˜ì—¬ ì§€ë‚˜ì¹˜ê²Œ ë¾°ì¡±í•œ ë¶„í¬ë¥¼ í™•ì‚°ì‹œí‚µë‹ˆë‹¤. ì¼ê´€ì„± ì •ê·œí™” ì£¼ì˜ ë“œë¡­(Consistency-Regularized AttentionDrop)ì€ KL ê¸°ë°˜ì˜ ì¼ê´€ì„± ì†ì‹¤ì„ í†µí•´ ì—¬ëŸ¬ ë…ë¦½ì ì¸ ì£¼ì˜ ë“œë¡­ ë³€ë™ í•˜ì—ì„œ ì¶œë ¥ì˜ ì•ˆì •ì„±ì„ ê°•í™”í•©ë‹ˆë‹¤. ì—°êµ¬ ê²°ê³¼ì— ë”°ë¥´ë©´, ì£¼ì˜ ë“œë¡­ì€ í‘œì¤€ ë“œë¡­ì•„ì›ƒ(Dropout), ë“œë¡­ì»¤ë„¥íŠ¸(DropConnect), R-ë“œë¡­(R-Drop) ê¸°ì¤€ì„ ì— ë¹„í•´ ì •í™•ë„, ë³´ì •, ì ëŒ€ì  ê²¬ê³ ì„±ì„ ì¼ê´€ë˜ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” ìì—°ì–´ ì²˜ë¦¬, ì»´í“¨í„° ë¹„ì „, ìŒì„± ì²˜ë¦¬ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì´ëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ ì•„í‚¤í…ì²˜ì˜ ê³¼ì í•© ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ìƒˆë¡œìš´ í™•ë¥ ì  ì •ê·œí™” ê¸°ë²•ì¸ AttentionDropì„ ì œì•ˆí•©ë‹ˆë‹¤. AttentionDropì€ ì…€í”„ ì–´í…ì…˜ ë¶„í¬ì— ì§ì ‘ ì‘ìš©í•˜ëŠ” ì„¸ ê°€ì§€ ë³€í˜• ê¸°ë²•ì„ í¬í•¨í•©ë‹ˆë‹¤. Hard Attention Maskingì€ ë‹¤ì–‘í•œ ë¬¸ë§¥ í™œìš©ì„ ìœ„í•´ ì¿¼ë¦¬ë‹¹ ìƒìœ„ kê°œì˜ ì–´í…ì…˜ ë¡œì§“ì„ ë¬´ì‘ìœ„ë¡œ 0ìœ¼ë¡œ ì„¤ì •í•˜ê³ , Blurred Attention Smoothingì€ ê³¼ë„í•˜ê²Œ ë¾°ì¡±í•œ ë¶„í¬ë¥¼ ì™„í™”í•˜ê¸° ìœ„í•´ ë™ì  ê°€ìš°ì‹œì•ˆ ì»¨ë³¼ë£¨ì…˜ì„ ì ìš©í•˜ë©°, Consistency-Regularized AttentionDropì€ ì—¬ëŸ¬ ë…ë¦½ì ì¸ AttentionDrop ë³€í˜•ì— ëŒ€í•´ KL ê¸°ë°˜ ì¼ê´€ì„± ì†ì‹¤ì„ í†µí•´ ì¶œë ¥ì˜ ì•ˆì •ì„±ì„ ê°•í™”í•©ë‹ˆë‹¤. ì—°êµ¬ ê²°ê³¼, AttentionDropì€ ê¸°ì¡´ì˜ Dropout, DropConnect, R-Drop ëŒ€ë¹„ ì •í™•ë„, ë³´ì •, ì ëŒ€ì  ê°•ê±´ì„±ì„ ì¼ê´€ë˜ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Transformer ê¸°ë°˜ ì•„í‚¤í…ì²˜ëŠ” ìì—°ì–´ ì²˜ë¦¬, ì»´í“¨í„° ë¹„ì „, ìŒì„± ì²˜ë¦¬ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ì§€ë§Œ, ë°ì´í„°ê°€ ì œí•œì ì´ê±°ë‚˜ ë…¸ì´ì¦ˆê°€ ë§ì€ ê²½ìš° ê³¼ì í•© ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆë‹¤.
- 2. ë³¸ ì—°êµ¬ì—ì„œëŠ” ìê¸° ì£¼ì˜ ë¶„í¬ì— ì§ì ‘ ì‘ìš©í•˜ëŠ” ì„¸ ê°€ì§€ ë³€í˜•ì˜ AttentionDropì´ë¼ëŠ” í™•ë¥ ì  ì •ê·œí™” ê¸°ë²•ì„ ì œì•ˆí•˜ì˜€ë‹¤.
- 3. Hard Attention Maskingì€ ì¿¼ë¦¬ë‹¹ ìƒìœ„ kê°œì˜ ì£¼ì˜ ë¡œê·¸ì‡ì„ ë¬´ì‘ìœ„ë¡œ 0ìœ¼ë¡œ ë§Œë“¤ì–´ ë‹¤ì–‘í•œ ë¬¸ë§¥ í™œìš©ì„ ìœ ë„í•œë‹¤.
- 4. Blurred Attention Smoothingì€ ë™ì  ê°€ìš°ì‹œì•ˆ ì»¨ë³¼ë£¨ì…˜ì„ ì ìš©í•˜ì—¬ ì§€ë‚˜ì¹˜ê²Œ ë¾°ì¡±í•œ ë¶„í¬ë¥¼ í™•ì‚°ì‹œí‚¨ë‹¤.
- 5. Consistency-Regularized AttentionDropì€ KL ê¸°ë°˜ì˜ ì¼ê´€ì„± ì†ì‹¤ì„ í†µí•´ ì—¬ëŸ¬ ë…ë¦½ì ì¸ AttentionDrop ë³€í˜• í•˜ì—ì„œ ì¶œë ¥ì˜ ì•ˆì •ì„±ì„ ê°•í™”í•œë‹¤.


---

*Generated on 2025-09-23 09:54:45*