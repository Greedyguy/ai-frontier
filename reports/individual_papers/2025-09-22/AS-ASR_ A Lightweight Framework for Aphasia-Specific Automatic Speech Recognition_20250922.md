---
keywords:
  - Aphasia-Specific Speech Recognition
  - Whisper-Tiny
  - GPT-4 Reference Enhancement
  - Zero-Shot Learning
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2506.06566
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T10:02:28.758204",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Aphasia-Specific Speech Recognition",
    "Whisper-Tiny",
    "GPT-4 Reference Enhancement",
    "Zero-Shot Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Aphasia-Specific Speech Recognition": 0.88,
    "Whisper-Tiny": 0.8,
    "GPT-4 Reference Enhancement": 0.85,
    "Zero-Shot Learning": 0.9
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "aphasia-specific speech recognition",
        "canonical": "Aphasia-Specific Speech Recognition",
        "aliases": [
          "AS-ASR"
        ],
        "category": "unique_technical",
        "rationale": "This term represents a novel application of speech recognition technology tailored for aphasia, offering a unique link to specialized research in disordered speech.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.88
      },
      {
        "surface": "Whisper-tiny",
        "canonical": "Whisper-Tiny",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "As a specific model variant used in the framework, it provides a link to discussions on lightweight models for edge devices.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "GPT-4-based reference enhancement",
        "canonical": "GPT-4 Reference Enhancement",
        "aliases": [
          "GPT-4 Enhancement"
        ],
        "category": "specific_connectable",
        "rationale": "This technique links to broader discussions on using advanced language models for improving data quality.",
        "novelty_score": 0.7,
        "connectivity_score": 0.78,
        "specificity_score": 0.82,
        "link_intent_score": 0.85
      },
      {
        "surface": "Zero-Shot Baseline",
        "canonical": "Zero-Shot Learning",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "This concept ties into the trending topic of zero-shot learning, which is crucial for understanding model performance without prior specific training.",
        "novelty_score": 0.55,
        "connectivity_score": 0.85,
        "specificity_score": 0.75,
        "link_intent_score": 0.9
      }
    ],
    "ban_list_suggestions": [
      "standard speech",
      "evaluation settings",
      "supervision quality"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "aphasia-specific speech recognition",
      "resolved_canonical": "Aphasia-Specific Speech Recognition",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "Whisper-tiny",
      "resolved_canonical": "Whisper-Tiny",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "GPT-4-based reference enhancement",
      "resolved_canonical": "GPT-4 Reference Enhancement",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.78,
        "specificity": 0.82,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Zero-Shot Baseline",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.85,
        "specificity": 0.75,
        "link_intent": 0.9
      }
    }
  ]
}
-->

# AS-ASR: A Lightweight Framework for Aphasia-Specific Automatic Speech Recognition

**Korean Title:** AS-ASR: ì‹¤ì–´ì¦ íŠ¹í™” ìë™ ìŒì„± ì¸ì‹ì„ ìœ„í•œ ê²½ëŸ‰ í”„ë ˆì„ì›Œí¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2506.06566.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2506.06566](https://arxiv.org/abs/2506.06566)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Listening, Imagining \& Refining_ A Heuristic Optimized ASR Correction Framework with LLMs_20250919|Listening, Imagining \& Refining: A Heuristic Optimized ASR Correction Framework with LLMs]] (85.5% similar)
- [[2025-09-22/Frustratingly Easy Data Augmentation for Low-Resource ASR_20250922|Frustratingly Easy Data Augmentation for Low-Resource ASR]] (84.0% similar)
- [[2025-09-22/LESS_ Large Language Model Enhanced Semi-Supervised Learning for Speech Foundational Models Using in-the-wild Data_20250922|LESS: Large Language Model Enhanced Semi-Supervised Learning for Speech Foundational Models Using in-the-wild Data]] (82.5% similar)
- [[2025-09-22/Session-Level Spoken Language Assessment with a Multimodal Foundation Model via Multi-Target Learning_20250922|Session-Level Spoken Language Assessment with a Multimodal Foundation Model via Multi-Target Learning]] (81.5% similar)
- [[2025-09-19/SpeechOp_ Inference-Time Task Composition for Generative Speech Processing_20250919|SpeechOp: Inference-Time Task Composition for Generative Speech Processing]] (80.9% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/GPT-4 Reference Enhancement|GPT-4 Reference Enhancement]], [[keywords/Zero-Shot Learning|Zero-Shot Learning]]
**âš¡ Unique Technical**: [[keywords/Aphasia-Specific Speech Recognition|Aphasia-Specific Speech Recognition]], [[keywords/Whisper-Tiny|Whisper-Tiny]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2506.06566v2 Announce Type: replace-cross 
Abstract: This paper proposes AS-ASR, a lightweight aphasia-specific speech recognition framework based on Whisper-tiny, tailored for low-resource deployment on edge devices. Our approach introduces a hybrid training strategy that systematically combines standard and aphasic speech at varying ratios, enabling robust generalization, and a GPT-4-based reference enhancement method that refines noisy aphasic transcripts, improving supervision quality. We conduct extensive experiments across multiple data mixing configurations and evaluation settings. Results show that our fine-tuned model significantly outperforms the zero-shot baseline, reducing WER on aphasic speech by over 30% while preserving performance on standard speech. The proposed framework offers a scalable, efficient solution for real-world disordered speech recognition.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2506.06566v2 ë°œí‘œ ìœ í˜•: êµì°¨ êµì²´  
ì´ˆë¡: ë³¸ ë…¼ë¬¸ì€ Whisper-tinyë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ê²½ëŸ‰í˜• ì‹¤ì–´ì¦ íŠ¹í™” ìŒì„± ì¸ì‹ í”„ë ˆì„ì›Œí¬ì¸ AS-ASRì„ ì œì•ˆí•˜ë©°, ì—£ì§€ ë””ë°”ì´ìŠ¤ì—ì„œì˜ ì €ìì› ë°°í¬ì— ì í•©í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ìš°ë¦¬ì˜ ì ‘ê·¼ ë°©ì‹ì€ í‘œì¤€ ìŒì„±ê³¼ ì‹¤ì–´ì¦ ìŒì„±ì„ ë‹¤ì–‘í•œ ë¹„ìœ¨ë¡œ ì²´ê³„ì ìœ¼ë¡œ ê²°í•©í•˜ëŠ” í•˜ì´ë¸Œë¦¬ë“œ í›ˆë ¨ ì „ëµì„ ë„ì…í•˜ì—¬ ê°•ë ¥í•œ ì¼ë°˜í™”ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ê³ , GPT-4 ê¸°ë°˜ì˜ ì°¸ì¡° í–¥ìƒ ë°©ë²•ì„ í†µí•´ ì¡ìŒì´ ìˆëŠ” ì‹¤ì–´ì¦ ì „ì‚¬ë¥¼ ì •ì œí•˜ì—¬ ê°ë… í’ˆì§ˆì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì—¬ëŸ¬ ë°ì´í„° í˜¼í•© êµ¬ì„± ë° í‰ê°€ ì„¤ì •ì—ì„œ ê´‘ë²”ìœ„í•œ ì‹¤í—˜ì„ ìˆ˜í–‰í•˜ì˜€ìŠµë‹ˆë‹¤. ê²°ê³¼ëŠ” ë¯¸ì„¸ ì¡°ì •ëœ ëª¨ë¸ì´ ì œë¡œìƒ· ê¸°ì¤€ì„ ì„ í¬ê²Œ ëŠ¥ê°€í•˜ë©°, ì‹¤ì–´ì¦ ìŒì„±ì˜ WERì„ 30% ì´ìƒ ê°ì†Œì‹œí‚¤ë©´ì„œ í‘œì¤€ ìŒì„±ì˜ ì„±ëŠ¥ì„ ìœ ì§€í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì œì•ˆëœ í”„ë ˆì„ì›Œí¬ëŠ” ì‹¤ì œ í™˜ê²½ì—ì„œì˜ ì¥ì•  ìŒì„± ì¸ì‹ì„ ìœ„í•œ í™•ì¥ ê°€ëŠ¥í•˜ê³  íš¨ìœ¨ì ì¸ ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ê²½ëŸ‰í™”ëœ ì‹¤ì–´ì¦ íŠ¹í™” ìŒì„± ì¸ì‹ í”„ë ˆì„ì›Œí¬ì¸ AS-ASRì„ ì œì•ˆí•©ë‹ˆë‹¤. Whisper-tinyë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì´ í”„ë ˆì„ì›Œí¬ëŠ” ì—£ì§€ ë””ë°”ì´ìŠ¤ì—ì„œì˜ ì €ìì› ë°°í¬ë¥¼ ëª©í‘œë¡œ í•©ë‹ˆë‹¤. ì œì•ˆëœ ë°©ë²•ì€ í‘œì¤€ ë° ì‹¤ì–´ì¦ ìŒì„±ì„ ë‹¤ì–‘í•œ ë¹„ìœ¨ë¡œ ê²°í•©í•˜ëŠ” í•˜ì´ë¸Œë¦¬ë“œ í›ˆë ¨ ì „ëµê³¼ GPT-4 ê¸°ë°˜ì˜ ì°¸ì¡° ê°œì„  ë°©ë²•ì„ ë„ì…í•˜ì—¬, ì¡ìŒì´ ë§ì€ ì‹¤ì–´ì¦ ìŒì„± ì „ì‚¬ë¥¼ ê°œì„ í•©ë‹ˆë‹¤. ë‹¤ì–‘í•œ ë°ì´í„° í˜¼í•© êµ¬ì„±ê³¼ í‰ê°€ ì„¤ì •ì—ì„œì˜ ì‹¤í—˜ ê²°ê³¼, ë¯¸ì„¸ ì¡°ì •ëœ ëª¨ë¸ì´ ì‹¤ì–´ì¦ ìŒì„±ì˜ WERì„ 30% ì´ìƒ ê°ì†Œì‹œí‚¤ë©´ì„œ í‘œì¤€ ìŒì„± ì„±ëŠ¥ì„ ìœ ì§€í•˜ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ì‹¤ì œ í™˜ê²½ì—ì„œì˜ ì¥ì•  ìŒì„± ì¸ì‹ì„ ìœ„í•œ í™•ì¥ ê°€ëŠ¥í•˜ê³  íš¨ìœ¨ì ì¸ ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. AS-ASRì€ Whisper-tiny ê¸°ë°˜ì˜ ê²½ëŸ‰í™”ëœ ì‹¤ì–´ì¦ íŠ¹í™” ìŒì„± ì¸ì‹ í”„ë ˆì„ì›Œí¬ë¡œ, ì—£ì§€ ë””ë°”ì´ìŠ¤ì—ì„œì˜ ì €ìì› ë°°í¬ë¥¼ ëª©í‘œë¡œ í•œë‹¤.
- 2. í‘œì¤€ ë° ì‹¤ì–´ì¦ ìŒì„±ì„ ë‹¤ì–‘í•œ ë¹„ìœ¨ë¡œ ê²°í•©í•˜ëŠ” í•˜ì´ë¸Œë¦¬ë“œ í›ˆë ¨ ì „ëµì„ ë„ì…í•˜ì—¬ ê°•ë ¥í•œ ì¼ë°˜í™”ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤.
- 3. GPT-4 ê¸°ë°˜ì˜ ì°¸ì¡° í–¥ìƒ ë°©ë²•ì„ í†µí•´ ì‹¤ì–´ì¦ ìŒì„±ì˜ ì¡ìŒì´ ì„ì¸ ì „ì‚¬ë¥¼ ê°œì„ í•˜ì—¬ ê°ë… í’ˆì§ˆì„ í–¥ìƒì‹œí‚¨ë‹¤.
- 4. ë‹¤ì–‘í•œ ë°ì´í„° í˜¼í•© êµ¬ì„±ê³¼ í‰ê°€ ì„¤ì •ì—ì„œì˜ ì‹¤í—˜ ê²°ê³¼, ë¯¸ì„¸ ì¡°ì •ëœ ëª¨ë¸ì´ ì œë¡œìƒ· ê¸°ì¤€ ëª¨ë¸ ëŒ€ë¹„ ì‹¤ì–´ì¦ ìŒì„±ì˜ WERì„ 30% ì´ìƒ ê°ì†Œì‹œí‚¨ë‹¤.
- 5. ì œì•ˆëœ í”„ë ˆì„ì›Œí¬ëŠ” ì‹¤ì œ í™˜ê²½ì—ì„œì˜ ì¥ì•  ìŒì„± ì¸ì‹ì„ ìœ„í•œ í™•ì¥ ê°€ëŠ¥í•˜ê³  íš¨ìœ¨ì ì¸ ì†”ë£¨ì…˜ì„ ì œê³µí•œë‹¤.


---

*Generated on 2025-09-23 10:02:28*