---
keywords:
  - Vision-Language Model
  - Agentic Reasoning
  - Adversarial Robustness
  - Hallucination in Models
  - Structured Inference
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2509.15435
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T08:56:27.929430",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Vision-Language Model",
    "Agentic Reasoning",
    "Adversarial Robustness",
    "Hallucination in Models",
    "Structured Inference"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Vision-Language Model": 0.85,
    "Agentic Reasoning": 0.8,
    "Adversarial Robustness": 0.82,
    "Hallucination in Models": 0.78,
    "Structured Inference": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Vision-Language Models",
        "canonical": "Vision-Language Model",
        "aliases": [
          "LVLMs",
          "Vision-Language Systems"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-Language Models are central to the paper's focus on improving multimodal capabilities and robustness.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Agentic Reasoning",
        "canonical": "Agentic Reasoning",
        "aliases": [
          "ORCA Framework"
        ],
        "category": "unique_technical",
        "rationale": "Agentic Reasoning is a novel framework proposed in the paper for enhancing model robustness.",
        "novelty_score": 0.78,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Adversarial Robustness",
        "canonical": "Adversarial Robustness",
        "aliases": [
          "Robustness to Adversarial Attacks"
        ],
        "category": "specific_connectable",
        "rationale": "Adversarial Robustness is a key outcome of the proposed framework, relevant to many existing models.",
        "novelty_score": 0.5,
        "connectivity_score": 0.75,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "Hallucination",
        "canonical": "Hallucination in Models",
        "aliases": [
          "Model Hallucination"
        ],
        "category": "specific_connectable",
        "rationale": "Addressing hallucination is a critical challenge in LVLMs, directly tackled by the ORCA framework.",
        "novelty_score": 0.55,
        "connectivity_score": 0.7,
        "specificity_score": 0.72,
        "link_intent_score": 0.78
      },
      {
        "surface": "Structured Inference Reasoning",
        "canonical": "Structured Inference",
        "aliases": [
          "Inference Reasoning"
        ],
        "category": "unique_technical",
        "rationale": "Structured Inference Reasoning is a specific method used in ORCA to improve model accuracy.",
        "novelty_score": 0.65,
        "connectivity_score": 0.68,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "Large Vision-Language Models",
      "test-time structured inference"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Vision-Language Models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Agentic Reasoning",
      "resolved_canonical": "Agentic Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.78,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Adversarial Robustness",
      "resolved_canonical": "Adversarial Robustness",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.75,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Hallucination",
      "resolved_canonical": "Hallucination in Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.7,
        "specificity": 0.72,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Structured Inference Reasoning",
      "resolved_canonical": "Structured Inference",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.68,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# ORCA: Agentic Reasoning For Hallucination and Adversarial Robustness in Vision-Language Models

**Korean Title:** ORCA: ì‹œê°-ì–¸ì–´ ëª¨ë¸ì—ì„œ í™˜ê° ë° ì ëŒ€ì  ê²¬ê³ ì„±ì„ ìœ„í•œ ì—ì´ì „íŠ¸ì  ì¶”ë¡ 

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15435.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2509.15435](https://arxiv.org/abs/2509.15435)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/ORIC_ Benchmarking Object Recognition in Incongruous Context for Large Vision-Language Models_20250922|ORIC: Benchmarking Object Recognition in Incongruous Context for Large Vision-Language Models]] (88.7% similar)
- [[2025-09-22/Robust Vision-Language Models via Tensor Decomposition_ A Defense Against Adversarial Attacks_20250922|Robust Vision-Language Models via Tensor Decomposition: A Defense Against Adversarial Attacks]] (84.6% similar)
- [[2025-09-22/Cache-of-Thought_ Master-Apprentice Framework for Cost-Effective Vision Language Model Reasoning_20250922|Cache-of-Thought: Master-Apprentice Framework for Cost-Effective Vision Language Model Reasoning]] (84.1% similar)
- [[2025-09-17/DSCC-HS_ A Dynamic Self-Reinforcing Framework for Hallucination Suppression in Large Language Models_20250917|DSCC-HS: A Dynamic Self-Reinforcing Framework for Hallucination Suppression in Large Language Models]] (83.4% similar)
- [[2025-09-22/EyePCR_ A Comprehensive Benchmark for Fine-Grained Perception, Knowledge Comprehension and Clinical Reasoning in Ophthalmic Surgery_20250922|EyePCR: A Comprehensive Benchmark for Fine-Grained Perception, Knowledge Comprehension and Clinical Reasoning in Ophthalmic Surgery]] (83.4% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Adversarial Robustness|Adversarial Robustness]], [[keywords/Hallucination in Models|Hallucination in Models]]
**âš¡ Unique Technical**: [[keywords/Agentic Reasoning|Agentic Reasoning]], [[keywords/Structured Inference|Structured Inference]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15435v1 Announce Type: cross 
Abstract: Large Vision-Language Models (LVLMs) exhibit strong multimodal capabilities but remain vulnerable to hallucinations from intrinsic errors and adversarial attacks from external exploitations, limiting their reliability in real-world applications. We present ORCA, an agentic reasoning framework that improves the factual accuracy and adversarial robustness of pretrained LVLMs through test-time structured inference reasoning with a suite of small vision models (less than 3B parameters). ORCA operates via an Observe--Reason--Critique--Act loop, querying multiple visual tools with evidential questions, validating cross-model inconsistencies, and refining predictions iteratively without access to model internals or retraining. ORCA also stores intermediate reasoning traces, which supports auditable decision-making. Though designed primarily to mitigate object-level hallucinations, ORCA also exhibits emergent adversarial robustness without requiring adversarial training or defense mechanisms. We evaluate ORCA across three settings: (1) clean images on hallucination benchmarks, (2) adversarially perturbed images without defense, and (3) adversarially perturbed images with defense applied. On the POPE hallucination benchmark, ORCA improves standalone LVLM performance by +3.64\% to +40.67\% across different subsets. Under adversarial perturbations on POPE, ORCA achieves an average accuracy gain of +20.11\% across LVLMs. When combined with defense techniques on adversarially perturbed AMBER images, ORCA further improves standalone LVLM performance, with gains ranging from +1.20\% to +48.00\% across evaluation metrics. These results demonstrate that ORCA offers a promising path toward building more reliable and robust multimodal systems.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15435v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ëŒ€í˜• ë¹„ì „-ì–¸ì–´ ëª¨ë¸(LVLMs)ì€ ê°•ë ¥í•œ ë‹¤ì¤‘ ëª¨ë‹¬ ëŠ¥ë ¥ì„ ë³´ì´ì§€ë§Œ, ë‚´ì¬ì  ì˜¤ë¥˜ë¡œ ì¸í•œ í™˜ê°ê³¼ ì™¸ë¶€ ì•…ìš©ìœ¼ë¡œ ì¸í•œ ì ëŒ€ì  ê³µê²©ì— ì·¨ì•½í•˜ì—¬ ì‹¤ì œ ì‘ìš©ì—ì„œì˜ ì‹ ë¢°ì„±ì„ ì œí•œí•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì‚¬ì „ í•™ìŠµëœ LVLMsì˜ ì‚¬ì‹¤ì  ì •í™•ì„±ê³¼ ì ëŒ€ì  ê°•ê±´ì„±ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ í…ŒìŠ¤íŠ¸ ì‹œê°„ êµ¬ì¡°ì  ì¶”ë¡ ì„ í†µí•´ ì†Œí˜• ë¹„ì „ ëª¨ë¸(3B ë§¤ê°œë³€ìˆ˜ ë¯¸ë§Œ)ì˜ ì§‘í•©ì„ ì‚¬ìš©í•˜ëŠ” ORCAë¼ëŠ” ì—ì´ì „íŠ¸ ì¶”ë¡  í”„ë ˆì„ì›Œí¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ORCAëŠ” ê´€ì°°-ì¶”ë¡ -ë¹„íŒ-í–‰ë™ ë£¨í”„ë¥¼ í†µí•´ ì—¬ëŸ¬ ì‹œê° ë„êµ¬ì— ì¦ê±° ê¸°ë°˜ ì§ˆë¬¸ì„ í•˜ê³ , ëª¨ë¸ ê°„ ë¶ˆì¼ì¹˜ë¥¼ ê²€ì¦í•˜ë©°, ëª¨ë¸ ë‚´ë¶€ ì ‘ê·¼ì´ë‚˜ ì¬í›ˆë ¨ ì—†ì´ ì˜ˆì¸¡ì„ ë°˜ë³µì ìœ¼ë¡œ ìˆ˜ì •í•©ë‹ˆë‹¤. ORCAëŠ” ë˜í•œ ê°ì‚¬ ê°€ëŠ¥í•œ ì˜ì‚¬ ê²°ì •ì„ ì§€ì›í•˜ëŠ” ì¤‘ê°„ ì¶”ë¡  í”ì ì„ ì €ì¥í•©ë‹ˆë‹¤. ì£¼ë¡œ ê°ì²´ ìˆ˜ì¤€ì˜ í™˜ê°ì„ ì™„í™”í•˜ê¸° ìœ„í•´ ì„¤ê³„ë˜ì—ˆì§€ë§Œ, ORCAëŠ” ì ëŒ€ì  í›ˆë ¨ì´ë‚˜ ë°©ì–´ ë©”ì»¤ë‹ˆì¦˜ ì—†ì´ë„ ë°œìƒí•˜ëŠ” ì ëŒ€ì  ê°•ê±´ì„±ì„ ë³´ì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ORCAë¥¼ ì„¸ ê°€ì§€ ì„¤ì •ì—ì„œ í‰ê°€í•©ë‹ˆë‹¤: (1) í™˜ê° ë²¤ì¹˜ë§ˆí¬ì—ì„œì˜ ê¹¨ë—í•œ ì´ë¯¸ì§€, (2) ë°©ì–´ ì—†ì´ ì ëŒ€ì ìœ¼ë¡œ ë³€í˜•ëœ ì´ë¯¸ì§€, (3) ë°©ì–´ê°€ ì ìš©ëœ ì ëŒ€ì ìœ¼ë¡œ ë³€í˜•ëœ ì´ë¯¸ì§€. POPE í™˜ê° ë²¤ì¹˜ë§ˆí¬ì—ì„œ ORCAëŠ” ë…ë¦½í˜• LVLM ì„±ëŠ¥ì„ ë‹¤ì–‘í•œ í•˜ìœ„ ì§‘í•©ì—ì„œ +3.64%ì—ì„œ +40.67%ê¹Œì§€ í–¥ìƒì‹œí‚µë‹ˆë‹¤. POPEì—ì„œì˜ ì ëŒ€ì  ë³€í˜• í•˜ì—ì„œ ORCAëŠ” LVLMs ì „ë°˜ì— ê±¸ì³ í‰ê·  ì •í™•ë„ ì¦ê°€ +20.11%ë¥¼ ë‹¬ì„±í•©ë‹ˆë‹¤. ì ëŒ€ì ìœ¼ë¡œ ë³€í˜•ëœ AMBER ì´ë¯¸ì§€ì— ë°©ì–´ ê¸°ë²•ì„ ê²°í•©í•  ë•Œ, ORCAëŠ” ë…ë¦½í˜• LVLM ì„±ëŠ¥ì„ ë”ìš± í–¥ìƒì‹œì¼œ í‰ê°€ ì§€í‘œ ì „ë°˜ì— ê±¸ì³ +1.20%ì—ì„œ +48.00%ê¹Œì§€ì˜ í–¥ìƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŸ¬í•œ ê²°ê³¼ëŠ” ORCAê°€ ë³´ë‹¤ ì‹ ë¢°í•  ìˆ˜ ìˆê³  ê°•ë ¥í•œ ë‹¤ì¤‘ ëª¨ë‹¬ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ëŠ” ë° ìœ ë§í•œ ê²½ë¡œë¥¼ ì œê³µí•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ëŒ€í˜• ë¹„ì „-ì–¸ì–´ ëª¨ë¸(LVLM)ì€ ê°•ë ¥í•œ ë‹¤ì¤‘ ëª¨ë‹¬ ê¸°ëŠ¥ì„ ê°€ì§€ê³  ìˆì§€ë§Œ, ë‚´ì¬ì  ì˜¤ë¥˜ì™€ ì™¸ë¶€ ê³µê²©ìœ¼ë¡œ ì¸í•œ í™˜ê°ì— ì·¨ì•½í•˜ì—¬ ì‹¤ì œ ì‘ìš©ì—ì„œ ì‹ ë¢°ì„±ì´ ì œí•œë©ë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ORCAë¼ëŠ” ì—ì´ì „íŠ¸ì  ì¶”ë¡  í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•˜ì—¬, ì‚¬ì „ í•™ìŠµëœ LVLMì˜ ì‚¬ì‹¤ì  ì •í™•ì„±ê³¼ ì ëŒ€ì  ê°•ì¸ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ORCAëŠ” ì‘ì€ ë¹„ì „ ëª¨ë¸ì„ í™œìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸ ì‹œ êµ¬ì¡°í™”ëœ ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ë©°, ëª¨ë¸ ë‚´ë¶€ ì ‘ê·¼ì´ë‚˜ ì¬í•™ìŠµ ì—†ì´ ì˜ˆì¸¡ì„ ê°œì„ í•©ë‹ˆë‹¤. ORCAëŠ” ì¤‘ê°„ ì¶”ë¡  ê³¼ì •ì„ ì €ì¥í•˜ì—¬ ê²€ì¦ ê°€ëŠ¥í•œ ì˜ì‚¬ê²°ì •ì„ ì§€ì›í•˜ë©°, ê°ì²´ ìˆ˜ì¤€ í™˜ê°ì„ ì¤„ì´ê¸° ìœ„í•´ ì„¤ê³„ë˜ì—ˆì§€ë§Œ, ì ëŒ€ì  ê°•ì¸ì„±ë„ ë°œí˜„í•©ë‹ˆë‹¤. POPE í™˜ê° ë²¤ì¹˜ë§ˆí¬ì—ì„œ ORCAëŠ” LVLM ì„±ëŠ¥ì„ ìµœëŒ€ 40.67%ê¹Œì§€ í–¥ìƒì‹œì¼°ìœ¼ë©°, ì ëŒ€ì  ì´ë¯¸ì§€ì—ì„œë„ í‰ê·  20.11%ì˜ ì •í™•ë„ í–¥ìƒì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ê²°ê³¼ëŠ” ORCAê°€ ë” ì‹ ë¢°í•  ìˆ˜ ìˆê³  ê°•ë ¥í•œ ë‹¤ì¤‘ ëª¨ë‹¬ ì‹œìŠ¤í…œ êµ¬ì¶•ì— ìœ ë§í•œ ê²½ë¡œë¥¼ ì œê³µí•¨ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ORCAëŠ” ëŒ€í˜• ë¹„ì „-ì–¸ì–´ ëª¨ë¸(LVLM)ì˜ ì‚¬ì‹¤ì  ì •í™•ì„±ê³¼ ì ëŒ€ì  ê²¬ê³ ì„±ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ì„¤ê³„ëœ ì—ì´ì „íŠ¸ì  ì¶”ë¡  í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.
- 2. ORCAëŠ” ê´€ì°°-ì¶”ë¡ -ë¹„íŒ-í–‰ë™ ë£¨í”„ë¥¼ í†µí•´ ì—¬ëŸ¬ ì‹œê° ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¦ê±° ê¸°ë°˜ ì§ˆë¬¸ì„ í•˜ê³ , êµì°¨ ëª¨ë¸ ë¶ˆì¼ì¹˜ë¥¼ ê²€ì¦í•˜ë©°, ì˜ˆì¸¡ì„ ë°˜ë³µì ìœ¼ë¡œ ìˆ˜ì •í•©ë‹ˆë‹¤.
- 3. ORCAëŠ” ì£¼ë¡œ ê°ì²´ ìˆ˜ì¤€ì˜ í™˜ê°ì„ ì™„í™”í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆì§€ë§Œ, ì ëŒ€ì  í›ˆë ¨ì´ë‚˜ ë°©ì–´ ë©”ì»¤ë‹ˆì¦˜ ì—†ì´ë„ ì ëŒ€ì  ê²¬ê³ ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
- 4. POPE í™˜ê° ë²¤ì¹˜ë§ˆí¬ì—ì„œ ORCAëŠ” ë…ë¦½í˜• LVLM ì„±ëŠ¥ì„ +3.64%ì—ì„œ +40.67%ê¹Œì§€ ê°œì„ í–ˆìŠµë‹ˆë‹¤.
- 5. ORCAëŠ” ì ëŒ€ì ìœ¼ë¡œ ë³€í˜•ëœ ì´ë¯¸ì§€ì— ë°©ì–´ ê¸°ìˆ ì„ ê²°í•©í•  ë•Œ, í‰ê°€ ì§€í‘œ ì „ë°˜ì— ê±¸ì³ ë…ë¦½í˜• LVLM ì„±ëŠ¥ì„ +1.20%ì—ì„œ +48.00%ê¹Œì§€ ì¶”ê°€ë¡œ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-23 08:56:27*