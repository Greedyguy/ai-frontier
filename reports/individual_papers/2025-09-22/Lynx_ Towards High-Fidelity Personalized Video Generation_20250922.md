---
keywords:
  - Transformer
  - Perceiver Resampler
  - Facial Embeddings
  - Variational Autoencoder
  - Attention Mechanism
category: cs.CV
publish_date: 2025-09-22
arxiv_id: 2509.15496
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:58:37.310759",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Transformer",
    "Perceiver Resampler",
    "Facial Embeddings",
    "Variational Autoencoder",
    "Attention Mechanism"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Transformer": 0.85,
    "Perceiver Resampler": 0.7,
    "Facial Embeddings": 0.8,
    "Variational Autoencoder": 0.78,
    "Attention Mechanism": 0.82
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Diffusion Transformer",
        "canonical": "Transformer",
        "aliases": [
          "DiT"
        ],
        "category": "broad_technical",
        "rationale": "The Diffusion Transformer is a specific application of the Transformer model, which is a fundamental concept in machine learning, aiding in linking various related works.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Perceiver Resampler",
        "canonical": "Perceiver Resampler",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This is a novel component introduced in the paper, which is crucial for identity fidelity in video generation, offering a unique link to this work.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      },
      {
        "surface": "ArcFace-derived facial embeddings",
        "canonical": "Facial Embeddings",
        "aliases": [
          "ArcFace"
        ],
        "category": "specific_connectable",
        "rationale": "Facial embeddings are a specific concept in computer vision, and linking to ArcFace provides a connection to identity verification technologies.",
        "novelty_score": 0.5,
        "connectivity_score": 0.75,
        "specificity_score": 0.78,
        "link_intent_score": 0.8
      },
      {
        "surface": "Dense VAE features",
        "canonical": "Variational Autoencoder",
        "aliases": [
          "VAE"
        ],
        "category": "specific_connectable",
        "rationale": "VAEs are a well-known model in machine learning, and dense VAE features are crucial for fine-grained detail preservation, enhancing connectivity with generative models.",
        "novelty_score": 0.55,
        "connectivity_score": 0.82,
        "specificity_score": 0.72,
        "link_intent_score": 0.78
      },
      {
        "surface": "Cross-attention",
        "canonical": "Attention Mechanism",
        "aliases": [
          "Cross-attention"
        ],
        "category": "specific_connectable",
        "rationale": "Cross-attention is a specific application of the attention mechanism, which is pivotal in transformer architectures, facilitating links to a broad range of related research.",
        "novelty_score": 0.4,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.82
      }
    ],
    "ban_list_suggestions": [
      "identity fidelity",
      "temporal coherence",
      "visual realism"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Diffusion Transformer",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Perceiver Resampler",
      "resolved_canonical": "Perceiver Resampler",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "ArcFace-derived facial embeddings",
      "resolved_canonical": "Facial Embeddings",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.75,
        "specificity": 0.78,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Dense VAE features",
      "resolved_canonical": "Variational Autoencoder",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.82,
        "specificity": 0.72,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Cross-attention",
      "resolved_canonical": "Attention Mechanism",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.82
      }
    }
  ]
}
-->

# Lynx: Towards High-Fidelity Personalized Video Generation

**Korean Title:** Lynx: 고충실도 개인 맞춤형 비디오 생성에 대한 연구

## 📋 메타데이터

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15496.pdf)
**Category**: cs.CV
**Published**: 2025-09-22
**ArXiv ID**: [2509.15496](https://arxiv.org/abs/2509.15496)

## 🔗 유사한 논문
- [[2025-09-19/Controllable Localized Face Anonymization Via Diffusion Inpainting_20250919|Controllable Localized Face Anonymization Via Diffusion Inpainting]] (81.4% similar)
- [[2025-09-18/Identity-Preserving Text-to-Video Generation Guided by Simple yet Effective Spatial-Temporal Decoupled Representations_20250918|Identity-Preserving Text-to-Video Generation Guided by Simple yet Effective Spatial-Temporal Decoupled Representations]] (80.6% similar)
- [[2025-09-22/Combo_ Co-speech holistic 3D human motion generation and efficient customizable adaptation in harmony_20250922|Combo: Co-speech holistic 3D human motion generation and efficient customizable adaptation in harmony]] (79.3% similar)
- [[2025-09-19/AToken_ A Unified Tokenizer for Vision_20250919|AToken: A Unified Tokenizer for Vision]] (79.2% similar)
- [[2025-09-22/Emulating Human-like Adaptive Vision for Efficient and Flexible Machine Visual Perception_20250922|Emulating Human-like Adaptive Vision for Efficient and Flexible Machine Visual Perception]] (79.1% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Transformer|Transformer]]
**🔗 Specific Connectable**: [[keywords/Facial Embeddings|Facial Embeddings]], [[keywords/Variational Autoencoder|Variational Autoencoder]], [[keywords/Attention Mechanism|Attention Mechanism]]
**⚡ Unique Technical**: [[keywords/Perceiver Resampler|Perceiver Resampler]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.15496v1 Announce Type: new 
Abstract: We present Lynx, a high-fidelity model for personalized video synthesis from a single input image. Built on an open-source Diffusion Transformer (DiT) foundation model, Lynx introduces two lightweight adapters to ensure identity fidelity. The ID-adapter employs a Perceiver Resampler to convert ArcFace-derived facial embeddings into compact identity tokens for conditioning, while the Ref-adapter integrates dense VAE features from a frozen reference pathway, injecting fine-grained details across all transformer layers through cross-attention. These modules collectively enable robust identity preservation while maintaining temporal coherence and visual realism. Through evaluation on a curated benchmark of 40 subjects and 20 unbiased prompts, which yielded 800 test cases, Lynx has demonstrated superior face resemblance, competitive prompt following, and strong video quality, thereby advancing the state of personalized video generation.

## 🔍 Abstract (한글 번역)

arXiv:2509.15496v1 발표 유형: 신규  
초록: 우리는 단일 입력 이미지로부터 개인화된 비디오 합성을 위한 고충실도 모델인 Lynx를 소개합니다. 오픈 소스 Diffusion Transformer (DiT) 기반 모델에 구축된 Lynx는 정체성 충실도를 보장하기 위해 두 개의 경량 어댑터를 도입합니다. ID-어댑터는 ArcFace에서 유도된 얼굴 임베딩을 조건부로 사용하기 위해 Perceiver Resampler를 사용하여 압축된 정체성 토큰으로 변환하며, Ref-어댑터는 고정된 참조 경로에서 밀집 VAE 특징을 통합하여 교차 주의를 통해 모든 변환기 레이어에 세밀한 세부사항을 주입합니다. 이러한 모듈들은 집합적으로 시간적 일관성과 시각적 사실성을 유지하면서 강력한 정체성 보존을 가능하게 합니다. 40명의 피험자와 20개의 편향 없는 프롬프트로 구성된 큐레이션된 벤치마크에서 800개의 테스트 사례를 통해 평가한 결과, Lynx는 우수한 얼굴 유사성, 경쟁력 있는 프롬프트 수행, 강력한 비디오 품질을 입증하여 개인화된 비디오 생성의 상태를 발전시켰습니다.

## 📝 요약

Lynx는 단일 입력 이미지로부터 개인화된 비디오를 생성하는 고품질 모델입니다. 이 모델은 오픈소스 Diffusion Transformer(DiT) 기반으로 구축되었으며, 두 가지 경량 어댑터를 도입하여 정체성 유지를 보장합니다. ID-어댑터는 ArcFace에서 파생된 얼굴 임베딩을 압축된 정체성 토큰으로 변환하고, Ref-어댑터는 고정된 참조 경로에서 밀집 VAE 특징을 통합하여 모든 변환기 층에 세밀한 디테일을 주입합니다. 이러한 모듈들은 정체성 보존과 시각적 현실성을 유지하면서도 시간적 일관성을 제공합니다. 40명의 피험자와 20개의 편향되지 않은 프롬프트로 구성된 벤치마크 평가에서 Lynx는 뛰어난 얼굴 유사성, 경쟁력 있는 프롬프트 수행, 높은 비디오 품질을 보여주며 개인화된 비디오 생성의 발전을 이루었습니다.

## 🎯 주요 포인트

- 1. Lynx는 단일 입력 이미지로부터 개인화된 비디오 합성을 위한 고충실도 모델입니다.
- 2. Lynx는 Diffusion Transformer 기반 모델에 두 개의 경량 어댑터를 도입하여 정체성 충실도를 보장합니다.
- 3. ID-adapter는 ArcFace에서 파생된 얼굴 임베딩을 압축된 정체성 토큰으로 변환하여 조건화합니다.
- 4. Ref-adapter는 고정된 참조 경로에서 밀집된 VAE 특징을 통합하여 모든 트랜스포머 레이어에 세밀한 디테일을 주입합니다.
- 5. Lynx는 40명의 피험자와 20개의 편향되지 않은 프롬프트로 구성된 벤치마크 평가를 통해 뛰어난 얼굴 유사성과 비디오 품질을 입증했습니다.


---

*Generated on 2025-09-23 11:58:37*