---
keywords:
  - Large Language Model
  - Knowledge Graph
  - Temporal Reasoning
  - EvoReasoner
  - EvoKG
category: cs.LG
publish_date: 2025-09-22
arxiv_id: 2509.15464
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T10:25:54.256706",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Knowledge Graph",
    "Temporal Reasoning",
    "EvoReasoner",
    "EvoKG"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Knowledge Graph": 0.8,
    "Temporal Reasoning": 0.78,
    "EvoReasoner": 0.7,
    "EvoKG": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "A foundational concept in the paper, linking to a broad range of NLP and AI topics.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.5,
        "link_intent_score": 0.85
      },
      {
        "surface": "Knowledge Graphs",
        "canonical": "Knowledge Graph",
        "aliases": [
          "KGs"
        ],
        "category": "specific_connectable",
        "rationale": "Central to the paper's approach, facilitating connections to graph-based reasoning and data structures.",
        "novelty_score": 0.4,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Temporal Reasoning",
        "canonical": "Temporal Reasoning",
        "aliases": [
          "Time-based Reasoning"
        ],
        "category": "unique_technical",
        "rationale": "A unique aspect of the paper's contribution, focusing on time-sensitive data processing.",
        "novelty_score": 0.65,
        "connectivity_score": 0.75,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "EvoReasoner",
        "canonical": "EvoReasoner",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "A novel algorithm introduced in the paper, crucial for understanding its specific contributions.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.9,
        "link_intent_score": 0.7
      },
      {
        "surface": "EvoKG",
        "canonical": "EvoKG",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "A new module proposed in the paper, significant for its role in updating knowledge graphs.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.88,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "method",
      "approach",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.5,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Knowledge Graphs",
      "resolved_canonical": "Knowledge Graph",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Temporal Reasoning",
      "resolved_canonical": "Temporal Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.75,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "EvoReasoner",
      "resolved_canonical": "EvoReasoner",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.9,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "EvoKG",
      "resolved_canonical": "EvoKG",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.88,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# Temporal Reasoning with Large Language Models Augmented by Evolving Knowledge Graphs

**Korean Title:** 시간적 추론: 진화하는 지식 그래프로 보강된 대형 언어 모델을 활용하여

## 📋 메타데이터

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15464.pdf)
**Category**: cs.LG
**Published**: 2025-09-22
**ArXiv ID**: [2509.15464](https://arxiv.org/abs/2509.15464)

## 🔗 유사한 논문
- [[2025-09-22/Query Optimization for Parametric Knowledge Refinement in Retrieval-Augmented Large Language Models_20250922|Query Optimization for Parametric Knowledge Refinement in Retrieval-Augmented Large Language Models]] (85.9% similar)
- [[2025-09-19/Enhancing Logical Reasoning in Language Models via Symbolically-Guided Monte Carlo Process Supervision_20250919|Enhancing Logical Reasoning in Language Models via Symbolically-Guided Monte Carlo Process Supervision]] (85.8% similar)
- [[2025-09-18/KBM_ Delineating Knowledge Boundary for Adaptive Retrieval in Large Language Models_20250918|KBM: Delineating Knowledge Boundary for Adaptive Retrieval in Large Language Models]] (85.2% similar)
- [[2025-09-17/THOR_ Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning_20250917|THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning]] (85.1% similar)
- [[2025-09-22/Entropy-Regularized Process Reward Model_20250922|Entropy-Regularized Process Reward Model]] (85.0% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Knowledge Graph|Knowledge Graph]]
**⚡ Unique Technical**: [[keywords/Temporal Reasoning|Temporal Reasoning]], [[keywords/EvoReasoner|EvoReasoner]], [[keywords/EvoKG|EvoKG]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.15464v1 Announce Type: new 
Abstract: Large language models (LLMs) excel at many language understanding tasks but struggle to reason over knowledge that evolves. To address this, recent work has explored augmenting LLMs with knowledge graphs (KGs) to provide structured, up-to-date information. However, many existing approaches assume a static snapshot of the KG and overlook the temporal dynamics and factual inconsistencies inherent in real-world data. To address the challenge of reasoning over temporally shifting knowledge, we propose EvoReasoner, a temporal-aware multi-hop reasoning algorithm that performs global-local entity grounding, multi-route decomposition, and temporally grounded scoring. To ensure that the underlying KG remains accurate and up-to-date, we introduce EvoKG, a noise-tolerant KG evolution module that incrementally updates the KG from unstructured documents through confidence-based contradiction resolution and temporal trend tracking. We evaluate our approach on temporal QA benchmarks and a novel end-to-end setting where the KG is dynamically updated from raw documents. Our method outperforms both prompting-based and KG-enhanced baselines, effectively narrowing the gap between small and large LLMs on dynamic question answering. Notably, an 8B-parameter model using our approach matches the performance of a 671B model prompted seven months later. These results highlight the importance of combining temporal reasoning with KG evolution for robust and up-to-date LLM performance. Our code is publicly available at github.com/junhongmit/TREK.

## 🔍 Abstract (한글 번역)

arXiv:2509.15464v1 발표 유형: 새로운 것  
초록: 대형 언어 모델(LLMs)은 많은 언어 이해 작업에서 뛰어난 성능을 보이지만, 변화하는 지식을 추론하는 데 어려움을 겪습니다. 이를 해결하기 위해 최근 연구에서는 LLMs에 지식 그래프(KGs)를 추가하여 구조화되고 최신 정보를 제공하는 방법을 탐구하고 있습니다. 그러나 많은 기존 접근 방식은 KG의 정적 스냅샷을 가정하고, 실제 데이터에 내재된 시간적 역학 및 사실적 불일치를 간과합니다. 시간적으로 변화하는 지식을 추론하는 문제를 해결하기 위해, 우리는 글로벌-로컬 엔티티 그라운딩, 다중 경로 분해 및 시간적으로 기반이 된 점수를 수행하는 시간 인식 다중 홉 추론 알고리즘인 EvoReasoner를 제안합니다. 기본 KG가 정확하고 최신 상태를 유지하도록 하기 위해, 우리는 비구조화된 문서로부터 신뢰 기반 모순 해결 및 시간적 추세 추적을 통해 KG를 점진적으로 업데이트하는 노이즈 내성 KG 진화 모듈인 EvoKG를 도입합니다. 우리는 시간적 QA 벤치마크와 원시 문서로부터 KG가 동적으로 업데이트되는 새로운 종단 간 설정에서 우리의 접근 방식을 평가합니다. 우리의 방법은 프롬프트 기반 및 KG 강화 기준선을 능가하여 동적 질문 응답에서 작은 LLM과 큰 LLM 간의 격차를 효과적으로 좁힙니다. 특히, 우리의 접근 방식을 사용하는 8B-파라미터 모델은 7개월 후 프롬프트된 671B 모델의 성능과 일치합니다. 이러한 결과는 강력하고 최신의 LLM 성능을 위해 시간적 추론과 KG 진화를 결합하는 것의 중요성을 강조합니다. 우리의 코드는 github.com/junhongmit/TREK에서 공개적으로 이용 가능합니다.

## 📝 요약

이 논문은 대형 언어 모델(LLM)이 시간에 따라 변화하는 지식을 다루는 데 어려움을 겪는 문제를 해결하기 위해, 지식 그래프(KG)를 활용한 EvoReasoner라는 알고리즘을 제안합니다. EvoReasoner는 시간 인식 멀티홉 추론을 통해 글로벌-로컬 엔티티 연결, 다중 경로 분해, 시간 기반 점수를 수행합니다. 또한, EvoKG 모듈을 통해 비구조화된 문서로부터 KG를 점진적으로 업데이트하여 최신 정보를 유지합니다. 이 방법은 시간 기반 질문 응답 벤치마크와 동적으로 KG를 업데이트하는 새로운 설정에서 기존 방법들보다 우수한 성능을 보였습니다. 특히, 8억 개의 매개변수를 가진 모델이 671억 개의 모델과 유사한 성능을 발휘함을 보여주며, 시간적 추론과 KG 진화의 중요성을 강조합니다. 코드와 관련 자료는 GitHub에서 공개되어 있습니다.

## 🎯 주요 포인트

- 1. EvoReasoner는 시간에 따라 변화하는 지식을 다루기 위해 글로벌-로컬 엔티티 그라운딩, 다중 경로 분해, 시간 기반 스코어링을 수행하는 알고리즘입니다.
- 2. EvoKG는 신뢰 기반 모순 해결과 시간 추세 추적을 통해 비정형 문서에서 KG를 점진적으로 업데이트하는 모듈입니다.
- 3. 제안된 방법은 시간적 QA 벤치마크와 원시 문서에서 동적으로 업데이트되는 KG를 사용하는 새로운 설정에서 평가되었습니다.
- 4. 8B-파라미터 모델이 제안된 방법을 사용하여 671B 모델의 성능과 일치하며, 이는 작은 LLM과 큰 LLM 간의 성능 격차를 효과적으로 줄였습니다.
- 5. 시간적 추론과 KG 진화의 결합이 강력하고 최신의 LLM 성능을 위해 중요하다는 점을 강조합니다.


---

*Generated on 2025-09-23 10:25:54*