---
keywords:
  - Large Language Model
  - Competitive Programming
  - Ollama Runtime
  - Kattis Problem Set
  - Gemini Model
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2509.15283
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T08:52:57.876308",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Competitive Programming",
    "Ollama Runtime",
    "Kattis Problem Set",
    "Gemini Model"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Competitive Programming": 0.78,
    "Ollama Runtime": 0.65,
    "Kattis Problem Set": 0.72,
    "Gemini Model": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "This term is central to the study and connects with existing research on language models.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "competitive programming tasks",
        "canonical": "Competitive Programming",
        "aliases": [
          "programming challenges"
        ],
        "category": "specific_connectable",
        "rationale": "Links to a specific application domain of LLMs, relevant for connecting with programming-focused studies.",
        "novelty_score": 0.7,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Ollama runtime",
        "canonical": "Ollama Runtime",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "A unique technical term specific to the study's methodology, useful for linking implementation details.",
        "novelty_score": 0.85,
        "connectivity_score": 0.6,
        "specificity_score": 0.9,
        "link_intent_score": 0.65
      },
      {
        "surface": "Kattis corpus",
        "canonical": "Kattis Problem Set",
        "aliases": [
          "Kattis"
        ],
        "category": "unique_technical",
        "rationale": "Specific dataset used in the study, important for linking to other works using the same corpus.",
        "novelty_score": 0.75,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.72
      },
      {
        "surface": "Gemini 1.5",
        "canonical": "Gemini Model",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "A specific model compared in the study, relevant for linking to proprietary model discussions.",
        "novelty_score": 0.8,
        "connectivity_score": 0.65,
        "specificity_score": 0.88,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "performance",
      "method",
      "evaluation"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "competitive programming tasks",
      "resolved_canonical": "Competitive Programming",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Ollama runtime",
      "resolved_canonical": "Ollama Runtime",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.6,
        "specificity": 0.9,
        "link_intent": 0.65
      }
    },
    {
      "candidate_surface": "Kattis corpus",
      "resolved_canonical": "Kattis Problem Set",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "Gemini 1.5",
      "resolved_canonical": "Gemini Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.65,
        "specificity": 0.88,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# Evaluating the Limitations of Local LLMs in Solving Complex Programming Challenges

**Korean Title:** 지역 LLM의 복잡한 프로그래밍 문제 해결에 대한 한계 평가

## 📋 메타데이터

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15283.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2509.15283](https://arxiv.org/abs/2509.15283)

## 🔗 유사한 논문
- [[2025-09-22/Are LLMs Better Formalizers than Solvers on Complex Problems?_20250922|Are LLMs Better Formalizers than Solvers on Complex Problems?]] (85.5% similar)
- [[2025-09-22/A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages_20250922|A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages]] (85.2% similar)
- [[2025-09-19/Automating Modelica Module Generation Using Large Language Models_ A Case Study on Building Control Description Language_20250919|Automating Modelica Module Generation Using Large Language Models: A Case Study on Building Control Description Language]] (84.4% similar)
- [[2025-09-19/CodeLSI_ Leveraging Foundation Models for Automated Code Generation with Low-Rank Optimization and Domain-Specific Instruction Tuning_20250919|CodeLSI: Leveraging Foundation Models for Automated Code Generation with Low-Rank Optimization and Domain-Specific Instruction Tuning]] (83.6% similar)
- [[2025-09-22/How do Language Models Generate Slang_ A Systematic Comparison between Human and Machine-Generated Slang Usages_20250922|How do Language Models Generate Slang: A Systematic Comparison between Human and Machine-Generated Slang Usages]] (83.4% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Competitive Programming|Competitive Programming]]
**⚡ Unique Technical**: [[keywords/Ollama Runtime|Ollama Runtime]], [[keywords/Kattis Problem Set|Kattis Problem Set]], [[keywords/Gemini Model|Gemini Model]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.15283v1 Announce Type: cross 
Abstract: This study examines the performance of today's open-source, locally hosted large-language models (LLMs) in handling complex competitive programming tasks with extended problem descriptions and contexts. Building on the original Framework for AI-driven Code Generation Evaluation (FACE), the authors retrofit the pipeline to work entirely offline through the Ollama runtime, collapsing FACE's sprawling per-problem directory tree into a handful of consolidated JSON files, and adding robust checkpointing so multi-day runs can resume after failures. The enhanced framework generates, submits, and records solutions for the full Kattis corpus of 3,589 problems across eight code-oriented models ranging from 6.7-9 billion parameters. The submission results show that the overall pass@1 accuracy is modest for the local models, with the best models performing at approximately half the acceptance rate of the proprietary models, Gemini 1.5 and ChatGPT-4. These findings expose a persistent gap between private, cost-controlled LLM deployments and state-of-the-art proprietary services, yet also highlight the rapid progress of open models and the practical benefits of an evaluation workflow that organizations can replicate on in-house hardware.

## 🔍 Abstract (한글 번역)

arXiv:2509.15283v1 발표 유형: 교차  
초록: 이 연구는 오늘날의 오픈 소스, 로컬 호스팅된 대형 언어 모델(LLM)이 확장된 문제 설명과 맥락을 포함한 복잡한 경쟁 프로그래밍 작업을 처리하는 성능을 조사합니다. AI 기반 코드 생성 평가를 위한 원래의 프레임워크(FACE)를 기반으로, 저자들은 Ollama 런타임을 통해 파이프라인을 완전히 오프라인으로 작동하도록 개조하여 FACE의 방대한 문제별 디렉토리 트리를 몇 개의 통합된 JSON 파일로 축소하고, 다중일 실행이 실패 후에도 재개될 수 있도록 강력한 체크포인트 기능을 추가했습니다. 향상된 프레임워크는 6.7-9억 매개변수 범위의 8개 코드 지향 모델에 걸쳐 3,589개의 문제로 구성된 전체 Kattis 코퍼스에 대한 솔루션을 생성, 제출 및 기록합니다. 제출 결과는 로컬 모델의 전반적인 pass@1 정확도가 미미하며, 최고의 모델이 Gemini 1.5 및 ChatGPT-4와 같은 독점 모델의 수용률의 절반 정도에 불과하다는 것을 보여줍니다. 이러한 결과는 사설, 비용 통제된 LLM 배포와 최첨단 독점 서비스 간의 지속적인 격차를 드러내지만, 또한 오픈 모델의 빠른 발전과 조직이 자체 하드웨어에서 복제할 수 있는 평가 워크플로우의 실질적인 이점을 강조합니다.

## 📝 요약

이 연구는 오늘날의 오픈 소스, 로컬 호스팅된 대형 언어 모델(LLM)이 복잡한 프로그래밍 문제를 처리하는 성능을 평가합니다. 기존 AI 기반 코드 생성 평가 프레임워크(FACE)를 오프라인 환경에서 작동하도록 수정하여 Ollama 런타임을 통해 문제 해결 과정을 통합하고, 체크포인트 기능을 추가했습니다. 6.7-9억 매개변수를 가진 8개의 코드 지향 모델을 사용하여 3,589개의 Kattis 문제에 대한 솔루션을 생성, 제출, 기록했습니다. 결과적으로 로컬 모델의 pass@1 정확도는 낮았으며, 상위 모델도 Gemini 1.5 및 ChatGPT-4와 비교하여 절반 수준의 수용률을 보였습니다. 이는 사설 LLM과 최신 상용 서비스 간의 격차를 보여주지만, 오픈 모델의 빠른 발전과 자체 하드웨어에서 평가 워크플로를 복제할 수 있는 실질적 이점을 강조합니다.

## 🎯 주요 포인트

- 1. 본 연구는 복잡한 경쟁 프로그래밍 과제를 처리하는 데 있어 오픈 소스, 로컬 호스팅 대형 언어 모델(LLM)의 성능을 평가합니다.
- 2. 연구진은 FACE 프레임워크를 오프라인에서 완전히 작동하도록 개조하여 Ollama 런타임을 통해 문제별 디렉토리 트리를 통합된 JSON 파일로 축소하고, 견고한 체크포인트 기능을 추가했습니다.
- 3. 연구 결과, 로컬 모델의 전체 pass@1 정확도는 보통 수준이며, 최고의 모델도 Gemini 1.5와 ChatGPT-4 같은 독점 모델의 절반 정도의 수락률을 보였습니다.
- 4. 이 결과는 비용이 통제된 LLM 배포와 최첨단 독점 서비스 간의 지속적인 격차를 드러내지만, 오픈 모델의 빠른 발전과 조직이 자체 하드웨어에서 복제할 수 있는 평가 워크플로의 실질적인 이점을 강조합니다.


---

*Generated on 2025-09-23 08:52:57*