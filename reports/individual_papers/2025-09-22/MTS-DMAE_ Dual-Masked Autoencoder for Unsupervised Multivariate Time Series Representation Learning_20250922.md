---
keywords:
  - Dual-Masked Autoencoder
  - Unsupervised Multivariate Time Series Representation Learning
  - Masked Time-Series Modeling
  - Self-supervised Learning
category: cs.LG
publish_date: 2025-09-22
arxiv_id: 2509.16078
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T10:41:42.150482",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Dual-Masked Autoencoder",
    "Unsupervised Multivariate Time Series Representation Learning",
    "Masked Time-Series Modeling",
    "Self-supervised Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Dual-Masked Autoencoder": 0.8,
    "Unsupervised Multivariate Time Series Representation Learning": 0.75,
    "Masked Time-Series Modeling": 0.78,
    "Self-supervised Learning": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Dual-Masked Autoencoder",
        "canonical": "Dual-Masked Autoencoder",
        "aliases": [
          "DMAE"
        ],
        "category": "unique_technical",
        "rationale": "A novel framework specifically introduced in the paper, providing a unique approach to MTS representation learning.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "Unsupervised Multivariate Time Series Representation Learning",
        "canonical": "Unsupervised Multivariate Time Series Representation Learning",
        "aliases": [
          "Unsupervised MTS Representation Learning"
        ],
        "category": "unique_technical",
        "rationale": "Central to the paper's focus, this concept is key for understanding the context of the proposed method.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.75
      },
      {
        "surface": "Masked Time-Series Modeling",
        "canonical": "Masked Time-Series Modeling",
        "aliases": [
          "Masked Time-Series"
        ],
        "category": "unique_technical",
        "rationale": "Describes the innovative approach used in the paper, crucial for linking to related techniques.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Self-supervised Learning",
        "canonical": "Self-supervised Learning",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "This concept is integral to the methodology and connects well with existing literature on learning paradigms.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.75,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "representation",
      "learning",
      "framework"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Dual-Masked Autoencoder",
      "resolved_canonical": "Dual-Masked Autoencoder",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Unsupervised Multivariate Time Series Representation Learning",
      "resolved_canonical": "Unsupervised Multivariate Time Series Representation Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Masked Time-Series Modeling",
      "resolved_canonical": "Masked Time-Series Modeling",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Self-supervised Learning",
      "resolved_canonical": "Self-supervised Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.75,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# MTS-DMAE: Dual-Masked Autoencoder for Unsupervised Multivariate Time Series Representation Learning

**Korean Title:** MTS-DMAE: ë¹„ì§€ë„ ë‹¤ë³€ëŸ‰ ì‹œê³„ì—´ í‘œí˜„ í•™ìŠµì„ ìœ„í•œ ì´ì¤‘ ë§ˆìŠ¤í¬ ìë™ ì¸ì½”ë”

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16078.pdf)
**Category**: cs.LG
**Published**: 2025-09-22
**ArXiv ID**: [2509.16078](https://arxiv.org/abs/2509.16078)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/MoCA_ Multi-modal Cross-masked Autoencoder for Digital Health Measurements_20250922|MoCA: Multi-modal Cross-masked Autoencoder for Digital Health Measurements]] (82.7% similar)
- [[2025-09-18/Masked Feature Modeling Enhances Adaptive Segmentation_20250918|Masked Feature Modeling Enhances Adaptive Segmentation]] (81.5% similar)
- [[2025-09-22/VMDNet_ Time Series Forecasting with Leakage-Free Samplewise Variational Mode Decomposition and Multibranch Decoding_20250922|VMDNet: Time Series Forecasting with Leakage-Free Samplewise Variational Mode Decomposition and Multibranch Decoding]] (80.7% similar)
- [[2025-09-17/Bridging Past and Future_ Distribution-Aware Alignment for Time Series Forecasting_20250917|Bridging Past and Future: Distribution-Aware Alignment for Time Series Forecasting]] (80.6% similar)
- [[2025-09-18/Beyond Marginals_ Learning Joint Spatio-Temporal Patterns for Multivariate Anomaly Detection_20250918|Beyond Marginals: Learning Joint Spatio-Temporal Patterns for Multivariate Anomaly Detection]] (80.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Self-supervised Learning|Self-supervised Learning]]
**âš¡ Unique Technical**: [[keywords/Dual-Masked Autoencoder|Dual-Masked Autoencoder]], [[keywords/Unsupervised Multivariate Time Series Representation Learning|Unsupervised Multivariate Time Series Representation Learning]], [[keywords/Masked Time-Series Modeling|Masked Time-Series Modeling]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16078v1 Announce Type: new 
Abstract: Unsupervised multivariate time series (MTS) representation learning aims to extract compact and informative representations from raw sequences without relying on labels, enabling efficient transfer to diverse downstream tasks. In this paper, we propose Dual-Masked Autoencoder (DMAE), a novel masked time-series modeling framework for unsupervised MTS representation learning. DMAE formulates two complementary pretext tasks: (1) reconstructing masked values based on visible attributes, and (2) estimating latent representations of masked features, guided by a teacher encoder. To further improve representation quality, we introduce a feature-level alignment constraint that encourages the predicted latent representations to align with the teacher's outputs. By jointly optimizing these objectives, DMAE learns temporally coherent and semantically rich representations. Comprehensive evaluations across classification, regression, and forecasting tasks demonstrate that our approach achieves consistent and superior performance over competitive baselines.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.16078v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: ë¹„ì§€ë„ ë‹¤ë³€ëŸ‰ ì‹œê³„ì—´(MTS) í‘œí˜„ í•™ìŠµì€ ë ˆì´ë¸”ì— ì˜ì¡´í•˜ì§€ ì•Šê³  ì›ì‹œ ì‹œí€€ìŠ¤ë¡œë¶€í„° ê°„ê²°í•˜ê³  ì •ë³´ê°€ í’ë¶€í•œ í‘œí˜„ì„ ì¶”ì¶œí•˜ì—¬ ë‹¤ì–‘í•œ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—…ìœ¼ë¡œì˜ íš¨ìœ¨ì ì¸ ì „ì´ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤. ì´ ë…¼ë¬¸ì—ì„œëŠ” ë¹„ì§€ë„ MTS í‘œí˜„ í•™ìŠµì„ ìœ„í•œ ìƒˆë¡œìš´ ë§ˆìŠ¤í¬ë“œ ì‹œê³„ì—´ ëª¨ë¸ë§ í”„ë ˆì„ì›Œí¬ì¸ Dual-Masked Autoencoder (DMAE)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. DMAEëŠ” ë‘ ê°€ì§€ ìƒí˜¸ ë³´ì™„ì ì¸ ì‚¬ì „ ê³¼ì œë¥¼ ê³µì‹í™”í•©ë‹ˆë‹¤: (1) ë³´ì´ëŠ” ì†ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ ë§ˆìŠ¤í¬ëœ ê°’ì„ ì¬êµ¬ì„±í•˜ëŠ” ê²ƒ, ê·¸ë¦¬ê³  (2) êµì‚¬ ì¸ì½”ë”ì— ì˜í•´ ì•ˆë‚´ë˜ëŠ” ë§ˆìŠ¤í¬ëœ íŠ¹ì§•ì˜ ì ì¬ í‘œí˜„ì„ ì¶”ì •í•˜ëŠ” ê²ƒ. í‘œí˜„ì˜ í’ˆì§ˆì„ ë”ìš± í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ì˜ˆì¸¡ëœ ì ì¬ í‘œí˜„ì´ êµì‚¬ì˜ ì¶œë ¥ê³¼ ì •ë ¬ë˜ë„ë¡ ìœ ë„í•˜ëŠ” íŠ¹ì§• ìˆ˜ì¤€ì˜ ì •ë ¬ ì œì•½ì„ ë„ì…í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ëª©í‘œë¥¼ ê³µë™ìœ¼ë¡œ ìµœì í™”í•¨ìœ¼ë¡œì¨, DMAEëŠ” ì‹œê°„ì ìœ¼ë¡œ ì¼ê´€ë˜ê³  ì˜ë¯¸ì ìœ¼ë¡œ í’ë¶€í•œ í‘œí˜„ì„ í•™ìŠµí•©ë‹ˆë‹¤. ë¶„ë¥˜, íšŒê·€ ë° ì˜ˆì¸¡ ì‘ì—… ì „ë°˜ì— ê±¸ì¹œ ì¢…í•©ì ì¸ í‰ê°€ë¥¼ í†µí•´ ìš°ë¦¬ì˜ ì ‘ê·¼ ë°©ì‹ì´ ê²½ìŸë ¥ ìˆëŠ” ê¸°ì¤€ì„ ë³´ë‹¤ ì¼ê´€ë˜ê³  ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë‹¬ì„±í•¨ì„ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì—ì„œëŠ” ë¹„ì§€ë„ ë‹¤ë³€ëŸ‰ ì‹œê³„ì—´ í‘œí˜„ í•™ìŠµì„ ìœ„í•œ ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ì¸ Dual-Masked Autoencoder (DMAE)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. DMAEëŠ” ë‘ ê°€ì§€ ë³´ì¡° ê³¼ì œë¥¼ í†µí•´ ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ëª¨ë¸ë§í•©ë‹ˆë‹¤: (1) ë³´ì´ëŠ” ì†ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ ë§ˆìŠ¤í‚¹ëœ ê°’ì„ ì¬êµ¬ì„±í•˜ê³ , (2) êµì‚¬ ì¸ì½”ë”ì˜ ì§€ë„ë¥¼ ë°›ì•„ ë§ˆìŠ¤í‚¹ëœ íŠ¹ì§•ì˜ ì ì¬ í‘œí˜„ì„ ì¶”ì •í•©ë‹ˆë‹¤. ë˜í•œ, ì˜ˆì¸¡ëœ ì ì¬ í‘œí˜„ì´ êµì‚¬ì˜ ì¶œë ¥ê³¼ ì •ë ¬ë˜ë„ë¡ í•˜ëŠ” íŠ¹ì§• ìˆ˜ì¤€ì˜ ì •ë ¬ ì œì•½ì„ ë„ì…í•˜ì—¬ í‘œí˜„ì˜ í’ˆì§ˆì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì´ ë°©ë²•ë¡ ì€ ì‹œê³„ì—´ì˜ ì‹œê°„ì  ì¼ê´€ì„±ê³¼ ì˜ë¯¸ì  í’ë¶€í•¨ì„ í•™ìŠµí•˜ë©°, ë¶„ë¥˜, íšŒê·€, ì˜ˆì¸¡ ì‘ì—…ì—ì„œ ê¸°ì¡´ ê¸°ë²•ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Dual-Masked Autoencoder (DMAE)ëŠ” ë¹„ì§€ë„ ë‹¤ë³€ëŸ‰ ì‹œê³„ì—´ í‘œí˜„ í•™ìŠµì„ ìœ„í•œ ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.
- 2. DMAEëŠ” ë‘ ê°€ì§€ ë³´ì™„ì ì¸ ì‚¬ì „ ê³¼ì œë¥¼ í†µí•´ ë§ˆìŠ¤í‚¹ëœ ê°’ì„ ì¬êµ¬ì„±í•˜ê³ , ë§ˆìŠ¤í‚¹ëœ íŠ¹ì§•ì˜ ì ì¬ í‘œí˜„ì„ ì¶”ì •í•©ë‹ˆë‹¤.
- 3. íŠ¹ì§• ìˆ˜ì¤€ì˜ ì •ë ¬ ì œì•½ì„ ë„ì…í•˜ì—¬ ì˜ˆì¸¡ëœ ì ì¬ í‘œí˜„ì´ êµì‚¬ ì¸ì½”ë”ì˜ ì¶œë ¥ê³¼ ì •ë ¬ë˜ë„ë¡ ìœ ë„í•©ë‹ˆë‹¤.
- 4. DMAEëŠ” ì‹œê°„ì ìœ¼ë¡œ ì¼ê´€ë˜ê³  ì˜ë¯¸ì ìœ¼ë¡œ í’ë¶€í•œ í‘œí˜„ì„ í•™ìŠµí•©ë‹ˆë‹¤.
- 5. ë¶„ë¥˜, íšŒê·€, ì˜ˆì¸¡ ì‘ì—…ì—ì„œ DMAEëŠ” ê²½ìŸë ¥ ìˆëŠ” ê¸°ì¤€ì„ ë³´ë‹¤ ì¼ê´€ë˜ê³  ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.


---

*Generated on 2025-09-23 10:41:42*