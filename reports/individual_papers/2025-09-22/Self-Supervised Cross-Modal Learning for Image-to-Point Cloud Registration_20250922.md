---
keywords:
  - Self-supervised Learning
  - Multimodal Learning
  - Image-to-Point Cloud Registration
  - Geometric-Semantic Embedding
  - Coarse-to-Fine Registration
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2509.15882
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T09:18:00.083081",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Self-supervised Learning",
    "Multimodal Learning",
    "Image-to-Point Cloud Registration",
    "Geometric-Semantic Embedding",
    "Coarse-to-Fine Registration"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Self-supervised Learning": 0.8,
    "Multimodal Learning": 0.78,
    "Image-to-Point Cloud Registration": 0.72,
    "Geometric-Semantic Embedding": 0.7,
    "Coarse-to-Fine Registration": 0.68
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Self-supervised",
        "canonical": "Self-supervised Learning",
        "aliases": [
          "self-supervised"
        ],
        "category": "specific_connectable",
        "rationale": "Self-supervised learning is a key technique in the proposed framework, enabling annotation-free alignment.",
        "novelty_score": 0.55,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Cross-modal learning",
        "canonical": "Multimodal Learning",
        "aliases": [
          "cross-modal"
        ],
        "category": "specific_connectable",
        "rationale": "Cross-modal learning is central to bridging 2D and 3D modalities, enhancing connectivity with existing multimodal concepts.",
        "novelty_score": 0.6,
        "connectivity_score": 0.88,
        "specificity_score": 0.75,
        "link_intent_score": 0.78
      },
      {
        "surface": "Image-to-point cloud registration",
        "canonical": "Image-to-Point Cloud Registration",
        "aliases": [
          "I2P registration"
        ],
        "category": "unique_technical",
        "rationale": "This unique technical process is the core focus of the paper, offering a novel approach to registration tasks.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.72
      },
      {
        "surface": "Geometric-semantic fused embedding",
        "canonical": "Geometric-Semantic Embedding",
        "aliases": [
          "fused embedding"
        ],
        "category": "unique_technical",
        "rationale": "This embedding technique is pivotal for aligning 2D and 3D data, providing a unique link to semantic and geometric integration.",
        "novelty_score": 0.68,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      },
      {
        "surface": "Coarse-to-fine registration",
        "canonical": "Coarse-to-Fine Registration",
        "aliases": [
          "coarse-to-fine"
        ],
        "category": "unique_technical",
        "rationale": "This registration paradigm is crucial for achieving precise alignment, linking to hierarchical processing concepts.",
        "novelty_score": 0.65,
        "connectivity_score": 0.67,
        "specificity_score": 0.78,
        "link_intent_score": 0.68
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Self-supervised",
      "resolved_canonical": "Self-supervised Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Cross-modal learning",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.88,
        "specificity": 0.75,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Image-to-point cloud registration",
      "resolved_canonical": "Image-to-Point Cloud Registration",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "Geometric-semantic fused embedding",
      "resolved_canonical": "Geometric-Semantic Embedding",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Coarse-to-fine registration",
      "resolved_canonical": "Coarse-to-Fine Registration",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.67,
        "specificity": 0.78,
        "link_intent": 0.68
      }
    }
  ]
}
-->

# Self-Supervised Cross-Modal Learning for Image-to-Point Cloud Registration

**Korean Title:** ìê¸° ì§€ë„ í•™ìŠµì„ í†µí•œ ì´ë¯¸ì§€-í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ì •í•©ì„ ìœ„í•œ êµì°¨ ëª¨ë‹¬ í•™ìŠµ

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15882.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2509.15882](https://arxiv.org/abs/2509.15882)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Seeing 3D Through 2D Lenses_ 3D Few-Shot Class-Incremental Learning via Cross-Modal Geometric Rectification_20250919|Seeing 3D Through 2D Lenses: 3D Few-Shot Class-Incremental Learning via Cross-Modal Geometric Rectification]] (85.3% similar)
- [[2025-09-18/InterKey_ Cross-modal Intersection Keypoints for Global Localization on OpenStreetMap_20250918|InterKey: Cross-modal Intersection Keypoints for Global Localization on OpenStreetMap]] (82.0% similar)
- [[2025-09-22/Towards Sharper Object Boundaries in Self-Supervised Depth Estimation_20250922|Towards Sharper Object Boundaries in Self-Supervised Depth Estimation]] (81.4% similar)
- [[2025-09-22/A re-calibration method for object detection with multi-modal alignment bias in autonomous driving_20250922|A re-calibration method for object detection with multi-modal alignment bias in autonomous driving]] (81.2% similar)
- [[2025-09-19/Semantic-LiDAR-Inertial-Wheel Odometry Fusion for Robust Localization in Large-Scale Dynamic Environments_20250919|Semantic-LiDAR-Inertial-Wheel Odometry Fusion for Robust Localization in Large-Scale Dynamic Environments]] (81.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Self-supervised Learning|Self-supervised Learning]], [[keywords/Multimodal Learning|Multimodal Learning]]
**âš¡ Unique Technical**: [[keywords/Image-to-Point Cloud Registration|Image-to-Point Cloud Registration]], [[keywords/Geometric-Semantic Embedding|Geometric-Semantic Embedding]], [[keywords/Coarse-to-Fine Registration|Coarse-to-Fine Registration]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15882v1 Announce Type: cross 
Abstract: Bridging 2D and 3D sensor modalities is critical for robust perception in autonomous systems. However, image-to-point cloud (I2P) registration remains challenging due to the semantic-geometric gap between texture-rich but depth-ambiguous images and sparse yet metrically precise point clouds, as well as the tendency of existing methods to converge to local optima. To overcome these limitations, we introduce CrossI2P, a self-supervised framework that unifies cross-modal learning and two-stage registration in a single end-to-end pipeline. First, we learn a geometric-semantic fused embedding space via dual-path contrastive learning, enabling annotation-free, bidirectional alignment of 2D textures and 3D structures. Second, we adopt a coarse-to-fine registration paradigm: a global stage establishes superpoint-superpixel correspondences through joint intra-modal context and cross-modal interaction modeling, followed by a geometry-constrained point-level refinement for precise registration. Third, we employ a dynamic training mechanism with gradient normalization to balance losses for feature alignment, correspondence refinement, and pose estimation. Extensive experiments demonstrate that CrossI2P outperforms state-of-the-art methods by 23.7% on the KITTI Odometry benchmark and by 37.9% on nuScenes, significantly improving both accuracy and robustness.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15882v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ììœ¨ ì‹œìŠ¤í…œì—ì„œ ê²¬ê³ í•œ ì¸ì‹ì„ ìœ„í•´ 2Dì™€ 3D ì„¼ì„œ ëª¨ë‹¬ë¦¬í‹°ë¥¼ ì—°ê²°í•˜ëŠ” ê²ƒì€ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ë¯¸ì§€ì—ì„œ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ(I2P)ë¡œì˜ ì •í•©ì€ í…ìŠ¤ì²˜ê°€ í’ë¶€í•˜ì§€ë§Œ ê¹Šì´ê°€ ëª¨í˜¸í•œ ì´ë¯¸ì§€ì™€ í¬ì†Œí•˜ì§€ë§Œ ì¸¡ì •ì ìœ¼ë¡œ ì •í™•í•œ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ì‚¬ì´ì˜ ì˜ë¯¸-ê¸°í•˜í•™ì  ì°¨ì´ë¡œ ì¸í•´ ì—¬ì „íˆ ì–´ë ¤ì›€ì„ ê²ªê³  ìˆìœ¼ë©°, ê¸°ì¡´ ë°©ë²•ë“¤ì´ ì§€ì—­ ìµœì ì ì— ìˆ˜ë ´í•˜ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì œí•œì„ ê·¹ë³µí•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” í¬ë¡œìŠ¤I2P(CrossI2P)ë¼ëŠ” ìê¸° ì§€ë„ í•™ìŠµ í”„ë ˆì„ì›Œí¬ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” í¬ë¡œìŠ¤ ëª¨ë‹¬ í•™ìŠµê³¼ 2ë‹¨ê³„ ì •í•©ì„ ë‹¨ì¼ ì¢…ë‹¨ ê°„ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ í†µí•©í•©ë‹ˆë‹¤. ë¨¼ì €, ì´ì¤‘ ê²½ë¡œ ëŒ€ì¡° í•™ìŠµì„ í†µí•´ ê¸°í•˜í•™ì -ì˜ë¯¸ì  ìœµí•© ì„ë² ë”© ê³µê°„ì„ í•™ìŠµí•˜ì—¬ ì£¼ì„ ì—†ì´ 2D í…ìŠ¤ì²˜ì™€ 3D êµ¬ì¡°ì˜ ì–‘ë°©í–¥ ì •ë ¬ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ë‘ ë²ˆì§¸ë¡œ, ìš°ë¦¬ëŠ” ê±°ì¹ ê²Œë¶€í„° ì •ë°€í•˜ê²Œì˜ ì •í•© íŒ¨ëŸ¬ë‹¤ì„ì„ ì±„íƒí•©ë‹ˆë‹¤: ì „ì—­ ë‹¨ê³„ì—ì„œëŠ” ëª¨ë‹¬ ë‚´ ë§¥ë½ê³¼ ëª¨ë‹¬ ê°„ ìƒí˜¸ì‘ìš© ëª¨ë¸ë§ì„ í†µí•´ ìŠˆí¼í¬ì¸íŠ¸-ìŠˆí¼í”½ì…€ ëŒ€ì‘ì„ ì„¤ì •í•˜ê³ , ì´ì–´ì„œ ì •ë°€í•œ ì •í•©ì„ ìœ„í•œ ê¸°í•˜í•™ì  ì œì•½ì„ ê°€ì§„ í¬ì¸íŠ¸ ìˆ˜ì¤€ì˜ ì •ì œë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì„¸ ë²ˆì§¸ë¡œ, ìš°ë¦¬ëŠ” íŠ¹ì§• ì •ë ¬, ëŒ€ì‘ ì •ì œ ë° ìì„¸ ì¶”ì •ì„ ìœ„í•œ ì†ì‹¤ì„ ê· í˜• ìˆê²Œ ì¡°ì •í•˜ê¸° ìœ„í•´ ê·¸ë˜ë””ì–¸íŠ¸ ì •ê·œí™”ë¥¼ ì‚¬ìš©í•˜ëŠ” ë™ì  í›ˆë ¨ ë©”ì»¤ë‹ˆì¦˜ì„ ì±„íƒí•©ë‹ˆë‹¤. ê´‘ë²”ìœ„í•œ ì‹¤í—˜ ê²°ê³¼, í¬ë¡œìŠ¤I2PëŠ” KITTI ì£¼í–‰ ê²½ë¡œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ 23.7%, nuScenesì—ì„œ 37.9% ë” ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì—¬, ì •í™•ì„±ê³¼ ê²¬ê³ ì„±ì„ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ììœ¨ ì‹œìŠ¤í…œì—ì„œ 2D ì´ë¯¸ì§€ì™€ 3D í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ê°„ì˜ ë“±ë¡ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ CrossI2Pë¼ëŠ” ìê°€ ì§€ë„ í•™ìŠµ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. CrossI2PëŠ” í¬ë¡œìŠ¤ ëª¨ë‹¬ í•™ìŠµê³¼ ì´ë‹¨ê³„ ë“±ë¡ì„ í†µí•©í•˜ì—¬ 2D í…ìŠ¤ì²˜ì™€ 3D êµ¬ì¡°ì˜ ì •ë ¬ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ì²« ë²ˆì§¸ ë‹¨ê³„ì—ì„œëŠ” ëŒ€ì¡° í•™ìŠµì„ í†µí•´ ê¸°í•˜í•™ì -ì˜ë¯¸ë¡ ì  ì„ë² ë”© ê³µê°„ì„ í•™ìŠµí•˜ê³ , ë‘ ë²ˆì§¸ ë‹¨ê³„ì—ì„œëŠ” ê¸€ë¡œë²Œ ë‹¨ê³„ì™€ ê¸°í•˜í•™ì  ì œì•½ì„ í†µí•œ ì •ë°€ ë“±ë¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ë˜í•œ, ë™ì  í•™ìŠµ ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´ íŠ¹ì§• ì •ë ¬ê³¼ ìì„¸ ì¶”ì •ì˜ ì†ì‹¤ì„ ê· í˜• ìˆê²Œ ì¡°ì •í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, CrossI2PëŠ” KITTI Odometryì™€ nuScenes ë²¤ì¹˜ë§ˆí¬ì—ì„œ ê°ê° 23.7%ì™€ 37.9%ì˜ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. CrossI2PëŠ” ìê°€ ì§€ë„ í•™ìŠµ í”„ë ˆì„ì›Œí¬ë¡œ, 2D ì´ë¯¸ì§€ì™€ 3D í¬ì¸íŠ¸ í´ë¼ìš°ë“œì˜ êµì°¨ ëª¨ë‹¬ í•™ìŠµê³¼ ì´ë‹¨ê³„ ì •í•©ì„ í†µí•©í•˜ì—¬ ë‹¨ì¼ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ êµ¬í˜„í•©ë‹ˆë‹¤.
- 2. ê¸°í•˜í•™ì -ì˜ë¯¸ì  ìœµí•© ì„ë² ë”© ê³µê°„ì„ í•™ìŠµí•˜ì—¬ ì£¼ì„ ì—†ì´ 2D í…ìŠ¤ì²˜ì™€ 3D êµ¬ì¡°ì˜ ì–‘ë°©í–¥ ì •ë ¬ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
- 3. ì¡°-ì„¸ë°€ ì •í•© íŒ¨ëŸ¬ë‹¤ì„ì„ ì±„íƒí•˜ì—¬, ê¸€ë¡œë²Œ ë‹¨ê³„ì—ì„œ ìŠˆí¼í¬ì¸íŠ¸-ìŠˆí¼í”½ì…€ ëŒ€ì‘ì„ ì„¤ì •í•˜ê³ , ê¸°í•˜í•™ì  ì œì•½ì„ í†µí•œ í¬ì¸íŠ¸ ë ˆë²¨ ì •ë°€ ì •í•©ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
- 4. ë™ì  í•™ìŠµ ë©”ì»¤ë‹ˆì¦˜ê³¼ ê·¸ë˜ë””ì–¸íŠ¸ ì •ê·œí™”ë¥¼ í™œìš©í•˜ì—¬ íŠ¹ì§• ì •ë ¬, ëŒ€ì‘ ì •ì œ, ìì„¸ ì¶”ì •ì˜ ì†ì‹¤ ê· í˜•ì„ ë§ì¶¥ë‹ˆë‹¤.
- 5. CrossI2PëŠ” KITTI Odometry ë²¤ì¹˜ë§ˆí¬ì—ì„œ 23.7%, nuScenesì—ì„œ 37.9% ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì—¬, ì •í™•ì„±ê³¼ ê²¬ê³ ì„±ì„ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤.


---

*Generated on 2025-09-23 09:18:00*