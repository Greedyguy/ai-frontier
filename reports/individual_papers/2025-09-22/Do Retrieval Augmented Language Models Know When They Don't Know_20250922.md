---
keywords:
  - Retrieval Augmented Generation
  - Refusal Post-Training
  - In-Context Fine-Tuning
  - Over-Refusal Behavior
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2509.01476
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T10:10:59.764842",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Retrieval Augmented Generation",
    "Refusal Post-Training",
    "In-Context Fine-Tuning",
    "Over-Refusal Behavior"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Retrieval Augmented Generation": 0.79,
    "Refusal Post-Training": 0.81,
    "In-Context Fine-Tuning": 0.77,
    "Over-Refusal Behavior": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Retrieval Augmented Language Models",
        "canonical": "Retrieval Augmented Generation",
        "aliases": [
          "RALMs"
        ],
        "category": "specific_connectable",
        "rationale": "Connects to the concept of enhancing language models with retrieval mechanisms, which is a trending topic.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.82,
        "link_intent_score": 0.79
      },
      {
        "surface": "Refusal Post-Training",
        "canonical": "Refusal Post-Training",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Introduces a novel approach to improve model responses by training them to refuse uncertain answers.",
        "novelty_score": 0.72,
        "connectivity_score": 0.65,
        "specificity_score": 0.78,
        "link_intent_score": 0.81
      },
      {
        "surface": "In-Context Fine-Tuning",
        "canonical": "In-Context Fine-Tuning",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Represents a specific method of fine-tuning models using contextual information, enhancing model adaptability.",
        "novelty_score": 0.68,
        "connectivity_score": 0.72,
        "specificity_score": 0.75,
        "link_intent_score": 0.77
      },
      {
        "surface": "Over-Refusal Behavior",
        "canonical": "Over-Refusal Behavior",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Highlights a specific issue in model behavior that affects the balance between refusal and answer quality.",
        "novelty_score": 0.65,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "hallucinations",
      "evaluation",
      "influence"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Retrieval Augmented Language Models",
      "resolved_canonical": "Retrieval Augmented Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.82,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Refusal Post-Training",
      "resolved_canonical": "Refusal Post-Training",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.65,
        "specificity": 0.78,
        "link_intent": 0.81
      }
    },
    {
      "candidate_surface": "In-Context Fine-Tuning",
      "resolved_canonical": "In-Context Fine-Tuning",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.72,
        "specificity": 0.75,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Over-Refusal Behavior",
      "resolved_canonical": "Over-Refusal Behavior",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# Do Retrieval Augmented Language Models Know When They Don't Know?

**Korean Title:** íšŒìˆ˜ ì¦ê°• ì–¸ì–´ ëª¨ë¸ì€ ìì‹ ì´ ëª¨ë¥¼ ë•Œë¥¼ ì•Œê³  ìˆëŠ”ê°€?

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.01476.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2509.01476](https://arxiv.org/abs/2509.01476)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/It Depends_ Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge_20250922|It Depends: Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge]] (86.5% similar)
- [[2025-09-22/Quantifying Self-Awareness of Knowledge in Large Language Models_20250922|Quantifying Self-Awareness of Knowledge in Large Language Models]] (85.1% similar)
- [[2025-09-22/Query Optimization for Parametric Knowledge Refinement in Retrieval-Augmented Large Language Models_20250922|Query Optimization for Parametric Knowledge Refinement in Retrieval-Augmented Large Language Models]] (84.7% similar)
- [[2025-09-22/Pointing to a Llama and Call it a Camel_ On the Sycophancy of Multimodal Large Language Models_20250922|Pointing to a Llama and Call it a Camel: On the Sycophancy of Multimodal Large Language Models]] (84.7% similar)
- [[2025-09-22/Search and Refine During Think_ Facilitating Knowledge Refinement for Improved Retrieval-Augmented Reasoning_20250922|Search and Refine During Think: Facilitating Knowledge Refinement for Improved Retrieval-Augmented Reasoning]] (84.4% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Retrieval Augmented Generation|Retrieval Augmented Generation]]
**âš¡ Unique Technical**: [[keywords/Refusal Post-Training|Refusal Post-Training]], [[keywords/In-Context Fine-Tuning|In-Context Fine-Tuning]], [[keywords/Over-Refusal Behavior|Over-Refusal Behavior]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.01476v2 Announce Type: replace-cross 
Abstract: Existing Large Language Models (LLMs) occasionally generate plausible yet factually incorrect responses, known as hallucinations. Researchers are primarily using two approaches to mitigate hallucinations, namely Retrieval Augmented Language Models (RALMs) and refusal post-training. However, current research predominantly emphasizes their individual effectiveness while overlooking the evaluation of the refusal capability of RALMs. In this study, we ask the fundamental question: Do RALMs know when they don't know? Specifically, we ask three questions. First, are RALMs well-calibrated regarding different internal and external knowledge states? We examine the influence of various factors. Contrary to expectations, we find that LLMs exhibit significant \textbf{over-refusal} behavior. Then, how does refusal post-training affect the over-refusal issue? We investigate the Refusal-aware Instruction Tuning and In-Context Fine-tuning methods. Our results show that the over-refusal problem is mitigated by In-context fine-tuning. but magnified by R-tuning. However, we also find that the refusal ability may conflict with the quality of the answer. Finally, we develop a simple yet effective refusal method for refusal post-trained models to improve their overall answer quality in terms of refusal and correct answers. Our study provides a more comprehensive understanding of the influence of important factors on RALM systems.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.01476v2 ë°œí‘œ ìœ í˜•: êµì°¨ êµì²´  
ì´ˆë¡: ê¸°ì¡´ì˜ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ ë•Œë•Œë¡œ ê·¸ëŸ´ë“¯í•˜ì§€ë§Œ ì‚¬ì‹¤ê³¼ ë‹¤ë¥¸ ì‘ë‹µì„ ìƒì„±í•˜ëŠ”ë°, ì´ë¥¼ í™˜ê°(hallucinations)ì´ë¼ê³  í•©ë‹ˆë‹¤. ì—°êµ¬ìë“¤ì€ ì£¼ë¡œ í™˜ê°ì„ ì¤„ì´ê¸° ìœ„í•´ ê²€ìƒ‰ ì¦ê°• ì–¸ì–´ ëª¨ë¸(RALM)ê³¼ ê±°ë¶€ í›„ í•™ìŠµì´ë¼ëŠ” ë‘ ê°€ì§€ ì ‘ê·¼ ë°©ì‹ì„ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ í˜„ì¬ ì—°êµ¬ëŠ” ì£¼ë¡œ ì´ë“¤ì˜ ê°œë³„ì ì¸ íš¨ê³¼ì— ì¤‘ì ì„ ë‘ê³  ìˆìœ¼ë©°, RALMì˜ ê±°ë¶€ ëŠ¥ë ¥ í‰ê°€ë¥¼ ê°„ê³¼í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ì—ì„œëŠ” ê¸°ë³¸ì ì¸ ì§ˆë¬¸ì„ ì œê¸°í•©ë‹ˆë‹¤: RALMì€ ìì‹ ì´ ëª¨ë¥¼ ë•Œë¥¼ ì•Œ ìˆ˜ ìˆì„ê¹Œìš”? êµ¬ì²´ì ìœ¼ë¡œ ì„¸ ê°€ì§€ ì§ˆë¬¸ì„ ë˜ì§‘ë‹ˆë‹¤. ì²«ì§¸, RALMì€ ë‹¤ì–‘í•œ ë‚´ë¶€ ë° ì™¸ë¶€ ì§€ì‹ ìƒíƒœì— ëŒ€í•´ ì˜ ë³´ì •ë˜ì–´ ìˆëŠ”ê°€? ì—¬ëŸ¬ ìš”ì¸ì˜ ì˜í–¥ì„ ì¡°ì‚¬í•©ë‹ˆë‹¤. ê¸°ëŒ€ì™€ ë‹¬ë¦¬, LLMì€ ìƒë‹¹í•œ \textbf{ê³¼ë„í•œ ê±°ë¶€} í–‰ë™ì„ ë³´ì¸ë‹¤ëŠ” ê²ƒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ê·¸ë ‡ë‹¤ë©´ ê±°ë¶€ í›„ í•™ìŠµì€ ê³¼ë„í•œ ê±°ë¶€ ë¬¸ì œì— ì–´ë–»ê²Œ ì˜í–¥ì„ ë¯¸ì¹ ê¹Œìš”? ìš°ë¦¬ëŠ” ê±°ë¶€ ì¸ì‹ ì§€ì‹œ ì¡°ì •ê³¼ ë§¥ë½ ë‚´ ë¯¸ì„¸ ì¡°ì • ë°©ë²•ì„ ì¡°ì‚¬í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ê²°ê³¼ëŠ” ë§¥ë½ ë‚´ ë¯¸ì„¸ ì¡°ì •ì´ ê³¼ë„í•œ ê±°ë¶€ ë¬¸ì œë¥¼ ì™„í™”í•˜ì§€ë§Œ, R-íŠœë‹ì— ì˜í•´ í™•ëŒ€ëœë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ìš°ë¦¬ëŠ” ë˜í•œ ê±°ë¶€ ëŠ¥ë ¥ì´ ë‹µë³€ì˜ ì§ˆê³¼ ì¶©ëŒí•  ìˆ˜ ìˆìŒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ, ìš°ë¦¬ëŠ” ê±°ë¶€ í›„ í•™ìŠµëœ ëª¨ë¸ì˜ ì „ë°˜ì ì¸ ë‹µë³€ í’ˆì§ˆì„ ê±°ë¶€ì™€ ì˜¬ë°”ë¥¸ ë‹µë³€ ì¸¡ë©´ì—ì„œ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ê°„ë‹¨í•˜ë©´ì„œë„ íš¨ê³¼ì ì¸ ê±°ë¶€ ë°©ë²•ì„ ê°œë°œí–ˆìŠµë‹ˆë‹¤. ìš°ë¦¬ì˜ ì—°êµ¬ëŠ” RALM ì‹œìŠ¤í…œì— ì¤‘ìš”í•œ ìš”ì¸ì´ ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë³´ë‹¤ í¬ê´„ì ìœ¼ë¡œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ í™˜ê° ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ë‘ ê°€ì§€ ì ‘ê·¼ë²•, ì¦‰ ê²€ìƒ‰ ì¦ê°• ì–¸ì–´ ëª¨ë¸(RALM)ê³¼ ê±°ë¶€ í›„ í•™ìŠµì— ëŒ€í•´ ë‹¤ë£¹ë‹ˆë‹¤. ì—°êµ¬ëŠ” RALMì˜ ê±°ë¶€ ëŠ¥ë ¥ì„ í‰ê°€í•˜ëŠ” ë° ì¤‘ì ì„ ë‘ë©°, RALMì´ ìì‹ ì˜ ì§€ì‹ í•œê³„ë¥¼ ì¸ì§€í•˜ëŠ”ì§€ë¥¼ ì¡°ì‚¬í•©ë‹ˆë‹¤. ì—°êµ¬ ê²°ê³¼, LLMì´ ê³¼ë„í•œ ê±°ë¶€ í–‰ë™ì„ ë³´ì´ë©°, ì´ëŠ” In-context ë¯¸ì„¸ ì¡°ì •ìœ¼ë¡œ ì™„í™”ë˜ì§€ë§Œ R-íŠœë‹ìœ¼ë¡œëŠ” ì•…í™”ë©ë‹ˆë‹¤. ë˜í•œ, ê±°ë¶€ ëŠ¥ë ¥ì´ ë‹µë³€ì˜ ì§ˆê³¼ ì¶©ëŒí•  ìˆ˜ ìˆìŒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ, ì—°êµ¬ëŠ” ê±°ë¶€ í›„ í•™ìŠµëœ ëª¨ë¸ì˜ ì „ë°˜ì ì¸ ë‹µë³€ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ê°„ë‹¨í•˜ë©´ì„œë„ íš¨ê³¼ì ì¸ ê±°ë¶€ ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” RALM ì‹œìŠ¤í…œì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ì£¼ìš” ìš”ì¸ì— ëŒ€í•œ í¬ê´„ì ì¸ ì´í•´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì€ ì¢…ì¢… ì‚¬ì‹¤ê³¼ ë‹¤ë¥¸ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í™˜ê°(hallucinations) ë¬¸ì œë¥¼ ê²ªìœ¼ë©°, ì´ë¥¼ ì™„í™”í•˜ê¸° ìœ„í•´ ê²€ìƒ‰ ì¦ê°• ì–¸ì–´ ëª¨ë¸(RALMs)ê³¼ ê±°ë¶€ í›„ í›ˆë ¨ ë°©ë²•ì´ ì‚¬ìš©ëœë‹¤.
- 2. ì—°êµ¬ì—ì„œëŠ” RALMsì˜ ê±°ë¶€ ëŠ¥ë ¥ í‰ê°€ë¥¼ ê°„ê³¼í•œ ê¸°ì¡´ ì—°êµ¬ì™€ ë‹¬ë¦¬, RALMsê°€ ìì‹ ì´ ëª¨ë¥´ëŠ” ê²ƒì„ ì¸ì§€í•  ìˆ˜ ìˆëŠ”ì§€ë¥¼ íƒêµ¬í•œë‹¤.
- 3. RALMsëŠ” ë‚´ë¶€ ë° ì™¸ë¶€ ì§€ì‹ ìƒíƒœì— ëŒ€í•œ ê³¼ì‰ ê±°ë¶€(over-refusal) í–‰ë™ì„ ë³´ì´ë©°, ì´ëŠ” In-context fine-tuningìœ¼ë¡œ ì™„í™”ë˜ì§€ë§Œ R-tuningìœ¼ë¡œëŠ” ì•…í™”ëœë‹¤.
- 4. ê±°ë¶€ ëŠ¥ë ¥ì€ ì‘ë‹µì˜ ì§ˆê³¼ ìƒì¶©í•  ìˆ˜ ìˆìœ¼ë©°, ì´ë¥¼ ê°œì„ í•˜ê¸° ìœ„í•´ ê°„ë‹¨í•˜ì§€ë§Œ íš¨ê³¼ì ì¸ ê±°ë¶€ ë°©ë²•ì„ ê°œë°œí•˜ì˜€ë‹¤.
- 5. ë³¸ ì—°êµ¬ëŠ” RALM ì‹œìŠ¤í…œì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ì¤‘ìš”í•œ ìš”ì†Œë“¤ì— ëŒ€í•œ í¬ê´„ì ì¸ ì´í•´ë¥¼ ì œê³µí•œë‹¤.


---

*Generated on 2025-09-23 10:10:59*