---
keywords:
  - Multimodal Learning
  - LiDAR Point Cloud
  - Calibration Bias
  - Semantic Segmentation
category: cs.CV
publish_date: 2025-09-22
arxiv_id: 2405.16848
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T12:27:22.133980",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multimodal Learning",
    "LiDAR Point Cloud",
    "Calibration Bias",
    "Semantic Segmentation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multimodal Learning": 0.8,
    "LiDAR Point Cloud": 0.78,
    "Calibration Bias": 0.77,
    "Semantic Segmentation": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "multi-modal object detection",
        "canonical": "Multimodal Learning",
        "aliases": [
          "multi-modal detection"
        ],
        "category": "specific_connectable",
        "rationale": "Links to the concept of integrating multiple data sources, which is crucial in autonomous systems.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.72,
        "link_intent_score": 0.8
      },
      {
        "surface": "LiDAR point cloud",
        "canonical": "LiDAR Point Cloud",
        "aliases": [
          "LiDAR data"
        ],
        "category": "unique_technical",
        "rationale": "Essential for understanding sensor fusion in autonomous driving.",
        "novelty_score": 0.65,
        "connectivity_score": 0.75,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "calibration bias",
        "canonical": "Calibration Bias",
        "aliases": [
          "calibration error"
        ],
        "category": "unique_technical",
        "rationale": "Key to addressing the paper's focus on improving detection accuracy.",
        "novelty_score": 0.68,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      },
      {
        "surface": "semantic segmentation guidance",
        "canonical": "Semantic Segmentation",
        "aliases": [
          "segmentation"
        ],
        "category": "broad_technical",
        "rationale": "Provides context for how the re-calibration model improves detection performance.",
        "novelty_score": 0.45,
        "connectivity_score": 0.82,
        "specificity_score": 0.7,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "object detection",
      "autonomous driving",
      "detection framework"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "multi-modal object detection",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.72,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "LiDAR point cloud",
      "resolved_canonical": "LiDAR Point Cloud",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.75,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "calibration bias",
      "resolved_canonical": "Calibration Bias",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "semantic segmentation guidance",
      "resolved_canonical": "Semantic Segmentation",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.82,
        "specificity": 0.7,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# A re-calibration method for object detection with multi-modal alignment bias in autonomous driving

**Korean Title:** ììœ¨ì£¼í–‰ì—ì„œ ë‹¤ì¤‘ ëª¨ë‹¬ ì •ë ¬ í¸í–¥ì„ ê³ ë ¤í•œ ê°ì²´ íƒì§€ë¥¼ ìœ„í•œ ì¬ë³´ì • ë°©ë²•

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2405.16848.pdf)
**Category**: cs.CV
**Published**: 2025-09-22
**ArXiv ID**: [2405.16848](https://arxiv.org/abs/2405.16848)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Semantic-LiDAR-Inertial-Wheel Odometry Fusion for Robust Localization in Large-Scale Dynamic Environments_20250919|Semantic-LiDAR-Inertial-Wheel Odometry Fusion for Robust Localization in Large-Scale Dynamic Environments]] (84.5% similar)
- [[2025-09-22/PAN_ Pillars-Attention-Based Network for 3D Object Detection_20250922|PAN: Pillars-Attention-Based Network for 3D Object Detection]] (83.1% similar)
- [[2025-09-19/Semantic Exploration and Dense Mapping of Complex Environments using Ground Robot with Panoramic LiDAR-Camera Fusion_20250919|Semantic Exploration and Dense Mapping of Complex Environments using Ground Robot with Panoramic LiDAR-Camera Fusion]] (82.5% similar)
- [[2025-09-19/Traffic Co-Simulation Framework Empowered by Infrastructure Camera Sensing and Reinforcement Learning_20250919|Traffic Co-Simulation Framework Empowered by Infrastructure Camera Sensing and Reinforcement Learning]] (82.5% similar)
- [[2025-09-18/VSE-MOT_ Multi-Object Tracking in Low-Quality Video Scenes Guided by Visual Semantic Enhancement_20250918|VSE-MOT: Multi-Object Tracking in Low-Quality Video Scenes Guided by Visual Semantic Enhancement]] (82.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Semantic Segmentation|Semantic Segmentation]]
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**âš¡ Unique Technical**: [[keywords/LiDAR Point Cloud|LiDAR Point Cloud]], [[keywords/Calibration Bias|Calibration Bias]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2405.16848v3 Announce Type: replace 
Abstract: Multi-modal object detection in autonomous driving has achieved great breakthroughs due to the usage of fusing complementary information from different sensors. The calibration in fusion between sensors such as LiDAR and camera was always supposed to be precise in previous work. However, in reality, calibration matrices are fixed when the vehicles leave the factory, but mechanical vibration, road bumps, and data lags may cause calibration bias. As there is relatively limited research on the impact of calibration on fusion detection performance, multi-sensor detection methods with flexible calibration dependency have remained a key objective. In this paper, we systematically evaluate the sensitivity of the SOTA EPNet++ detection framework and prove that even slight bias on calibration can reduce the performance seriously. To address this vulnerability, we propose a re-calibration model to re-calibrate the misalignment in detection tasks. This model integrates LiDAR point cloud, camera image, and initial calibration matrix as inputs, generating re-calibrated bias through semantic segmentation guidance and a tailored loss function design. The re-calibration model can operate with existing detection algorithms, enhancing both robustness against calibration bias and overall object detection performance. Our approach establishes a foundational methodology for maintaining reliability in multi-modal perception systems under real-world calibration uncertainties.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2405.16848v3 ë°œí‘œ ìœ í˜•: êµì²´  
ì´ˆë¡: ììœ¨ ì£¼í–‰ì—ì„œì˜ ë‹¤ì¤‘ ëª¨ë‹¬ ê°ì²´ íƒì§€ëŠ” ë‹¤ì–‘í•œ ì„¼ì„œë¡œë¶€í„° ë³´ì™„ì ì¸ ì •ë³´ë¥¼ ìœµí•©í•˜ì—¬ í° ëŒíŒŒêµ¬ë¥¼ ì´ë£¨ì—ˆìŠµë‹ˆë‹¤. ì´ì „ ì—°êµ¬ì—ì„œëŠ” LiDARì™€ ì¹´ë©”ë¼ì™€ ê°™ì€ ì„¼ì„œ ê°„ì˜ ìœµí•©ì—ì„œì˜ ë³´ì •ì´ í•­ìƒ ì •í™•í•´ì•¼ í•œë‹¤ê³  ê°€ì •ë˜ì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì‹¤ì œë¡œëŠ” ì°¨ëŸ‰ì´ ê³µì¥ì„ ë– ë‚  ë•Œ ë³´ì • í–‰ë ¬ì´ ê³ ì •ë˜ì§€ë§Œ, ê¸°ê³„ì  ì§„ë™, ë„ë¡œ ì¶©ê²©, ë°ì´í„° ì§€ì—°ìœ¼ë¡œ ì¸í•´ ë³´ì • í¸í–¥ì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë³´ì •ì´ ìœµí•© íƒì§€ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì— ëŒ€í•œ ì—°êµ¬ê°€ ìƒëŒ€ì ìœ¼ë¡œ ì œí•œì ì´ê¸° ë•Œë¬¸ì—, ìœ ì—°í•œ ë³´ì • ì˜ì¡´ì„±ì„ ê°€ì§„ ë‹¤ì¤‘ ì„¼ì„œ íƒì§€ ë°©ë²•ì´ ì—¬ì „íˆ ì£¼ìš” ëª©í‘œë¡œ ë‚¨ì•„ ìˆìŠµë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” SOTA EPNet++ íƒì§€ í”„ë ˆì„ì›Œí¬ì˜ ë¯¼ê°ì„±ì„ ì²´ê³„ì ìœ¼ë¡œ í‰ê°€í•˜ê³ , ë³´ì •ì˜ ì•½ê°„ì˜ í¸í–¥ì¡°ì°¨ë„ ì„±ëŠ¥ì„ ì‹¬ê°í•˜ê²Œ ì €í•˜ì‹œí‚¬ ìˆ˜ ìˆìŒì„ ì¦ëª…í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì·¨ì•½ì ì„ í•´ê²°í•˜ê¸° ìœ„í•´, íƒì§€ ì‘ì—…ì—ì„œì˜ ë¶ˆì¼ì¹˜ë¥¼ ì¬ë³´ì •í•˜ê¸° ìœ„í•œ ì¬ë³´ì • ëª¨ë¸ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ LiDAR í¬ì¸íŠ¸ í´ë¼ìš°ë“œ, ì¹´ë©”ë¼ ì´ë¯¸ì§€, ì´ˆê¸° ë³´ì • í–‰ë ¬ì„ ì…ë ¥ìœ¼ë¡œ í†µí•©í•˜ì—¬, ì˜ë¯¸ë¡ ì  ë¶„í•  ì§€ì¹¨ê³¼ ë§ì¶¤í˜• ì†ì‹¤ í•¨ìˆ˜ ì„¤ê³„ë¥¼ í†µí•´ ì¬ë³´ì •ëœ í¸í–¥ì„ ìƒì„±í•©ë‹ˆë‹¤. ì¬ë³´ì • ëª¨ë¸ì€ ê¸°ì¡´ íƒì§€ ì•Œê³ ë¦¬ì¦˜ê³¼ í•¨ê»˜ ì‘ë™í•  ìˆ˜ ìˆìœ¼ë©°, ë³´ì • í¸í–¥ì— ëŒ€í•œ ê°•ê±´ì„±ì„ í–¥ìƒì‹œí‚¤ê³  ì „ì²´ ê°ì²´ íƒì§€ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ìš°ë¦¬ì˜ ì ‘ê·¼ ë°©ì‹ì€ ì‹¤ì œ ì„¸ê³„ì˜ ë³´ì • ë¶ˆí™•ì‹¤ì„± í•˜ì—ì„œ ë‹¤ì¤‘ ëª¨ë‹¬ ì¸ì‹ ì‹œìŠ¤í…œì˜ ì‹ ë¢°ì„±ì„ ìœ ì§€í•˜ê¸° ìœ„í•œ ê¸°ì´ˆì ì¸ ë°©ë²•ë¡ ì„ í™•ë¦½í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ììœ¨ì£¼í–‰ì—ì„œ LiDARì™€ ì¹´ë©”ë¼ ê°™ì€ ë‹¤ì–‘í•œ ì„¼ì„œì˜ ìœµí•©ì„ í†µí•œ ë‹¤ì¤‘ ëª¨ë‹¬ ê°ì²´ íƒì§€ì˜ ì„±ê³¼ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. ê¸°ì¡´ ì—°êµ¬ëŠ” ì„¼ì„œ ê°„ ìœµí•© ì‹œ ë³´ì •ì´ ì •í™•í•˜ë‹¤ê³  ê°€ì •í–ˆì§€ë§Œ, ì‹¤ì œë¡œëŠ” ì°¨ëŸ‰ ì¶œê³  í›„ ê¸°ê³„ì  ì§„ë™ì´ë‚˜ ë„ë¡œ ìƒíƒœë¡œ ì¸í•´ ë³´ì • ì˜¤ì°¨ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ëŠ” SOTA EPNet++ íƒì§€ í”„ë ˆì„ì›Œí¬ì˜ ë¯¼ê°ë„ë¥¼ í‰ê°€í•˜ì—¬, ë³´ì •ì˜ ë¯¸ì„¸í•œ ì˜¤ì°¨ë„ ì„±ëŠ¥ ì €í•˜ë¥¼ ì´ˆë˜í•  ìˆ˜ ìˆìŒì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, íƒì§€ ì‘ì—…ì—ì„œì˜ ë¹„ì •ë ¬ ë¬¸ì œë¥¼ ì¬ë³´ì •í•˜ëŠ” ëª¨ë¸ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ LiDAR ì  êµ¬ë¦„, ì¹´ë©”ë¼ ì´ë¯¸ì§€, ì´ˆê¸° ë³´ì • í–‰ë ¬ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„, ì˜ë¯¸ë¡ ì  ì„¸ë¶„í™”ì™€ ë§ì¶¤í˜• ì†ì‹¤ í•¨ìˆ˜ ì„¤ê³„ë¥¼ í†µí•´ ì¬ë³´ì •ëœ ì˜¤ì°¨ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì œì•ˆëœ ëª¨ë¸ì€ ê¸°ì¡´ íƒì§€ ì•Œê³ ë¦¬ì¦˜ê³¼ í•¨ê»˜ ì‘ë™í•˜ì—¬ ë³´ì • ì˜¤ì°¨ì— ëŒ€í•œ ê°•ê±´ì„±ê³¼ ê°ì²´ íƒì§€ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì´ ì ‘ê·¼ë²•ì€ ì‹¤ì œ í™˜ê²½ì—ì„œì˜ ë³´ì • ë¶ˆí™•ì‹¤ì„± í•˜ì—ì„œë„ ì‹ ë¢°ì„±ì„ ìœ ì§€í•˜ëŠ” ë‹¤ì¤‘ ëª¨ë‹¬ ì¸ì‹ ì‹œìŠ¤í…œì˜ ê¸°ì´ˆ ë°©ë²•ë¡ ì„ ì œì‹œí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ììœ¨ì£¼í–‰ì—ì„œ ë©€í‹°ëª¨ë‹¬ ê°ì²´ íƒì§€ëŠ” ë‹¤ì–‘í•œ ì„¼ì„œì˜ ë³´ì™„ì  ì •ë³´ë¥¼ ìœµí•©í•˜ì—¬ í° ë°œì „ì„ ì´ë£¨ì—ˆë‹¤.
- 2. ê¸°ì¡´ ì—°êµ¬ì—ì„œëŠ” ì„¼ì„œ ê°„ ìœµí•©ì„ ìœ„í•œ ë³´ì •ì´ ì •í™•í•´ì•¼ í•œë‹¤ê³  ê°€ì •í–ˆìœ¼ë‚˜, ì‹¤ì œë¡œëŠ” ê¸°ê³„ì  ì§„ë™, ë„ë¡œ ì¶©ê²©, ë°ì´í„° ì§€ì—° ë“±ì´ ë³´ì • í¸í–¥ì„ ì´ˆë˜í•  ìˆ˜ ìˆë‹¤.
- 3. ë³¸ ì—°êµ¬ì—ì„œëŠ” SOTA EPNet++ íƒì§€ í”„ë ˆì„ì›Œí¬ì˜ ë¯¼ê°ë„ë¥¼ ì²´ê³„ì ìœ¼ë¡œ í‰ê°€í•˜ê³ , ë³´ì •ì˜ ë¯¸ì„¸í•œ í¸í–¥ì´ ì„±ëŠ¥ ì €í•˜ë¥¼ ì´ˆë˜í•  ìˆ˜ ìˆìŒì„ ì…ì¦í•˜ì˜€ë‹¤.
- 4. ë³´ì • í¸í–¥ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, LiDAR í¬ì¸íŠ¸ í´ë¼ìš°ë“œ, ì¹´ë©”ë¼ ì´ë¯¸ì§€, ì´ˆê¸° ë³´ì • í–‰ë ¬ì„ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ ì¬ë³´ì • ëª¨ë¸ì„ ì œì•ˆí•˜ì˜€ë‹¤.
- 5. ì œì•ˆëœ ì¬ë³´ì • ëª¨ë¸ì€ ê¸°ì¡´ íƒì§€ ì•Œê³ ë¦¬ì¦˜ê³¼ í•¨ê»˜ ì‘ë™í•˜ì—¬ ë³´ì • í¸í–¥ì— ëŒ€í•œ ê°•ì¸ì„±ê³¼ ê°ì²´ íƒì§€ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¨ë‹¤.


---

*Generated on 2025-09-23 12:27:22*