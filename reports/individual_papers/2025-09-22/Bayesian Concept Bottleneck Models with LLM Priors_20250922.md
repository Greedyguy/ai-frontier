---
keywords:
  - Concept Bottleneck Models
  - Large Language Model
  - Bayesian Framework
  - Interpretability-Accuracy Tradeoff
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2410.15555
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T09:47:56.801622",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Concept Bottleneck Models",
    "Large Language Model",
    "Bayesian Framework",
    "Interpretability-Accuracy Tradeoff"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Concept Bottleneck Models": 0.78,
    "Large Language Model": 0.82,
    "Bayesian Framework": 0.79,
    "Interpretability-Accuracy Tradeoff": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Concept Bottleneck Models",
        "canonical": "Concept Bottleneck Models",
        "aliases": [
          "CBM",
          "Concept Bottleneck"
        ],
        "category": "unique_technical",
        "rationale": "This is a central concept in the paper, representing a specific model architecture that balances interpretability and accuracy.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "LLMs are used as a concept extraction mechanism and prior, crucial for understanding the paper's methodology.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.82
      },
      {
        "surface": "Bayesian Framework",
        "canonical": "Bayesian Framework",
        "aliases": [
          "Bayesian Approach",
          "Bayesian Method"
        ],
        "category": "specific_connectable",
        "rationale": "The Bayesian framework is key to the novel approach proposed, enabling rigorous statistical inference.",
        "novelty_score": 0.68,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.79
      },
      {
        "surface": "Interpretability-Accuracy Tradeoff",
        "canonical": "Interpretability-Accuracy Tradeoff",
        "aliases": [
          "Interpretability Tradeoff"
        ],
        "category": "unique_technical",
        "rationale": "This tradeoff is a critical issue addressed by the proposed model, relevant for linking discussions on model performance.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.78,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Concept Bottleneck Models",
      "resolved_canonical": "Concept Bottleneck Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Bayesian Framework",
      "resolved_canonical": "Bayesian Framework",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Interpretability-Accuracy Tradeoff",
      "resolved_canonical": "Interpretability-Accuracy Tradeoff",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.78,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Bayesian Concept Bottleneck Models with LLM Priors

**Korean Title:** ë² ì´ì§€ì•ˆ ê°œë… ë³‘ëª© ëª¨ë¸ê³¼ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ ì‚¬ì „ ë¶„í¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2410.15555.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2410.15555](https://arxiv.org/abs/2410.15555)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/EnCoBo_ Energy-Guided Concept Bottlenecks for Interpretable Generation_20250919|EnCoBo: Energy-Guided Concept Bottlenecks for Interpretable Generation]] (83.7% similar)
- [[2025-09-22/Calibrating LLM Confidence by Probing Perturbed Representation Stability_20250922|Calibrating LLM Confidence by Probing Perturbed Representation Stability]] (81.9% similar)
- [[2025-09-22/Capturing Polysemanticity with PRISM_ A Multi-Concept Feature Description Framework_20250922|Capturing Polysemanticity with PRISM: A Multi-Concept Feature Description Framework]] (81.0% similar)
- [[2025-09-22/Benchmarking Debiasing Methods for LLM-based Parameter Estimates_20250922|Benchmarking Debiasing Methods for LLM-based Parameter Estimates]] (81.0% similar)
- [[2025-09-19/Modular Machine Learning_ An Indispensable Path towards New-Generation Large Language Models_20250919|Modular Machine Learning: An Indispensable Path towards New-Generation Large Language Models]] (80.4% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Bayesian Framework|Bayesian Framework]]
**âš¡ Unique Technical**: [[keywords/Concept Bottleneck Models|Concept Bottleneck Models]], [[keywords/Interpretability-Accuracy Tradeoff|Interpretability-Accuracy Tradeoff]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2410.15555v2 Announce Type: replace-cross 
Abstract: Concept Bottleneck Models (CBMs) have been proposed as a compromise between white-box and black-box models, aiming to achieve interpretability without sacrificing accuracy. The standard training procedure for CBMs is to predefine a candidate set of human-interpretable concepts, extract their values from the training data, and identify a sparse subset as inputs to a transparent prediction model. However, such approaches are often hampered by the tradeoff between exploring a sufficiently large set of concepts versus controlling the cost of obtaining concept extractions, resulting in a large interpretability-accuracy tradeoff. This work investigates a novel approach that sidesteps these challenges: BC-LLM iteratively searches over a potentially infinite set of concepts within a Bayesian framework, in which Large Language Models (LLMs) serve as both a concept extraction mechanism and prior. Even though LLMs can be miscalibrated and hallucinate, we prove that BC-LLM can provide rigorous statistical inference and uncertainty quantification. Across image, text, and tabular datasets, BC-LLM outperforms interpretable baselines and even black-box models in certain settings, converges more rapidly towards relevant concepts, and is more robust to out-of-distribution samples.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2410.15555v2 ë°œí‘œ ìœ í˜•: êµì²´-êµì°¨  
ì´ˆë¡: ê°œë… ë³‘ëª© ëª¨ë¸(CBMs)ì€ í•´ì„ ê°€ëŠ¥ì„±ê³¼ ì •í™•ì„± ê°„ì˜ ì ˆì¶©ì„ ëª©í‘œë¡œ í•˜ëŠ” í™”ì´íŠ¸ë°•ìŠ¤ì™€ ë¸”ë™ë°•ìŠ¤ ëª¨ë¸ ê°„ì˜ íƒ€í˜‘ì•ˆìœ¼ë¡œ ì œì•ˆë˜ì—ˆìŠµë‹ˆë‹¤. CBMì˜ í‘œì¤€ í›ˆë ¨ ì ˆì°¨ëŠ” ì¸ê°„ì´ í•´ì„í•  ìˆ˜ ìˆëŠ” ê°œë…ì˜ í›„ë³´ ì§‘í•©ì„ ë¯¸ë¦¬ ì •ì˜í•˜ê³ , í›ˆë ¨ ë°ì´í„°ì—ì„œ ê·¸ ê°’ì„ ì¶”ì¶œí•œ í›„, íˆ¬ëª…í•œ ì˜ˆì¸¡ ëª¨ë¸ì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•  í¬ì†Œí•œ ë¶€ë¶„ ì§‘í•©ì„ ì‹ë³„í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ëŸ¬í•œ ì ‘ê·¼ ë°©ì‹ì€ ì¶©ë¶„íˆ í° ê°œë… ì§‘í•©ì„ íƒìƒ‰í•˜ëŠ” ê²ƒê³¼ ê°œë… ì¶”ì¶œ ë¹„ìš©ì„ ì œì–´í•˜ëŠ” ê²ƒ ì‚¬ì´ì˜ ê· í˜•ì„ ë§ì¶”ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªì–´, í•´ì„ ê°€ëŠ¥ì„±ê³¼ ì •í™•ì„± ê°„ì˜ í° ì ˆì¶©ì„ ì´ˆë˜í•©ë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í”¼í•˜ëŠ” ìƒˆë¡œìš´ ì ‘ê·¼ ë°©ì‹ì„ ì¡°ì‚¬í•©ë‹ˆë‹¤: BC-LLMì€ ì ì¬ì ìœ¼ë¡œ ë¬´í•œí•œ ê°œë… ì§‘í•©ì„ ë² ì´ì§€ì•ˆ í”„ë ˆì„ì›Œí¬ ë‚´ì—ì„œ ë°˜ë³µì ìœ¼ë¡œ íƒìƒ‰í•˜ë©°, ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì´ ê°œë… ì¶”ì¶œ ë©”ì»¤ë‹ˆì¦˜ê³¼ ì‚¬ì „ìœ¼ë¡œ ì‘ìš©í•©ë‹ˆë‹¤. LLMì´ ì˜ëª» ì¡°ì •ë˜ê±°ë‚˜ í™˜ìƒì„ ì¼ìœ¼í‚¬ ìˆ˜ ìˆìŒì—ë„ ë¶ˆêµ¬í•˜ê³ , ìš°ë¦¬ëŠ” BC-LLMì´ ì—„ê²©í•œ í†µê³„ì  ì¶”ë¡ ê³¼ ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™”ë¥¼ ì œê³µí•  ìˆ˜ ìˆìŒì„ ì¦ëª…í•©ë‹ˆë‹¤. ì´ë¯¸ì§€, í…ìŠ¤íŠ¸ ë° í‘œ í˜•ì‹ ë°ì´í„°ì…‹ ì „ë°˜ì— ê±¸ì³, BC-LLMì€ í•´ì„ ê°€ëŠ¥í•œ ê¸°ì¤€ì„ ì„ ëŠ¥ê°€í•˜ê³  íŠ¹ì • ì„¤ì •ì—ì„œëŠ” ë¸”ë™ë°•ìŠ¤ ëª¨ë¸ë³´ë‹¤ë„ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì´ë©°, ê´€ë ¨ ê°œë…ìœ¼ë¡œ ë” ë¹ ë¥´ê²Œ ìˆ˜ë ´í•˜ê³ , ë¶„í¬ ì™¸ ìƒ˜í”Œì— ëŒ€í•´ ë” ê°•ê±´í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ í•´ì„ ê°€ëŠ¥ì„±ê³¼ ì •í™•ì„±ì˜ ê· í˜•ì„ ì´ë£¨ê¸° ìœ„í•œ ê°œë… ë³‘ëª© ëª¨ë¸(CBM)ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ BC-LLMì´ë¼ëŠ” ìƒˆë¡œìš´ ì ‘ê·¼ ë°©ì‹ì„ ì œì•ˆí•©ë‹ˆë‹¤. BC-LLMì€ ë² ì´ì§€ì•ˆ í”„ë ˆì„ì›Œí¬ ë‚´ì—ì„œ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ í™œìš©í•˜ì—¬ ë¬´í•œí•œ ê°œë… ì§‘í•©ì„ íƒìƒ‰í•˜ë©°, LLMì„ ê°œë… ì¶”ì¶œ ë©”ì»¤ë‹ˆì¦˜ ë° ì‚¬ì „ ì •ë³´ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤. LLMì˜ ì˜¤ì°¨ì™€ í™˜ê° ê°€ëŠ¥ì„±ì—ë„ ë¶ˆêµ¬í•˜ê³ , BC-LLMì€ í†µê³„ì  ì¶”ë¡ ê³¼ ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™”ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì´ë¯¸ì§€, í…ìŠ¤íŠ¸, í‘œ í˜•ì‹ ë°ì´í„°ì—ì„œ BC-LLMì€ í•´ì„ ê°€ëŠ¥í•œ ê¸°ì¤€ ëª¨ë¸ê³¼ íŠ¹ì • ìƒí™©ì˜ ë¸”ë™ë°•ìŠ¤ ëª¨ë¸ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì´ë©°, ê´€ë ¨ ê°œë…ì— ë” ë¹ ë¥´ê²Œ ìˆ˜ë ´í•˜ê³  ë¶„í¬ ì™¸ ìƒ˜í”Œì— ëŒ€í•´ ë” ê°•ê±´í•¨ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Concept Bottleneck Models(CBMs)ëŠ” í•´ì„ ê°€ëŠ¥ì„±ê³¼ ì •í™•ì„±ì˜ ê· í˜•ì„ ë§ì¶”ê¸° ìœ„í•œ ëª¨ë¸ë¡œ ì œì•ˆë˜ì—ˆìŠµë‹ˆë‹¤.
- 2. ê¸°ì¡´ CBMsëŠ” ì¸ê°„ì´ í•´ì„ ê°€ëŠ¥í•œ ê°œë…ì„ ë¯¸ë¦¬ ì •ì˜í•˜ê³ , ì´ë¥¼ íˆ¬ëª…í•œ ì˜ˆì¸¡ ëª¨ë¸ì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.
- 3. BC-LLMì€ ì ì¬ì ìœ¼ë¡œ ë¬´í•œí•œ ê°œë… ì§‘í•©ì„ íƒìƒ‰í•˜ëŠ” ìƒˆë¡œìš´ ì ‘ê·¼ë²•ìœ¼ë¡œ, ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì„ ê°œë… ì¶”ì¶œ ë©”ì»¤ë‹ˆì¦˜ìœ¼ë¡œ í™œìš©í•©ë‹ˆë‹¤.
- 4. BC-LLMì€ ì´ë¯¸ì§€, í…ìŠ¤íŠ¸, í‘œ í˜•ì‹ ë°ì´í„°ì…‹ì—ì„œ í•´ì„ ê°€ëŠ¥í•œ ê¸°ì¤€ ëª¨ë¸ê³¼ ë¸”ë™ë°•ìŠ¤ ëª¨ë¸ì„ ëŠ¥ê°€í•˜ëŠ” ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.
- 5. BC-LLMì€ ê´€ë ¨ ê°œë…ìœ¼ë¡œ ë” ë¹ ë¥´ê²Œ ìˆ˜ë ´í•˜ê³ , ë¶„í¬ ì™¸ ìƒ˜í”Œì— ëŒ€í•´ ë” ê°•ê±´í•œ íŠ¹ì„±ì„ ë³´ì…ë‹ˆë‹¤.


---

*Generated on 2025-09-23 09:47:56*