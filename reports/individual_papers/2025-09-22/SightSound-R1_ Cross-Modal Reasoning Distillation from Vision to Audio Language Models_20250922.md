---
keywords:
  - Large Language Model
  - Vision-Language Model
  - Cross-Modal Distillation
  - Multimodal Learning
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2509.15661
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T09:08:56.782014",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Vision-Language Model",
    "Cross-Modal Distillation",
    "Multimodal Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Vision-Language Model": 0.9,
    "Cross-Modal Distillation": 0.8,
    "Multimodal Learning": 0.88
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Audio-Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LALMs",
          "Audio-Language Models"
        ],
        "category": "broad_technical",
        "rationale": "Connects to existing discussions on large models and their applications in different modalities.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Vision-Language Models",
        "canonical": "Vision-Language Model",
        "aliases": [
          "LVLMs"
        ],
        "category": "evolved_concepts",
        "rationale": "Highlights the cross-modal capabilities and is a trending concept in multimodal learning.",
        "novelty_score": 0.5,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.9
      },
      {
        "surface": "Cross-Modal Distillation",
        "canonical": "Cross-Modal Distillation",
        "aliases": [
          "Cross-Modal Knowledge Transfer"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a unique approach for transferring reasoning capabilities across modalities.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Audio-Visual Question Answering",
        "canonical": "Multimodal Learning",
        "aliases": [
          "AVQA"
        ],
        "category": "specific_connectable",
        "rationale": "Represents a specific application of multimodal learning, linking audio and visual data.",
        "novelty_score": 0.55,
        "connectivity_score": 0.82,
        "specificity_score": 0.78,
        "link_intent_score": 0.88
      }
    ],
    "ban_list_suggestions": [
      "test-time scaling",
      "audio-grounded validation",
      "distillation pipeline"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Audio-Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Vision-Language Models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.9
      }
    },
    {
      "candidate_surface": "Cross-Modal Distillation",
      "resolved_canonical": "Cross-Modal Distillation",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Audio-Visual Question Answering",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.82,
        "specificity": 0.78,
        "link_intent": 0.88
      }
    }
  ]
}
-->

# SightSound-R1: Cross-Modal Reasoning Distillation from Vision to Audio Language Models

**Korean Title:** SightSound-R1: ì‹œê°ì—ì„œ ì˜¤ë””ì˜¤ ì–¸ì–´ ëª¨ë¸ë¡œì˜ êµì°¨ ëª¨ë‹¬ ì¶”ë¡  ì¦ë¥˜

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15661.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2509.15661](https://arxiv.org/abs/2509.15661)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/Omni-CLST_ Error-aware Curriculum Learning with guided Selective chain-of-Thought for audio question answering_20250918|Omni-CLST: Error-aware Curriculum Learning with guided Selective chain-of-Thought for audio question answering]] (85.5% similar)
- [[2025-09-22/Perception-R1_ Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward_20250922|Perception-R1: Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward]] (84.8% similar)
- [[2025-09-22/Exploring Fine-Tuning of Large Audio Language Models for Spoken Language Understanding under Limited Speech data_20250922|Exploring Fine-Tuning of Large Audio Language Models for Spoken Language Understanding under Limited Speech data]] (84.6% similar)
- [[2025-09-19/Cross-Modal Knowledge Distillation for Speech Large Language Models_20250919|Cross-Modal Knowledge Distillation for Speech Large Language Models]] (84.2% similar)
- [[2025-09-18/Spatial Audio Motion Understanding and Reasoning_20250918|Spatial Audio Motion Understanding and Reasoning]] (83.7% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**âš¡ Unique Technical**: [[keywords/Cross-Modal Distillation|Cross-Modal Distillation]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15661v1 Announce Type: cross 
Abstract: While large audio-language models (LALMs) have demonstrated state-of-the-art audio understanding, their reasoning capability in complex soundscapes still falls behind large vision-language models (LVLMs). Compared to the visual domain, one bottleneck is the lack of large-scale chain-of-thought audio data to teach LALM stepwise reasoning. To circumvent this data and modality gap, we present SightSound-R1, a cross-modal distillation framework that transfers advanced reasoning from a stronger LVLM teacher to a weaker LALM student on the same audio-visual question answering (AVQA) dataset. SightSound-R1 consists of three core steps: (i) test-time scaling to generate audio-focused chains of thought (CoT) from an LVLM teacher, (ii) audio-grounded validation to filter hallucinations, and (iii) a distillation pipeline with supervised fine-tuning (SFT) followed by Group Relative Policy Optimization (GRPO) for the LALM student. Results show that SightSound-R1 improves LALM reasoning performance both in the in-domain AVQA test set as well as in unseen auditory scenes and questions, outperforming both pretrained and label-only distilled baselines. Thus, we conclude that vision reasoning can be effectively transferred to audio models and scaled with abundant audio-visual data.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15661v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ëŒ€í˜• ì˜¤ë””ì˜¤-ì–¸ì–´ ëª¨ë¸(LALM)ì€ ìµœì²¨ë‹¨ ì˜¤ë””ì˜¤ ì´í•´ ëŠ¥ë ¥ì„ ë³´ì—¬ì£¼ì—ˆì§€ë§Œ, ë³µì¡í•œ ì‚¬ìš´ë“œìŠ¤ì¼€ì´í”„ì—ì„œì˜ ì¶”ë¡  ëŠ¥ë ¥ì€ ì—¬ì „íˆ ëŒ€í˜• ë¹„ì „-ì–¸ì–´ ëª¨ë¸(LVLM)ì— ë’¤ì²˜ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì‹œê°ì  ë„ë©”ì¸ê³¼ ë¹„êµí–ˆì„ ë•Œ, í•˜ë‚˜ì˜ ë³‘ëª© í˜„ìƒì€ LALMì˜ ë‹¨ê³„ë³„ ì¶”ë¡ ì„ ê°€ë¥´ì¹  ëŒ€ê·œëª¨ ì‚¬ê³ ì˜ ì—°ì‡„ ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ë‹¤ëŠ” ì ì…ë‹ˆë‹¤. ì´ëŸ¬í•œ ë°ì´í„° ë° ëª¨ë‹¬ë¦¬í‹° ê²©ì°¨ë¥¼ í•´ì†Œí•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” SightSound-R1ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ëŠ” ë™ì¼í•œ ì˜¤ë””ì˜¤-ë¹„ì£¼ì–¼ ì§ˆë¬¸ ì‘ë‹µ(AVQA) ë°ì´í„°ì…‹ì—ì„œ ë” ê°•ë ¥í•œ LVLM êµì‚¬ë¡œë¶€í„° ë” ì•½í•œ LALM í•™ìƒì—ê²Œ ê³ ê¸‰ ì¶”ë¡ ì„ ì „ì´í•˜ëŠ” êµì°¨ ëª¨ë‹¬ ì¦ë¥˜ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. SightSound-R1ì€ ì„¸ ê°€ì§€ í•µì‹¬ ë‹¨ê³„ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤: (i) LVLM êµì‚¬ë¡œë¶€í„° ì˜¤ë””ì˜¤ ì¤‘ì‹¬ì˜ ì‚¬ê³ ì˜ ì—°ì‡„(CoT)ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•œ í…ŒìŠ¤íŠ¸ ì‹œê°„ ìŠ¤ì¼€ì¼ë§, (ii) í™˜ê°ì„ í•„í„°ë§í•˜ê¸° ìœ„í•œ ì˜¤ë””ì˜¤ ê¸°ë°˜ ê²€ì¦, (iii) ê°ë…ëœ ë¯¸ì„¸ ì¡°ì •(SFT) í›„ ê·¸ë£¹ ìƒëŒ€ ì •ì±… ìµœì í™”(GRPO)ë¥¼ í†µí•œ LALM í•™ìƒì„ ìœ„í•œ ì¦ë¥˜ íŒŒì´í”„ë¼ì¸. ê²°ê³¼ëŠ” SightSound-R1ì´ ë„ë©”ì¸ ë‚´ AVQA í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¿ë§Œ ì•„ë‹ˆë¼ ë³´ì§€ ëª»í•œ ì²­ê°ì  ì¥ë©´ ë° ì§ˆë¬¸ì—ì„œë„ LALMì˜ ì¶”ë¡  ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ë©°, ì‚¬ì „ í•™ìŠµ ë° ë ˆì´ë¸”ë§Œ ì¦ë¥˜ëœ ê¸°ì¤€ ëª¨ë¸ì„ ëŠ¥ê°€í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë”°ë¼ì„œ ìš°ë¦¬ëŠ” ë¹„ì „ ì¶”ë¡ ì´ ì˜¤ë””ì˜¤ ëª¨ë¸ë¡œ íš¨ê³¼ì ìœ¼ë¡œ ì „ì´ë  ìˆ˜ ìˆìœ¼ë©°, í’ë¶€í•œ ì˜¤ë””ì˜¤-ë¹„ì£¼ì–¼ ë°ì´í„°ë¡œ í™•ì¥ë  ìˆ˜ ìˆìŒì„ ê²°ë¡ ì§“ìŠµë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

SightSound-R1ì€ ëŒ€ê·œëª¨ ì‹œê°-ì–¸ì–´ ëª¨ë¸(LVLM)ì˜ ê³ ê¸‰ ì¶”ë¡  ëŠ¥ë ¥ì„ ëŒ€ê·œëª¨ ì˜¤ë””ì˜¤-ì–¸ì–´ ëª¨ë¸(LALM)ì— ì „ì´ì‹œí‚¤ëŠ” êµì°¨ ëª¨ë‹¬ ì¦ë¥˜ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ì˜¤ë””ì˜¤-ë¹„ì£¼ì–¼ ì§ˆë¬¸ ì‘ë‹µ(AVQA) ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬ LALMì˜ ë³µì¡í•œ ì†Œë¦¬ í™˜ê²½ì—ì„œì˜ ì¶”ë¡  ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. SightSound-R1ì€ LVLM êµì‚¬ë¡œë¶€í„° ì˜¤ë””ì˜¤ ì¤‘ì‹¬ì˜ ì‚¬ê³  ì²´ì¸ì„ ìƒì„±í•˜ê³ , ì˜¤ë””ì˜¤ ê¸°ë°˜ ê²€ì¦ì„ í†µí•´ ì˜¤ë¥˜ë¥¼ ê±¸ëŸ¬ë‚´ë©°, ì§€ë„ í•™ìŠµ ë° ê·¸ë£¹ ìƒëŒ€ ì •ì±… ìµœì í™”ë¥¼ í†µí•´ LALM í•™ìƒì„ ë¯¸ì„¸ ì¡°ì •í•©ë‹ˆë‹¤. ê²°ê³¼ì ìœ¼ë¡œ, SightSound-R1ì€ LALMì˜ ì¶”ë¡  ì„±ëŠ¥ì„ í–¥ìƒì‹œì¼œ, ì‚¬ì „ í•™ìŠµ ëª¨ë¸ê³¼ ë ˆì´ë¸”ë§Œ ì‚¬ìš©í•œ ì¦ë¥˜ ê¸°ë²•ì„ ëŠ¥ê°€í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì‹œê°ì  ì¶”ë¡ ì´ ì˜¤ë””ì˜¤ ëª¨ë¸ë¡œ íš¨ê³¼ì ìœ¼ë¡œ ì „ì´ë  ìˆ˜ ìˆìŒì„ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€ê·œëª¨ ì˜¤ë””ì˜¤-ì–¸ì–´ ëª¨ë¸(LALM)ì€ ìµœì²¨ë‹¨ ì˜¤ë””ì˜¤ ì´í•´ë¥¼ ë³´ì—¬ì£¼ì§€ë§Œ, ë³µì¡í•œ ì†Œë¦¬ í™˜ê²½ì—ì„œì˜ ì¶”ë¡  ëŠ¥ë ¥ì€ ì—¬ì „íˆ ëŒ€ê·œëª¨ ë¹„ì „-ì–¸ì–´ ëª¨ë¸(LVLM)ì— ë’¤ì²˜ì§‘ë‹ˆë‹¤.
- 2. SightSound-R1ì€ ê°•ë ¥í•œ LVLM êµì‚¬ë¡œë¶€í„° ì•½í•œ LALM í•™ìƒì—ê²Œ ê³ ê¸‰ ì¶”ë¡ ì„ ì „ì´ì‹œí‚¤ëŠ” êµì°¨ ëª¨ë‹¬ ì¦ë¥˜ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.
- 3. SightSound-R1ì€ LVLM êµì‚¬ë¡œë¶€í„° ì˜¤ë””ì˜¤ ì¤‘ì‹¬ì˜ ì‚¬ê³  ì²´ì¸ì„ ìƒì„±í•˜ëŠ” í…ŒìŠ¤íŠ¸ ì‹œ í™•ì¥, í™˜ê°ì„ ê±¸ëŸ¬ë‚´ëŠ” ì˜¤ë””ì˜¤ ê¸°ë°˜ ê²€ì¦, ê°ë…ëœ ë¯¸ì„¸ ì¡°ì •ê³¼ GRPOë¥¼ í†µí•œ ì¦ë¥˜ íŒŒì´í”„ë¼ì¸ì˜ ì„¸ ê°€ì§€ í•µì‹¬ ë‹¨ê³„ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.
- 4. SightSound-R1ì€ AVQA í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì™€ ë³´ì§€ ëª»í•œ ì²­ê° ì¥ë©´ ë° ì§ˆë¬¸ì—ì„œ LALMì˜ ì¶”ë¡  ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
- 5. ì‹œê°ì  ì¶”ë¡ ì€ ì˜¤ë””ì˜¤ ëª¨ë¸ë¡œ íš¨ê³¼ì ìœ¼ë¡œ ì „ì´ë  ìˆ˜ ìˆìœ¼ë©°, í’ë¶€í•œ ì˜¤ë””ì˜¤-ë¹„ì£¼ì–¼ ë°ì´í„°ë¡œ í™•ì¥ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-23 09:08:56*