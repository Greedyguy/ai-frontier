---
keywords:
  - Large Language Model
  - Local Differential Privacy
  - In-Context Learning
  - Privacy-Utility Trade-off
category: cs.CL
publish_date: 2025-09-22
arxiv_id: 2503.04990
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:42:00.732699",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Local Differential Privacy",
    "In-Context Learning",
    "Privacy-Utility Trade-off"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Local Differential Privacy": 0.78,
    "In-Context Learning": 0.8,
    "Privacy-Utility Trade-off": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Large Language Models"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's focus on privacy in language models, linking to broader discussions in NLP.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Local Differential Privacy",
        "canonical": "Local Differential Privacy",
        "aliases": [
          "LDP"
        ],
        "category": "unique_technical",
        "rationale": "Key to the framework's approach to privacy, offering a unique angle on privacy mechanisms.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "In-Context Learning",
        "canonical": "In-Context Learning",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Highlights the framework's innovative use of LLM capabilities, relevant to recent advancements in NLP.",
        "novelty_score": 0.6,
        "connectivity_score": 0.72,
        "specificity_score": 0.75,
        "link_intent_score": 0.8
      },
      {
        "surface": "Privacy-Utility Trade-off",
        "canonical": "Privacy-Utility Trade-off",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Essential for understanding the balance achieved by the framework, crucial for privacy research.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.78,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Local Differential Privacy",
      "resolved_canonical": "Local Differential Privacy",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "In-Context Learning",
      "resolved_canonical": "In-Context Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.72,
        "specificity": 0.75,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Privacy-Utility Trade-off",
      "resolved_canonical": "Privacy-Utility Trade-off",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.78,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# DP-GTR: Differentially Private Prompt Protection via Group Text Rewriting

**Korean Title:** DP-GTR: ê·¸ë£¹ í…ìŠ¤íŠ¸ ì¬ì‘ì„±ì„ í†µí•œ ì°¨ë“± í”„ë¼ì´ë²„ì‹œ í”„ë¡¬í”„íŠ¸ ë³´í˜¸

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2503.04990.pdf)
**Category**: cs.CL
**Published**: 2025-09-22
**ArXiv ID**: [2503.04990](https://arxiv.org/abs/2503.04990)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/SynBench_ A Benchmark for Differentially Private Text Generation_20250918|SynBench: A Benchmark for Differentially Private Text Generation]] (85.0% similar)
- [[2025-09-19/The Sum Leaks More Than Its Parts_ Compositional Privacy Risks and Mitigations in Multi-Agent Collaboration_20250919|The Sum Leaks More Than Its Parts: Compositional Privacy Risks and Mitigations in Multi-Agent Collaboration]] (82.7% similar)
- [[2025-09-22/Personalized Language Models via Privacy-Preserving Evolutionary Model Merging_20250922|Personalized Language Models via Privacy-Preserving Evolutionary Model Merging]] (82.6% similar)
- [[2025-09-19/GRADA_ Graph-based Reranking against Adversarial Documents Attack_20250919|GRADA: Graph-based Reranking against Adversarial Documents Attack]] (82.5% similar)
- [[2025-09-19/Enterprise AI Must Enforce Participant-Aware Access Control_20250919|Enterprise AI Must Enforce Participant-Aware Access Control]] (81.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/In-Context Learning|In-Context Learning]]
**âš¡ Unique Technical**: [[keywords/Local Differential Privacy|Local Differential Privacy]], [[keywords/Privacy-Utility Trade-off|Privacy-Utility Trade-off]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2503.04990v2 Announce Type: replace 
Abstract: Prompt privacy is crucial, especially when using online large language models (LLMs), due to the sensitive information often contained within prompts. While LLMs can enhance prompt privacy through text rewriting, existing methods primarily focus on document-level rewriting, neglecting the rich, multi-granular representations of text. This limitation restricts LLM utilization to specific tasks, overlooking their generalization and in-context learning capabilities, thus hindering practical application. To address this gap, we introduce DP-GTR, a novel three-stage framework that leverages local differential privacy (DP) and the composition theorem via group text rewriting. DP-GTR is the first framework to integrate both document-level and word-level information while exploiting in-context learning to simultaneously improve privacy and utility, effectively bridging local and global DP mechanisms at the individual data point level. Experiments on CommonSense QA and DocVQA demonstrate that DP-GTR outperforms existing approaches, achieving a superior privacy-utility trade-off. Furthermore, our framework is compatible with existing rewriting techniques, serving as a plug-in to enhance privacy protection. Our code is publicly available at github.com/ResponsibleAILab/DP-GTR.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2503.04990v2 ë°œí‘œ ìœ í˜•: êµì²´  
ì´ˆë¡: í”„ë¡¬í”„íŠ¸ í”„ë¼ì´ë²„ì‹œëŠ” íŠ¹íˆ ì˜¨ë¼ì¸ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ ì‚¬ìš©í•  ë•Œ í”„ë¡¬í”„íŠ¸ì— ì¢…ì¢… í¬í•¨ëœ ë¯¼ê°í•œ ì •ë³´ ë•Œë¬¸ì— ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤. LLMì€ í…ìŠ¤íŠ¸ ì¬ì‘ì„±ì„ í†µí•´ í”„ë¡¬í”„íŠ¸ í”„ë¼ì´ë²„ì‹œë¥¼ ê°•í™”í•  ìˆ˜ ìˆì§€ë§Œ, ê¸°ì¡´ ë°©ë²•ì€ ì£¼ë¡œ ë¬¸ì„œ ìˆ˜ì¤€ì˜ ì¬ì‘ì„±ì— ì´ˆì ì„ ë§ì¶”ì–´ í…ìŠ¤íŠ¸ì˜ í’ë¶€í•˜ê³  ë‹¤ì¤‘ ì„¸ë¶„í™”ëœ í‘œí˜„ì„ ê°„ê³¼í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ ì œí•œì€ LLMì˜ í™œìš©ì„ íŠ¹ì • ì‘ì—…ìœ¼ë¡œ ì œí•œí•˜ì—¬ ì¼ë°˜í™” ë° ë¬¸ë§¥ ë‚´ í•™ìŠµ ëŠ¥ë ¥ì„ ê°„ê³¼í•˜ê²Œ í•˜ì—¬ ì‹¤ìš©ì ì¸ ì ìš©ì„ ì €í•´í•©ë‹ˆë‹¤. ì´ ê²©ì°¨ë¥¼ í•´ì†Œí•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” DP-GTRì´ë¼ëŠ” ìƒˆë¡œìš´ 3ë‹¨ê³„ í”„ë ˆì„ì›Œí¬ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ì´ëŠ” ë¡œì»¬ ì°¨ë“± í”„ë¼ì´ë²„ì‹œ(DP)ì™€ ê·¸ë£¹ í…ìŠ¤íŠ¸ ì¬ì‘ì„±ì„ í†µí•œ í•©ì„± ì •ë¦¬ë¥¼ í™œìš©í•©ë‹ˆë‹¤. DP-GTRì€ ë¬¸ì„œ ìˆ˜ì¤€ê³¼ ë‹¨ì–´ ìˆ˜ì¤€ì˜ ì •ë³´ë¥¼ ëª¨ë‘ í†µí•©í•˜ë©´ì„œ ë¬¸ë§¥ ë‚´ í•™ìŠµì„ í™œìš©í•˜ì—¬ í”„ë¼ì´ë²„ì‹œì™€ ìœ ìš©ì„±ì„ ë™ì‹œì— í–¥ìƒì‹œí‚¤ëŠ” ìµœì´ˆì˜ í”„ë ˆì„ì›Œí¬ë¡œ, ê°œë³„ ë°ì´í„° í¬ì¸íŠ¸ ìˆ˜ì¤€ì—ì„œ ë¡œì»¬ ë° ê¸€ë¡œë²Œ DP ë©”ì»¤ë‹ˆì¦˜ì„ íš¨ê³¼ì ìœ¼ë¡œ ì—°ê²°í•©ë‹ˆë‹¤. CommonSense QAì™€ DocVQAì— ëŒ€í•œ ì‹¤í—˜ì€ DP-GTRì´ ê¸°ì¡´ ì ‘ê·¼ ë°©ì‹ì„ ëŠ¥ê°€í•˜ì—¬ ìš°ìˆ˜í•œ í”„ë¼ì´ë²„ì‹œ-ìœ ìš©ì„± ê· í˜•ì„ ë‹¬ì„±í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë˜í•œ, ìš°ë¦¬ì˜ í”„ë ˆì„ì›Œí¬ëŠ” ê¸°ì¡´ì˜ ì¬ì‘ì„± ê¸°ìˆ ê³¼ í˜¸í™˜ë˜ì–´ í”„ë¼ì´ë²„ì‹œ ë³´í˜¸ë¥¼ ê°•í™”í•˜ëŠ” í”ŒëŸ¬ê·¸ì¸ìœ¼ë¡œ ì‘ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìš°ë¦¬ì˜ ì½”ë“œëŠ” github.com/ResponsibleAILab/DP-GTRì—ì„œ ê³µê°œì ìœ¼ë¡œ ì´ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì˜¨ë¼ì¸ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM) ì‚¬ìš© ì‹œ ì¤‘ìš”í•œ í”„ë¡¬í”„íŠ¸ í”„ë¼ì´ë²„ì‹œ ë¬¸ì œë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. ê¸°ì¡´ ë°©ë²•ë“¤ì€ ì£¼ë¡œ ë¬¸ì„œ ìˆ˜ì¤€ì˜ ì¬ì‘ì„±ì„ ë‹¤ë£¨ë©°, í…ìŠ¤íŠ¸ì˜ ë‹¤ì–‘í•œ í‘œí˜„ì„ ì¶©ë¶„íˆ í™œìš©í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ì €ìë“¤ì€ DP-GTRì´ë¼ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ë¡œì»¬ ì°¨ë“± í”„ë¼ì´ë²„ì‹œ(DP)ì™€ ê·¸ë£¹ í…ìŠ¤íŠ¸ ì¬ì‘ì„±ì„ í†µí•´ ë¬¸ì„œ ë° ë‹¨ì–´ ìˆ˜ì¤€ ì •ë³´ë¥¼ í†µí•©í•˜ì—¬ í”„ë¼ì´ë²„ì‹œì™€ ìœ ìš©ì„±ì„ ë™ì‹œì— ê°œì„ í•©ë‹ˆë‹¤. CommonSense QAì™€ DocVQA ì‹¤í—˜ì—ì„œ DP-GTRì€ ê¸°ì¡´ ë°©ë²•ë“¤ë³´ë‹¤ ë›°ì–´ë‚œ í”„ë¼ì´ë²„ì‹œ-ìœ ìš©ì„± ê· í˜•ì„ ë³´ì—¬ì£¼ì—ˆìœ¼ë©°, ê¸°ì¡´ ì¬ì‘ì„± ê¸°ìˆ ê³¼ë„ í˜¸í™˜ë©ë‹ˆë‹¤. ì½”ë“œë„ ê³µê°œë˜ì–´ ìˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì˜¨ë¼ì¸ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM) ì‚¬ìš© ì‹œ í”„ë¡¬í”„íŠ¸ì— í¬í•¨ëœ ë¯¼ê°í•œ ì •ë³´ë¥¼ ë³´í˜¸í•˜ê¸° ìœ„í•´ í”„ë¡¬í”„íŠ¸ í”„ë¼ì´ë²„ì‹œê°€ ì¤‘ìš”í•©ë‹ˆë‹¤.
- 2. ê¸°ì¡´ ë°©ë²•ì€ ë¬¸ì„œ ìˆ˜ì¤€ì˜ ì¬ì‘ì„±ì— ì¤‘ì ì„ ë‘ì–´ LLMì˜ ì¼ë°˜í™” ë° ë§¥ë½ ë‚´ í•™ìŠµ ê¸°ëŠ¥ì„ ì¶©ë¶„íˆ í™œìš©í•˜ì§€ ëª»í•©ë‹ˆë‹¤.
- 3. DP-GTRì€ ë¡œì»¬ ì°¨ë“± í”„ë¼ì´ë²„ì‹œ(DP)ì™€ ê·¸ë£¹ í…ìŠ¤íŠ¸ ì¬ì‘ì„±ì„ í†µí•œ ì¡°í•© ì •ë¦¬ë¥¼ í™œìš©í•˜ì—¬ í”„ë¼ì´ë²„ì‹œì™€ ìœ í‹¸ë¦¬í‹°ë¥¼ ë™ì‹œì— ê°œì„ í•˜ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.
- 4. DP-GTRì€ ë¬¸ì„œ ìˆ˜ì¤€ê³¼ ë‹¨ì–´ ìˆ˜ì¤€ì˜ ì •ë³´ë¥¼ í†µí•©í•˜ì—¬ ê°œì¸ ë°ì´í„° í¬ì¸íŠ¸ ìˆ˜ì¤€ì—ì„œ ë¡œì»¬ ë° ê¸€ë¡œë²Œ DP ë©”ì»¤ë‹ˆì¦˜ì„ ì—°ê²°í•©ë‹ˆë‹¤.
- 5. CommonSense QAì™€ DocVQA ì‹¤í—˜ì—ì„œ DP-GTRì€ ê¸°ì¡´ ì ‘ê·¼ë²•ë³´ë‹¤ ìš°ìˆ˜í•œ í”„ë¼ì´ë²„ì‹œ-ìœ í‹¸ë¦¬í‹° ê· í˜•ì„ ë‹¬ì„±í•˜ë©°, ê¸°ì¡´ ì¬ì‘ì„± ê¸°ìˆ ê³¼ í˜¸í™˜ ê°€ëŠ¥í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-23 11:42:00*