---
keywords:
  - Empathy-R1 Framework
  - Chain-of-Empathy Reasoning
  - Reinforcement Learning
  - Empathy-QA Dataset
  - Long Counseling Texts
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2509.14851
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T10:16:42.491336",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Empathy-R1 Framework",
    "Chain-of-Empathy Reasoning",
    "Reinforcement Learning",
    "Empathy-QA Dataset",
    "Long Counseling Texts"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Empathy-R1 Framework": 0.8,
    "Chain-of-Empathy Reasoning": 0.78,
    "Reinforcement Learning": 0.85,
    "Empathy-QA Dataset": 0.77,
    "Long Counseling Texts": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Empathy-R1",
        "canonical": "Empathy-R1 Framework",
        "aliases": [
          "Empathy-R1"
        ],
        "category": "unique_technical",
        "rationale": "Represents a novel framework specifically designed for mental health support, offering potential for unique insights and connections.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "Chain-of-Empathy",
        "canonical": "Chain-of-Empathy Reasoning",
        "aliases": [
          "CoE"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a new reasoning process inspired by cognitive-behavioral therapy, enhancing the interpretability of AI responses.",
        "novelty_score": 0.8,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Reinforcement Learning",
        "canonical": "Reinforcement Learning",
        "aliases": [
          "RL"
        ],
        "category": "broad_technical",
        "rationale": "A fundamental technique in AI that enhances the framework's response quality, relevant for linking with other AI methodologies.",
        "novelty_score": 0.4,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Empathy-QA",
        "canonical": "Empathy-QA Dataset",
        "aliases": [
          "Empathy-QA"
        ],
        "category": "unique_technical",
        "rationale": "A large-scale dataset critical for training and evaluating the framework, offering opportunities for data-driven insights.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.88,
        "link_intent_score": 0.77
      },
      {
        "surface": "Long Counseling Texts",
        "canonical": "Long Counseling Texts",
        "aliases": [
          "LCTs"
        ],
        "category": "specific_connectable",
        "rationale": "Focuses on a specific application area for AI, linking mental health support with language processing challenges.",
        "novelty_score": 0.65,
        "connectivity_score": 0.72,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Empathy-R1",
      "resolved_canonical": "Empathy-R1 Framework",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Chain-of-Empathy",
      "resolved_canonical": "Chain-of-Empathy Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Reinforcement Learning",
      "resolved_canonical": "Reinforcement Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Empathy-QA",
      "resolved_canonical": "Empathy-QA Dataset",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.88,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Long Counseling Texts",
      "resolved_canonical": "Long Counseling Texts",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.72,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Empathy-R1: A Chain-of-Empathy and Reinforcement Learning Framework for Long-Form Mental Health Support

**Korean Title:** ê³µê°-R1: ì¥ê¸° ì •ì‹  ê±´ê°• ì§€ì›ì„ ìœ„í•œ ê³µê° ì—°ì‡„ ë° ê°•í™” í•™ìŠµ í”„ë ˆì„ì›Œí¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.14851.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2509.14851](https://arxiv.org/abs/2509.14851)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/Empathy-R1_ A Chain-of-Empathy and Reinforcement Learning Framework for Long-Form Mental Health Support_20250918|Empathy-R1: A Chain-of-Empathy and Reinforcement Learning Framework for Long-Form Mental Health Support]] (99.3% similar)
- [[2025-09-19/LLM Agents at the Roundtable_ A Multi-Perspective and Dialectical Reasoning Framework for Essay Scoring_20250919|LLM Agents at the Roundtable: A Multi-Perspective and Dialectical Reasoning Framework for Essay Scoring]] (82.1% similar)
- [[2025-09-22/Fleming-R1_ Toward Expert-Level Medical Reasoning via Reinforcement Learning_20250922|Fleming-R1: Toward Expert-Level Medical Reasoning via Reinforcement Learning]] (81.0% similar)
- [[2025-09-22/Chain of Strategy Optimization Makes Large Language Models Better Emotional Supporter_20250922|Chain of Strategy Optimization Makes Large Language Models Better Emotional Supporter]] (81.0% similar)
- [[2025-09-22/Perception-R1_ Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward_20250922|Perception-R1: Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward]] (80.9% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Reinforcement Learning|Reinforcement Learning]]
**ğŸ”— Specific Connectable**: [[keywords/Long Counseling Texts|Long Counseling Texts]]
**âš¡ Unique Technical**: [[keywords/Empathy-R1 Framework|Empathy-R1 Framework]], [[keywords/Chain-of-Empathy Reasoning|Chain-of-Empathy Reasoning]], [[keywords/Empathy-QA Dataset|Empathy-QA Dataset]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.14851v2 Announce Type: replace-cross 
Abstract: Empathy is critical for effective mental health support, especially when addressing Long Counseling Texts (LCTs). However, existing Large Language Models (LLMs) often generate replies that are semantically fluent but lack the structured reasoning necessary for genuine psychological support, particularly in a Chinese context. To bridge this gap, we introduce Empathy-R1, a novel framework that integrates a Chain-of-Empathy (CoE) reasoning process with Reinforcement Learning (RL) to enhance response quality for LCTs. Inspired by cognitive-behavioral therapy, our CoE paradigm guides the model to sequentially reason about a help-seeker's emotions, causes, and intentions, making its thinking process both transparent and interpretable. Our framework is empowered by a new large-scale Chinese dataset, Empathy-QA, and a two-stage training process. First, Supervised Fine-Tuning instills the CoE's reasoning structure. Subsequently, RL, guided by a dedicated reward model, refines the therapeutic relevance and contextual appropriateness of the final responses. Experiments show that Empathy-R1 achieves strong performance on key automatic metrics. More importantly, human evaluations confirm its superiority, showing a clear preference over strong baselines and achieving a Win@1 rate of 44.30% on our new benchmark. By enabling interpretable and contextually nuanced responses, Empathy-R1 represents a significant advancement in developing responsible and genuinely beneficial AI for mental health support.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.14851v2 ë°œí‘œ ìœ í˜•: êµì°¨ êµì²´  
ì´ˆë¡: ê³µê°ì€ íŠ¹íˆ ê¸´ ìƒë‹´ í…ìŠ¤íŠ¸(LCT)ë¥¼ ë‹¤ë£° ë•Œ íš¨ê³¼ì ì¸ ì •ì‹  ê±´ê°• ì§€ì›ì— í•„ìˆ˜ì ì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê¸°ì¡´ì˜ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì°½í•œ ë‹µë³€ì„ ìƒì„±í•˜ì§€ë§Œ, íŠ¹íˆ ì¤‘êµ­ì–´ ë§¥ë½ì—ì„œ ì§„ì •í•œ ì‹¬ë¦¬ì  ì§€ì›ì— í•„ìš”í•œ êµ¬ì¡°í™”ëœ ì¶”ë¡ ì´ ë¶€ì¡±í•œ ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ê²©ì°¨ë¥¼ í•´ì†Œí•˜ê¸° ìœ„í•´ ìš°ë¦¬ëŠ” LCTì˜ ì‘ë‹µ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ê³µê° ì²´ì¸(CoE) ì¶”ë¡  í”„ë¡œì„¸ìŠ¤ì™€ ê°•í™” í•™ìŠµ(RL)ì„ í†µí•©í•œ ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ì¸ Empathy-R1ì„ ì†Œê°œí•©ë‹ˆë‹¤. ì¸ì§€ í–‰ë™ ì¹˜ë£Œì—ì„œ ì˜ê°ì„ ë°›ì€ ìš°ë¦¬ì˜ CoE íŒ¨ëŸ¬ë‹¤ì„ì€ ëª¨ë¸ì´ ë„ì›€ì„ ìš”ì²­í•˜ëŠ” ì‚¬ëŒì˜ ê°ì •, ì›ì¸ ë° ì˜ë„ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì¶”ë¡ í•˜ë„ë¡ ì•ˆë‚´í•˜ì—¬ ì‚¬ê³  ê³¼ì •ì„ íˆ¬ëª…í•˜ê³  í•´ì„ ê°€ëŠ¥í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤. ìš°ë¦¬ì˜ í”„ë ˆì„ì›Œí¬ëŠ” ìƒˆë¡œìš´ ëŒ€ê·œëª¨ ì¤‘êµ­ì–´ ë°ì´í„°ì…‹ì¸ Empathy-QAì™€ 2ë‹¨ê³„ í•™ìŠµ í”„ë¡œì„¸ìŠ¤ë¥¼ í†µí•´ ê°•í™”ë©ë‹ˆë‹¤. ë¨¼ì €, ì§€ë„í˜• ë¯¸ì„¸ ì¡°ì •ì„ í†µí•´ CoEì˜ ì¶”ë¡  êµ¬ì¡°ë¥¼ ì£¼ì…í•©ë‹ˆë‹¤. ê·¸ í›„, ì „ìš© ë³´ìƒ ëª¨ë¸ì— ì˜í•´ ì•ˆë‚´ë˜ëŠ” RLì€ ìµœì¢… ì‘ë‹µì˜ ì¹˜ë£Œì  ê´€ë ¨ì„±ê³¼ ë§¥ë½ì  ì ì ˆì„±ì„ ê°œì„ í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼ Empathy-R1ì€ ì£¼ìš” ìë™ ì§€í‘œì—ì„œ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. ë” ì¤‘ìš”í•œ ê²ƒì€ ì¸ê°„ í‰ê°€ì—ì„œ ê°•ë ¥í•œ ê¸°ì¤€ì„ ë³´ë‹¤ ëª…í™•í•œ ì„ í˜¸ë„ë¥¼ ë³´ì´ë©° ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ì—ì„œ Win@1 ë¹„ìœ¨ 44.30%ë¥¼ ë‹¬ì„±í•˜ì—¬ ê·¸ ìš°ìˆ˜ì„±ì„ í™•ì¸í–ˆë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. í•´ì„ ê°€ëŠ¥í•˜ê³  ë§¥ë½ì ìœ¼ë¡œ ë¯¸ë¬˜í•œ ì‘ë‹µì„ ê°€ëŠ¥í•˜ê²Œ í•¨ìœ¼ë¡œì¨ Empathy-R1ì€ ì •ì‹  ê±´ê°• ì§€ì›ì„ ìœ„í•œ ì±…ì„ ìˆê³  ì§„ì •ìœ¼ë¡œ ìœ ìµí•œ AI ê°œë°œì— ìˆì–´ ì¤‘ìš”í•œ ì§„ì „ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

Empathy-R1ì€ ì¥ë¬¸ì˜ ìƒë‹´ í…ìŠ¤íŠ¸(LCTs)ì— ëŒ€í•œ íš¨ê³¼ì ì¸ ì •ì‹  ê±´ê°• ì§€ì›ì„ ìœ„í•´ ê°œë°œëœ ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ê¸°ì¡´ì˜ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì´ ì‹¬ë¦¬ì  ì§€ì›ì— í•„ìš”í•œ êµ¬ì¡°ì  ì¶”ë¡ ì„ ê²°ì—¬í•œ ë°˜ë©´, Empathy-R1ì€ Chain-of-Empathy(CoE) ì¶”ë¡  ê³¼ì •ê³¼ ê°•í™” í•™ìŠµ(RL)ì„ ê²°í•©í•˜ì—¬ ì‘ë‹µì˜ ì§ˆì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. CoEëŠ” ì¸ì§€í–‰ë™ì¹˜ë£Œì—ì„œ ì˜ê°ì„ ë°›ì•„, ë„ì›€ì„ ìš”ì²­í•˜ëŠ” ì‚¬ëŒì˜ ê°ì •, ì›ì¸, ì˜ë„ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì¶”ë¡ í•˜ì—¬ íˆ¬ëª…í•˜ê³  í•´ì„ ê°€ëŠ¥í•œ ì‚¬ê³  ê³¼ì •ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ëŒ€ê·œëª¨ ì¤‘êµ­ì–´ ë°ì´í„°ì…‹ Empathy-QAì™€ ë‘ ë‹¨ê³„ì˜ í›ˆë ¨ ê³¼ì •ì„ í†µí•´ ê°•í™”ë©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, Empathy-R1ì€ ìë™ í‰ê°€ ì§€í‘œì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë©°, ì¸ê°„ í‰ê°€ì—ì„œë„ ê°•ë ¥í•œ ê¸°ì¤€ ëª¨ë¸ë³´ë‹¤ ì„ í˜¸ë˜ë©° Win@1 ë¹„ìœ¨ 44.30%ë¥¼ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ì •ì‹  ê±´ê°• ì§€ì›ì„ ìœ„í•œ ì±…ì„ ìˆê³  ìœ ìµí•œ AI ê°œë°œì— ìˆì–´ ì¤‘ìš”í•œ ë°œì „ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Empathy-R1ì€ ì¥ë¬¸ì˜ ìƒë‹´ í…ìŠ¤íŠ¸(LCTs)ì— ëŒ€í•œ ì‘ë‹µ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ê³µê°ì˜ ì—°ì‡„ ì¶”ë¡ (CoE)ê³¼ ê°•í™” í•™ìŠµ(RL)ì„ í†µí•©í•œ ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.
- 2. CoE íŒ¨ëŸ¬ë‹¤ì„ì€ ì¸ì§€í–‰ë™ì¹˜ë£Œì—ì„œ ì˜ê°ì„ ë°›ì•„ ë„ì›€ì„ ìš”ì²­í•˜ëŠ” ì‚¬ëŒì˜ ê°ì •, ì›ì¸, ì˜ë„ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì¶”ë¡ í•˜ì—¬ ëª¨ë¸ì˜ ì‚¬ê³  ê³¼ì •ì„ íˆ¬ëª…í•˜ê³  í•´ì„ ê°€ëŠ¥í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤.
- 3. Empathy-R1ì€ ìƒˆë¡œìš´ ëŒ€ê·œëª¨ ì¤‘êµ­ì–´ ë°ì´í„°ì…‹ Empathy-QAì™€ ë‘ ë‹¨ê³„ì˜ í›ˆë ¨ ê³¼ì •ì„ í†µí•´ ê°•í™”ë©ë‹ˆë‹¤.
- 4. Empathy-R1ì€ ìë™ í‰ê°€ ì§€í‘œì—ì„œ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë³´ì´ë©°, ì¸ê°„ í‰ê°€ì—ì„œë„ ê°•ë ¥í•œ ê¸°ì¤€ì„ ë³´ë‹¤ ìš°ìˆ˜í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
- 5. Empathy-R1ì€ í•´ì„ ê°€ëŠ¥í•˜ê³  ìƒí™©ì— ë§ëŠ” ì‘ë‹µì„ ê°€ëŠ¥í•˜ê²Œ í•˜ì—¬ ì •ì‹  ê±´ê°• ì§€ì›ì„ ìœ„í•œ ì±…ì„ ìˆê³  ìœ ìµí•œ AI ê°œë°œì— ì¤‘ìš”í•œ ì§„ì „ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.


---

*Generated on 2025-09-23 10:16:42*