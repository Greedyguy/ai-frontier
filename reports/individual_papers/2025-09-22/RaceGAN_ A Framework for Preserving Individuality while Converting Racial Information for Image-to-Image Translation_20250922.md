---
keywords:
  - Generative Adversarial Networks
  - Image-to-Image Translation
  - CycleGAN
  - StarGAN
  - Racial Attribute Translation
category: cs.CV
publish_date: 2025-09-22
arxiv_id: 2509.15391
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:56:38.326295",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Generative Adversarial Networks",
    "Image-to-Image Translation",
    "CycleGAN",
    "StarGAN",
    "Racial Attribute Translation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Generative Adversarial Networks": 0.8,
    "Image-to-Image Translation": 0.82,
    "CycleGAN": 0.7,
    "StarGAN": 0.72,
    "Racial Attribute Translation": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Generative Adversarial Networks",
        "canonical": "Generative Adversarial Networks",
        "aliases": [
          "GANs"
        ],
        "category": "broad_technical",
        "rationale": "GANs are central to the paper's methodology and widely connected in the field of deep learning.",
        "novelty_score": 0.45,
        "connectivity_score": 0.85,
        "specificity_score": 0.65,
        "link_intent_score": 0.8
      },
      {
        "surface": "image-to-image translation",
        "canonical": "Image-to-Image Translation",
        "aliases": [
          "image translation"
        ],
        "category": "specific_connectable",
        "rationale": "This is a core concept of the paper, linking it to various applications in computer vision.",
        "novelty_score": 0.55,
        "connectivity_score": 0.78,
        "specificity_score": 0.72,
        "link_intent_score": 0.82
      },
      {
        "surface": "CycleGAN",
        "canonical": "CycleGAN",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "CycleGAN is a foundational model in the field of image translation, relevant for historical context.",
        "novelty_score": 0.6,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      },
      {
        "surface": "StarGAN",
        "canonical": "StarGAN",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "StarGAN is a significant advancement in multi-domain translation, directly relevant to the paper's focus.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.78,
        "link_intent_score": 0.72
      },
      {
        "surface": "racial attribute translation",
        "canonical": "Racial Attribute Translation",
        "aliases": [
          "racial traits translation"
        ],
        "category": "unique_technical",
        "rationale": "This is the novel contribution of the paper, linking it to specific applications in demographic studies.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "multi-domain",
      "style mapping",
      "reference-guided"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Generative Adversarial Networks",
      "resolved_canonical": "Generative Adversarial Networks",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.85,
        "specificity": 0.65,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "image-to-image translation",
      "resolved_canonical": "Image-to-Image Translation",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.78,
        "specificity": 0.72,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "CycleGAN",
      "resolved_canonical": "CycleGAN",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "StarGAN",
      "resolved_canonical": "StarGAN",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.78,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "racial attribute translation",
      "resolved_canonical": "Racial Attribute Translation",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# RaceGAN: A Framework for Preserving Individuality while Converting Racial Information for Image-to-Image Translation

**Korean Title:** RaceGAN: 이미지-이미지 변환을 위한 인종 정보 변환 시 개별성을 유지하는 프레임워크

## 📋 메타데이터

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15391.pdf)
**Category**: cs.CV
**Published**: 2025-09-22
**ArXiv ID**: [2509.15391](https://arxiv.org/abs/2509.15391)

## 🔗 유사한 논문
- [[2025-09-19/A Race Bias Free Face Aging Model for Reliable Kinship Verification_20250919|A Race Bias Free Face Aging Model for Reliable Kinship Verification]] (82.8% similar)
- [[2025-09-19/Style Transfer with Diffusion Models for Synthetic-to-Real Domain Adaptation_20250919|Style Transfer with Diffusion Models for Synthetic-to-Real Domain Adaptation]] (82.0% similar)
- [[2025-09-22/PRISM_ Phase-enhanced Radial-based Image Signature Mapping framework for fingerprinting AI-generated images_20250922|PRISM: Phase-enhanced Radial-based Image Signature Mapping framework for fingerprinting AI-generated images]] (81.4% similar)
- [[2025-09-19/Controllable Localized Face Anonymization Via Diffusion Inpainting_20250919|Controllable Localized Face Anonymization Via Diffusion Inpainting]] (80.4% similar)
- [[2025-09-17/Class-invariant Test-Time Augmentation for Domain Generalization_20250917|Class-invariant Test-Time Augmentation for Domain Generalization]] (80.4% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Generative Adversarial Networks|Generative Adversarial Networks]]
**🔗 Specific Connectable**: [[keywords/Image-to-Image Translation|Image-to-Image Translation]]
**⚡ Unique Technical**: [[keywords/CycleGAN|CycleGAN]], [[keywords/StarGAN|StarGAN]], [[keywords/Racial Attribute Translation|Racial Attribute Translation]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.15391v1 Announce Type: new 
Abstract: Generative adversarial networks (GANs) have demonstrated significant progress in unpaired image-to-image translation in recent years for several applications. CycleGAN was the first to lead the way, although it was restricted to a pair of domains. StarGAN overcame this constraint by tackling image-to-image translation across various domains, although it was not able to map in-depth low-level style changes for these domains. Style mapping via reference-guided image synthesis has been made possible by the innovations of StarGANv2 and StyleGAN. However, these models do not maintain individuality and need an extra reference image in addition to the input. Our study aims to translate racial traits by means of multi-domain image-to-image translation. We present RaceGAN, a novel framework capable of mapping style codes over several domains during racial attribute translation while maintaining individuality and high level semantics without relying on a reference image. RaceGAN outperforms other models in translating racial features (i.e., Asian, White, and Black) when tested on Chicago Face Dataset. We also give quantitative findings utilizing InceptionReNetv2-based classification to demonstrate the effectiveness of our racial translation. Moreover, we investigate how well the model partitions the latent space into distinct clusters of faces for each ethnic group.

## 🔍 Abstract (한글 번역)

arXiv:2509.15391v1 발표 유형: 신규  
초록: 생성적 적대 신경망(GANs)은 최근 몇 년간 여러 응용 분야에서 비대칭 이미지-이미지 변환에 있어 상당한 진전을 보였습니다. CycleGAN은 두 개의 도메인에 제한되었지만, 최초로 이 분야를 선도했습니다. StarGAN은 여러 도메인 간의 이미지-이미지 변환 문제를 해결하여 이 제약을 극복했으나, 이러한 도메인에 대해 심층적인 저수준 스타일 변화를 매핑하지는 못했습니다. StarGANv2와 StyleGAN의 혁신 덕분에 참조 기반 이미지 합성을 통한 스타일 매핑이 가능해졌습니다. 그러나 이러한 모델들은 개별성을 유지하지 못하고 입력 외에 추가 참조 이미지가 필요합니다. 본 연구는 다중 도메인 이미지-이미지 변환을 통해 인종적 특성을 번역하는 것을 목표로 합니다. 우리는 RaceGAN을 소개하며, 이는 참조 이미지에 의존하지 않고 개별성과 고수준의 의미를 유지하면서 인종 속성 변환 동안 여러 도메인에 걸쳐 스타일 코드를 매핑할 수 있는 새로운 프레임워크입니다. RaceGAN은 시카고 얼굴 데이터셋에서 테스트했을 때 인종적 특징(즉, 아시아인, 백인, 흑인) 번역에서 다른 모델들을 능가합니다. 우리는 또한 InceptionReNetv2 기반 분류를 활용한 정량적 결과를 제시하여 우리의 인종 번역의 효과를 입증합니다. 더 나아가, 모델이 각 민족 그룹에 대한 얼굴의 잠재 공간을 어떻게 명확히 구분된 클러스터로 분할하는지를 조사합니다.

## 📝 요약

이 연구는 다중 도메인 이미지 변환을 통해 인종적 특성을 변환하는 새로운 프레임워크인 RaceGAN을 제안합니다. 기존의 CycleGAN과 StarGAN은 도메인 간 이미지 변환에 제한이 있었고, StarGANv2와 StyleGAN은 스타일 매핑을 위해 추가 참조 이미지가 필요했습니다. RaceGAN은 참조 이미지 없이도 개별성을 유지하면서 고수준의 의미를 보존하며 여러 도메인에서 스타일 코드를 매핑할 수 있습니다. Chicago Face Dataset에서 아시아인, 백인, 흑인의 인종적 특징을 효과적으로 변환하며, InceptionReNetv2 기반 분류를 통해 성능을 입증했습니다. 또한, 모델이 잠재 공간을 각 인종 그룹의 얼굴로 어떻게 구분하는지도 분석했습니다.

## 🎯 주요 포인트

- 1. RaceGAN은 다중 도메인 이미지 변환을 통해 인종적 특성을 번역하며 개별성과 고수준 의미를 유지합니다.
- 2. CycleGAN과 StarGAN의 한계를 극복하여, RaceGAN은 참조 이미지 없이 여러 도메인에서 스타일 코드를 매핑할 수 있습니다.
- 3. RaceGAN은 Chicago Face Dataset에서 아시아인, 백인, 흑인의 인종적 특징을 번역하는 데 있어 다른 모델보다 뛰어난 성능을 보입니다.
- 4. InceptionReNetv2 기반 분류를 사용한 정량적 결과를 통해 인종 번역의 효과를 입증합니다.
- 5. 모델이 각 민족 그룹에 대해 잠재 공간을 명확히 구분된 얼굴 클러스터로 분할하는 능력을 조사합니다.


---

*Generated on 2025-09-23 11:56:38*