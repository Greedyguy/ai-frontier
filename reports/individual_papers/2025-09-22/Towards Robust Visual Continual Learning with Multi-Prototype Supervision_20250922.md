---
keywords:
  - Continual Learning
  - Language-guided Supervision
  - Multi-Prototype Supervision
  - Vision-Language Model
category: cs.CV
publish_date: 2025-09-22
arxiv_id: 2509.16011
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T12:17:06.860980",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Continual Learning",
    "Language-guided Supervision",
    "Multi-Prototype Supervision",
    "Vision-Language Model"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Continual Learning": 0.78,
    "Language-guided Supervision": 0.81,
    "Multi-Prototype Supervision": 0.83,
    "Vision-Language Model": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Continual Learning",
        "canonical": "Continual Learning",
        "aliases": [
          "CL"
        ],
        "category": "broad_technical",
        "rationale": "Continual Learning is a foundational concept in machine learning, relevant for linking with other adaptive learning techniques.",
        "novelty_score": 0.45,
        "connectivity_score": 0.89,
        "specificity_score": 0.65,
        "link_intent_score": 0.78
      },
      {
        "surface": "Language-guided supervision",
        "canonical": "Language-guided Supervision",
        "aliases": [
          "Language-guided"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel approach in the context of visual learning, enhancing the specificity of language and vision integration.",
        "novelty_score": 0.72,
        "connectivity_score": 0.68,
        "specificity_score": 0.82,
        "link_intent_score": 0.81
      },
      {
        "surface": "Multi-Prototype Supervision",
        "canonical": "Multi-Prototype Supervision",
        "aliases": [
          "MuproCL"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a new method for handling semantic ambiguity and visual diversity, crucial for linking advanced learning models.",
        "novelty_score": 0.78,
        "connectivity_score": 0.72,
        "specificity_score": 0.85,
        "link_intent_score": 0.83
      },
      {
        "surface": "Vision-Language Model",
        "canonical": "Vision-Language Model",
        "aliases": [
          "Vision-Language"
        ],
        "category": "evolved_concepts",
        "rationale": "This represents a growing area of research that bridges vision and language, enhancing connectivity with multimodal studies.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.78,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Continual Learning",
      "resolved_canonical": "Continual Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.89,
        "specificity": 0.65,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Language-guided supervision",
      "resolved_canonical": "Language-guided Supervision",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.68,
        "specificity": 0.82,
        "link_intent": 0.81
      }
    },
    {
      "candidate_surface": "Multi-Prototype Supervision",
      "resolved_canonical": "Multi-Prototype Supervision",
      "decision": "linked",
      "scores": {
        "novelty": 0.78,
        "connectivity": 0.72,
        "specificity": 0.85,
        "link_intent": 0.83
      }
    },
    {
      "candidate_surface": "Vision-Language Model",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.78,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Towards Robust Visual Continual Learning with Multi-Prototype Supervision

**Korean Title:** ê°•ê±´í•œ ì‹œê°ì  ì§€ì† í•™ìŠµì„ ìœ„í•œ ë‹¤ì¤‘ í”„ë¡œí† íƒ€ì… ê°ë… ë°©ë²• ì—°êµ¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16011.pdf)
**Category**: cs.CV
**Published**: 2025-09-22
**ArXiv ID**: [2509.16011](https://arxiv.org/abs/2509.16011)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Perception-R1_ Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward_20250922|Perception-R1: Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward]] (85.5% similar)
- [[2025-09-22/LLMs Can Compensate for Deficiencies in Visual Representations_20250922|LLMs Can Compensate for Deficiencies in Visual Representations]] (84.9% similar)
- [[2025-09-19/Modular Machine Learning_ An Indispensable Path towards New-Generation Large Language Models_20250919|Modular Machine Learning: An Indispensable Path towards New-Generation Large Language Models]] (84.8% similar)
- [[2025-09-22/Global Pre-fixing, Local Adjusting_ A Simple yet Effective Contrastive Strategy for Continual Learning_20250922|Global Pre-fixing, Local Adjusting: A Simple yet Effective Contrastive Strategy for Continual Learning]] (84.7% similar)
- [[2025-09-19/Decoupled Proxy Alignment_ Mitigating Language Prior Conflict for Multimodal Alignment in MLLM_20250919|Decoupled Proxy Alignment: Mitigating Language Prior Conflict for Multimodal Alignment in MLLM]] (84.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Continual Learning|Continual Learning]]
**âš¡ Unique Technical**: [[keywords/Language-guided Supervision|Language-guided Supervision]], [[keywords/Multi-Prototype Supervision|Multi-Prototype Supervision]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16011v1 Announce Type: new 
Abstract: Language-guided supervision, which utilizes a frozen semantic target from a Pretrained Language Model (PLM), has emerged as a promising paradigm for visual Continual Learning (CL). However, relying on a single target introduces two critical limitations: 1) semantic ambiguity, where a polysemous category name results in conflicting visual representations, and 2) intra-class visual diversity, where a single prototype fails to capture the rich variety of visual appearances within a class. To this end, we propose MuproCL, a novel framework that replaces the single target with multiple, context-aware prototypes. Specifically, we employ a lightweight LLM agent to perform category disambiguation and visual-modal expansion to generate a robust set of semantic prototypes. A LogSumExp aggregation mechanism allows the vision model to adaptively align with the most relevant prototype for a given image. Extensive experiments across various CL baselines demonstrate that MuproCL consistently enhances performance and robustness, establishing a more effective path for language-guided continual learning.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.16011v1 ë°œí‘œ ìœ í˜•: ìƒˆë¡œìš´ ê²ƒ  
ì´ˆë¡: ì‚¬ì „ í•™ìŠµëœ ì–¸ì–´ ëª¨ë¸(PLM)ì—ì„œ ê³ ì •ëœ ì˜ë¯¸ì  ëª©í‘œë¥¼ í™œìš©í•˜ëŠ” ì–¸ì–´ ì•ˆë‚´ ê°ë…ì€ ì‹œê°ì  ì—°ì† í•™ìŠµ(CL)ì„ ìœ„í•œ ìœ ë§í•œ íŒ¨ëŸ¬ë‹¤ì„ìœ¼ë¡œ ë¶€ìƒí•˜ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë‹¨ì¼ ëª©í‘œì— ì˜ì¡´í•˜ëŠ” ê²ƒì€ ë‘ ê°€ì§€ ì¤‘ìš”í•œ í•œê³„ë¥¼ ì´ˆë˜í•©ë‹ˆë‹¤: 1) ë‹¤ì˜ì  ë²”ì£¼ ì´ë¦„ì´ ìƒì¶©ë˜ëŠ” ì‹œê°ì  í‘œí˜„ì„ ì´ˆë˜í•˜ëŠ” ì˜ë¯¸ì  ëª¨í˜¸ì„±, 2) ë‹¨ì¼ í”„ë¡œí† íƒ€ì…ì´ í´ë˜ìŠ¤ ë‚´ì˜ ë‹¤ì–‘í•œ ì‹œê°ì  ì™¸í˜•ì„ í¬ì°©í•˜ì§€ ëª»í•˜ëŠ” í´ë˜ìŠ¤ ë‚´ ì‹œê°ì  ë‹¤ì–‘ì„±. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” MuproCLì´ë¼ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•˜ì—¬ ë‹¨ì¼ ëª©í‘œë¥¼ ë‹¤ì¤‘ì˜, ë¬¸ë§¥ ì¸ì‹ í”„ë¡œí† íƒ€ì…ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤. êµ¬ì²´ì ìœ¼ë¡œ, ìš°ë¦¬ëŠ” ê²½ëŸ‰ì˜ LLM ì—ì´ì „íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë²”ì£¼ ë¹„ëª¨í˜¸í™” ë° ì‹œê°-ëª¨ë‹¬ í™•ì¥ì„ ìˆ˜í–‰í•˜ì—¬ ê°•ë ¥í•œ ì˜ë¯¸ì  í”„ë¡œí† íƒ€ì… ì„¸íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. LogSumExp ì§‘ê³„ ë©”ì»¤ë‹ˆì¦˜ì€ ë¹„ì „ ëª¨ë¸ì´ ì£¼ì–´ì§„ ì´ë¯¸ì§€ì— ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ì€ í”„ë¡œí† íƒ€ì…ê³¼ ì ì‘ì ìœ¼ë¡œ ì •ë ¬í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. ë‹¤ì–‘í•œ CL ê¸°ì¤€ì„ ì— ëŒ€í•œ ê´‘ë²”ìœ„í•œ ì‹¤í—˜ì„ í†µí•´ MuproCLì´ ì„±ëŠ¥ê³¼ ê²¬ê³ ì„±ì„ ì§€ì†ì ìœ¼ë¡œ í–¥ìƒì‹œí‚¤ë©°, ì–¸ì–´ ì•ˆë‚´ ì—°ì† í•™ìŠµì„ ìœ„í•œ ë³´ë‹¤ íš¨ê³¼ì ì¸ ê²½ë¡œë¥¼ í™•ë¦½í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì‚¬ì „ í•™ìŠµëœ ì–¸ì–´ ëª¨ë¸(PLM)ì„ í™œìš©í•œ ì–¸ì–´ ê¸°ë°˜ ê°ë…ì´ ì‹œê°ì  ì§€ì† í•™ìŠµ(CL)ì—ì„œ ìœ ë§í•œ ì ‘ê·¼ë²•ìœ¼ë¡œ ë– ì˜¤ë¥´ê³  ìˆìŒì„ ì„¤ëª…í•©ë‹ˆë‹¤. ê¸°ì¡´ ë°©ë²•ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´, MuproCLì´ë¼ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ë‹¨ì¼ ëª©í‘œ ëŒ€ì‹  ë‹¤ì¤‘, ë¬¸ë§¥ ì¸ì‹ í”„ë¡œí† íƒ€ì…ì„ ì‚¬ìš©í•˜ì—¬ ì˜ë¯¸ì  ëª¨í˜¸ì„±ê³¼ í´ë˜ìŠ¤ ë‚´ ì‹œê°ì  ë‹¤ì–‘ì„±ì„ í•´ê²°í•©ë‹ˆë‹¤. ê²½ëŸ‰ LLM ì—ì´ì „íŠ¸ë¥¼ í™œìš©í•´ ì¹´í…Œê³ ë¦¬ ë¹„ëª¨í˜¸í™”ì™€ ì‹œê°-ëª¨ë‹¬ í™•ì¥ì„ ìˆ˜í–‰í•˜ë©°, LogSumExp ì§‘ê³„ ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ í”„ë¡œí† íƒ€ì…ê³¼ ì ì‘ì ìœ¼ë¡œ ì •ë ¬í•©ë‹ˆë‹¤. ë‹¤ì–‘í•œ CL ê¸°ì¤€ ì‹¤í—˜ì—ì„œ MuproCLì€ ì„±ëŠ¥ê³¼ ê²¬ê³ ì„±ì„ ì§€ì†ì ìœ¼ë¡œ í–¥ìƒì‹œì¼œ ì–¸ì–´ ê¸°ë°˜ ì§€ì† í•™ìŠµì˜ íš¨ê³¼ì ì¸ ê²½ë¡œë¥¼ ì œì‹œí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. MuproCLì€ ë‹¨ì¼ ëª©í‘œ ëŒ€ì‹  ë‹¤ì¤‘, ë¬¸ë§¥ ì¸ì‹ í”„ë¡œí† íƒ€ì…ì„ ì‚¬ìš©í•˜ì—¬ ì‹œê°ì  ì§€ì† í•™ìŠµì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
- 2. ê²½ëŸ‰ LLM ì—ì´ì „íŠ¸ë¥¼ í™œìš©í•˜ì—¬ ë²”ì£¼ ë¹„ëª¨í˜¸í™” ë° ì‹œê°ì  ëª¨ë‹¬ í™•ì¥ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
- 3. LogSumExp ì§‘ê³„ ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´ ë¹„ì „ ëª¨ë¸ì´ ì£¼ì–´ì§„ ì´ë¯¸ì§€ì— ê°€ì¥ ê´€ë ¨ì„± ìˆëŠ” í”„ë¡œí† íƒ€ì…ê³¼ ì ì‘ì ìœ¼ë¡œ ì •ë ¬í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
- 4. ë‹¤ì–‘í•œ ì§€ì† í•™ìŠµ ê¸°ì¤€ ì‹¤í—˜ì—ì„œ MuproCLì€ ì¼ê´€ë˜ê²Œ ì„±ëŠ¥ê³¼ ê²¬ê³ ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
- 5. MuproCLì€ ì–¸ì–´ ê¸°ë°˜ ì§€ì† í•™ìŠµì„ ìœ„í•œ ë³´ë‹¤ íš¨ê³¼ì ì¸ ê²½ë¡œë¥¼ ì œì‹œí•©ë‹ˆë‹¤.


---

*Generated on 2025-09-23 12:17:06*