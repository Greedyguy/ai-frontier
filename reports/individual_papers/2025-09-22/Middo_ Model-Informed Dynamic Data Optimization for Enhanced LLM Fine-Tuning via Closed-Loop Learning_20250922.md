---
keywords:
  - Large Language Model
  - Supervised Fine-Tuning
  - Model-Informed Dynamic Data Optimization
  - Closed-Loop Learning
  - Dynamic Learning Principles
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2508.21589
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T10:09:50.652365",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Supervised Fine-Tuning",
    "Model-Informed Dynamic Data Optimization",
    "Closed-Loop Learning",
    "Dynamic Learning Principles"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Supervised Fine-Tuning": 0.78,
    "Model-Informed Dynamic Data Optimization": 0.8,
    "Closed-Loop Learning": 0.77,
    "Dynamic Learning Principles": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Large Language Models"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's focus on optimizing fine-tuning processes.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Supervised Fine-Tuning",
        "canonical": "Supervised Fine-Tuning",
        "aliases": [
          "SFT"
        ],
        "category": "unique_technical",
        "rationale": "Key process discussed for enhancing LLM performance.",
        "novelty_score": 0.65,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Model-informed dynamic data optimization",
        "canonical": "Model-Informed Dynamic Data Optimization",
        "aliases": [
          "Middo"
        ],
        "category": "unique_technical",
        "rationale": "Describes the novel framework introduced in the paper.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Closed-loop learning",
        "canonical": "Closed-Loop Learning",
        "aliases": [
          "Closed-loop optimization"
        ],
        "category": "specific_connectable",
        "rationale": "Represents the iterative process crucial to the framework.",
        "novelty_score": 0.55,
        "connectivity_score": 0.78,
        "specificity_score": 0.75,
        "link_intent_score": 0.77
      },
      {
        "surface": "Dynamic learning principles",
        "canonical": "Dynamic Learning Principles",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Highlights the evolving nature of the learning process in the framework.",
        "novelty_score": 0.68,
        "connectivity_score": 0.65,
        "specificity_score": 0.82,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Supervised Fine-Tuning",
      "resolved_canonical": "Supervised Fine-Tuning",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Model-informed dynamic data optimization",
      "resolved_canonical": "Model-Informed Dynamic Data Optimization",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Closed-loop learning",
      "resolved_canonical": "Closed-Loop Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.78,
        "specificity": 0.75,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Dynamic learning principles",
      "resolved_canonical": "Dynamic Learning Principles",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.65,
        "specificity": 0.82,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Middo: Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning

**Korean Title:** 미도: 폐루프 학습을 통한 향상된 대규모 언어 모델(LLM) 미세 조정을 위한 모델 정보 기반 동적 데이터 최적화

## 📋 메타데이터

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2508.21589.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2508.21589](https://arxiv.org/abs/2508.21589)

## 🔗 유사한 논문
- [[2025-09-22/A method for improving multilingual quality and diversity of instruction fine-tuning datasets_20250922|A method for improving multilingual quality and diversity of instruction fine-tuning datasets]] (88.5% similar)
- [[2025-09-19/Decoupled Proxy Alignment_ Mitigating Language Prior Conflict for Multimodal Alignment in MLLM_20250919|Decoupled Proxy Alignment: Mitigating Language Prior Conflict for Multimodal Alignment in MLLM]] (86.9% similar)
- [[2025-09-19/Modular Machine Learning_ An Indispensable Path towards New-Generation Large Language Models_20250919|Modular Machine Learning: An Indispensable Path towards New-Generation Large Language Models]] (86.7% similar)
- [[2025-09-22/A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages_20250922|A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages]] (85.8% similar)
- [[2025-09-19/Adding LLMs to the psycholinguistic norming toolbox_ A practical guide to getting the most out of human ratings_20250919|Adding LLMs to the psycholinguistic norming toolbox: A practical guide to getting the most out of human ratings]] (85.7% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Closed-Loop Learning|Closed-Loop Learning]]
**⚡ Unique Technical**: [[keywords/Supervised Fine-Tuning|Supervised Fine-Tuning]], [[keywords/Model-Informed Dynamic Data Optimization|Model-Informed Dynamic Data Optimization]], [[keywords/Dynamic Learning Principles|Dynamic Learning Principles]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2508.21589v3 Announce Type: replace-cross 
Abstract: Supervised Fine-Tuning (SFT) Large Language Models (LLM) fundamentally rely on high-quality training data. While data selection and data synthesis are two common strategies to improve data quality, existing approaches often face limitations in static dataset curation that fail to adapt to evolving model capabilities. In this paper, we introduce Middo, a self-evolving Model-informed dynamic data optimization framework that uses model-aware data selection and context-preserving data refinement. Unlike conventional one-off filtering/synthesis methods, our framework establishes a closed-loop optimization system: (1) A self-referential diagnostic module proactively identifies suboptimal samples through tri-axial model signals - loss patterns (complexity), embedding cluster dynamics (diversity), and self-alignment scores (quality); (2) An adaptive optimization engine then transforms suboptimal samples into pedagogically valuable training points while preserving semantic integrity; (3) This optimization process continuously evolves with model capability through dynamic learning principles. Experiments on multiple benchmarks demonstrate that our Middo consistently enhances the quality of seed data and boosts LLM's performance with improving accuracy by 7.15% on average while maintaining the original dataset scale. This work establishes a new paradigm for sustainable LLM training through dynamic human-AI co-evolution of data and models. Our datasets, models, and code are coming soon. Our datasets, models, and code are publicly available at https://github.com/Word2VecT/Middo.

## 🔍 Abstract (한글 번역)

arXiv:2508.21589v3 발표 유형: 교차 교체  
초록: 지도 학습 세부 조정(SFT) 대형 언어 모델(LLM)은 근본적으로 고품질의 학습 데이터에 의존합니다. 데이터 선택과 데이터 합성은 데이터 품질을 향상시키기 위한 두 가지 일반적인 전략이지만, 기존 접근법은 모델의 능력이 발전함에 따라 적응하지 못하는 정적 데이터셋 큐레이션의 한계를 자주 직면합니다. 이 논문에서는 모델 인식 데이터 선택과 문맥 보존 데이터 정제를 사용하는 자가 진화 모델 정보 기반 동적 데이터 최적화 프레임워크인 Middo를 소개합니다. 기존의 일회성 필터링/합성 방법과 달리, 우리의 프레임워크는 폐쇄 루프 최적화 시스템을 구축합니다: (1) 자기 참조 진단 모듈은 복잡성(손실 패턴), 다양성(임베딩 클러스터 동역학), 품질(자기 정렬 점수)이라는 세 축의 모델 신호를 통해 최적화되지 않은 샘플을 능동적으로 식별합니다; (2) 적응형 최적화 엔진은 의미적 무결성을 유지하면서 최적화되지 않은 샘플을 교육적으로 가치 있는 학습 포인트로 변환합니다; (3) 이 최적화 과정은 동적 학습 원칙을 통해 모델의 능력과 함께 지속적으로 진화합니다. 여러 벤치마크 실험에서 우리의 Middo는 시드 데이터의 품질을 지속적으로 향상시키고, 원래 데이터셋 규모를 유지하면서 평균 7.15%의 정확도 향상을 통해 LLM의 성능을 향상시킵니다. 이 연구는 데이터와 모델의 동적 인간-AI 공동 진화를 통한 지속 가능한 LLM 학습의 새로운 패러다임을 확립합니다. 우리의 데이터셋, 모델 및 코드는 곧 공개될 예정입니다. 우리의 데이터셋, 모델 및 코드는 https://github.com/Word2VecT/Middo에서 공개적으로 이용 가능합니다.

## 📝 요약

이 논문에서는 고품질 훈련 데이터를 필요로 하는 대규모 언어 모델(LLM)의 지도 학습을 개선하기 위해 Middo라는 동적 데이터 최적화 프레임워크를 제안합니다. 기존의 정적 데이터 선택 및 합성 방법의 한계를 극복하기 위해, Middo는 모델 인식 데이터 선택과 맥락 보존 데이터 정제를 활용합니다. 이 프레임워크는 삼중 축 모델 신호를 통해 비최적 샘플을 식별하고, 이를 교육적으로 가치 있는 훈련 데이터로 변환하는 적응형 최적화 엔진을 포함합니다. 실험 결과, Middo는 데이터 품질을 지속적으로 향상시키며, LLM의 성능을 평균 7.15% 향상시켰습니다. 이 연구는 데이터와 모델의 동적 인간-AI 공진화를 통해 지속 가능한 LLM 훈련의 새로운 패러다임을 제시합니다.

## 🎯 주요 포인트

- 1. Middo는 모델 인식 데이터 선택과 문맥 보존 데이터 정제를 사용하는 자가 진화형 동적 데이터 최적화 프레임워크입니다.
- 2. 이 프레임워크는 손실 패턴, 임베딩 클러스터 동역학, 자기 정렬 점수를 통해 비최적 샘플을 식별하는 자기 참조 진단 모듈을 포함합니다.
- 3. 적응형 최적화 엔진은 비최적 샘플을 교육적으로 가치 있는 훈련 포인트로 변환하며, 의미적 무결성을 유지합니다.
- 4. Middo는 모델의 능력에 따라 지속적으로 진화하며, 평균적으로 정확도를 7.15% 향상시킵니다.
- 5. 이 연구는 동적 인간-AI 데이터 및 모델의 공동 진화를 통한 지속 가능한 대형 언어 모델(LLM) 훈련의 새로운 패러다임을 제시합니다.


---

*Generated on 2025-09-23 10:09:50*