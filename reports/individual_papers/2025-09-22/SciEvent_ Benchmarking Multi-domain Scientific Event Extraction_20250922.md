---
keywords:
  - Scientific Event Extraction
  - Large Language Model
  - Multi-domain Benchmark
  - Event Extraction Schema
category: cs.CL
publish_date: 2025-09-22
arxiv_id: 2509.15620
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:31:29.512591",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Scientific Event Extraction",
    "Large Language Model",
    "Multi-domain Benchmark",
    "Event Extraction Schema"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Scientific Event Extraction": 0.8,
    "Large Language Model": 0.85,
    "Multi-domain Benchmark": 0.78,
    "Event Extraction Schema": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Scientific Event Extraction",
        "canonical": "Scientific Event Extraction",
        "aliases": [
          "SciEvent"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a new benchmark for event extraction across multiple scientific domains, enhancing interdisciplinary research connections.",
        "novelty_score": 0.85,
        "connectivity_score": 0.7,
        "specificity_score": 0.88,
        "link_intent_score": 0.8
      },
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Connects to the existing concept of large language models, which are pivotal in processing and extracting scientific information.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Multi-domain Benchmark",
        "canonical": "Multi-domain Benchmark",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Represents a novel approach to benchmarking across various scientific fields, fostering cross-domain insights.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Event Extraction Schema",
        "canonical": "Event Extraction Schema",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Defines a structured approach to capturing scientific events, crucial for improving information extraction accuracy.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "entity-relation extraction",
      "performance gap",
      "manual annotations"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Scientific Event Extraction",
      "resolved_canonical": "Scientific Event Extraction",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.7,
        "specificity": 0.88,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Multi-domain Benchmark",
      "resolved_canonical": "Multi-domain Benchmark",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Event Extraction Schema",
      "resolved_canonical": "Event Extraction Schema",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# SciEvent: Benchmarking Multi-domain Scientific Event Extraction

**Korean Title:** ê³¼í•™ ì´ë²¤íŠ¸: ë‹¤ì¤‘ ë„ë©”ì¸ ê³¼í•™ ì´ë²¤íŠ¸ ì¶”ì¶œì˜ ë²¤ì¹˜ë§ˆí‚¹

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15620.pdf)
**Category**: cs.CL
**Published**: 2025-09-22
**ArXiv ID**: [2509.15620](https://arxiv.org/abs/2509.15620)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/SNaRe_ Domain-aware Data Generation for Low-Resource Event Detection_20250919|SNaRe: Domain-aware Data Generation for Low-Resource Event Detection]] (82.8% similar)
- [[2025-09-19/An Evaluation-Centric Paradigm for Scientific Visualization Agents_20250919|An Evaluation-Centric Paradigm for Scientific Visualization Agents]] (80.0% similar)
- [[2025-09-19/DiCoRe_ Enhancing Zero-shot Event Detection via Divergent-Convergent LLM Reasoning_20250919|DiCoRe: Enhancing Zero-shot Event Detection via Divergent-Convergent LLM Reasoning]] (77.7% similar)
- [[2025-09-19/SPICE_ An Automated SWE-Bench Labeling Pipeline for Issue Clarity, Test Coverage, and Effort Estimation_20250919|SPICE: An Automated SWE-Bench Labeling Pipeline for Issue Clarity, Test Coverage, and Effort Estimation]] (77.5% similar)
- [[2025-09-17/Combining Evidence and Reasoning for Biomedical Fact-Checking_20250917|Combining Evidence and Reasoning for Biomedical Fact-Checking]] (77.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**âš¡ Unique Technical**: [[keywords/Scientific Event Extraction|Scientific Event Extraction]], [[keywords/Multi-domain Benchmark|Multi-domain Benchmark]], [[keywords/Event Extraction Schema|Event Extraction Schema]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15620v1 Announce Type: new 
Abstract: Scientific information extraction (SciIE) has primarily relied on entity-relation extraction in narrow domains, limiting its applicability to interdisciplinary research and struggling to capture the necessary context of scientific information, often resulting in fragmented or conflicting statements. In this paper, we introduce SciEvent, a novel multi-domain benchmark of scientific abstracts annotated via a unified event extraction (EE) schema designed to enable structured and context-aware understanding of scientific content. It includes 500 abstracts across five research domains, with manual annotations of event segments, triggers, and fine-grained arguments. We define SciIE as a multi-stage EE pipeline: (1) segmenting abstracts into core scientific activities--Background, Method, Result, and Conclusion; and (2) extracting the corresponding triggers and arguments. Experiments with fine-tuned EE models, large language models (LLMs), and human annotators reveal a performance gap, with current models struggling in domains such as sociology and humanities. SciEvent serves as a challenging benchmark and a step toward generalizable, multi-domain SciIE.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15620v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: ê³¼í•™ ì •ë³´ ì¶”ì¶œ(SciIE)ì€ ì£¼ë¡œ ì¢ì€ ë¶„ì•¼ì—ì„œì˜ ì—”í‹°í‹°-ê´€ê³„ ì¶”ì¶œì— ì˜ì¡´í•´ ì™”ìœ¼ë©°, ì´ëŠ” í•™ì œ ê°„ ì—°êµ¬ì—ì˜ ì ìš© ê°€ëŠ¥ì„±ì„ ì œí•œí•˜ê³  ê³¼í•™ ì •ë³´ì˜ í•„ìˆ˜ì ì¸ ë§¥ë½ì„ í¬ì°©í•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªì–´ ì¢…ì¢… ë‹¨í¸ì ì´ê±°ë‚˜ ìƒì¶©ë˜ëŠ” ì§„ìˆ ì„ ì´ˆë˜í•©ë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ê³¼í•™ ì½˜í…ì¸ ì˜ êµ¬ì¡°ì ì´ê³  ë§¥ë½ì„ ê³ ë ¤í•œ ì´í•´ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ê¸° ìœ„í•´ í†µí•©ëœ ì´ë²¤íŠ¸ ì¶”ì¶œ(EE) ìŠ¤í‚¤ë§ˆë¥¼ í†µí•´ ì£¼ì„ì´ ë‹¬ë¦° ê³¼í•™ ì´ˆë¡ì˜ ìƒˆë¡œìš´ ë‹¤ì¤‘ ë„ë©”ì¸ ë²¤ì¹˜ë§ˆí¬ì¸ SciEventë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ì´ëŠ” ë‹¤ì„¯ ê°œì˜ ì—°êµ¬ ë¶„ì•¼ì— ê±¸ì³ 500ê°œì˜ ì´ˆë¡ì„ í¬í•¨í•˜ë©°, ì´ë²¤íŠ¸ ì„¸ê·¸ë¨¼íŠ¸, íŠ¸ë¦¬ê±° ë° ì„¸ë¶€ì ì¸ ì¸ìˆ˜ì— ëŒ€í•œ ìˆ˜ë™ ì£¼ì„ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” SciIEë¥¼ ë‹¤ë‹¨ê³„ EE íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì •ì˜í•©ë‹ˆë‹¤: (1) ì´ˆë¡ì„ í•µì‹¬ ê³¼í•™ í™œë™--ë°°ê²½, ë°©ë²•, ê²°ê³¼, ê²°ë¡ ìœ¼ë¡œ ì„¸ë¶„í™”í•˜ê³ ; (2) í•´ë‹¹ íŠ¸ë¦¬ê±°ì™€ ì¸ìˆ˜ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. ì„¸ë°€í•˜ê²Œ ì¡°ì •ëœ EE ëª¨ë¸, ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM), ì¸ê°„ ì£¼ì„ìì™€ì˜ ì‹¤í—˜ì€ ì‚¬íšŒí•™ ë° ì¸ë¬¸í•™ê³¼ ê°™ì€ ë¶„ì•¼ì—ì„œ í˜„ì¬ ëª¨ë¸ì´ ì–´ë ¤ì›€ì„ ê²ªê³  ìˆìŒì„ ë³´ì—¬ì£¼ëŠ” ì„±ëŠ¥ ê²©ì°¨ë¥¼ ë“œëŸ¬ëƒ…ë‹ˆë‹¤. SciEventëŠ” ë„ì „ì ì¸ ë²¤ì¹˜ë§ˆí¬ë¡œì„œ ì¼ë°˜í™” ê°€ëŠ¥í•˜ê³  ë‹¤ì¤‘ ë„ë©”ì¸ì— ê±¸ì¹œ SciIEë¡œ ë‚˜ì•„ê°€ëŠ” í•œ ê±¸ìŒì´ ë©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ê³¼í•™ ì •ë³´ ì¶”ì¶œ(SciIE)ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ SciEventë¼ëŠ” ìƒˆë¡œìš´ ë‹¤ì¤‘ ë„ë©”ì¸ ë²¤ì¹˜ë§ˆí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. SciEventëŠ” í†µí•©ëœ ì´ë²¤íŠ¸ ì¶”ì¶œ(EE) ìŠ¤í‚¤ë§ˆë¥¼ í†µí•´ ê³¼í•™ì  ë‚´ìš©ì„ êµ¬ì¡°ì ì´ê³  ë§¥ë½ì ìœ¼ë¡œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. 5ê°œ ì—°êµ¬ ë¶„ì•¼ì—ì„œ 500ê°œì˜ ì´ˆë¡ì„ ìˆ˜ì§‘í•˜ê³ , ì´ë²¤íŠ¸ ì„¸ê·¸ë¨¼íŠ¸, íŠ¸ë¦¬ê±°, ì„¸ë¶€ì ì¸ ì¸ìë¥¼ ìˆ˜ì‘ì—…ìœ¼ë¡œ ì£¼ì„ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤. SciIEëŠ” (1) ì´ˆë¡ì„ ë°°ê²½, ë°©ë²•, ê²°ê³¼, ê²°ë¡ ì˜ í•µì‹¬ ê³¼í•™ í™œë™ìœ¼ë¡œ ì„¸ë¶„í™”í•˜ê³ , (2) í•´ë‹¹ íŠ¸ë¦¬ê±°ì™€ ì¸ìë¥¼ ì¶”ì¶œí•˜ëŠ” ë‹¤ë‹¨ê³„ EE íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì •ì˜ë©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, í˜„ì¬ ëª¨ë¸ë“¤ì´ ì‚¬íšŒí•™ ë° ì¸ë¬¸í•™ ë¶„ì•¼ì—ì„œ ì–´ë ¤ì›€ì„ ê²ªê³  ìˆìŒì„ ë³´ì—¬ì£¼ë©°, SciEventëŠ” ì¼ë°˜í™” ê°€ëŠ¥í•œ ë‹¤ì¤‘ ë„ë©”ì¸ SciIEë¡œ ë‚˜ì•„ê°€ëŠ” ì¤‘ìš”í•œ ë°œíŒì´ ë©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. SciEventëŠ” ê³¼í•™ ì •ë³´ ì¶”ì¶œì„ ìœ„í•œ ìƒˆë¡œìš´ ë‹¤ì¤‘ ë„ë©”ì¸ ë²¤ì¹˜ë§ˆí¬ë¡œ, í†µí•©ëœ ì´ë²¤íŠ¸ ì¶”ì¶œ ìŠ¤í‚¤ë§ˆë¥¼ í†µí•´ ê³¼í•™ ì½˜í…ì¸ ì˜ êµ¬ì¡°ì ì´ê³  ë§¥ë½ì ì¸ ì´í•´ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
- 2. SciEventëŠ” 5ê°œ ì—°êµ¬ ë¶„ì•¼ì˜ 500ê°œ ì´ˆë¡ì„ í¬í•¨í•˜ë©°, ì´ë²¤íŠ¸ ì„¸ê·¸ë¨¼íŠ¸, íŠ¸ë¦¬ê±°, ì„¸ë¶€ì ì¸ ì¸ìˆ˜ì— ëŒ€í•œ ìˆ˜ì‘ì—… ì£¼ì„ì„ ì œê³µí•©ë‹ˆë‹¤.
- 3. SciIEëŠ” ë°°ê²½, ë°©ë²•, ê²°ê³¼, ê²°ë¡ ìœ¼ë¡œ ì´ˆë¡ì„ ì„¸ë¶„í™”í•˜ê³ , í•´ë‹¹ íŠ¸ë¦¬ê±°ì™€ ì¸ìˆ˜ë¥¼ ì¶”ì¶œí•˜ëŠ” ë‹¤ë‹¨ê³„ ì´ë²¤íŠ¸ ì¶”ì¶œ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì •ì˜ë©ë‹ˆë‹¤.
- 4. ì‹¤í—˜ ê²°ê³¼, í˜„ì¬ ëª¨ë¸ì€ ì‚¬íšŒí•™ ë° ì¸ë¬¸í•™ ë¶„ì•¼ì—ì„œ ì„±ëŠ¥ ê²©ì°¨ë¥¼ ë³´ì´ë©°, SciEventëŠ” ì¼ë°˜í™” ê°€ëŠ¥í•œ ë‹¤ì¤‘ ë„ë©”ì¸ ê³¼í•™ ì •ë³´ ì¶”ì¶œì„ ìœ„í•œ ë„ì „ì ì¸ ë²¤ì¹˜ë§ˆí¬ë¡œ ì‘ìš©í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-23 11:31:29*