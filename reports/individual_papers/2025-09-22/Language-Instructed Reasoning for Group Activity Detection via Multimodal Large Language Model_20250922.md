---
keywords:
  - Multimodal Learning
  - Group Activity Detection
  - Transformer
  - Multimodal Dual-Alignment Fusion
category: cs.CV
publish_date: 2025-09-22
arxiv_id: 2509.16054
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T12:19:10.238755",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multimodal Learning",
    "Group Activity Detection",
    "Transformer",
    "Multimodal Dual-Alignment Fusion"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multimodal Learning": 0.78,
    "Group Activity Detection": 0.77,
    "Transformer": 0.7,
    "Multimodal Dual-Alignment Fusion": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multimodal Large Language Model",
        "canonical": "Multimodal Learning",
        "aliases": [
          "MLLM"
        ],
        "category": "specific_connectable",
        "rationale": "Connects with the trend of integrating multiple modalities in language models, enhancing cross-domain insights.",
        "novelty_score": 0.58,
        "connectivity_score": 0.85,
        "specificity_score": 0.72,
        "link_intent_score": 0.78
      },
      {
        "surface": "Group Activity Detection",
        "canonical": "Group Activity Detection",
        "aliases": [
          "GAD"
        ],
        "category": "unique_technical",
        "rationale": "A specialized task within computer vision, offering a unique link to activity recognition research.",
        "novelty_score": 0.65,
        "connectivity_score": 0.68,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      },
      {
        "surface": "Transformer Networks",
        "canonical": "Transformer",
        "aliases": [
          "Transformer Networks"
        ],
        "category": "broad_technical",
        "rationale": "A foundational architecture in modern deep learning, facilitating connections across various applications.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.7
      },
      {
        "surface": "Multimodal Dual-Alignment Fusion",
        "canonical": "Multimodal Dual-Alignment Fusion",
        "aliases": [
          "MDAF"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel integration technique for aligning multimodal data, enhancing model performance.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "video sequences",
      "visual features"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multimodal Large Language Model",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.85,
        "specificity": 0.72,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Group Activity Detection",
      "resolved_canonical": "Group Activity Detection",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.68,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Transformer Networks",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Multimodal Dual-Alignment Fusion",
      "resolved_canonical": "Multimodal Dual-Alignment Fusion",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# Language-Instructed Reasoning for Group Activity Detection via Multimodal Large Language Model

**Korean Title:** ì–¸ì–´ ì§€ì‹œì  ì¶”ë¡ ì„ í†µí•œ ê·¸ë£¹ í™œë™ íƒì§€: ë‹¤ì¤‘ ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì„ í™œìš©í•˜ì—¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16054.pdf)
**Category**: cs.CV
**Published**: 2025-09-22
**ArXiv ID**: [2509.16054](https://arxiv.org/abs/2509.16054)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Unleashing the Potential of Multimodal LLMs for Zero-Shot Spatio-Temporal Video Grounding_20250919|Unleashing the Potential of Multimodal LLMs for Zero-Shot Spatio-Temporal Video Grounding]] (83.1% similar)
- [[2025-09-19/DetectAnyLLM_ Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models_20250919|DetectAnyLLM: Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models]] (82.9% similar)
- [[2025-09-22/Perception-R1_ Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward_20250922|Perception-R1: Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward]] (82.2% similar)
- [[2025-09-19/Modular Machine Learning_ An Indispensable Path towards New-Generation Large Language Models_20250919|Modular Machine Learning: An Indispensable Path towards New-Generation Large Language Models]] (81.4% similar)
- [[2025-09-18/LLM-I_ LLMs are Naturally Interleaved Multimodal Creators_20250918|LLM-I: LLMs are Naturally Interleaved Multimodal Creators]] (81.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Transformer|Transformer]]
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**âš¡ Unique Technical**: [[keywords/Group Activity Detection|Group Activity Detection]], [[keywords/Multimodal Dual-Alignment Fusion|Multimodal Dual-Alignment Fusion]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16054v1 Announce Type: new 
Abstract: Group activity detection (GAD) aims to simultaneously identify group members and categorize their collective activities within video sequences. Existing deep learning-based methods develop specialized architectures (e.g., transformer networks) to model the dynamics of individual roles and semantic dependencies between individuals and groups. However, they rely solely on implicit pattern recognition from visual features and struggle with contextual reasoning and explainability. In this work, we propose LIR-GAD, a novel framework of language-instructed reasoning for GAD via Multimodal Large Language Model (MLLM). Our approach expand the original vocabulary of MLLM by introducing an activity-level  token and multiple cluster-specific  tokens. We process video frames alongside two specially designed tokens and language instructions, which are then integrated into the MLLM. The pretrained commonsense knowledge embedded in the MLLM enables the  token and  tokens to effectively capture the semantic information of collective activities and learn distinct representational features of different groups, respectively. Also, we introduce a multi-label classification loss to further enhance the  token's ability to learn discriminative semantic representations. Then, we design a Multimodal Dual-Alignment Fusion (MDAF) module that integrates MLLM's hidden embeddings corresponding to the designed tokens with visual features, significantly enhancing the performance of GAD. Both quantitative and qualitative experiments demonstrate the superior performance of our proposed method in GAD taks.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.16054v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: ê·¸ë£¹ í™œë™ ê°ì§€(GAD)ëŠ” ë¹„ë””ì˜¤ ì‹œí€€ìŠ¤ ë‚´ì—ì„œ ê·¸ë£¹ êµ¬ì„±ì›ì„ ì‹ë³„í•˜ê³  ê·¸ë“¤ì˜ ì§‘ë‹¨ í™œë™ì„ ë¶„ë¥˜í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë”¥ëŸ¬ë‹ ê¸°ë°˜ ë°©ë²•ë“¤ì€ ê°œë³„ ì—­í• ì˜ ì—­í•™ê³¼ ê°œì¸ê³¼ ê·¸ë£¹ ê°„ì˜ ì˜ë¯¸ì  ì˜ì¡´ì„±ì„ ëª¨ë¸ë§í•˜ê¸° ìœ„í•´ íŠ¹í™”ëœ ì•„í‚¤í…ì²˜(ì˜ˆ: íŠ¸ëœìŠ¤í¬ë¨¸ ë„¤íŠ¸ì›Œí¬)ë¥¼ ê°œë°œí•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ëŸ¬í•œ ë°©ë²•ë“¤ì€ ì‹œê°ì  íŠ¹ì§•ì—ì„œ ì•”ë¬µì ì¸ íŒ¨í„´ ì¸ì‹ì—ë§Œ ì˜ì¡´í•˜ë©°, ë§¥ë½ì  ì¶”ë¡ ê³¼ ì„¤ëª… ê°€ëŠ¥ì„±ì—ì„œ ì–´ë ¤ì›€ì„ ê²ªìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” ë©€í‹°ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(MLLM)ì„ í†µí•œ GADë¥¼ ìœ„í•œ ì–¸ì–´ ì§€ì‹œ ì¶”ë¡ ì˜ ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ì¸ LIR-GADë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì ‘ê·¼ë²•ì€ í™œë™ ìˆ˜ì¤€ í† í°ê³¼ ì—¬ëŸ¬ í´ëŸ¬ìŠ¤í„° íŠ¹ì • í† í°ì„ ë„ì…í•˜ì—¬ MLLMì˜ ì›ë˜ ì–´íœ˜ë¥¼ í™•ì¥í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ë¹„ë””ì˜¤ í”„ë ˆì„ì„ ë‘ ê°œì˜ íŠ¹ë³„íˆ ì„¤ê³„ëœ í† í°ê³¼ ì–¸ì–´ ì§€ì‹œì™€ í•¨ê»˜ ì²˜ë¦¬í•˜ê³ , ì´ë¥¼ MLLMì— í†µí•©í•©ë‹ˆë‹¤. MLLMì— ë‚´ì¥ëœ ì‚¬ì „ í•™ìŠµëœ ìƒì‹ ì§€ì‹ì€ í† í°ê³¼ í† í°ë“¤ì´ ì§‘ë‹¨ í™œë™ì˜ ì˜ë¯¸ ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í¬ì°©í•˜ê³ , ê°ê° ë‹¤ë¥¸ ê·¸ë£¹ì˜ ë…íŠ¹í•œ í‘œí˜„ íŠ¹ì§•ì„ í•™ìŠµí•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤. ë˜í•œ, ìš°ë¦¬ëŠ” í† í°ì˜ ì°¨ë³„ì ì¸ ì˜ë¯¸ í‘œí˜„ í•™ìŠµ ëŠ¥ë ¥ì„ ë”ìš± í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ë‹¤ì¤‘ ë ˆì´ë¸” ë¶„ë¥˜ ì†ì‹¤ì„ ë„ì…í•©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ, ì„¤ê³„ëœ í† í°ì— í•´ë‹¹í•˜ëŠ” MLLMì˜ ìˆ¨ê²¨ì§„ ì„ë² ë”©ì„ ì‹œê°ì  íŠ¹ì§•ê³¼ í†µí•©í•˜ëŠ” ë©€í‹°ëª¨ë‹¬ ì´ì¤‘ ì •ë ¬ ìœµí•©(MDAF) ëª¨ë“ˆì„ ì„¤ê³„í•˜ì—¬ GADì˜ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì •ëŸ‰ì  ë° ì •ì„±ì  ì‹¤í—˜ ëª¨ë‘ ìš°ë¦¬ì˜ ì œì•ˆëœ ë°©ë²•ì´ GAD ì‘ì—…ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì„ì„ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì—ì„œëŠ” ë¹„ë””ì˜¤ ì‹œí€€ìŠ¤ì—ì„œ ê·¸ë£¹ í™œë™ì„ ê°ì§€í•˜ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ì¸ LIR-GADë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë”¥ëŸ¬ë‹ ê¸°ë°˜ ë°©ë²•ë“¤ì´ ì‹œê°ì  íŠ¹ì§•ì— ì˜ì¡´í•˜ëŠ” ë°˜ë©´, LIR-GADëŠ” ë‹¤ì¤‘ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(MLLM)ì„ í™œìš©í•˜ì—¬ ì–¸ì–´ ì§€ì‹œë¥¼ í†µí•œ ì¶”ë¡ ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. MLLMì˜ ì›ë˜ ì–´íœ˜ë¥¼ í™•ì¥í•˜ì—¬ í™œë™ ìˆ˜ì¤€ì˜ í† í°ê³¼ ì—¬ëŸ¬ í´ëŸ¬ìŠ¤í„° íŠ¹ì • í† í°ì„ ë„ì…í•˜ê³ , ë¹„ë””ì˜¤ í”„ë ˆì„ê³¼ í•¨ê»˜ ì´ í† í°ë“¤ì„ ì²˜ë¦¬í•˜ì—¬ ì§‘ë‹¨ í™œë™ì˜ ì˜ë¯¸ ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í¬ì°©í•©ë‹ˆë‹¤. ë˜í•œ, ë‹¤ì¤‘ ë ˆì´ë¸” ë¶„ë¥˜ ì†ì‹¤ì„ ë„ì…í•˜ì—¬ í† í°ì˜ íŒë³„ì  ì˜ë¯¸ í‘œí˜„ í•™ìŠµ ëŠ¥ë ¥ì„ ê°•í™”í•©ë‹ˆë‹¤. MLLMì˜ ìˆ¨ê²¨ì§„ ì„ë² ë”©ê³¼ ì‹œê°ì  íŠ¹ì§•ì„ í†µí•©í•˜ëŠ” ë‹¤ì¤‘ëª¨ë‹¬ ì´ì¤‘ ì •ë ¬ ìœµí•©(MDAF) ëª¨ë“ˆì„ ì„¤ê³„í•˜ì—¬ GADì˜ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì´ ê·¸ë£¹ í™œë™ ê°ì§€ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì„ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. LIR-GADëŠ” ë¹„ë””ì˜¤ ì‹œí€€ìŠ¤ ë‚´ì—ì„œ ê·¸ë£¹ í™œë™ì„ ê°ì§€í•˜ê¸° ìœ„í•´ ë‹¤ì¤‘ ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(MLLM)ì„ í™œìš©í•œ ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.
- 2. MLLMì˜ ì›ë˜ ì–´íœ˜ë¥¼ í™•ì¥í•˜ì—¬ í™œë™ ìˆ˜ì¤€ í† í°ê³¼ ì—¬ëŸ¬ í´ëŸ¬ìŠ¤í„°ë³„ í† í°ì„ ë„ì…í•˜ì—¬ ì§‘ë‹¨ í™œë™ì˜ ì˜ë¯¸ ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í¬ì°©í•©ë‹ˆë‹¤.
- 3. ë‹¤ì¤‘ ë ˆì´ë¸” ë¶„ë¥˜ ì†ì‹¤ì„ ë„ì…í•˜ì—¬ í† í°ì˜ ì°¨ë³„ì  ì˜ë¯¸ í‘œí˜„ í•™ìŠµ ëŠ¥ë ¥ì„ ê°•í™”í•©ë‹ˆë‹¤.
- 4. MDAF ëª¨ë“ˆì€ ì„¤ê³„ëœ í† í°ê³¼ ì‹œê°ì  íŠ¹ì§•ì„ í†µí•©í•˜ì—¬ GADì˜ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
- 5. ì •ëŸ‰ì  ë° ì •ì„±ì  ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì´ GAD ì‘ì—…ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì„ì„ ì…ì¦í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-23 12:19:10*