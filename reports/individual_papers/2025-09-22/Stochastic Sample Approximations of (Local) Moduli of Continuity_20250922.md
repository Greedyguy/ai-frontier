---
keywords:
  - Moduli of Local Continuity
  - Neural Network
  - Stochastic Sample Approximation
category: cs.LG
publish_date: 2025-09-22
arxiv_id: 2509.15368
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T10:21:59.535276",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Moduli of Local Continuity",
    "Neural Network",
    "Stochastic Sample Approximation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Moduli of Local Continuity": 0.78,
    "Neural Network": 0.85,
    "Stochastic Sample Approximation": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "moduli of local continuity",
        "canonical": "Moduli of Local Continuity",
        "aliases": [
          "local continuity modulus",
          "local moduli"
        ],
        "category": "unique_technical",
        "rationale": "This concept is central to the paper and offers a unique perspective on evaluating neural network robustness.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "neural networks",
        "canonical": "Neural Network",
        "aliases": [
          "neural nets",
          "NN"
        ],
        "category": "broad_technical",
        "rationale": "Neural networks are a foundational element in the study, providing a strong link to existing literature.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "stochastic sample approximation",
        "canonical": "Stochastic Sample Approximation",
        "aliases": [
          "stochastic approximation",
          "sample approximation"
        ],
        "category": "unique_technical",
        "rationale": "This method is a novel approach within the paper, relevant for linking to stochastic processes in machine learning.",
        "novelty_score": 0.68,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "robustness",
      "fairness",
      "repeated uses"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "moduli of local continuity",
      "resolved_canonical": "Moduli of Local Continuity",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "neural networks",
      "resolved_canonical": "Neural Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "stochastic sample approximation",
      "resolved_canonical": "Stochastic Sample Approximation",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# Stochastic Sample Approximations of (Local) Moduli of Continuity

**Korean Title:** ì—°ì†ì„±ì˜ (êµ­ì†Œ) ëª¨ë“ˆë¼ì´ì˜ í™•ë¥ ì  ìƒ˜í”Œ ê·¼ì‚¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15368.pdf)
**Category**: cs.LG
**Published**: 2025-09-22
**ArXiv ID**: [2509.15368](https://arxiv.org/abs/2509.15368)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Geometric Integration for Neural Control Variates_20250922|Geometric Integration for Neural Control Variates]] (79.2% similar)
- [[2025-09-22/Flavors of Margin_ Implicit Bias of Steepest Descent in Homogeneous Neural Networks_20250922|Flavors of Margin: Implicit Bias of Steepest Descent in Homogeneous Neural Networks]] (79.2% similar)
- [[2025-09-22/Computing Linear Regions in Neural Networks with Skip Connections_20250922|Computing Linear Regions in Neural Networks with Skip Connections]] (78.6% similar)
- [[2025-09-22/Accelerated Gradient Methods with Biased Gradient Estimates_ Risk Sensitivity, High-Probability Guarantees, and Large Deviation Bounds_20250922|Accelerated Gradient Methods with Biased Gradient Estimates: Risk Sensitivity, High-Probability Guarantees, and Large Deviation Bounds]] (78.0% similar)
- [[2025-09-18/Probabilistic and nonlinear compressive sensing_20250918|Probabilistic and nonlinear compressive sensing]] (77.9% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Neural Network|Neural Network]]
**âš¡ Unique Technical**: [[keywords/Moduli of Local Continuity|Moduli of Local Continuity]], [[keywords/Stochastic Sample Approximation|Stochastic Sample Approximation]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15368v1 Announce Type: new 
Abstract: Modulus of local continuity is used to evaluate the robustness of neural networks and fairness of their repeated uses in closed-loop models. Here, we revisit a connection between generalized derivatives and moduli of local continuity, and present a non-uniform stochastic sample approximation for moduli of local continuity. This is of importance in studying robustness of neural networks and fairness of their repeated uses.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15368v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: êµ­ì†Œ ì—°ì†ì„±ì˜ ëª¨ë“ˆëŸ¬ìŠ¤ëŠ” ì‹ ê²½ë§ì˜ ê²¬ê³ ì„±ê³¼ íë£¨í”„ ëª¨ë¸ì—ì„œì˜ ë°˜ë³µ ì‚¬ìš©ì˜ ê³µì •ì„±ì„ í‰ê°€í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. ì—¬ê¸°ì„œ ìš°ë¦¬ëŠ” ì¼ë°˜í™”ëœ ë„í•¨ìˆ˜ì™€ êµ­ì†Œ ì—°ì†ì„±ì˜ ëª¨ë“ˆëŸ¬ìŠ¤ ê°„ì˜ ì—°ê²°ì„ ì¬ê²€í† í•˜ê³ , êµ­ì†Œ ì—°ì†ì„±ì˜ ëª¨ë“ˆëŸ¬ìŠ¤ì— ëŒ€í•œ ë¹„ê· ì¼ í™•ë¥  ìƒ˜í”Œ ê·¼ì‚¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ì´ëŠ” ì‹ ê²½ë§ì˜ ê²¬ê³ ì„±ê³¼ ë°˜ë³µ ì‚¬ìš©ì˜ ê³µì •ì„±ì„ ì—°êµ¬í•˜ëŠ” ë° ì¤‘ìš”í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì‹ ê²½ë§ì˜ ê°•ê±´ì„±ê³¼ ë°˜ë³µ ì‚¬ìš©ì˜ ê³µì •ì„±ì„ í‰ê°€í•˜ê¸° ìœ„í•´ ì§€ì—­ ì—°ì†ì„±ì˜ ëª¨ë“ˆëŸ¬ìŠ¤ë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì¼ë°˜í™”ëœ ë„í•¨ìˆ˜ì™€ ì§€ì—­ ì—°ì†ì„± ëª¨ë“ˆëŸ¬ìŠ¤ ê°„ì˜ ì—°ê²°ì„ ì¬ê²€í† í•˜ê³ , ë¹„ê· ì¼ í™•ë¥ ì  ìƒ˜í”Œ ê·¼ì‚¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ì´ëŠ” ì‹ ê²½ë§ì˜ ê°•ê±´ì„±ê³¼ ê³µì •ì„± ì—°êµ¬ì— ì¤‘ìš”í•œ ê¸°ì—¬ë¥¼ í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì§€ì—­ ì—°ì†ì„±ì˜ ëª¨ë“ˆëŸ¬ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹ ê²½ë§ì˜ ê²¬ê³ ì„±ê³¼ ë°˜ë³µ ì‚¬ìš©ì˜ ê³µì •ì„±ì„ í‰ê°€í•©ë‹ˆë‹¤.
- 2. ì¼ë°˜í™”ëœ ë„í•¨ìˆ˜ì™€ ì§€ì—­ ì—°ì†ì„±ì˜ ëª¨ë“ˆëŸ¬ìŠ¤ ê°„ì˜ ì—°ê²°ì„ ì¬ê²€í† í•©ë‹ˆë‹¤.
- 3. ì§€ì—­ ì—°ì†ì„±ì˜ ëª¨ë“ˆëŸ¬ìŠ¤ì— ëŒ€í•œ ë¹„ê· ì¼ í™•ë¥  ìƒ˜í”Œ ê·¼ì‚¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.
- 4. ì´ëŠ” ì‹ ê²½ë§ì˜ ê²¬ê³ ì„±ê³¼ ë°˜ë³µ ì‚¬ìš©ì˜ ê³µì •ì„±ì„ ì—°êµ¬í•˜ëŠ” ë° ì¤‘ìš”í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-23 10:21:59*