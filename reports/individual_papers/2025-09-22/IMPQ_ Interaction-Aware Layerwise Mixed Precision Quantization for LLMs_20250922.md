---
keywords:
  - Large Language Model
  - Mixed-Precision Quantization
  - Shapley-based Progressive Quantization Estimation
  - Interaction-aware Mixed-Precision Quantization
category: cs.LG
publish_date: 2025-09-22
arxiv_id: 2509.15455
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T10:25:06.297474",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Mixed-Precision Quantization",
    "Shapley-based Progressive Quantization Estimation",
    "Interaction-aware Mixed-Precision Quantization"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Mixed-Precision Quantization": 0.88,
    "Shapley-based Progressive Quantization Estimation": 0.92,
    "Interaction-aware Mixed-Precision Quantization": 0.9
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are central to the paper's focus on quantization techniques.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Mixed-Precision Quantization",
        "canonical": "Mixed-Precision Quantization",
        "aliases": [
          "MPQ"
        ],
        "category": "unique_technical",
        "rationale": "This is a core technique discussed in the paper, crucial for understanding the proposed method.",
        "novelty_score": 0.75,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.88
      },
      {
        "surface": "Shapley-based Progressive Quantization Estimation",
        "canonical": "Shapley-based Progressive Quantization Estimation",
        "aliases": [
          "SPQE"
        ],
        "category": "unique_technical",
        "rationale": "A novel method introduced in the paper, important for linking to quantization strategies.",
        "novelty_score": 0.85,
        "connectivity_score": 0.6,
        "specificity_score": 0.9,
        "link_intent_score": 0.92
      },
      {
        "surface": "Interaction-aware Mixed-Precision Quantization",
        "canonical": "Interaction-aware Mixed-Precision Quantization",
        "aliases": [
          "IMPQ"
        ],
        "category": "unique_technical",
        "rationale": "The main contribution of the paper, essential for understanding the proposed optimization approach.",
        "novelty_score": 0.8,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.9
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "experiment"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Mixed-Precision Quantization",
      "resolved_canonical": "Mixed-Precision Quantization",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "Shapley-based Progressive Quantization Estimation",
      "resolved_canonical": "Shapley-based Progressive Quantization Estimation",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.6,
        "specificity": 0.9,
        "link_intent": 0.92
      }
    },
    {
      "candidate_surface": "Interaction-aware Mixed-Precision Quantization",
      "resolved_canonical": "Interaction-aware Mixed-Precision Quantization",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.9
      }
    }
  ]
}
-->

# IMPQ: Interaction-Aware Layerwise Mixed Precision Quantization for LLMs

**Korean Title:** IMPQ: ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ ìœ„í•œ ìƒí˜¸ì‘ìš© ì¸ì‹ ê³„ì¸µë³„ í˜¼í•© ì •ë°€ë„ ì–‘ìí™”

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15455.pdf)
**Category**: cs.LG
**Published**: 2025-09-22
**ArXiv ID**: [2509.15455](https://arxiv.org/abs/2509.15455)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Calibrating LLM Confidence by Probing Perturbed Representation Stability_20250922|Calibrating LLM Confidence by Probing Perturbed Representation Stability]] (86.3% similar)
- [[2025-09-22/It Depends_ Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge_20250922|It Depends: Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge]] (85.6% similar)
- [[2025-09-22/Exploring Polyglot Harmony_ On Multilingual Data Allocation for Large Language Models Pretraining_20250922|Exploring Polyglot Harmony: On Multilingual Data Allocation for Large Language Models Pretraining]] (83.9% similar)
- [[2025-09-22/IGD_ Token Decisiveness Modeling via Information Gain in LLMs for Personalized Recommendation_20250922|IGD: Token Decisiveness Modeling via Information Gain in LLMs for Personalized Recommendation]] (83.6% similar)
- [[2025-09-22/Benchmarking Debiasing Methods for LLM-based Parameter Estimates_20250922|Benchmarking Debiasing Methods for LLM-based Parameter Estimates]] (83.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**âš¡ Unique Technical**: [[keywords/Mixed-Precision Quantization|Mixed-Precision Quantization]], [[keywords/Shapley-based Progressive Quantization Estimation|Shapley-based Progressive Quantization Estimation]], [[keywords/Interaction-aware Mixed-Precision Quantization|Interaction-aware Mixed-Precision Quantization]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15455v1 Announce Type: new 
Abstract: Large Language Models (LLMs) promise impressive capabilities, yet their multi-billion-parameter scale makes on-device or low-resource deployment prohibitive. Mixed-precision quantization offers a compelling solution, but existing methods struggle when the average precision drops below four bits, as they rely on isolated, layer-specific metrics that overlook critical inter-layer interactions affecting overall performance. In this paper, we propose two innovations to address these limitations. First, we frame the mixed-precision quantization problem as a cooperative game among layers and introduce Shapley-based Progressive Quantization Estimation (SPQE) to efficiently obtain accurate Shapley estimates of layer sensitivities and inter-layer interactions. Second, building upon SPQE, we propose Interaction-aware Mixed-Precision Quantization (IMPQ) which translates these Shapley estimates into a binary quadratic optimization formulation, assigning either 2 or 4-bit precision to layers under strict memory constraints. Comprehensive experiments conducted on Llama-3, Gemma-2, and Qwen-3 models across three independent PTQ backends (Quanto, HQQ, GPTQ) demonstrate IMPQ's scalability and consistently superior performance compared to methods relying solely on isolated metrics. Across average precisions spanning 4 bit down to 2 bit, IMPQ cuts Perplexity by 20 to 80 percent relative to the best baseline, with the margin growing as the bit-width tightens.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15455v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì€ ì¸ìƒì ì¸ ëŠ¥ë ¥ì„ ì•½ì†í•˜ì§€ë§Œ, ìˆ˜ì‹­ì–µ ê°œì˜ ë§¤ê°œë³€ìˆ˜ ê·œëª¨ë¡œ ì¸í•´ ì¥ì¹˜ ë‚´ ë˜ëŠ” ì €ìì› í™˜ê²½ì—ì„œì˜ ë°°í¬ê°€ ì–´ë µìŠµë‹ˆë‹¤. í˜¼í•© ì •ë°€ë„ ì–‘ìí™”ëŠ” ë§¤ë ¥ì ì¸ í•´ê²°ì±…ì„ ì œê³µí•˜ì§€ë§Œ, ê¸°ì¡´ ë°©ë²•ì€ í‰ê·  ì •ë°€ë„ê°€ 4ë¹„íŠ¸ ì´í•˜ë¡œ ë–¨ì–´ì§ˆ ë•Œ ì–´ë ¤ì›€ì„ ê²ªìŠµë‹ˆë‹¤. ì´ëŠ” ê°œë³„ì ì´ê³  ê³„ì¸µë³„ ë©”íŠ¸ë¦­ì— ì˜ì¡´í•˜ì—¬ ì „ì²´ ì„±ëŠ¥ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ì¤‘ìš”í•œ ê³„ì¸µ ê°„ ìƒí˜¸ì‘ìš©ì„ ê°„ê³¼í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì´ëŸ¬í•œ ì œí•œì„ í•´ê²°í•˜ê¸° ìœ„í•œ ë‘ ê°€ì§€ í˜ì‹ ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì²«ì§¸, í˜¼í•© ì •ë°€ë„ ì–‘ìí™” ë¬¸ì œë¥¼ ê³„ì¸µ ê°„ì˜ í˜‘ë ¥ ê²Œì„ìœ¼ë¡œ í”„ë ˆì„í™”í•˜ê³ , ê³„ì¸µ ë¯¼ê°ë„ì™€ ê³„ì¸µ ê°„ ìƒí˜¸ì‘ìš©ì— ëŒ€í•œ ì •í™•í•œ ìƒ¤í”Œë¦¬ ì¶”ì •ì¹˜ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì–»ê¸° ìœ„í•´ ìƒ¤í”Œë¦¬ ê¸°ë°˜ ì ì§„ì  ì–‘ìí™” ì¶”ì •(SPQE)ì„ ë„ì…í•©ë‹ˆë‹¤. ë‘˜ì§¸, SPQEë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ì—¬, ì´ëŸ¬í•œ ìƒ¤í”Œë¦¬ ì¶”ì •ì¹˜ë¥¼ ì´ì§„ ì´ì°¨ ìµœì í™” ê³µì‹ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì—„ê²©í•œ ë©”ëª¨ë¦¬ ì œì•½ í•˜ì— ê³„ì¸µì— 2ë¹„íŠ¸ ë˜ëŠ” 4ë¹„íŠ¸ ì •ë°€ë„ë¥¼ í• ë‹¹í•˜ëŠ” ìƒí˜¸ì‘ìš© ì¸ì‹ í˜¼í•© ì •ë°€ë„ ì–‘ìí™”(IMPQ)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. Llama-3, Gemma-2, Qwen-3 ëª¨ë¸ì—ì„œ ì„¸ ê°€ì§€ ë…ë¦½ì ì¸ PTQ ë°±ì—”ë“œ(Quanto, HQQ, GPTQ)ë¥¼ í†µí•´ ìˆ˜í–‰ëœ í¬ê´„ì ì¸ ì‹¤í—˜ì€ IMPQì˜ í™•ì¥ì„±ê³¼ ê³ ë¦½ëœ ë©”íŠ¸ë¦­ì—ë§Œ ì˜ì¡´í•˜ëŠ” ë°©ë²•ì— ë¹„í•´ ì¼ê´€ë˜ê²Œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. í‰ê·  ì •ë°€ë„ê°€ 4ë¹„íŠ¸ì—ì„œ 2ë¹„íŠ¸ë¡œ ê°ì†Œí•˜ëŠ” ë™ì•ˆ, IMPQëŠ” ìµœìƒì˜ ê¸°ì¤€ì„ ì— ë¹„í•´ ë‹¹í˜¹ë„ë¥¼ 20%ì—ì„œ 80%ê¹Œì§€ ì¤„ì´ë©°, ë¹„íŠ¸ í­ì´ ì¢ì•„ì§ˆìˆ˜ë¡ ê·¸ ì°¨ì´ëŠ” ë”ìš± ì»¤ì§‘ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ íš¨ìœ¨ì ì¸ ë°°í¬ë¥¼ ìœ„í•´ í˜¼í•© ì •ë°€ë„ ì–‘ìí™”ê°€ ìœ ë§í•˜ì§€ë§Œ, ê¸°ì¡´ ë°©ë²•ì€ í‰ê·  ì •ë°€ë„ê°€ 4ë¹„íŠ¸ ì´í•˜ë¡œ ë–¨ì–´ì§ˆ ë•Œ ì„±ëŠ¥ ì €í•˜ë¥¼ ê²ªìŠµë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì´ëŸ¬í•œ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ë‘ ê°€ì§€ í˜ì‹ ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì²«ì§¸, í˜¼í•© ì •ë°€ë„ ì–‘ìí™” ë¬¸ì œë¥¼ ê³„ì¸µ ê°„ í˜‘ë ¥ ê²Œì„ìœ¼ë¡œ ë³´ê³ , Shapley ê¸°ë°˜ì˜ ì ì§„ì  ì–‘ìí™” ì¶”ì •(SPQE)ì„ ë„ì…í•˜ì—¬ ê³„ì¸µ ë¯¼ê°ë„ì™€ ìƒí˜¸ì‘ìš©ì„ ì •í™•íˆ ì¶”ì •í•©ë‹ˆë‹¤. ë‘˜ì§¸, SPQEë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒí˜¸ì‘ìš© ì¸ì‹ í˜¼í•© ì •ë°€ë„ ì–‘ìí™”(IMPQ)ë¥¼ ì œì•ˆí•˜ì—¬, ì´ë¥¼ ì´ì§„ ì´ì°¨ ìµœì í™” ë¬¸ì œë¡œ ë³€í™˜í•˜ì—¬ ë©”ëª¨ë¦¬ ì œì•½ í•˜ì— 2ë¹„íŠ¸ ë˜ëŠ” 4ë¹„íŠ¸ ì •ë°€ë„ë¥¼ í• ë‹¹í•©ë‹ˆë‹¤. Llama-3, Gemma-2, Qwen-3 ëª¨ë¸ì— ëŒ€í•œ ì‹¤í—˜ ê²°ê³¼, IMPQëŠ” ê¸°ì¡´ ë°©ë²•ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì´ë©°, í‰ê·  ì •ë°€ë„ê°€ 4ë¹„íŠ¸ì—ì„œ 2ë¹„íŠ¸ë¡œ ì¤„ì–´ë“¤ìˆ˜ë¡ Perplexityë¥¼ 20%ì—ì„œ 80%ê¹Œì§€ ê°ì†Œì‹œì¼°ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ê¸°ê¸° ë‚´ ë˜ëŠ” ì €ìì› í™˜ê²½ ë°°í¬ë¥¼ ìœ„í•´ í˜¼í•© ì •ë°€ë„ ì–‘ìí™”ê°€ ì¤‘ìš”í•œ í•´ê²°ì±…ìœ¼ë¡œ ì œì‹œë©ë‹ˆë‹¤.
- 2. ê¸°ì¡´ ë°©ë²•ë“¤ì´ í‰ê·  ì •ë°€ë„ê°€ 4ë¹„íŠ¸ ì´í•˜ë¡œ ë–¨ì–´ì§ˆ ë•Œ ì„±ëŠ¥ ì €í•˜ë¥¼ ê²ªëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ë³¸ ë…¼ë¬¸ì€ Shapley ê¸°ë°˜ì˜ ì ì§„ì  ì–‘ìí™” ì¶”ì •(SPQE)ì„ ë„ì…í•˜ì—¬ ë ˆì´ì–´ ë¯¼ê°ë„ì™€ ìƒí˜¸ì‘ìš©ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì¶”ì •í•©ë‹ˆë‹¤.
- 3. SPQEë¥¼ ê¸°ë°˜ìœ¼ë¡œ, ìƒí˜¸ì‘ìš©ì„ ê³ ë ¤í•œ í˜¼í•© ì •ë°€ë„ ì–‘ìí™”(IMPQ)ë¥¼ ì œì•ˆí•˜ì—¬, 2ë¹„íŠ¸ ë˜ëŠ” 4ë¹„íŠ¸ ì •ë°€ë„ë¥¼ ë ˆì´ì–´ì— í• ë‹¹í•˜ëŠ” ì´ì§„ ì´ì°¨ ìµœì í™” ë¬¸ì œë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
- 4. ë‹¤ì–‘í•œ ëª¨ë¸ê³¼ PTQ ë°±ì—”ë“œì—ì„œì˜ ì‹¤í—˜ ê²°ê³¼, IMPQëŠ” ê¸°ì¡´ì˜ ê³ ë¦½ëœ ë©”íŠ¸ë¦­ì— ì˜ì¡´í•˜ëŠ” ë°©ë²•ë“¤ë³´ë‹¤ ì¼ê´€ë˜ê²Œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì´ë©°, ë¹„íŠ¸ í­ì´ ì¤„ì–´ë“¤ìˆ˜ë¡ Perplexityë¥¼ 20%ì—ì„œ 80%ê¹Œì§€ ê°ì†Œì‹œí‚µë‹ˆë‹¤.


---

*Generated on 2025-09-23 10:25:06*