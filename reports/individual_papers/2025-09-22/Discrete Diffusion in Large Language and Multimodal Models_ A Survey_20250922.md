---
keywords:
  - Discrete Diffusion Language Models
  - Discrete Diffusion Multimodal Language Models
  - Parallel Decoding
  - Vision-Language Model
  - Denoising-based Generation
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2506.13759
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T10:04:21.259182",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Discrete Diffusion Language Models",
    "Discrete Diffusion Multimodal Language Models",
    "Parallel Decoding",
    "Vision-Language Model",
    "Denoising-based Generation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Discrete Diffusion Language Models": 0.78,
    "Discrete Diffusion Multimodal Language Models": 0.8,
    "Parallel Decoding": 0.77,
    "Vision-Language Model": 0.79,
    "Denoising-based Generation": 0.76
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Discrete Diffusion Language Models",
        "canonical": "Discrete Diffusion Language Models",
        "aliases": [
          "dLLMs"
        ],
        "category": "unique_technical",
        "rationale": "Represents a novel paradigm in language model design distinct from autoregressive models.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Discrete Diffusion Multimodal Language Models",
        "canonical": "Discrete Diffusion Multimodal Language Models",
        "aliases": [
          "dMLLMs"
        ],
        "category": "unique_technical",
        "rationale": "Highlights a specific application of discrete diffusion in multimodal contexts, offering new research directions.",
        "novelty_score": 0.78,
        "connectivity_score": 0.68,
        "specificity_score": 0.82,
        "link_intent_score": 0.8
      },
      {
        "surface": "Parallel Decoding",
        "canonical": "Parallel Decoding",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Key technique enabling faster inference in discrete diffusion models.",
        "novelty_score": 0.6,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.77
      },
      {
        "surface": "Vision-Language",
        "canonical": "Vision-Language Model",
        "aliases": [],
        "category": "evolved_concepts",
        "rationale": "Represents a significant application area for multimodal models, linking language and vision.",
        "novelty_score": 0.55,
        "connectivity_score": 0.8,
        "specificity_score": 0.78,
        "link_intent_score": 0.79
      },
      {
        "surface": "Denoising-based Generation",
        "canonical": "Denoising-based Generation",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Central to the generation strategy of discrete diffusion models, differentiating them from traditional methods.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.75,
        "link_intent_score": 0.76
      }
    ],
    "ban_list_suggestions": [
      "autoregressive",
      "inference speed"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Discrete Diffusion Language Models",
      "resolved_canonical": "Discrete Diffusion Language Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Discrete Diffusion Multimodal Language Models",
      "resolved_canonical": "Discrete Diffusion Multimodal Language Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.78,
        "connectivity": 0.68,
        "specificity": 0.82,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Parallel Decoding",
      "resolved_canonical": "Parallel Decoding",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Vision-Language",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.8,
        "specificity": 0.78,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Denoising-based Generation",
      "resolved_canonical": "Denoising-based Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.75,
        "link_intent": 0.76
      }
    }
  ]
}
-->

# Discrete Diffusion in Large Language and Multimodal Models: A Survey

**Korean Title:** ëŒ€í˜• ì–¸ì–´ ë° ë‹¤ì¤‘ ëª¨ë‹¬ ëª¨ë¸ì—ì„œì˜ ì´ì‚° í™•ì‚°: ì¡°ì‚¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2506.13759.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2506.13759](https://arxiv.org/abs/2506.13759)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Modular Machine Learning_ An Indispensable Path towards New-Generation Large Language Models_20250919|Modular Machine Learning: An Indispensable Path towards New-Generation Large Language Models]] (86.3% similar)
- [[2025-09-18/From Automation to Autonomy_ A Survey on Large Language Models in Scientific Discovery_20250918|From Automation to Autonomy: A Survey on Large Language Models in Scientific Discovery]] (85.7% similar)
- [[2025-09-19/Decoupled Proxy Alignment_ Mitigating Language Prior Conflict for Multimodal Alignment in MLLM_20250919|Decoupled Proxy Alignment: Mitigating Language Prior Conflict for Multimodal Alignment in MLLM]] (85.5% similar)
- [[2025-09-19/DetectAnyLLM_ Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models_20250919|DetectAnyLLM: Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models]] (85.5% similar)
- [[2025-09-18/Fast and Fluent Diffusion Language Models via Convolutional Decoding and Rejective Fine-tuning_20250918|Fast and Fluent Diffusion Language Models via Convolutional Decoding and Rejective Fine-tuning]] (84.7% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Parallel Decoding|Parallel Decoding]], [[keywords/Denoising-based Generation|Denoising-based Generation]]
**âš¡ Unique Technical**: [[keywords/Discrete Diffusion Language Models|Discrete Diffusion Language Models]], [[keywords/Discrete Diffusion Multimodal Language Models|Discrete Diffusion Multimodal Language Models]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2506.13759v5 Announce Type: replace-cross 
Abstract: In this work, we provide a systematic survey of Discrete Diffusion Language Models (dLLMs) and Discrete Diffusion Multimodal Language Models (dMLLMs). Unlike autoregressive (AR) models, dLLMs and dMLLMs adopt a multi-token, parallel decoding paradigm using full attention and a denoising-based generation strategy. This paradigm naturally enables parallel generation, fine-grained output control, and dynamic perception. These capabilities are previously difficult to achieve with AR models. A growing number of industrial-scale proprietary d(M)LLMs, as well as a large number of open-source academic d(M)LLMs, have demonstrated performance comparable to their autoregressive counterparts, while achieving up to 10$\times$ acceleration in inference speed. These developments position discrete diffusion models as a promising alternative to intelligence based on the traditional autoregressive approach. In this work, we present a comprehensive overview of the research in the dLLM and dMLLM domains. We trace the historical development of dLLMs and dMLLMs, formalize the underlying mathematical frameworks, list commonly-used modeling methods, and categorize representative models. We further analyze key techniques for training, inference, quantization. We also discuss the trustworthy issues and summarize emerging applications across language, vision-language, and biological domains and etc.. We conclude by discussing future directions for research and deployment. Relative papers are collected in https://github.com/LiQiiiii/Awesome-Discrete-Diffusion-LLM_MLLM

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2506.13759v5 ë°œí‘œ ìœ í˜•: êµì°¨ êµì²´  
ì´ˆë¡: ë³¸ ì—°êµ¬ì—ì„œëŠ” ì´ì‚° í™•ì‚° ì–¸ì–´ ëª¨ë¸(dLLM)ê³¼ ì´ì‚° í™•ì‚° ë‹¤ì¤‘ëª¨ë‹¬ ì–¸ì–´ ëª¨ë¸(dMLLM)ì— ëŒ€í•œ ì²´ê³„ì ì¸ ì¡°ì‚¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ìê¸°íšŒê·€(AR) ëª¨ë¸ê³¼ ë‹¬ë¦¬, dLLMê³¼ dMLLMì€ ì „ì²´ ì£¼ì˜(attention)ì™€ ì¡ìŒ ì œê±° ê¸°ë°˜ ìƒì„± ì „ëµì„ ì‚¬ìš©í•˜ëŠ” ë‹¤ì¤‘ í† í°, ë³‘ë ¬ ë””ì½”ë”© íŒ¨ëŸ¬ë‹¤ì„ì„ ì±„íƒí•©ë‹ˆë‹¤. ì´ íŒ¨ëŸ¬ë‹¤ì„ì€ ìì—°ìŠ¤ëŸ½ê²Œ ë³‘ë ¬ ìƒì„±, ì„¸ë°€í•œ ì¶œë ¥ ì œì–´ ë° ë™ì  ì¸ì‹ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ê¸°ëŠ¥ì€ AR ëª¨ë¸ë¡œëŠ” ì´ì „ì— ë‹¬ì„±í•˜ê¸° ì–´ë ¤ì› ìŠµë‹ˆë‹¤. ì‚°ì—… ê·œëª¨ì˜ ë…ì  d(M)LLMë¿ë§Œ ì•„ë‹ˆë¼ ë‹¤ìˆ˜ì˜ ì˜¤í”ˆ ì†ŒìŠ¤ í•™ìˆ  d(M)LLMì´ ìê¸°íšŒê·€ ëª¨ë¸ê³¼ ë¹„êµí•  ë§Œí•œ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì—ˆìœ¼ë©°, ì¶”ë¡  ì†ë„ì—ì„œ ìµœëŒ€ 10ë°°ì˜ ê°€ì†ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë°œì „ì€ ì „í†µì ì¸ ìê¸°íšŒê·€ ì ‘ê·¼ ë°©ì‹ì— ê¸°ë°˜í•œ ì¸ê³µì§€ëŠ¥ì— ëŒ€í•œ ìœ ë§í•œ ëŒ€ì•ˆìœ¼ë¡œ ì´ì‚° í™•ì‚° ëª¨ë¸ì„ ìë¦¬ë§¤ê¹€í•˜ê²Œ í•©ë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” dLLMê³¼ dMLLM ë¶„ì•¼ì˜ ì—°êµ¬ì— ëŒ€í•œ í¬ê´„ì ì¸ ê°œìš”ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. dLLMê³¼ dMLLMì˜ ì—­ì‚¬ì  ë°œì „ì„ ì¶”ì í•˜ê³ , ê¸°ë³¸ ìˆ˜í•™ì  í”„ë ˆì„ì›Œí¬ë¥¼ ê³µì‹í™”í•˜ë©°, ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ëª¨ë¸ë§ ë°©ë²•ì„ ë‚˜ì—´í•˜ê³ , ëŒ€í‘œ ëª¨ë¸ì„ ë¶„ë¥˜í•©ë‹ˆë‹¤. ë˜í•œ, í›ˆë ¨, ì¶”ë¡ , ì–‘ìí™”ì— ëŒ€í•œ ì£¼ìš” ê¸°ìˆ ì„ ë¶„ì„í•©ë‹ˆë‹¤. ì‹ ë¢°ì„± ë¬¸ì œë¥¼ ë…¼ì˜í•˜ê³ , ì–¸ì–´, ë¹„ì „-ì–¸ì–´, ìƒë¬¼í•™ì  ë¶„ì•¼ ë“±ì—ì„œì˜ ìƒˆë¡œìš´ ì‘ìš©ì„ ìš”ì•½í•©ë‹ˆë‹¤. ì—°êµ¬ ë° ë°°í¬ì˜ ë¯¸ë˜ ë°©í–¥ì— ëŒ€í•´ ë…¼ì˜í•˜ë©° ê²°ë¡ ì„ ë‚´ë¦½ë‹ˆë‹¤. ê´€ë ¨ ë…¼ë¬¸ì€ https://github.com/LiQiiiii/Awesome-Discrete-Diffusion-LLM_MLLMì— ìˆ˜ì§‘ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì´ì‚° í™•ì‚° ì–¸ì–´ ëª¨ë¸(dLLM)ê³¼ ì´ì‚° í™•ì‚° ë‹¤ì¤‘ëª¨ë‹¬ ì–¸ì–´ ëª¨ë¸(dMLLM)ì— ëŒ€í•œ ì²´ê³„ì ì¸ ì¡°ì‚¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ìê¸°íšŒê·€ ëª¨ë¸ê³¼ ë‹¬ë¦¬, dLLMê³¼ dMLLMì€ ë©€í‹° í† í°, ë³‘ë ¬ ë””ì½”ë”© íŒ¨ëŸ¬ë‹¤ì„ì„ ì±„íƒí•˜ì—¬ ë³‘ë ¬ ìƒì„±, ì„¸ë°€í•œ ì¶œë ¥ ì œì–´, ë™ì  ì¸ì‹ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ëª¨ë¸ë“¤ì€ ìê¸°íšŒê·€ ëª¨ë¸ì— ë¹„í•´ ìµœëŒ€ 10ë°° ë¹ ë¥¸ ì¶”ë¡  ì†ë„ë¥¼ ë³´ì´ë©°, ì‚°ì—… ê·œëª¨ì˜ ë…ì  ëª¨ë¸ê³¼ ì˜¤í”ˆ ì†ŒìŠ¤ í•™ìˆ  ëª¨ë¸ ëª¨ë‘ì—ì„œ ìœ ì‚¬í•œ ì„±ëŠ¥ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤. ë…¼ë¬¸ì€ dLLMê³¼ dMLLMì˜ ì—­ì‚¬ì  ë°œì „, ìˆ˜í•™ì  í”„ë ˆì„ì›Œí¬, ì¼ë°˜ì ì¸ ëª¨ë¸ë§ ë°©ë²•, ëŒ€í‘œ ëª¨ë¸ì„ ë¶„ë¥˜í•˜ê³ , í›ˆë ¨, ì¶”ë¡ , ì–‘ìí™”ì˜ ì£¼ìš” ê¸°ìˆ ì„ ë¶„ì„í•©ë‹ˆë‹¤. ë˜í•œ ì‹ ë¢°ì„± ë¬¸ì œì™€ ì–¸ì–´, ë¹„ì „-ì–¸ì–´, ìƒë¬¼í•™ì  ë¶„ì•¼ì˜ ì‘ìš©ì„ ë…¼ì˜í•˜ë©°, í–¥í›„ ì—°êµ¬ ë°©í–¥ì„ ì œì‹œí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë³¸ ë…¼ë¬¸ì€ Discrete Diffusion Language Models (dLLMs)ì™€ Discrete Diffusion Multimodal Language Models (dMLLMs)ì— ëŒ€í•œ ì²´ê³„ì ì¸ ì¡°ì‚¬ë¥¼ ì œê³µí•œë‹¤.
- 2. dLLMsì™€ dMLLMsëŠ” ë‹¤ì¤‘ í† í°, ë³‘ë ¬ ë””ì½”ë”© íŒ¨ëŸ¬ë‹¤ì„ì„ ì±„íƒí•˜ì—¬ ë³‘ë ¬ ìƒì„±, ì„¸ë°€í•œ ì¶œë ¥ ì œì–´, ë™ì  ì¸ì‹ì„ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤.
- 3. d(M)LLMsëŠ” ê¸°ì¡´ì˜ autoregressive ëª¨ë¸ê³¼ ë¹„êµí•˜ì—¬ ìµœëŒ€ 10ë°°ì˜ ì¶”ë¡  ì†ë„ ê°€ì†ì„ ë‹¬ì„±í•˜ë©´ì„œ ì„±ëŠ¥ì„ ì…ì¦í•˜ì˜€ë‹¤.
- 4. ë…¼ë¬¸ì€ dLLMê³¼ dMLLMì˜ ì—­ì‚¬ì  ë°œì „, ìˆ˜í•™ì  í”„ë ˆì„ì›Œí¬, ì¼ë°˜ì ì¸ ëª¨ë¸ë§ ë°©ë²•, ëŒ€í‘œ ëª¨ë¸ì„ í¬ê´„ì ìœ¼ë¡œ ê°œê´€í•œë‹¤.
- 5. ì—°êµ¬ëŠ” ì–¸ì–´, ë¹„ì „-ì–¸ì–´, ìƒë¬¼í•™ì  ë¶„ì•¼ ë“±ì—ì„œì˜ ìƒˆë¡œìš´ ì‘ìš©ì„ ìš”ì•½í•˜ê³ , ì‹ ë¢°ì„± ë¬¸ì œì™€ ë¯¸ë˜ ì—°êµ¬ ë°©í–¥ì„ ë…¼ì˜í•œë‹¤.


---

*Generated on 2025-09-23 10:04:21*