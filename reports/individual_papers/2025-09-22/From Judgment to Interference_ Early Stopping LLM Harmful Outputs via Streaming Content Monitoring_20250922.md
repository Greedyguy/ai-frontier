---
keywords:
  - Large Language Model
  - Streaming Content Monitor
  - FineHarm Dataset
  - Safety Alignment
  - Partial Detection
category: cs.CL
publish_date: 2025-09-22
arxiv_id: 2506.09996
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:48:30.898081",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Streaming Content Monitor",
    "FineHarm Dataset",
    "Safety Alignment",
    "Partial Detection"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Streaming Content Monitor": 0.8,
    "FineHarm Dataset": 0.78,
    "Safety Alignment": 0.82,
    "Partial Detection": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Language Model"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's focus on safety alignment and moderation techniques.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Streaming Content Monitor",
        "canonical": "Streaming Content Monitor",
        "aliases": [
          "SCM"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel approach for early stopping harmful outputs in LLMs.",
        "novelty_score": 0.75,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "FineHarm",
        "canonical": "FineHarm Dataset",
        "aliases": [
          "FineHarm"
        ],
        "category": "unique_technical",
        "rationale": "A new dataset crucial for training models in partial detection of harmful content.",
        "novelty_score": 0.8,
        "connectivity_score": 0.65,
        "specificity_score": 0.88,
        "link_intent_score": 0.78
      },
      {
        "surface": "Safety Alignment",
        "canonical": "Safety Alignment",
        "aliases": [
          "Alignment"
        ],
        "category": "specific_connectable",
        "rationale": "Key concept in ensuring LLMs produce non-harmful outputs.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.82
      },
      {
        "surface": "Partial Detection",
        "canonical": "Partial Detection",
        "aliases": [
          "Early Stopping"
        ],
        "category": "specific_connectable",
        "rationale": "Describes the method of detecting harmful content before full output is generated.",
        "novelty_score": 0.65,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "moderation",
      "detection"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Streaming Content Monitor",
      "resolved_canonical": "Streaming Content Monitor",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "FineHarm",
      "resolved_canonical": "FineHarm Dataset",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.65,
        "specificity": 0.88,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Safety Alignment",
      "resolved_canonical": "Safety Alignment",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Partial Detection",
      "resolved_canonical": "Partial Detection",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# From Judgment to Interference: Early Stopping LLM Harmful Outputs via Streaming Content Monitoring

**Korean Title:** íŒë‹¨ì—ì„œ ê°„ì„­ìœ¼ë¡œ: ìŠ¤íŠ¸ë¦¬ë° ì½˜í…ì¸  ëª¨ë‹ˆí„°ë§ì„ í†µí•œ LLM ìœ í•´ ì¶œë ¥ì˜ ì¡°ê¸° ì¤‘ì§€

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2506.09996.pdf)
**Category**: cs.CL
**Published**: 2025-09-22
**ArXiv ID**: [2506.09996](https://arxiv.org/abs/2506.09996)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Red Teaming Multimodal Language Models_ Evaluating Harm Across Prompt Modalities and Models_20250922|Red Teaming Multimodal Language Models: Evaluating Harm Across Prompt Modalities and Models]] (85.7% similar)
- [[2025-09-19/SMARTER_ A Data-efficient Framework to Improve Toxicity Detection with Explanation via Self-augmenting Large Language Models_20250919|SMARTER: A Data-efficient Framework to Improve Toxicity Detection with Explanation via Self-augmenting Large Language Models]] (85.4% similar)
- [[2025-09-22/Toxicity Red-Teaming_ Benchmarking LLM Safety in Singapore's Low-Resource Languages_20250922|Toxicity Red-Teaming: Benchmarking LLM Safety in Singapore's Low-Resource Languages]] (85.1% similar)
- [[2025-09-22/It Depends_ Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge_20250922|It Depends: Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge]] (85.0% similar)
- [[2025-09-22/AdaSteer_ Your Aligned LLM is Inherently an Adaptive Jailbreak Defender_20250922|AdaSteer: Your Aligned LLM is Inherently an Adaptive Jailbreak Defender]] (84.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Safety Alignment|Safety Alignment]], [[keywords/Partial Detection|Partial Detection]]
**âš¡ Unique Technical**: [[keywords/Streaming Content Monitor|Streaming Content Monitor]], [[keywords/FineHarm Dataset|FineHarm Dataset]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2506.09996v2 Announce Type: replace 
Abstract: Though safety alignment has been applied to most large language models (LLMs), LLM service providers generally deploy a subsequent moderation as the external safety guardrail in real-world products. Existing moderators mainly practice a conventional full detection, which determines the harmfulness based on the complete LLM output, causing high service latency. Recent works pay more attention to partial detection where moderators oversee the generation midway and early stop the output if harmfulness is detected, but they directly apply moderators trained with the full detection paradigm to incomplete outputs, introducing a training-inference gap that lowers the performance. In this paper, we explore how to form a data-and-model solution that natively supports partial detection. For the data, we construct FineHarm, a dataset consisting of 29K prompt-response pairs with fine-grained annotations to provide reasonable supervision for token-level training. Then, we propose the streaming content monitor, which is trained with dual supervision of response- and token-level labels and can follow the output stream of LLM to make a timely judgment of harmfulness. Experiments show that SCM gains 0.95+ in macro F1 score that is comparable to full detection, by only seeing the first 18% of tokens in responses on average. Moreover, the SCM can serve as a pseudo-harmfulness annotator for improving safety alignment and lead to a higher harmlessness score than DPO.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2506.09996v2 ë°œí‘œ ìœ í˜•: êµì²´  
ì´ˆë¡: ì•ˆì „ ì •ë ¬ì€ ëŒ€ë¶€ë¶„ì˜ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì— ì ìš©ë˜ì—ˆì§€ë§Œ, LLM ì„œë¹„ìŠ¤ ì œê³µìëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì‹¤ì œ ì œí’ˆì—ì„œ ì™¸ë¶€ ì•ˆì „ ê°€ë“œë ˆì¼ë¡œì„œ í›„ì† ì¡°ì •(moderation)ì„ ë°°ì¹˜í•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ì¡°ì •ìëŠ” ì£¼ë¡œ LLM ì¶œë ¥ ì „ì²´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìœ í•´ì„±ì„ íŒë‹¨í•˜ëŠ” ì „í†µì ì¸ ì „ì²´ íƒì§€ë¥¼ ìˆ˜í–‰í•˜ì—¬ ë†’ì€ ì„œë¹„ìŠ¤ ì§€ì—°ì„ ì´ˆë˜í•©ë‹ˆë‹¤. ìµœê·¼ ì—°êµ¬ë“¤ì€ ì¡°ì •ìê°€ ìƒì„± ì¤‘ê°„ì„ ê°ë…í•˜ê³  ìœ í•´ì„±ì´ ê°ì§€ë˜ë©´ ì¶œë ¥ì„ ì¡°ê¸°ì— ì¤‘ë‹¨í•˜ëŠ” ë¶€ë¶„ íƒì§€ì— ë” ë§ì€ ì£¼ì˜ë¥¼ ê¸°ìš¸ì´ê³  ìˆì§€ë§Œ, ì „ì²´ íƒì§€ íŒ¨ëŸ¬ë‹¤ì„ìœ¼ë¡œ í›ˆë ¨ëœ ì¡°ì •ìë¥¼ ë¶ˆì™„ì „í•œ ì¶œë ¥ì— ì§ì ‘ ì ìš©í•˜ì—¬ ì„±ëŠ¥ì„ ì €í•˜ì‹œí‚¤ëŠ” í›ˆë ¨-ì¶”ë¡  ê°„ê·¹ì„ ì´ˆë˜í•©ë‹ˆë‹¤. ì´ ë…¼ë¬¸ì—ì„œëŠ” ë¶€ë¶„ íƒì§€ë¥¼ ë³¸ì§ˆì ìœ¼ë¡œ ì§€ì›í•˜ëŠ” ë°ì´í„° ë° ëª¨ë¸ ì†”ë£¨ì…˜ì„ ì–´ë–»ê²Œ í˜•ì„±í•  ìˆ˜ ìˆëŠ”ì§€ íƒêµ¬í•©ë‹ˆë‹¤. ë°ì´í„° ì¸¡ë©´ì—ì„œëŠ”, FineHarmì´ë¼ëŠ” ë°ì´í„°ì…‹ì„ êµ¬ì¶•í•˜ì—¬ 29Kì˜ í”„ë¡¬í”„íŠ¸-ì‘ë‹µ ìŒê³¼ ì„¸ë°€í•œ ì£¼ì„ì„ í¬í•¨í•˜ì—¬ í† í° ìˆ˜ì¤€ í›ˆë ¨ì— í•©ë¦¬ì ì¸ ê°ë…ì„ ì œê³µí•©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ, ì‘ë‹µ ë° í† í° ìˆ˜ì¤€ ë ˆì´ë¸”ì˜ ì´ì¤‘ ê°ë…ìœ¼ë¡œ í›ˆë ¨ëœ ìŠ¤íŠ¸ë¦¬ë° ì½˜í…ì¸  ëª¨ë‹ˆí„°ë¥¼ ì œì•ˆí•˜ë©°, ì´ëŠ” LLMì˜ ì¶œë ¥ ìŠ¤íŠ¸ë¦¼ì„ ë”°ë¼ ìœ í•´ì„±ì— ëŒ€í•œ ì ì‹œ íŒë‹¨ì„ ë‚´ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, SCMì€ í‰ê· ì ìœ¼ë¡œ ì‘ë‹µì˜ ì²« 18%ì˜ í† í°ë§Œ ë³´ê³ ë„ ì „ì²´ íƒì§€ì™€ ë¹„êµí•  ë•Œ ë§¤í¬ë¡œ F1 ì ìˆ˜ì—ì„œ 0.95 ì´ìƒì˜ ì„±ê³¼ë¥¼ ì–»ì—ˆìŠµë‹ˆë‹¤. ë”ìš±ì´, SCMì€ ì•ˆì „ ì •ë ¬ì„ ê°œì„ í•˜ê¸° ìœ„í•œ ì˜ì‚¬ ìœ í•´ì„± ì£¼ì„ìë¡œì„œ ì‘ìš©í•  ìˆ˜ ìˆìœ¼ë©°, DPOë³´ë‹¤ ë†’ì€ ë¬´í•´ì„± ì ìˆ˜ë¥¼ ì´ëŒì–´ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì•ˆì „ì„±ì„ ê°œì„ í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ì ‘ê·¼ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ì•ˆì „ì„± ê²€ì‚¬ëŠ” ì „ì²´ ì¶œë ¥ë¬¼ì„ ê¸°ë°˜ìœ¼ë¡œ ìœ í•´ì„±ì„ íŒë‹¨í•˜ì—¬ ì„œë¹„ìŠ¤ ì§€ì—°ì„ ì´ˆë˜í•˜ëŠ” ë°˜ë©´, ì´ ì—°êµ¬ëŠ” ë¶€ë¶„ ê²€ì¶œì„ í†µí•´ ì¶œë ¥ ë„ì¤‘ ìœ í•´ì„±ì„ ì¡°ê¸°ì— ê°ì§€í•˜ê³  ì¤‘ë‹¨í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì„ íƒêµ¬í•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ 29,000ê°œì˜ í”„ë¡¬í”„íŠ¸-ì‘ë‹µ ìŒìœ¼ë¡œ êµ¬ì„±ëœ FineHarm ë°ì´í„°ì…‹ì„ êµ¬ì¶•í•˜ê³ , ì‘ë‹µ ë° í† í° ìˆ˜ì¤€ì˜ ì´ì¤‘ ê°ë…ì„ ë°›ëŠ” ìŠ¤íŠ¸ë¦¬ë° ì½˜í…ì¸  ëª¨ë‹ˆí„°(SCM)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, SCMì€ í‰ê· ì ìœ¼ë¡œ ì‘ë‹µì˜ ì²« 18%ì˜ í† í°ë§Œ ë³´ê³ ë„ ë†’ì€ ì •í™•ë„ì˜ ìœ í•´ì„± íŒë‹¨ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ë©°, ì•ˆì „ì„± ì •ë ¬ì„ ê°œì„ í•˜ëŠ” ë° ê¸°ì—¬í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€ë¶€ë¶„ì˜ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì—ëŠ” ì•ˆì „ ì •ë ¬ì´ ì ìš©ë˜ì—ˆì§€ë§Œ, ì‹¤ì œ ì œí’ˆì—ì„œëŠ” ì™¸ë¶€ ì•ˆì „ ê°€ë“œë ˆì¼ë¡œì„œ í›„ì† ì¡°ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.
- 2. ê¸°ì¡´ì˜ ì¡°ì •ìëŠ” ì „ì²´ íƒì§€ë¥¼ í†µí•´ ìœ í•´ì„±ì„ íŒë‹¨í•˜ì—¬ ì„œë¹„ìŠ¤ ì§€ì—°ì„ ì´ˆë˜í•©ë‹ˆë‹¤.
- 3. ë¶€ë¶„ íƒì§€ì— ì¤‘ì ì„ ë‘” ìµœê·¼ ì—°êµ¬ì—ì„œëŠ” ìƒì„± ì¤‘ê°„ì„ ê°ë…í•˜ê³  ìœ í•´ì„±ì´ ê°ì§€ë˜ë©´ ì¶œë ¥ì„ ì¡°ê¸° ì¤‘ë‹¨í•©ë‹ˆë‹¤.
- 4. FineHarm ë°ì´í„°ì…‹ì„ êµ¬ì¶•í•˜ì—¬ í† í° ìˆ˜ì¤€ì˜ í›ˆë ¨ì„ ìœ„í•œ ì„¸ë°€í•œ ì£¼ì„ì„ ì œê³µí•©ë‹ˆë‹¤.
- 5. ìŠ¤íŠ¸ë¦¬ë° ì½˜í…ì¸  ëª¨ë‹ˆí„°(SCM)ëŠ” ì‘ë‹µê³¼ í† í° ìˆ˜ì¤€ ë ˆì´ë¸”ì˜ ì´ì¤‘ ê°ë…ìœ¼ë¡œ í›ˆë ¨ë˜ì–´, í‰ê· ì ìœ¼ë¡œ ì‘ë‹µì˜ ì²« 18%ì˜ í† í°ë§Œ ë³´ê³ ë„ ìœ í•´ì„±ì„ íŒë‹¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-23 11:48:30*