---
keywords:
  - Retrieval Augmented Generation
  - Large Language Model
  - Reinforcement Learning
  - Lossless Compression
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2508.19282
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T10:09:02.529687",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Retrieval Augmented Generation",
    "Large Language Model",
    "Reinforcement Learning",
    "Lossless Compression"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Retrieval Augmented Generation": 0.88,
    "Large Language Model": 0.8,
    "Reinforcement Learning": 0.82,
    "Lossless Compression": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Retrieval-Augmented Generation",
        "canonical": "Retrieval Augmented Generation",
        "aliases": [
          "RAG"
        ],
        "category": "specific_connectable",
        "rationale": "RAG is a trending concept that enhances LLMs by integrating external knowledge, making it a strong candidate for linking.",
        "novelty_score": 0.45,
        "connectivity_score": 0.85,
        "specificity_score": 0.78,
        "link_intent_score": 0.88
      },
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "LLMs are central to the paper's focus and are a key component in many NLP applications.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.8
      },
      {
        "surface": "Reinforcement Learning",
        "canonical": "Reinforcement Learning",
        "aliases": [
          "RL"
        ],
        "category": "specific_connectable",
        "rationale": "Reinforcement Learning is crucial for the proposed method, CORE, optimizing the compression process.",
        "novelty_score": 0.55,
        "connectivity_score": 0.78,
        "specificity_score": 0.72,
        "link_intent_score": 0.82
      },
      {
        "surface": "Lossless Compression",
        "canonical": "Lossless Compression",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This is a novel approach specific to the paper, aiming to maintain performance while reducing input size.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Retrieval-Augmented Generation",
      "resolved_canonical": "Retrieval Augmented Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.85,
        "specificity": 0.78,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Reinforcement Learning",
      "resolved_canonical": "Reinforcement Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.78,
        "specificity": 0.72,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Lossless Compression",
      "resolved_canonical": "Lossless Compression",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# CORE-RAG: Lossless Compression for Retrieval-Augmented LLMs via Reinforcement Learning

**Korean Title:** CORE-RAG: ê°•í™” í•™ìŠµì„ í†µí•œ ê²€ìƒ‰ ì¦ê°• ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ ë¬´ì†ì‹¤ ì••ì¶•

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2508.19282.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2508.19282](https://arxiv.org/abs/2508.19282)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Enhancing Retrieval Augmentation via Adversarial Collaboration_20250919|Enhancing Retrieval Augmentation via Adversarial Collaboration]] (86.5% similar)
- [[2025-09-22/Relevance to Utility_ Process-Supervised Rewrite for RAG_20250922|Relevance to Utility: Process-Supervised Rewrite for RAG]] (85.8% similar)
- [[2025-09-22/CodeRAG_ Finding Relevant and Necessary Knowledge for Retrieval-Augmented Repository-Level Code Completion_20250922|CodeRAG: Finding Relevant and Necessary Knowledge for Retrieval-Augmented Repository-Level Code Completion]] (85.7% similar)
- [[2025-09-19/GRADA_ Graph-based Reranking against Adversarial Documents Attack_20250919|GRADA: Graph-based Reranking against Adversarial Documents Attack]] (85.7% similar)
- [[2025-09-22/Query Optimization for Parametric Knowledge Refinement in Retrieval-Augmented Large Language Models_20250922|Query Optimization for Parametric Knowledge Refinement in Retrieval-Augmented Large Language Models]] (85.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Retrieval Augmented Generation|Retrieval Augmented Generation]], [[keywords/Reinforcement Learning|Reinforcement Learning]]
**âš¡ Unique Technical**: [[keywords/Lossless Compression|Lossless Compression]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2508.19282v2 Announce Type: replace-cross 
Abstract: Retrieval-Augmented Generation (RAG) has emerged as a promising approach to enhance the timeliness of knowledge and the factual accuracy of responses in Large Language Models (LLMs). However, the inclusion of excessive retrieved documents substantially increases the input length, leading to higher computational costs. Previous studies have attempted to compress retrieved documents into shorter texts before in-context integration, but such methods often compromise end-task performance. The lack of well-defined compression targets forces many approaches to rely on fixed heuristics, which cannot guarantee that the compressed content will effectively support the end task. To address these limitations, we propose CORE, a novel method designed to achieve lossless context compression for RAG. CORE employs reinforcement learning to optimize the compression process without relying on predefined compression labels, which enables the compressor to generate summaries that maximize the accuracy of answers generated by the LLM. Extensive experiments on four datasets demonstrate the superiority of our approach. With a high compression ratio of 3\%, our method not only avoids performance degradation compared to prepending full documents across all datasets but also improves the average Exact Match (EM) score by 3.3 points. The code will be released soon.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2508.19282v2 ë°œí‘œ ìœ í˜•: êµì²´-í¬ë¡œìŠ¤  
ì´ˆë¡: Retrieval-Augmented Generation (RAG)ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì—ì„œ ì§€ì‹ì˜ ì ì‹œì„±ê³¼ ì‘ë‹µì˜ ì‚¬ì‹¤ì  ì •í™•ì„±ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ìœ ë§í•œ ì ‘ê·¼ë²•ìœ¼ë¡œ ë¶€ìƒí•˜ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê³¼ë„í•œ ê²€ìƒ‰ ë¬¸ì„œì˜ í¬í•¨ì€ ì…ë ¥ ê¸¸ì´ë¥¼ ìƒë‹¹íˆ ì¦ê°€ì‹œì¼œ ê³„ì‚° ë¹„ìš©ì„ ë†’ì…ë‹ˆë‹¤. ì´ì „ ì—°êµ¬ì—ì„œëŠ” ë§¥ë½ ë‚´ í†µí•© ì „ì— ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë” ì§§ì€ í…ìŠ¤íŠ¸ë¡œ ì••ì¶•í•˜ë ¤ê³  ì‹œë„í–ˆì§€ë§Œ, ì´ëŸ¬í•œ ë°©ë²•ì€ ì¢…ì¢… ìµœì¢… ì‘ì—… ì„±ëŠ¥ì„ ì €í•˜ì‹œí‚µë‹ˆë‹¤. ì˜ ì •ì˜ëœ ì••ì¶• ëª©í‘œì˜ ë¶€ì¬ë¡œ ì¸í•´ ë§ì€ ì ‘ê·¼ë²•ì´ ê³ ì •ëœ íœ´ë¦¬ìŠ¤í‹±ì— ì˜ì¡´í•˜ê²Œ ë˜ë©°, ì´ëŠ” ì••ì¶•ëœ ë‚´ìš©ì´ ìµœì¢… ì‘ì—…ì„ íš¨ê³¼ì ìœ¼ë¡œ ì§€ì›í•  ê²ƒì´ë¼ëŠ” ë³´ì¥ì„ ì œê³µí•˜ì§€ ëª»í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì œí•œì ì„ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” RAGë¥¼ ìœ„í•œ ë¬´ì†ì‹¤ ë§¥ë½ ì••ì¶•ì„ ë‹¬ì„±í•˜ê¸° ìœ„í•´ ì„¤ê³„ëœ ìƒˆë¡œìš´ ë°©ë²•ì¸ COREë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. COREëŠ” ê°•í™” í•™ìŠµì„ í™œìš©í•˜ì—¬ ì‚¬ì „ ì •ì˜ëœ ì••ì¶• ë ˆì´ë¸”ì— ì˜ì¡´í•˜ì§€ ì•Šê³  ì••ì¶• ê³¼ì •ì„ ìµœì í™”í•˜ì—¬, LLMì´ ìƒì„±í•˜ëŠ” ë‹µë³€ì˜ ì •í™•ì„±ì„ ê·¹ëŒ€í™”í•˜ëŠ” ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. ë„¤ ê°œì˜ ë°ì´í„°ì…‹ì— ëŒ€í•œ ê´‘ë²”ìœ„í•œ ì‹¤í—˜ì€ ìš°ë¦¬ì˜ ì ‘ê·¼ë²•ì˜ ìš°ìˆ˜ì„±ì„ ì…ì¦í•©ë‹ˆë‹¤. 3%ì˜ ë†’ì€ ì••ì¶• ë¹„ìœ¨ë¡œ, ìš°ë¦¬ì˜ ë°©ë²•ì€ ëª¨ë“  ë°ì´í„°ì…‹ì—ì„œ ì „ì²´ ë¬¸ì„œë¥¼ ì²¨ë¶€í•˜ëŠ” ê²ƒê³¼ ë¹„êµí•˜ì—¬ ì„±ëŠ¥ ì €í•˜ë¥¼ í”¼í•  ë¿ë§Œ ì•„ë‹ˆë¼ í‰ê·  ì •í™• ì¼ì¹˜(EM) ì ìˆ˜ë¥¼ 3.3ì  í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì½”ë“œëŠ” ê³§ ê³µê°œë  ì˜ˆì •ì…ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì •ë³´ ì •í™•ì„±ê³¼ ì‹œì˜ì„±ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ê²€ìƒ‰ ì¦ê°• ìƒì„±(RAG) ì ‘ê·¼ë²•ì˜ ë¬¸ì œì ì„ í•´ê²°í•˜ê³ ì í•©ë‹ˆë‹¤. ê¸°ì¡´ ë°©ë²•ì€ ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ì§§ê²Œ ì••ì¶•í•˜ë ¤ í–ˆìœ¼ë‚˜, ì´ëŠ” ì¢…ì¢… ì„±ëŠ¥ ì €í•˜ë¥¼ ì´ˆë˜í–ˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ì €ìë“¤ì€ ê°•í™” í•™ìŠµì„ í™œìš©í•œ ìƒˆë¡œìš´ ë°©ë²•ì¸ COREë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. COREëŠ” ì‚¬ì „ ì •ì˜ëœ ì••ì¶• ê¸°ì¤€ ì—†ì´ë„ ë¬¸ë§¥ì„ ì†ì‹¤ ì—†ì´ ì••ì¶•í•  ìˆ˜ ìˆìœ¼ë©°, LLMì˜ ì‘ë‹µ ì •í™•ì„±ì„ ê·¹ëŒ€í™”í•˜ëŠ” ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤. ë„¤ ê°œì˜ ë°ì´í„°ì…‹ì— ëŒ€í•œ ì‹¤í—˜ ê²°ê³¼, COREëŠ” 3%ì˜ ë†’ì€ ì••ì¶• ë¹„ìœ¨ì„ ìœ ì§€í•˜ë©´ì„œë„ ì„±ëŠ¥ ì €í•˜ ì—†ì´ í‰ê·  ì •í™•ë„(EM) ì ìˆ˜ë¥¼ 3.3ì  í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤. ì½”ë“œë„ ê³§ ê³µê°œë  ì˜ˆì •ì…ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Retrieval-Augmented Generation (RAG)ëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ ì§€ì‹ ìµœì‹ ì„±ê³¼ ì‚¬ì‹¤ì  ì •í™•ì„±ì„ í–¥ìƒì‹œí‚¤ëŠ” ìœ ë§í•œ ì ‘ê·¼ë²•ìœ¼ë¡œ ë¶€ìƒí•˜ê³  ìˆë‹¤.
- 2. ê¸°ì¡´ ì—°êµ¬ë“¤ì€ ë¬¸ì„œ ì••ì¶•ì„ ì‹œë„í–ˆìœ¼ë‚˜, ê³ ì •ëœ íœ´ë¦¬ìŠ¤í‹±ì— ì˜ì¡´í•˜ì—¬ ìµœì¢… ì‘ì—… ì„±ëŠ¥ì„ ì €í•˜ì‹œí‚¬ ìˆ˜ ìˆë‹¤.
- 3. COREëŠ” ê°•í™” í•™ìŠµì„ í™œìš©í•˜ì—¬ ì‚¬ì „ ì •ì˜ëœ ì••ì¶• ë¼ë²¨ ì—†ì´ ì••ì¶• ê³¼ì •ì„ ìµœì í™”í•˜ê³ , LLMì˜ ë‹µë³€ ì •í™•ì„±ì„ ê·¹ëŒ€í™”í•˜ëŠ” ìš”ì•½ì„ ìƒì„±í•œë‹¤.
- 4. COREëŠ” 3%ì˜ ë†’ì€ ì••ì¶• ë¹„ìœ¨ë¡œ ì„±ëŠ¥ ì €í•˜ ì—†ì´ í‰ê·  ì •í™• ì¼ì¹˜(EM) ì ìˆ˜ë¥¼ 3.3ì  í–¥ìƒì‹œí‚¨ë‹¤.
- 5. COREì˜ ìš°ìˆ˜ì„±ì€ ë„¤ ê°œì˜ ë°ì´í„°ì…‹ì„ í†µí•œ ê´‘ë²”ìœ„í•œ ì‹¤í—˜ì—ì„œ ì…ì¦ë˜ì—ˆìœ¼ë©°, ì½”ë“œê°€ ê³§ ê³µê°œë  ì˜ˆì •ì´ë‹¤.


---

*Generated on 2025-09-23 10:09:02*