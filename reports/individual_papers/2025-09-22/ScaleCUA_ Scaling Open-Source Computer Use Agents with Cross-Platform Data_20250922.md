---
keywords:
  - Vision-Language Model
  - Computer Use Agent
  - Cross-Platform Data
  - Data-Driven Scaling
  - Foundation Model
category: cs.CV
publish_date: 2025-09-22
arxiv_id: 2509.15221
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T12:41:41.570610",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Vision-Language Model",
    "Computer Use Agent",
    "Cross-Platform Data",
    "Data-Driven Scaling",
    "Foundation Model"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Vision-Language Model": 0.82,
    "Computer Use Agent": 0.78,
    "Cross-Platform Data": 0.74,
    "Data-Driven Scaling": 0.73,
    "Foundation Model": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Vision-Language Models",
        "canonical": "Vision-Language Model",
        "aliases": [
          "VLM",
          "Vision-Language"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-Language Models are pivotal in linking multimodal learning approaches with computer use agents.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "Computer Use Agents",
        "canonical": "Computer Use Agent",
        "aliases": [
          "CUA"
        ],
        "category": "unique_technical",
        "rationale": "Central to the paper's theme, it represents a new class of agents that can be linked with broader AI concepts.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Cross-Platform Data",
        "canonical": "Cross-Platform Data",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Highlights the novel aspect of data interoperability across different operating systems, crucial for scaling agents.",
        "novelty_score": 0.68,
        "connectivity_score": 0.72,
        "specificity_score": 0.8,
        "link_intent_score": 0.74
      },
      {
        "surface": "Data-Driven Scaling",
        "canonical": "Data-Driven Scaling",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Emphasizes the methodology of scaling through data, which is a key innovation in the paper.",
        "novelty_score": 0.7,
        "connectivity_score": 0.7,
        "specificity_score": 0.77,
        "link_intent_score": 0.73
      },
      {
        "surface": "Foundation Models",
        "canonical": "Foundation Model",
        "aliases": [],
        "category": "broad_technical",
        "rationale": "Foundation Models are integral to understanding the underlying technology of CUAs.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.65,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Vision-Language Models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Computer Use Agents",
      "resolved_canonical": "Computer Use Agent",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Cross-Platform Data",
      "resolved_canonical": "Cross-Platform Data",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.72,
        "specificity": 0.8,
        "link_intent": 0.74
      }
    },
    {
      "candidate_surface": "Data-Driven Scaling",
      "resolved_canonical": "Data-Driven Scaling",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.7,
        "specificity": 0.77,
        "link_intent": 0.73
      }
    },
    {
      "candidate_surface": "Foundation Models",
      "resolved_canonical": "Foundation Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.65,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# ScaleCUA: Scaling Open-Source Computer Use Agents with Cross-Platform Data

**Korean Title:** ScaleCUA: 크로스 플랫폼 데이터를 활용한 오픈 소스 컴퓨터 사용 에이전트의 확장

## 📋 메타데이터

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15221.pdf)
**Category**: cs.CV
**Published**: 2025-09-22
**ArXiv ID**: [2509.15221](https://arxiv.org/abs/2509.15221)

## 🔗 유사한 논문
- [[2025-09-19/UnifiedVisual_ A Framework for Constructing Unified Vision-Language Datasets_20250919|UnifiedVisual: A Framework for Constructing Unified Vision-Language Datasets]] (83.5% similar)
- [[2025-09-22/GUI-ReWalk_ Massive Data Generation for GUI Agent via Stochastic Exploration and Intent-Aware Reasoning_20250922|GUI-ReWalk: Massive Data Generation for GUI Agent via Stochastic Exploration and Intent-Aware Reasoning]] (81.3% similar)
- [[2025-09-22/Cache-of-Thought_ Master-Apprentice Framework for Cost-Effective Vision Language Model Reasoning_20250922|Cache-of-Thought: Master-Apprentice Framework for Cost-Effective Vision Language Model Reasoning]] (81.3% similar)
- [[2025-09-22/Quality-Driven Curation of Remote Sensing Vision-Language Data via Learned Scoring Models_20250922|Quality-Driven Curation of Remote Sensing Vision-Language Data via Learned Scoring Models]] (81.1% similar)
- [[2025-09-22/GUI-ARP_ Enhancing Grounding with Adaptive Region Perception for GUI Agents_20250922|GUI-ARP: Enhancing Grounding with Adaptive Region Perception for GUI Agents]] (80.8% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Foundation Model|Foundation Model]]
**⚡ Unique Technical**: [[keywords/Computer Use Agent|Computer Use Agent]], [[keywords/Cross-Platform Data|Cross-Platform Data]], [[keywords/Data-Driven Scaling|Data-Driven Scaling]]
**🚀 Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.15221v2 Announce Type: replace 
Abstract: Vision-Language Models (VLMs) have enabled computer use agents (CUAs) that operate GUIs autonomously, showing great potential, yet progress is limited by the lack of large-scale, open-source computer use data and foundation models. In this work, we introduce ScaleCUA, a step toward scaling open-source CUAs. It offers a large-scale dataset spanning 6 operating systems and 3 task domains, built via a closed-loop pipeline uniting automated agents with human experts. Trained on this scaled-up data, ScaleCUA can operate seamlessly across platforms. Specifically, it delivers strong gains over baselines (+26.6 on WebArena-Lite-v2, +10.7 on ScreenSpot-Pro) and sets new state-of-the-art results (94.4% on MMBench-GUI L1-Hard, 60.6% on OSWorld-G, 47.4% on WebArena-Lite-v2). These findings underscore the power of data-driven scaling for general-purpose computer use agents. We will release data, models, and code to advance future research: https://github.com/OpenGVLab/ScaleCUA.

## 🔍 Abstract (한글 번역)

arXiv:2509.15221v2 발표 유형: 교체  
초록: 비전-언어 모델(Vision-Language Models, VLMs)은 그래픽 사용자 인터페이스(GUI)를 자율적으로 작동하는 컴퓨터 사용 에이전트(CUAs)를 가능하게 하여 큰 잠재력을 보여주고 있지만, 대규모 오픈 소스 컴퓨터 사용 데이터와 기초 모델의 부족으로 인해 발전이 제한되고 있습니다. 본 연구에서는 오픈 소스 CUA의 확장을 위한 단계로서 ScaleCUA를 소개합니다. 이는 자동화된 에이전트와 인간 전문가를 결합한 폐쇄 루프 파이프라인을 통해 구축된 6개의 운영 체제와 3개의 작업 도메인을 아우르는 대규모 데이터셋을 제공합니다. 이 확장된 데이터로 학습된 ScaleCUA는 플랫폼 간 원활하게 작동할 수 있습니다. 특히, 이는 기준선 대비 강력한 향상을 제공하며(+26.6점 WebArena-Lite-v2, +10.7점 ScreenSpot-Pro), 새로운 최첨단 결과를 설정합니다(94.4% MMBench-GUI L1-Hard, 60.6% OSWorld-G, 47.4% WebArena-Lite-v2). 이러한 결과는 범용 컴퓨터 사용 에이전트를 위한 데이터 기반 확장의 힘을 강조합니다. 우리는 향후 연구 발전을 위해 데이터, 모델 및 코드를 공개할 예정입니다: https://github.com/OpenGVLab/ScaleCUA.

## 📝 요약

이 연구는 대규모 오픈소스 데이터 부족으로 발전이 제한된 비전-언어 모델(VLMs)을 활용한 컴퓨터 사용 에이전트(CUAs)의 확장을 목표로 합니다. 이를 위해 6개의 운영 체제와 3개의 작업 도메인을 아우르는 대규모 데이터셋인 ScaleCUA를 소개합니다. 자동화된 에이전트와 인간 전문가를 결합한 폐쇄 루프 파이프라인을 통해 구축된 이 데이터셋은 플랫폼 간 원활한 작동을 가능하게 합니다. ScaleCUA는 기존 모델 대비 웹아레나-라이트-v2에서 +26.6, 스크린스팟-프로에서 +10.7의 성능 향상을 보였으며, MMBench-GUI L1-Hard에서 94.4%, OSWorld-G에서 60.6%, WebArena-Lite-v2에서 47.4%의 새로운 최고 성능을 기록했습니다. 이 연구는 데이터 기반 확장의 중요성을 강조하며, 향후 연구를 위해 데이터, 모델 및 코드를 공개할 예정입니다.

## 🎯 주요 포인트

- 1. Vision-Language Models(VLMs)를 활용한 컴퓨터 사용 에이전트(CUAs)는 GUI를 자율적으로 운영할 수 있지만, 대규모 오픈 소스 데이터와 기초 모델의 부족으로 발전이 제한되고 있습니다.
- 2. ScaleCUA는 6개의 운영 체제와 3개의 작업 도메인을 아우르는 대규모 데이터셋을 제공하여 오픈 소스 CUAs의 확장을 목표로 하고 있습니다.
- 3. ScaleCUA는 자동화된 에이전트와 인간 전문가를 결합한 폐쇄 루프 파이프라인을 통해 구축되었으며, 플랫폼 간 원활한 작동을 가능하게 합니다.
- 4. ScaleCUA는 기존 기준치 대비 WebArena-Lite-v2에서 +26.6, ScreenSpot-Pro에서 +10.7의 성능 향상을 보여주며, 여러 벤치마크에서 새로운 최고 성과를 기록했습니다.
- 5. 데이터, 모델, 코드가 공개될 예정이며, 이는 향후 연구 발전에 기여할 것입니다.


---

*Generated on 2025-09-23 12:41:41*