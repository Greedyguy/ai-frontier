---
keywords:
  - A/B Testing
  - Large Language Model Agents
  - User Interaction Simulation
  - Between-Subject A/B Testing
category: cs.CL
publish_date: 2025-09-22
arxiv_id: 2504.09723
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:52:29.441258",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "A/B Testing",
    "Large Language Model Agents",
    "User Interaction Simulation",
    "Between-Subject A/B Testing"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "A/B Testing": 0.82,
    "Large Language Model Agents": 0.88,
    "User Interaction Simulation": 0.79,
    "Between-Subject A/B Testing": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "A/B testing",
        "canonical": "A/B Testing",
        "aliases": [
          "AB Testing",
          "Split Testing"
        ],
        "category": "unique_technical",
        "rationale": "A/B Testing is central to the paper's focus on evaluating UI/UX design decisions and is a key concept in web experimentation.",
        "novelty_score": 0.65,
        "connectivity_score": 0.78,
        "specificity_score": 0.85,
        "link_intent_score": 0.82
      },
      {
        "surface": "LLM Agents",
        "canonical": "Large Language Model Agents",
        "aliases": [
          "LLM Agents"
        ],
        "category": "specific_connectable",
        "rationale": "LLM Agents are a novel application of Large Language Models for simulating user interactions, which is a core innovation of the paper.",
        "novelty_score": 0.7,
        "connectivity_score": 0.85,
        "specificity_score": 0.8,
        "link_intent_score": 0.88
      },
      {
        "surface": "user interaction behaviors",
        "canonical": "User Interaction Simulation",
        "aliases": [
          "User Behavior Simulation"
        ],
        "category": "unique_technical",
        "rationale": "Simulating user interactions is a unique technical approach that differentiates the proposed method from traditional A/B testing.",
        "novelty_score": 0.68,
        "connectivity_score": 0.77,
        "specificity_score": 0.83,
        "link_intent_score": 0.79
      },
      {
        "surface": "between-subject A/B testing",
        "canonical": "Between-Subject A/B Testing",
        "aliases": [
          "Between-Subject Testing"
        ],
        "category": "unique_technical",
        "rationale": "This specific type of A/B testing is crucial for understanding the experimental setup used in the paper.",
        "novelty_score": 0.6,
        "connectivity_score": 0.72,
        "specificity_score": 0.78,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "experiment",
      "method",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "A/B testing",
      "resolved_canonical": "A/B Testing",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.78,
        "specificity": 0.85,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "LLM Agents",
      "resolved_canonical": "Large Language Model Agents",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.85,
        "specificity": 0.8,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "user interaction behaviors",
      "resolved_canonical": "User Interaction Simulation",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.77,
        "specificity": 0.83,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "between-subject A/B testing",
      "resolved_canonical": "Between-Subject A/B Testing",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.72,
        "specificity": 0.78,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# AgentA/B: Automated and Scalable Web A/BTesting with Interactive LLM Agents

**Korean Title:** ì—ì´ì „íŠ¸A/B: ìƒí˜¸ì‘ìš©í˜• LLM ì—ì´ì „íŠ¸ë¥¼ í™œìš©í•œ ìë™í™” ë° í™•ì¥ ê°€ëŠ¥í•œ ì›¹ A/B í…ŒìŠ¤íŠ¸

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2504.09723.pdf)
**Category**: cs.CL
**Published**: 2025-09-22
**ArXiv ID**: [2504.09723](https://arxiv.org/abs/2504.09723)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/UXAgent_ A System for Simulating Usability Testing of Web Design with LLM Agents_20250922|UXAgent: A System for Simulating Usability Testing of Web Design with LLM Agents]] (89.7% similar)
- [[2025-09-18/AppAgent v2_ Advanced Agent for Flexible Mobile Interactions_20250918|AppAgent v2: Advanced Agent for Flexible Mobile Interactions]] (85.4% similar)
- [[2025-09-18/Designing AI-Agents with Personalities_ A Psychometric Approach_20250918|Designing AI-Agents with Personalities: A Psychometric Approach]] (83.9% similar)
- [[2025-09-19/An LLM-based multi-agent framework for agile effort estimation_20250919|An LLM-based multi-agent framework for agile effort estimation]] (83.3% similar)
- [[2025-09-18/$Agent^2$_ An Agent-Generates-Agent Framework for Reinforcement Learning Automation_20250918|$Agent^2$: An Agent-Generates-Agent Framework for Reinforcement Learning Automation]] (83.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Large Language Model Agents|Large Language Model Agents]]
**âš¡ Unique Technical**: [[keywords/A/B Testing|A/B Testing]], [[keywords/User Interaction Simulation|User Interaction Simulation]], [[keywords/Between-Subject A/B Testing|Between-Subject A/B Testing]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2504.09723v3 Announce Type: replace-cross 
Abstract: A/B testing experiment is a widely adopted method for evaluating UI/UX design decisions in modern web applications. Yet, traditional A/B testing remains constrained by its dependence on the large-scale and live traffic of human participants, and the long time of waiting for the testing result. Through formative interviews with six experienced industry practitioners, we identified critical bottlenecks in current A/B testing workflows. In response, we present AgentA/B, a novel system that leverages Large Language Model-based autonomous agents (LLM Agents) to automatically simulate user interaction behaviors with real webpages. AgentA/B enables scalable deployment of LLM agents with diverse personas, each capable of navigating the dynamic webpage and interactively executing multi-step interactions like search, clicking, filtering, and purchasing. In a demonstrative controlled experiment, we employ AgentA/B to simulate a between-subject A/B testing with 1,000 LLM agents Amazon.com, and compare agent behaviors with real human shopping behaviors at a scale. Our findings suggest AgentA/B can emulate human-like behavior patterns.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2504.09723v3 ë°œí‘œ ìœ í˜•: êµì°¨ êµì²´  
ì´ˆë¡: A/B í…ŒìŠ¤íŠ¸ ì‹¤í—˜ì€ í˜„ëŒ€ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ UI/UX ë””ìì¸ ê²°ì •ì„ í‰ê°€í•˜ê¸° ìœ„í•´ ë„ë¦¬ ì±„íƒëœ ë°©ë²•ì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì „í†µì ì¸ A/B í…ŒìŠ¤íŠ¸ëŠ” ëŒ€ê·œëª¨ì˜ ì‹¤ì‹œê°„ ì¸ê°„ ì°¸ì—¬ì íŠ¸ë˜í”½ì— ì˜ì¡´í•˜ê³ , í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ê¸°ë‹¤ë¦¬ëŠ” ê¸´ ì‹œê°„ì— ì˜í•´ ì œì•½ì„ ë°›ìŠµë‹ˆë‹¤. ì—¬ì„¯ ëª…ì˜ ê²½í—˜ ë§ì€ ì—…ê³„ ì‹¤ë¬´ìë“¤ê³¼ì˜ í˜•ì„±ì  ì¸í„°ë·°ë¥¼ í†µí•´ í˜„ì¬ A/B í…ŒìŠ¤íŠ¸ ì›Œí¬í”Œë¡œìš°ì—ì„œì˜ ì£¼ìš” ë³‘ëª© í˜„ìƒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ì´ì— ëŒ€ì‘í•˜ì—¬, ìš°ë¦¬ëŠ” ì‹¤ì‹œê°„ ì›¹í˜ì´ì§€ì™€ì˜ ì‚¬ìš©ì ìƒí˜¸ì‘ìš© í–‰ë™ì„ ìë™ìœ¼ë¡œ ì‹œë®¬ë ˆì´ì…˜í•˜ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ê¸°ë°˜ì˜ ììœ¨ ì—ì´ì „íŠ¸(LLM ì—ì´ì „íŠ¸)ë¥¼ í™œìš©í•œ ìƒˆë¡œìš´ ì‹œìŠ¤í…œì¸ AgentA/Bë¥¼ ì œì‹œí•©ë‹ˆë‹¤. AgentA/BëŠ” ë‹¤ì–‘í•œ í˜ë¥´ì†Œë‚˜ë¥¼ ê°€ì§„ LLM ì—ì´ì „íŠ¸ë¥¼ í™•ì¥ ê°€ëŠ¥í•˜ê²Œ ë°°í¬í•  ìˆ˜ ìˆìœ¼ë©°, ê° ì—ì´ì „íŠ¸ëŠ” ë™ì  ì›¹í˜ì´ì§€ë¥¼ íƒìƒ‰í•˜ê³  ê²€ìƒ‰, í´ë¦­, í•„í„°ë§, êµ¬ë§¤ì™€ ê°™ì€ ë‹¤ë‹¨ê³„ ìƒí˜¸ì‘ìš©ì„ ìƒí˜¸ì‘ìš©ì ìœ¼ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹œì—°ì ì¸ í†µì œ ì‹¤í—˜ì—ì„œ, ìš°ë¦¬ëŠ” AgentA/Bë¥¼ ì‚¬ìš©í•˜ì—¬ 1,000ê°œì˜ LLM ì—ì´ì „íŠ¸ë¥¼ í†µí•œ í”¼í—˜ì ê°„ A/B í…ŒìŠ¤íŠ¸ë¥¼ Amazon.comì—ì„œ ì‹œë®¬ë ˆì´ì…˜í•˜ê³ , ì—ì´ì „íŠ¸ í–‰ë™ì„ ëŒ€ê·œëª¨ë¡œ ì‹¤ì œ ì¸ê°„ì˜ ì‡¼í•‘ í–‰ë™ê³¼ ë¹„êµí•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì—°êµ¬ ê²°ê³¼ëŠ” AgentA/Bê°€ ì¸ê°„ê³¼ ìœ ì‚¬í•œ í–‰ë™ íŒ¨í„´ì„ ëª¨ë°©í•  ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì „í†µì ì¸ A/B í…ŒìŠ¤íŠ¸ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ AgentA/Bë¼ëŠ” ìƒˆë¡œìš´ ì‹œìŠ¤í…œì„ ì œì•ˆí•©ë‹ˆë‹¤. AgentA/BëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ê¸°ë°˜ì˜ ììœ¨ ì—ì´ì „íŠ¸ë¥¼ í™œìš©í•˜ì—¬ ì‹¤ì œ ì›¹ í˜ì´ì§€ì—ì„œ ì‚¬ìš©ì ìƒí˜¸ì‘ìš©ì„ ìë™ìœ¼ë¡œ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë‹¤ì–‘í•œ í˜ë¥´ì†Œë‚˜ë¥¼ ê°€ì§„ ì—ì´ì „íŠ¸ë“¤ì´ ë™ì  ì›¹ í˜ì´ì§€ë¥¼ íƒìƒ‰í•˜ê³  ê²€ìƒ‰, í´ë¦­, í•„í„°ë§, êµ¬ë§¤ì™€ ê°™ì€ ë‹¤ë‹¨ê³„ ìƒí˜¸ì‘ìš©ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹¤í—˜ì—ì„œëŠ” 1,000ê°œì˜ ì—ì´ì „íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ Amazon.comì—ì„œì˜ A/B í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•˜ê³ , ì—ì´ì „íŠ¸ì˜ í–‰ë™ì´ ì‹¤ì œ ì¸ê°„ì˜ ì‡¼í•‘ í–‰ë™ê³¼ ìœ ì‚¬í•¨ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” AgentA/Bê°€ ì¸ê°„ê³¼ ìœ ì‚¬í•œ í–‰ë™ íŒ¨í„´ì„ ëª¨ë°©í•  ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì „í†µì ì¸ A/B í…ŒìŠ¤íŠ¸ëŠ” ëŒ€ê·œëª¨ì˜ ì‹¤ì‹œê°„ ì‚¬ìš©ì íŠ¸ë˜í”½ê³¼ ê¸´ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ëŒ€ê¸° ì‹œê°„ì— ì˜ì¡´í•˜ëŠ” í•œê³„ê°€ ìˆë‹¤.
- 2. AgentA/BëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ ê¸°ë°˜ì˜ ììœ¨ ì—ì´ì „íŠ¸ë¥¼ í™œìš©í•˜ì—¬ ì‹¤ì œ ì›¹í˜ì´ì§€ì—ì„œ ì‚¬ìš©ì ìƒí˜¸ì‘ìš©ì„ ìë™ìœ¼ë¡œ ì‹œë®¬ë ˆì´ì…˜í•˜ëŠ” ì‹œìŠ¤í…œì´ë‹¤.
- 3. AgentA/BëŠ” ë‹¤ì–‘í•œ í˜ë¥´ì†Œë‚˜ë¥¼ ê°€ì§„ LLM ì—ì´ì „íŠ¸ë¥¼ ëŒ€ê·œëª¨ë¡œ ë°°ì¹˜í•˜ì—¬ ê²€ìƒ‰, í´ë¦­, í•„í„°ë§, êµ¬ë§¤ ë“±ì˜ ë‹¤ë‹¨ê³„ ìƒí˜¸ì‘ìš©ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.
- 4. AgentA/Bë¥¼ ì‚¬ìš©í•œ ì‹¤í—˜ì—ì„œ 1,000ëª…ì˜ LLM ì—ì´ì „íŠ¸ë¥¼ í†µí•´ Amazon.comì—ì„œì˜ A/B í…ŒìŠ¤íŠ¸ë¥¼ ì‹œë®¬ë ˆì´ì…˜í•˜ê³ , ì‹¤ì œ ì¸ê°„ì˜ ì‡¼í•‘ í–‰ë™ê³¼ ë¹„êµí•˜ì˜€ë‹¤.
- 5. ì—°êµ¬ ê²°ê³¼, AgentA/BëŠ” ì¸ê°„ê³¼ ìœ ì‚¬í•œ í–‰ë™ íŒ¨í„´ì„ ëª¨ë°©í•  ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•œë‹¤.


---

*Generated on 2025-09-23 11:52:29*