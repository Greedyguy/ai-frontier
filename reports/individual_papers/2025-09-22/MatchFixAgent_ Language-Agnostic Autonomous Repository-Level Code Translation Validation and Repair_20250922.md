---
keywords:
  - Large Language Model
  - Code Translation
  - Equivalence Validation
  - Multi-Agent Architecture
category: cs.LG
publish_date: 2025-09-22
arxiv_id: 2509.16187
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T10:58:27.541301",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Code Translation",
    "Equivalence Validation",
    "Multi-Agent Architecture"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Code Translation": 0.78,
    "Equivalence Validation": 0.77,
    "Multi-Agent Architecture": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Model",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "Connects to the broader field of AI and machine learning, facilitating links to related technologies.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Code Translation",
        "canonical": "Code Translation",
        "aliases": [
          "Programming Language Translation"
        ],
        "category": "unique_technical",
        "rationale": "Central to the paper's focus, enabling connections to software engineering and programming language studies.",
        "novelty_score": 0.75,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Equivalence Validation",
        "canonical": "Equivalence Validation",
        "aliases": [
          "Functional Equivalence Checking"
        ],
        "category": "unique_technical",
        "rationale": "Key process in ensuring accurate code translation, linking to software verification and validation fields.",
        "novelty_score": 0.68,
        "connectivity_score": 0.72,
        "specificity_score": 0.78,
        "link_intent_score": 0.77
      },
      {
        "surface": "Multi-Agent Architecture",
        "canonical": "Multi-Agent Architecture",
        "aliases": [
          "Agent-Based System"
        ],
        "category": "specific_connectable",
        "rationale": "Highlights the structural approach of the system, connecting to studies in distributed systems and AI.",
        "novelty_score": 0.6,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "test agent",
      "repair agent",
      "verdict agent"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Model",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Code Translation",
      "resolved_canonical": "Code Translation",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Equivalence Validation",
      "resolved_canonical": "Equivalence Validation",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.72,
        "specificity": 0.78,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Multi-Agent Architecture",
      "resolved_canonical": "Multi-Agent Architecture",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# MatchFixAgent: Language-Agnostic Autonomous Repository-Level Code Translation Validation and Repair

**Korean Title:** MatchFixAgent: ì–¸ì–´ì— êµ¬ì• ë°›ì§€ ì•ŠëŠ” ììœ¨ì  ì €ì¥ì†Œ ìˆ˜ì¤€ì˜ ì½”ë“œ ë²ˆì—­ ê²€ì¦ ë° ìˆ˜ì •

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16187.pdf)
**Category**: cs.LG
**Published**: 2025-09-22
**ArXiv ID**: [2509.16187](https://arxiv.org/abs/2509.16187)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/Semantic Alignment-Enhanced Code Translation via an LLM-Based Multi-Agent System_20250918|Semantic Alignment-Enhanced Code Translation via an LLM-Based Multi-Agent System]] (86.4% similar)
- [[2025-09-19/RulER_ Automated Rule-Based Semantic Error Localization and Repair for Code Translation_20250919|RulER: Automated Rule-Based Semantic Error Localization and Repair for Code Translation]] (84.0% similar)
- [[2025-09-19/On the Use of Agentic Coding_ An Empirical Study of Pull Requests on GitHub_20250919|On the Use of Agentic Coding: An Empirical Study of Pull Requests on GitHub]] (81.4% similar)
- [[2025-09-19/Translate, then Detect_ Leveraging Machine Translation for Cross-Lingual Toxicity Classification_20250919|Translate, then Detect: Leveraging Machine Translation for Cross-Lingual Toxicity Classification]] (80.4% similar)
- [[2025-09-19/Ticket-Bench_ A Kickoff for Multilingual and Regionalized Agent Evaluation_20250919|Ticket-Bench: A Kickoff for Multilingual and Regionalized Agent Evaluation]] (80.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Multi-Agent Architecture|Multi-Agent Architecture]]
**âš¡ Unique Technical**: [[keywords/Code Translation|Code Translation]], [[keywords/Equivalence Validation|Equivalence Validation]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16187v1 Announce Type: cross 
Abstract: Code translation transforms source code from one programming language (PL) to another. Validating the functional equivalence of translation and repairing, if necessary, are critical steps in code translation. Existing automated validation and repair approaches struggle to generalize to many PLs due to high engineering overhead, and they rely on existing and often inadequate test suites, which results in false claims of equivalence and ineffective translation repair. We develop MatchFixAgent, a large language model (LLM)-based, PL-agnostic framework for equivalence validation and repair of translations. MatchFixAgent features a multi-agent architecture that divides equivalence validation into several sub-tasks to ensure thorough and consistent semantic analysis of the translation. Then it feeds this analysis to test agent to write and execute tests. Upon observing a test failure, the repair agent attempts to fix the translation bug. The final (in)equivalence decision is made by the verdict agent, considering semantic analyses and test execution results.
  We compare MatchFixAgent's validation and repair results with four repository-level code translation techniques. We use 2,219 translation pairs from their artifacts, which cover 6 PL pairs, and are collected from 24 GitHub projects totaling over 900K lines of code. Our results demonstrate that MatchFixAgent produces (in)equivalence verdicts for 99.2% of translation pairs, with the same equivalence validation result as prior work on 72.8% of them. When MatchFixAgent's result disagrees with prior work, we find that 60.7% of the time MatchFixAgent's result is actually correct. In addition, we show that MatchFixAgent can repair 50.6% of inequivalent translation, compared to prior work's 18.5%. This demonstrates that MatchFixAgent is far more adaptable to many PL pairs than prior work, while producing highly accurate validation results.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.16187v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ì½”ë“œ ë²ˆì—­ì€ ì†ŒìŠ¤ ì½”ë“œë¥¼ í•œ í”„ë¡œê·¸ë˜ë° ì–¸ì–´(PL)ì—ì„œ ë‹¤ë¥¸ ì–¸ì–´ë¡œ ë³€í™˜í•˜ëŠ” ì‘ì—…ì…ë‹ˆë‹¤. ë²ˆì—­ì˜ ê¸°ëŠ¥ì  ë™ë“±ì„±ì„ ê²€ì¦í•˜ê³  í•„ìš”ì‹œ ìˆ˜ì •í•˜ëŠ” ê²ƒì€ ì½”ë“œ ë²ˆì—­ì—ì„œ ì¤‘ìš”í•œ ë‹¨ê³„ì…ë‹ˆë‹¤. ê¸°ì¡´ì˜ ìë™í™”ëœ ê²€ì¦ ë° ìˆ˜ì • ì ‘ê·¼ë²•ì€ ë†’ì€ ì—”ì§€ë‹ˆì–´ë§ ë¹„ìš© ë•Œë¬¸ì— ë§ì€ PLì— ì¼ë°˜í™”í•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªìœ¼ë©°, ê¸°ì¡´ì˜ ë¶ˆì¶©ë¶„í•œ í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ì— ì˜ì¡´í•˜ì—¬ ë™ë“±ì„±ì— ëŒ€í•œ ì˜ëª»ëœ ì£¼ì¥ê³¼ ë¹„íš¨ìœ¨ì ì¸ ë²ˆì—­ ìˆ˜ì •ì„ ì´ˆë˜í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ë²ˆì—­ì˜ ë™ë“±ì„± ê²€ì¦ ë° ìˆ˜ì •ì„ ìœ„í•œ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM) ê¸°ë°˜ì˜ PL-ë…ë¦½ì  í”„ë ˆì„ì›Œí¬ì¸ MatchFixAgentë¥¼ ê°œë°œí–ˆìŠµë‹ˆë‹¤. MatchFixAgentëŠ” ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì•„í‚¤í…ì²˜ë¥¼ íŠ¹ì§•ìœ¼ë¡œ í•˜ì—¬ ë²ˆì—­ì˜ ì² ì €í•˜ê³  ì¼ê´€ëœ ì˜ë¯¸ ë¶„ì„ì„ ë³´ì¥í•˜ê¸° ìœ„í•´ ë™ë“±ì„± ê²€ì¦ì„ ì—¬ëŸ¬ í•˜ìœ„ ì‘ì—…ìœ¼ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ ì´ ë¶„ì„ì„ í…ŒìŠ¤íŠ¸ ì—ì´ì „íŠ¸ì— ì œê³µí•˜ì—¬ í…ŒìŠ¤íŠ¸ë¥¼ ì‘ì„±í•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ê°€ ê´€ì°°ë˜ë©´ ìˆ˜ì • ì—ì´ì „íŠ¸ê°€ ë²ˆì—­ ë²„ê·¸ë¥¼ ìˆ˜ì •í•˜ë ¤ê³  ì‹œë„í•©ë‹ˆë‹¤. ìµœì¢… (ë¹„)ë™ë“±ì„± ê²°ì •ì€ ì˜ë¯¸ ë¶„ì„ ë° í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ê²°ê³¼ë¥¼ ê³ ë ¤í•˜ì—¬ íŒê²° ì—ì´ì „íŠ¸ì— ì˜í•´ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.  
ìš°ë¦¬ëŠ” MatchFixAgentì˜ ê²€ì¦ ë° ìˆ˜ì • ê²°ê³¼ë¥¼ ë„¤ ê°€ì§€ ì €ì¥ì†Œ ìˆ˜ì¤€ ì½”ë“œ ë²ˆì—­ ê¸°ìˆ ê³¼ ë¹„êµí•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” 6ê°œì˜ PL ìŒì„ ë‹¤ë£¨ëŠ” 2,219ê°œì˜ ë²ˆì—­ ìŒì„ ì‚¬ìš©í•˜ë©°, ì´ëŠ” 24ê°œì˜ GitHub í”„ë¡œì íŠ¸ì—ì„œ ìˆ˜ì§‘ëœ ì´ 90ë§Œ ì¤„ ì´ìƒì˜ ì½”ë“œì—ì„œ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤. ìš°ë¦¬ì˜ ê²°ê³¼ëŠ” MatchFixAgentê°€ ë²ˆì—­ ìŒì˜ 99.2%ì— ëŒ€í•´ (ë¹„)ë™ë“±ì„± íŒê²°ì„ ë‚´ë¦¬ë©°, ê·¸ ì¤‘ 72.8%ëŠ” ì´ì „ ì‘ì—…ê³¼ ë™ì¼í•œ ë™ë“±ì„± ê²€ì¦ ê²°ê³¼ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. MatchFixAgentì˜ ê²°ê³¼ê°€ ì´ì „ ì‘ì—…ê³¼ ì¼ì¹˜í•˜ì§€ ì•ŠëŠ” ê²½ìš°, 60.7%ì˜ ê²½ìš° MatchFixAgentì˜ ê²°ê³¼ê°€ ì‹¤ì œë¡œ ì˜¬ë°”ë¦„ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, MatchFixAgentê°€ ì´ì „ ì‘ì—…ì˜ 18.5%ì— ë¹„í•´ 50.6%ì˜ ë¹„ë™ë“± ë²ˆì—­ì„ ìˆ˜ì •í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŠ” MatchFixAgentê°€ ì´ì „ ì‘ì—…ë³´ë‹¤ ë§ì€ PL ìŒì— í›¨ì”¬ ë” ì ì‘ë ¥ì´ ë›°ì–´ë‚˜ë©°, ë§¤ìš° ì •í™•í•œ ê²€ì¦ ê²°ê³¼ë¥¼ ìƒì„±í•¨ì„ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

MatchFixAgentëŠ” í”„ë¡œê·¸ë˜ë° ì–¸ì–´ ê°„ ì½”ë“œ ë²ˆì—­ì˜ ê¸°ëŠ¥ì  ë™ë“±ì„±ì„ ê²€ì¦í•˜ê³  í•„ìš” ì‹œ ìˆ˜ì •í•˜ëŠ” LLM ê¸°ë°˜ì˜ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œì€ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì•„í‚¤í…ì²˜ë¥¼ í†µí•´ ë²ˆì—­ì˜ ì˜ë¯¸ ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³ , í…ŒìŠ¤íŠ¸ ì—ì´ì „íŠ¸ê°€ í…ŒìŠ¤íŠ¸ë¥¼ ì‘ì„± ë° ì‹¤í–‰í•˜ë©°, ì˜¤ë¥˜ ë°œìƒ ì‹œ ìˆ˜ë¦¬ ì—ì´ì „íŠ¸ê°€ ë²ˆì—­ ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤. ìµœì¢… ë™ë“±ì„± íŒë‹¨ì€ ì˜ë¯¸ ë¶„ì„ê³¼ í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤. 6ê°œì˜ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ ìŒì„ í¬í•¨í•œ 2,219ê°œì˜ ë²ˆì—­ ìŒì„ ëŒ€ìƒìœ¼ë¡œ í•œ ì‹¤í—˜ì—ì„œ MatchFixAgentëŠ” 99.2%ì˜ ë²ˆì—­ ìŒì— ëŒ€í•´ ë™ë“±ì„± íŒë‹¨ì„ ë‚´ë ¸ìœ¼ë©°, ê¸°ì¡´ ë°©ë²•ê³¼ì˜ ë¶ˆì¼ì¹˜ ì‹œ 60.7%ì˜ ê²½ìš°ì— MatchFixAgentì˜ ê²°ê³¼ê°€ ì •í™•í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, MatchFixAgentëŠ” ê¸°ì¡´ ë°©ë²•ë³´ë‹¤ 50.6%ì˜ ë¹„ë™ë“± ë²ˆì—­ì„ ì„±ê³µì ìœ¼ë¡œ ìˆ˜ì •í•˜ì—¬ ë” ë†’ì€ ì ì‘ì„±ê³¼ ì •í™•ì„±ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. MatchFixAgentëŠ” í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì— êµ¬ì• ë°›ì§€ ì•ŠëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ê¸°ë°˜ì˜ ì½”ë“œ ë²ˆì—­ ë“±ê°€ì„± ê²€ì¦ ë° ìˆ˜ì •ì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.
- 2. MatchFixAgentëŠ” ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì•„í‚¤í…ì²˜ë¥¼ í†µí•´ ë²ˆì—­ì˜ ì² ì €í•˜ê³  ì¼ê´€ëœ ì˜ë¯¸ ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³ , í…ŒìŠ¤íŠ¸ ì—ì´ì „íŠ¸ë¥¼ í†µí•´ í…ŒìŠ¤íŠ¸ë¥¼ ì‘ì„± ë° ì‹¤í–‰í•©ë‹ˆë‹¤.
- 3. MatchFixAgentëŠ” 6ê°œì˜ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ ìŒì„ í¬í•¨í•œ 2,219ê°œì˜ ë²ˆì—­ ìŒì— ëŒ€í•´ 99.2%ì˜ ë“±ê°€ì„± íŒì •ì„ ë‚´ë ¸ìœ¼ë©°, ê¸°ì¡´ ì—°êµ¬ì™€ 72.8%ì˜ ì¼ì¹˜ìœ¨ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.
- 4. MatchFixAgentëŠ” ê¸°ì¡´ ì—°êµ¬ë³´ë‹¤ 60.7% ë” ì •í™•í•œ ê²°ê³¼ë¥¼ ì œê³µí•˜ë©°, ë¹„ë“±ê°€ ë²ˆì—­ì˜ 50.6%ë¥¼ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- 5. MatchFixAgentëŠ” ë‹¤ì–‘í•œ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ ìŒì— ëŒ€í•´ ë†’ì€ ì ì‘ì„±ê³¼ ì •í™•ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.


---

*Generated on 2025-09-23 10:58:27*