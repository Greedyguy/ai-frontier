---
keywords:
  - Multimodal Dataset Distillation
  - Generative Models
  - Bi-directional Contrastive Loss
  - Vision-Language Model
category: cs.CV
publish_date: 2025-09-22
arxiv_id: 2509.15472
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:57:52.181292",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multimodal Dataset Distillation",
    "Generative Models",
    "Bi-directional Contrastive Loss",
    "Vision-Language Model"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multimodal Dataset Distillation": 0.78,
    "Generative Models": 0.82,
    "Bi-directional Contrastive Loss": 0.75,
    "Vision-Language Model": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multimodal Dataset Distillation",
        "canonical": "Multimodal Dataset Distillation",
        "aliases": [
          "Dataset Distillation",
          "Multimodal Distillation"
        ],
        "category": "unique_technical",
        "rationale": "This concept is central to the paper and represents a novel approach to dataset synthesis in multimodal contexts.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Generative Models",
        "canonical": "Generative Models",
        "aliases": [
          "Generative Model"
        ],
        "category": "broad_technical",
        "rationale": "Generative models are a key component of the proposed method and are widely applicable across different domains.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.82
      },
      {
        "surface": "Bi-directional Contrastive Loss",
        "canonical": "Bi-directional Contrastive Loss",
        "aliases": [
          "Contrastive Loss"
        ],
        "category": "unique_technical",
        "rationale": "This specific loss function is a novel contribution that addresses the challenges of correlation and diversity in dataset distillation.",
        "novelty_score": 0.68,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      },
      {
        "surface": "Vision-Language Model",
        "canonical": "Vision-Language Model",
        "aliases": [
          "Vision-Language Models"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-language models are crucial for understanding and linking multimodal datasets, as highlighted in the paper.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.75,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "Matching Training Trajectories",
      "Caption Synthesis Strategy"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multimodal Dataset Distillation",
      "resolved_canonical": "Multimodal Dataset Distillation",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Generative Models",
      "resolved_canonical": "Generative Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Bi-directional Contrastive Loss",
      "resolved_canonical": "Bi-directional Contrastive Loss",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Vision-Language Model",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.75,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# Efficient Multimodal Dataset Distillation via Generative Models

**Korean Title:** íš¨ìœ¨ì ì¸ ë‹¤ì¤‘ ëª¨ë‹¬ ë°ì´í„°ì…‹ ì¦ë¥˜ë¥¼ ìœ„í•œ ìƒì„± ëª¨ë¸ í™œìš©

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15472.pdf)
**Category**: cs.CV
**Published**: 2025-09-22
**ArXiv ID**: [2509.15472](https://arxiv.org/abs/2509.15472)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/DistillMatch_ Leveraging Knowledge Distillation from Vision Foundation Model for Multimodal Image Matching_20250922|DistillMatch: Leveraging Knowledge Distillation from Vision Foundation Model for Multimodal Image Matching]] (83.6% similar)
- [[2025-09-22/RespoDiff_ Dual-Module Bottleneck Transformation for Responsible & Faithful T2I Generation_20250922|RespoDiff: Dual-Module Bottleneck Transformation for Responsible & Faithful T2I Generation]] (83.2% similar)
- [[2025-09-22/Kuramoto Orientation Diffusion Models_20250922|Kuramoto Orientation Diffusion Models]] (82.8% similar)
- [[2025-09-22/PRISM_ Phase-enhanced Radial-based Image Signature Mapping framework for fingerprinting AI-generated images_20250922|PRISM: Phase-enhanced Radial-based Image Signature Mapping framework for fingerprinting AI-generated images]] (82.2% similar)
- [[2025-09-22/Autoguided Online Data Curation for Diffusion Model Training_20250922|Autoguided Online Data Curation for Diffusion Model Training]] (82.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Generative Models|Generative Models]]
**âš¡ Unique Technical**: [[keywords/Multimodal Dataset Distillation|Multimodal Dataset Distillation]], [[keywords/Bi-directional Contrastive Loss|Bi-directional Contrastive Loss]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15472v1 Announce Type: new 
Abstract: Dataset distillation aims to synthesize a small dataset from a large dataset, enabling the model trained on it to perform well on the original dataset. With the blooming of large language models and multimodal large language models, the importance of multimodal datasets, particularly image-text datasets, has grown significantly. However, existing multimodal dataset distillation methods are constrained by the Matching Training Trajectories algorithm, which significantly increases the computing resource requirement, and takes days to process the distillation. In this work, we introduce EDGE, a generative distillation method for efficient multimodal dataset distillation. Specifically, we identify two key challenges of distilling multimodal datasets with generative models: 1) The lack of correlation between generated images and captions. 2) The lack of diversity among generated samples. To address the aforementioned issues, we propose a novel generative model training workflow with a bi-directional contrastive loss and a diversity loss. Furthermore, we propose a caption synthesis strategy to further improve text-to-image retrieval performance by introducing more text information. Our method is evaluated on Flickr30K, COCO, and CC3M datasets, demonstrating superior performance and efficiency compared to existing approaches. Notably, our method achieves results 18x faster than the state-of-the-art method.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15472v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: ë°ì´í„°ì…‹ ì¦ë¥˜ëŠ” ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì—ì„œ ì†Œê·œëª¨ ë°ì´í„°ì…‹ì„ í•©ì„±í•˜ì—¬, ì´ë¥¼ í†µí•´ í•™ìŠµëœ ëª¨ë¸ì´ ì›ë³¸ ë°ì´í„°ì…‹ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë°œíœ˜í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ê³¼ ë‹¤ì¤‘ ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ ê¸‰ì†í•œ ë°œì „ê³¼ í•¨ê»˜, íŠ¹íˆ ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ë°ì´í„°ì…‹ê³¼ ê°™ì€ ë‹¤ì¤‘ ëª¨ë‹¬ ë°ì´í„°ì…‹ì˜ ì¤‘ìš”ì„±ì´ í¬ê²Œ ì¦ê°€í–ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê¸°ì¡´ì˜ ë‹¤ì¤‘ ëª¨ë‹¬ ë°ì´í„°ì…‹ ì¦ë¥˜ ë°©ë²•ì€ ë§¤ì¹­ í•™ìŠµ ê²½ë¡œ ì•Œê³ ë¦¬ì¦˜ì— ì˜í•´ ì œì•½ì„ ë°›ìœ¼ë©°, ì´ëŠ” ì»´í“¨íŒ… ìì› ìš”êµ¬ë¥¼ í¬ê²Œ ì¦ê°€ì‹œí‚¤ê³  ì¦ë¥˜ ê³¼ì •ì„ ë©°ì¹ ì— ê±¸ì³ ì²˜ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” íš¨ìœ¨ì ì¸ ë‹¤ì¤‘ ëª¨ë‹¬ ë°ì´í„°ì…‹ ì¦ë¥˜ë¥¼ ìœ„í•œ ìƒì„±ì  ì¦ë¥˜ ë°©ë²•ì¸ EDGEë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. êµ¬ì²´ì ìœ¼ë¡œ, ìš°ë¦¬ëŠ” ìƒì„± ëª¨ë¸ì„ ì‚¬ìš©í•œ ë‹¤ì¤‘ ëª¨ë‹¬ ë°ì´í„°ì…‹ ì¦ë¥˜ì˜ ë‘ ê°€ì§€ ì£¼ìš” ê³¼ì œë¥¼ ì‹ë³„í–ˆìŠµë‹ˆë‹¤: 1) ìƒì„±ëœ ì´ë¯¸ì§€ì™€ ìº¡ì…˜ ê°„ì˜ ìƒê´€ê´€ê³„ ë¶€ì¡±. 2) ìƒì„±ëœ ìƒ˜í”Œ ê°„ì˜ ë‹¤ì–‘ì„± ë¶€ì¡±. ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ì–‘ë°©í–¥ ëŒ€ì¡° ì†ì‹¤ê³¼ ë‹¤ì–‘ì„± ì†ì‹¤ì„ í¬í•¨í•œ ìƒˆë¡œìš´ ìƒì„± ëª¨ë¸ í•™ìŠµ ì›Œí¬í”Œë¡œìš°ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ë” ë‚˜ì•„ê°€, ìš°ë¦¬ëŠ” ë” ë§ì€ í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ë„ì…í•˜ì—¬ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ê²€ìƒ‰ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ìº¡ì…˜ í•©ì„± ì „ëµì„ ì œì•ˆí•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ë°©ë²•ì€ Flickr30K, COCO, CC3M ë°ì´í„°ì…‹ì—ì„œ í‰ê°€ë˜ì—ˆìœ¼ë©°, ê¸°ì¡´ ì ‘ê·¼ ë°©ì‹ì— ë¹„í•´ ë›°ì–´ë‚œ ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„±ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤. íŠ¹íˆ, ìš°ë¦¬ì˜ ë°©ë²•ì€ ìµœì²¨ë‹¨ ë°©ë²•ë³´ë‹¤ 18ë°° ë¹ ë¥¸ ê²°ê³¼ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì—ì„œ ì‘ì€ ë°ì´í„°ì…‹ì„ í•©ì„±í•˜ì—¬ ì›ë³¸ ë°ì´í„°ì…‹ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë°œíœ˜í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ë°ì´í„°ì…‹ ì¦ë¥˜ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. íŠ¹íˆ, ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ì™€ ê°™ì€ ë‹¤ì¤‘ ëª¨ë‹¬ ë°ì´í„°ì…‹ì˜ ì¤‘ìš”ì„±ì´ ì»¤ì§ì— ë”°ë¼, ê¸°ì¡´ ë°©ë²•ë¡ ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ EDGEë¼ëŠ” íš¨ìœ¨ì ì¸ ìƒì„±ì  ì¦ë¥˜ ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. EDGEëŠ” ìƒì„±ëœ ì´ë¯¸ì§€ì™€ ìº¡ì…˜ ê°„ì˜ ìƒê´€ì„± ë¶€ì¡± ë° ìƒ˜í”Œ ë‹¤ì–‘ì„± ë¶€ì¡± ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì–‘ë°©í–¥ ëŒ€ì¡° ì†ì‹¤ê³¼ ë‹¤ì–‘ì„± ì†ì‹¤ì„ í¬í•¨í•œ ìƒˆë¡œìš´ ìƒì„± ëª¨ë¸ í›ˆë ¨ ë°©ì‹ì„ ë„ì…í•©ë‹ˆë‹¤. ë˜í•œ, ìº¡ì…˜ í•©ì„± ì „ëµì„ í†µí•´ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ê²€ìƒ‰ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. Flickr30K, COCO, CC3M ë°ì´í„°ì…‹ì—ì„œì˜ ì‹¤í—˜ ê²°ê³¼, EDGEëŠ” ê¸°ì¡´ ë°©ë²•ë³´ë‹¤ 18ë°° ë¹ ë¥¸ ì†ë„ë¡œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë°ì´í„°ì…‹ ì¦ë¥˜ëŠ” í° ë°ì´í„°ì…‹ì—ì„œ ì‘ì€ ë°ì´í„°ì…‹ì„ í•©ì„±í•˜ì—¬ ì›ë³¸ ë°ì´í„°ì…‹ì—ì„œ ì˜ ì‘ë™í•˜ëŠ” ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¤ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•œë‹¤.
- 2. ê¸°ì¡´ì˜ ë©€í‹°ëª¨ë‹¬ ë°ì´í„°ì…‹ ì¦ë¥˜ ë°©ë²•ì€ ë†’ì€ ê³„ì‚° ìì›ì„ ìš”êµ¬í•˜ëŠ” Matching Training Trajectories ì•Œê³ ë¦¬ì¦˜ì— ì˜í•´ ì œí•œëœë‹¤.
- 3. EDGEëŠ” íš¨ìœ¨ì ì¸ ë©€í‹°ëª¨ë‹¬ ë°ì´í„°ì…‹ ì¦ë¥˜ë¥¼ ìœ„í•œ ìƒì„±ì  ì¦ë¥˜ ë°©ë²•ìœ¼ë¡œ, ìƒì„±ëœ ì´ë¯¸ì§€ì™€ ìº¡ì…˜ ê°„ì˜ ìƒê´€ê´€ê³„ ë¶€ì¡± ë° ìƒì„± ìƒ˜í”Œ ê°„ì˜ ë‹¤ì–‘ì„± ë¶€ì¡± ë¬¸ì œë¥¼ í•´ê²°í•œë‹¤.
- 4. ì œì•ˆëœ ë°©ë²•ì€ ì–‘ë°©í–¥ ëŒ€ì¡° ì†ì‹¤ê³¼ ë‹¤ì–‘ì„± ì†ì‹¤ì„ í¬í•¨í•œ ìƒˆë¡œìš´ ìƒì„± ëª¨ë¸ í›ˆë ¨ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‚¬ìš©í•œë‹¤.
- 5. Flickr30K, COCO, CC3M ë°ì´í„°ì…‹ì—ì„œ í‰ê°€ëœ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì€ ê¸°ì¡´ ë°©ë²•ë³´ë‹¤ 18ë°° ë¹ ë¥¸ ì†ë„ë¡œ ìš°ìˆ˜í•œ ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„±ì„ ë³´ì—¬ì¤€ë‹¤.


---

*Generated on 2025-09-23 11:57:52*