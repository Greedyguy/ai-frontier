---
keywords:
  - Deep Learning
  - Gaussian Noise Injection
  - Feature Stability
  - Class-wise Feature Alignment
  - Hessian Eigenvalues
category: cs.LG
publish_date: 2025-09-22
arxiv_id: 2405.18499
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:14:43.776558",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Deep Learning",
    "Gaussian Noise Injection",
    "Feature Stability",
    "Class-wise Feature Alignment",
    "Hessian Eigenvalues"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Deep Learning": 0.78,
    "Gaussian Noise Injection": 0.79,
    "Feature Stability": 0.77,
    "Class-wise Feature Alignment": 0.82,
    "Hessian Eigenvalues": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Robustness of deep neural networks",
        "canonical": "Deep Learning",
        "aliases": [
          "Robust Deep Learning",
          "Neural Network Robustness"
        ],
        "category": "broad_technical",
        "rationale": "Links to existing knowledge on improving neural network robustness, a key aspect of deep learning.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.78
      },
      {
        "surface": "Gaussian Noise Injection",
        "canonical": "Gaussian Noise Injection",
        "aliases": [
          "Noise Injection",
          "Additive Gaussian Noise"
        ],
        "category": "unique_technical",
        "rationale": "A specific technique discussed in the paper that enhances model robustness, useful for specialized linking.",
        "novelty_score": 0.72,
        "connectivity_score": 0.65,
        "specificity_score": 0.82,
        "link_intent_score": 0.79
      },
      {
        "surface": "Feature Stability",
        "canonical": "Feature Stability",
        "aliases": [
          "Stable Features",
          "Feature Robustness"
        ],
        "category": "unique_technical",
        "rationale": "Central to the paper's methodology, providing a novel approach to noise robustness.",
        "novelty_score": 0.68,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      },
      {
        "surface": "Class-wise Feature Alignment",
        "canonical": "Class-wise Feature Alignment",
        "aliases": [
          "Feature Alignment",
          "Class Feature Alignment"
        ],
        "category": "unique_technical",
        "rationale": "A novel mechanism proposed in the paper, enhancing connectivity in noise-robust model discussions.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.85,
        "link_intent_score": 0.82
      },
      {
        "surface": "Hessian Eigenvalues",
        "canonical": "Hessian Eigenvalues",
        "aliases": [
          "Curvature Analysis",
          "Eigenvalue Analysis"
        ],
        "category": "specific_connectable",
        "rationale": "Links to mathematical analysis of model robustness, relevant for theoretical discussions.",
        "novelty_score": 0.6,
        "connectivity_score": 0.72,
        "specificity_score": 0.78,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Robustness of deep neural networks",
      "resolved_canonical": "Deep Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Gaussian Noise Injection",
      "resolved_canonical": "Gaussian Noise Injection",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.65,
        "specificity": 0.82,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Feature Stability",
      "resolved_canonical": "Feature Stability",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Class-wise Feature Alignment",
      "resolved_canonical": "Class-wise Feature Alignment",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.85,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Hessian Eigenvalues",
      "resolved_canonical": "Hessian Eigenvalues",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.72,
        "specificity": 0.78,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Training More Robust Classification Model via Discriminative Loss and Gaussian Noise Injection

**Korean Title:** ë”ìš± ê²¬ê³ í•œ ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨: íŒë³„ ì†ì‹¤ê³¼ ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ ì£¼ì…ì„ í†µí•œ ì ‘ê·¼ë²•

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2405.18499.pdf)
**Category**: cs.LG
**Published**: 2025-09-22
**ArXiv ID**: [2405.18499](https://arxiv.org/abs/2405.18499)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Noise-Robustness Through Noise_ Asymmetric LoRA Adaption with Poisoning Expert_20250922|Noise-Robustness Through Noise: Asymmetric LoRA Adaption with Poisoning Expert]] (85.2% similar)
- [[2025-09-22/A noise-corrected Langevin algorithm and sampling by half-denoising_20250922|A noise-corrected Langevin algorithm and sampling by half-denoising]] (83.7% similar)
- [[2025-09-18/Not All Degradations Are Equal_ A Targeted Feature Denoising Framework for Generalizable Image Super-Resolution_20250918|Not All Degradations Are Equal: A Targeted Feature Denoising Framework for Generalizable Image Super-Resolution]] (83.3% similar)
- [[2025-09-22/Accelerated Gradient Methods with Biased Gradient Estimates_ Risk Sensitivity, High-Probability Guarantees, and Large Deviation Bounds_20250922|Accelerated Gradient Methods with Biased Gradient Estimates: Risk Sensitivity, High-Probability Guarantees, and Large Deviation Bounds]] (81.7% similar)
- [[2025-09-22/PCSR_ Pseudo-label Consistency-Guided Sample Refinement for Noisy Correspondence Learning_20250922|PCSR: Pseudo-label Consistency-Guided Sample Refinement for Noisy Correspondence Learning]] (81.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Deep Learning|Deep Learning]]
**ğŸ”— Specific Connectable**: [[keywords/Hessian Eigenvalues|Hessian Eigenvalues]]
**âš¡ Unique Technical**: [[keywords/Gaussian Noise Injection|Gaussian Noise Injection]], [[keywords/Feature Stability|Feature Stability]], [[keywords/Class-wise Feature Alignment|Class-wise Feature Alignment]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2405.18499v3 Announce Type: replace-cross 
Abstract: Robustness of deep neural networks to input noise remains a critical challenge, as naive noise injection often degrades accuracy on clean (uncorrupted) data. We propose a novel training framework that addresses this trade-off through two complementary objectives. First, we introduce a loss function applied at the penultimate layer that explicitly enforces intra-class compactness and increases the margin to analytically defined decision boundaries. This enhances feature discriminativeness and class separability for clean data. Second, we propose a class-wise feature alignment mechanism that brings noisy data clusters closer to their clean counterparts. Furthermore, we provide a theoretical analysis demonstrating that improving feature stability under additive Gaussian noise implicitly reduces the curvature of the softmax loss landscape in input space, as measured by Hessian eigenvalues.This thus naturally enhances robustness without explicit curvature penalties. Conversely, we also theoretically show that lower curvatures lead to more robust models. We validate the effectiveness of our method on standard benchmarks and our custom dataset. Our approach significantly reinforces model robustness to various perturbations while maintaining high accuracy on clean data, advancing the understanding and practice of noise-robust deep learning.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2405.18499v3 ë°œí‘œ ìœ í˜•: êµì°¨ êµì²´  
ì´ˆë¡: ì…ë ¥ ì¡ìŒì— ëŒ€í•œ ì‹¬ì¸µ ì‹ ê²½ë§ì˜ ê°•ê±´ì„±ì€ ì—¬ì „íˆ ì¤‘ìš”í•œ ê³¼ì œë¡œ ë‚¨ì•„ ìˆìœ¼ë©°, ë‹¨ìˆœí•œ ì¡ìŒ ì£¼ì…ì€ ì¢…ì¢… ê¹¨ë—í•œ(ì†ìƒë˜ì§€ ì•Šì€) ë°ì´í„°ì˜ ì •í™•ë„ë¥¼ ì €í•˜ì‹œí‚µë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì´ ìƒì¶© ê´€ê³„ë¥¼ ë‘ ê°€ì§€ ìƒí˜¸ ë³´ì™„ì ì¸ ëª©í‘œë¥¼ í†µí•´ í•´ê²°í•˜ëŠ” ìƒˆë¡œìš´ í›ˆë ¨ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì²«ì§¸, ìš°ë¦¬ëŠ” í´ë˜ìŠ¤ ë‚´ì˜ ë°€ì§‘ì„±ì„ ëª…ì‹œì ìœ¼ë¡œ ê°•í™”í•˜ê³  ë¶„ì„ì ìœ¼ë¡œ ì •ì˜ëœ ê²°ì • ê²½ê³„ì— ëŒ€í•œ ì—¬ìœ ë¥¼ ì¦ê°€ì‹œí‚¤ëŠ” ì†ì‹¤ í•¨ìˆ˜ë¥¼ ë§ˆì§€ë§‰ ì „ ì¸µì— ë„ì…í•©ë‹ˆë‹¤. ì´ëŠ” ê¹¨ë—í•œ ë°ì´í„°ì— ëŒ€í•œ íŠ¹ì§•ì˜ ë³€ë³„ë ¥ê³¼ í´ë˜ìŠ¤ ë¶„ë¦¬ë¥¼ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ë‘˜ì§¸, ìš°ë¦¬ëŠ” ì¡ìŒì´ ìˆëŠ” ë°ì´í„° í´ëŸ¬ìŠ¤í„°ë¥¼ ê·¸ë“¤ì˜ ê¹¨ë—í•œ ëŒ€ì‘ë¬¼ì— ë” ê°€ê¹ê²Œ ê°€ì ¸ì˜¤ëŠ” í´ë˜ìŠ¤ë³„ íŠ¹ì§• ì •ë ¬ ë©”ì»¤ë‹ˆì¦˜ì„ ì œì•ˆí•©ë‹ˆë‹¤. ë˜í•œ, ìš°ë¦¬ëŠ” ê°€ìš°ì‹œì•ˆ ì¡ìŒì´ ì¶”ê°€ëœ ìƒí™©ì—ì„œ íŠ¹ì§• ì•ˆì •ì„±ì„ í–¥ìƒì‹œí‚¤ëŠ” ê²ƒì´ ì…ë ¥ ê³µê°„ì—ì„œ ì†Œí”„íŠ¸ë§¥ìŠ¤ ì†ì‹¤ ì§€í˜•ì˜ ê³¡ë¥ ì„ ì•”ì‹œì ìœ¼ë¡œ ê°ì†Œì‹œí‚¨ë‹¤ëŠ” ì´ë¡ ì  ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ëŠ” í—¤ì„¸ í–‰ë ¬ì˜ ê³ ìœ ê°’ìœ¼ë¡œ ì¸¡ì •ë˜ë©°, ëª…ì‹œì ì¸ ê³¡ë¥  í˜ë„í‹° ì—†ì´ ìì—°ìŠ¤ëŸ½ê²Œ ê°•ê±´ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ë°˜ëŒ€ë¡œ, ìš°ë¦¬ëŠ” ë‚®ì€ ê³¡ë¥ ì´ ë” ê°•ê±´í•œ ëª¨ë¸ë¡œ ì´ì–´ì§„ë‹¤ëŠ” ê²ƒì„ ì´ë¡ ì ìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤. ìš°ë¦¬ëŠ” í‘œì¤€ ë²¤ì¹˜ë§ˆí¬ì™€ ì‚¬ìš©ì ì •ì˜ ë°ì´í„°ì…‹ì—ì„œ ìš°ë¦¬ì˜ ë°©ë²•ì˜ íš¨ê³¼ë¥¼ ê²€ì¦í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì ‘ê·¼ ë°©ì‹ì€ ë‹¤ì–‘í•œ êµë€ì— ëŒ€í•œ ëª¨ë¸ì˜ ê°•ê±´ì„±ì„ í¬ê²Œ ê°•í™”í•˜ë©´ì„œë„ ê¹¨ë—í•œ ë°ì´í„°ì— ëŒ€í•œ ë†’ì€ ì •í™•ë„ë¥¼ ìœ ì§€í•˜ì—¬ ì¡ìŒì— ê°•í•œ ì‹¬ì¸µ í•™ìŠµì˜ ì´í•´ì™€ ì‹¤ì²œì„ ë°œì „ì‹œí‚µë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì…ë ¥ ë…¸ì´ì¦ˆì— ëŒ€í•œ ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ ê°•ê±´ì„±ì„ ê°œì„ í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ í›ˆë ¨ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì£¼ìš” ê¸°ì—¬ëŠ” ë‘ ê°€ì§€ ëª©í‘œë¥¼ í†µí•´ ë…¸ì´ì¦ˆì— ëŒ€í•œ ê°•ê±´ì„±ì„ ë†’ì´ë©´ì„œë„ ê¹¨ë—í•œ ë°ì´í„°ì— ëŒ€í•œ ì •í™•ì„±ì„ ìœ ì§€í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì²«ì§¸, ë§ˆì§€ë§‰ ì´ì „ ì¸µì—ì„œì˜ ì†ì‹¤ í•¨ìˆ˜ë¥¼ ë„ì…í•˜ì—¬ í´ë˜ìŠ¤ ë‚´ì˜ ì»´íŒ©íŠ¸ì„±ì„ ê°•í™”í•˜ê³  ê²°ì • ê²½ê³„ì˜ ë§ˆì§„ì„ ì¦ê°€ì‹œì¼œ ê¹¨ë—í•œ ë°ì´í„°ì˜ íŠ¹ì§• êµ¬ë³„ì„±ê³¼ í´ë˜ìŠ¤ ë¶„ë¦¬ë¥¼ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ë‘˜ì§¸, í´ë˜ìŠ¤ë³„ íŠ¹ì§• ì •ë ¬ ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´ ë…¸ì´ì¦ˆ ë°ì´í„° í´ëŸ¬ìŠ¤í„°ë¥¼ ê¹¨ë—í•œ ë°ì´í„°ì— ê°€ê¹ê²Œ ë§Œë“­ë‹ˆë‹¤. ì´ë¡ ì ìœ¼ë¡œëŠ” ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ í•˜ì—ì„œì˜ íŠ¹ì§• ì•ˆì •ì„± í–¥ìƒì´ ì…ë ¥ ê³µê°„ì—ì„œ ì†Œí”„íŠ¸ë§¥ìŠ¤ ì†ì‹¤ì˜ ê³¡ë¥ ì„ ê°ì†Œì‹œí‚¨ë‹¤ëŠ” ê²ƒì„ ë³´ì´ë©°, ì´ëŠ” ê³¡ë¥  í˜ë„í‹° ì—†ì´ ìì—°ìŠ¤ëŸ½ê²Œ ê°•ê±´ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ì™€ ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ì„ í†µí•´ ì´ ë°©ë²•ì˜ íš¨ê³¼ë¥¼ ê²€ì¦í•˜ë©°, ë…¸ì´ì¦ˆì— ëŒ€í•œ ê°•ê±´ì„±ì„ ê°•í™”í•˜ë©´ì„œë„ ê¹¨ë—í•œ ë°ì´í„°ì— ëŒ€í•œ ë†’ì€ ì •í™•ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì…ë ¥ ë…¸ì´ì¦ˆì— ëŒ€í•œ ì‹¬ì¸µ ì‹ ê²½ë§ì˜ ê°•ê±´ì„±ì„ ê°œì„ í•˜ê¸° ìœ„í•´ ë‘ ê°€ì§€ ìƒí˜¸ ë³´ì™„ì ì¸ ëª©í‘œë¥¼ ì œì•ˆí•˜ëŠ” ìƒˆë¡œìš´ í›ˆë ¨ í”„ë ˆì„ì›Œí¬ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤.
- 2. ì „ì´ì¸µì—ì„œì˜ ì†ì‹¤ í•¨ìˆ˜ë¥¼ í†µí•´ í´ë˜ìŠ¤ ë‚´ ì••ì¶•ì„±ì„ ê°•í™”í•˜ê³  ê²°ì • ê²½ê³„ì˜ ì—¬ìœ ë¥¼ ì¦ê°€ì‹œì¼œ ê¹¨ë—í•œ ë°ì´í„°ì— ëŒ€í•œ íŠ¹ì§• êµ¬ë³„ì„±ê³¼ í´ë˜ìŠ¤ ë¶„ë¦¬ë¥¼ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
- 3. í´ë˜ìŠ¤ë³„ íŠ¹ì§• ì •ë ¬ ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´ ë…¸ì´ì¦ˆê°€ ìˆëŠ” ë°ì´í„° í´ëŸ¬ìŠ¤í„°ë¥¼ ê¹¨ë—í•œ ë°ì´í„°ì™€ ë” ê°€ê¹ê²Œ ë§Œë“­ë‹ˆë‹¤.
- 4. ì´ë¡ ì  ë¶„ì„ì„ í†µí•´ ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ í•˜ì—ì„œì˜ íŠ¹ì§• ì•ˆì •ì„± ê°œì„ ì´ ì…ë ¥ ê³µê°„ì—ì„œ ì†Œí”„íŠ¸ë§¥ìŠ¤ ì†ì‹¤ ì§€í˜•ì˜ ê³¡ë¥ ì„ ê°ì†Œì‹œí‚¨ë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
- 5. ì œì•ˆëœ ë°©ë²•ì´ ë‹¤ì–‘í•œ êµë€ì— ëŒ€í•œ ëª¨ë¸ì˜ ê°•ê±´ì„±ì„ ê°•í™”í•˜ë©´ì„œë„ ê¹¨ë—í•œ ë°ì´í„°ì— ëŒ€í•œ ë†’ì€ ì •í™•ì„±ì„ ìœ ì§€í•¨ì„ í‘œì¤€ ë²¤ì¹˜ë§ˆí¬ì™€ ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ì„ í†µí•´ ê²€ì¦í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-23 11:14:43*