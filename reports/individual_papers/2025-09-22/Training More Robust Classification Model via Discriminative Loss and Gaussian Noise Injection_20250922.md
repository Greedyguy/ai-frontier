---
keywords:
  - Deep Learning
  - Gaussian Noise Injection
  - Feature Stability
  - Class-wise Feature Alignment
  - Hessian Eigenvalues
category: cs.LG
publish_date: 2025-09-22
arxiv_id: 2405.18499
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:14:43.776558",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Deep Learning",
    "Gaussian Noise Injection",
    "Feature Stability",
    "Class-wise Feature Alignment",
    "Hessian Eigenvalues"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Deep Learning": 0.78,
    "Gaussian Noise Injection": 0.79,
    "Feature Stability": 0.77,
    "Class-wise Feature Alignment": 0.82,
    "Hessian Eigenvalues": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Robustness of deep neural networks",
        "canonical": "Deep Learning",
        "aliases": [
          "Robust Deep Learning",
          "Neural Network Robustness"
        ],
        "category": "broad_technical",
        "rationale": "Links to existing knowledge on improving neural network robustness, a key aspect of deep learning.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.78
      },
      {
        "surface": "Gaussian Noise Injection",
        "canonical": "Gaussian Noise Injection",
        "aliases": [
          "Noise Injection",
          "Additive Gaussian Noise"
        ],
        "category": "unique_technical",
        "rationale": "A specific technique discussed in the paper that enhances model robustness, useful for specialized linking.",
        "novelty_score": 0.72,
        "connectivity_score": 0.65,
        "specificity_score": 0.82,
        "link_intent_score": 0.79
      },
      {
        "surface": "Feature Stability",
        "canonical": "Feature Stability",
        "aliases": [
          "Stable Features",
          "Feature Robustness"
        ],
        "category": "unique_technical",
        "rationale": "Central to the paper's methodology, providing a novel approach to noise robustness.",
        "novelty_score": 0.68,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      },
      {
        "surface": "Class-wise Feature Alignment",
        "canonical": "Class-wise Feature Alignment",
        "aliases": [
          "Feature Alignment",
          "Class Feature Alignment"
        ],
        "category": "unique_technical",
        "rationale": "A novel mechanism proposed in the paper, enhancing connectivity in noise-robust model discussions.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.85,
        "link_intent_score": 0.82
      },
      {
        "surface": "Hessian Eigenvalues",
        "canonical": "Hessian Eigenvalues",
        "aliases": [
          "Curvature Analysis",
          "Eigenvalue Analysis"
        ],
        "category": "specific_connectable",
        "rationale": "Links to mathematical analysis of model robustness, relevant for theoretical discussions.",
        "novelty_score": 0.6,
        "connectivity_score": 0.72,
        "specificity_score": 0.78,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Robustness of deep neural networks",
      "resolved_canonical": "Deep Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Gaussian Noise Injection",
      "resolved_canonical": "Gaussian Noise Injection",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.65,
        "specificity": 0.82,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Feature Stability",
      "resolved_canonical": "Feature Stability",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Class-wise Feature Alignment",
      "resolved_canonical": "Class-wise Feature Alignment",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.85,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Hessian Eigenvalues",
      "resolved_canonical": "Hessian Eigenvalues",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.72,
        "specificity": 0.78,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Training More Robust Classification Model via Discriminative Loss and Gaussian Noise Injection

**Korean Title:** 더욱 견고한 분류 모델 훈련: 판별 손실과 가우시안 노이즈 주입을 통한 접근법

## 📋 메타데이터

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2405.18499.pdf)
**Category**: cs.LG
**Published**: 2025-09-22
**ArXiv ID**: [2405.18499](https://arxiv.org/abs/2405.18499)

## 🔗 유사한 논문
- [[2025-09-22/Noise-Robustness Through Noise_ Asymmetric LoRA Adaption with Poisoning Expert_20250922|Noise-Robustness Through Noise: Asymmetric LoRA Adaption with Poisoning Expert]] (85.2% similar)
- [[2025-09-22/A noise-corrected Langevin algorithm and sampling by half-denoising_20250922|A noise-corrected Langevin algorithm and sampling by half-denoising]] (83.7% similar)
- [[2025-09-18/Not All Degradations Are Equal_ A Targeted Feature Denoising Framework for Generalizable Image Super-Resolution_20250918|Not All Degradations Are Equal: A Targeted Feature Denoising Framework for Generalizable Image Super-Resolution]] (83.3% similar)
- [[2025-09-22/Accelerated Gradient Methods with Biased Gradient Estimates_ Risk Sensitivity, High-Probability Guarantees, and Large Deviation Bounds_20250922|Accelerated Gradient Methods with Biased Gradient Estimates: Risk Sensitivity, High-Probability Guarantees, and Large Deviation Bounds]] (81.7% similar)
- [[2025-09-22/PCSR_ Pseudo-label Consistency-Guided Sample Refinement for Noisy Correspondence Learning_20250922|PCSR: Pseudo-label Consistency-Guided Sample Refinement for Noisy Correspondence Learning]] (81.6% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Deep Learning|Deep Learning]]
**🔗 Specific Connectable**: [[keywords/Hessian Eigenvalues|Hessian Eigenvalues]]
**⚡ Unique Technical**: [[keywords/Gaussian Noise Injection|Gaussian Noise Injection]], [[keywords/Feature Stability|Feature Stability]], [[keywords/Class-wise Feature Alignment|Class-wise Feature Alignment]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2405.18499v3 Announce Type: replace-cross 
Abstract: Robustness of deep neural networks to input noise remains a critical challenge, as naive noise injection often degrades accuracy on clean (uncorrupted) data. We propose a novel training framework that addresses this trade-off through two complementary objectives. First, we introduce a loss function applied at the penultimate layer that explicitly enforces intra-class compactness and increases the margin to analytically defined decision boundaries. This enhances feature discriminativeness and class separability for clean data. Second, we propose a class-wise feature alignment mechanism that brings noisy data clusters closer to their clean counterparts. Furthermore, we provide a theoretical analysis demonstrating that improving feature stability under additive Gaussian noise implicitly reduces the curvature of the softmax loss landscape in input space, as measured by Hessian eigenvalues.This thus naturally enhances robustness without explicit curvature penalties. Conversely, we also theoretically show that lower curvatures lead to more robust models. We validate the effectiveness of our method on standard benchmarks and our custom dataset. Our approach significantly reinforces model robustness to various perturbations while maintaining high accuracy on clean data, advancing the understanding and practice of noise-robust deep learning.

## 🔍 Abstract (한글 번역)

arXiv:2405.18499v3 발표 유형: 교차 교체  
초록: 입력 잡음에 대한 심층 신경망의 강건성은 여전히 중요한 과제로 남아 있으며, 단순한 잡음 주입은 종종 깨끗한(손상되지 않은) 데이터의 정확도를 저하시킵니다. 우리는 이 상충 관계를 두 가지 상호 보완적인 목표를 통해 해결하는 새로운 훈련 프레임워크를 제안합니다. 첫째, 우리는 클래스 내의 밀집성을 명시적으로 강화하고 분석적으로 정의된 결정 경계에 대한 여유를 증가시키는 손실 함수를 마지막 전 층에 도입합니다. 이는 깨끗한 데이터에 대한 특징의 변별력과 클래스 분리를 향상시킵니다. 둘째, 우리는 잡음이 있는 데이터 클러스터를 그들의 깨끗한 대응물에 더 가깝게 가져오는 클래스별 특징 정렬 메커니즘을 제안합니다. 또한, 우리는 가우시안 잡음이 추가된 상황에서 특징 안정성을 향상시키는 것이 입력 공간에서 소프트맥스 손실 지형의 곡률을 암시적으로 감소시킨다는 이론적 분석을 제공합니다. 이는 헤세 행렬의 고유값으로 측정되며, 명시적인 곡률 페널티 없이 자연스럽게 강건성을 향상시킵니다. 반대로, 우리는 낮은 곡률이 더 강건한 모델로 이어진다는 것을 이론적으로 보여줍니다. 우리는 표준 벤치마크와 사용자 정의 데이터셋에서 우리의 방법의 효과를 검증합니다. 우리의 접근 방식은 다양한 교란에 대한 모델의 강건성을 크게 강화하면서도 깨끗한 데이터에 대한 높은 정확도를 유지하여 잡음에 강한 심층 학습의 이해와 실천을 발전시킵니다.

## 📝 요약

이 논문은 입력 노이즈에 대한 딥러닝 모델의 강건성을 개선하기 위한 새로운 훈련 프레임워크를 제안합니다. 주요 기여는 두 가지 목표를 통해 노이즈에 대한 강건성을 높이면서도 깨끗한 데이터에 대한 정확성을 유지하는 것입니다. 첫째, 마지막 이전 층에서의 손실 함수를 도입하여 클래스 내의 컴팩트성을 강화하고 결정 경계의 마진을 증가시켜 깨끗한 데이터의 특징 구별성과 클래스 분리를 향상시킵니다. 둘째, 클래스별 특징 정렬 메커니즘을 통해 노이즈 데이터 클러스터를 깨끗한 데이터에 가깝게 만듭니다. 이론적으로는 가우시안 노이즈 하에서의 특징 안정성 향상이 입력 공간에서 소프트맥스 손실의 곡률을 감소시킨다는 것을 보이며, 이는 곡률 페널티 없이 자연스럽게 강건성을 향상시킵니다. 다양한 벤치마크와 커스텀 데이터셋을 통해 이 방법의 효과를 검증하며, 노이즈에 대한 강건성을 강화하면서도 깨끗한 데이터에 대한 높은 정확성을 유지합니다.

## 🎯 주요 포인트

- 1. 입력 노이즈에 대한 심층 신경망의 강건성을 개선하기 위해 두 가지 상호 보완적인 목표를 제안하는 새로운 훈련 프레임워크를 소개합니다.
- 2. 전이층에서의 손실 함수를 통해 클래스 내 압축성을 강화하고 결정 경계의 여유를 증가시켜 깨끗한 데이터에 대한 특징 구별성과 클래스 분리를 향상시킵니다.
- 3. 클래스별 특징 정렬 메커니즘을 통해 노이즈가 있는 데이터 클러스터를 깨끗한 데이터와 더 가깝게 만듭니다.
- 4. 이론적 분석을 통해 가우시안 노이즈 하에서의 특징 안정성 개선이 입력 공간에서 소프트맥스 손실 지형의 곡률을 감소시킨다는 것을 보여줍니다.
- 5. 제안된 방법이 다양한 교란에 대한 모델의 강건성을 강화하면서도 깨끗한 데이터에 대한 높은 정확성을 유지함을 표준 벤치마크와 커스텀 데이터셋을 통해 검증합니다.


---

*Generated on 2025-09-23 11:14:43*