---
keywords:
  - Large Language Model
  - Supervised Fine-Tuning
  - Direct Preference Optimization
  - Synthetic Data Generation
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2508.15432
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T09:40:05.670254",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Supervised Fine-Tuning",
    "Direct Preference Optimization",
    "Synthetic Data Generation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Supervised Fine-Tuning": 0.8,
    "Direct Preference Optimization": 0.78,
    "Synthetic Data Generation": 0.82
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Connects to a wide range of discussions on language model advancements and datasets.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Supervised Fine-Tuning",
        "canonical": "Supervised Fine-Tuning",
        "aliases": [
          "SFT"
        ],
        "category": "specific_connectable",
        "rationale": "Key process in adapting models, relevant to both existing and emerging techniques.",
        "novelty_score": 0.7,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.8
      },
      {
        "surface": "Direct Preference Optimization",
        "canonical": "Direct Preference Optimization",
        "aliases": [
          "DPO"
        ],
        "category": "unique_technical",
        "rationale": "A specific alignment task that is critical for model performance tuning.",
        "novelty_score": 0.8,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Synthetic Data Generation",
        "canonical": "Synthetic Data Generation",
        "aliases": [
          "Data Synthesis"
        ],
        "category": "unique_technical",
        "rationale": "Central to the paper's framework, facilitating scalable data creation for model training.",
        "novelty_score": 0.75,
        "connectivity_score": 0.7,
        "specificity_score": 0.9,
        "link_intent_score": 0.82
      }
    ],
    "ban_list_suggestions": [
      "framework",
      "pipeline",
      "mechanism"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Supervised Fine-Tuning",
      "resolved_canonical": "Supervised Fine-Tuning",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Direct Preference Optimization",
      "resolved_canonical": "Direct Preference Optimization",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Synthetic Data Generation",
      "resolved_canonical": "Synthetic Data Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.7,
        "specificity": 0.9,
        "link_intent": 0.82
      }
    }
  ]
}
-->

# SyGra: A Unified Graph-Based Framework for Scalable Generation, Quality Tagging, and Management of Synthetic Data

**Korean Title:** SyGra: í•©ì„± ë°ì´í„°ì˜ í™•ì¥ ê°€ëŠ¥í•œ ìƒì„±, í’ˆì§ˆ íƒœê¹… ë° ê´€ë¦¬ì— ëŒ€í•œ í†µí•© ê·¸ë˜í”„ ê¸°ë°˜ í”„ë ˆì„ì›Œí¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2508.15432.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2508.15432](https://arxiv.org/abs/2508.15432)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages_20250922|A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages]] (86.8% similar)
- [[2025-09-19/Middo_ Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning_20250919|Middo: Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning]] (85.6% similar)
- [[2025-09-17/Synthetic Data Generation for Screen Time and App Usage_20250917|Synthetic Data Generation for Screen Time and App Usage]] (83.9% similar)
- [[2025-09-22/LiteLong_ Resource-Efficient Long-Context Data Synthesis for LLMs_20250922|LiteLong: Resource-Efficient Long-Context Data Synthesis for LLMs]] (83.1% similar)
- [[2025-09-19/Enhancing Logical Reasoning in Language Models via Symbolically-Guided Monte Carlo Process Supervision_20250919|Enhancing Logical Reasoning in Language Models via Symbolically-Guided Monte Carlo Process Supervision]] (82.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Supervised Fine-Tuning|Supervised Fine-Tuning]]
**âš¡ Unique Technical**: [[keywords/Direct Preference Optimization|Direct Preference Optimization]], [[keywords/Synthetic Data Generation|Synthetic Data Generation]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2508.15432v2 Announce Type: replace 
Abstract: The advancement of large language models (LLMs) is critically dependent on the availability of high-quality datasets for Supervised Fine-Tuning (SFT), alignment tasks like Direct Preference Optimization (DPO), etc. In this work, we present a comprehensive synthetic data generation framework that facilitates scalable, configurable, and high-fidelity generation of synthetic data tailored for these training paradigms. Our approach employs a modular and configuration-based pipeline capable of modeling complex dialogue flows with minimal manual intervention. This framework uses a dual-stage quality tagging mechanism, combining heuristic rules and LLM-based evaluations, to automatically filter and score data extracted from OASST-formatted conversations, ensuring the curation of high-quality dialogue samples. The resulting datasets are structured under a flexible schema supporting both SFT and DPO use cases, enabling seamless integration into diverse training workflows. Together, these innovations offer a robust solution for generating and managing synthetic conversational data at scale, significantly reducing the overhead of data preparation in LLM training pipelines.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2508.15432v2 ë°œí‘œ ìœ í˜•: êµì²´  
ì´ˆë¡: ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ë°œì „ì€ ê°ë…ëœ ë¯¸ì„¸ ì¡°ì •(SFT), ì§ì ‘ ì„ í˜¸ ìµœì í™”(DPO)ì™€ ê°™ì€ ì •ë ¬ ì‘ì—…ì„ ìœ„í•œ ê³ í’ˆì§ˆ ë°ì´í„°ì…‹ì˜ ê°€ìš©ì„±ì— í¬ê²Œ ì˜ì¡´í•©ë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” ì´ëŸ¬í•œ í›ˆë ¨ íŒ¨ëŸ¬ë‹¤ì„ì— ë§ì¶˜ í•©ì„± ë°ì´í„°ë¥¼ í™•ì¥ ê°€ëŠ¥í•˜ê³  êµ¬ì„± ê°€ëŠ¥í•˜ë©° ë†’ì€ ì¶©ì‹¤ë„ë¡œ ìƒì„±í•  ìˆ˜ ìˆëŠ” ì¢…í•©ì ì¸ í•©ì„± ë°ì´í„° ìƒì„± í”„ë ˆì„ì›Œí¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì ‘ê·¼ë²•ì€ ìµœì†Œí•œì˜ ìˆ˜ì‘ì—… ê°œì…ìœ¼ë¡œ ë³µì¡í•œ ëŒ€í™” íë¦„ì„ ëª¨ë¸ë§í•  ìˆ˜ ìˆëŠ” ëª¨ë“ˆì‹ ë° êµ¬ì„± ê¸°ë°˜ íŒŒì´í”„ë¼ì¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” íœ´ë¦¬ìŠ¤í‹± ê·œì¹™ê³¼ LLM ê¸°ë°˜ í‰ê°€ë¥¼ ê²°í•©í•œ ì´ì¤‘ ë‹¨ê³„ í’ˆì§ˆ íƒœê·¸ ë©”ì»¤ë‹ˆì¦˜ì„ ì‚¬ìš©í•˜ì—¬ OASST í˜•ì‹ì˜ ëŒ€í™”ì—ì„œ ì¶”ì¶œí•œ ë°ì´í„°ë¥¼ ìë™ìœ¼ë¡œ í•„í„°ë§í•˜ê³  ì ìˆ˜ë¥¼ ë§¤ê²¨ ê³ í’ˆì§ˆ ëŒ€í™” ìƒ˜í”Œì„ ì„ ë³„í•©ë‹ˆë‹¤. ê²°ê³¼ ë°ì´í„°ì…‹ì€ SFT ë° DPO ì‚¬ìš© ì‚¬ë¡€ ëª¨ë‘ë¥¼ ì§€ì›í•˜ëŠ” ìœ ì—°í•œ ìŠ¤í‚¤ë§ˆë¡œ êµ¬ì¡°í™”ë˜ì–´ ë‹¤ì–‘í•œ í›ˆë ¨ ì›Œí¬í”Œë¡œìš°ì— ì›í™œí•˜ê²Œ í†µí•©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ í˜ì‹ ì€ ëŒ€ê·œëª¨ë¡œ í•©ì„± ëŒ€í™” ë°ì´í„°ë¥¼ ìƒì„±í•˜ê³  ê´€ë¦¬í•˜ê¸° ìœ„í•œ ê°•ë ¥í•œ ì†”ë£¨ì…˜ì„ ì œê³µí•˜ì—¬ LLM í›ˆë ¨ íŒŒì´í”„ë¼ì¸ì—ì„œ ë°ì´í„° ì¤€ë¹„ì˜ ë¶€ë‹´ì„ í¬ê²Œ ì¤„ì…ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ë°œì „ì„ ìœ„í•œ ê³ í’ˆì§ˆ ë°ì´í„°ì…‹ ìƒì„± í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ê°ë…ëœ ë¯¸ì„¸ ì¡°ì •(SFT)ê³¼ ì§ì ‘ ì„ í˜¸ ìµœì í™”(DPO)ì™€ ê°™ì€ ì‘ì—…ì— ì í•©í•œ í•©ì„± ë°ì´í„°ë¥¼ ëŒ€ê·œëª¨ë¡œ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ëª¨ë“ˆí˜• ë° êµ¬ì„± ê¸°ë°˜ íŒŒì´í”„ë¼ì¸ì„ ì‚¬ìš©í•˜ì—¬ ë³µì¡í•œ ëŒ€í™” íë¦„ì„ ìµœì†Œí•œì˜ ìˆ˜ì‘ì—…ìœ¼ë¡œ ëª¨ë¸ë§í•˜ë©°, ì´ì¤‘ ë‹¨ê³„ í’ˆì§ˆ íƒœê·¸ ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´ ìë™ìœ¼ë¡œ ë°ì´í„°ë¥¼ í•„í„°ë§í•˜ê³  í‰ê°€í•©ë‹ˆë‹¤. ê²°ê³¼ì ìœ¼ë¡œ ìƒì„±ëœ ë°ì´í„°ì…‹ì€ ë‹¤ì–‘í•œ í›ˆë ¨ ì›Œí¬í”Œë¡œìš°ì— ì‰½ê²Œ í†µí•©ë  ìˆ˜ ìˆëŠ” ìœ ì—°í•œ êµ¬ì¡°ë¥¼ ê°€ì§€ë©°, LLM í›ˆë ¨ ê³¼ì •ì—ì„œ ë°ì´í„° ì¤€ë¹„ì˜ ë¶€ë‹´ì„ í¬ê²Œ ì¤„ì…ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ë°œì „ì€ ê³ í’ˆì§ˆ ë°ì´í„°ì…‹ì˜ ê°€ìš©ì„±ì— í¬ê²Œ ì˜ì¡´í•©ë‹ˆë‹¤.
- 2. ë³¸ ì—°êµ¬ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ í›ˆë ¨ì„ ìœ„í•œ í•©ì„± ë°ì´í„° ìƒì„± í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.
- 3. ì œì•ˆëœ í”„ë ˆì„ì›Œí¬ëŠ” ìµœì†Œí•œì˜ ìˆ˜ì‘ì—… ê°œì…ìœ¼ë¡œ ë³µì¡í•œ ëŒ€í™” íë¦„ì„ ëª¨ë¸ë§í•  ìˆ˜ ìˆëŠ” ëª¨ë“ˆí˜• ë° êµ¬ì„± ê¸°ë°˜ íŒŒì´í”„ë¼ì¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
- 4. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ì´ì¤‘ ë‹¨ê³„ í’ˆì§ˆ íƒœê¹… ë©”ì»¤ë‹ˆì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ê³ í’ˆì§ˆ ëŒ€í™” ìƒ˜í”Œì„ ìë™ìœ¼ë¡œ í•„í„°ë§í•˜ê³  í‰ê°€í•©ë‹ˆë‹¤.
- 5. ìƒì„±ëœ ë°ì´í„°ì…‹ì€ ë‹¤ì–‘í•œ í›ˆë ¨ ì›Œí¬í”Œë¡œìš°ì— ì›í™œí•˜ê²Œ í†µí•©ë  ìˆ˜ ìˆë„ë¡ ìœ ì—°í•œ ìŠ¤í‚¤ë§ˆë¡œ êµ¬ì¡°í™”ë©ë‹ˆë‹¤.


---

*Generated on 2025-09-23 09:40:05*