---
keywords:
  - Vision-Language Model
  - Object Recognition in Incongruous Context Benchmark
  - LLM-guided sampling
  - CLIP-guided sampling
  - contextual incongruity
category: cs.LG
publish_date: 2025-09-22
arxiv_id: 2509.15695
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T10:51:44.628683",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Vision-Language Model",
    "Object Recognition in Incongruous Context Benchmark",
    "LLM-guided sampling",
    "CLIP-guided sampling",
    "contextual incongruity"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Vision-Language Model": 0.85,
    "Object Recognition in Incongruous Context Benchmark": 0.78,
    "LLM-guided sampling": 0.72,
    "CLIP-guided sampling": 0.74,
    "contextual incongruity": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Vision-Language Models",
        "canonical": "Vision-Language Model",
        "aliases": [
          "LVLMs"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-Language Models are central to the paper's focus on integrating visual and textual information, making it a key concept for linking.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Object Recognition in Incongruous Context Benchmark",
        "canonical": "Object Recognition in Incongruous Context Benchmark",
        "aliases": [
          "ORIC"
        ],
        "category": "unique_technical",
        "rationale": "ORIC is a novel benchmark introduced in the paper, crucial for understanding the evaluation of LVLMs in unexpected contexts.",
        "novelty_score": 0.92,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "LLM-guided sampling",
        "canonical": "LLM-guided sampling",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This method is specific to the paper's approach to identifying contextually incongruous objects, offering unique insights.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.78,
        "link_intent_score": 0.72
      },
      {
        "surface": "CLIP-guided sampling",
        "canonical": "CLIP-guided sampling",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "CLIP-guided sampling is a distinct technique used in the paper to detect hallucinated objects, highlighting its innovative approach.",
        "novelty_score": 0.8,
        "connectivity_score": 0.62,
        "specificity_score": 0.8,
        "link_intent_score": 0.74
      },
      {
        "surface": "contextual incongruity",
        "canonical": "contextual incongruity",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Understanding contextual incongruity is essential for linking the paper's discussion on recognition failures in LVLMs.",
        "novelty_score": 0.65,
        "connectivity_score": 0.75,
        "specificity_score": 0.72,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "errors",
      "recognition failures",
      "context"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Vision-Language Models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Object Recognition in Incongruous Context Benchmark",
      "resolved_canonical": "Object Recognition in Incongruous Context Benchmark",
      "decision": "linked",
      "scores": {
        "novelty": 0.92,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "LLM-guided sampling",
      "resolved_canonical": "LLM-guided sampling",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.78,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "CLIP-guided sampling",
      "resolved_canonical": "CLIP-guided sampling",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.62,
        "specificity": 0.8,
        "link_intent": 0.74
      }
    },
    {
      "candidate_surface": "contextual incongruity",
      "resolved_canonical": "contextual incongruity",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.75,
        "specificity": 0.72,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# ORIC: Benchmarking Object Recognition in Incongruous Context for Large Vision-Language Models

**Korean Title:** ORIC: 대규모 비전-언어 모델을 위한 부조화 맥락에서의 객체 인식 벤치마킹

## 📋 메타데이터

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15695.pdf)
**Category**: cs.LG
**Published**: 2025-09-22
**ArXiv ID**: [2509.15695](https://arxiv.org/abs/2509.15695)

## 🔗 유사한 논문
- [[2025-09-22/ORCA_ Agentic Reasoning For Hallucination and Adversarial Robustness in Vision-Language Models_20250922|ORCA: Agentic Reasoning For Hallucination and Adversarial Robustness in Vision-Language Models]] (88.7% similar)
- [[2025-09-22/Perception-R1_ Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward_20250922|Perception-R1: Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward]] (82.5% similar)
- [[2025-09-18/The Art of Saying "Maybe"_ A Conformal Lens for Uncertainty Benchmarking in VLMs_20250918|The Art of Saying "Maybe": A Conformal Lens for Uncertainty Benchmarking in VLMs]] (81.5% similar)
- [[2025-09-22/Cache-of-Thought_ Master-Apprentice Framework for Cost-Effective Vision Language Model Reasoning_20250922|Cache-of-Thought: Master-Apprentice Framework for Cost-Effective Vision Language Model Reasoning]] (81.5% similar)
- [[2025-09-22/LLMs Can Compensate for Deficiencies in Visual Representations_20250922|LLMs Can Compensate for Deficiencies in Visual Representations]] (81.1% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/contextual incongruity|contextual incongruity]]
**⚡ Unique Technical**: [[keywords/Object Recognition in Incongruous Context Benchmark|Object Recognition in Incongruous Context Benchmark]], [[keywords/LLM-guided sampling|LLM-guided sampling]], [[keywords/CLIP-guided sampling|CLIP-guided sampling]]
**🚀 Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.15695v1 Announce Type: cross 
Abstract: Large Vision-Language Models (LVLMs) have made significant strides in image caption, visual question answering, and robotics by integrating visual and textual information. However, they remain prone to errors in incongruous contexts, where objects appear unexpectedly or are absent when contextually expected. This leads to two key recognition failures: object misidentification and hallucination. To systematically examine this issue, we introduce the Object Recognition in Incongruous Context Benchmark (ORIC), a novel benchmark that evaluates LVLMs in scenarios where object-context relationships deviate from expectations. ORIC employs two key strategies: (1) LLM-guided sampling, which identifies objects that are present but contextually incongruous, and (2) CLIP-guided sampling, which detects plausible yet nonexistent objects that are likely to be hallucinated, thereby creating an incongruous context. Evaluating 18 LVLMs and two open-vocabulary detection models, our results reveal significant recognition gaps, underscoring the challenges posed by contextual incongruity. This work provides critical insights into LVLMs' limitations and encourages further research on context-aware object recognition.

## 🔍 Abstract (한글 번역)

arXiv:2509.15695v1 발표 유형: 교차  
초록: 대형 비전-언어 모델(LVLMs)은 시각적 및 텍스트 정보를 통합하여 이미지 캡션, 시각적 질문 응답 및 로봇 공학 분야에서 상당한 발전을 이루었습니다. 그러나 이러한 모델은 예상치 못한 상황에서 객체가 나타나거나 맥락상 예상되는 객체가 없는 경우와 같은 불일치한 맥락에서 오류에 취약합니다. 이는 두 가지 주요 인식 실패로 이어집니다: 객체 오인식과 환각. 이 문제를 체계적으로 조사하기 위해, 우리는 객체-맥락 관계가 기대와 벗어나는 시나리오에서 LVLMs를 평가하는 새로운 벤치마크인 불일치한 맥락에서의 객체 인식 벤치마크(ORIC)를 소개합니다. ORIC는 두 가지 주요 전략을 사용합니다: (1) LLM-유도 샘플링, 이는 존재하지만 맥락상 불일치한 객체를 식별하며, (2) CLIP-유도 샘플링, 이는 환각될 가능성이 높은 그럴듯하지만 존재하지 않는 객체를 감지하여 불일치한 맥락을 생성합니다. 18개의 LVLMs와 두 개의 개방형 어휘 탐지 모델을 평가한 결과, 맥락적 불일치로 인한 인식 격차가 상당함을 밝혀내어, 맥락적 불일치가 제기하는 도전 과제를 강조합니다. 이 연구는 LVLMs의 한계를 이해하는 데 중요한 통찰을 제공하며, 맥락 인식 객체 인식에 대한 추가 연구를 장려합니다.

## 📝 요약

대형 비전-언어 모델(LVLMs)은 이미지 캡션, 시각적 질문 응답, 로봇공학 등에서 발전을 이루었지만, 예상치 못한 맥락에서 오류를 범하기 쉽습니다. 이러한 오류는 객체 오인식과 환각으로 이어집니다. 본 연구는 이러한 문제를 체계적으로 분석하기 위해 객체-맥락 관계가 기대와 다른 시나리오를 평가하는 새로운 벤치마크인 ORIC를 제안합니다. ORIC는 LLM과 CLIP 가이드 샘플링을 통해 맥락적으로 부적절한 객체와 환각 가능성이 있는 객체를 식별합니다. 18개의 LVLM과 두 개의 개방형 어휘 탐지 모델을 평가한 결과, 맥락적 부조화가 인식에 큰 영향을 미친다는 사실을 발견했습니다. 이 연구는 LVLM의 한계를 이해하고 맥락 인식 객체 인식 연구를 촉진하는 데 기여합니다.

## 🎯 주요 포인트

- 1. 대형 비전-언어 모델(LVLMs)은 이미지 캡션, 시각적 질문 응답, 로봇 공학에서 시각적 및 텍스트 정보를 통합하여 큰 발전을 이루었으나, 부적절한 맥락에서는 오류가 발생하기 쉽다.
- 2. LVLMs의 주요 인식 실패는 객체 오인식과 환각 현상으로, 예상과 다른 객체-맥락 관계에서 발생한다.
- 3. 새로운 벤치마크인 ORIC는 예상과 다른 객체-맥락 관계 시나리오에서 LVLMs를 평가하며, LLM 및 CLIP 가이드 샘플링을 통해 부적절한 맥락을 생성한다.
- 4. 18개의 LVLMs와 두 개의 오픈 보캐뷸러리 감지 모델을 평가한 결과, 맥락적 부적절성으로 인한 인식 격차가 크게 나타났다.
- 5. 이 연구는 LVLMs의 한계를 밝히고, 맥락 인식 객체 인식에 대한 추가 연구를 촉진한다.


---

*Generated on 2025-09-23 10:51:44*