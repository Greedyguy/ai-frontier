---
keywords:
  - Simultaneous Speech-to-Text Translation
  - Large Language Model
  - Simultaneous Self-Augmentation
  - Offline Supervised Fine-Tuning Data
category: cs.CL
publish_date: 2025-09-22
arxiv_id: 2509.15692
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:38:53.582570",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Simultaneous Speech-to-Text Translation",
    "Large Language Model",
    "Simultaneous Self-Augmentation",
    "Offline Supervised Fine-Tuning Data"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Simultaneous Speech-to-Text Translation": 0.78,
    "Large Language Model": 0.72,
    "Simultaneous Self-Augmentation": 0.79,
    "Offline Supervised Fine-Tuning Data": 0.71
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Simultaneous speech-to-text translation",
        "canonical": "Simultaneous Speech-to-Text Translation",
        "aliases": [
          "Simul-S2TT"
        ],
        "category": "unique_technical",
        "rationale": "This is a specific and novel application of translation technology that directly relates to the paper's focus on real-time translation capabilities.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Large audio-language models",
        "canonical": "Large Language Model",
        "aliases": [
          "LALM"
        ],
        "category": "broad_technical",
        "rationale": "This term connects to the broader category of Large Language Models, which are central to the paper's methodology.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.72
      },
      {
        "surface": "Simultaneous Self-Augmentation",
        "canonical": "Simultaneous Self-Augmentation",
        "aliases": [
          "SimulSA"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel strategy for enhancing model capabilities without architectural changes, central to the paper's contribution.",
        "novelty_score": 0.8,
        "connectivity_score": 0.7,
        "specificity_score": 0.82,
        "link_intent_score": 0.79
      },
      {
        "surface": "offline SFT data",
        "canonical": "Offline Supervised Fine-Tuning Data",
        "aliases": [
          "offline SFT"
        ],
        "category": "specific_connectable",
        "rationale": "This term is crucial for understanding the data preparation process that bridges pretraining and inference.",
        "novelty_score": 0.58,
        "connectivity_score": 0.75,
        "specificity_score": 0.78,
        "link_intent_score": 0.71
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance",
      "strategy"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Simultaneous speech-to-text translation",
      "resolved_canonical": "Simultaneous Speech-to-Text Translation",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Large audio-language models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "Simultaneous Self-Augmentation",
      "resolved_canonical": "Simultaneous Self-Augmentation",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.7,
        "specificity": 0.82,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "offline SFT data",
      "resolved_canonical": "Offline Supervised Fine-Tuning Data",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.75,
        "specificity": 0.78,
        "link_intent": 0.71
      }
    }
  ]
}
-->

# Direct Simultaneous Translation Activation for Large Audio-Language Models

**Korean Title:** ëŒ€í˜• ì˜¤ë””ì˜¤-ì–¸ì–´ ëª¨ë¸ì„ ìœ„í•œ ì§ì ‘ ë™ì‹œ ë²ˆì—­ í™œì„±í™”

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15692.pdf)
**Category**: cs.CL
**Published**: 2025-09-22
**ArXiv ID**: [2509.15692](https://arxiv.org/abs/2509.15692)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Exploring Fine-Tuning of Large Audio Language Models for Spoken Language Understanding under Limited Speech data_20250922|Exploring Fine-Tuning of Large Audio Language Models for Spoken Language Understanding under Limited Speech data]] (83.1% similar)
- [[2025-09-22/Chunk Based Speech Pre-training with High Resolution Finite Scalar Quantization_20250922|Chunk Based Speech Pre-training with High Resolution Finite Scalar Quantization]] (82.0% similar)
- [[2025-09-19/SpeechOp_ Inference-Time Task Composition for Generative Speech Processing_20250919|SpeechOp: Inference-Time Task Composition for Generative Speech Processing]] (81.9% similar)
- [[2025-09-17/SSL-SSAW_ Self-Supervised Learning with Sigmoid Self-Attention Weighting for Question-Based Sign Language Translation_20250917|SSL-SSAW: Self-Supervised Learning with Sigmoid Self-Attention Weighting for Question-Based Sign Language Translation]] (81.8% similar)
- [[2025-09-19/Hybrid Autoregressive-Diffusion Model for Real-Time Sign Language Production_20250919|Hybrid Autoregressive-Diffusion Model for Real-Time Sign Language Production]] (81.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Offline Supervised Fine-Tuning Data|Offline Supervised Fine-Tuning Data]]
**âš¡ Unique Technical**: [[keywords/Simultaneous Speech-to-Text Translation|Simultaneous Speech-to-Text Translation]], [[keywords/Simultaneous Self-Augmentation|Simultaneous Self-Augmentation]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15692v1 Announce Type: cross 
Abstract: Simultaneous speech-to-text translation (Simul-S2TT) aims to translate speech into target text in real time, outputting translations while receiving source speech input, rather than waiting for the entire utterance to be spoken. Simul-S2TT research often modifies model architectures to implement read-write strategies. However, with the rise of large audio-language models (LALMs), a key challenge is how to directly activate Simul-S2TT capabilities in base models without additional architectural changes. In this paper, we introduce {\bf Simul}taneous {\bf S}elf-{\bf A}ugmentation ({\bf SimulSA}), a strategy that utilizes LALMs' inherent capabilities to obtain simultaneous data by randomly truncating speech and constructing partially aligned translation. By incorporating them into offline SFT data, SimulSA effectively bridges the distribution gap between offline translation during pretraining and simultaneous translation during inference. Experimental results demonstrate that augmenting only about {\bf 1\%} of the simultaneous data, compared to the full offline SFT data, can significantly activate LALMs' Simul-S2TT capabilities without modifications to model architecture or decoding strategy.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15692v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ë™ì‹œ ìŒì„±-í…ìŠ¤íŠ¸ ë²ˆì—­(Simul-S2TT)ì€ ì „ì²´ ë°œí™”ë¥¼ ê¸°ë‹¤ë¦¬ì§€ ì•Šê³  ì†ŒìŠ¤ ìŒì„± ì…ë ¥ì„ ë°›ìœ¼ë©´ì„œ ë²ˆì—­ì„ ì¶œë ¥í•˜ì—¬ ìŒì„±ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ëŒ€ìƒ í…ìŠ¤íŠ¸ë¡œ ë²ˆì—­í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤. Simul-S2TT ì—°êµ¬ëŠ” ì¢…ì¢… ì½ê¸°-ì“°ê¸° ì „ëµì„ êµ¬í˜„í•˜ê¸° ìœ„í•´ ëª¨ë¸ ì•„í‚¤í…ì²˜ë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ëŒ€í˜• ì˜¤ë””ì˜¤-ì–¸ì–´ ëª¨ë¸(LALMs)ì˜ ë¶€ìƒìœ¼ë¡œ ì¸í•´ ì¶”ê°€ì ì¸ ì•„í‚¤í…ì²˜ ë³€ê²½ ì—†ì´ ê¸°ë³¸ ëª¨ë¸ì—ì„œ Simul-S2TT ê¸°ëŠ¥ì„ ì§ì ‘ í™œì„±í™”í•˜ëŠ” ê²ƒì´ ì£¼ìš” ê³¼ì œê°€ ë˜ê³  ìˆìŠµë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ëŒ€í˜• ì˜¤ë””ì˜¤-ì–¸ì–´ ëª¨ë¸ì˜ ê³ ìœ í•œ ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ ìŒì„±ì„ ë¬´ì‘ìœ„ë¡œ ì˜ë¼ë‚´ê³  ë¶€ë¶„ì ìœ¼ë¡œ ì •ë ¬ëœ ë²ˆì—­ì„ êµ¬ì„±í•˜ì—¬ ë™ì‹œ ë°ì´í„°ë¥¼ ì–»ëŠ” ì „ëµì¸ {\bf Simul}taneous {\bf S}elf-{\bf A}ugmentation ({\bf SimulSA})ì„ ì†Œê°œí•©ë‹ˆë‹¤. ì´ë¥¼ ì˜¤í”„ë¼ì¸ SFT ë°ì´í„°ì— í†µí•©í•¨ìœ¼ë¡œì¨, SimulSAëŠ” ì‚¬ì „ í•™ìŠµ ì¤‘ ì˜¤í”„ë¼ì¸ ë²ˆì—­ê³¼ ì¶”ë¡  ì¤‘ ë™ì‹œ ë²ˆì—­ ê°„ì˜ ë¶„í¬ ì°¨ì´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì—°ê²°í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼ëŠ” ì „ì²´ ì˜¤í”„ë¼ì¸ SFT ë°ì´í„°ì— ë¹„í•´ ì•½ {\bf 1\%}ì˜ ë™ì‹œ ë°ì´í„°ë¥¼ ì¦ê°•í•˜ëŠ” ê²ƒë§Œìœ¼ë¡œë„ ëª¨ë¸ ì•„í‚¤í…ì²˜ë‚˜ ë””ì½”ë”© ì „ëµì„ ìˆ˜ì •í•˜ì§€ ì•Šê³  LALMsì˜ Simul-S2TT ê¸°ëŠ¥ì„ í¬ê²Œ í™œì„±í™”í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì‹¤ì‹œê°„ ìŒì„±-í…ìŠ¤íŠ¸ ë²ˆì—­(Simul-S2TT)ì„ ìœ„í•œ ìƒˆë¡œìš´ ì „ëµì¸ SimulSAë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ ì—°êµ¬ëŠ” ëª¨ë¸ êµ¬ì¡°ë¥¼ ìˆ˜ì •í•˜ì—¬ ë²ˆì—­ì„ êµ¬í˜„í–ˆì§€ë§Œ, ì´ ì—°êµ¬ëŠ” ëŒ€í˜• ì˜¤ë””ì˜¤-ì–¸ì–´ ëª¨ë¸(LALMs)ì˜ ê¸°ë³¸ ëª¨ë¸ì„ ë³€ê²½í•˜ì§€ ì•Šê³  Simul-S2TT ê¸°ëŠ¥ì„ í™œì„±í™”í•˜ëŠ” ë°©ë²•ì„ íƒêµ¬í•©ë‹ˆë‹¤. SimulSAëŠ” ìŒì„±ì„ ë¬´ì‘ìœ„ë¡œ ì˜ë¼ë‚´ê³  ë¶€ë¶„ì ìœ¼ë¡œ ì •ë ¬ëœ ë²ˆì—­ì„ êµ¬ì„±í•˜ì—¬ LALMsì˜ ê³ ìœ í•œ ëŠ¥ë ¥ì„ í™œìš©í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì‚¬ì „ í›ˆë ¨ ì¤‘ ì˜¤í”„ë¼ì¸ ë²ˆì—­ê³¼ ì¶”ë¡  ì¤‘ ì‹¤ì‹œê°„ ë²ˆì—­ ê°„ì˜ ë¶„í¬ ì°¨ì´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì¤„ì…ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì „ì²´ ì˜¤í”„ë¼ì¸ ë°ì´í„°ì˜ ì•½ 1%ë§Œì„ ì‚¬ìš©í•˜ì—¬ë„ ëª¨ë¸ êµ¬ì¡°ë‚˜ ë””ì½”ë”© ì „ëµì˜ ë³€ê²½ ì—†ì´ LALMsì˜ Simul-S2TT ê¸°ëŠ¥ì„ í¬ê²Œ í™œì„±í™”í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Simul-S2TTëŠ” ì‹¤ì‹œê°„ìœ¼ë¡œ ìŒì„±ì„ ë²ˆì—­í•˜ì—¬ ì…ë ¥ê³¼ ë™ì‹œì— ë²ˆì—­ì„ ì¶œë ¥í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.
- 2. SimulSAëŠ” ëŒ€ê·œëª¨ ì˜¤ë””ì˜¤-ì–¸ì–´ ëª¨ë¸(LALMs)ì˜ ë‚´ì¬ëœ ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ ë™ì‹œ ë²ˆì—­ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ì „ëµì…ë‹ˆë‹¤.
- 3. SimulSAëŠ” ìŒì„±ì„ ë¬´ì‘ìœ„ë¡œ ì˜ë¼ë‚´ê³  ë¶€ë¶„ì ìœ¼ë¡œ ì •ë ¬ëœ ë²ˆì—­ì„ êµ¬ì„±í•˜ì—¬ ë™ì‹œ ë²ˆì—­ê³¼ ì˜¤í”„ë¼ì¸ ë²ˆì—­ ê°„ì˜ ë¶„í¬ ì°¨ì´ë¥¼ ì¤„ì…ë‹ˆë‹¤.
- 4. ì‹¤í—˜ ê²°ê³¼, ì „ì²´ ì˜¤í”„ë¼ì¸ SFT ë°ì´í„°ì˜ ì•½ 1%ë§Œì„ ë™ì‹œ ë°ì´í„°ë¡œ ì¦ê°•í•´ë„ ëª¨ë¸ ì•„í‚¤í…ì²˜ë‚˜ ë””ì½”ë”© ì „ëµì˜ ë³€ê²½ ì—†ì´ LALMsì˜ Simul-S2TT ê¸°ëŠ¥ì„ í™œì„±í™”í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.


---

*Generated on 2025-09-23 11:38:53*