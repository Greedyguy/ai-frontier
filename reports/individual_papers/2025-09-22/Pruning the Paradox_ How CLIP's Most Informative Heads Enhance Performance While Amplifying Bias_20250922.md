---
keywords:
  - Vision-Language Model
  - Attention Mechanism
  - Concept Consistency Score
  - Bias in AI
  - Out-of-Domain Detection
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2503.11103
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T09:52:25.657645",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Vision-Language Model",
    "Attention Mechanism",
    "Concept Consistency Score",
    "Bias in AI",
    "Out-of-Domain Detection"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Vision-Language Model": 0.85,
    "Attention Mechanism": 0.82,
    "Concept Consistency Score": 0.78,
    "Bias in AI": 0.8,
    "Out-of-Domain Detection": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "CLIP",
        "canonical": "Vision-Language Model",
        "aliases": [
          "Contrastive Languageâ€“Image Pretraining"
        ],
        "category": "evolved_concepts",
        "rationale": "CLIP is central to the paper's analysis and aligns with the trending concept of Vision-Language Models.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.8,
        "link_intent_score": 0.85
      },
      {
        "surface": "attention heads",
        "canonical": "Attention Mechanism",
        "aliases": [
          "attention layers"
        ],
        "category": "specific_connectable",
        "rationale": "Attention heads are a key component in understanding CLIP's internal mechanisms.",
        "novelty_score": 0.4,
        "connectivity_score": 0.9,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "Concept Consistency Score",
        "canonical": "Concept Consistency Score",
        "aliases": [
          "CCS"
        ],
        "category": "unique_technical",
        "rationale": "CCS is a novel metric introduced in the paper, crucial for interpretability analysis.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "social biases",
        "canonical": "Bias in AI",
        "aliases": [
          "algorithmic bias",
          "AI bias"
        ],
        "category": "broad_technical",
        "rationale": "Understanding and mitigating social biases is a critical aspect of deploying AI models like CLIP.",
        "novelty_score": 0.5,
        "connectivity_score": 0.7,
        "specificity_score": 0.6,
        "link_intent_score": 0.8
      },
      {
        "surface": "out-of-domain detection",
        "canonical": "Out-of-Domain Detection",
        "aliases": [
          "OOD detection"
        ],
        "category": "specific_connectable",
        "rationale": "Out-of-domain detection is a significant application area for CLIP's attention heads.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.72,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "performance",
      "experiment",
      "method"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "CLIP",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.8,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "attention heads",
      "resolved_canonical": "Attention Mechanism",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.9,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Concept Consistency Score",
      "resolved_canonical": "Concept Consistency Score",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "social biases",
      "resolved_canonical": "Bias in AI",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.7,
        "specificity": 0.6,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "out-of-domain detection",
      "resolved_canonical": "Out-of-Domain Detection",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.72,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Pruning the Paradox: How CLIP's Most Informative Heads Enhance Performance While Amplifying Bias

**Korean Title:** ì—­ì„¤ì˜ ê°€ì§€ì¹˜ê¸°: CLIPì˜ ê°€ì¥ ì •ë³´ì ì¸ í—¤ë“œê°€ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ë©´ì„œ í¸í–¥ì„ ì¦í­ì‹œí‚¤ëŠ” ë°©ë²•

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2503.11103.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2503.11103](https://arxiv.org/abs/2503.11103)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/Singular Value Few-shot Adaptation of Vision-Language Models_20250918|Singular Value Few-shot Adaptation of Vision-Language Models]] (81.3% similar)
- [[2025-09-22/LLMs Can Compensate for Deficiencies in Visual Representations_20250922|LLMs Can Compensate for Deficiencies in Visual Representations]] (80.9% similar)
- [[2025-09-22/PCSR_ Pseudo-label Consistency-Guided Sample Refinement for Noisy Correspondence Learning_20250922|PCSR: Pseudo-label Consistency-Guided Sample Refinement for Noisy Correspondence Learning]] (80.5% similar)
- [[2025-09-18/Locally Explaining Prediction Behavior via Gradual Interventions and Measuring Property Gradients_20250918|Locally Explaining Prediction Behavior via Gradual Interventions and Measuring Property Gradients]] (80.3% similar)
- [[2025-09-22/RegionMed-CLIP_ A Region-Aware Multimodal Contrastive Learning Pre-trained Model for Medical Image Understanding_20250922|RegionMed-CLIP: A Region-Aware Multimodal Contrastive Learning Pre-trained Model for Medical Image Understanding]] (80.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Bias in AI|Bias in AI]]
**ğŸ”— Specific Connectable**: [[keywords/Attention Mechanism|Attention Mechanism]], [[keywords/Out-of-Domain Detection|Out-of-Domain Detection]]
**âš¡ Unique Technical**: [[keywords/Concept Consistency Score|Concept Consistency Score]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2503.11103v3 Announce Type: replace-cross 
Abstract: CLIP is one of the most popular foundation models and is heavily used for many vision-language tasks, yet little is known about its inner workings. As CLIP is increasingly deployed in real-world applications, it is becoming even more critical to understand its limitations and embedded social biases to mitigate potentially harmful downstream consequences. However, the question of what internal mechanisms drive both the impressive capabilities as well as problematic shortcomings of CLIP has largely remained unanswered. To bridge this gap, we study the conceptual consistency of text descriptions for attention heads in CLIP-like models. Specifically, we propose Concept Consistency Score (CCS), a novel interpretability metric that measures how consistently individual attention heads in CLIP models align with specific concepts. Our soft-pruning experiments reveal that high CCS heads are critical for preserving model performance, as pruning them leads to a significantly larger performance drop than pruning random or low CCS heads. Notably, we find that high CCS heads capture essential concepts and play a key role in out-of-domain detection, concept-specific reasoning, and video-language understanding. Moreover, we prove that high CCS heads learn spurious correlations which amplify social biases. These results position CCS as a powerful interpretability metric exposing the paradox of performance and social biases in CLIP models.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2503.11103v3 ë°œí‘œ ìœ í˜•: êµì°¨ ëŒ€ì²´  
ì´ˆë¡: CLIPì€ ê°€ì¥ ì¸ê¸° ìˆëŠ” ê¸°ì´ˆ ëª¨ë¸ ì¤‘ í•˜ë‚˜ë¡œ, ë§ì€ ë¹„ì „-ì–¸ì–´ ì‘ì—…ì— ë„ë¦¬ ì‚¬ìš©ë˜ê³  ìˆì§€ë§Œ, ê·¸ ë‚´ë¶€ ì‘ë™ ë°©ì‹ì— ëŒ€í•´ì„œëŠ” ê±°ì˜ ì•Œë ¤ì ¸ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. CLIPì´ ì‹¤ì œ ì‘ìš© í”„ë¡œê·¸ë¨ì— ì ì  ë” ë§ì´ ë°°í¬ë¨ì— ë”°ë¼, ê·¸ í•œê³„ì™€ ë‚´ì¬ëœ ì‚¬íšŒì  í¸ê²¬ì„ ì´í•´í•˜ì—¬ ì ì¬ì ìœ¼ë¡œ í•´ë¡œìš´ í•˜ë¥˜ ê²°ê³¼ë¥¼ ì™„í™”í•˜ëŠ” ê²ƒì´ ë”ìš± ì¤‘ìš”í•´ì§€ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ CLIPì˜ ì¸ìƒì ì¸ ëŠ¥ë ¥ê³¼ ë¬¸ì œì ì´ ëª¨ë‘ ë¬´ì—‡ì— ì˜í•´ êµ¬ë™ë˜ëŠ”ì§€ì— ëŒ€í•œ ì§ˆë¬¸ì€ ëŒ€ì²´ë¡œ ë‹µì„ ì–»ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ê²©ì°¨ë¥¼ í•´ì†Œí•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” CLIP ìœ ì‚¬ ëª¨ë¸ì—ì„œ ì£¼ì˜ í—¤ë“œì˜ í…ìŠ¤íŠ¸ ì„¤ëª…ì— ëŒ€í•œ ê°œë…ì  ì¼ê´€ì„±ì„ ì—°êµ¬í•©ë‹ˆë‹¤. êµ¬ì²´ì ìœ¼ë¡œ, ìš°ë¦¬ëŠ” CLIP ëª¨ë¸ì˜ ê°œë³„ ì£¼ì˜ í—¤ë“œê°€ íŠ¹ì • ê°œë…ê³¼ ì–¼ë§ˆë‚˜ ì¼ê´€ë˜ê²Œ ì •ë ¬ë˜ëŠ”ì§€ë¥¼ ì¸¡ì •í•˜ëŠ” ìƒˆë¡œìš´ í•´ì„ ê°€ëŠ¥ì„± ì§€í‘œì¸ ê°œë… ì¼ê´€ì„± ì ìˆ˜(Concept Consistency Score, CCS)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì†Œí”„íŠ¸ í”„ë£¨ë‹ ì‹¤í—˜ì€ ë†’ì€ CCS í—¤ë“œê°€ ëª¨ë¸ ì„±ëŠ¥ì„ ìœ ì§€í•˜ëŠ” ë° ì¤‘ìš”í•˜ë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŠ” ë¬´ì‘ìœ„ ë˜ëŠ” ë‚®ì€ CCS í—¤ë“œë¥¼ í”„ë£¨ë‹í•˜ëŠ” ê²ƒë³´ë‹¤ ì„±ëŠ¥ ì €í•˜ê°€ í›¨ì”¬ ë” í¬ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. íŠ¹íˆ, ìš°ë¦¬ëŠ” ë†’ì€ CCS í—¤ë“œê°€ í•„ìˆ˜ ê°œë…ì„ í¬ì°©í•˜ê³ , ë„ë©”ì¸ ì™¸ íƒì§€, ê°œë…ë³„ ì¶”ë¡ , ë¹„ë””ì˜¤-ì–¸ì–´ ì´í•´ì—ì„œ ì¤‘ìš”í•œ ì—­í• ì„ í•œë‹¤ëŠ” ê²ƒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ë”ìš±ì´, ìš°ë¦¬ëŠ” ë†’ì€ CCS í—¤ë“œê°€ ì‚¬íšŒì  í¸ê²¬ì„ ì¦í­ì‹œí‚¤ëŠ” ì˜ëª»ëœ ìƒê´€ê´€ê³„ë¥¼ í•™ìŠµí•œë‹¤ëŠ” ê²ƒì„ ì¦ëª…í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ê²°ê³¼ëŠ” CCSë¥¼ CLIP ëª¨ë¸ì—ì„œ ì„±ëŠ¥ê³¼ ì‚¬íšŒì  í¸ê²¬ì˜ ì—­ì„¤ì„ ë“œëŸ¬ë‚´ëŠ” ê°•ë ¥í•œ í•´ì„ ê°€ëŠ¥ì„± ì§€í‘œë¡œ ìë¦¬ë§¤ê¹€í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ CLIP ëª¨ë¸ì˜ ë‚´ë¶€ ì‘ë™ ë°©ì‹ì„ ì´í•´í•˜ê¸° ìœ„í•´ ìƒˆë¡œìš´ í•´ì„ ê°€ëŠ¥ì„± ì§€í‘œì¸ ê°œë… ì¼ê´€ì„± ì ìˆ˜(CCS)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. CCSëŠ” CLIP ëª¨ë¸ì˜ ê°œë³„ ì–´í…ì…˜ í—¤ë“œê°€ íŠ¹ì • ê°œë…ê³¼ ì–¼ë§ˆë‚˜ ì¼ê´€ë˜ê²Œ ì •ë ¬ë˜ëŠ”ì§€ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤. ì—°êµ¬ ê²°ê³¼, ë†’ì€ CCSë¥¼ ê°€ì§„ í—¤ë“œëŠ” ëª¨ë¸ ì„±ëŠ¥ ìœ ì§€ì— ì¤‘ìš”í•˜ë©°, ì´ë“¤ì„ ì œê±°í•˜ë©´ ì„±ëŠ¥ì´ í¬ê²Œ ì €í•˜ë©ë‹ˆë‹¤. ë˜í•œ, ì´ëŸ¬í•œ í—¤ë“œëŠ” ë³¸ì§ˆì ì¸ ê°œë…ì„ í¬ì°©í•˜ê³ , ë„ë©”ì¸ ì™¸ íƒì§€ ë° ê°œë…ë³„ ì¶”ë¡ , ë¹„ë””ì˜¤-ì–¸ì–´ ì´í•´ì— ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë†’ì€ CCS í—¤ë“œëŠ” ì‚¬íšŒì  í¸í–¥ì„ ì¦í­ì‹œí‚¤ëŠ” ì˜ëª»ëœ ìƒê´€ê´€ê³„ë¥¼ í•™ìŠµí•˜ê¸°ë„ í•©ë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” CLIP ëª¨ë¸ì˜ ì„±ëŠ¥ê³¼ ì‚¬íšŒì  í¸í–¥ì˜ ì—­ì„¤ì„ ë“œëŸ¬ë‚´ëŠ” ë° CCSê°€ ê°•ë ¥í•œ í•´ì„ ë„êµ¬ì„ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. CLIP ëª¨ë¸ì˜ ë‚´ë¶€ ë©”ì»¤ë‹ˆì¦˜ê³¼ í•œê³„, ì‚¬íšŒì  í¸í–¥ì„±ì„ ì´í•´í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.
- 2. Concept Consistency Score (CCS)ëŠ” CLIP ëª¨ë¸ì˜ ì£¼ì˜ í—¤ë“œê°€ íŠ¹ì • ê°œë…ê³¼ ì–¼ë§ˆë‚˜ ì¼ê´€ë˜ê²Œ ì •ë ¬ë˜ëŠ”ì§€ë¥¼ ì¸¡ì •í•˜ëŠ” ìƒˆë¡œìš´ í•´ì„ ê°€ëŠ¥ì„± ì§€í‘œì…ë‹ˆë‹¤.
- 3. ë†’ì€ CCSë¥¼ ê°€ì§„ ì£¼ì˜ í—¤ë“œëŠ” ëª¨ë¸ ì„±ëŠ¥ ìœ ì§€ì— ì¤‘ìš”í•˜ë©°, ì´ë“¤ì„ ì œê±°í•˜ë©´ ì„±ëŠ¥ì´ í¬ê²Œ ì €í•˜ë©ë‹ˆë‹¤.
- 4. ë†’ì€ CCS í—¤ë“œëŠ” ë³¸ì§ˆì ì¸ ê°œë…ì„ í¬ì°©í•˜ê³ , ë„ë©”ì¸ ì™¸ íƒì§€, ê°œë…ë³„ ì¶”ë¡ , ë¹„ë””ì˜¤-ì–¸ì–´ ì´í•´ì— ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.
- 5. ë†’ì€ CCS í—¤ë“œëŠ” ì‚¬íšŒì  í¸í–¥ì„ ì¦í­ì‹œí‚¤ëŠ” ì˜ëª»ëœ ìƒê´€ê´€ê³„ë¥¼ í•™ìŠµí•˜ë©°, ì´ëŠ” CLIP ëª¨ë¸ì˜ ì„±ëŠ¥ê³¼ ì‚¬íšŒì  í¸í–¥ì˜ ì—­ì„¤ì„ ë“œëŸ¬ëƒ…ë‹ˆë‹¤.


---

*Generated on 2025-09-23 09:52:25*