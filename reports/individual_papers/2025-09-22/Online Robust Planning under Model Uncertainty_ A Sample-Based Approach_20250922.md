---
keywords:
  - Markov Decision Processes
  - Robust Markov Decision Processes
  - Monte Carlo Tree Search
  - Sample Average Approximation
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2509.10162
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T09:41:53.625532",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Markov Decision Processes",
    "Robust Markov Decision Processes",
    "Monte Carlo Tree Search",
    "Sample Average Approximation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Markov Decision Processes": 0.78,
    "Robust Markov Decision Processes": 0.81,
    "Monte Carlo Tree Search": 0.8,
    "Sample Average Approximation": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Markov Decision Processes",
        "canonical": "Markov Decision Processes",
        "aliases": [
          "MDPs"
        ],
        "category": "broad_technical",
        "rationale": "Markov Decision Processes are foundational to the study of planning and decision-making under uncertainty, providing strong links to related research.",
        "novelty_score": 0.45,
        "connectivity_score": 0.85,
        "specificity_score": 0.65,
        "link_intent_score": 0.78
      },
      {
        "surface": "Robust Markov Decision Processes",
        "canonical": "Robust Markov Decision Processes",
        "aliases": [
          "RMDPs"
        ],
        "category": "unique_technical",
        "rationale": "RMDPs extend traditional MDPs to handle model uncertainty, offering a unique angle for linking research on robust planning.",
        "novelty_score": 0.72,
        "connectivity_score": 0.68,
        "specificity_score": 0.82,
        "link_intent_score": 0.81
      },
      {
        "surface": "Monte Carlo Tree Search",
        "canonical": "Monte Carlo Tree Search",
        "aliases": [
          "MCTS"
        ],
        "category": "specific_connectable",
        "rationale": "MCTS is a widely used algorithm for decision-making in uncertain environments, connecting to a broad range of applications in AI.",
        "novelty_score": 0.58,
        "connectivity_score": 0.79,
        "specificity_score": 0.76,
        "link_intent_score": 0.8
      },
      {
        "surface": "Sample Average Approximation",
        "canonical": "Sample Average Approximation",
        "aliases": [
          "SAA"
        ],
        "category": "unique_technical",
        "rationale": "SAA is crucial for computing robust value functions, linking to optimization techniques in uncertain environments.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.78,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "online planning",
      "generative model",
      "approximation errors"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Markov Decision Processes",
      "resolved_canonical": "Markov Decision Processes",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.85,
        "specificity": 0.65,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Robust Markov Decision Processes",
      "resolved_canonical": "Robust Markov Decision Processes",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.68,
        "specificity": 0.82,
        "link_intent": 0.81
      }
    },
    {
      "candidate_surface": "Monte Carlo Tree Search",
      "resolved_canonical": "Monte Carlo Tree Search",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.79,
        "specificity": 0.76,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Sample Average Approximation",
      "resolved_canonical": "Sample Average Approximation",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.78,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Online Robust Planning under Model Uncertainty: A Sample-Based Approach

**Korean Title:** ëª¨ë¸ ë¶ˆí™•ì‹¤ì„± í•˜ì—ì„œì˜ ì˜¨ë¼ì¸ ê°•ê±´ ê³„íš: ìƒ˜í”Œ ê¸°ë°˜ ì ‘ê·¼ë²•

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.10162.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2509.10162](https://arxiv.org/abs/2509.10162)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Online reinforcement learning via sparse Gaussian mixture model Q-functions_20250919|Online reinforcement learning via sparse Gaussian mixture model Q-functions]] (81.6% similar)
- [[2025-09-19/ActivePusher_ Active Learning and Planning with Residual Physics for Nonprehensile Manipulation_20250919|ActivePusher: Active Learning and Planning with Residual Physics for Nonprehensile Manipulation]] (81.2% similar)
- [[2025-09-19/Optimal Control of Markov Decision Processes for Efficiency with Linear Temporal Logic Tasks_20250919|Optimal Control of Markov Decision Processes for Efficiency with Linear Temporal Logic Tasks]] (81.0% similar)
- [[2025-09-22/Hierarchical Reinforcement Learning with Low-Level MPC for Multi-Agent Control_20250922|Hierarchical Reinforcement Learning with Low-Level MPC for Multi-Agent Control]] (80.7% similar)
- [[2025-09-19/Multi-Fidelity Hybrid Reinforcement Learning via Information Gain Maximization_20250919|Multi-Fidelity Hybrid Reinforcement Learning via Information Gain Maximization]] (80.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Markov Decision Processes|Markov Decision Processes]]
**ğŸ”— Specific Connectable**: [[keywords/Monte Carlo Tree Search|Monte Carlo Tree Search]]
**âš¡ Unique Technical**: [[keywords/Robust Markov Decision Processes|Robust Markov Decision Processes]], [[keywords/Sample Average Approximation|Sample Average Approximation]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.10162v2 Announce Type: replace 
Abstract: Online planning in Markov Decision Processes (MDPs) enables agents to make sequential decisions by simulating future trajectories from the current state, making it well-suited for large-scale or dynamic environments. Sample-based methods such as Sparse Sampling and Monte Carlo Tree Search (MCTS) are widely adopted for their ability to approximate optimal actions using a generative model. However, in practical settings, the generative model is often learned from limited data, introducing approximation errors that can degrade performance or lead to unsafe behaviors. To address these challenges, Robust MDPs (RMDPs) offer a principled framework for planning under model uncertainty, yet existing approaches are typically computationally intensive and not suited for real-time use. In this work, we introduce Robust Sparse Sampling (RSS), the first online planning algorithm for RMDPs with finite-sample theoretical performance guarantees. Unlike Sparse Sampling, which estimates the nominal value function, RSS computes a robust value function by leveraging the efficiency and theoretical properties of Sample Average Approximation (SAA), enabling tractable robust policy computation in online settings. RSS is applicable to infinite or continuous state spaces, and its sample and computational complexities are independent of the state space size. We provide theoretical performance guarantees and empirically show that RSS outperforms standard Sparse Sampling in environments with uncertain dynamics.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.10162v2 ë°œí‘œ ìœ í˜•: êµì²´  
ì´ˆë¡: ë§ˆë¥´ì½”í”„ ê²°ì • í”„ë¡œì„¸ìŠ¤(MDP)ì—ì„œì˜ ì˜¨ë¼ì¸ ê³„íšì€ ì—ì´ì „íŠ¸ê°€ í˜„ì¬ ìƒíƒœì—ì„œ ë¯¸ë˜ ê²½ë¡œë¥¼ ì‹œë®¬ë ˆì´ì…˜í•˜ì—¬ ìˆœì°¨ì ì¸ ê²°ì •ì„ ë‚´ë¦´ ìˆ˜ ìˆê²Œ í•˜ì—¬ ëŒ€ê·œëª¨ ë˜ëŠ” ë™ì  í™˜ê²½ì— ì í•©í•©ë‹ˆë‹¤. Sparse Sampling ë° ëª¬í…Œì¹´ë¥¼ë¡œ íŠ¸ë¦¬ íƒìƒ‰(MCTS)ê³¼ ê°™ì€ ìƒ˜í”Œ ê¸°ë°˜ ë°©ë²•ì€ ìƒì„± ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìµœì ì˜ í–‰ë™ì„ ê·¼ì‚¬í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ ë•Œë¬¸ì— ë„ë¦¬ ì±„íƒë˜ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ìƒì„± ëª¨ë¸ì´ ì œí•œëœ ë°ì´í„°ì—ì„œ í•™ìŠµë˜ëŠ” ê²½ìš°ê°€ ë§ì•„ ê·¼ì‚¬ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì—¬ ì„±ëŠ¥ì´ ì €í•˜ë˜ê±°ë‚˜ ì•ˆì „í•˜ì§€ ì•Šì€ í–‰ë™ìœ¼ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ê°•ê±´í•œ MDP(RMDP)ëŠ” ëª¨ë¸ ë¶ˆí™•ì‹¤ì„± í•˜ì—ì„œ ê³„íšì„ ìœ„í•œ ì›ì¹™ì ì¸ í”„ë ˆì„ì›Œí¬ë¥¼ ì œê³µí•˜ì§€ë§Œ, ê¸°ì¡´ ì ‘ê·¼ ë°©ì‹ì€ ì¼ë°˜ì ìœ¼ë¡œ ê³„ì‚° ì§‘ì•½ì ì´ë©° ì‹¤ì‹œê°„ ì‚¬ìš©ì— ì í•©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” ìœ í•œ ìƒ˜í”Œ ì´ë¡ ì  ì„±ëŠ¥ ë³´ì¥ì„ ê°–ì¶˜ RMDPë¥¼ ìœ„í•œ ìµœì´ˆì˜ ì˜¨ë¼ì¸ ê³„íš ì•Œê³ ë¦¬ì¦˜ì¸ ê°•ê±´í•œ Sparse Sampling(RSS)ì„ ì†Œê°œí•©ë‹ˆë‹¤. RSSëŠ” ëª…ëª© ê°€ì¹˜ í•¨ìˆ˜ë¥¼ ì¶”ì •í•˜ëŠ” Sparse Samplingê³¼ ë‹¬ë¦¬, ìƒ˜í”Œ í‰ê·  ê·¼ì‚¬(SAA)ì˜ íš¨ìœ¨ì„±ê³¼ ì´ë¡ ì  íŠ¹ì„±ì„ í™œìš©í•˜ì—¬ ê°•ê±´í•œ ê°€ì¹˜ í•¨ìˆ˜ë¥¼ ê³„ì‚°í•¨ìœ¼ë¡œì¨ ì˜¨ë¼ì¸ í™˜ê²½ì—ì„œ ì‹¤í–‰ ê°€ëŠ¥í•œ ê°•ê±´í•œ ì •ì±… ê³„ì‚°ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. RSSëŠ” ë¬´í•œ ë˜ëŠ” ì—°ì† ìƒíƒœ ê³µê°„ì— ì ìš© ê°€ëŠ¥í•˜ë©°, ê·¸ ìƒ˜í”Œ ë° ê³„ì‚° ë³µì¡ë„ëŠ” ìƒíƒœ ê³µê°„ í¬ê¸°ì— ë…ë¦½ì ì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì´ë¡ ì  ì„±ëŠ¥ ë³´ì¥ì„ ì œê³µí•˜ê³ , RSSê°€ ë¶ˆí™•ì‹¤í•œ ë™ì  í™˜ê²½ì—ì„œ í‘œì¤€ Sparse Samplingë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì„ì„ ì‹¤ì¦ì ìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë§ˆë¥´ì½”í”„ ê²°ì • ê³¼ì •(MDP)ì—ì„œ ëª¨ë¸ ë¶ˆí™•ì‹¤ì„±ì„ ê³ ë ¤í•œ ì˜¨ë¼ì¸ ê³„íš ì•Œê³ ë¦¬ì¦˜ì¸ Robust Sparse Sampling(RSS)ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ Sparse Samplingì€ ëª…ëª©ì  ê°€ì¹˜ í•¨ìˆ˜ë¥¼ ì¶”ì •í•˜ëŠ” ë°˜ë©´, RSSëŠ” ìƒ˜í”Œ í‰ê·  ê·¼ì‚¬(SAA)ì˜ íš¨ìœ¨ì„±ì„ í™œìš©í•˜ì—¬ ê²¬ê³ í•œ ê°€ì¹˜ í•¨ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. ì´ëŠ” ë¬´í•œ ë˜ëŠ” ì—°ì† ìƒíƒœ ê³µê°„ì—ì„œë„ ì ìš© ê°€ëŠ¥í•˜ë©°, ìƒíƒœ ê³µê°„ í¬ê¸°ì— ë…ë¦½ì ì¸ ìƒ˜í”Œ ë° ê³„ì‚° ë³µì¡ì„±ì„ ê°€ì§‘ë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” RSSê°€ ë¶ˆí™•ì‹¤í•œ ë™ì  í™˜ê²½ì—ì„œ ê¸°ì¡´ì˜ Sparse Samplingë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì„ì„ ì´ë¡ ì  ì„±ëŠ¥ ë³´ì¥ê³¼ ì‹¤í—˜ì„ í†µí•´ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë§ˆë¥´ì½”í”„ ê²°ì • í”„ë¡œì„¸ìŠ¤(MDP)ì—ì„œ ì˜¨ë¼ì¸ ê³„íšì€ í˜„ì¬ ìƒíƒœì—ì„œ ë¯¸ë˜ ê²½ë¡œë¥¼ ì‹œë®¬ë ˆì´ì…˜í•˜ì—¬ ìˆœì°¨ì  ê²°ì •ì„ ë‚´ë¦¬ë„ë¡ ë„ì™€ì¤€ë‹¤.
- 2. ìƒ˜í”Œ ê¸°ë°˜ ë°©ë²•ì¸ Sparse Samplingê³¼ ëª¬í…Œì¹´ë¥¼ë¡œ íŠ¸ë¦¬ íƒìƒ‰(MCTS)ì€ ìƒì„± ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìµœì ì˜ í–‰ë™ì„ ê·¼ì‚¬í•˜ëŠ” ë° ë„ë¦¬ ì‚¬ìš©ëœë‹¤.
- 3. ì œí•œëœ ë°ì´í„°ë¡œ í•™ìŠµëœ ìƒì„± ëª¨ë¸ì€ ê·¼ì‚¬ ì˜¤ë¥˜ë¥¼ ì´ˆë˜í•˜ì—¬ ì„±ëŠ¥ ì €í•˜ë‚˜ ì•ˆì „í•˜ì§€ ì•Šì€ í–‰ë™ì„ ìœ ë°œí•  ìˆ˜ ìˆë‹¤.
- 4. Robust MDPs(RMDPs)ëŠ” ëª¨ë¸ ë¶ˆí™•ì‹¤ì„± í•˜ì—ì„œ ê³„íšì„ ì„¸ìš°ê¸° ìœ„í•œ ì²´ê³„ì ì¸ í”„ë ˆì„ì›Œí¬ë¥¼ ì œê³µí•˜ì§€ë§Œ, ê¸°ì¡´ ì ‘ê·¼ë²•ì€ ê³„ì‚° ë¹„ìš©ì´ ë†’ì•„ ì‹¤ì‹œê°„ ì‚¬ìš©ì— ì í•©í•˜ì§€ ì•Šë‹¤.
- 5. Robust Sparse Sampling(RSS)ì€ RMDPsë¥¼ ìœ„í•œ ìµœì´ˆì˜ ì˜¨ë¼ì¸ ê³„íš ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ, ìœ í•œ ìƒ˜í”Œ ì´ë¡ ì  ì„±ëŠ¥ ë³´ì¥ì„ ì œê³µí•˜ë©°, ë¶ˆí™•ì‹¤í•œ ë™ì  í™˜ê²½ì—ì„œ í‘œì¤€ Sparse Samplingë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤.


---

*Generated on 2025-09-23 09:41:53*