---
keywords:
  - Vision-Language Model
  - Large Language Model
  - Evaluation Bias
  - Semantic Similarity
  - Evaluation Bias
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2509.10707
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T09:42:13.680061",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Vision-Language Model",
    "Large Language Model",
    "Evaluation Bias",
    "Semantic Similarity",
    "Evaluation Bias"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Vision-Language Model": 0.85,
    "Large Language Model": 0.8,
    "Evaluation Bias": 0.7,
    "Semantic Similarity": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Vision-Language Descriptions",
        "canonical": "Vision-Language Model",
        "aliases": [
          "Vision-Language Systems"
        ],
        "category": "evolved_concepts",
        "rationale": "This term is central to the paper's focus on how AI models evaluate multimodal inputs, linking to the broader concept of Vision-Language Models.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.72,
        "link_intent_score": 0.85
      },
      {
        "surface": "GPT Models",
        "canonical": "Large Language Model",
        "aliases": [
          "GPT-4o",
          "GPT-4o-mini",
          "GPT-5"
        ],
        "category": "broad_technical",
        "rationale": "GPT models are a subset of Large Language Models, which are crucial for understanding AI evaluation patterns.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.8
      },
      {
        "surface": "Evaluation Personalities",
        "canonical": "Evaluation Bias",
        "aliases": [
          "Assessment Strategies"
        ],
        "category": "unique_technical",
        "rationale": "The concept of 'evaluation personalities' is unique to this study, highlighting biases in AI assessment.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      },
      {
        "surface": "Semantic Similarity",
        "canonical": "Semantic Similarity",
        "aliases": [
          "Semantic Clustering"
        ],
        "category": "specific_connectable",
        "rationale": "Semantic similarity is a key method used in the paper to analyze model evaluation patterns.",
        "novelty_score": 0.5,
        "connectivity_score": 0.78,
        "specificity_score": 0.7,
        "link_intent_score": 0.78
      },
      {
        "surface": "Negative Assessment Bias",
        "canonical": "Evaluation Bias",
        "aliases": [
          "Negative Bias"
        ],
        "category": "unique_technical",
        "rationale": "The paper identifies a specific bias towards negative assessments, which is crucial for understanding AI evaluation behavior.",
        "novelty_score": 0.65,
        "connectivity_score": 0.65,
        "specificity_score": 0.75,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "AI systems",
      "NVIDIA",
      "Gemini 2.5 Pro"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Vision-Language Descriptions",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.72,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "GPT Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Evaluation Personalities",
      "resolved_canonical": "Evaluation Bias",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Semantic Similarity",
      "resolved_canonical": "Semantic Similarity",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.78,
        "specificity": 0.7,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Negative Assessment Bias",
      "resolved_canonical": "Evaluation Bias",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.65,
        "specificity": 0.75,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# Understanding AI Evaluation Patterns: How Different GPT Models Assess Vision-Language Descriptions

**Korean Title:** AI 평가 패턴 이해: 다양한 GPT 모델이 시각-언어 설명을 평가하는 방법

## 📋 메타데이터

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.10707.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2509.10707](https://arxiv.org/abs/2509.10707)

## 🔗 유사한 논문
- [[2025-09-18/Designing AI-Agents with Personalities_ A Psychometric Approach_20250918|Designing AI-Agents with Personalities: A Psychometric Approach]] (83.6% similar)
- [[2025-09-22/Where Fact Ends and Fairness Begins_ Redefining AI Bias Evaluation through Cognitive Biases_20250922|Where Fact Ends and Fairness Begins: Redefining AI Bias Evaluation through Cognitive Biases]] (81.9% similar)
- [[2025-09-18/Is GPT-4o mini Blinded by its Own Safety Filters? Exposing the Multimodal-to-Unimodal Bottleneck in Hate Speech Detection_20250918|Is GPT-4o mini Blinded by its Own Safety Filters? Exposing the Multimodal-to-Unimodal Bottleneck in Hate Speech Detection]] (81.8% similar)
- [[2025-09-19/Judging with Many Minds_ Do More Perspectives Mean Less Prejudice? On Bias Amplifications and Resistance in Multi-Agent Based LLM-as-Judge_20250919|Judging with Many Minds: Do More Perspectives Mean Less Prejudice? On Bias Amplifications and Resistance in Multi-Agent Based LLM-as-Judge]] (81.2% similar)
- [[2025-09-22/MEDAL_ A Framework for Benchmarking LLMs as Multilingual Open-Domain Dialogue Evaluators_20250922|MEDAL: A Framework for Benchmarking LLMs as Multilingual Open-Domain Dialogue Evaluators]] (80.9% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Semantic Similarity|Semantic Similarity]]
**⚡ Unique Technical**: [[keywords/Evaluation Bias|Evaluation Bias]], [[keywords/Evaluation Bias|Evaluation Bias]]
**🚀 Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.10707v2 Announce Type: replace 
Abstract: As AI systems increasingly evaluate other AI outputs, understanding their assessment behavior becomes crucial for preventing cascading biases. This study analyzes vision-language descriptions generated by NVIDIA's Describe Anything Model and evaluated by three GPT variants (GPT-4o, GPT-4o-mini, GPT-5) to uncover distinct "evaluation personalities" the underlying assessment strategies and biases each model demonstrates. GPT-4o-mini exhibits systematic consistency with minimal variance, GPT-4o excels at error detection, while GPT-5 shows extreme conservatism with high variability. Controlled experiments using Gemini 2.5 Pro as an independent question generator validate that these personalities are inherent model properties rather than artifacts. Cross-family analysis through semantic similarity of generated questions reveals significant divergence: GPT models cluster together with high similarity while Gemini exhibits markedly different evaluation strategies. All GPT models demonstrate a consistent 2:1 bias favoring negative assessment over positive confirmation, though this pattern appears family-specific rather than universal across AI architectures. These findings suggest that evaluation competence does not scale with general capability and that robust AI assessment requires diverse architectural perspectives.

## 🔍 Abstract (한글 번역)

arXiv:2509.10707v2 발표 유형: 교체  
초록: AI 시스템이 다른 AI 출력물을 평가하는 사례가 증가함에 따라, 그들의 평가 행동을 이해하는 것이 연속적인 편향을 방지하는 데 중요해지고 있습니다. 본 연구는 NVIDIA의 Describe Anything Model이 생성한 비전-언어 설명을 세 가지 GPT 변형(GPT-4o, GPT-4o-mini, GPT-5)이 평가한 결과를 분석하여 각 모델이 보여주는 독특한 "평가 성격", 기본 평가 전략 및 편향을 밝혀냅니다. GPT-4o-mini는 최소한의 변동성을 가진 체계적인 일관성을 보이며, GPT-4o는 오류 탐지에 뛰어난 반면, GPT-5는 높은 변동성을 가진 극단적인 보수성을 나타냅니다. 독립적인 질문 생성기로 Gemini 2.5 Pro를 사용한 통제된 실험은 이러한 성격이 인위적인 산물이 아니라 본질적인 모델 속성임을 검증합니다. 생성된 질문의 의미적 유사성을 통한 교차 계열 분석은 상당한 차이를 드러냅니다: GPT 모델은 높은 유사성으로 함께 클러스터링되는 반면, Gemini는 현저히 다른 평가 전략을 보입니다. 모든 GPT 모델은 긍정적 확인보다 부정적 평가를 선호하는 2:1의 일관된 편향을 보여주지만, 이 패턴은 AI 아키텍처 전반에 걸쳐 보편적이라기보다는 계열 특유의 것으로 보입니다. 이러한 발견은 평가 역량이 일반적인 능력과 비례하지 않으며, 견고한 AI 평가에는 다양한 아키텍처적 관점이 필요함을 시사합니다.

## 📝 요약

이 연구는 AI 시스템이 다른 AI의 출력을 평가하는 과정에서 발생할 수 있는 편향을 이해하기 위해, NVIDIA의 Describe Anything Model이 생성한 비전-언어 설명을 세 가지 GPT 변형(GPT-4o, GPT-4o-mini, GPT-5)이 평가하는 방식을 분석합니다. 연구 결과, GPT-4o-mini는 일관성이 높고 변동이 적으며, GPT-4o는 오류 탐지에 뛰어나고, GPT-5는 보수적이며 변동성이 큽니다. Gemini 2.5 Pro를 사용한 실험을 통해 이러한 평가 성향이 모델의 고유한 특성임을 확인했습니다. 또한, GPT 모델들은 서로 유사한 평가 전략을 보이지만, Gemini는 다른 전략을 사용합니다. 모든 GPT 모델은 부정적 평가를 긍정적 평가보다 두 배 더 자주 하는 경향이 있으며, 이는 AI 아키텍처 전반에 걸친 보편적 패턴이 아니라 특정 모델군에 국한된 현상임을 시사합니다. 연구는 평가 능력이 일반적인 능력과 비례하지 않으며, 다양한 아키텍처 관점이 필요함을 강조합니다.

## 🎯 주요 포인트

- 1. AI 시스템 간의 평가 과정에서 발생할 수 있는 편향을 방지하기 위해 AI 평가 행동을 이해하는 것이 중요합니다.
- 2. GPT-4o-mini는 일관성이 높고 변동성이 적으며, GPT-4o는 오류 탐지에 뛰어나고, GPT-5는 극도로 보수적이며 변동성이 큽니다.
- 3. Gemini 2.5 Pro를 사용한 실험을 통해 이러한 평가 성향이 모델의 고유한 특성임을 확인했습니다.
- 4. GPT 모델들은 부정적 평가를 긍정적 확인보다 2:1 비율로 선호하는 경향이 있으며, 이는 AI 아키텍처 전반에 걸친 보편적 패턴은 아닙니다.
- 5. 평가 역량은 일반적인 능력과 비례하지 않으며, 다양한 아키텍처 관점이 필요합니다.


---

*Generated on 2025-09-23 09:42:13*