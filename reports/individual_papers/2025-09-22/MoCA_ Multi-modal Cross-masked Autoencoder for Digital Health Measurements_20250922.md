---
keywords:
  - Multi-modal Cross-masked Autoencoder
  - Self-supervised Learning
  - Transformer
  - Kernelized Canonical Correlation Analysis
  - Digital Health
category: cs.LG
publish_date: 2025-09-22
arxiv_id: 2506.02260
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:20:20.269851",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multi-modal Cross-masked Autoencoder",
    "Self-supervised Learning",
    "Transformer",
    "Kernelized Canonical Correlation Analysis",
    "Digital Health"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multi-modal Cross-masked Autoencoder": 0.8,
    "Self-supervised Learning": 0.78,
    "Transformer": 0.75,
    "Kernelized Canonical Correlation Analysis": 0.72,
    "Digital Health": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multi-modal Cross-masked Autoencoder",
        "canonical": "Multi-modal Cross-masked Autoencoder",
        "aliases": [
          "MoCA"
        ],
        "category": "unique_technical",
        "rationale": "Represents a novel framework specifically designed for leveraging multi-modal data in digital health, enhancing connectivity with unique methodologies.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "self-supervised learning",
        "canonical": "Self-supervised Learning",
        "aliases": [
          "SSL"
        ],
        "category": "specific_connectable",
        "rationale": "A key approach in the paper that aligns with existing self-supervised learning frameworks, facilitating connections to similar methodologies.",
        "novelty_score": 0.4,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.78
      },
      {
        "surface": "Transformer architecture",
        "canonical": "Transformer",
        "aliases": [],
        "category": "broad_technical",
        "rationale": "A foundational architecture used in the proposed framework, linking to a broad range of applications in machine learning.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.75
      },
      {
        "surface": "kernelized canonical correlation analysis",
        "canonical": "Kernelized Canonical Correlation Analysis",
        "aliases": [
          "KCCA"
        ],
        "category": "unique_technical",
        "rationale": "Provides a theoretical foundation for the framework, offering a specific connection to statistical analysis methods.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.72
      },
      {
        "surface": "digital health",
        "canonical": "Digital Health",
        "aliases": [],
        "category": "evolved_concepts",
        "rationale": "Represents the primary application domain of the study, connecting to a growing field of interdisciplinary research.",
        "novelty_score": 0.5,
        "connectivity_score": 0.75,
        "specificity_score": 0.65,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "experiment"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multi-modal Cross-masked Autoencoder",
      "resolved_canonical": "Multi-modal Cross-masked Autoencoder",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "self-supervised learning",
      "resolved_canonical": "Self-supervised Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Transformer architecture",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "kernelized canonical correlation analysis",
      "resolved_canonical": "Kernelized Canonical Correlation Analysis",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "digital health",
      "resolved_canonical": "Digital Health",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.75,
        "specificity": 0.65,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# MoCA: Multi-modal Cross-masked Autoencoder for Digital Health Measurements

**Korean Title:** MoCA: ë””ì§€í„¸ ê±´ê°• ì¸¡ì •ì„ ìœ„í•œ ë‹¤ì¤‘ ëª¨ë‹¬ êµì°¨ ë§ˆìŠ¤í¬ ìë™ ì¸ì½”ë”

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2506.02260.pdf)
**Category**: cs.LG
**Published**: 2025-09-22
**ArXiv ID**: [2506.02260](https://arxiv.org/abs/2506.02260)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/CSMoE_ An Efficient Remote Sensing Foundation Model with Soft Mixture-of-Experts_20250918|CSMoE: An Efficient Remote Sensing Foundation Model with Soft Mixture-of-Experts]] (82.8% similar)
- [[2025-09-22/MTS-DMAE_ Dual-Masked Autoencoder for Unsupervised Multivariate Time Series Representation Learning_20250922|MTS-DMAE: Dual-Masked Autoencoder for Unsupervised Multivariate Time Series Representation Learning]] (82.7% similar)
- [[2025-09-22/Self-supervised learning of imaging and clinical signatures using a multimodal joint-embedding predictive architecture_20250922|Self-supervised learning of imaging and clinical signatures using a multimodal joint-embedding predictive architecture]] (82.3% similar)
- [[2025-09-17/MOCHA_ Multi-modal Objects-aware Cross-arcHitecture Alignment_20250917|MOCHA: Multi-modal Objects-aware Cross-arcHitecture Alignment]] (81.7% similar)
- [[2025-09-19/Mixture of Multicenter Experts in Multimodal AI for Debiased Radiotherapy Target Delineation_20250919|Mixture of Multicenter Experts in Multimodal AI for Debiased Radiotherapy Target Delineation]] (81.7% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Transformer|Transformer]]
**ğŸ”— Specific Connectable**: [[keywords/Self-supervised Learning|Self-supervised Learning]]
**âš¡ Unique Technical**: [[keywords/Multi-modal Cross-masked Autoencoder|Multi-modal Cross-masked Autoencoder]], [[keywords/Kernelized Canonical Correlation Analysis|Kernelized Canonical Correlation Analysis]]
**ğŸš€ Evolved Concepts**: [[keywords/Digital Health|Digital Health]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2506.02260v3 Announce Type: replace-cross 
Abstract: Wearable devices enable continuous multi-modal physiological and behavioral monitoring, yet analysis of these data streams faces fundamental challenges including the lack of gold-standard labels and incomplete sensor data. While self-supervised learning approaches have shown promise for addressing these issues, existing multi-modal extensions present opportunities to better leverage the rich temporal and cross-modal correlations inherent in simultaneously recorded wearable sensor data. We propose the Multi-modal Cross-masked Autoencoder (MoCA), a self-supervised learning framework that combines transformer architecture with masked autoencoder (MAE) methodology, using a principled cross-modality masking scheme that explicitly leverages correlation structures between sensor modalities. MoCA demonstrates strong performance boosts across reconstruction and downstream classification tasks on diverse benchmark datasets. We further establish theoretical guarantees by establishing a fundamental connection between multi-modal MAE loss and kernelized canonical correlation analysis through a Reproducing Kernel Hilbert Space framework, providing principled guidance for correlation-aware masking strategy design. Our approach offers a novel solution for leveraging unlabeled multi-modal wearable data while handling missing modalities, with broad applications across digital health domains.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2506.02260v3 ë°œí‘œ ìœ í˜•: êµì°¨ êµì²´  
ì´ˆë¡: ì›¨ì–´ëŸ¬ë¸” ê¸°ê¸°ëŠ” ì§€ì†ì ì¸ ë‹¤ì¤‘ ëª¨ë“œ ìƒë¦¬ ë° í–‰ë™ ëª¨ë‹ˆí„°ë§ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ì§€ë§Œ, ì´ëŸ¬í•œ ë°ì´í„° ìŠ¤íŠ¸ë¦¼ì˜ ë¶„ì„ì€ í‘œì¤€ ë ˆì´ë¸”ì˜ ë¶€ì¡±ê³¼ ë¶ˆì™„ì „í•œ ì„¼ì„œ ë°ì´í„°ì™€ ê°™ì€ ê·¼ë³¸ì ì¸ ë¬¸ì œì— ì§ë©´í•´ ìˆìŠµë‹ˆë‹¤. ìê¸° ì§€ë„ í•™ìŠµ ì ‘ê·¼ë²•ì€ ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë° ìœ ë§í•œ ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì£¼ì—ˆì§€ë§Œ, ê¸°ì¡´ì˜ ë‹¤ì¤‘ ëª¨ë“œ í™•ì¥ì€ ë™ì‹œì— ê¸°ë¡ëœ ì›¨ì–´ëŸ¬ë¸” ì„¼ì„œ ë°ì´í„°ì— ë‚´ì¬ëœ í’ë¶€í•œ ì‹œê°„ì  ë° êµì°¨ ëª¨ë“œ ìƒê´€ê´€ê³„ë¥¼ ë” ì˜ í™œìš©í•  ê¸°íšŒë¥¼ ì œê³µí•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ ì•„í‚¤í…ì²˜ì™€ ë§ˆìŠ¤í¬ë“œ ì˜¤í† ì¸ì½”ë”(MAE) ë°©ë²•ë¡ ì„ ê²°í•©í•œ ìê¸° ì§€ë„ í•™ìŠµ í”„ë ˆì„ì›Œí¬ì¸ ë‹¤ì¤‘ ëª¨ë“œ êµì°¨ ë§ˆìŠ¤í¬ë“œ ì˜¤í† ì¸ì½”ë”(MoCA)ë¥¼ ì œì•ˆí•˜ë©°, ì„¼ì„œ ëª¨ë‹¬ë¦¬í‹° ê°„ì˜ ìƒê´€ êµ¬ì¡°ë¥¼ ëª…ì‹œì ìœ¼ë¡œ í™œìš©í•˜ëŠ” ì›ì¹™ì ì¸ êµì°¨ ëª¨ë‹¬ë¦¬í‹° ë§ˆìŠ¤í‚¹ ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. MoCAëŠ” ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì—ì„œ ì¬êµ¬ì„±ê³¼ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ë¶„ë¥˜ ì‘ì—… ì „ë°˜ì— ê±¸ì³ ê°•ë ¥í•œ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ë˜í•œ ë‹¤ì¤‘ ëª¨ë“œ MAE ì†ì‹¤ê³¼ ì¬ìƒ ì»¤ë„ íë² ë¥´íŠ¸ ê³µê°„ í”„ë ˆì„ì›Œí¬ë¥¼ í†µí•œ ì»¤ë„í™”ëœ ì •ì¤€ ìƒê´€ ë¶„ì„ ê°„ì˜ ê·¼ë³¸ì ì¸ ì—°ê²°ì„ í™•ë¦½í•˜ì—¬ ìƒê´€ ì¸ì‹ ë§ˆìŠ¤í‚¹ ì „ëµ ì„¤ê³„ì— ëŒ€í•œ ì›ì¹™ì ì¸ ì§€ì¹¨ì„ ì œê³µí•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì ‘ê·¼ë²•ì€ ëˆ„ë½ëœ ëª¨ë‹¬ë¦¬í‹°ë¥¼ ì²˜ë¦¬í•˜ë©´ì„œ ë ˆì´ë¸”ì´ ì—†ëŠ” ë‹¤ì¤‘ ëª¨ë“œ ì›¨ì–´ëŸ¬ë¸” ë°ì´í„°ë¥¼ í™œìš©í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ì†”ë£¨ì…˜ì„ ì œê³µí•˜ë©°, ë””ì§€í„¸ ê±´ê°• ë¶„ì•¼ ì „ë°˜ì— ê±¸ì³ ê´‘ë²”ìœ„í•œ ì‘ìš© ê°€ëŠ¥ì„±ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì›¨ì–´ëŸ¬ë¸” ê¸°ê¸°ì˜ ë‹¤ì¤‘ ëª¨ë“œ ë°ì´í„° ë¶„ì„ì˜ ì–´ë ¤ì›€ì„ í•´ê²°í•˜ê¸° ìœ„í•´ ì œì•ˆëœ Multi-modal Cross-masked Autoencoder (MoCA)ë¼ëŠ” ìƒˆë¡œìš´ ìê¸° ì§€ë„ í•™ìŠµ í”„ë ˆì„ì›Œí¬ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. MoCAëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ ì•„í‚¤í…ì²˜ì™€ ë§ˆìŠ¤í¬ë“œ ì˜¤í† ì¸ì½”ë”(MAE) ë°©ë²•ë¡ ì„ ê²°í•©í•˜ì—¬, ì„¼ì„œ ëª¨ë“œ ê°„ì˜ ìƒê´€ êµ¬ì¡°ë¥¼ í™œìš©í•˜ëŠ” êµì°¨ ëª¨ë“œ ë§ˆìŠ¤í‚¹ ê¸°ë²•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ ì ‘ê·¼ë²•ì€ ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì—ì„œ ì¬êµ¬ì„±ê³¼ ë¶„ë¥˜ ì‘ì—…ì˜ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œì¼°ìœ¼ë©°, ì´ë¡ ì ìœ¼ë¡œë„ ë‹¤ì¤‘ ëª¨ë“œ MAE ì†ì‹¤ê³¼ ì»¤ë„í™”ëœ ì •ì¤€ ìƒê´€ ë¶„ì„ ê°„ì˜ ì—°ê²°ì„ í†µí•´ ìƒê´€ ì¸ì‹ ë§ˆìŠ¤í‚¹ ì „ëµ ì„¤ê³„ì— ëŒ€í•œ ì§€ì¹¨ì„ ì œê³µí•©ë‹ˆë‹¤. MoCAëŠ” ë ˆì´ë¸”ì´ ì—†ëŠ” ë‹¤ì¤‘ ëª¨ë“œ ì›¨ì–´ëŸ¬ë¸” ë°ì´í„°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•˜ê³ , ëˆ„ë½ëœ ëª¨ë“œ ë¬¸ì œë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” í˜ì‹ ì ì¸ ì†”ë£¨ì…˜ì„ ì œì‹œí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì›¨ì–´ëŸ¬ë¸” ê¸°ê¸°ì˜ ë‹¤ì¤‘ ëª¨ë‹¬ë¦¬í‹° ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ì§€ì†ì ì¸ ìƒë¦¬ ë° í–‰ë™ ëª¨ë‹ˆí„°ë§ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ì§€ë§Œ, ë°ì´í„° ë¶„ì„ì—ëŠ” í‘œì¤€ ë ˆì´ë¸” ë¶€ì¡±ê³¼ ë¶ˆì™„ì „í•œ ì„¼ì„œ ë°ì´í„°ë¼ëŠ” ê·¼ë³¸ì ì¸ ë¬¸ì œê°€ ì¡´ì¬í•©ë‹ˆë‹¤.
- 2. ì œì•ˆëœ Multi-modal Cross-masked Autoencoder (MoCA)ëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ ì•„í‚¤í…ì²˜ì™€ ë§ˆìŠ¤í¬ë“œ ì˜¤í† ì¸ì½”ë” ë°©ë²•ë¡ ì„ ê²°í•©í•˜ì—¬ ì„¼ì„œ ëª¨ë‹¬ë¦¬í‹° ê°„ì˜ ìƒê´€ êµ¬ì¡°ë¥¼ í™œìš©í•˜ëŠ” êµì°¨ ëª¨ë‹¬ë¦¬í‹° ë§ˆìŠ¤í‚¹ ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
- 3. MoCAëŠ” ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì—ì„œ ì¬êµ¬ì„± ë° ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ë¶„ë¥˜ ì‘ì—…ì—ì„œ ê°•ë ¥í•œ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
- 4. ì´ë¡ ì  ë³´ì¥ì„ í†µí•´ ë‹¤ì¤‘ ëª¨ë‹¬ MAE ì†ì‹¤ê³¼ ì»¤ë„í™”ëœ ì •ì¤€ ìƒê´€ ë¶„ì„ ê°„ì˜ ê·¼ë³¸ì ì¸ ì—°ê²°ì„ í™•ë¦½í•˜ì—¬ ìƒê´€ ì¸ì‹ ë§ˆìŠ¤í‚¹ ì „ëµ ì„¤ê³„ë¥¼ ìœ„í•œ ì›ì¹™ì ì¸ ì§€ì¹¨ì„ ì œê³µí•©ë‹ˆë‹¤.
- 5. ì œì•ˆëœ ì ‘ê·¼ ë°©ì‹ì€ ë””ì§€í„¸ í—¬ìŠ¤ ë¶„ì•¼ ì „ë°˜ì— ê±¸ì³ ì‘ìš© ê°€ëŠ¥í•œ, ë ˆì´ë¸”ì´ ì—†ëŠ” ë‹¤ì¤‘ ëª¨ë‹¬ ì›¨ì–´ëŸ¬ë¸” ë°ì´í„°ë¥¼ í™œìš©í•˜ë©´ì„œ ëˆ„ë½ëœ ëª¨ë‹¬ë¦¬í‹°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ìƒˆë¡œìš´ ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.


---

*Generated on 2025-09-23 11:20:20*