---
keywords:
  - Multi-modal Cross-masked Autoencoder
  - Self-supervised Learning
  - Transformer
  - Kernelized Canonical Correlation Analysis
  - Digital Health
category: cs.LG
publish_date: 2025-09-22
arxiv_id: 2506.02260
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:20:20.269851",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multi-modal Cross-masked Autoencoder",
    "Self-supervised Learning",
    "Transformer",
    "Kernelized Canonical Correlation Analysis",
    "Digital Health"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multi-modal Cross-masked Autoencoder": 0.8,
    "Self-supervised Learning": 0.78,
    "Transformer": 0.75,
    "Kernelized Canonical Correlation Analysis": 0.72,
    "Digital Health": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multi-modal Cross-masked Autoencoder",
        "canonical": "Multi-modal Cross-masked Autoencoder",
        "aliases": [
          "MoCA"
        ],
        "category": "unique_technical",
        "rationale": "Represents a novel framework specifically designed for leveraging multi-modal data in digital health, enhancing connectivity with unique methodologies.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "self-supervised learning",
        "canonical": "Self-supervised Learning",
        "aliases": [
          "SSL"
        ],
        "category": "specific_connectable",
        "rationale": "A key approach in the paper that aligns with existing self-supervised learning frameworks, facilitating connections to similar methodologies.",
        "novelty_score": 0.4,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.78
      },
      {
        "surface": "Transformer architecture",
        "canonical": "Transformer",
        "aliases": [],
        "category": "broad_technical",
        "rationale": "A foundational architecture used in the proposed framework, linking to a broad range of applications in machine learning.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.75
      },
      {
        "surface": "kernelized canonical correlation analysis",
        "canonical": "Kernelized Canonical Correlation Analysis",
        "aliases": [
          "KCCA"
        ],
        "category": "unique_technical",
        "rationale": "Provides a theoretical foundation for the framework, offering a specific connection to statistical analysis methods.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.72
      },
      {
        "surface": "digital health",
        "canonical": "Digital Health",
        "aliases": [],
        "category": "evolved_concepts",
        "rationale": "Represents the primary application domain of the study, connecting to a growing field of interdisciplinary research.",
        "novelty_score": 0.5,
        "connectivity_score": 0.75,
        "specificity_score": 0.65,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "experiment"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multi-modal Cross-masked Autoencoder",
      "resolved_canonical": "Multi-modal Cross-masked Autoencoder",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "self-supervised learning",
      "resolved_canonical": "Self-supervised Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Transformer architecture",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "kernelized canonical correlation analysis",
      "resolved_canonical": "Kernelized Canonical Correlation Analysis",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "digital health",
      "resolved_canonical": "Digital Health",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.75,
        "specificity": 0.65,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# MoCA: Multi-modal Cross-masked Autoencoder for Digital Health Measurements

**Korean Title:** MoCA: 디지털 건강 측정을 위한 다중 모달 교차 마스크 자동 인코더

## 📋 메타데이터

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2506.02260.pdf)
**Category**: cs.LG
**Published**: 2025-09-22
**ArXiv ID**: [2506.02260](https://arxiv.org/abs/2506.02260)

## 🔗 유사한 논문
- [[2025-09-18/CSMoE_ An Efficient Remote Sensing Foundation Model with Soft Mixture-of-Experts_20250918|CSMoE: An Efficient Remote Sensing Foundation Model with Soft Mixture-of-Experts]] (82.8% similar)
- [[2025-09-22/MTS-DMAE_ Dual-Masked Autoencoder for Unsupervised Multivariate Time Series Representation Learning_20250922|MTS-DMAE: Dual-Masked Autoencoder for Unsupervised Multivariate Time Series Representation Learning]] (82.7% similar)
- [[2025-09-22/Self-supervised learning of imaging and clinical signatures using a multimodal joint-embedding predictive architecture_20250922|Self-supervised learning of imaging and clinical signatures using a multimodal joint-embedding predictive architecture]] (82.3% similar)
- [[2025-09-17/MOCHA_ Multi-modal Objects-aware Cross-arcHitecture Alignment_20250917|MOCHA: Multi-modal Objects-aware Cross-arcHitecture Alignment]] (81.7% similar)
- [[2025-09-19/Mixture of Multicenter Experts in Multimodal AI for Debiased Radiotherapy Target Delineation_20250919|Mixture of Multicenter Experts in Multimodal AI for Debiased Radiotherapy Target Delineation]] (81.7% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Transformer|Transformer]]
**🔗 Specific Connectable**: [[keywords/Self-supervised Learning|Self-supervised Learning]]
**⚡ Unique Technical**: [[keywords/Multi-modal Cross-masked Autoencoder|Multi-modal Cross-masked Autoencoder]], [[keywords/Kernelized Canonical Correlation Analysis|Kernelized Canonical Correlation Analysis]]
**🚀 Evolved Concepts**: [[keywords/Digital Health|Digital Health]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2506.02260v3 Announce Type: replace-cross 
Abstract: Wearable devices enable continuous multi-modal physiological and behavioral monitoring, yet analysis of these data streams faces fundamental challenges including the lack of gold-standard labels and incomplete sensor data. While self-supervised learning approaches have shown promise for addressing these issues, existing multi-modal extensions present opportunities to better leverage the rich temporal and cross-modal correlations inherent in simultaneously recorded wearable sensor data. We propose the Multi-modal Cross-masked Autoencoder (MoCA), a self-supervised learning framework that combines transformer architecture with masked autoencoder (MAE) methodology, using a principled cross-modality masking scheme that explicitly leverages correlation structures between sensor modalities. MoCA demonstrates strong performance boosts across reconstruction and downstream classification tasks on diverse benchmark datasets. We further establish theoretical guarantees by establishing a fundamental connection between multi-modal MAE loss and kernelized canonical correlation analysis through a Reproducing Kernel Hilbert Space framework, providing principled guidance for correlation-aware masking strategy design. Our approach offers a novel solution for leveraging unlabeled multi-modal wearable data while handling missing modalities, with broad applications across digital health domains.

## 🔍 Abstract (한글 번역)

arXiv:2506.02260v3 발표 유형: 교차 교체  
초록: 웨어러블 기기는 지속적인 다중 모드 생리 및 행동 모니터링을 가능하게 하지만, 이러한 데이터 스트림의 분석은 표준 레이블의 부족과 불완전한 센서 데이터와 같은 근본적인 문제에 직면해 있습니다. 자기 지도 학습 접근법은 이러한 문제를 해결하는 데 유망한 가능성을 보여주었지만, 기존의 다중 모드 확장은 동시에 기록된 웨어러블 센서 데이터에 내재된 풍부한 시간적 및 교차 모드 상관관계를 더 잘 활용할 기회를 제공합니다. 우리는 트랜스포머 아키텍처와 마스크드 오토인코더(MAE) 방법론을 결합한 자기 지도 학습 프레임워크인 다중 모드 교차 마스크드 오토인코더(MoCA)를 제안하며, 센서 모달리티 간의 상관 구조를 명시적으로 활용하는 원칙적인 교차 모달리티 마스킹 방식을 사용합니다. MoCA는 다양한 벤치마크 데이터셋에서 재구성과 다운스트림 분류 작업 전반에 걸쳐 강력한 성능 향상을 보여줍니다. 우리는 또한 다중 모드 MAE 손실과 재생 커널 힐베르트 공간 프레임워크를 통한 커널화된 정준 상관 분석 간의 근본적인 연결을 확립하여 상관 인식 마스킹 전략 설계에 대한 원칙적인 지침을 제공합니다. 우리의 접근법은 누락된 모달리티를 처리하면서 레이블이 없는 다중 모드 웨어러블 데이터를 활용하기 위한 새로운 솔루션을 제공하며, 디지털 건강 분야 전반에 걸쳐 광범위한 응용 가능성을 가지고 있습니다.

## 📝 요약

이 논문은 웨어러블 기기의 다중 모드 데이터 분석의 어려움을 해결하기 위해 제안된 Multi-modal Cross-masked Autoencoder (MoCA)라는 새로운 자기 지도 학습 프레임워크를 소개합니다. MoCA는 트랜스포머 아키텍처와 마스크드 오토인코더(MAE) 방법론을 결합하여, 센서 모드 간의 상관 구조를 활용하는 교차 모드 마스킹 기법을 사용합니다. 이 접근법은 다양한 벤치마크 데이터셋에서 재구성과 분류 작업의 성능을 크게 향상시켰으며, 이론적으로도 다중 모드 MAE 손실과 커널화된 정준 상관 분석 간의 연결을 통해 상관 인식 마스킹 전략 설계에 대한 지침을 제공합니다. MoCA는 레이블이 없는 다중 모드 웨어러블 데이터를 효과적으로 활용하고, 누락된 모드 문제를 처리할 수 있는 혁신적인 솔루션을 제시합니다.

## 🎯 주요 포인트

- 1. 웨어러블 기기의 다중 모달리티 데이터를 활용하여 지속적인 생리 및 행동 모니터링을 가능하게 하지만, 데이터 분석에는 표준 레이블 부족과 불완전한 센서 데이터라는 근본적인 문제가 존재합니다.
- 2. 제안된 Multi-modal Cross-masked Autoencoder (MoCA)는 트랜스포머 아키텍처와 마스크드 오토인코더 방법론을 결합하여 센서 모달리티 간의 상관 구조를 활용하는 교차 모달리티 마스킹 방식을 사용합니다.
- 3. MoCA는 다양한 벤치마크 데이터셋에서 재구성 및 다운스트림 분류 작업에서 강력한 성능 향상을 보여줍니다.
- 4. 이론적 보장을 통해 다중 모달 MAE 손실과 커널화된 정준 상관 분석 간의 근본적인 연결을 확립하여 상관 인식 마스킹 전략 설계를 위한 원칙적인 지침을 제공합니다.
- 5. 제안된 접근 방식은 디지털 헬스 분야 전반에 걸쳐 응용 가능한, 레이블이 없는 다중 모달 웨어러블 데이터를 활용하면서 누락된 모달리티를 처리하는 새로운 솔루션을 제공합니다.


---

*Generated on 2025-09-23 11:20:20*