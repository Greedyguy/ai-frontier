---
keywords:
  - FOVAL
  - Neural Network
  - Temporal Convolutional Networks
  - Cross-Validation
  - Extended Reality
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2408.03591
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T09:45:02.217248",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "FOVAL",
    "Neural Network",
    "Temporal Convolutional Networks",
    "Cross-Validation",
    "Extended Reality"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "FOVAL": 0.78,
    "Neural Network": 0.82,
    "Temporal Convolutional Networks": 0.77,
    "Cross-Validation": 0.76,
    "Extended Reality": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "FOVAL",
        "canonical": "FOVAL",
        "aliases": [
          "Fixation Depth Estimation"
        ],
        "category": "unique_technical",
        "rationale": "FOVAL represents a novel approach in fixation depth estimation, offering potential for unique insights and connections in eye-tracking research.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.78
      },
      {
        "surface": "Long Short-Term Memory networks",
        "canonical": "Neural Network",
        "aliases": [
          "LSTM"
        ],
        "category": "broad_technical",
        "rationale": "LSTMs are a foundational neural network architecture relevant for sequence modeling, linking to broader machine learning concepts.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.82
      },
      {
        "surface": "Temporal Convolutional Networks",
        "canonical": "Temporal Convolutional Networks",
        "aliases": [
          "TCN"
        ],
        "category": "specific_connectable",
        "rationale": "TCNs are a specific neural network architecture that can be linked to temporal data processing techniques.",
        "novelty_score": 0.6,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      },
      {
        "surface": "Leave-One-Out Cross-Validation",
        "canonical": "Cross-Validation",
        "aliases": [
          "LOOCV"
        ],
        "category": "specific_connectable",
        "rationale": "LOOCV is a specific validation technique that can be linked to model evaluation methods in machine learning.",
        "novelty_score": 0.5,
        "connectivity_score": 0.7,
        "specificity_score": 0.75,
        "link_intent_score": 0.76
      },
      {
        "surface": "extended reality",
        "canonical": "Extended Reality",
        "aliases": [
          "XR"
        ],
        "category": "evolved_concepts",
        "rationale": "Extended Reality is an emerging field that intersects with various technological applications, providing strong linking potential.",
        "novelty_score": 0.65,
        "connectivity_score": 0.78,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "calibration-free",
      "subject-invariant",
      "mean absolute error"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "FOVAL",
      "resolved_canonical": "FOVAL",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Long Short-Term Memory networks",
      "resolved_canonical": "Neural Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Temporal Convolutional Networks",
      "resolved_canonical": "Temporal Convolutional Networks",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Leave-One-Out Cross-Validation",
      "resolved_canonical": "Cross-Validation",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.7,
        "specificity": 0.75,
        "link_intent": 0.76
      }
    },
    {
      "candidate_surface": "extended reality",
      "resolved_canonical": "Extended Reality",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.78,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# FOVAL: Calibration-Free and Subject-Invariant Fixation Depth Estimation Across Diverse Eye-Tracking Datasets

**Korean Title:** FOVAL: 다양한 시선 추적 데이터셋에서 보정이 필요 없고 피험자에 구애받지 않는 고정 깊이 추정

## 📋 메타데이터

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2408.03591.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2408.03591](https://arxiv.org/abs/2408.03591)

## 🔗 유사한 논문
- [[2025-09-19/ForceVLA_ Enhancing VLA Models with a Force-aware MoE for Contact-rich Manipulation_20250919|ForceVLA: Enhancing VLA Models with a Force-aware MoE for Contact-rich Manipulation]] (82.5% similar)
- [[2025-09-22/ORCA_ Agentic Reasoning For Hallucination and Adversarial Robustness in Vision-Language Models_20250922|ORCA: Agentic Reasoning For Hallucination and Adversarial Robustness in Vision-Language Models]] (81.2% similar)
- [[2025-09-19/Depth AnyEvent_ A Cross-Modal Distillation Paradigm for Event-Based Monocular Depth Estimation_20250919|Depth AnyEvent: A Cross-Modal Distillation Paradigm for Event-Based Monocular Depth Estimation]] (81.1% similar)
- [[2025-09-18/Lost in Translation? Vocabulary Alignment for Source-Free Domain Adaptation in Open-Vocabulary Semantic Segmentation_20250918|Lost in Translation? Vocabulary Alignment for Source-Free Domain Adaptation in Open-Vocabulary Semantic Segmentation]] (80.9% similar)
- [[2025-09-22/Saccadic Vision for Fine-Grained Visual Classification_20250922|Saccadic Vision for Fine-Grained Visual Classification]] (80.9% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Neural Network|Neural Network]]
**🔗 Specific Connectable**: [[keywords/Temporal Convolutional Networks|Temporal Convolutional Networks]], [[keywords/Cross-Validation|Cross-Validation]]
**⚡ Unique Technical**: [[keywords/FOVAL|FOVAL]]
**🚀 Evolved Concepts**: [[keywords/Extended Reality|Extended Reality]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2408.03591v2 Announce Type: replace-cross 
Abstract: Accurate fixation depth estimation is essential for applications in extended reality (XR), robotics, and human-computer interaction. However, current methods heavily depend on user-specific calibration, which limits their scalability and usability. We introduce FOVAL, a robust calibration-free approach that combines spatiotemporal sequence modelling via Long Short-Term Memory (LSTM) networks with subject-invariant feature engineering and normalisation. Compared to Transformers, Temporal Convolutional Networks (TCNs), and CNNs, FOVAL achieves superior performance, particularly in scenarios with limited and noisy gaze data. Evaluations across three benchmark datasets using Leave-One-Out Cross-Validation (LOOCV) and cross-dataset validation show a mean absolute error (MAE) of 9.1 cm and strong generalisation without calibration. We further analyse inter-subject variability and domain shifts, providing insight into model robustness and adaptation. FOVAL's scalability and accuracy make it highly suitable for real-world deployment.

## 🔍 Abstract (한글 번역)

arXiv:2408.03591v2 발표 유형: 교차 교체  
초록: 정확한 고정 깊이 추정은 확장 현실(XR), 로봇공학 및 인간-컴퓨터 상호작용 응용 분야에서 필수적입니다. 그러나 현재의 방법들은 사용자별 보정에 크게 의존하여 확장성과 사용성을 제한합니다. 우리는 LSTM(Long Short-Term Memory) 네트워크를 통한 시공간 시퀀스 모델링과 주제 불변 특징 공학 및 정규화를 결합한 강력한 보정 없는 접근 방식인 FOVAL을 소개합니다. 트랜스포머, 시계열 컨볼루션 네트워크(TCN), CNN과 비교했을 때, FOVAL은 특히 제한적이고 잡음이 많은 시선 데이터 시나리오에서 우수한 성능을 발휘합니다. 세 가지 벤치마크 데이터셋에서 Leave-One-Out 교차 검증(LOOCV) 및 교차 데이터셋 검증을 통해 평균 절대 오차(MAE) 9.1 cm와 보정 없이 강력한 일반화를 보여줍니다. 우리는 또한 피험자 간 변동성과 도메인 변화를 분석하여 모델의 강건성과 적응에 대한 통찰력을 제공합니다. FOVAL의 확장성과 정확성은 실제 환경에서의 배포에 매우 적합합니다.

## 📝 요약

이 논문은 XR, 로봇공학, 인간-컴퓨터 상호작용에서 중요한 고정 깊이 추정을 위한 새로운 접근법인 FOVAL을 제안합니다. FOVAL은 사용자별 보정 없이 LSTM 네트워크를 활용한 시공간 시퀀스 모델링과 주제 불변적 특징 공학 및 정규화를 결합하여 기존 방법의 한계를 극복합니다. FOVAL은 제한적이고 잡음이 많은 시선 데이터에서도 뛰어난 성능을 보이며, 세 가지 벤치마크 데이터셋에서 Leave-One-Out 교차 검증과 교차 데이터셋 검증을 통해 평균 절대 오차 9.1cm를 기록했습니다. 또한, 주제 간 변동성과 도메인 변화에 대한 분석을 통해 모델의 견고성과 적응성을 입증했습니다. FOVAL은 보정 없이도 높은 정확도와 확장성을 제공하여 실제 환경에 적합합니다.

## 🎯 주요 포인트

- 1. FOVAL은 사용자별 보정이 필요 없는 견고한 방법으로, LSTM 네트워크를 활용한 시공간 시퀀스 모델링과 주제 불변 특징 엔지니어링 및 정규화를 결합합니다.
- 2. FOVAL은 제한적이고 잡음이 많은 시선 데이터 시나리오에서 특히 뛰어난 성능을 발휘하며, Transformers, TCNs, CNNs보다 우수한 성능을 보입니다.
- 3. 세 가지 벤치마크 데이터셋에 대한 평가에서 FOVAL은 보정 없이도 평균 절대 오차(MAE) 9.1cm를 기록하며 강력한 일반화 성능을 입증했습니다.
- 4. 연구는 주제 간 변동성과 도메인 변화를 분석하여 모델의 견고성과 적응에 대한 통찰을 제공합니다.
- 5. FOVAL의 확장성과 정확성은 실제 환경에서의 적용에 매우 적합합니다.


---

*Generated on 2025-09-23 09:45:02*