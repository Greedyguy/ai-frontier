---
keywords:
  - FOVAL
  - Neural Network
  - Temporal Convolutional Networks
  - Cross-Validation
  - Extended Reality
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2408.03591
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T09:45:02.217248",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "FOVAL",
    "Neural Network",
    "Temporal Convolutional Networks",
    "Cross-Validation",
    "Extended Reality"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "FOVAL": 0.78,
    "Neural Network": 0.82,
    "Temporal Convolutional Networks": 0.77,
    "Cross-Validation": 0.76,
    "Extended Reality": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "FOVAL",
        "canonical": "FOVAL",
        "aliases": [
          "Fixation Depth Estimation"
        ],
        "category": "unique_technical",
        "rationale": "FOVAL represents a novel approach in fixation depth estimation, offering potential for unique insights and connections in eye-tracking research.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.78
      },
      {
        "surface": "Long Short-Term Memory networks",
        "canonical": "Neural Network",
        "aliases": [
          "LSTM"
        ],
        "category": "broad_technical",
        "rationale": "LSTMs are a foundational neural network architecture relevant for sequence modeling, linking to broader machine learning concepts.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.82
      },
      {
        "surface": "Temporal Convolutional Networks",
        "canonical": "Temporal Convolutional Networks",
        "aliases": [
          "TCN"
        ],
        "category": "specific_connectable",
        "rationale": "TCNs are a specific neural network architecture that can be linked to temporal data processing techniques.",
        "novelty_score": 0.6,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      },
      {
        "surface": "Leave-One-Out Cross-Validation",
        "canonical": "Cross-Validation",
        "aliases": [
          "LOOCV"
        ],
        "category": "specific_connectable",
        "rationale": "LOOCV is a specific validation technique that can be linked to model evaluation methods in machine learning.",
        "novelty_score": 0.5,
        "connectivity_score": 0.7,
        "specificity_score": 0.75,
        "link_intent_score": 0.76
      },
      {
        "surface": "extended reality",
        "canonical": "Extended Reality",
        "aliases": [
          "XR"
        ],
        "category": "evolved_concepts",
        "rationale": "Extended Reality is an emerging field that intersects with various technological applications, providing strong linking potential.",
        "novelty_score": 0.65,
        "connectivity_score": 0.78,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "calibration-free",
      "subject-invariant",
      "mean absolute error"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "FOVAL",
      "resolved_canonical": "FOVAL",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Long Short-Term Memory networks",
      "resolved_canonical": "Neural Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Temporal Convolutional Networks",
      "resolved_canonical": "Temporal Convolutional Networks",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Leave-One-Out Cross-Validation",
      "resolved_canonical": "Cross-Validation",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.7,
        "specificity": 0.75,
        "link_intent": 0.76
      }
    },
    {
      "candidate_surface": "extended reality",
      "resolved_canonical": "Extended Reality",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.78,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# FOVAL: Calibration-Free and Subject-Invariant Fixation Depth Estimation Across Diverse Eye-Tracking Datasets

**Korean Title:** FOVAL: ë‹¤ì–‘í•œ ì‹œì„  ì¶”ì  ë°ì´í„°ì…‹ì—ì„œ ë³´ì •ì´ í•„ìš” ì—†ê³  í”¼í—˜ìì— êµ¬ì• ë°›ì§€ ì•ŠëŠ” ê³ ì • ê¹Šì´ ì¶”ì •

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2408.03591.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2408.03591](https://arxiv.org/abs/2408.03591)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/ForceVLA_ Enhancing VLA Models with a Force-aware MoE for Contact-rich Manipulation_20250919|ForceVLA: Enhancing VLA Models with a Force-aware MoE for Contact-rich Manipulation]] (82.5% similar)
- [[2025-09-22/ORCA_ Agentic Reasoning For Hallucination and Adversarial Robustness in Vision-Language Models_20250922|ORCA: Agentic Reasoning For Hallucination and Adversarial Robustness in Vision-Language Models]] (81.2% similar)
- [[2025-09-19/Depth AnyEvent_ A Cross-Modal Distillation Paradigm for Event-Based Monocular Depth Estimation_20250919|Depth AnyEvent: A Cross-Modal Distillation Paradigm for Event-Based Monocular Depth Estimation]] (81.1% similar)
- [[2025-09-18/Lost in Translation? Vocabulary Alignment for Source-Free Domain Adaptation in Open-Vocabulary Semantic Segmentation_20250918|Lost in Translation? Vocabulary Alignment for Source-Free Domain Adaptation in Open-Vocabulary Semantic Segmentation]] (80.9% similar)
- [[2025-09-22/Saccadic Vision for Fine-Grained Visual Classification_20250922|Saccadic Vision for Fine-Grained Visual Classification]] (80.9% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Neural Network|Neural Network]]
**ğŸ”— Specific Connectable**: [[keywords/Temporal Convolutional Networks|Temporal Convolutional Networks]], [[keywords/Cross-Validation|Cross-Validation]]
**âš¡ Unique Technical**: [[keywords/FOVAL|FOVAL]]
**ğŸš€ Evolved Concepts**: [[keywords/Extended Reality|Extended Reality]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2408.03591v2 Announce Type: replace-cross 
Abstract: Accurate fixation depth estimation is essential for applications in extended reality (XR), robotics, and human-computer interaction. However, current methods heavily depend on user-specific calibration, which limits their scalability and usability. We introduce FOVAL, a robust calibration-free approach that combines spatiotemporal sequence modelling via Long Short-Term Memory (LSTM) networks with subject-invariant feature engineering and normalisation. Compared to Transformers, Temporal Convolutional Networks (TCNs), and CNNs, FOVAL achieves superior performance, particularly in scenarios with limited and noisy gaze data. Evaluations across three benchmark datasets using Leave-One-Out Cross-Validation (LOOCV) and cross-dataset validation show a mean absolute error (MAE) of 9.1 cm and strong generalisation without calibration. We further analyse inter-subject variability and domain shifts, providing insight into model robustness and adaptation. FOVAL's scalability and accuracy make it highly suitable for real-world deployment.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2408.03591v2 ë°œí‘œ ìœ í˜•: êµì°¨ êµì²´  
ì´ˆë¡: ì •í™•í•œ ê³ ì • ê¹Šì´ ì¶”ì •ì€ í™•ì¥ í˜„ì‹¤(XR), ë¡œë´‡ê³µí•™ ë° ì¸ê°„-ì»´í“¨í„° ìƒí˜¸ì‘ìš© ì‘ìš© ë¶„ì•¼ì—ì„œ í•„ìˆ˜ì ì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ í˜„ì¬ì˜ ë°©ë²•ë“¤ì€ ì‚¬ìš©ìë³„ ë³´ì •ì— í¬ê²Œ ì˜ì¡´í•˜ì—¬ í™•ì¥ì„±ê³¼ ì‚¬ìš©ì„±ì„ ì œí•œí•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” LSTM(Long Short-Term Memory) ë„¤íŠ¸ì›Œí¬ë¥¼ í†µí•œ ì‹œê³µê°„ ì‹œí€€ìŠ¤ ëª¨ë¸ë§ê³¼ ì£¼ì œ ë¶ˆë³€ íŠ¹ì§• ê³µí•™ ë° ì •ê·œí™”ë¥¼ ê²°í•©í•œ ê°•ë ¥í•œ ë³´ì • ì—†ëŠ” ì ‘ê·¼ ë°©ì‹ì¸ FOVALì„ ì†Œê°œí•©ë‹ˆë‹¤. íŠ¸ëœìŠ¤í¬ë¨¸, ì‹œê³„ì—´ ì»¨ë³¼ë£¨ì…˜ ë„¤íŠ¸ì›Œí¬(TCN), CNNê³¼ ë¹„êµí–ˆì„ ë•Œ, FOVALì€ íŠ¹íˆ ì œí•œì ì´ê³  ì¡ìŒì´ ë§ì€ ì‹œì„  ë°ì´í„° ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë°œíœ˜í•©ë‹ˆë‹¤. ì„¸ ê°€ì§€ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì—ì„œ Leave-One-Out êµì°¨ ê²€ì¦(LOOCV) ë° êµì°¨ ë°ì´í„°ì…‹ ê²€ì¦ì„ í†µí•´ í‰ê·  ì ˆëŒ€ ì˜¤ì°¨(MAE) 9.1 cmì™€ ë³´ì • ì—†ì´ ê°•ë ¥í•œ ì¼ë°˜í™”ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ë˜í•œ í”¼í—˜ì ê°„ ë³€ë™ì„±ê³¼ ë„ë©”ì¸ ë³€í™”ë¥¼ ë¶„ì„í•˜ì—¬ ëª¨ë¸ì˜ ê°•ê±´ì„±ê³¼ ì ì‘ì— ëŒ€í•œ í†µì°°ë ¥ì„ ì œê³µí•©ë‹ˆë‹¤. FOVALì˜ í™•ì¥ì„±ê³¼ ì •í™•ì„±ì€ ì‹¤ì œ í™˜ê²½ì—ì„œì˜ ë°°í¬ì— ë§¤ìš° ì í•©í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ XR, ë¡œë´‡ê³µí•™, ì¸ê°„-ì»´í“¨í„° ìƒí˜¸ì‘ìš©ì—ì„œ ì¤‘ìš”í•œ ê³ ì • ê¹Šì´ ì¶”ì •ì„ ìœ„í•œ ìƒˆë¡œìš´ ì ‘ê·¼ë²•ì¸ FOVALì„ ì œì•ˆí•©ë‹ˆë‹¤. FOVALì€ ì‚¬ìš©ìë³„ ë³´ì • ì—†ì´ LSTM ë„¤íŠ¸ì›Œí¬ë¥¼ í™œìš©í•œ ì‹œê³µê°„ ì‹œí€€ìŠ¤ ëª¨ë¸ë§ê³¼ ì£¼ì œ ë¶ˆë³€ì  íŠ¹ì§• ê³µí•™ ë° ì •ê·œí™”ë¥¼ ê²°í•©í•˜ì—¬ ê¸°ì¡´ ë°©ë²•ì˜ í•œê³„ë¥¼ ê·¹ë³µí•©ë‹ˆë‹¤. FOVALì€ ì œí•œì ì´ê³  ì¡ìŒì´ ë§ì€ ì‹œì„  ë°ì´í„°ì—ì„œë„ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì´ë©°, ì„¸ ê°€ì§€ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì—ì„œ Leave-One-Out êµì°¨ ê²€ì¦ê³¼ êµì°¨ ë°ì´í„°ì…‹ ê²€ì¦ì„ í†µí•´ í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ 9.1cmë¥¼ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, ì£¼ì œ ê°„ ë³€ë™ì„±ê³¼ ë„ë©”ì¸ ë³€í™”ì— ëŒ€í•œ ë¶„ì„ì„ í†µí•´ ëª¨ë¸ì˜ ê²¬ê³ ì„±ê³¼ ì ì‘ì„±ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤. FOVALì€ ë³´ì • ì—†ì´ë„ ë†’ì€ ì •í™•ë„ì™€ í™•ì¥ì„±ì„ ì œê³µí•˜ì—¬ ì‹¤ì œ í™˜ê²½ì— ì í•©í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. FOVALì€ ì‚¬ìš©ìë³„ ë³´ì •ì´ í•„ìš” ì—†ëŠ” ê²¬ê³ í•œ ë°©ë²•ìœ¼ë¡œ, LSTM ë„¤íŠ¸ì›Œí¬ë¥¼ í™œìš©í•œ ì‹œê³µê°„ ì‹œí€€ìŠ¤ ëª¨ë¸ë§ê³¼ ì£¼ì œ ë¶ˆë³€ íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§ ë° ì •ê·œí™”ë¥¼ ê²°í•©í•©ë‹ˆë‹¤.
- 2. FOVALì€ ì œí•œì ì´ê³  ì¡ìŒì´ ë§ì€ ì‹œì„  ë°ì´í„° ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ íŠ¹íˆ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ë©°, Transformers, TCNs, CNNsë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.
- 3. ì„¸ ê°€ì§€ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì— ëŒ€í•œ í‰ê°€ì—ì„œ FOVALì€ ë³´ì • ì—†ì´ë„ í‰ê·  ì ˆëŒ€ ì˜¤ì°¨(MAE) 9.1cmë¥¼ ê¸°ë¡í•˜ë©° ê°•ë ¥í•œ ì¼ë°˜í™” ì„±ëŠ¥ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.
- 4. ì—°êµ¬ëŠ” ì£¼ì œ ê°„ ë³€ë™ì„±ê³¼ ë„ë©”ì¸ ë³€í™”ë¥¼ ë¶„ì„í•˜ì—¬ ëª¨ë¸ì˜ ê²¬ê³ ì„±ê³¼ ì ì‘ì— ëŒ€í•œ í†µì°°ì„ ì œê³µí•©ë‹ˆë‹¤.
- 5. FOVALì˜ í™•ì¥ì„±ê³¼ ì •í™•ì„±ì€ ì‹¤ì œ í™˜ê²½ì—ì„œì˜ ì ìš©ì— ë§¤ìš° ì í•©í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-23 09:45:02*