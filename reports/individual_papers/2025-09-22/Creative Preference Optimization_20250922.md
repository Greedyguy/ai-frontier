---
keywords:
  - Large Language Model
  - Creative Preference Optimization
  - MuCE Dataset
  - NoveltyBench
  - Psychological Creativity Assessments
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2505.14442
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T09:57:50.968045",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Creative Preference Optimization",
    "MuCE Dataset",
    "NoveltyBench",
    "Psychological Creativity Assessments"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Creative Preference Optimization": 0.95,
    "MuCE Dataset": 0.9,
    "NoveltyBench": 0.8,
    "Psychological Creativity Assessments": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "A fundamental technology discussed in the paper, linking to a broad area of research in NLP.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.5,
        "link_intent_score": 0.85
      },
      {
        "surface": "Creative Preference Optimization",
        "canonical": "Creative Preference Optimization",
        "aliases": [
          "CrPO"
        ],
        "category": "unique_technical",
        "rationale": "A novel method introduced in the paper, central to its contributions.",
        "novelty_score": 0.9,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.95
      },
      {
        "surface": "MuCE",
        "canonical": "MuCE Dataset",
        "aliases": [
          "MuCE"
        ],
        "category": "unique_technical",
        "rationale": "A new dataset introduced in the paper, critical for evaluating the proposed method.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.9
      },
      {
        "surface": "NoveltyBench",
        "canonical": "NoveltyBench",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "A benchmark used for additional evaluations, highlighting the method's generalizability.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "psychological creativity assessments",
        "canonical": "Psychological Creativity Assessments",
        "aliases": [],
        "category": "evolved_concepts",
        "rationale": "Represents a novel application area for LLMs, bridging psychology and AI.",
        "novelty_score": 0.7,
        "connectivity_score": 0.55,
        "specificity_score": 0.75,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "evaluation"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.5,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Creative Preference Optimization",
      "resolved_canonical": "Creative Preference Optimization",
      "decision": "linked",
      "scores": {
        "novelty": 0.9,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.95
      }
    },
    {
      "candidate_surface": "MuCE",
      "resolved_canonical": "MuCE Dataset",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.9
      }
    },
    {
      "candidate_surface": "NoveltyBench",
      "resolved_canonical": "NoveltyBench",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "psychological creativity assessments",
      "resolved_canonical": "Psychological Creativity Assessments",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.55,
        "specificity": 0.75,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# Creative Preference Optimization

**Korean Title:** 창의적 선호 최적화

## 📋 메타데이터

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2505.14442.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2505.14442](https://arxiv.org/abs/2505.14442)

## 🔗 유사한 논문
- [[2025-09-22/A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages_20250922|A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages]] (84.5% similar)
- [[2025-09-18/Evolving Language Models without Labels_ Majority Drives Selection, Novelty Promotes Variation_20250918|Evolving Language Models without Labels: Majority Drives Selection, Novelty Promotes Variation]] (83.3% similar)
- [[2025-09-19/Enhancing Logical Reasoning in Language Models via Symbolically-Guided Monte Carlo Process Supervision_20250919|Enhancing Logical Reasoning in Language Models via Symbolically-Guided Monte Carlo Process Supervision]] (83.2% similar)
- [[2025-09-22/Exploring the Impact of Personality Traits on LLM Bias and Toxicity_20250922|Exploring the Impact of Personality Traits on LLM Bias and Toxicity]] (83.0% similar)
- [[2025-09-22/It Depends_ Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge_20250922|It Depends: Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge]] (83.0% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**⚡ Unique Technical**: [[keywords/Creative Preference Optimization|Creative Preference Optimization]], [[keywords/MuCE Dataset|MuCE Dataset]], [[keywords/NoveltyBench|NoveltyBench]]
**🚀 Evolved Concepts**: [[keywords/Psychological Creativity Assessments|Psychological Creativity Assessments]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2505.14442v2 Announce Type: replace-cross 
Abstract: While Large Language Models (LLMs) have demonstrated impressive performance across natural language generation tasks, their ability to generate truly creative content-characterized by novelty, diversity, surprise, and quality-remains limited. Existing methods for enhancing LLM creativity often focus narrowly on diversity or specific tasks, failing to address creativity's multifaceted nature in a generalizable way. In this work, we propose Creative Preference Optimization (CrPO), a novel alignment method that injects signals from multiple creativity dimensions into the preference optimization objective in a modular fashion. We train and evaluate creativity-augmented versions of several models using CrPO and MuCE, a new large-scale human preference dataset spanning over 200,000 human-generated responses and ratings from more than 30 psychological creativity assessments. Our models outperform strong baselines, including GPT-4o, on both automated and human evaluations, producing more novel, diverse, and surprising generations while maintaining high output quality. Additional evaluations on NoveltyBench further confirm the generalizability of our approach. Together, our results demonstrate that directly optimizing for creativity within preference frameworks is a promising direction for advancing the creative capabilities of LLMs without compromising output quality.

## 🔍 Abstract (한글 번역)

arXiv:2505.14442v2 발표 유형: 교체-교차  
초록: 대형 언어 모델(LLM)은 자연어 생성 작업에서 인상적인 성능을 보여주었지만, 참신성, 다양성, 놀라움, 품질로 특징지어지는 진정한 창의적 콘텐츠를 생성하는 능력은 여전히 제한적입니다. LLM의 창의성을 향상시키기 위한 기존 방법들은 종종 다양성이나 특정 작업에 좁게 초점을 맞추어, 창의성의 다면적 특성을 일반화 가능한 방식으로 다루지 못합니다. 본 연구에서는 창의적 선호 최적화(CrPO)를 제안합니다. 이는 여러 창의성 차원의 신호를 모듈식으로 선호 최적화 목표에 주입하는 새로운 정렬 방법입니다. 우리는 CrPO와 MuCE를 사용하여 여러 모델의 창의성 증강 버전을 훈련하고 평가했습니다. MuCE는 30개 이상의 심리적 창의성 평가에서 20만 개 이상의 인간 생성 응답과 평가를 포함하는 새로운 대규모 인간 선호 데이터셋입니다. 우리의 모델은 GPT-4o를 포함한 강력한 기준선을 자동 및 인간 평가 모두에서 능가하며, 높은 출력 품질을 유지하면서 더 참신하고 다양하며 놀라운 생성을 만들어냅니다. NoveltyBench에서의 추가 평가를 통해 우리의 접근 방식의 일반화 가능성을 더욱 확인했습니다. 종합적으로, 우리의 결과는 선호 프레임워크 내에서 창의성을 직접 최적화하는 것이 출력 품질을 저하시키지 않으면서 LLM의 창의적 역량을 발전시키는 유망한 방향임을 보여줍니다.

## 📝 요약

이 논문은 대형 언어 모델(LLM)의 창의적 콘텐츠 생성 능력을 향상시키기 위한 새로운 방법론인 Creative Preference Optimization(CrPO)을 제안합니다. 기존 방법들이 창의성의 다양한 측면을 충분히 고려하지 못하는 문제를 해결하기 위해, CrPO는 여러 창의성 차원의 신호를 선호 최적화 목표에 모듈식으로 통합합니다. 연구진은 CrPO와 대규모 인간 선호 데이터셋 MuCE를 활용하여 여러 모델을 훈련하고 평가했으며, 그 결과 GPT-4o를 포함한 강력한 기준 모델들보다 더 새롭고 다양하며 놀라운 결과물을 생성하면서도 높은 품질을 유지하는 성과를 보였습니다. 추가적으로 NoveltyBench 평가에서도 접근법의 일반화 가능성을 확인했습니다. 이 연구는 선호 프레임워크 내에서 창의성을 직접 최적화하는 것이 LLM의 창의적 능력을 향상시키는 유망한 방향임을 보여줍니다.

## 🎯 주요 포인트

- 1. 대형 언어 모델(LLM)은 자연어 생성 작업에서 뛰어난 성능을 보이지만, 참신하고 다양한 창의적 콘텐츠 생성 능력은 제한적이다.
- 2. 기존의 LLM 창의성 향상 방법은 다양성이나 특정 작업에만 초점을 맞추어 창의성의 다면적 특성을 일반화된 방식으로 다루지 못한다.
- 3. 본 연구에서는 창의성의 여러 차원을 선호 최적화 목표에 모듈식으로 주입하는 새로운 정렬 방법인 Creative Preference Optimization(CrPO)을 제안한다.
- 4. CrPO와 MuCE를 사용하여 창의성이 강화된 모델을 훈련하고 평가한 결과, 자동 및 인간 평가에서 GPT-4o를 포함한 강력한 기준 모델들을 능가하였다.
- 5. NoveltyBench에서의 추가 평가를 통해 우리의 접근 방식이 일반화 가능함을 확인하였으며, 선호 프레임워크 내에서 창의성을 직접 최적화하는 것이 LLM의 창의적 능력을 향상시키는 유망한 방향임을 입증하였다.


---

*Generated on 2025-09-23 09:57:50*