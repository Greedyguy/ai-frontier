---
keywords:
  - Large Language Model
  - Emotion-Aware Speech Generation
  - Character-Specific Voice Synthesis
  - Multimodal Learning
  - Vision-Language Model
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2509.15253
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T08:49:43.202658",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Emotion-Aware Speech Generation",
    "Character-Specific Voice Synthesis",
    "Multimodal Learning",
    "Vision-Language Model"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.78,
    "Emotion-Aware Speech Generation": 0.82,
    "Character-Specific Voice Synthesis": 0.79,
    "Multimodal Learning": 0.8,
    "Vision-Language Model": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Model",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "The use of large language models is central to the dialogue attribution and emotion analysis, linking to broader NLP applications.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.78
      },
      {
        "surface": "Emotion-Aware Speech Generation",
        "canonical": "Emotion-Aware Speech Generation",
        "aliases": [
          "Emotion-Based TTS"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel approach specific to the paper, focusing on generating speech with emotional context, which is unique in the domain of speech synthesis.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.82
      },
      {
        "surface": "Character-Specific Voices",
        "canonical": "Character-Specific Voice Synthesis",
        "aliases": [
          "Voice Personalization"
        ],
        "category": "unique_technical",
        "rationale": "The creation of distinct voice profiles for different characters is a unique technical contribution, enhancing personalization in speech synthesis.",
        "novelty_score": 0.68,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.79
      },
      {
        "surface": "Multimodal Learning",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal Integration"
        ],
        "category": "specific_connectable",
        "rationale": "The integration of visual and textual data for emotion analysis and dialogue attribution is a key example of multimodal learning.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Vision-Language Model",
        "canonical": "Vision-Language Model",
        "aliases": [
          "VLM"
        ],
        "category": "evolved_concepts",
        "rationale": "The system's ability to integrate visual information with dialogue context aligns with the concept of vision-language models.",
        "novelty_score": 0.55,
        "connectivity_score": 0.82,
        "specificity_score": 0.75,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "end-to-end pipeline",
      "interactive and immersive"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Model",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Emotion-Aware Speech Generation",
      "resolved_canonical": "Emotion-Aware Speech Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Character-Specific Voices",
      "resolved_canonical": "Character-Specific Voice Synthesis",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Multimodal Learning",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Vision-Language Model",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.82,
        "specificity": 0.75,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Emotion-Aware Speech Generation with Character-Specific Voices for Comics

**Korean Title:** ë§Œí™”ìš© ìºë¦­í„°ë³„ ìŒì„±ìœ¼ë¡œ ê°ì • ì¸ì‹ ìŒì„± ìƒì„±

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15253.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2509.15253](https://arxiv.org/abs/2509.15253)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Towards Human-like Multimodal Conversational Agent by Generating Engaging Speech_20250919|Towards Human-like Multimodal Conversational Agent by Generating Engaging Speech]] (79.8% similar)
- [[2025-09-22/Combo_ Co-speech holistic 3D human motion generation and efficient customizable adaptation in harmony_20250922|Combo: Co-speech holistic 3D human motion generation and efficient customizable adaptation in harmony]] (79.2% similar)
- [[2025-09-18/Mitigating Intra-Speaker Variability in Diarization with Style-Controllable Speech Augmentation_20250918|Mitigating Intra-Speaker Variability in Diarization with Style-Controllable Speech Augmentation]] (79.2% similar)
- [[2025-09-22/FLOAT_ Generative Motion Latent Flow Matching for Audio-driven Talking Portrait_20250922|FLOAT: Generative Motion Latent Flow Matching for Audio-driven Talking Portrait]] (78.5% similar)
- [[2025-09-22/Experimenting with Affective Computing Models in Video Interviews with Spanish-speaking Older Adults_20250922|Experimenting with Affective Computing Models in Video Interviews with Spanish-speaking Older Adults]] (78.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**âš¡ Unique Technical**: [[keywords/Emotion-Aware Speech Generation|Emotion-Aware Speech Generation]], [[keywords/Character-Specific Voice Synthesis|Character-Specific Voice Synthesis]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15253v1 Announce Type: cross 
Abstract: This paper presents an end-to-end pipeline for generating character-specific, emotion-aware speech from comics. The proposed system takes full comic volumes as input and produces speech aligned with each character's dialogue and emotional state. An image processing module performs character detection, text recognition, and emotion intensity recognition. A large language model performs dialogue attribution and emotion analysis by integrating visual information with the evolving plot context. Speech is synthesized through a text-to-speech model with distinct voice profiles tailored to each character and emotion. This work enables automated voiceover generation for comics, offering a step toward interactive and immersive comic reading experience.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15253v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ì´ ë…¼ë¬¸ì€ ë§Œí™”ì—ì„œ ìºë¦­í„°ë³„ ê°ì • ì¸ì‹ ìŒì„±ì„ ìƒì„±í•˜ê¸° ìœ„í•œ ì¢…ë‹¨ ê°„ íŒŒì´í”„ë¼ì¸ì„ ì œì‹œí•©ë‹ˆë‹¤. ì œì•ˆëœ ì‹œìŠ¤í…œì€ ì „ì²´ ë§Œí™” ê¶Œì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ê° ìºë¦­í„°ì˜ ëŒ€ì‚¬ì™€ ê°ì • ìƒíƒœì— ë§ì¶° ì¡°ì •ëœ ìŒì„±ì„ ìƒì„±í•©ë‹ˆë‹¤. ì´ë¯¸ì§€ ì²˜ë¦¬ ëª¨ë“ˆì€ ìºë¦­í„° ê°ì§€, í…ìŠ¤íŠ¸ ì¸ì‹ ë° ê°ì • ê°•ë„ ì¸ì‹ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì€ ì‹œê°ì  ì •ë³´ë¥¼ ë°œì „í•˜ëŠ” ì¤„ê±°ë¦¬ ë§¥ë½ê³¼ í†µí•©í•˜ì—¬ ëŒ€ì‚¬ í• ë‹¹ ë° ê°ì • ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ìŒì„±ì€ ê° ìºë¦­í„°ì™€ ê°ì •ì— ë§ì¶˜ ë…íŠ¹í•œ ìŒì„± í”„ë¡œíŒŒì¼ì„ ì‚¬ìš©í•˜ëŠ” í…ìŠ¤íŠ¸-ìŒì„± ë³€í™˜ ëª¨ë¸ì„ í†µí•´ í•©ì„±ë©ë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ë§Œí™”ë¥¼ ìœ„í•œ ìë™ ìŒì„± ë”ë¹™ ìƒì„±ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ì—¬ ìƒí˜¸ì‘ìš©ì ì´ê³  ëª°ì…ì ì¸ ë§Œí™” ì½ê¸° ê²½í—˜ì„ í–¥í•œ í•œ ê±¸ìŒì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë§Œí™”ì—ì„œ ìºë¦­í„°ë³„ ê°ì • ì¸ì‹ ìŒì„±ì„ ìƒì„±í•˜ëŠ” ì¢…ë‹¨ ê°„ íŒŒì´í”„ë¼ì¸ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì œì•ˆëœ ì‹œìŠ¤í…œì€ ë§Œí™” ì „ì²´ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ê° ìºë¦­í„°ì˜ ëŒ€ì‚¬ì™€ ê°ì • ìƒíƒœì— ë§ì¶˜ ìŒì„±ì„ ìƒì„±í•©ë‹ˆë‹¤. ì´ë¯¸ì§€ ì²˜ë¦¬ ëª¨ë“ˆì€ ìºë¦­í„° ê°ì§€, í…ìŠ¤íŠ¸ ì¸ì‹, ê°ì • ê°•ë„ ì¸ì‹ì„ ìˆ˜í–‰í•˜ë©°, ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì€ ì‹œê° ì •ë³´ì™€ í”Œë¡¯ ë§¥ë½ì„ í†µí•©í•˜ì—¬ ëŒ€ì‚¬ í• ë‹¹ ë° ê°ì • ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. í…ìŠ¤íŠ¸-ìŒì„± ë³€í™˜ ëª¨ë¸ì€ ê° ìºë¦­í„°ì™€ ê°ì •ì— ë§ì¶˜ ê³ ìœ í•œ ìŒì„± í”„ë¡œí•„ë¡œ ìŒì„±ì„ í•©ì„±í•©ë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ë§Œí™”ì˜ ìë™ ìŒì„± í•´ì„¤ ìƒì„±ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ì—¬ ìƒí˜¸ì‘ìš©ì ì´ê³  ëª°ì…ê° ìˆëŠ” ë§Œí™” ì½ê¸° ê²½í—˜ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì´ ë…¼ë¬¸ì€ ë§Œí™”ì—ì„œ ìºë¦­í„°ë³„ ê°ì • ì¸ì‹ ìŒì„±ì„ ìƒì„±í•˜ëŠ” ì¢…ë‹¨ ê°„ íŒŒì´í”„ë¼ì¸ì„ ì œì•ˆí•©ë‹ˆë‹¤.
- 2. ì œì•ˆëœ ì‹œìŠ¤í…œì€ ì „ì²´ ë§Œí™” ë³¼ë¥¨ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ê° ìºë¦­í„°ì˜ ëŒ€ì‚¬ì™€ ê°ì • ìƒíƒœì— ë§ì¶˜ ìŒì„±ì„ ìƒì„±í•©ë‹ˆë‹¤.
- 3. ì´ë¯¸ì§€ ì²˜ë¦¬ ëª¨ë“ˆì€ ìºë¦­í„° ê°ì§€, í…ìŠ¤íŠ¸ ì¸ì‹, ê°ì • ê°•ë„ ì¸ì‹ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
- 4. ëŒ€í™” ì†ì„±ê³¼ ê°ì • ë¶„ì„ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì´ ì‹œê° ì •ë³´ë¥¼ í”Œë¡¯ ë§¥ë½ê³¼ í†µí•©í•˜ì—¬ ìˆ˜í–‰í•©ë‹ˆë‹¤.
- 5. í…ìŠ¤íŠ¸-ìŒì„± ë³€í™˜ ëª¨ë¸ì€ ê° ìºë¦­í„°ì™€ ê°ì •ì— ë§ì¶˜ ë…íŠ¹í•œ ìŒì„± í”„ë¡œí•„ë¡œ ìŒì„±ì„ í•©ì„±í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-23 08:49:43*