---
keywords:
  - Large Language Model
  - Emotion-Aware Speech Generation
  - Character-Specific Voice Synthesis
  - Multimodal Learning
  - Vision-Language Model
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2509.15253
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T08:49:43.202658",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Emotion-Aware Speech Generation",
    "Character-Specific Voice Synthesis",
    "Multimodal Learning",
    "Vision-Language Model"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.78,
    "Emotion-Aware Speech Generation": 0.82,
    "Character-Specific Voice Synthesis": 0.79,
    "Multimodal Learning": 0.8,
    "Vision-Language Model": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Model",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "The use of large language models is central to the dialogue attribution and emotion analysis, linking to broader NLP applications.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.78
      },
      {
        "surface": "Emotion-Aware Speech Generation",
        "canonical": "Emotion-Aware Speech Generation",
        "aliases": [
          "Emotion-Based TTS"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel approach specific to the paper, focusing on generating speech with emotional context, which is unique in the domain of speech synthesis.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.82
      },
      {
        "surface": "Character-Specific Voices",
        "canonical": "Character-Specific Voice Synthesis",
        "aliases": [
          "Voice Personalization"
        ],
        "category": "unique_technical",
        "rationale": "The creation of distinct voice profiles for different characters is a unique technical contribution, enhancing personalization in speech synthesis.",
        "novelty_score": 0.68,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.79
      },
      {
        "surface": "Multimodal Learning",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal Integration"
        ],
        "category": "specific_connectable",
        "rationale": "The integration of visual and textual data for emotion analysis and dialogue attribution is a key example of multimodal learning.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Vision-Language Model",
        "canonical": "Vision-Language Model",
        "aliases": [
          "VLM"
        ],
        "category": "evolved_concepts",
        "rationale": "The system's ability to integrate visual information with dialogue context aligns with the concept of vision-language models.",
        "novelty_score": 0.55,
        "connectivity_score": 0.82,
        "specificity_score": 0.75,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "end-to-end pipeline",
      "interactive and immersive"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Model",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Emotion-Aware Speech Generation",
      "resolved_canonical": "Emotion-Aware Speech Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Character-Specific Voices",
      "resolved_canonical": "Character-Specific Voice Synthesis",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Multimodal Learning",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Vision-Language Model",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.82,
        "specificity": 0.75,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Emotion-Aware Speech Generation with Character-Specific Voices for Comics

**Korean Title:** 만화용 캐릭터별 음성으로 감정 인식 음성 생성

## 📋 메타데이터

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15253.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2509.15253](https://arxiv.org/abs/2509.15253)

## 🔗 유사한 논문
- [[2025-09-19/Towards Human-like Multimodal Conversational Agent by Generating Engaging Speech_20250919|Towards Human-like Multimodal Conversational Agent by Generating Engaging Speech]] (79.8% similar)
- [[2025-09-22/Combo_ Co-speech holistic 3D human motion generation and efficient customizable adaptation in harmony_20250922|Combo: Co-speech holistic 3D human motion generation and efficient customizable adaptation in harmony]] (79.2% similar)
- [[2025-09-18/Mitigating Intra-Speaker Variability in Diarization with Style-Controllable Speech Augmentation_20250918|Mitigating Intra-Speaker Variability in Diarization with Style-Controllable Speech Augmentation]] (79.2% similar)
- [[2025-09-22/FLOAT_ Generative Motion Latent Flow Matching for Audio-driven Talking Portrait_20250922|FLOAT: Generative Motion Latent Flow Matching for Audio-driven Talking Portrait]] (78.5% similar)
- [[2025-09-22/Experimenting with Affective Computing Models in Video Interviews with Spanish-speaking Older Adults_20250922|Experimenting with Affective Computing Models in Video Interviews with Spanish-speaking Older Adults]] (78.1% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**⚡ Unique Technical**: [[keywords/Emotion-Aware Speech Generation|Emotion-Aware Speech Generation]], [[keywords/Character-Specific Voice Synthesis|Character-Specific Voice Synthesis]]
**🚀 Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.15253v1 Announce Type: cross 
Abstract: This paper presents an end-to-end pipeline for generating character-specific, emotion-aware speech from comics. The proposed system takes full comic volumes as input and produces speech aligned with each character's dialogue and emotional state. An image processing module performs character detection, text recognition, and emotion intensity recognition. A large language model performs dialogue attribution and emotion analysis by integrating visual information with the evolving plot context. Speech is synthesized through a text-to-speech model with distinct voice profiles tailored to each character and emotion. This work enables automated voiceover generation for comics, offering a step toward interactive and immersive comic reading experience.

## 🔍 Abstract (한글 번역)

arXiv:2509.15253v1 발표 유형: 교차  
초록: 이 논문은 만화에서 캐릭터별 감정 인식 음성을 생성하기 위한 종단 간 파이프라인을 제시합니다. 제안된 시스템은 전체 만화 권을 입력으로 받아 각 캐릭터의 대사와 감정 상태에 맞춰 조정된 음성을 생성합니다. 이미지 처리 모듈은 캐릭터 감지, 텍스트 인식 및 감정 강도 인식을 수행합니다. 대형 언어 모델은 시각적 정보를 발전하는 줄거리 맥락과 통합하여 대사 할당 및 감정 분석을 수행합니다. 음성은 각 캐릭터와 감정에 맞춘 독특한 음성 프로파일을 사용하는 텍스트-음성 변환 모델을 통해 합성됩니다. 이 연구는 만화를 위한 자동 음성 더빙 생성을 가능하게 하여 상호작용적이고 몰입적인 만화 읽기 경험을 향한 한 걸음을 제공합니다.

## 📝 요약

이 논문은 만화에서 캐릭터별 감정 인식 음성을 생성하는 종단 간 파이프라인을 제안합니다. 제안된 시스템은 만화 전체를 입력으로 받아 각 캐릭터의 대사와 감정 상태에 맞춘 음성을 생성합니다. 이미지 처리 모듈은 캐릭터 감지, 텍스트 인식, 감정 강도 인식을 수행하며, 대형 언어 모델은 시각 정보와 플롯 맥락을 통합하여 대사 할당 및 감정 분석을 수행합니다. 텍스트-음성 변환 모델은 각 캐릭터와 감정에 맞춘 고유한 음성 프로필로 음성을 합성합니다. 이 연구는 만화의 자동 음성 해설 생성을 가능하게 하여 상호작용적이고 몰입감 있는 만화 읽기 경험을 제공합니다.

## 🎯 주요 포인트

- 1. 이 논문은 만화에서 캐릭터별 감정 인식 음성을 생성하는 종단 간 파이프라인을 제안합니다.
- 2. 제안된 시스템은 전체 만화 볼륨을 입력으로 받아 각 캐릭터의 대사와 감정 상태에 맞춘 음성을 생성합니다.
- 3. 이미지 처리 모듈은 캐릭터 감지, 텍스트 인식, 감정 강도 인식을 수행합니다.
- 4. 대화 속성과 감정 분석은 대형 언어 모델이 시각 정보를 플롯 맥락과 통합하여 수행합니다.
- 5. 텍스트-음성 변환 모델은 각 캐릭터와 감정에 맞춘 독특한 음성 프로필로 음성을 합성합니다.


---

*Generated on 2025-09-23 08:49:43*