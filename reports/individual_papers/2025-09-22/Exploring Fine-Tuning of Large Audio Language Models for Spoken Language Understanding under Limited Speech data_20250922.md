---
keywords:
  - Large Language Model
  - Spoken Language Understanding
  - Curriculum Learning
  - Cross-lingual Spoken Language Understanding
  - Fine-tuning
category: cs.LG
publish_date: 2025-09-22
arxiv_id: 2509.15389
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T10:48:13.675590",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Spoken Language Understanding",
    "Curriculum Learning",
    "Cross-lingual Spoken Language Understanding",
    "Fine-tuning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Spoken Language Understanding": 0.78,
    "Curriculum Learning": 0.8,
    "Cross-lingual Spoken Language Understanding": 0.77,
    "Fine-tuning": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Audio Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LALMs"
        ],
        "category": "broad_technical",
        "rationale": "Connects to broader discussions on large models in language processing.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Spoken Language Understanding",
        "canonical": "Spoken Language Understanding",
        "aliases": [
          "SLU"
        ],
        "category": "unique_technical",
        "rationale": "Specific to the domain of audio and language processing, providing a unique link.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Curriculum Learning",
        "canonical": "Curriculum Learning",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "A specific technique that enhances model performance under limited data conditions.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.72,
        "link_intent_score": 0.8
      },
      {
        "surface": "Cross-lingual SLU",
        "canonical": "Cross-lingual Spoken Language Understanding",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Addresses the adaptation of models across languages, a niche yet important area.",
        "novelty_score": 0.68,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      },
      {
        "surface": "Fine-tuning",
        "canonical": "Fine-tuning",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "A key process in adapting models to specific tasks, relevant across various domains.",
        "novelty_score": 0.5,
        "connectivity_score": 0.82,
        "specificity_score": 0.65,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "Limited Speech Data",
      "Text-only Fine-tuning"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Audio Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Spoken Language Understanding",
      "resolved_canonical": "Spoken Language Understanding",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Curriculum Learning",
      "resolved_canonical": "Curriculum Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.72,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Cross-lingual SLU",
      "resolved_canonical": "Cross-lingual Spoken Language Understanding",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Fine-tuning",
      "resolved_canonical": "Fine-tuning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.82,
        "specificity": 0.65,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Exploring Fine-Tuning of Large Audio Language Models for Spoken Language Understanding under Limited Speech data

**Korean Title:** 제한된 음성 데이터 하에서 구어 이해를 위한 대형 오디오 언어 모델의 미세 조정 탐구

## 📋 메타데이터

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15389.pdf)
**Category**: cs.LG
**Published**: 2025-09-22
**ArXiv ID**: [2509.15389](https://arxiv.org/abs/2509.15389)

## 🔗 유사한 논문
- [[2025-09-22/Fine-Tuning Large Multimodal Models for Automatic Pronunciation Assessment_20250922|Fine-Tuning Large Multimodal Models for Automatic Pronunciation Assessment]] (86.0% similar)
- [[2025-09-22/A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages_20250922|A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages]] (85.2% similar)
- [[2025-09-19/Middo_ Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning_20250919|Middo: Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning]] (85.2% similar)
- [[2025-09-22/A method for improving multilingual quality and diversity of instruction fine-tuning datasets_20250922|A method for improving multilingual quality and diversity of instruction fine-tuning datasets]] (84.9% similar)
- [[2025-09-22/LESS_ Large Language Model Enhanced Semi-Supervised Learning for Speech Foundational Models Using in-the-wild Data_20250922|LESS: Large Language Model Enhanced Semi-Supervised Learning for Speech Foundational Models Using in-the-wild Data]] (84.8% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Curriculum Learning|Curriculum Learning]], [[keywords/Fine-tuning|Fine-tuning]]
**⚡ Unique Technical**: [[keywords/Spoken Language Understanding|Spoken Language Understanding]], [[keywords/Cross-lingual Spoken Language Understanding|Cross-lingual Spoken Language Understanding]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.15389v1 Announce Type: cross 
Abstract: Large Audio Language Models (LALMs) have emerged as powerful tools for speech-related tasks but remain underexplored for fine-tuning, especially with limited speech data. To bridge this gap, we systematically examine how different fine-tuning schemes including text-only, direct mixing, and curriculum learning affect spoken language understanding (SLU), focusing on scenarios where text-label pairs are abundant while paired speech-label data are limited. Results show that LALMs already achieve competitive performance with text-only fine-tuning, highlighting their strong generalization ability. Adding even small amounts of speech data (2-5%) yields substantial further gains, with curriculum learning particularly effective under scarce data. In cross-lingual SLU, combining source-language speech data with target-language text and minimal target-language speech data enables effective adaptation. Overall, this study provides practical insights into the LALM fine-tuning under realistic data constraints.

## 🔍 Abstract (한글 번역)

arXiv:2509.15389v1 발표 유형: 교차  
초록: 대형 오디오 언어 모델(LALMs)은 음성 관련 작업에 강력한 도구로 부상했지만, 특히 제한된 음성 데이터로 세부 조정하는 것은 충분히 탐구되지 않았습니다. 이러한 격차를 해소하기 위해, 우리는 텍스트 전용, 직접 혼합, 커리큘럼 학습을 포함한 다양한 세부 조정 방식이 음성 언어 이해(SLU)에 어떻게 영향을 미치는지를 체계적으로 조사합니다. 특히 텍스트-레이블 쌍이 풍부한 반면, 음성-레이블 쌍 데이터가 제한된 시나리오에 중점을 둡니다. 결과는 LALMs가 텍스트 전용 세부 조정만으로도 이미 경쟁력 있는 성능을 달성하여 강력한 일반화 능력을 강조함을 보여줍니다. 소량의 음성 데이터(2-5%)를 추가하면 상당한 추가 이득이 있으며, 커리큘럼 학습은 데이터가 부족한 상황에서 특히 효과적입니다. 교차 언어 SLU에서는 소스 언어 음성 데이터를 타겟 언어 텍스트 및 최소한의 타겟 언어 음성 데이터와 결합하여 효과적인 적응을 가능하게 합니다. 전반적으로, 이 연구는 현실적인 데이터 제약 조건 하에서 LALM 세부 조정에 대한 실질적인 통찰력을 제공합니다.

## 📝 요약

이 논문은 대규모 오디오 언어 모델(LALMs)의 미세 조정 방법을 탐구하며, 특히 제한된 음성 데이터 환경에서의 성능을 분석합니다. 텍스트만을 사용한 미세 조정에서도 경쟁력 있는 성능을 보이며, 소량의 음성 데이터를 추가하면 성능이 크게 향상됩니다. 커리큘럼 학습은 데이터가 부족할 때 특히 효과적입니다. 또한, 교차 언어 음성 이해(SLU)에서 소스 언어의 음성 데이터와 타겟 언어의 텍스트 및 최소한의 타겟 언어 음성 데이터를 결합하면 효과적인 적응이 가능합니다. 이 연구는 현실적인 데이터 제약 하에서 LALM의 미세 조정에 대한 실질적인 통찰을 제공합니다.

## 🎯 주요 포인트

- 1. 대규모 오디오 언어 모델(LALMs)은 텍스트만을 사용한 미세 조정에서도 경쟁력 있는 성능을 발휘하며, 일반화 능력이 뛰어나다.
- 2. 제한된 양의 음성 데이터를 추가하면 성능이 크게 향상되며, 커리큘럼 학습은 특히 데이터가 부족한 상황에서 효과적이다.
- 3. 교차 언어적 음성 언어 이해(SLU)에서는 소스 언어의 음성 데이터와 타겟 언어의 텍스트 및 최소한의 타겟 언어 음성 데이터를 결합하면 효과적인 적응이 가능하다.
- 4. 본 연구는 현실적인 데이터 제약 하에서 LALM의 미세 조정에 대한 실질적인 통찰을 제공한다.


---

*Generated on 2025-09-23 10:48:13*