---
keywords:
  - Large Language Model
  - Spoken Language Understanding
  - Curriculum Learning
  - Cross-lingual Spoken Language Understanding
  - Fine-tuning
category: cs.LG
publish_date: 2025-09-22
arxiv_id: 2509.15389
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T10:48:13.675590",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Spoken Language Understanding",
    "Curriculum Learning",
    "Cross-lingual Spoken Language Understanding",
    "Fine-tuning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Spoken Language Understanding": 0.78,
    "Curriculum Learning": 0.8,
    "Cross-lingual Spoken Language Understanding": 0.77,
    "Fine-tuning": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Audio Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LALMs"
        ],
        "category": "broad_technical",
        "rationale": "Connects to broader discussions on large models in language processing.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Spoken Language Understanding",
        "canonical": "Spoken Language Understanding",
        "aliases": [
          "SLU"
        ],
        "category": "unique_technical",
        "rationale": "Specific to the domain of audio and language processing, providing a unique link.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Curriculum Learning",
        "canonical": "Curriculum Learning",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "A specific technique that enhances model performance under limited data conditions.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.72,
        "link_intent_score": 0.8
      },
      {
        "surface": "Cross-lingual SLU",
        "canonical": "Cross-lingual Spoken Language Understanding",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Addresses the adaptation of models across languages, a niche yet important area.",
        "novelty_score": 0.68,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      },
      {
        "surface": "Fine-tuning",
        "canonical": "Fine-tuning",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "A key process in adapting models to specific tasks, relevant across various domains.",
        "novelty_score": 0.5,
        "connectivity_score": 0.82,
        "specificity_score": 0.65,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "Limited Speech Data",
      "Text-only Fine-tuning"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Audio Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Spoken Language Understanding",
      "resolved_canonical": "Spoken Language Understanding",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Curriculum Learning",
      "resolved_canonical": "Curriculum Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.72,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Cross-lingual SLU",
      "resolved_canonical": "Cross-lingual Spoken Language Understanding",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Fine-tuning",
      "resolved_canonical": "Fine-tuning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.82,
        "specificity": 0.65,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Exploring Fine-Tuning of Large Audio Language Models for Spoken Language Understanding under Limited Speech data

**Korean Title:** ì œí•œëœ ìŒì„± ë°ì´í„° í•˜ì—ì„œ êµ¬ì–´ ì´í•´ë¥¼ ìœ„í•œ ëŒ€í˜• ì˜¤ë””ì˜¤ ì–¸ì–´ ëª¨ë¸ì˜ ë¯¸ì„¸ ì¡°ì • íƒêµ¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15389.pdf)
**Category**: cs.LG
**Published**: 2025-09-22
**ArXiv ID**: [2509.15389](https://arxiv.org/abs/2509.15389)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Fine-Tuning Large Multimodal Models for Automatic Pronunciation Assessment_20250922|Fine-Tuning Large Multimodal Models for Automatic Pronunciation Assessment]] (86.0% similar)
- [[2025-09-22/A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages_20250922|A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages]] (85.2% similar)
- [[2025-09-19/Middo_ Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning_20250919|Middo: Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning]] (85.2% similar)
- [[2025-09-22/A method for improving multilingual quality and diversity of instruction fine-tuning datasets_20250922|A method for improving multilingual quality and diversity of instruction fine-tuning datasets]] (84.9% similar)
- [[2025-09-22/LESS_ Large Language Model Enhanced Semi-Supervised Learning for Speech Foundational Models Using in-the-wild Data_20250922|LESS: Large Language Model Enhanced Semi-Supervised Learning for Speech Foundational Models Using in-the-wild Data]] (84.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Curriculum Learning|Curriculum Learning]], [[keywords/Fine-tuning|Fine-tuning]]
**âš¡ Unique Technical**: [[keywords/Spoken Language Understanding|Spoken Language Understanding]], [[keywords/Cross-lingual Spoken Language Understanding|Cross-lingual Spoken Language Understanding]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15389v1 Announce Type: cross 
Abstract: Large Audio Language Models (LALMs) have emerged as powerful tools for speech-related tasks but remain underexplored for fine-tuning, especially with limited speech data. To bridge this gap, we systematically examine how different fine-tuning schemes including text-only, direct mixing, and curriculum learning affect spoken language understanding (SLU), focusing on scenarios where text-label pairs are abundant while paired speech-label data are limited. Results show that LALMs already achieve competitive performance with text-only fine-tuning, highlighting their strong generalization ability. Adding even small amounts of speech data (2-5%) yields substantial further gains, with curriculum learning particularly effective under scarce data. In cross-lingual SLU, combining source-language speech data with target-language text and minimal target-language speech data enables effective adaptation. Overall, this study provides practical insights into the LALM fine-tuning under realistic data constraints.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15389v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ëŒ€í˜• ì˜¤ë””ì˜¤ ì–¸ì–´ ëª¨ë¸(LALMs)ì€ ìŒì„± ê´€ë ¨ ì‘ì—…ì— ê°•ë ¥í•œ ë„êµ¬ë¡œ ë¶€ìƒí–ˆì§€ë§Œ, íŠ¹íˆ ì œí•œëœ ìŒì„± ë°ì´í„°ë¡œ ì„¸ë¶€ ì¡°ì •í•˜ëŠ” ê²ƒì€ ì¶©ë¶„íˆ íƒêµ¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ê²©ì°¨ë¥¼ í•´ì†Œí•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” í…ìŠ¤íŠ¸ ì „ìš©, ì§ì ‘ í˜¼í•©, ì»¤ë¦¬í˜ëŸ¼ í•™ìŠµì„ í¬í•¨í•œ ë‹¤ì–‘í•œ ì„¸ë¶€ ì¡°ì • ë°©ì‹ì´ ìŒì„± ì–¸ì–´ ì´í•´(SLU)ì— ì–´ë–»ê²Œ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ì¡°ì‚¬í•©ë‹ˆë‹¤. íŠ¹íˆ í…ìŠ¤íŠ¸-ë ˆì´ë¸” ìŒì´ í’ë¶€í•œ ë°˜ë©´, ìŒì„±-ë ˆì´ë¸” ìŒ ë°ì´í„°ê°€ ì œí•œëœ ì‹œë‚˜ë¦¬ì˜¤ì— ì¤‘ì ì„ ë‘¡ë‹ˆë‹¤. ê²°ê³¼ëŠ” LALMsê°€ í…ìŠ¤íŠ¸ ì „ìš© ì„¸ë¶€ ì¡°ì •ë§Œìœ¼ë¡œë„ ì´ë¯¸ ê²½ìŸë ¥ ìˆëŠ” ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ì—¬ ê°•ë ¥í•œ ì¼ë°˜í™” ëŠ¥ë ¥ì„ ê°•ì¡°í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì†ŒëŸ‰ì˜ ìŒì„± ë°ì´í„°(2-5%)ë¥¼ ì¶”ê°€í•˜ë©´ ìƒë‹¹í•œ ì¶”ê°€ ì´ë“ì´ ìˆìœ¼ë©°, ì»¤ë¦¬í˜ëŸ¼ í•™ìŠµì€ ë°ì´í„°ê°€ ë¶€ì¡±í•œ ìƒí™©ì—ì„œ íŠ¹íˆ íš¨ê³¼ì ì…ë‹ˆë‹¤. êµì°¨ ì–¸ì–´ SLUì—ì„œëŠ” ì†ŒìŠ¤ ì–¸ì–´ ìŒì„± ë°ì´í„°ë¥¼ íƒ€ê²Ÿ ì–¸ì–´ í…ìŠ¤íŠ¸ ë° ìµœì†Œí•œì˜ íƒ€ê²Ÿ ì–¸ì–´ ìŒì„± ë°ì´í„°ì™€ ê²°í•©í•˜ì—¬ íš¨ê³¼ì ì¸ ì ì‘ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ì „ë°˜ì ìœ¼ë¡œ, ì´ ì—°êµ¬ëŠ” í˜„ì‹¤ì ì¸ ë°ì´í„° ì œì•½ ì¡°ê±´ í•˜ì—ì„œ LALM ì„¸ë¶€ ì¡°ì •ì— ëŒ€í•œ ì‹¤ì§ˆì ì¸ í†µì°°ë ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€ê·œëª¨ ì˜¤ë””ì˜¤ ì–¸ì–´ ëª¨ë¸(LALMs)ì˜ ë¯¸ì„¸ ì¡°ì • ë°©ë²•ì„ íƒêµ¬í•˜ë©°, íŠ¹íˆ ì œí•œëœ ìŒì„± ë°ì´í„° í™˜ê²½ì—ì„œì˜ ì„±ëŠ¥ì„ ë¶„ì„í•©ë‹ˆë‹¤. í…ìŠ¤íŠ¸ë§Œì„ ì‚¬ìš©í•œ ë¯¸ì„¸ ì¡°ì •ì—ì„œë„ ê²½ìŸë ¥ ìˆëŠ” ì„±ëŠ¥ì„ ë³´ì´ë©°, ì†ŒëŸ‰ì˜ ìŒì„± ë°ì´í„°ë¥¼ ì¶”ê°€í•˜ë©´ ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤. ì»¤ë¦¬í˜ëŸ¼ í•™ìŠµì€ ë°ì´í„°ê°€ ë¶€ì¡±í•  ë•Œ íŠ¹íˆ íš¨ê³¼ì ì…ë‹ˆë‹¤. ë˜í•œ, êµì°¨ ì–¸ì–´ ìŒì„± ì´í•´(SLU)ì—ì„œ ì†ŒìŠ¤ ì–¸ì–´ì˜ ìŒì„± ë°ì´í„°ì™€ íƒ€ê²Ÿ ì–¸ì–´ì˜ í…ìŠ¤íŠ¸ ë° ìµœì†Œí•œì˜ íƒ€ê²Ÿ ì–¸ì–´ ìŒì„± ë°ì´í„°ë¥¼ ê²°í•©í•˜ë©´ íš¨ê³¼ì ì¸ ì ì‘ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” í˜„ì‹¤ì ì¸ ë°ì´í„° ì œì•½ í•˜ì—ì„œ LALMì˜ ë¯¸ì„¸ ì¡°ì •ì— ëŒ€í•œ ì‹¤ì§ˆì ì¸ í†µì°°ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€ê·œëª¨ ì˜¤ë””ì˜¤ ì–¸ì–´ ëª¨ë¸(LALMs)ì€ í…ìŠ¤íŠ¸ë§Œì„ ì‚¬ìš©í•œ ë¯¸ì„¸ ì¡°ì •ì—ì„œë„ ê²½ìŸë ¥ ìˆëŠ” ì„±ëŠ¥ì„ ë°œíœ˜í•˜ë©°, ì¼ë°˜í™” ëŠ¥ë ¥ì´ ë›°ì–´ë‚˜ë‹¤.
- 2. ì œí•œëœ ì–‘ì˜ ìŒì„± ë°ì´í„°ë¥¼ ì¶”ê°€í•˜ë©´ ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë˜ë©°, ì»¤ë¦¬í˜ëŸ¼ í•™ìŠµì€ íŠ¹íˆ ë°ì´í„°ê°€ ë¶€ì¡±í•œ ìƒí™©ì—ì„œ íš¨ê³¼ì ì´ë‹¤.
- 3. êµì°¨ ì–¸ì–´ì  ìŒì„± ì–¸ì–´ ì´í•´(SLU)ì—ì„œëŠ” ì†ŒìŠ¤ ì–¸ì–´ì˜ ìŒì„± ë°ì´í„°ì™€ íƒ€ê²Ÿ ì–¸ì–´ì˜ í…ìŠ¤íŠ¸ ë° ìµœì†Œí•œì˜ íƒ€ê²Ÿ ì–¸ì–´ ìŒì„± ë°ì´í„°ë¥¼ ê²°í•©í•˜ë©´ íš¨ê³¼ì ì¸ ì ì‘ì´ ê°€ëŠ¥í•˜ë‹¤.
- 4. ë³¸ ì—°êµ¬ëŠ” í˜„ì‹¤ì ì¸ ë°ì´í„° ì œì•½ í•˜ì—ì„œ LALMì˜ ë¯¸ì„¸ ì¡°ì •ì— ëŒ€í•œ ì‹¤ì§ˆì ì¸ í†µì°°ì„ ì œê³µí•œë‹¤.


---

*Generated on 2025-09-23 10:48:13*