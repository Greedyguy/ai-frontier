---
keywords:
  - Multimodal Learning
  - EyePCR
  - Cognitive Evaluation
  - Knowledge Graph
  - Surgical Video Analysis
category: cs.CV
publish_date: 2025-09-22
arxiv_id: 2509.15596
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T12:02:03.282594",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multimodal Learning",
    "EyePCR",
    "Cognitive Evaluation",
    "Knowledge Graph",
    "Surgical Video Analysis"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multimodal Learning": 0.85,
    "EyePCR": 0.78,
    "Cognitive Evaluation": 0.82,
    "Knowledge Graph": 0.79,
    "Surgical Video Analysis": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multimodal Large Language Models",
        "canonical": "Multimodal Learning",
        "aliases": [
          "MLLMs"
        ],
        "category": "specific_connectable",
        "rationale": "Links to the trending concept of integrating multiple data modalities in language models.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "EyePCR",
        "canonical": "EyePCR",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Represents a novel benchmark specifically designed for ophthalmic surgery analysis.",
        "novelty_score": 0.92,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.78
      },
      {
        "surface": "Perception, Comprehension and Reasoning",
        "canonical": "Cognitive Evaluation",
        "aliases": [
          "Perception",
          "Comprehension",
          "Reasoning"
        ],
        "category": "evolved_concepts",
        "rationale": "Captures the triad of cognitive processes evaluated in the benchmark, relevant for linking cognitive tasks.",
        "novelty_score": 0.55,
        "connectivity_score": 0.8,
        "specificity_score": 0.75,
        "link_intent_score": 0.82
      },
      {
        "surface": "Medical Knowledge Graph",
        "canonical": "Knowledge Graph",
        "aliases": [
          "Medical Graph"
        ],
        "category": "broad_technical",
        "rationale": "Facilitates connections with existing knowledge graph concepts in medical informatics.",
        "novelty_score": 0.4,
        "connectivity_score": 0.85,
        "specificity_score": 0.65,
        "link_intent_score": 0.79
      },
      {
        "surface": "Surgical Video Understanding",
        "canonical": "Surgical Video Analysis",
        "aliases": [
          "Surgical Video Comprehension"
        ],
        "category": "specific_connectable",
        "rationale": "Highlights the focus on video analysis in surgical contexts, relevant for linking to computer vision tasks.",
        "novelty_score": 0.68,
        "connectivity_score": 0.78,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "benchmark",
      "performance",
      "model"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multimodal Large Language Models",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "EyePCR",
      "resolved_canonical": "EyePCR",
      "decision": "linked",
      "scores": {
        "novelty": 0.92,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Perception, Comprehension and Reasoning",
      "resolved_canonical": "Cognitive Evaluation",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.8,
        "specificity": 0.75,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Medical Knowledge Graph",
      "resolved_canonical": "Knowledge Graph",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.85,
        "specificity": 0.65,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Surgical Video Understanding",
      "resolved_canonical": "Surgical Video Analysis",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.78,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# EyePCR: A Comprehensive Benchmark for Fine-Grained Perception, Knowledge Comprehension and Clinical Reasoning in Ophthalmic Surgery

**Korean Title:** 아이PCR: 안과 수술에서의 세밀한 지각, 지식 이해 및 임상 추론을 위한 종합 벤치마크

## 📋 메타데이터

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15596.pdf)
**Category**: cs.CV
**Published**: 2025-09-22
**ArXiv ID**: [2509.15596](https://arxiv.org/abs/2509.15596)

## 🔗 유사한 논문
- [[2025-09-22/EHR-MCP_ Real-world Evaluation of Clinical Information Retrieval by Large Language Models via Model Context Protocol_20250922|EHR-MCP: Real-world Evaluation of Clinical Information Retrieval by Large Language Models via Model Context Protocol]] (83.6% similar)
- [[2025-09-22/ORCA_ Agentic Reasoning For Hallucination and Adversarial Robustness in Vision-Language Models_20250922|ORCA: Agentic Reasoning For Hallucination and Adversarial Robustness in Vision-Language Models]] (83.4% similar)
- [[2025-09-22/Perception-R1_ Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward_20250922|Perception-R1: Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward]] (83.3% similar)
- [[2025-09-22/Exploring the Capabilities of LLM Encoders for Image-Text Retrieval in Chest X-rays_20250922|Exploring the Capabilities of LLM Encoders for Image-Text Retrieval in Chest X-rays]] (83.2% similar)
- [[2025-09-22/Data-Efficient Learning for Generalizable Surgical Video Understanding_20250922|Data-Efficient Learning for Generalizable Surgical Video Understanding]] (83.0% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Knowledge Graph|Knowledge Graph]]
**🔗 Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]], [[keywords/Surgical Video Analysis|Surgical Video Analysis]]
**⚡ Unique Technical**: [[keywords/EyePCR|EyePCR]]
**🚀 Evolved Concepts**: [[keywords/Cognitive Evaluation|Cognitive Evaluation]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.15596v1 Announce Type: new 
Abstract: MLLMs (Multimodal Large Language Models) have showcased remarkable capabilities, but their performance in high-stakes, domain-specific scenarios like surgical settings, remains largely under-explored. To address this gap, we develop \textbf{EyePCR}, a large-scale benchmark for ophthalmic surgery analysis, grounded in structured clinical knowledge to evaluate cognition across \textit{Perception}, \textit{Comprehension} and \textit{Reasoning}. EyePCR offers a richly annotated corpus with more than 210k VQAs, which cover 1048 fine-grained attributes for multi-view perception, medical knowledge graph of more than 25k triplets for comprehension, and four clinically grounded reasoning tasks. The rich annotations facilitate in-depth cognitive analysis, simulating how surgeons perceive visual cues and combine them with domain knowledge to make decisions, thus greatly improving models' cognitive ability. In particular, \textbf{EyePCR-MLLM}, a domain-adapted variant of Qwen2.5-VL-7B, achieves the highest accuracy on MCQs for \textit{Perception} among compared models and outperforms open-source models in \textit{Comprehension} and \textit{Reasoning}, rivalling commercial models like GPT-4.1. EyePCR reveals the limitations of existing MLLMs in surgical cognition and lays the foundation for benchmarking and enhancing clinical reliability of surgical video understanding models.

## 🔍 Abstract (한글 번역)

arXiv:2509.15596v1 발표 유형: 신규  
초록: MLLMs(다중모달 대형 언어 모델)은 놀라운 능력을 보여주었지만, 수술 환경과 같은 고위험, 도메인 특화 시나리오에서의 성능은 여전히 거의 탐구되지 않았습니다. 이러한 격차를 해소하기 위해, 우리는 안과 수술 분석을 위한 대규모 벤치마크인 \textbf{EyePCR}를 개발하였으며, 이는 \textit{지각}, \textit{이해}, \textit{추론} 전반에 걸쳐 인지를 평가하기 위해 구조화된 임상 지식에 기반을 두고 있습니다. EyePCR는 210,000개 이상의 VQA와 1,048개의 세밀한 속성을 포함하는 다중 시각 지각, 25,000개 이상의 삼중항으로 구성된 의료 지식 그래프를 통한 이해, 그리고 네 가지 임상 기반 추론 과제를 포함하는 풍부하게 주석이 달린 코퍼스를 제공합니다. 이러한 풍부한 주석은 외과의가 시각적 단서를 어떻게 인지하고 이를 도메인 지식과 결합하여 결정을 내리는지를 시뮬레이션하여 모델의 인지 능력을 크게 향상시킵니다. 특히, Qwen2.5-VL-7B의 도메인 적응 변형인 \textbf{EyePCR-MLLM}은 비교 모델 중 \textit{지각}에 대한 MCQ에서 가장 높은 정확도를 달성하였으며, \textit{이해} 및 \textit{추론}에서 오픈 소스 모델을 능가하여 GPT-4.1과 같은 상용 모델과 경쟁합니다. EyePCR는 수술 인지에서 기존 MLLMs의 한계를 드러내며, 수술 비디오 이해 모델의 임상 신뢰성을 벤치마킹하고 향상시키기 위한 기초를 마련합니다.

## 📝 요약

이 논문은 다중모달 대형 언어 모델(MLLMs)의 외과적 환경에서의 성능을 평가하기 위해 개발된 EyePCR이라는 대규모 벤치마크를 소개합니다. EyePCR은 안과 수술 분석을 위한 구조화된 임상 지식을 바탕으로 지각, 이해, 추론 능력을 평가합니다. 210,000개 이상의 VQA와 25,000개 이상의 트리플릿으로 구성된 의료 지식 그래프, 4개의 임상 기반 추론 과제를 포함하여, 모델의 인지 능력을 심층적으로 분석할 수 있는 풍부한 주석을 제공합니다. 특히, EyePCR-MLLM은 Qwen2.5-VL-7B의 도메인 적응형 변형으로, 지각, 이해, 추론에서 높은 정확도를 기록하며 상용 모델과 경쟁합니다. 이 연구는 기존 MLLMs의 한계를 드러내고, 외과적 비디오 이해 모델의 임상적 신뢰성을 향상시키기 위한 기초를 마련합니다.

## 🎯 주요 포인트

- 1. MLLMs는 외과 수술과 같은 고위험, 도메인 특화 시나리오에서의 성능이 충분히 탐구되지 않았다.
- 2. EyePCR는 안과 수술 분석을 위한 대규모 벤치마크로, 인지 능력을 평가하기 위해 구조화된 임상 지식에 기반한다.
- 3. EyePCR는 210k 이상의 VQA와 1048개의 세부 속성을 포함하여 다중 시각 인식을 지원하며, 25k 이상의 트리플렛을 포함한 의료 지식 그래프를 제공한다.
- 4. EyePCR-MLLM은 Qwen2.5-VL-7B의 도메인 적응 변형으로, \textit{Perception}에서 가장 높은 정확도를 기록하고 \textit{Comprehension}과 \textit{Reasoning}에서 상용 모델과 경쟁한다.
- 5. EyePCR는 기존 MLLMs의 외과적 인지 한계를 드러내고 외과 비디오 이해 모델의 임상 신뢰성을 향상시키기 위한 기초를 마련한다.


---

*Generated on 2025-09-23 12:02:03*