---
keywords:
  - Large Language Model
  - Unified Medical Language System
  - Medical Translation
  - Structured Prompting
  - LoRA-based Fine-tuning
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2509.00934
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T10:10:08.356721",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Unified Medical Language System",
    "Medical Translation",
    "Structured Prompting",
    "LoRA-based Fine-tuning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Unified Medical Language System": 0.8,
    "Medical Translation": 0.78,
    "Structured Prompting": 0.77,
    "LoRA-based Fine-tuning": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Language Model"
        ],
        "category": "broad_technical",
        "rationale": "Central to the study, linking advancements in language model applications.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Unified Medical Language System",
        "canonical": "Unified Medical Language System",
        "aliases": [
          "UMLS"
        ],
        "category": "unique_technical",
        "rationale": "Key domain-specific resource for medical translation, enhancing specificity.",
        "novelty_score": 0.75,
        "connectivity_score": 0.7,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "Medical Translation",
        "canonical": "Medical Translation",
        "aliases": [
          "Healthcare Translation"
        ],
        "category": "unique_technical",
        "rationale": "Focus of the study, crucial for linking medical and linguistic domains.",
        "novelty_score": 0.68,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Structured Prompting",
        "canonical": "Structured Prompting",
        "aliases": [
          "Prompt Engineering"
        ],
        "category": "specific_connectable",
        "rationale": "Important technique for improving LLM performance in specific tasks.",
        "novelty_score": 0.6,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      },
      {
        "surface": "LoRA-based Fine-tuning",
        "canonical": "LoRA-based Fine-tuning",
        "aliases": [
          "Low-Rank Adaptation Fine-tuning"
        ],
        "category": "unique_technical",
        "rationale": "Innovative fine-tuning method enhancing model adaptability and performance.",
        "novelty_score": 0.72,
        "connectivity_score": 0.68,
        "specificity_score": 0.88,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "structured knowledge",
      "performance gains"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Unified Medical Language System",
      "resolved_canonical": "Unified Medical Language System",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.7,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Medical Translation",
      "resolved_canonical": "Medical Translation",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Structured Prompting",
      "resolved_canonical": "Structured Prompting",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "LoRA-based Fine-tuning",
      "resolved_canonical": "LoRA-based Fine-tuning",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.68,
        "specificity": 0.88,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# MedCOD: Enhancing English-to-Spanish Medical Translation of Large Language Models Using Enriched Chain-of-Dictionary Framework

**Korean Title:** MedCOD: 사전 체인 강화 프레임워크를 활용한 대형 언어 모델의 영어-스페인어 의료 번역 향상

## 📋 메타데이터

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.00934.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2509.00934](https://arxiv.org/abs/2509.00934)

## 🔗 유사한 논문
- [[2025-09-19/MedVAL_ Toward Expert-Level Medical Text Validation with Language Models_20250919|MedVAL: Toward Expert-Level Medical Text Validation with Language Models]] (83.3% similar)
- [[2025-09-22/OpenWHO_ A Document-Level Parallel Corpus for Health Translation in Low-Resource Languages_20250922|OpenWHO: A Document-Level Parallel Corpus for Health Translation in Low-Resource Languages]] (82.1% similar)
- [[2025-09-22/Enhancing LLM Language Adaption through Cross-lingual In-Context Pre-training_20250922|Enhancing LLM Language Adaption through Cross-lingual In-Context Pre-training]] (82.0% similar)
- [[2025-09-19/Middo_ Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning_20250919|Middo: Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning]] (81.9% similar)
- [[2025-09-22/Multilingual LLM Prompting Strategies for Medical English-Vietnamese Machine Translation_20250922|Multilingual LLM Prompting Strategies for Medical English-Vietnamese Machine Translation]] (81.8% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Structured Prompting|Structured Prompting]]
**⚡ Unique Technical**: [[keywords/Unified Medical Language System|Unified Medical Language System]], [[keywords/Medical Translation|Medical Translation]], [[keywords/LoRA-based Fine-tuning|LoRA-based Fine-tuning]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.00934v2 Announce Type: replace-cross 
Abstract: We present MedCOD (Medical Chain-of-Dictionary), a hybrid framework designed to improve English-to-Spanish medical translation by integrating domain-specific structured knowledge into large language models (LLMs). MedCOD integrates domain-specific knowledge from both the Unified Medical Language System (UMLS) and the LLM-as-Knowledge-Base (LLM-KB) paradigm to enhance structured prompting and fine-tuning. We constructed a parallel corpus of 2,999 English-Spanish MedlinePlus articles and a 100-sentence test set annotated with structured medical contexts. Four open-source LLMs (Phi-4, Qwen2.5-14B, Qwen2.5-7B, and LLaMA-3.1-8B) were evaluated using structured prompts that incorporated multilingual variants, medical synonyms, and UMLS-derived definitions, combined with LoRA-based fine-tuning. Experimental results demonstrate that MedCOD significantly improves translation quality across all models. For example, Phi-4 with MedCOD and fine-tuning achieved BLEU 44.23, chrF++ 28.91, and COMET 0.863, surpassing strong baseline models like GPT-4o and GPT-4o-mini. Ablation studies confirm that both MedCOD prompting and model adaptation independently contribute to performance gains, with their combination yielding the highest improvements. These findings highlight the potential of structured knowledge integration to enhance LLMs for medical translation tasks.

## 🔍 Abstract (한글 번역)

arXiv:2509.00934v2 발표 유형: 교차 교체  
초록: 우리는 대규모 언어 모델(LLM)에 분야별 구조화된 지식을 통합하여 영어-스페인어 의학 번역을 개선하기 위해 설계된 하이브리드 프레임워크인 MedCOD(의학 사전 체인)를 제시합니다. MedCOD는 구조화된 프롬프트와 미세 조정을 강화하기 위해 통합 의료 언어 시스템(UMLS)과 LLM-지식-기반(LLM-KB) 패러다임 모두에서 분야별 지식을 통합합니다. 우리는 2,999개의 영어-스페인어 MedlinePlus 기사와 구조화된 의료 맥락으로 주석이 달린 100문장 테스트 세트를 구축했습니다. 네 가지 오픈 소스 LLM(Phi-4, Qwen2.5-14B, Qwen2.5-7B, LLaMA-3.1-8B)은 다국어 변형, 의학적 동의어 및 UMLS에서 파생된 정의를 통합한 구조화된 프롬프트와 LoRA 기반의 미세 조정을 사용하여 평가되었습니다. 실험 결과는 MedCOD가 모든 모델에서 번역 품질을 크게 향상시킨다는 것을 보여줍니다. 예를 들어, MedCOD와 미세 조정을 사용한 Phi-4는 BLEU 44.23, chrF++ 28.91, COMET 0.863을 달성하여 GPT-4o 및 GPT-4o-mini와 같은 강력한 기준 모델을 능가했습니다. 소거 연구는 MedCOD 프롬프트와 모델 적응이 모두 독립적으로 성능 향상에 기여하며, 이들의 조합이 가장 높은 개선을 가져온다는 것을 확인했습니다. 이러한 발견은 구조화된 지식 통합이 의학 번역 작업을 위한 LLM을 향상시킬 수 있는 잠재력을 강조합니다.

## 📝 요약

MedCOD(의료 사전 체인)은 영어에서 스페인어로의 의료 번역을 개선하기 위해 대형 언어 모델(LLM)에 도메인 특화 구조적 지식을 통합한 하이브리드 프레임워크입니다. MedCOD는 UMLS와 LLM-KB 패러다임의 지식을 활용하여 구조적 프롬프트와 미세 조정을 강화합니다. 2,999개의 영어-스페인어 MedlinePlus 기사와 100문장 테스트 세트를 구축하여 실험한 결과, MedCOD는 모든 모델에서 번역 품질을 크게 향상시켰습니다. 특히 Phi-4 모델은 BLEU 44.23, chrF++ 28.91, COMET 0.863을 기록하며 기존 강력한 모델을 능가했습니다. 연구 결과는 구조적 지식 통합이 의료 번역 작업에서 LLM의 성능을 향상시킬 수 있음을 보여줍니다.

## 🎯 주요 포인트

- 1. MedCOD는 영어-스페인어 의료 번역을 개선하기 위해 도메인별 구조화된 지식을 대형 언어 모델(LLM)에 통합하는 하이브리드 프레임워크입니다.
- 2. MedCOD는 UMLS와 LLM-KB 패러다임의 도메인별 지식을 통합하여 구조화된 프롬프트와 미세 조정을 강화합니다.
- 3. 실험 결과, MedCOD는 모든 모델에서 번역 품질을 크게 향상시키며, 특히 Phi-4 모델이 BLEU 44.23, chrF++ 28.91, COMET 0.863을 기록하여 강력한 기준 모델을 능가했습니다.
- 4. MedCOD 프롬프트와 모델 적응은 각각 성능 향상에 기여하며, 두 요소의 결합이 가장 큰 개선을 가져옵니다.
- 5. 구조화된 지식 통합이 의료 번역 작업에서 LLM의 성능을 향상시킬 잠재력을 가지고 있음을 시사합니다.


---

*Generated on 2025-09-23 10:10:08*