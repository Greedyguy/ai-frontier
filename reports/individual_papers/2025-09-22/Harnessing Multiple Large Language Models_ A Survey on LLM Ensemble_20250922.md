---
keywords:
  - LLM Ensemble
  - Ensemble Before Inference
  - Ensemble During Inference
  - Ensemble After Inference
category: cs.CL
publish_date: 2025-09-22
arxiv_id: 2502.18036
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T11:41:38.245659",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "LLM Ensemble",
    "Ensemble Before Inference",
    "Ensemble During Inference",
    "Ensemble After Inference"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "LLM Ensemble": 0.8,
    "Ensemble Before Inference": 0.78,
    "Ensemble During Inference": 0.79,
    "Ensemble After Inference": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "LLM Ensemble",
        "canonical": "LLM Ensemble",
        "aliases": [
          "Large Language Model Ensemble",
          "LLM Aggregation"
        ],
        "category": "unique_technical",
        "rationale": "This concept is central to the paper and represents a novel approach in the use of multiple LLMs.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "ensemble-before-inference",
        "canonical": "Ensemble Before Inference",
        "aliases": [
          "pre-inference ensemble"
        ],
        "category": "specific_connectable",
        "rationale": "This method is part of the taxonomy introduced and can link to related ensemble strategies.",
        "novelty_score": 0.7,
        "connectivity_score": 0.75,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "ensemble-during-inference",
        "canonical": "Ensemble During Inference",
        "aliases": [
          "inference-time ensemble"
        ],
        "category": "specific_connectable",
        "rationale": "This is a distinct phase in the ensemble process, relevant for linking inference techniques.",
        "novelty_score": 0.68,
        "connectivity_score": 0.77,
        "specificity_score": 0.82,
        "link_intent_score": 0.79
      },
      {
        "surface": "ensemble-after-inference",
        "canonical": "Ensemble After Inference",
        "aliases": [
          "post-inference ensemble"
        ],
        "category": "specific_connectable",
        "rationale": "This phase is crucial for understanding post-processing in ensemble methods.",
        "novelty_score": 0.67,
        "connectivity_score": 0.74,
        "specificity_score": 0.83,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "method",
      "review",
      "paper",
      "study"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "LLM Ensemble",
      "resolved_canonical": "LLM Ensemble",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "ensemble-before-inference",
      "resolved_canonical": "Ensemble Before Inference",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.75,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "ensemble-during-inference",
      "resolved_canonical": "Ensemble During Inference",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.77,
        "specificity": 0.82,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "ensemble-after-inference",
      "resolved_canonical": "Ensemble After Inference",
      "decision": "linked",
      "scores": {
        "novelty": 0.67,
        "connectivity": 0.74,
        "specificity": 0.83,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Harnessing Multiple Large Language Models: A Survey on LLM Ensemble

**Korean Title:** ë‹¤ì¤‘ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ í™œìš©: LLM ì•™ìƒë¸”ì— ê´€í•œ ì¡°ì‚¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2502.18036.pdf)
**Category**: cs.CL
**Published**: 2025-09-22
**ArXiv ID**: [2502.18036](https://arxiv.org/abs/2502.18036)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/From Automation to Autonomy_ A Survey on Large Language Models in Scientific Discovery_20250918|From Automation to Autonomy: A Survey on Large Language Models in Scientific Discovery]] (85.5% similar)
- [[2025-09-19/Modular Machine Learning_ An Indispensable Path towards New-Generation Large Language Models_20250919|Modular Machine Learning: An Indispensable Path towards New-Generation Large Language Models]] (85.0% similar)
- [[2025-09-22/Predicting Language Models' Success at Zero-Shot Probabilistic Prediction_20250922|Predicting Language Models' Success at Zero-Shot Probabilistic Prediction]] (84.6% similar)
- [[2025-09-22/Are LLMs Better Formalizers than Solvers on Complex Problems?_20250922|Are LLMs Better Formalizers than Solvers on Complex Problems?]] (84.2% similar)
- [[2025-09-22/A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages_20250922|A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages]] (84.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Ensemble Before Inference|Ensemble Before Inference]], [[keywords/Ensemble During Inference|Ensemble During Inference]], [[keywords/Ensemble After Inference|Ensemble After Inference]]
**âš¡ Unique Technical**: [[keywords/LLM Ensemble|LLM Ensemble]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2502.18036v5 Announce Type: replace 
Abstract: LLM Ensemble -- which involves the comprehensive use of multiple large language models (LLMs), each aimed at handling user queries during downstream inference, to benefit from their individual strengths -- has gained substantial attention recently. The widespread availability of LLMs, coupled with their varying strengths and out-of-the-box usability, has profoundly advanced the field of LLM Ensemble. This paper presents the first systematic review of recent developments in LLM Ensemble. First, we introduce our taxonomy of LLM Ensemble and discuss several related research problems. Then, we provide a more in-depth classification of the methods under the broad categories of "ensemble-before-inference, ensemble-during-inference, ensemble-after-inference'', and review all relevant methods. Finally, we introduce related benchmarks and applications, summarize existing studies, and suggest several future research directions. A curated list of papers on LLM Ensemble is available at https://github.com/junchenzhi/Awesome-LLM-Ensemble.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2502.18036v5 ë°œí‘œ ìœ í˜•: êµì²´  
ì´ˆë¡: LLM ì•™ìƒë¸”ì€ ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ê°ê¸° ë‹¤ë¥¸ ê°•ì ì„ ê°€ì§„ ì—¬ëŸ¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ ì¢…í•©ì ìœ¼ë¡œ í™œìš©í•˜ì—¬ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì¶”ë¡  ì‹œ ì´ë“¤ì˜ ê°œë³„ì ì¸ ê°•ì ì„ í™œìš©í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ, ìµœê·¼ ìƒë‹¹í•œ ì£¼ëª©ì„ ë°›ê³  ìˆìŠµë‹ˆë‹¤. LLMì˜ ê´‘ë²”ìœ„í•œ ê°€ìš©ì„±ê³¼ ë‹¤ì–‘í•œ ê°•ì , ê·¸ë¦¬ê³  ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥í•œ íŠ¹ì„±ì€ LLM ì•™ìƒë¸” ë¶„ì•¼ë¥¼ í¬ê²Œ ë°œì „ì‹œì¼°ìŠµë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì€ LLM ì•™ìƒë¸”ì˜ ìµœê·¼ ë°œì „ì— ëŒ€í•œ ìµœì´ˆì˜ ì²´ê³„ì ì¸ ë¦¬ë·°ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ë¨¼ì €, LLM ì•™ìƒë¸”ì˜ ë¶„ë¥˜ ì²´ê³„ë¥¼ ì†Œê°œí•˜ê³  ê´€ë ¨ ì—°êµ¬ ë¬¸ì œë“¤ì„ ë…¼ì˜í•©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ, "ì¶”ë¡  ì „ ì•™ìƒë¸”, ì¶”ë¡  ì¤‘ ì•™ìƒë¸”, ì¶”ë¡  í›„ ì•™ìƒë¸”"ì´ë¼ëŠ” ë„“ì€ ë²”ì£¼ì— ë”°ë¼ ë°©ë²•ë“¤ì„ ë³´ë‹¤ ì‹¬ì¸µì ìœ¼ë¡œ ë¶„ë¥˜í•˜ê³ , ê´€ë ¨ëœ ëª¨ë“  ë°©ë²•ì„ ê²€í† í•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ, ê´€ë ¨ ë²¤ì¹˜ë§ˆí¬ì™€ ì‘ìš© í”„ë¡œê·¸ë¨ì„ ì†Œê°œí•˜ê³ , ê¸°ì¡´ ì—°êµ¬ë¥¼ ìš”ì•½í•˜ë©°, í–¥í›„ ì—°êµ¬ ë°©í–¥ì„ ì œì•ˆí•©ë‹ˆë‹¤. LLM ì•™ìƒë¸”ì— ê´€í•œ ë…¼ë¬¸ ëª©ë¡ì€ https://github.com/junchenzhi/Awesome-LLM-Ensembleì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ìµœê·¼ ì£¼ëª©ë°›ê³  ìˆëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM) ì•™ìƒë¸”ì— ëŒ€í•œ ì²´ê³„ì ì¸ ë¦¬ë·°ë¥¼ ì œê³µí•©ë‹ˆë‹¤. LLM ì•™ìƒë¸”ì€ ì—¬ëŸ¬ LLMì„ í™œìš©í•˜ì—¬ ê° ëª¨ë¸ì˜ ê°•ì ì„ ì‚´ë ¤ ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë°©ë²•ë¡ ì…ë‹ˆë‹¤. ì €ìë“¤ì€ LLM ì•™ìƒë¸”ì˜ ë¶„ë¥˜ ì²´ê³„ë¥¼ ì œì‹œí•˜ê³ , "ì¶”ë¡  ì „ ì•™ìƒë¸”", "ì¶”ë¡  ì¤‘ ì•™ìƒë¸”", "ì¶”ë¡  í›„ ì•™ìƒë¸”"ë¡œ ë°©ë²•ë¡ ì„ ë¶„ë¥˜í•˜ì—¬ ê´€ë ¨ ì—°êµ¬ë¥¼ ê²€í† í•©ë‹ˆë‹¤. ë˜í•œ, ê´€ë ¨ ë²¤ì¹˜ë§ˆí¬ì™€ ì‘ìš© ì‚¬ë¡€ë¥¼ ì†Œê°œí•˜ê³ , í–¥í›„ ì—°êµ¬ ë°©í–¥ì„ ì œì•ˆí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. LLM ì•™ìƒë¸”ì€ ì—¬ëŸ¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì„ ì¢…í•©ì ìœ¼ë¡œ í™œìš©í•˜ì—¬ ê° ëª¨ë¸ì˜ ê°•ì ì„ ì‚´ë ¤ ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ ì£¼ëª©ë°›ê³  ìˆë‹¤.
- 2. ë³¸ ë…¼ë¬¸ì€ LLM ì•™ìƒë¸”ì˜ ìµœê·¼ ë°œì „ì„ ì²´ê³„ì ìœ¼ë¡œ ê²€í† í•œ ìµœì´ˆì˜ ì—°êµ¬ë¡œ, LLM ì•™ìƒë¸”ì˜ ë¶„ë¥˜ ì²´ê³„ë¥¼ ì†Œê°œí•˜ê³  ê´€ë ¨ ì—°êµ¬ ë¬¸ì œë¥¼ ë…¼ì˜í•œë‹¤.
- 3. "ì¶”ë¡  ì „ ì•™ìƒë¸”, ì¶”ë¡  ì¤‘ ì•™ìƒë¸”, ì¶”ë¡  í›„ ì•™ìƒë¸”"ì´ë¼ëŠ” ë²”ì£¼ë¡œ ë°©ë²•ì„ ë¶„ë¥˜í•˜ê³  ê´€ë ¨ ë°©ë²•ë“¤ì„ ê²€í† í•œë‹¤.
- 4. ê´€ë ¨ ë²¤ì¹˜ë§ˆí¬ì™€ ì‘ìš© ì‚¬ë¡€ë¥¼ ì†Œê°œí•˜ê³  ê¸°ì¡´ ì—°êµ¬ë¥¼ ìš”ì•½í•˜ë©°, í–¥í›„ ì—°êµ¬ ë°©í–¥ì„ ì œì•ˆí•œë‹¤.
- 5. LLM ì•™ìƒë¸”ì— ê´€í•œ ë…¼ë¬¸ ëª©ë¡ì€ https://github.com/junchenzhi/Awesome-LLM-Ensembleì—ì„œ í™•ì¸í•  ìˆ˜ ìˆë‹¤.


---

*Generated on 2025-09-23 11:41:38*