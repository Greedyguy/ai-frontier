---
keywords:
  - Transformer
  - Flow Matching Generative Model
  - Audio-Driven Talking Portrait
  - Speech-Driven Emotion Enhancement
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2412.01064
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T09:48:45.030844",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Transformer",
    "Flow Matching Generative Model",
    "Audio-Driven Talking Portrait",
    "Speech-Driven Emotion Enhancement"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Transformer": 0.85,
    "Flow Matching Generative Model": 0.7,
    "Audio-Driven Talking Portrait": 0.72,
    "Speech-Driven Emotion Enhancement": 0.71
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Transformer-based vector field predictor",
        "canonical": "Transformer",
        "aliases": [
          "Transformer predictor",
          "Vector field Transformer"
        ],
        "category": "broad_technical",
        "rationale": "Transformers are a foundational technology in machine learning, facilitating connections to various related models and techniques.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "flow matching generative model",
        "canonical": "Flow Matching Generative Model",
        "aliases": [
          "Flow-based generative model",
          "Flow matching model"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel approach specific to the paper, offering unique insights into generative model advancements.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      },
      {
        "surface": "audio-driven talking portrait",
        "canonical": "Audio-Driven Talking Portrait",
        "aliases": [
          "Audio-driven portrait animation",
          "Talking portrait"
        ],
        "category": "unique_technical",
        "rationale": "This concept is central to the paper's contribution and connects to advancements in audio-visual synthesis.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.72
      },
      {
        "surface": "speech-driven emotion enhancement",
        "canonical": "Speech-Driven Emotion Enhancement",
        "aliases": [
          "Emotion enhancement via speech",
          "Speech emotion enhancement"
        ],
        "category": "unique_technical",
        "rationale": "This technique highlights the integration of emotion in generative models, linking to emotional AI research.",
        "novelty_score": 0.68,
        "connectivity_score": 0.58,
        "specificity_score": 0.78,
        "link_intent_score": 0.71
      }
    ],
    "ban_list_suggestions": [
      "portrait image animation",
      "temporally consistent video generation",
      "fast sampling"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Transformer-based vector field predictor",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "flow matching generative model",
      "resolved_canonical": "Flow Matching Generative Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "audio-driven talking portrait",
      "resolved_canonical": "Audio-Driven Talking Portrait",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "speech-driven emotion enhancement",
      "resolved_canonical": "Speech-Driven Emotion Enhancement",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.58,
        "specificity": 0.78,
        "link_intent": 0.71
      }
    }
  ]
}
-->

# FLOAT: Generative Motion Latent Flow Matching for Audio-driven Talking Portrait

**Korean Title:** FLOAT: ì˜¤ë””ì˜¤ ê¸°ë°˜ì˜ ë§í•˜ëŠ” ì´ˆìƒí™”ë¥¼ ìœ„í•œ ìƒì„±ì  ëª¨ì…˜ ì ì¬ íë¦„ ë§¤ì¹­

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2412.01064.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2412.01064](https://arxiv.org/abs/2412.01064)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Generating Moving 3D Soundscapes with Latent Diffusion Models_20250922|Generating Moving 3D Soundscapes with Latent Diffusion Models]] (83.0% similar)
- [[2025-09-18/Real-Time Streaming Mel Vocoding with Generative Flow Matching_20250918|Real-Time Streaming Mel Vocoding with Generative Flow Matching]] (82.3% similar)
- [[2025-09-19/Hybrid Autoregressive-Diffusion Model for Real-Time Sign Language Production_20250919|Hybrid Autoregressive-Diffusion Model for Real-Time Sign Language Production]] (82.1% similar)
- [[2025-09-17/RFM-Editing_ Rectified Flow Matching for Text-guided Audio Editing_20250917|RFM-Editing: Rectified Flow Matching for Text-guided Audio Editing]] (81.1% similar)
- [[2025-09-22/Compose Yourself_ Average-Velocity Flow Matching for One-Step Speech Enhancement_20250922|Compose Yourself: Average-Velocity Flow Matching for One-Step Speech Enhancement]] (81.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Transformer|Transformer]]
**âš¡ Unique Technical**: [[keywords/Flow Matching Generative Model|Flow Matching Generative Model]], [[keywords/Audio-Driven Talking Portrait|Audio-Driven Talking Portrait]], [[keywords/Speech-Driven Emotion Enhancement|Speech-Driven Emotion Enhancement]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2412.01064v5 Announce Type: replace-cross 
Abstract: With the rapid advancement of diffusion-based generative models, portrait image animation has achieved remarkable results. However, it still faces challenges in temporally consistent video generation and fast sampling due to its iterative sampling nature. This paper presents FLOAT, an audio-driven talking portrait video generation method based on flow matching generative model. Instead of a pixel-based latent space, we take advantage of a learned orthogonal motion latent space, enabling efficient generation and editing of temporally consistent motion. To achieve this, we introduce a transformer-based vector field predictor with an effective frame-wise conditioning mechanism. Additionally, our method supports speech-driven emotion enhancement, enabling a natural incorporation of expressive motions. Extensive experiments demonstrate that our method outperforms state-of-the-art audio-driven talking portrait methods in terms of visual quality, motion fidelity, and efficiency.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2412.01064v5 ë°œí‘œ ìœ í˜•: êµì°¨ êµì²´  
ì´ˆë¡: í™•ì‚° ê¸°ë°˜ ìƒì„± ëª¨ë¸ì˜ ê¸‰ì†í•œ ë°œì „ìœ¼ë¡œ ì¸í•´ ì´ˆìƒí™” ì´ë¯¸ì§€ ì• ë‹ˆë©”ì´ì…˜ì´ ë†€ë¼ìš´ ê²°ê³¼ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë°˜ë³µì ì¸ ìƒ˜í”Œë§ íŠ¹ì„±ìœ¼ë¡œ ì¸í•´ ì‹œê°„ì ìœ¼ë¡œ ì¼ê´€ëœ ë¹„ë””ì˜¤ ìƒì„±ê³¼ ë¹ ë¥¸ ìƒ˜í”Œë§ì—ì„œ ì—¬ì „íˆ ì–´ë ¤ì›€ì„ ê²ªê³  ìˆìŠµë‹ˆë‹¤. ì´ ë…¼ë¬¸ì—ì„œëŠ” íë¦„ ë§¤ì¹­ ìƒì„± ëª¨ë¸ì— ê¸°ë°˜í•œ ì˜¤ë””ì˜¤ êµ¬ë™ ëŒ€í™”í˜• ì´ˆìƒí™” ë¹„ë””ì˜¤ ìƒì„± ë°©ë²•ì¸ FLOATë¥¼ ì œì‹œí•©ë‹ˆë‹¤. í”½ì…€ ê¸°ë°˜ ì ì¬ ê³µê°„ ëŒ€ì‹  í•™ìŠµëœ ì§êµ ìš´ë™ ì ì¬ ê³µê°„ì„ í™œìš©í•˜ì—¬ ì‹œê°„ì ìœ¼ë¡œ ì¼ê´€ëœ ìš´ë™ì˜ íš¨ìœ¨ì ì¸ ìƒì„± ë° í¸ì§‘ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ íš¨ê³¼ì ì¸ í”„ë ˆì„ ë‹¨ìœ„ ì¡°ê±´ ë©”ì»¤ë‹ˆì¦˜ì„ ê°–ì¶˜ íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ ë²¡í„° í•„ë“œ ì˜ˆì¸¡ê¸°ë¥¼ ë„ì…í•©ë‹ˆë‹¤. ë˜í•œ, ìš°ë¦¬ì˜ ë°©ë²•ì€ ìŒì„± êµ¬ë™ ê°ì • í–¥ìƒì„ ì§€ì›í•˜ì—¬ í‘œí˜„ë ¥ì´ í’ë¶€í•œ ë™ì‘ì„ ìì—°ìŠ¤ëŸ½ê²Œ í†µí•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê´‘ë²”ìœ„í•œ ì‹¤í—˜ì„ í†µí•´ ìš°ë¦¬ì˜ ë°©ë²•ì´ ì‹œê°ì  í’ˆì§ˆ, ìš´ë™ ì¶©ì‹¤ë„ ë° íš¨ìœ¨ì„± ì¸¡ë©´ì—ì„œ ìµœì²¨ë‹¨ ì˜¤ë””ì˜¤ êµ¬ë™ ëŒ€í™”í˜• ì´ˆìƒí™” ë°©ë²•ì„ ëŠ¥ê°€í•¨ì„ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì—ì„œëŠ” FLOWë¼ëŠ” ì˜¤ë””ì˜¤ ê¸°ë°˜ì˜ ì–¼êµ´ ì• ë‹ˆë©”ì´ì…˜ ìƒì„± ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ íë¦„ ë§¤ì¹­ ìƒì„± ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í”½ì…€ ê¸°ë°˜ì´ ì•„ë‹Œ í•™ìŠµëœ ì •ê·œ ì§êµ ìš´ë™ ì ì¬ ê³µê°„ì„ í™œìš©í•¨ìœ¼ë¡œì¨ ì‹œê°„ì ìœ¼ë¡œ ì¼ê´€ëœ ëª¨ì…˜ì„ íš¨ìœ¨ì ìœ¼ë¡œ ìƒì„±í•˜ê³  í¸ì§‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ì˜ ë²¡í„° í•„ë“œ ì˜ˆì¸¡ê¸°ë¥¼ ë„ì…í•˜ì—¬ í”„ë ˆì„ ë‹¨ìœ„ì˜ íš¨ê³¼ì ì¸ ì¡°ê±´ë¶€ ë©”ì»¤ë‹ˆì¦˜ì„ êµ¬í˜„í•˜ì˜€ìŠµë‹ˆë‹¤. ì´ ë°©ë²•ì€ ê°ì • í‘œí˜„ì„ ìì—°ìŠ¤ëŸ½ê²Œ ê°•í™”í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ë„ ì§€ì›í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì€ ì‹œê°ì  í’ˆì§ˆ, ëª¨ì…˜ ì¶©ì‹¤ë„, íš¨ìœ¨ì„± ì¸¡ë©´ì—ì„œ ê¸°ì¡´ì˜ ì˜¤ë””ì˜¤ ê¸°ë°˜ ì–¼êµ´ ì• ë‹ˆë©”ì´ì…˜ ìƒì„± ë°©ë²•ì„ ëŠ¥ê°€í•˜ëŠ” ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë³¸ ë…¼ë¬¸ì€ íë¦„ ë§¤ì¹­ ìƒì„± ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ì˜¤ë””ì˜¤ ê¸°ë°˜ì˜ ë§í•˜ëŠ” ì´ˆìƒí™” ë¹„ë””ì˜¤ ìƒì„± ë°©ë²•ì¸ FLOATë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.
- 2. í•™ìŠµëœ ì§êµ ìš´ë™ ì ì¬ ê³µê°„ì„ í™œìš©í•˜ì—¬ ì‹œê°„ì ìœ¼ë¡œ ì¼ê´€ëœ ì›€ì§ì„ì„ íš¨ìœ¨ì ìœ¼ë¡œ ìƒì„±í•˜ê³  í¸ì§‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- 3. íš¨ê³¼ì ì¸ í”„ë ˆì„ë³„ ì¡°ê±´ ë©”ì»¤ë‹ˆì¦˜ì„ ê°–ì¶˜ íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ ë²¡í„° í•„ë“œ ì˜ˆì¸¡ê¸°ë¥¼ ë„ì…í•˜ì˜€ìŠµë‹ˆë‹¤.
- 4. ê°ì • í‘œí˜„ì„ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨í•  ìˆ˜ ìˆëŠ” ë§ ê¸°ë°˜ ê°ì • í–¥ìƒì„ ì§€ì›í•©ë‹ˆë‹¤.
- 5. ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì´ ì‹œê°ì  í’ˆì§ˆ, ì›€ì§ì„ ì¶©ì‹¤ë„ ë° íš¨ìœ¨ì„± ì¸¡ë©´ì—ì„œ ìµœì‹  ì˜¤ë””ì˜¤ ê¸°ë°˜ ë§í•˜ëŠ” ì´ˆìƒí™” ë°©ë²•ë³´ë‹¤ ìš°ìˆ˜í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.


---

*Generated on 2025-09-23 09:48:45*