---
keywords:
  - SceneForge
  - 3D-Text Contrastive Learning
  - Zero-Shot Learning
  - Compositional Augmentation
  - Large Language Model
category: cs.CV
publish_date: 2025-09-22
arxiv_id: 2509.15693
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T12:06:19.675537",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "SceneForge",
    "3D-Text Contrastive Learning",
    "Zero-Shot Learning",
    "Compositional Augmentation",
    "Large Language Model"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "SceneForge": 0.8,
    "3D-Text Contrastive Learning": 0.82,
    "Zero-Shot Learning": 0.85,
    "Compositional Augmentation": 0.79,
    "Large Language Model": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "SceneForge",
        "canonical": "SceneForge",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "SceneForge is a novel framework specific to this paper, providing a unique approach to 3D-text alignment.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "3D-text contrastive learning",
        "canonical": "3D-Text Contrastive Learning",
        "aliases": [
          "3D-text alignment"
        ],
        "category": "evolved_concepts",
        "rationale": "This concept is central to the paper's methodology, linking 3D data with textual descriptions.",
        "novelty_score": 0.7,
        "connectivity_score": 0.78,
        "specificity_score": 0.85,
        "link_intent_score": 0.82
      },
      {
        "surface": "Zero-shot classification",
        "canonical": "Zero-Shot Learning",
        "aliases": [
          "Zero-shot task"
        ],
        "category": "specific_connectable",
        "rationale": "Zero-shot learning is a key task evaluated in the paper, relevant to the broader field of machine learning.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.8,
        "link_intent_score": 0.85
      },
      {
        "surface": "Compositional augmentations",
        "canonical": "Compositional Augmentation",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This technique is a unique contribution of the paper, enhancing data diversity and complexity.",
        "novelty_score": 0.78,
        "connectivity_score": 0.7,
        "specificity_score": 0.88,
        "link_intent_score": 0.79
      },
      {
        "surface": "Large language model",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "Large language models are integral to generating coherent multi-object descriptions in the framework.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "SceneForge",
      "resolved_canonical": "SceneForge",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "3D-text contrastive learning",
      "resolved_canonical": "3D-Text Contrastive Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.78,
        "specificity": 0.85,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Zero-shot classification",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.8,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Compositional augmentations",
      "resolved_canonical": "Compositional Augmentation",
      "decision": "linked",
      "scores": {
        "novelty": 0.78,
        "connectivity": 0.7,
        "specificity": 0.88,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Large language model",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# SCENEFORGE: Enhancing 3D-text alignment with Structured Scene Compositions

**Korean Title:** SCENEFORGE: 구조화된 장면 구성으로 3D-텍스트 정렬 향상

## 📋 메타데이터

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15693.pdf)
**Category**: cs.CV
**Published**: 2025-09-22
**ArXiv ID**: [2509.15693](https://arxiv.org/abs/2509.15693)

## 🔗 유사한 논문
- [[2025-09-22/Spatial Understanding from Videos_ Structured Prompts Meet Simulation Data_20250922|Spatial Understanding from Videos: Structured Prompts Meet Simulation Data]] (82.5% similar)
- [[2025-09-22/Causal Reasoning Elicits Controllable 3D Scene Generation_20250922|Causal Reasoning Elicits Controllable 3D Scene Generation]] (81.8% similar)
- [[2025-09-22/Compose by Focus_ Scene Graph-based Atomic Skills_20250922|Compose by Focus: Scene Graph-based Atomic Skills]] (81.6% similar)
- [[2025-09-22/SegDINO3D_ 3D Instance Segmentation Empowered by Both Image-Level and Object-Level 2D Features_20250922|SegDINO3D: 3D Instance Segmentation Empowered by Both Image-Level and Object-Level 2D Features]] (81.3% similar)
- [[2025-09-19/SPATIALGEN_ Layout-guided 3D Indoor Scene Generation_20250919|SPATIALGEN: Layout-guided 3D Indoor Scene Generation]] (81.2% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Zero-Shot Learning|Zero-Shot Learning]]
**⚡ Unique Technical**: [[keywords/SceneForge|SceneForge]], [[keywords/Compositional Augmentation|Compositional Augmentation]]
**🚀 Evolved Concepts**: [[keywords/3D-Text Contrastive Learning|3D-Text Contrastive Learning]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.15693v1 Announce Type: new 
Abstract: The whole is greater than the sum of its parts-even in 3D-text contrastive learning. We introduce SceneForge, a novel framework that enhances contrastive alignment between 3D point clouds and text through structured multi-object scene compositions. SceneForge leverages individual 3D shapes to construct multi-object scenes with explicit spatial relations, pairing them with coherent multi-object descriptions refined by a large language model. By augmenting contrastive training with these structured, compositional samples, SceneForge effectively addresses the scarcity of large-scale 3D-text datasets, significantly enriching data complexity and diversity. We systematically investigate critical design elements, such as the optimal number of objects per scene, the proportion of compositional samples in training batches, and scene construction strategies. Extensive experiments demonstrate that SceneForge delivers substantial performance gains across multiple tasks, including zero-shot classification on ModelNet, ScanObjNN, Objaverse-LVIS, and ScanNet, as well as few-shot part segmentation on ShapeNetPart. SceneForge's compositional augmentations are model-agnostic, consistently improving performance across multiple encoder architectures. Moreover, SceneForge improves 3D visual question answering on ScanQA, generalizes robustly to retrieval scenarios with increasing scene complexity, and showcases spatial reasoning capabilities by adapting spatial configurations to align precisely with textual instructions.

## 🔍 Abstract (한글 번역)

arXiv:2509.15693v1 발표 유형: 신규  
초록: 전체는 부분의 합보다 크다 - 3D-텍스트 대조 학습에서도 마찬가지이다. 우리는 3D 포인트 클라우드와 텍스트 간의 대조적 정렬을 구조화된 다중 객체 장면 구성으로 향상시키는 새로운 프레임워크인 SceneForge를 소개한다. SceneForge는 개별 3D 형상을 활용하여 명시적인 공간 관계를 가진 다중 객체 장면을 구성하고, 이를 대형 언어 모델에 의해 정제된 일관된 다중 객체 설명과 짝지운다. 이러한 구조화된 구성 샘플로 대조적 훈련을 증강함으로써, SceneForge는 대규모 3D-텍스트 데이터셋의 부족 문제를 효과적으로 해결하고 데이터의 복잡성과 다양성을 크게 풍부하게 한다. 우리는 장면당 최적의 객체 수, 훈련 배치에서 구성 샘플의 비율, 장면 구성 전략과 같은 중요한 설계 요소를 체계적으로 조사한다. 광범위한 실험을 통해 SceneForge가 ModelNet, ScanObjNN, Objaverse-LVIS 및 ScanNet에서의 제로샷 분류, ShapeNetPart에서의 소수 샷 부분 분할을 포함한 여러 작업에서 상당한 성능 향상을 제공함을 입증한다. SceneForge의 구성적 증강은 모델에 구애받지 않으며, 여러 인코더 아키텍처에서 일관되게 성능을 향상시킨다. 더욱이, SceneForge는 ScanQA에서의 3D 시각적 질문 응답을 개선하고, 장면 복잡성이 증가하는 검색 시나리오에 강력하게 일반화하며, 공간 구성을 텍스트 지침에 정확히 맞추어 적응함으로써 공간 추론 능력을 보여준다.

## 📝 요약

SceneForge는 3D 포인트 클라우드와 텍스트 간의 대조적 정렬을 강화하는 새로운 프레임워크로, 구조화된 다중 객체 장면 구성을 통해 이를 실현합니다. 개별 3D 형태를 활용하여 명시적인 공간 관계를 가진 다중 객체 장면을 구성하고, 대형 언어 모델로 정제된 일관된 다중 객체 설명과 짝지어 대조적 학습을 강화합니다. 이는 대규모 3D-텍스트 데이터셋의 부족 문제를 해결하며 데이터의 복잡성과 다양성을 크게 향상시킵니다. 최적의 객체 수, 훈련 배치 내 구성 샘플 비율, 장면 구성 전략 등 주요 설계 요소를 체계적으로 조사했습니다. 실험 결과, SceneForge는 다양한 작업에서 성능을 크게 향상시키며, 여러 인코더 아키텍처에서 일관된 성능 개선을 보여줍니다. 또한, 3D 시각적 질문 응답, 검색 시나리오 일반화, 공간 구성 적응 등에서 탁월한 성과를 보입니다.

## 🎯 주요 포인트

- 1. SceneForge는 3D 포인트 클라우드와 텍스트 간의 대조적 정렬을 강화하는 새로운 프레임워크로, 구조화된 다중 객체 장면 구성을 통해 이를 구현합니다.
- 2. SceneForge는 개별 3D 형태를 활용하여 명시적인 공간 관계를 가진 다중 객체 장면을 구성하고, 이를 대형 언어 모델로 정제된 일관된 다중 객체 설명과 짝지어 줍니다.
- 3. 대조적 훈련을 구조화된 구성 샘플로 보강함으로써, SceneForge는 대규모 3D-텍스트 데이터셋의 부족 문제를 효과적으로 해결하고 데이터의 복잡성과 다양성을 크게 향상시킵니다.
- 4. SceneForge는 ModelNet, ScanObjNN, Objaverse-LVIS, ScanNet에서의 제로샷 분류와 ShapeNetPart에서의 소수샷 부품 분할 등 여러 작업에서 성능을 크게 향상시킵니다.
- 5. SceneForge는 모델에 구애받지 않는 구성적 증강을 제공하여 여러 인코더 아키텍처 전반에서 일관되게 성능을 개선하며, 3D 시각적 질문 응답과 복잡한 장면에서의 검색 시나리오에 강력하게 일반화됩니다.


---

*Generated on 2025-09-23 12:06:19*