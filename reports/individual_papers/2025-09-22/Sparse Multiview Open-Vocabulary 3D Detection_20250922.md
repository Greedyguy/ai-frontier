---
keywords:
  - 3D Object Detection
  - Open-Vocabulary Learning
  - Sparse-View 3D Detection
  - Pre-trained 2D Models
  - Featuremetric Consistency
category: cs.CV
publish_date: 2025-09-22
arxiv_id: 2509.15924
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T12:15:07.613860",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "3D Object Detection",
    "Open-Vocabulary Learning",
    "Sparse-View 3D Detection",
    "Pre-trained 2D Models",
    "Featuremetric Consistency"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "3D Object Detection": 0.8,
    "Open-Vocabulary Learning": 0.78,
    "Sparse-View 3D Detection": 0.77,
    "Pre-trained 2D Models": 0.79,
    "Featuremetric Consistency": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "3D object detection",
        "canonical": "3D Object Detection",
        "aliases": [
          "3D detection",
          "object detection in 3D"
        ],
        "category": "unique_technical",
        "rationale": "This is a specific task within computer vision that is central to the paper's contribution.",
        "novelty_score": 0.65,
        "connectivity_score": 0.78,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "open-vocabulary",
        "canonical": "Open-Vocabulary Learning",
        "aliases": [
          "open vocabulary"
        ],
        "category": "evolved_concepts",
        "rationale": "The concept is crucial for linking to broader discussions on flexible learning systems.",
        "novelty_score": 0.7,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "sparse-view setting",
        "canonical": "Sparse-View 3D Detection",
        "aliases": [
          "sparse view",
          "limited view"
        ],
        "category": "unique_technical",
        "rationale": "This represents a novel approach to 3D detection with limited data, a key focus of the paper.",
        "novelty_score": 0.68,
        "connectivity_score": 0.7,
        "specificity_score": 0.82,
        "link_intent_score": 0.77
      },
      {
        "surface": "pre-trained 2D foundation models",
        "canonical": "Pre-trained 2D Models",
        "aliases": [
          "2D foundation models",
          "pre-trained models"
        ],
        "category": "specific_connectable",
        "rationale": "These models are central to the paper's methodology and connect to broader trends in model reuse.",
        "novelty_score": 0.6,
        "connectivity_score": 0.85,
        "specificity_score": 0.78,
        "link_intent_score": 0.79
      },
      {
        "surface": "featuremetric consistency",
        "canonical": "Featuremetric Consistency",
        "aliases": [
          "feature metric consistency"
        ],
        "category": "unique_technical",
        "rationale": "This is a unique technical approach described in the paper to optimize 3D proposals.",
        "novelty_score": 0.72,
        "connectivity_score": 0.68,
        "specificity_score": 0.81,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "scene interpretation",
      "bounding boxes",
      "training data"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "3D object detection",
      "resolved_canonical": "3D Object Detection",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.78,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "open-vocabulary",
      "resolved_canonical": "Open-Vocabulary Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "sparse-view setting",
      "resolved_canonical": "Sparse-View 3D Detection",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.7,
        "specificity": 0.82,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "pre-trained 2D foundation models",
      "resolved_canonical": "Pre-trained 2D Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.85,
        "specificity": 0.78,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "featuremetric consistency",
      "resolved_canonical": "Featuremetric Consistency",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.68,
        "specificity": 0.81,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Sparse Multiview Open-Vocabulary 3D Detection

**Korean Title:** í¬ì†Œ ë‹¤ì¤‘ ì‹œì  ê°œë°©í˜• ì–´íœ˜ 3D íƒì§€

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15924.pdf)
**Category**: cs.CV
**Published**: 2025-09-22
**ArXiv ID**: [2509.15924](https://arxiv.org/abs/2509.15924)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Zero-Shot Visual Grounding in 3D Gaussians via View Retrieval_20250922|Zero-Shot Visual Grounding in 3D Gaussians via View Retrieval]] (83.9% similar)
- [[2025-09-22/The Missing Piece_ A Case for Pre-Training in 3D Medical Object Detection_20250922|The Missing Piece: A Case for Pre-Training in 3D Medical Object Detection]] (83.9% similar)
- [[2025-09-18/UniPLV_ Towards Label-Efficient Open-World 3D Scene Understanding by Regional Visual Language Supervision_20250918|UniPLV: Towards Label-Efficient Open-World 3D Scene Understanding by Regional Visual Language Supervision]] (83.3% similar)
- [[2025-09-22/DAOcc_ 3D Object Detection Assisted Multi-Sensor Fusion for 3D Occupancy Prediction_20250922|DAOcc: 3D Object Detection Assisted Multi-Sensor Fusion for 3D Occupancy Prediction]] (83.2% similar)
- [[2025-09-19/Seeing 3D Through 2D Lenses_ 3D Few-Shot Class-Incremental Learning via Cross-Modal Geometric Rectification_20250919|Seeing 3D Through 2D Lenses: 3D Few-Shot Class-Incremental Learning via Cross-Modal Geometric Rectification]] (82.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Pre-trained 2D Models|Pre-trained 2D Models]]
**âš¡ Unique Technical**: [[keywords/3D Object Detection|3D Object Detection]], [[keywords/Sparse-View 3D Detection|Sparse-View 3D Detection]], [[keywords/Featuremetric Consistency|Featuremetric Consistency]]
**ğŸš€ Evolved Concepts**: [[keywords/Open-Vocabulary Learning|Open-Vocabulary Learning]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15924v1 Announce Type: new 
Abstract: The ability to interpret and comprehend a 3D scene is essential for many vision and robotics systems. In numerous applications, this involves 3D object detection, i.e.~identifying the location and dimensions of objects belonging to a specific category, typically represented as bounding boxes. This has traditionally been solved by training to detect a fixed set of categories, which limits its use. In this work, we investigate open-vocabulary 3D object detection in the challenging yet practical sparse-view setting, where only a limited number of posed RGB images are available as input. Our approach is training-free, relying on pre-trained, off-the-shelf 2D foundation models instead of employing computationally expensive 3D feature fusion or requiring 3D-specific learning. By lifting 2D detections and directly optimizing 3D proposals for featuremetric consistency across views, we fully leverage the extensive training data available in 2D compared to 3D. Through standard benchmarks, we demonstrate that this simple pipeline establishes a powerful baseline, performing competitively with state-of-the-art techniques in densely sampled scenarios while significantly outperforming them in the sparse-view setting.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15924v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: 3D ì¥ë©´ì„ í•´ì„í•˜ê³  ì´í•´í•˜ëŠ” ëŠ¥ë ¥ì€ ë§ì€ ë¹„ì „ ë° ë¡œë´‡ ì‹œìŠ¤í…œì— í•„ìˆ˜ì ì…ë‹ˆë‹¤. ì—¬ëŸ¬ ì‘ìš© ë¶„ì•¼ì—ì„œ ì´ëŠ” 3D ê°ì²´ íƒì§€, ì¦‰ íŠ¹ì • ë²”ì£¼ì— ì†í•˜ëŠ” ê°ì²´ì˜ ìœ„ì¹˜ì™€ í¬ê¸°ë¥¼ ì‹ë³„í•˜ëŠ” ê²ƒì„ í¬í•¨í•˜ë©°, ì¼ë°˜ì ìœ¼ë¡œ ê²½ê³„ ìƒìë¡œ í‘œí˜„ë©ë‹ˆë‹¤. ì´ëŠ” ì „í†µì ìœ¼ë¡œ ê³ ì •ëœ ë²”ì£¼ì˜ ì§‘í•©ì„ íƒì§€í•˜ë„ë¡ í›ˆë ¨í•˜ì—¬ í•´ê²°ë˜ì–´ ì™”ìœ¼ë©°, ì´ëŠ” ì‚¬ìš©ì„ ì œí•œí•©ë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” ì…ë ¥ìœ¼ë¡œ ì œí•œëœ ìˆ˜ì˜ í¬ì¦ˆê°€ ìˆëŠ” RGB ì´ë¯¸ì§€ë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë„ì „ì ì´ì§€ë§Œ ì‹¤ìš©ì ì¸ í¬ì†Œ ë·° ì„¤ì •ì—ì„œ ê°œë°©í˜• ì–´íœ˜ 3D ê°ì²´ íƒì§€ë¥¼ ì¡°ì‚¬í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì ‘ê·¼ ë°©ì‹ì€ í›ˆë ¨ì´ í•„ìš” ì—†ìœ¼ë©°, ê³„ì‚° ë¹„ìš©ì´ ë§ì´ ë“œëŠ” 3D íŠ¹ì§• ìœµí•©ì„ ì‚¬ìš©í•˜ê±°ë‚˜ 3Dì— íŠ¹í™”ëœ í•™ìŠµì„ ìš”êµ¬í•˜ëŠ” ëŒ€ì‹ , ì‚¬ì „ í›ˆë ¨ëœ ê¸°ì„± 2D ê¸°ì´ˆ ëª¨ë¸ì— ì˜ì¡´í•©ë‹ˆë‹¤. 2D íƒì§€ë¥¼ ìƒìŠ¹ì‹œí‚¤ê³  ë·° ê°„ íŠ¹ì§• ë©”íŠ¸ë¦­ ì¼ê´€ì„±ì„ ìœ„í•´ 3D ì œì•ˆì„ ì§ì ‘ ìµœì í™”í•¨ìœ¼ë¡œì¨, 3Dì— ë¹„í•´ 2Dì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë°©ëŒ€í•œ í›ˆë ¨ ë°ì´í„°ë¥¼ ì™„ì „íˆ í™œìš©í•©ë‹ˆë‹¤. í‘œì¤€ ë²¤ì¹˜ë§ˆí¬ë¥¼ í†µí•´, ì´ ê°„ë‹¨í•œ íŒŒì´í”„ë¼ì¸ì´ ê°•ë ¥í•œ ê¸°ì¤€ì„ ì„¤ì •í•˜ë©°, ì¡°ë°€í•˜ê²Œ ìƒ˜í”Œë§ëœ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ìµœì²¨ë‹¨ ê¸°ìˆ ê³¼ ê²½ìŸë ¥ ìˆê²Œ ìˆ˜í–‰í•˜ë©´ì„œ í¬ì†Œ ë·° ì„¤ì •ì—ì„œëŠ” ì´ë¥¼ í¬ê²Œ ëŠ¥ê°€í•¨ì„ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì œí•œëœ ìˆ˜ì˜ RGB ì´ë¯¸ì§€ë¡œë¶€í„° 3D ê°ì²´ë¥¼ íƒì§€í•˜ëŠ” 'ì˜¤í”ˆ ë³´ìºë·¸ëŸ¬ë¦¬ 3D ê°ì²´ íƒì§€'ë¥¼ ì—°êµ¬í•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë°©ë²•ì€ ê³ ì •ëœ ì¹´í…Œê³ ë¦¬ë§Œ íƒì§€ ê°€ëŠ¥í•˜ì—¬ í™œìš©ì— ì œí•œì´ ìˆì—ˆìœ¼ë‚˜, ë³¸ ì—°êµ¬ëŠ” ì‚¬ì „ í•™ìŠµëœ 2D ëª¨ë¸ì„ í™œìš©í•˜ì—¬ 3D í•™ìŠµ ì—†ì´ë„ ê°ì²´ íƒì§€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤. 2D íƒì§€ë¥¼ 3D ì œì•ˆìœ¼ë¡œ ë³€í™˜í•˜ê³ , ë‹¤ì–‘í•œ ì‹œì ì—ì„œì˜ íŠ¹ì§• ì¼ê´€ì„±ì„ ìµœì í™”í•˜ì—¬ 2Dì˜ ë°©ëŒ€í•œ í•™ìŠµ ë°ì´í„°ë¥¼ ìµœëŒ€í•œ í™œìš©í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì€ ê¸°ì¡´ ìµœì²¨ë‹¨ ê¸°ìˆ ê³¼ ë¹„êµí•´ ë°€ì§‘ëœ ìƒ˜í”Œë§ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ê²½ìŸë ¥ ìˆëŠ” ì„±ëŠ¥ì„ ë³´ì´ë©°, í¬ì†Œí•œ ì‹œì ì˜ ê²½ìš°ì—ëŠ” ì›”ë“±í•œ ì„±ëŠ¥ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. 3D ì¥ë©´ í•´ì„ê³¼ ì´í•´ëŠ” ë¹„ì „ ë° ë¡œë´‡ ì‹œìŠ¤í…œì— í•„ìˆ˜ì ì…ë‹ˆë‹¤.
- 2. ë³¸ ì—°êµ¬ëŠ” ì œí•œëœ ìˆ˜ì˜ í¬ì¦ˆëœ RGB ì´ë¯¸ì§€ê°€ ì…ë ¥ìœ¼ë¡œ ì œê³µë˜ëŠ” í¬ì†Œ ë·° ì„¤ì •ì—ì„œì˜ ê°œë°©í˜• ì–´íœ˜ 3D ê°ì²´ íƒì§€ë¥¼ ì¡°ì‚¬í•©ë‹ˆë‹¤.
- 3. ì œì•ˆëœ ì ‘ê·¼ë²•ì€ ì‚¬ì „ í•™ìŠµëœ 2D ëª¨ë¸ì„ í™œìš©í•˜ì—¬ 3D íŠ¹ì„± ìœµí•©ì´ë‚˜ 3D í•™ìŠµ ì—†ì´ë„ 3D ì œì•ˆì„ ìµœì í™”í•©ë‹ˆë‹¤.
- 4. 2D íƒì§€ë¥¼ í™œìš©í•˜ì—¬ 3D ì œì•ˆì„ ìµœì í™”í•¨ìœ¼ë¡œì¨, 2Dì—ì„œì˜ ê´‘ë²”ìœ„í•œ í•™ìŠµ ë°ì´í„°ë¥¼ ìµœëŒ€í•œ í™œìš©í•©ë‹ˆë‹¤.
- 5. ì œì•ˆëœ ë°©ë²•ì€ í¬ì†Œ ë·° ì„¤ì •ì—ì„œ ê¸°ì¡´ ìµœì²¨ë‹¨ ê¸°ìˆ ì„ ëŠ¥ê°€í•˜ëŠ” ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.


---

*Generated on 2025-09-23 12:15:07*