---
keywords:
  - 3D Object Detection
  - Open-Vocabulary Learning
  - Sparse-View 3D Detection
  - Pre-trained 2D Models
  - Featuremetric Consistency
category: cs.CV
publish_date: 2025-09-22
arxiv_id: 2509.15924
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T12:15:07.613860",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "3D Object Detection",
    "Open-Vocabulary Learning",
    "Sparse-View 3D Detection",
    "Pre-trained 2D Models",
    "Featuremetric Consistency"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "3D Object Detection": 0.8,
    "Open-Vocabulary Learning": 0.78,
    "Sparse-View 3D Detection": 0.77,
    "Pre-trained 2D Models": 0.79,
    "Featuremetric Consistency": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "3D object detection",
        "canonical": "3D Object Detection",
        "aliases": [
          "3D detection",
          "object detection in 3D"
        ],
        "category": "unique_technical",
        "rationale": "This is a specific task within computer vision that is central to the paper's contribution.",
        "novelty_score": 0.65,
        "connectivity_score": 0.78,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "open-vocabulary",
        "canonical": "Open-Vocabulary Learning",
        "aliases": [
          "open vocabulary"
        ],
        "category": "evolved_concepts",
        "rationale": "The concept is crucial for linking to broader discussions on flexible learning systems.",
        "novelty_score": 0.7,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "sparse-view setting",
        "canonical": "Sparse-View 3D Detection",
        "aliases": [
          "sparse view",
          "limited view"
        ],
        "category": "unique_technical",
        "rationale": "This represents a novel approach to 3D detection with limited data, a key focus of the paper.",
        "novelty_score": 0.68,
        "connectivity_score": 0.7,
        "specificity_score": 0.82,
        "link_intent_score": 0.77
      },
      {
        "surface": "pre-trained 2D foundation models",
        "canonical": "Pre-trained 2D Models",
        "aliases": [
          "2D foundation models",
          "pre-trained models"
        ],
        "category": "specific_connectable",
        "rationale": "These models are central to the paper's methodology and connect to broader trends in model reuse.",
        "novelty_score": 0.6,
        "connectivity_score": 0.85,
        "specificity_score": 0.78,
        "link_intent_score": 0.79
      },
      {
        "surface": "featuremetric consistency",
        "canonical": "Featuremetric Consistency",
        "aliases": [
          "feature metric consistency"
        ],
        "category": "unique_technical",
        "rationale": "This is a unique technical approach described in the paper to optimize 3D proposals.",
        "novelty_score": 0.72,
        "connectivity_score": 0.68,
        "specificity_score": 0.81,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "scene interpretation",
      "bounding boxes",
      "training data"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "3D object detection",
      "resolved_canonical": "3D Object Detection",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.78,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "open-vocabulary",
      "resolved_canonical": "Open-Vocabulary Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "sparse-view setting",
      "resolved_canonical": "Sparse-View 3D Detection",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.7,
        "specificity": 0.82,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "pre-trained 2D foundation models",
      "resolved_canonical": "Pre-trained 2D Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.85,
        "specificity": 0.78,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "featuremetric consistency",
      "resolved_canonical": "Featuremetric Consistency",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.68,
        "specificity": 0.81,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Sparse Multiview Open-Vocabulary 3D Detection

**Korean Title:** 희소 다중 시점 개방형 어휘 3D 탐지

## 📋 메타데이터

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.15924.pdf)
**Category**: cs.CV
**Published**: 2025-09-22
**ArXiv ID**: [2509.15924](https://arxiv.org/abs/2509.15924)

## 🔗 유사한 논문
- [[2025-09-22/Zero-Shot Visual Grounding in 3D Gaussians via View Retrieval_20250922|Zero-Shot Visual Grounding in 3D Gaussians via View Retrieval]] (83.9% similar)
- [[2025-09-22/The Missing Piece_ A Case for Pre-Training in 3D Medical Object Detection_20250922|The Missing Piece: A Case for Pre-Training in 3D Medical Object Detection]] (83.9% similar)
- [[2025-09-18/UniPLV_ Towards Label-Efficient Open-World 3D Scene Understanding by Regional Visual Language Supervision_20250918|UniPLV: Towards Label-Efficient Open-World 3D Scene Understanding by Regional Visual Language Supervision]] (83.3% similar)
- [[2025-09-22/DAOcc_ 3D Object Detection Assisted Multi-Sensor Fusion for 3D Occupancy Prediction_20250922|DAOcc: 3D Object Detection Assisted Multi-Sensor Fusion for 3D Occupancy Prediction]] (83.2% similar)
- [[2025-09-19/Seeing 3D Through 2D Lenses_ 3D Few-Shot Class-Incremental Learning via Cross-Modal Geometric Rectification_20250919|Seeing 3D Through 2D Lenses: 3D Few-Shot Class-Incremental Learning via Cross-Modal Geometric Rectification]] (82.6% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Pre-trained 2D Models|Pre-trained 2D Models]]
**⚡ Unique Technical**: [[keywords/3D Object Detection|3D Object Detection]], [[keywords/Sparse-View 3D Detection|Sparse-View 3D Detection]], [[keywords/Featuremetric Consistency|Featuremetric Consistency]]
**🚀 Evolved Concepts**: [[keywords/Open-Vocabulary Learning|Open-Vocabulary Learning]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.15924v1 Announce Type: new 
Abstract: The ability to interpret and comprehend a 3D scene is essential for many vision and robotics systems. In numerous applications, this involves 3D object detection, i.e.~identifying the location and dimensions of objects belonging to a specific category, typically represented as bounding boxes. This has traditionally been solved by training to detect a fixed set of categories, which limits its use. In this work, we investigate open-vocabulary 3D object detection in the challenging yet practical sparse-view setting, where only a limited number of posed RGB images are available as input. Our approach is training-free, relying on pre-trained, off-the-shelf 2D foundation models instead of employing computationally expensive 3D feature fusion or requiring 3D-specific learning. By lifting 2D detections and directly optimizing 3D proposals for featuremetric consistency across views, we fully leverage the extensive training data available in 2D compared to 3D. Through standard benchmarks, we demonstrate that this simple pipeline establishes a powerful baseline, performing competitively with state-of-the-art techniques in densely sampled scenarios while significantly outperforming them in the sparse-view setting.

## 🔍 Abstract (한글 번역)

arXiv:2509.15924v1 발표 유형: 신규  
초록: 3D 장면을 해석하고 이해하는 능력은 많은 비전 및 로봇 시스템에 필수적입니다. 여러 응용 분야에서 이는 3D 객체 탐지, 즉 특정 범주에 속하는 객체의 위치와 크기를 식별하는 것을 포함하며, 일반적으로 경계 상자로 표현됩니다. 이는 전통적으로 고정된 범주의 집합을 탐지하도록 훈련하여 해결되어 왔으며, 이는 사용을 제한합니다. 본 연구에서는 입력으로 제한된 수의 포즈가 있는 RGB 이미지만 사용할 수 있는 도전적이지만 실용적인 희소 뷰 설정에서 개방형 어휘 3D 객체 탐지를 조사합니다. 우리의 접근 방식은 훈련이 필요 없으며, 계산 비용이 많이 드는 3D 특징 융합을 사용하거나 3D에 특화된 학습을 요구하는 대신, 사전 훈련된 기성 2D 기초 모델에 의존합니다. 2D 탐지를 상승시키고 뷰 간 특징 메트릭 일관성을 위해 3D 제안을 직접 최적화함으로써, 3D에 비해 2D에서 사용할 수 있는 방대한 훈련 데이터를 완전히 활용합니다. 표준 벤치마크를 통해, 이 간단한 파이프라인이 강력한 기준을 설정하며, 조밀하게 샘플링된 시나리오에서 최첨단 기술과 경쟁력 있게 수행하면서 희소 뷰 설정에서는 이를 크게 능가함을 입증합니다.

## 📝 요약

이 논문은 제한된 수의 RGB 이미지로부터 3D 객체를 탐지하는 '오픈 보캐뷸러리 3D 객체 탐지'를 연구합니다. 기존의 방법은 고정된 카테고리만 탐지 가능하여 활용에 제한이 있었으나, 본 연구는 사전 학습된 2D 모델을 활용하여 3D 학습 없이도 객체 탐지를 수행합니다. 2D 탐지를 3D 제안으로 변환하고, 다양한 시점에서의 특징 일관성을 최적화하여 2D의 방대한 학습 데이터를 최대한 활용합니다. 실험 결과, 제안된 방법은 기존 최첨단 기술과 비교해 밀집된 샘플링 시나리오에서 경쟁력 있는 성능을 보이며, 희소한 시점의 경우에는 월등한 성능을 나타냅니다.

## 🎯 주요 포인트

- 1. 3D 장면 해석과 이해는 비전 및 로봇 시스템에 필수적입니다.
- 2. 본 연구는 제한된 수의 포즈된 RGB 이미지가 입력으로 제공되는 희소 뷰 설정에서의 개방형 어휘 3D 객체 탐지를 조사합니다.
- 3. 제안된 접근법은 사전 학습된 2D 모델을 활용하여 3D 특성 융합이나 3D 학습 없이도 3D 제안을 최적화합니다.
- 4. 2D 탐지를 활용하여 3D 제안을 최적화함으로써, 2D에서의 광범위한 학습 데이터를 최대한 활용합니다.
- 5. 제안된 방법은 희소 뷰 설정에서 기존 최첨단 기술을 능가하는 성능을 보입니다.


---

*Generated on 2025-09-23 12:15:07*