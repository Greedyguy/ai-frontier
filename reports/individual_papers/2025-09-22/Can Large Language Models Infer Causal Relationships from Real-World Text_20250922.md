---
keywords:
  - Large Language Model
  - Causal Relationships
  - Artificial General Intelligence
  - Real-World Texts
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2505.18931
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T09:38:46.337969",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Causal Relationships",
    "Artificial General Intelligence",
    "Real-World Texts"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Causal Relationships": 0.78,
    "Artificial General Intelligence": 0.8,
    "Real-World Texts": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are central to the paper's investigation and connect to existing research in AI and NLP.",
        "novelty_score": 0.2,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Causal Relationships",
        "canonical": "Causal Relationships",
        "aliases": [
          "Causality"
        ],
        "category": "unique_technical",
        "rationale": "Understanding causal relationships is a unique and specific focus of the paper, crucial for advancing AI models.",
        "novelty_score": 0.65,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Artificial General Intelligence",
        "canonical": "Artificial General Intelligence",
        "aliases": [
          "AGI"
        ],
        "category": "evolved_concepts",
        "rationale": "Artificial General Intelligence represents the ultimate goal of LLM development and links to broader AI research.",
        "novelty_score": 0.55,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Real-World Texts",
        "canonical": "Real-World Texts",
        "aliases": [
          "Natural Texts"
        ],
        "category": "unique_technical",
        "rationale": "The focus on real-world texts distinguishes the paper's approach from synthetic datasets, highlighting its novelty.",
        "novelty_score": 0.68,
        "connectivity_score": 0.6,
        "specificity_score": 0.75,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.2,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Causal Relationships",
      "resolved_canonical": "Causal Relationships",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Artificial General Intelligence",
      "resolved_canonical": "Artificial General Intelligence",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Real-World Texts",
      "resolved_canonical": "Real-World Texts",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.6,
        "specificity": 0.75,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Can Large Language Models Infer Causal Relationships from Real-World Text?

**Korean Title:** ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì€ ì‹¤ì œ ì„¸ê³„ì˜ í…ìŠ¤íŠ¸ì—ì„œ ì¸ê³¼ ê´€ê³„ë¥¼ ì¶”ë¡ í•  ìˆ˜ ìˆëŠ”ê°€?

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2505.18931.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2505.18931](https://arxiv.org/abs/2505.18931)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Causal-Counterfactual RAG_ The Integration of Causal-Counterfactual Reasoning into RAG_20250919|Causal-Counterfactual RAG: The Integration of Causal-Counterfactual Reasoning into RAG]] (86.3% similar)
- [[2025-09-19/Rationality Check! Benchmarking the Rationality of Large Language Models_20250919|Rationality Check! Benchmarking the Rationality of Large Language Models]] (85.5% similar)
- [[2025-09-19/DetectAnyLLM_ Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models_20250919|DetectAnyLLM: Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models]] (85.5% similar)
- [[2025-09-22/Can LLMs Judge Debates? Evaluating Non-Linear Reasoning via Argumentation Theory Semantics_20250922|Can LLMs Judge Debates? Evaluating Non-Linear Reasoning via Argumentation Theory Semantics]] (85.4% similar)
- [[2025-09-17/Simulating a Bias Mitigation Scenario in Large Language Models_20250917|Simulating a Bias Mitigation Scenario in Large Language Models]] (85.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**âš¡ Unique Technical**: [[keywords/Causal Relationships|Causal Relationships]], [[keywords/Real-World Texts|Real-World Texts]]
**ğŸš€ Evolved Concepts**: [[keywords/Artificial General Intelligence|Artificial General Intelligence]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2505.18931v2 Announce Type: replace 
Abstract: Understanding and inferring causal relationships from texts is a core aspect of human cognition and is essential for advancing large language models (LLMs) towards artificial general intelligence. Existing work evaluating LLM causal reasoning primarily focuses on synthetically generated texts which involve straightforward causal relationships that are explicitly mentioned in the text. This fails to reflect the complexities of real-world tasks. In this paper, we investigate whether LLMs are capable of inferring causal relationships from real-world texts. We develop a benchmark drawn from real-world academic literature which includes diverse texts with respect to length, complexity of relationships (different levels of explicitness, number of nodes, and causal relationships), and domains and sub-domains. To the best of our knowledge, our benchmark is the first-ever real-world dataset for this task. Our experiments on this dataset show that LLMs face significant challenges in inferring causal relationships from real-world text, with the best-performing model achieving an average F1 score of only 0.477. Through systematic analysis across aspects of real-world text (degree of confounding, size of graph, length of text, domain), our benchmark offers targeted insights for further research into advancing LLM causal reasoning.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2505.18931v2 ë°œí‘œ ìœ í˜•: êµì²´  
ì´ˆë¡: í…ìŠ¤íŠ¸ì—ì„œ ì¸ê³¼ ê´€ê³„ë¥¼ ì´í•´í•˜ê³  ì¶”ë¡ í•˜ëŠ” ê²ƒì€ ì¸ê°„ ì¸ì§€ì˜ í•µì‹¬ ì¸¡ë©´ì´ë©°, ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ ì¸ê³µì§€ëŠ¥ ì¼ë°˜ ì§€ëŠ¥ìœ¼ë¡œ ë°œì „ì‹œí‚¤ê¸° ìœ„í•´ í•„ìˆ˜ì ì…ë‹ˆë‹¤. ê¸°ì¡´ì˜ LLM ì¸ê³¼ ì¶”ë¡  í‰ê°€ ì‘ì—…ì€ ì£¼ë¡œ í…ìŠ¤íŠ¸ì— ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰ëœ ë‹¨ìˆœí•œ ì¸ê³¼ ê´€ê³„ë¥¼ í¬í•¨í•˜ëŠ” í•©ì„±ì ìœ¼ë¡œ ìƒì„±ëœ í…ìŠ¤íŠ¸ì— ì¤‘ì ì„ ë‘ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ì‹¤ì œ ê³¼ì œì˜ ë³µì¡ì„±ì„ ë°˜ì˜í•˜ì§€ ëª»í•©ë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” LLMì´ ì‹¤ì œ í…ìŠ¤íŠ¸ì—ì„œ ì¸ê³¼ ê´€ê³„ë¥¼ ì¶”ë¡ í•  ìˆ˜ ìˆëŠ”ì§€ë¥¼ ì¡°ì‚¬í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ê¸¸ì´, ê´€ê³„ì˜ ë³µì¡ì„±(ëª…ì‹œì„±ì˜ ë‹¤ì–‘í•œ ìˆ˜ì¤€, ë…¸ë“œì˜ ìˆ˜, ì¸ê³¼ ê´€ê³„), ë„ë©”ì¸ ë° í•˜ìœ„ ë„ë©”ì¸ì— ë”°ë¼ ë‹¤ì–‘í•œ í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•˜ëŠ” ì‹¤ì œ í•™ìˆ  ë¬¸í—Œì—ì„œ ì¶”ì¶œí•œ ë²¤ì¹˜ë§ˆí¬ë¥¼ ê°œë°œí–ˆìŠµë‹ˆë‹¤. ìš°ë¦¬ê°€ ì•„ëŠ” í•œ, ìš°ë¦¬ì˜ ë²¤ì¹˜ë§ˆí¬ëŠ” ì´ ì‘ì—…ì„ ìœ„í•œ ìµœì´ˆì˜ ì‹¤ì œ ë°ì´í„°ì…‹ì…ë‹ˆë‹¤. ì´ ë°ì´í„°ì…‹ì— ëŒ€í•œ ì‹¤í—˜ ê²°ê³¼, LLMì€ ì‹¤ì œ í…ìŠ¤íŠ¸ì—ì„œ ì¸ê³¼ ê´€ê³„ë¥¼ ì¶”ë¡ í•˜ëŠ” ë° ìƒë‹¹í•œ ì–´ë ¤ì›€ì„ ê²ªê³  ìˆìœ¼ë©°, ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì€ ëª¨ë¸ë„ í‰ê·  F1 ì ìˆ˜ 0.477ì— ë¶ˆê³¼í•©ë‹ˆë‹¤. ì‹¤ì œ í…ìŠ¤íŠ¸ì˜ ì—¬ëŸ¬ ì¸¡ë©´(í˜¼ë€ì˜ ì •ë„, ê·¸ë˜í”„ì˜ í¬ê¸°, í…ìŠ¤íŠ¸ì˜ ê¸¸ì´, ë„ë©”ì¸)ì— ëŒ€í•œ ì²´ê³„ì ì¸ ë¶„ì„ì„ í†µí•´, ìš°ë¦¬ì˜ ë²¤ì¹˜ë§ˆí¬ëŠ” LLM ì¸ê³¼ ì¶”ë¡ ì„ ë°œì „ì‹œí‚¤ê¸° ìœ„í•œ ì¶”ê°€ ì—°êµ¬ì— ëŒ€í•œ ëª©í‘œ ì§€í–¥ì ì¸ í†µì°°ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì´ ì‹¤ì œ í…ìŠ¤íŠ¸ì—ì„œ ì¸ê³¼ê´€ê³„ë¥¼ ì¶”ë¡ í•  ìˆ˜ ìˆëŠ”ì§€ë¥¼ ì¡°ì‚¬í•©ë‹ˆë‹¤. ê¸°ì¡´ ì—°êµ¬ëŠ” ëª…ì‹œì ì¸ ì¸ê³¼ê´€ê³„ê°€ í¬í•¨ëœ í•©ì„± í…ìŠ¤íŠ¸ì— ì´ˆì ì„ ë§ì¶”ì—ˆìœ¼ë‚˜, ì´ëŠ” ì‹¤ì œ ê³¼ì œì˜ ë³µì¡ì„±ì„ ë°˜ì˜í•˜ì§€ ëª»í•©ë‹ˆë‹¤. ë³¸ ì—°êµ¬ëŠ” ë‹¤ì–‘í•œ ê¸¸ì´ì™€ ë³µì¡ì„±ì„ ê°€ì§„ ì‹¤ì œ í•™ìˆ  ë¬¸í—Œì—ì„œ ì¸ê³¼ê´€ê³„ë¥¼ í‰ê°€í•  ìˆ˜ ìˆëŠ” ë²¤ì¹˜ë§ˆí¬ë¥¼ ê°œë°œí•˜ì˜€ìœ¼ë©°, ì´ëŠ” ì´ ë¶„ì•¼ ìµœì´ˆì˜ ì‹¤ì œ ë°ì´í„°ì…‹ì…ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, LLMì€ ì‹¤ì œ í…ìŠ¤íŠ¸ì—ì„œ ì¸ê³¼ê´€ê³„ë¥¼ ì¶”ë¡ í•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªì—ˆìœ¼ë©°, ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì˜ í‰ê·  F1 ì ìˆ˜ëŠ” 0.477ì— ë¶ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì´ ë²¤ì¹˜ë§ˆí¬ëŠ” í˜¼ë€ ì •ë„, ê·¸ë˜í”„ í¬ê¸°, í…ìŠ¤íŠ¸ ê¸¸ì´, ë„ë©”ì¸ ë“± ë‹¤ì–‘í•œ ì¸¡ë©´ì—ì„œ ì²´ê³„ì ì¸ ë¶„ì„ì„ í†µí•´ LLMì˜ ì¸ê³¼ ì¶”ë¡  ì—°êµ¬ë¥¼ ìœ„í•œ ì¤‘ìš”í•œ í†µì°°ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì¸ê³¼ ì¶”ë¡  ëŠ¥ë ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•´ ì‹¤ì œ í•™ìˆ  ë¬¸í—Œì—ì„œ ë‹¤ì–‘í•œ í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ ë²¤ì¹˜ë§ˆí¬ë¥¼ ê°œë°œí–ˆìŠµë‹ˆë‹¤.
- 2. ì´ ë²¤ì¹˜ë§ˆí¬ëŠ” ì¸ê³¼ ê´€ê³„ì˜ ëª…ì‹œì„±, ë…¸ë“œ ìˆ˜, ë„ë©”ì¸ ë° í•˜ìœ„ ë„ë©”ì¸ ë“± ë‹¤ì–‘í•œ ë³µì¡ì„±ì„ ë°˜ì˜í•©ë‹ˆë‹¤.
- 3. ì‹¤í—˜ ê²°ê³¼, LLMì´ ì‹¤ì œ í…ìŠ¤íŠ¸ì—ì„œ ì¸ê³¼ ê´€ê³„ë¥¼ ì¶”ë¡ í•˜ëŠ” ë° ìƒë‹¹í•œ ì–´ë ¤ì›€ì„ ê²ªìœ¼ë©°, ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì˜ í‰ê·  F1 ì ìˆ˜ëŠ” 0.477ì— ë¶ˆê³¼í–ˆìŠµë‹ˆë‹¤.
- 4. ë³¸ ì—°êµ¬ëŠ” LLMì˜ ì¸ê³¼ ì¶”ë¡ ì„ ë°œì „ì‹œí‚¤ê¸° ìœ„í•œ ì¶”ê°€ ì—°êµ¬ì— ëŒ€í•œ í†µì°°ì„ ì œê³µí•©ë‹ˆë‹¤.


---

*Generated on 2025-09-23 09:38:46*