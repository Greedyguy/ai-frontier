---
keywords:
  - Multimodal Learning
  - Vision-Language Model
  - Knowledge Distillation
  - Self-supervised Learning
  - Generative Adversarial Network
category: cs.CV
publish_date: 2025-09-22
arxiv_id: 2509.16017
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T12:17:36.359005",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multimodal Learning",
    "Vision-Language Model",
    "Knowledge Distillation",
    "Self-supervised Learning",
    "Generative Adversarial Network"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multimodal Learning": 0.82,
    "Vision-Language Model": 0.79,
    "Knowledge Distillation": 0.77,
    "Self-supervised Learning": 0.78,
    "Generative Adversarial Network": 0.74
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multimodal Image Matching",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Cross-modal Image Matching"
        ],
        "category": "specific_connectable",
        "rationale": "This term is central to the paper's focus on matching images across different modalities, aligning with the concept of Multimodal Learning.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "Vision Foundation Model",
        "canonical": "Vision-Language Model",
        "aliases": [
          "VFM"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision Foundation Models are a key component in the paper, similar to Vision-Language Models in their cross-modal capabilities.",
        "novelty_score": 0.68,
        "connectivity_score": 0.75,
        "specificity_score": 0.82,
        "link_intent_score": 0.79
      },
      {
        "surface": "Knowledge Distillation",
        "canonical": "Knowledge Distillation",
        "aliases": [
          "Model Compression"
        ],
        "category": "broad_technical",
        "rationale": "This technique is crucial for transferring knowledge from large models to smaller ones, a core process in the paper.",
        "novelty_score": 0.47,
        "connectivity_score": 0.83,
        "specificity_score": 0.7,
        "link_intent_score": 0.77
      },
      {
        "surface": "DINOv2",
        "canonical": "Self-supervised Learning",
        "aliases": [
          "DINO",
          "DINOv3"
        ],
        "category": "specific_connectable",
        "rationale": "DINO models are examples of self-supervised learning, which is pivotal for feature extraction in this context.",
        "novelty_score": 0.6,
        "connectivity_score": 0.8,
        "specificity_score": 0.76,
        "link_intent_score": 0.78
      },
      {
        "surface": "V2I-GAN",
        "canonical": "Generative Adversarial Network",
        "aliases": [
          "Visible to Infrared GAN"
        ],
        "category": "unique_technical",
        "rationale": "This specific GAN variant is used for data augmentation, enhancing model generalization in the paper.",
        "novelty_score": 0.72,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.74
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multimodal Image Matching",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Vision Foundation Model",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.75,
        "specificity": 0.82,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Knowledge Distillation",
      "resolved_canonical": "Knowledge Distillation",
      "decision": "linked",
      "scores": {
        "novelty": 0.47,
        "connectivity": 0.83,
        "specificity": 0.7,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "DINOv2",
      "resolved_canonical": "Self-supervised Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.8,
        "specificity": 0.76,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "V2I-GAN",
      "resolved_canonical": "Generative Adversarial Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.74
      }
    }
  ]
}
-->

# DistillMatch: Leveraging Knowledge Distillation from Vision Foundation Model for Multimodal Image Matching

**Korean Title:** ë””ìŠ¤í‹¸ë§¤ì¹˜: ë©€í‹°ëª¨ë‹¬ ì´ë¯¸ì§€ ë§¤ì¹­ì„ ìœ„í•œ ë¹„ì „ íŒŒìš´ë°ì´ì…˜ ëª¨ë¸ì˜ ì§€ì‹ ì¦ë¥˜ í™œìš©

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.16017.pdf)
**Category**: cs.CV
**Published**: 2025-09-22
**ArXiv ID**: [2509.16017](https://arxiv.org/abs/2509.16017)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Efficient Multimodal Dataset Distillation via Generative Models_20250922|Efficient Multimodal Dataset Distillation via Generative Models]] (83.6% similar)
- [[2025-09-19/Multimodal Knowledge Distillation for Egocentric Action Recognition Robust to Missing Modalities_20250919|Multimodal Knowledge Distillation for Egocentric Action Recognition Robust to Missing Modalities]] (83.3% similar)
- [[2025-09-19/MARIC_ Multi-Agent Reasoning for Image Classification_20250919|MARIC: Multi-Agent Reasoning for Image Classification]] (82.4% similar)
- [[2025-09-22/The Moon's Many Faces_ A Single Unified Transformer for Multimodal Lunar Reconstruction_20250922|The Moon's Many Faces: A Single Unified Transformer for Multimodal Lunar Reconstruction]] (81.2% similar)
- [[2025-09-22/Temperature-Driven Robust Disease Detection in Brain and Gastrointestinal Disorders via Context-Aware Adaptive Knowledge Distillation_20250922|Temperature-Driven Robust Disease Detection in Brain and Gastrointestinal Disorders via Context-Aware Adaptive Knowledge Distillation]] (81.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Knowledge Distillation|Knowledge Distillation]]
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]], [[keywords/Self-supervised Learning|Self-supervised Learning]]
**âš¡ Unique Technical**: [[keywords/Generative Adversarial Network|Generative Adversarial Network]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16017v1 Announce Type: new 
Abstract: Multimodal image matching seeks pixel-level correspondences between images of different modalities, crucial for cross-modal perception, fusion and analysis. However, the significant appearance differences between modalities make this task challenging. Due to the scarcity of high-quality annotated datasets, existing deep learning methods that extract modality-common features for matching perform poorly and lack adaptability to diverse scenarios. Vision Foundation Model (VFM), trained on large-scale data, yields generalizable and robust feature representations adapted to data and tasks of various modalities, including multimodal matching. Thus, we propose DistillMatch, a multimodal image matching method using knowledge distillation from VFM. DistillMatch employs knowledge distillation to build a lightweight student model that extracts high-level semantic features from VFM (including DINOv2 and DINOv3) to assist matching across modalities. To retain modality-specific information, it extracts and injects modality category information into the other modality's features, which enhances the model's understanding of cross-modal correlations. Furthermore, we design V2I-GAN to boost the model's generalization by translating visible to pseudo-infrared images for data augmentation. Experiments show that DistillMatch outperforms existing algorithms on public datasets.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.16017v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: ë‹¤ì¤‘ ëª¨ë‹¬ ì´ë¯¸ì§€ ë§¤ì¹­ì€ ì„œë¡œ ë‹¤ë¥¸ ëª¨ë‹¬ë¦¬í‹°ì˜ ì´ë¯¸ì§€ ê°„ì— í”½ì…€ ìˆ˜ì¤€ì˜ ëŒ€ì‘ì„ ì°¾ëŠ” ì‘ì—…ìœ¼ë¡œ, êµì°¨ ëª¨ë‹¬ ì¸ì‹, ìœµí•© ë° ë¶„ì„ì— í•„ìˆ˜ì ì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ëª¨ë‹¬ë¦¬í‹° ê°„ì˜ ìƒë‹¹í•œ ì™¸ê´€ ì°¨ì´ë¡œ ì¸í•´ ì´ ì‘ì—…ì€ ë„ì „ì ì…ë‹ˆë‹¤. ê³ í’ˆì§ˆ ì£¼ì„ ë°ì´í„°ì…‹ì˜ ë¶€ì¡±ìœ¼ë¡œ ì¸í•´, ë§¤ì¹­ì„ ìœ„í•œ ëª¨ë‹¬ë¦¬í‹° ê³µí†µ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ëŠ” ê¸°ì¡´ì˜ ë”¥ëŸ¬ë‹ ë°©ë²•ë“¤ì€ ì„±ëŠ¥ì´ ì €ì¡°í•˜ë©° ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì— ëŒ€í•œ ì ì‘ë ¥ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ëŒ€ê·œëª¨ ë°ì´í„°ë¡œ í›ˆë ¨ëœ ë¹„ì „ íŒŒìš´ë°ì´ì…˜ ëª¨ë¸(VFM)ì€ ë‹¤ì¤‘ ëª¨ë‹¬ ë§¤ì¹­ì„ í¬í•¨í•˜ì—¬ ë‹¤ì–‘í•œ ëª¨ë‹¬ë¦¬í‹°ì˜ ë°ì´í„°ì™€ ì‘ì—…ì— ì ì‘ëœ ì¼ë°˜ì ì´ê³  ê°•ë ¥í•œ íŠ¹ì§• í‘œí˜„ì„ ì œê³µí•©ë‹ˆë‹¤. ë”°ë¼ì„œ ìš°ë¦¬ëŠ” VFMìœ¼ë¡œë¶€í„° ì§€ì‹ ì¦ë¥˜ë¥¼ ì‚¬ìš©í•˜ëŠ” ë‹¤ì¤‘ ëª¨ë‹¬ ì´ë¯¸ì§€ ë§¤ì¹­ ë°©ë²•ì¸ DistillMatchë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. DistillMatchëŠ” VFM(ì˜ˆ: DINOv2 ë° DINOv3)ì—ì„œ ê³ ìˆ˜ì¤€ì˜ ì˜ë¯¸ì  íŠ¹ì§•ì„ ì¶”ì¶œí•˜ì—¬ ëª¨ë‹¬ë¦¬í‹° ê°„ ë§¤ì¹­ì„ ì§€ì›í•˜ëŠ” ê²½ëŸ‰ í•™ìƒ ëª¨ë¸ì„ êµ¬ì¶•í•˜ê¸° ìœ„í•´ ì§€ì‹ ì¦ë¥˜ë¥¼ í™œìš©í•©ë‹ˆë‹¤. ëª¨ë‹¬ë¦¬í‹° íŠ¹ìœ ì˜ ì •ë³´ë¥¼ ìœ ì§€í•˜ê¸° ìœ„í•´, ë‹¤ë¥¸ ëª¨ë‹¬ë¦¬í‹°ì˜ íŠ¹ì§•ì— ëª¨ë‹¬ë¦¬í‹° ë²”ì£¼ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ ì£¼ì…í•¨ìœ¼ë¡œì¨ ëª¨ë¸ì˜ êµì°¨ ëª¨ë‹¬ ìƒê´€ ê´€ê³„ ì´í•´ë¥¼ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ë”ìš±ì´, ìš°ë¦¬ëŠ” ë°ì´í„° ì¦ê°•ì„ ìœ„í•´ ê°€ì‹œ ì´ë¯¸ì§€ë¥¼ ê°€ìƒ ì ì™¸ì„  ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ì—¬ ëª¨ë¸ì˜ ì¼ë°˜í™”ë¥¼ í–¥ìƒì‹œí‚¤ëŠ” V2I-GANì„ ì„¤ê³„í–ˆìŠµë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, DistillMatchëŠ” ê³µê³µ ë°ì´í„°ì…‹ì—ì„œ ê¸°ì¡´ ì•Œê³ ë¦¬ì¦˜ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ë‹¤ì¤‘ ëª¨ë‹¬ ì´ë¯¸ì§€ ë§¤ì¹­ì€ ì„œë¡œ ë‹¤ë¥¸ ëª¨ë‹¬ë¦¬í‹°ì˜ ì´ë¯¸ì§€ ê°„ í”½ì…€ ìˆ˜ì¤€ì˜ ëŒ€ì‘ì„ ì°¾ëŠ” ì‘ì—…ìœ¼ë¡œ, ëª¨ë‹¬ë¦¬í‹° ê°„ ì¸ì‹, ìœµí•© ë° ë¶„ì„ì— ì¤‘ìš”í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ëª¨ë‹¬ë¦¬í‹° ê°„ì˜ í° ì™¸ê´€ ì°¨ì´ë¡œ ì¸í•´ ì´ ì‘ì—…ì€ ì–´ë ¤ì›€ì„ ê²ªê³  ìˆìŠµë‹ˆë‹¤. ê¸°ì¡´ì˜ ë”¥ëŸ¬ë‹ ë°©ë²•ì€ ëª¨ë‹¬ë¦¬í‹° ê³µí†µ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ëŠ” ë° í•œê³„ê°€ ìˆìœ¼ë©°, ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì— ì ì‘í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤. ì´ì— ìš°ë¦¬ëŠ” ëŒ€ê·œëª¨ ë°ì´í„°ë¡œ í•™ìŠµëœ ë¹„ì „ íŒŒìš´ë°ì´ì…˜ ëª¨ë¸(VFM)ì„ í™œìš©í•œ DistillMatchë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. DistillMatchëŠ” VFMìœ¼ë¡œë¶€í„° ì§€ì‹ ì¦ë¥˜ë¥¼ í†µí•´ ê²½ëŸ‰í™”ëœ í•™ìƒ ëª¨ë¸ì„ êµ¬ì¶•í•˜ì—¬ ëª¨ë‹¬ë¦¬í‹° ê°„ ë§¤ì¹­ì„ ë•ìŠµë‹ˆë‹¤. ë˜í•œ, ëª¨ë‹¬ë¦¬í‹° ê³ ìœ  ì •ë³´ë¥¼ ìœ ì§€í•˜ê¸° ìœ„í•´ ëª¨ë‹¬ë¦¬í‹° ë²”ì£¼ ì •ë³´ë¥¼ ë‹¤ë¥¸ ëª¨ë‹¬ë¦¬í‹°ì˜ íŠ¹ì§•ì— ì£¼ì…í•˜ì—¬ ìƒí˜¸ ëª¨ë‹¬ ìƒê´€ì„±ì„ ê°•í™”í•©ë‹ˆë‹¤. V2I-GANì„ ì„¤ê³„í•˜ì—¬ ê°€ì‹œ ì´ë¯¸ì§€ë¥¼ ê°€ìƒ ì ì™¸ì„  ì´ë¯¸ì§€ë¡œ ë³€í™˜í•´ ë°ì´í„° ì¦ê°•ì„ í†µí•´ ëª¨ë¸ì˜ ì¼ë°˜í™”ë¥¼ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, DistillMatchëŠ” ê¸°ì¡´ ì•Œê³ ë¦¬ì¦˜ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë©€í‹°ëª¨ë‹¬ ì´ë¯¸ì§€ ë§¤ì¹­ì€ ì„œë¡œ ë‹¤ë¥¸ ëª¨ë‹¬ë¦¬í‹°ì˜ ì´ë¯¸ì§€ ê°„ í”½ì…€ ìˆ˜ì¤€ì˜ ëŒ€ì‘ì„ ì°¾ëŠ” ì‘ì—…ìœ¼ë¡œ, ëª¨ë‹¬ë¦¬í‹° ê°„ ì¸ì‹, ìœµí•© ë° ë¶„ì„ì— ì¤‘ìš”í•˜ë‹¤.
- 2. ê¸°ì¡´ì˜ ë”¥ëŸ¬ë‹ ë°©ë²•ì€ ê³ í’ˆì§ˆì˜ ì£¼ì„ ë°ì´í„°ì…‹ ë¶€ì¡±ìœ¼ë¡œ ì¸í•´ ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì— ì ì‘í•˜ì§€ ëª»í•˜ê³  ì„±ëŠ¥ì´ ì €ì¡°í•˜ë‹¤.
- 3. Vision Foundation Model(VFM)ì€ ëŒ€ê·œëª¨ ë°ì´í„°ë¡œ í›ˆë ¨ë˜ì–´ ë‹¤ì–‘í•œ ëª¨ë‹¬ë¦¬í‹°ì˜ ë°ì´í„°ì™€ ì‘ì—…ì— ì ì‘ ê°€ëŠ¥í•œ ì¼ë°˜ì ì´ê³  ê°•ë ¥í•œ íŠ¹ì§• í‘œí˜„ì„ ì œê³µí•œë‹¤.
- 4. DistillMatchëŠ” VFMìœ¼ë¡œë¶€í„° ì§€ì‹ ì¦ë¥˜ë¥¼ í™œìš©í•˜ì—¬ ê²½ëŸ‰ì˜ í•™ìƒ ëª¨ë¸ì„ êµ¬ì¶•í•˜ê³ , ëª¨ë‹¬ë¦¬í‹° ê°„ ë§¤ì¹­ì„ ë•ê¸° ìœ„í•´ ê³ ìˆ˜ì¤€ì˜ ì˜ë¯¸ì  íŠ¹ì§•ì„ ì¶”ì¶œí•œë‹¤.
- 5. V2I-GANì„ ì„¤ê³„í•˜ì—¬ ê°€ì‹œ ì´ë¯¸ì§€ë¥¼ ê°€ìƒ ì ì™¸ì„  ì´ë¯¸ì§€ë¡œ ë³€í™˜í•¨ìœ¼ë¡œì¨ ë°ì´í„° ì¦ê°•ì„ í†µí•´ ëª¨ë¸ì˜ ì¼ë°˜í™”ë¥¼ í–¥ìƒì‹œí‚¨ë‹¤.


---

*Generated on 2025-09-23 12:17:36*