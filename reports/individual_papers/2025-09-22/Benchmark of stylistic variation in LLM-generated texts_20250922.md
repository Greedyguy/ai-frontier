---
keywords:
  - Large Language Model
  - Multidimensional Analysis
  - AI-Brown Corpus
  - Instruction-tuned Model
category: cs.AI
publish_date: 2025-09-22
arxiv_id: 2509.10179
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-23T10:13:18.101798",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Multidimensional Analysis",
    "AI-Brown Corpus",
    "Instruction-tuned Model"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Multidimensional Analysis": 0.7,
    "AI-Brown Corpus": 0.65,
    "Instruction-tuned Model": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "This term is central to the study and connects with a wide range of research in natural language processing.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Multidimensional Analysis",
        "canonical": "Multidimensional Analysis",
        "aliases": [
          "MDA"
        ],
        "category": "unique_technical",
        "rationale": "This method is pivotal in analyzing stylistic variations, providing a unique technical approach.",
        "novelty_score": 0.65,
        "connectivity_score": 0.5,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      },
      {
        "surface": "AI-Brown Corpus",
        "canonical": "AI-Brown Corpus",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This corpus is specifically created for the study, offering a unique dataset for comparison.",
        "novelty_score": 0.8,
        "connectivity_score": 0.4,
        "specificity_score": 0.85,
        "link_intent_score": 0.65
      },
      {
        "surface": "Instruction-tuned Models",
        "canonical": "Instruction-tuned Model",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "These models represent a significant variation in LLMs, crucial for understanding performance differences.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.78,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "register variation",
      "dimensions of variation"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Multidimensional Analysis",
      "resolved_canonical": "Multidimensional Analysis",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.5,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "AI-Brown Corpus",
      "resolved_canonical": "AI-Brown Corpus",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.4,
        "specificity": 0.85,
        "link_intent": 0.65
      }
    },
    {
      "candidate_surface": "Instruction-tuned Models",
      "resolved_canonical": "Instruction-tuned Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.78,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# Benchmark of stylistic variation in LLM-generated texts

**Korean Title:** 스타일 변이의 벤치마크: 대형 언어 모델 생성 텍스트

## 📋 메타데이터

**Links**: [[daily_digest_20250922|20250922]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.10179.pdf)
**Category**: cs.AI
**Published**: 2025-09-22
**ArXiv ID**: [2509.10179](https://arxiv.org/abs/2509.10179)

## 🔗 유사한 논문
- [[2025-09-22/A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages_20250922|A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages]] (87.7% similar)
- [[2025-09-19/Adding LLMs to the psycholinguistic norming toolbox_ A practical guide to getting the most out of human ratings_20250919|Adding LLMs to the psycholinguistic norming toolbox: A practical guide to getting the most out of human ratings]] (87.1% similar)
- [[2025-09-22/How do Language Models Generate Slang_ A Systematic Comparison between Human and Machine-Generated Slang Usages_20250922|How do Language Models Generate Slang: A Systematic Comparison between Human and Machine-Generated Slang Usages]] (85.2% similar)
- [[2025-09-18/Catch Me If You Can? Not Yet_ LLMs Still Struggle to Imitate the Implicit Writing Styles of Everyday Authors_20250918|Catch Me If You Can? Not Yet: LLMs Still Struggle to Imitate the Implicit Writing Styles of Everyday Authors]] (84.5% similar)
- [[2025-09-19/CLEAR_ A Comprehensive Linguistic Evaluation of Argument Rewriting by Large Language Models_20250919|CLEAR: A Comprehensive Linguistic Evaluation of Argument Rewriting by Large Language Models]] (84.1% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Instruction-tuned Model|Instruction-tuned Model]]
**⚡ Unique Technical**: [[keywords/Multidimensional Analysis|Multidimensional Analysis]], [[keywords/AI-Brown Corpus|AI-Brown Corpus]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.10179v2 Announce Type: replace-cross 
Abstract: This study investigates the register variation in texts written by humans and comparable texts produced by large language models (LLMs). Biber's multidimensional analysis (MDA) is applied to a sample of human-written texts and AI-created texts generated to be their counterparts to find the dimensions of variation in which LLMs differ most significantly and most systematically from humans. As textual material, a new LLM-generated corpus AI-Brown is used, which is comparable to BE-21 (a Brown family corpus representing contemporary British English). Since all languages except English are underrepresented in the training data of frontier LLMs, similar analysis is replicated on Czech using AI-Koditex corpus and Czech multidimensional model. Examined were 16 frontier models in various settings and prompts, with emphasis placed on the difference between base models and instruction-tuned models. Based on this, a benchmark is created through which models can be compared with each other and ranked in interpretable dimensions.

## 🔍 Abstract (한글 번역)

arXiv:2509.10179v2 발표 유형: 교차 대체  
초록: 본 연구는 인간이 작성한 텍스트와 대형 언어 모델(LLMs)이 생성한 유사한 텍스트에서의 레지스터 변화를 조사합니다. Biber의 다차원 분석(MDA)은 인간이 작성한 텍스트와 그에 상응하도록 생성된 AI 생성 텍스트 샘플에 적용되어 LLM이 인간과 가장 크게 그리고 체계적으로 다른 변이 차원을 찾습니다. 텍스트 자료로는 현대 영국 영어를 대표하는 브라운 계열 코퍼스인 BE-21과 비교 가능한 새로운 LLM 생성 코퍼스 AI-Brown이 사용됩니다. 모든 언어가 영어를 제외하고는 최첨단 LLM의 훈련 데이터에서 과소 대표되기 때문에, 유사한 분석이 AI-Koditex 코퍼스와 체코 다차원 모델을 사용하여 체코어에 대해 반복됩니다. 다양한 설정과 프롬프트에서 16개의 최첨단 모델이 조사되었으며, 기본 모델과 지시 조정 모델 간의 차이에 중점을 두었습니다. 이를 바탕으로 모델을 서로 비교하고 해석 가능한 차원에서 순위를 매길 수 있는 벤치마크가 생성됩니다.

## 📝 요약

이 연구는 인간이 작성한 텍스트와 대형 언어 모델(LLM)이 생성한 유사 텍스트의 레지스터 변이를 조사합니다. Biber의 다차원 분석(MDA)을 활용하여 인간 작성 텍스트와 AI 생성 텍스트의 변이 차원을 비교했습니다. 연구에서는 AI-Brown이라는 새로운 LLM 생성 코퍼스를 사용하여 현대 영국 영어를 대표하는 BE-21과 비교했습니다. 또한, 영어 외의 언어가 LLM의 훈련 데이터에서 부족하다는 점을 고려하여 체코어에 대해서도 유사한 분석을 수행했습니다. 16개의 최첨단 모델을 다양한 설정과 프롬프트로 검토했으며, 기본 모델과 지시 조정 모델 간의 차이에 중점을 두었습니다. 이를 통해 모델을 비교하고 해석 가능한 차원에서 순위를 매길 수 있는 벤치마크를 생성했습니다.

## 🎯 주요 포인트

- 1. 본 연구는 인간이 작성한 텍스트와 대형 언어 모델(LLM)이 생성한 텍스트 간의 레지스터 변이를 조사합니다.
- 2. Biber의 다차원 분석(MDA)을 통해 LLM이 인간과 가장 크게 그리고 체계적으로 다른 변이 차원을 찾습니다.
- 3. AI-Brown이라는 새로운 LLM 생성 코퍼스를 사용하여 BE-21과 비교 분석을 수행합니다.
- 4. 영어 외의 언어는 LLM의 훈련 데이터에서 과소 대표되므로, 체코어에 대해서도 유사한 분석을 수행합니다.
- 5. 다양한 설정과 프롬프트에서 16개의 최첨단 모델을 검토하고, 이를 통해 모델 간 비교 및 해석 가능한 차원에서의 순위를 매기는 벤치마크를 생성합니다.


---

*Generated on 2025-09-23 10:13:18*