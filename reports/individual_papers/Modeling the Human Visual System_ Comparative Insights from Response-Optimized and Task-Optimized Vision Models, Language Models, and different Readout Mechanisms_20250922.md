# Modeling the Human Visual System: Comparative Insights from Response-Optimized and Task-Optimized Vision Models, Language Models, and different Readout Mechanisms

**Korean Title:** ì¸ê°„ ì‹œê° ì‹œìŠ¤í…œ ëª¨ë¸ë§: ë°˜ì‘ ìµœì í™” ë° ì‘ì—… ìµœì í™” ì‹œê° ëª¨ë¸, ì–¸ì–´ ëª¨ë¸, ë‹¤ì–‘í•œ íŒë… ë©”ì»¤ë‹ˆì¦˜ìœ¼ë¡œë¶€í„°ì˜ ë¹„êµì  í†µì°°

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[reports/digests/daily_digest_20250922|2025-09-22]] [[keywords/evolved/Cross-Modal Alignment|Cross-Modal Alignment]] [[keywords/specific/Neural Response Prediction|Neural Response Prediction]] [[keywords/broad/Computer Vision|Computer Vision]] [[keywords/broad/Large Language Models|Large Language Models]] [[keywords/unique/Response-Optimized Models|Response-Optimized Models]] [[categories/cs.LG|cs.LG]] [[2025-09-22/Emulating Human-like Adaptive Vision for Efficient and Flexible Machine Visual Perception_20250922|Emulating Human-like Adaptive Vision for Efficient and Flexible Machine Visual Perception]] (85.3% similar) [[2025-09-19/Large Multi-modal Models Can Interpret Features in Large Multi-modal Models_20250919|Large Multi-modal Models Can Interpret Features in Large Multi-modal Models]] (84.0% similar) [[2025-09-22/Large Vision Models Can Solve Mental Rotation Problems_20250922|Large Vision Models Can Solve Mental Rotation Problems]] (82.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Cross-Modal Alignment
**ğŸ”— Specific Connectable**: Neural Response Prediction
**ğŸ”¬ Broad Technical**: Computer Vision, Large Language Models
**â­ Unique Technical**: Response-Optimized Models
## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Emulating Human-like Adaptive Vision for Efficient and Flexible Machine Visual Perception_20250922|Emulating Human-like Adaptive Vision for Efficient and Flexible Machine Visual Perception]] (85.3% similar)
- [[2025-09-19/Large Multi-modal Models Can Interpret Features in Large Multi-modal Models_20250919|Large Multi-modal Models Can Interpret Features in Large Multi-modal Models]] (84.0% similar)
- [[2025-09-22/Large Vision Models Can Solve Mental Rotation Problems_20250922|Large Vision Models Can Solve Mental Rotation Problems]] (82.8% similar)
- [[2025-09-19/Leveraging Geometric Visual Illusions as Perceptual Inductive Biases for Vision Models_20250919|Leveraging Geometric Visual Illusions as Perceptual Inductive Biases for Vision Models]] (81.7% similar)
- [[2025-09-22/Perception-R1_ Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward_20250922|Perception-R1 Advancing Multimodal Reasoning Capabilities of MLLMs via Visual Perception Reward]] (81.6% similar)


**ArXiv ID**: [2410.14031](https://arxiv.org/abs/2410.14031)
**Published**: 2025-09-22
**Category**: cs.LG
**PDF**: [Download](https://arxiv.org/pdf/2410.14031.pdf)


**ArXiv ID**: [2410.14031](https://arxiv.org/abs/2410.14031)
**Published**: 2025-09-22
**Category**: cs.LG
**PDF**: [Download](https://arxiv.org/pdf/2410.14031.pdf)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Cross-modal Alignment
**ğŸ”— Specific Connectable**: Neural Response Prediction
**â­ Unique Technical**: Response-Optimized Models
**ğŸ”¬ Broad Technical**: Computer Vision, Large Language Models

## ğŸ·ï¸ ì¶”ì¶œëœ í‚¤ì›Œë“œ



`Computer Vision` â€¢ 

`Large Language Models` â€¢ 

`Neural Response Prediction` â€¢ 

`Response-Optimized Models` â€¢ 

`Cross-Modal Alignment`



## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸

Similar papers will be displayed here based on embedding similarity.

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2410.14031v5 Announce Type: replace-cross 
Abstract: Over the past decade, predictive modeling of neural responses in the primate visual system has advanced significantly, largely driven by various DNN approaches. These include models optimized directly for visual recognition, cross-modal alignment through contrastive objectives, neural response prediction from scratch, and large language model embeddings.Likewise, different readout mechanisms, ranging from fully linear to spatial-feature factorized methods have been explored for mapping network activations to neural responses. Despite the diversity of these approaches, it remains unclear which method performs best across different visual regions. In this study, we systematically compare these approaches for modeling the human visual system and investigate alternative strategies to improve response predictions. Our findings reveal that for early to mid-level visual areas, response-optimized models with visual inputs offer superior prediction accuracy, while for higher visual regions, embeddings from LLMs based on detailed contextual descriptions of images and task-optimized models pretrained on large vision datasets provide the best fit. Through comparative analysis of these modeling approaches, we identified three distinct regions in the visual cortex: one sensitive primarily to perceptual features of the input that are not captured by linguistic descriptions, another attuned to fine-grained visual details representing semantic information, and a third responsive to abstract, global meanings aligned with linguistic content. We also highlight the critical role of readout mechanisms, proposing a novel scheme that modulates receptive fields and feature maps based on semantic content, resulting in an accuracy boost of 3-23% over existing SOTAs for all models and brain regions. Together, these findings offer key insights into building more precise models of the visual system.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2410.14031v5 ë°œí‘œ ìœ í˜•: êµì°¨ êµì²´  
ì´ˆë¡: ì§€ë‚œ 10ë…„ ë™ì•ˆ ì˜ì¥ë¥˜ ì‹œê° ì‹œìŠ¤í…œì˜ ì‹ ê²½ ë°˜ì‘ ì˜ˆì¸¡ ëª¨ë¸ë§ì€ ë‹¤ì–‘í•œ ì‹¬ì¸µ ì‹ ê²½ë§(DNN) ì ‘ê·¼ ë°©ì‹ì— ì˜í•´ í¬ê²Œ ë°œì „í–ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì ‘ê·¼ ë°©ì‹ì—ëŠ” ì‹œê° ì¸ì‹ì„ ìœ„í•´ ì§ì ‘ ìµœì í™”ëœ ëª¨ë¸, ëŒ€ì¡°ì  ëª©í‘œë¥¼ í†µí•œ êµì°¨ ëª¨ë‹¬ ì •ë ¬, ì²˜ìŒë¶€í„° ì‹ ê²½ ë°˜ì‘ ì˜ˆì¸¡, ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ ì„ë² ë”© ë“±ì´ í¬í•¨ë©ë‹ˆë‹¤. ë˜í•œ, ë„¤íŠ¸ì›Œí¬ í™œì„±í™”ë¥¼ ì‹ ê²½ ë°˜ì‘ì— ë§¤í•‘í•˜ê¸° ìœ„í•´ ì™„ì „íˆ ì„ í˜•ì ì¸ ë°©ë²•ë¶€í„° ê³µê°„-íŠ¹ì§• ë¶„í•´ ë°©ë²•ê¹Œì§€ ë‹¤ì–‘í•œ ì½ê¸° ë©”ì»¤ë‹ˆì¦˜ì´ íƒêµ¬ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì ‘ê·¼ ë°©ì‹ì˜ ë‹¤ì–‘ì„±ì—ë„ ë¶ˆêµ¬í•˜ê³ , ì„œë¡œ ë‹¤ë¥¸ ì‹œê° ì˜ì—­ì—ì„œ ì–´ë–¤ ë°©ë²•ì´ ê°€ì¥ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ëŠ”ì§€ëŠ” ì—¬ì „íˆ ë¶ˆë¶„ëª…í•©ë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” ì¸ê°„ ì‹œê° ì‹œìŠ¤í…œì„ ëª¨ë¸ë§í•˜ê¸° ìœ„í•œ ì´ëŸ¬í•œ ì ‘ê·¼ ë°©ì‹ì„ ì²´ê³„ì ìœ¼ë¡œ ë¹„êµí•˜ê³ , ë°˜ì‘ ì˜ˆì¸¡ì„ ê°œì„ í•˜ê¸° ìœ„í•œ ëŒ€ì•ˆ ì „ëµì„ ì¡°ì‚¬í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì—°êµ¬ ê²°ê³¼ì— ë”°ë¥´ë©´, ì´ˆê¸°ì—ì„œ ì¤‘ê°„ ìˆ˜ì¤€ì˜ ì‹œê° ì˜ì—­ì—ì„œëŠ” ì‹œê° ì…ë ¥ì„ ì‚¬ìš©í•œ ë°˜ì‘ ìµœì í™” ëª¨ë¸ì´ ìš°ìˆ˜í•œ ì˜ˆì¸¡ ì •í™•ì„±ì„ ì œê³µí•˜ë©°, ê³ ì°¨ ì‹œê° ì˜ì—­ì—ì„œëŠ” ì´ë¯¸ì§€ì˜ ì„¸ë¶€ì ì¸ ë§¥ë½ ì„¤ëª…ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM) ì„ë² ë”©ê³¼ ëŒ€ê·œëª¨ ì‹œê° ë°ì´í„°ì…‹ì— ì‚¬ì „ í•™ìŠµëœ ì‘ì—… ìµœì í™” ëª¨ë¸ì´ ê°€ì¥ ì í•©í•œ ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ëª¨ë¸ë§ ì ‘ê·¼ ë°©ì‹ì„ ë¹„êµ ë¶„ì„í•œ ê²°ê³¼, ì‹œê° í”¼ì§ˆì—ì„œ ì„¸ ê°€ì§€ êµ¬ë³„ë˜ëŠ” ì˜ì—­ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤: ì–¸ì–´ì  ì„¤ëª…ìœ¼ë¡œ í¬ì°©ë˜ì§€ ì•ŠëŠ” ì…ë ¥ì˜ ì§€ê°ì  íŠ¹ì§•ì— ì£¼ë¡œ ë¯¼ê°í•œ ì˜ì—­, ì˜ë¯¸ ì •ë³´ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì„¸ë°€í•œ ì‹œê°ì  ì„¸ë¶€ì‚¬í•­ì— ë§ì¶°ì§„ ì˜ì—­, ì–¸ì–´ì  ë‚´ìš©ê³¼ ì¼ì¹˜í•˜ëŠ” ì¶”ìƒì ì´ê³  ì „ë°˜ì ì¸ ì˜ë¯¸ì— ë°˜ì‘í•˜ëŠ” ì˜ì—­ì…ë‹ˆë‹¤. ë˜í•œ, ì½ê¸° ë©”ì»¤ë‹ˆì¦˜ì˜ ì¤‘ìš”í•œ ì—­í• ì„ ê°•ì¡°í•˜ë©°, ì˜ë¯¸ì  ì½˜í…ì¸ ì— ê¸°ë°˜í•˜ì—¬ ìˆ˜ìš© ì˜ì—­ê³¼ íŠ¹ì§• ë§µì„ ì¡°ì ˆí•˜ëŠ” ìƒˆë¡œìš´ ë°©ì‹ì„ ì œì•ˆí•˜ì—¬ ëª¨ë“  ëª¨ë¸ê³¼ ë‡Œ ì˜ì—­ì—ì„œ ê¸°ì¡´ ìµœì²¨ë‹¨(SOTA) ëŒ€ë¹„ 3-23%ì˜ ì •í™•ë„ í–¥ìƒì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì—°êµ¬ ê²°ê³¼ëŠ” ì‹œê° ì‹œìŠ¤í…œì˜ ë³´ë‹¤ ì •í™•í•œ ëª¨ë¸ì„ êµ¬ì¶•í•˜ëŠ” ë° ì¤‘ìš”í•œ í†µì°°ë ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì§€ë‚œ 10ë…„ê°„ ì˜ì¥ë¥˜ ì‹œê° ì‹œìŠ¤í…œì˜ ì‹ ê²½ ë°˜ì‘ ì˜ˆì¸¡ ëª¨ë¸ë§ì€ ë‹¤ì–‘í•œ ì‹¬ì¸µ ì‹ ê²½ë§(DNN) ì ‘ê·¼ë²•ì— ì˜í•´ í¬ê²Œ ë°œì „í–ˆìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” ì´ëŸ¬í•œ ì ‘ê·¼ë²•ì„ ì²´ê³„ì ìœ¼ë¡œ ë¹„êµí•˜ì—¬ ì¸ê°„ ì‹œê° ì‹œìŠ¤í…œì˜ ëª¨ë¸ë§ì„ ìˆ˜í–‰í•˜ê³ , ë°˜ì‘ ì˜ˆì¸¡ì„ ê°œì„ í•  ëŒ€ì•ˆì„ íƒêµ¬í–ˆìŠµë‹ˆë‹¤. ì—°êµ¬ ê²°ê³¼, ì´ˆê¸° ë° ì¤‘ê°„ ìˆ˜ì¤€ì˜ ì‹œê° ì˜ì—­ì—ì„œëŠ” ì‹œê° ì…ë ¥ì— ìµœì í™”ëœ ëª¨ë¸ì´ ìš°ìˆ˜í•œ ì˜ˆì¸¡ ì •í™•ë„ë¥¼ ë³´ì˜€ìœ¼ë©°, ë†’ì€ ì‹œê° ì˜ì—­ì—ì„œëŠ” ì´ë¯¸ì§€ì˜ ë§¥ë½ì  ì„¤ëª…ì— ê¸°ë°˜í•œ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM) ì„ë² ë”©ê³¼ ëŒ€ê·œëª¨ ë¹„ì „ ë°ì´í„°ì…‹ì— ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì´ ê°€ì¥ ì í•©í•¨ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, ì‹œê° í”¼ì§ˆì˜ ì„¸ ê°€ì§€ êµ¬ì—­ì„ ì‹ë³„í–ˆìœ¼ë©°, ê° êµ¬ì—­ì€ ì–¸ì–´ì  ì„¤ëª…ìœ¼ë¡œ í¬ì°©ë˜ì§€ ì•ŠëŠ” ì§€ê°ì  íŠ¹ì§•, ì„¸ë°€í•œ ì‹œê°ì  ì„¸ë¶€ ì‚¬í•­, ì¶”ìƒì  ì˜ë¯¸ì— ë°˜ì‘í–ˆìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ì½ê¸° ë©”ì»¤ë‹ˆì¦˜ì„ ì œì•ˆí•˜ì—¬ ëª¨ë“  ëª¨ë¸ê³¼ ë‡Œ ì˜ì—­ì—ì„œ ê¸°ì¡´ ìµœê³  ì„±ëŠ¥ ëŒ€ë¹„ 3-23%ì˜ ì •í™•ë„ í–¥ìƒì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë°œê²¬ì€ ì‹œê° ì‹œìŠ¤í…œì˜ ë³´ë‹¤ ì •ë°€í•œ ëª¨ë¸ êµ¬ì¶•ì— ì¤‘ìš”í•œ í†µì°°ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸


- 1. ë‹¤ì–‘í•œ DNN ì ‘ê·¼ ë°©ì‹ì´ ì›ìˆ­ì´ ì‹œê° ì‹œìŠ¤í…œì˜ ì‹ ê²½ ë°˜ì‘ ì˜ˆì¸¡ ëª¨ë¸ë§ì„ í¬ê²Œ ë°œì „ì‹œì¼°ìŠµë‹ˆë‹¤.

- 2. ì´ˆê¸°ì—ì„œ ì¤‘ê°„ ìˆ˜ì¤€ì˜ ì‹œê° ì˜ì—­ì—ì„œëŠ” ì‹œê° ì…ë ¥ì— ìµœì í™”ëœ ëª¨ë¸ì´ ë›°ì–´ë‚œ ì˜ˆì¸¡ ì •í™•ì„±ì„ ì œê³µí•©ë‹ˆë‹¤.

- 3. ìƒìœ„ ì‹œê° ì˜ì—­ì—ì„œëŠ” ì´ë¯¸ì§€ì˜ ë§¥ë½ì  ì„¤ëª…ê³¼ ëŒ€ê·œëª¨ ë¹„ì „ ë°ì´í„°ì…‹ì— ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì´ ìµœì ì˜ ì í•©ì„±ì„ ë³´ì…ë‹ˆë‹¤.

- 4. ì‹œê° í”¼ì§ˆì˜ ì„¸ ê°€ì§€ êµ¬ë³„ëœ ì˜ì—­ì„ ì‹ë³„í–ˆìœ¼ë©°, ì´ëŠ” ê°ê° ì–¸ì–´ì  ì„¤ëª…ìœ¼ë¡œ í¬ì°©ë˜ì§€ ì•ŠëŠ” ì§€ê°ì  íŠ¹ì§•, ì˜ë¯¸ ì •ë³´ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì„¸ë°€í•œ ì‹œê°ì  ì„¸ë¶€ì‚¬í•­, ì–¸ì–´ì  ë‚´ìš©ê³¼ ì¼ì¹˜í•˜ëŠ” ì¶”ìƒì  ì˜ë¯¸ì— ë¯¼ê°í•©ë‹ˆë‹¤.

- 5. ìƒˆë¡œìš´ ë¦¬ë“œì•„ì›ƒ ë©”ì»¤ë‹ˆì¦˜ì„ ì œì•ˆí•˜ì—¬ ëª¨ë“  ëª¨ë¸ê³¼ ë‡Œ ì˜ì—­ì—ì„œ ê¸°ì¡´ SOTA ëŒ€ë¹„ 3-23%ì˜ ì •í™•ë„ í–¥ìƒì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-22 16:08:05*