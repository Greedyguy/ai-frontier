# Adversarial generalization of unfolding (model-based) networks

**Korean Title:** ì „ê°œ(ëª¨ë¸ ê¸°ë°˜) ë„¤íŠ¸ì›Œí¬ì˜ ì ëŒ€ì  ì¼ë°˜í™”

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Adversarial Generalization

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/Probabilistic and nonlinear compressive sensing_20250918|Probabilistic and nonlinear compressive sensing]] (82.6% similar)
- [[2025-09-17/A Neural Network for the Identical Kuramoto Equation_ Architectural Considerations and Performance Evaluation_20250917|A Neural Network for the Identical Kuramoto Equation Architectural Considerations and Performance Evaluation]] (80.6% similar)
- [[2025-09-19/A Multi-Agent LLM Defense Pipeline Against Prompt Injection Attacks_20250919|A Multi-Agent LLM Defense Pipeline Against Prompt Injection Attacks]] (79.9% similar)
- [[2025-09-19/Adversarial Distilled Retrieval-Augmented Guarding Model for Online Malicious Intent Detection_20250919|Adversarial Distilled Retrieval-Augmented Guarding Model for Online Malicious Intent Detection]] (79.2% similar)
- [[2025-09-19/Mini-Batch Robustness Verification of Deep Neural Networks_20250919|Mini-Batch Robustness Verification of Deep Neural Networks]] (79.1% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15370v1 Announce Type: new 
Abstract: Unfolding networks are interpretable networks emerging from iterative algorithms, incorporate prior knowledge of data structure, and are designed to solve inverse problems like compressed sensing, which deals with recovering data from noisy, missing observations. Compressed sensing finds applications in critical domains, from medical imaging to cryptography, where adversarial robustness is crucial to prevent catastrophic failures. However, a solid theoretical understanding of the performance of unfolding networks in the presence of adversarial attacks is still in its infancy. In this paper, we study the adversarial generalization of unfolding networks when perturbed with $l_2$-norm constrained attacks, generated by the fast gradient sign method. Particularly, we choose a family of state-of-the-art overaparameterized unfolding networks and deploy a new framework to estimate their adversarial Rademacher complexity. Given this estimate, we provide adversarial generalization error bounds for the networks under study, which are tight with respect to the attack level. To our knowledge, this is the first theoretical analysis on the adversarial generalization of unfolding networks. We further present a series of experiments on real-world data, with results corroborating our derived theory, consistently for all data. Finally, we observe that the family's overparameterization can be exploited to promote adversarial robustness, shedding light on how to efficiently robustify neural networks.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15370v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: ì „ê°œ ë„¤íŠ¸ì›Œí¬ëŠ” ë°˜ë³µ ì•Œê³ ë¦¬ì¦˜ì—ì„œ íŒŒìƒëœ í•´ì„ ê°€ëŠ¥í•œ ë„¤íŠ¸ì›Œí¬ë¡œ, ë°ì´í„° êµ¬ì¡°ì— ëŒ€í•œ ì‚¬ì „ ì§€ì‹ì„ í†µí•©í•˜ì—¬ ì••ì¶• ì„¼ì‹±ê³¼ ê°™ì€ ì—­ë¬¸ì œë¥¼ í•´ê²°í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ì••ì¶• ì„¼ì‹±ì€ ì˜ë£Œ ì˜ìƒë¶€í„° ì•”í˜¸í•™ê¹Œì§€ ì¤‘ìš”í•œ ë¶„ì•¼ì—ì„œ ì‘ìš©ë˜ë©°, ì´ë“¤ ë¶„ì•¼ì—ì„œëŠ” ì¹˜ëª…ì ì¸ ì‹¤íŒ¨ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ì ëŒ€ì  ê²¬ê³ ì„±ì´ í•„ìˆ˜ì ì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì ëŒ€ì  ê³µê²©ì´ ìˆëŠ” ìƒí™©ì—ì„œ ì „ê°œ ë„¤íŠ¸ì›Œí¬ì˜ ì„±ëŠ¥ì— ëŒ€í•œ í™•ê³ í•œ ì´ë¡ ì  ì´í•´ëŠ” ì•„ì§ ì´ˆê¸° ë‹¨ê³„ì— ìˆìŠµë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ë¹ ë¥¸ ê¸°ìš¸ê¸° ë¶€í˜¸ ë°©ë²•ì— ì˜í•´ ìƒì„±ëœ $l_2$-ë…¸ë¦„ ì œì•½ ê³µê²©ìœ¼ë¡œ êµë€ëœ ì „ê°œ ë„¤íŠ¸ì›Œí¬ì˜ ì ëŒ€ì  ì¼ë°˜í™”ë¥¼ ì—°êµ¬í•©ë‹ˆë‹¤. íŠ¹íˆ, ìµœì²¨ë‹¨ ê³¼ë§¤ê°œë³€ìˆ˜í™”ëœ ì „ê°œ ë„¤íŠ¸ì›Œí¬ì˜ ê³„ì—´ì„ ì„ íƒí•˜ê³ , ì´ë“¤ì˜ ì ëŒ€ì  ë¼ë°ë§ˆí—ˆ ë³µì¡ì„±ì„ ì¶”ì •í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¥¼ ë°°í¬í•©ë‹ˆë‹¤. ì´ ì¶”ì •ì¹˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì—°êµ¬ ì¤‘ì¸ ë„¤íŠ¸ì›Œí¬ì— ëŒ€í•œ ê³µê²© ìˆ˜ì¤€ì— ëŒ€í•´ ê¸´ë°€í•œ ì ëŒ€ì  ì¼ë°˜í™” ì˜¤ë¥˜ ê²½ê³„ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ìš°ë¦¬ê°€ ì•„ëŠ” í•œ, ì´ëŠ” ì „ê°œ ë„¤íŠ¸ì›Œí¬ì˜ ì ëŒ€ì  ì¼ë°˜í™”ì— ëŒ€í•œ ìµœì´ˆì˜ ì´ë¡ ì  ë¶„ì„ì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ë˜í•œ ì‹¤ì œ ë°ì´í„°ì— ëŒ€í•œ ì¼ë ¨ì˜ ì‹¤í—˜ì„ ì œì‹œí•˜ë©°, ëª¨ë“  ë°ì´í„°ì— ëŒ€í•´ ì¼ê´€ë˜ê²Œ ìš°ë¦¬ì˜ ì´ë¡ ì„ ë’·ë°›ì¹¨í•˜ëŠ” ê²°ê³¼ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ, ê³„ì—´ì˜ ê³¼ë§¤ê°œë³€ìˆ˜í™”ë¥¼ í™œìš©í•˜ì—¬ ì ëŒ€ì  ê²¬ê³ ì„±ì„ ì´‰ì§„í•  ìˆ˜ ìˆìŒì„ ê´€ì°°í•˜ë©°, ì‹ ê²½ë§ì„ íš¨ìœ¨ì ìœ¼ë¡œ ê²¬ê³ í•˜ê²Œ ë§Œë“œëŠ” ë°©ë²•ì— ëŒ€í•œ í†µì°°ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë°˜ë³µ ì•Œê³ ë¦¬ì¦˜ì—ì„œ íŒŒìƒëœ í•´ì„ ê°€ëŠ¥í•œ ë„¤íŠ¸ì›Œí¬ì¸ ì–¸í´ë”© ë„¤íŠ¸ì›Œí¬ì˜ ì ëŒ€ì  ì¼ë°˜í™”ë¥¼ ì—°êµ¬í•©ë‹ˆë‹¤. íŠ¹íˆ, $l_2$-ë…¸ë¦„ ì œì•½ ê³µê²©ì— ëŒ€í•œ ë„¤íŠ¸ì›Œí¬ì˜ ì„±ëŠ¥ì„ ì´ë¡ ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬, ê³µê²© ìˆ˜ì¤€ì— ë”°ë¥¸ ì¼ë°˜í™” ì˜¤ë¥˜ ê²½ê³„ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì´ëŠ” ì–¸í´ë”© ë„¤íŠ¸ì›Œí¬ì˜ ì ëŒ€ì  ì¼ë°˜í™”ì— ëŒ€í•œ ìµœì´ˆì˜ ì´ë¡ ì  ë¶„ì„ì…ë‹ˆë‹¤. ë˜í•œ, ì‹¤ì œ ë°ì´í„° ì‹¤í—˜ì„ í†µí•´ ì´ë¡ ì  ê²°ê³¼ë¥¼ ê²€ì¦í•˜ì˜€ìœ¼ë©°, ê³¼ë§¤ê°œë³€ìˆ˜í™”ê°€ ì ëŒ€ì  ê²¬ê³ ì„±ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ì˜ë£Œ ì˜ìƒ ë° ì•”í˜¸í•™ ë“± ì¤‘ìš”í•œ ë¶„ì•¼ì—ì„œì˜ ë„¤íŠ¸ì›Œí¬ ê²¬ê³ ì„± í–¥ìƒì— ê¸°ì—¬í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì „ê°œ ë„¤íŠ¸ì›Œí¬ëŠ” ë°˜ë³µ ì•Œê³ ë¦¬ì¦˜ì—ì„œ íŒŒìƒëœ í•´ì„ ê°€ëŠ¥í•œ ë„¤íŠ¸ì›Œí¬ë¡œ, ì—­ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ ì„¤ê³„ë˜ì—ˆìœ¼ë©°, ë°ì´í„° êµ¬ì¡°ì— ëŒ€í•œ ì‚¬ì „ ì§€ì‹ì„ í†µí•©í•©ë‹ˆë‹¤.

- 2. ì••ì¶• ì„¼ì‹±ì€ ì˜ë£Œ ì˜ìƒë¶€í„° ì•”í˜¸í•™ê¹Œì§€ ì¤‘ìš”í•œ ë¶„ì•¼ì—ì„œ ì‘ìš©ë˜ë©°, ì ëŒ€ì  ê³µê²©ì— ëŒ€í•œ ê²¬ê³ ì„±ì´ ì¤‘ìš”í•©ë‹ˆë‹¤.

- 3. ë³¸ ë…¼ë¬¸ì€ $l_2$-ë…¸ë¦„ìœ¼ë¡œ ì œí•œëœ ê³µê²©ì— ëŒ€í•œ ì „ê°œ ë„¤íŠ¸ì›Œí¬ì˜ ì ëŒ€ì  ì¼ë°˜í™”ë¥¼ ì—°êµ¬í•˜ë©°, ë¹ ë¥¸ ê¸°ìš¸ê¸° ë¶€í˜¸ ë°©ë²•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

- 4. ìš°ë¦¬ëŠ” ìµœì²¨ë‹¨ ê³¼ë§¤ê°œë³€ìˆ˜í™”ëœ ì „ê°œ ë„¤íŠ¸ì›Œí¬ì˜ ì ëŒ€ì  Rademacher ë³µì¡ì„±ì„ ì¶”ì •í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.

- 5. ì‹¤í—˜ ê²°ê³¼, ë„¤íŠ¸ì›Œí¬ì˜ ê³¼ë§¤ê°œë³€ìˆ˜í™”ê°€ ì ëŒ€ì  ê²¬ê³ ì„±ì„ ì´‰ì§„í•  ìˆ˜ ìˆìŒì„ ê´€ì°°í•˜ì˜€ìœ¼ë©°, ì´ëŠ” ì‹ ê²½ë§ì„ íš¨ìœ¨ì ìœ¼ë¡œ ê°•í™”í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ í†µì°°ì„ ì œê³µí•©ë‹ˆë‹¤.

---

*Generated on 2025-09-22 15:12:01*