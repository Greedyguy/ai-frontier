# RACap: Relation-Aware Prompting for Lightweight Retrieval-Augmented Image Captioning

**Korean Title:** RACap: 경량 검색 증강 이미지 캡셔닝을 위한 관계 인식 프롬프트 기법

## 📋 메타데이터

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Relation Aware Prompting

## 🔗 유사한 논문
- [[2025-09-19/RAcQUEt_ Unveiling the Dangers of Overlooked Referential Ambiguity in Visual LLMs_20250919|RAcQUEt Unveiling the Dangers of Overlooked Referential Ambiguity in Visual LLMs]] (81.5% similar)
- [[2025-09-19/Enhancing Retrieval Augmentation via Adversarial Collaboration_20250919|Enhancing Retrieval Augmentation via Adversarial Collaboration]] (81.1% similar)
- [[2025-09-19/Causal-Counterfactual RAG_ The Integration of Causal-Counterfactual Reasoning into RAG_20250919|Causal-Counterfactual RAG The Integration of Causal-Counterfactual Reasoning into RAG]] (80.6% similar)
- [[2025-09-19/Reconstruction Alignment Improves Unified Multimodal Models_20250919|Reconstruction Alignment Improves Unified Multimodal Models]] (80.4% similar)
- [[2025-09-19/Chain-of-Thought Re-ranking for Image Retrieval Tasks_20250919|Chain-of-Thought Re-ranking for Image Retrieval Tasks]] (80.2% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.15883v1 Announce Type: cross 
Abstract: Recent retrieval-augmented image captioning methods incorporate external knowledge to compensate for the limitations in comprehending complex scenes. However, current approaches face challenges in relation modeling: (1) the representation of semantic prompts is too coarse-grained to capture fine-grained relationships; (2) these methods lack explicit modeling of image objects and their semantic relationships. To address these limitations, we propose RACap, a relation-aware retrieval-augmented model for image captioning, which not only mines structured relation semantics from retrieval captions, but also identifies heterogeneous objects from the image. RACap effectively retrieves structured relation features that contain heterogeneous visual information to enhance the semantic consistency and relational expressiveness. Experimental results show that RACap, with only 10.8M trainable parameters, achieves superior performance compared to previous lightweight captioning models.

## 🔍 Abstract (한글 번역)

arXiv:2509.15883v1 발표 유형: 교차  
초록: 최근의 검색 보강 이미지 캡셔닝 방법은 복잡한 장면을 이해하는 데 한계가 있는 부분을 보완하기 위해 외부 지식을 통합합니다. 그러나 현재의 접근 방식은 관계 모델링에서 다음과 같은 문제에 직면해 있습니다: (1) 의미 프롬프트의 표현이 너무 거칠어 세밀한 관계를 포착하지 못합니다; (2) 이러한 방법들은 이미지 객체와 그들의 의미적 관계를 명시적으로 모델링하지 않습니다. 이러한 한계를 해결하기 위해, 우리는 이미지 캡셔닝을 위한 관계 인식 검색 보강 모델인 RACap을 제안합니다. 이 모델은 검색 캡션에서 구조화된 관계 의미를 발굴할 뿐만 아니라 이미지에서 이질적인 객체를 식별합니다. RACap은 이질적인 시각 정보를 포함하는 구조화된 관계 특징을 효과적으로 검색하여 의미적 일관성과 관계 표현력을 강화합니다. 실험 결과에 따르면, RACap은 단 10.8M의 학습 가능한 매개변수로 이전의 경량 캡셔닝 모델에 비해 우수한 성능을 달성합니다.

## 📝 요약

최근의 검색 기반 이미지 캡션 생성 방법은 외부 지식을 활용하여 복잡한 장면 이해의 한계를 보완하지만, 관계 모델링에서 어려움을 겪고 있습니다. 이를 해결하기 위해, 우리는 RACap이라는 관계 인식 검색 기반 모델을 제안합니다. 이 모델은 검색된 캡션에서 구조화된 관계 의미를 추출하고, 이미지에서 이질적인 객체를 식별합니다. RACap은 이질적인 시각 정보를 포함한 구조화된 관계 특징을 효과적으로 검색하여 의미적 일관성과 관계 표현력을 향상시킵니다. 실험 결과, RACap은 단 10.8M의 학습 가능한 파라미터로 이전의 경량 캡션 모델보다 우수한 성능을 보였습니다.

## 🎯 주요 포인트

- 1. 최근의 검색 보강 이미지 캡셔닝 방법은 복잡한 장면 이해의 한계를 보완하기 위해 외부 지식을 통합합니다.

- 2. 기존 접근법은 관계 모델링에서 세밀한 관계를 포착하지 못하는 조잡한 의미 프롬프트 표현과 이미지 객체 및 그 의미 관계의 명시적 모델링 부족 문제를 겪고 있습니다.

- 3. RACap은 검색 캡션에서 구조화된 관계 의미를 발굴하고 이미지에서 이질적인 객체를 식별하여 이러한 한계를 해결합니다.

- 4. RACap은 이질적인 시각 정보를 포함하는 구조화된 관계 특징을 효과적으로 검색하여 의미 일관성과 관계 표현력을 향상시킵니다.

- 5. 실험 결과, RACap은 10.8M의 훈련 가능한 파라미터만으로도 이전의 경량 캡셔닝 모델보다 우수한 성능을 달성했습니다.

---

*Generated on 2025-09-22 14:14:59*