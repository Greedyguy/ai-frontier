# OpenWHO: A Document-Level Parallel Corpus for Health Translation in Low-Resource Languages

**Korean Title:** OpenWHO: ì €ìì› ì–¸ì–´ì˜ ê±´ê°• ë²ˆì—­ì„ ìœ„í•œ ë¬¸ì„œ ìˆ˜ì¤€ ë³‘ë ¬ ì½”í¼ìŠ¤

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Low Resource Language Translation

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/OpenLens AI_ Fully Autonomous Research Agent for Health Infomatics_20250919|OpenLens AI Fully Autonomous Research Agent for Health Infomatics]] (80.6% similar)
- [[2025-09-22/EHR-MCP_ Real-world Evaluation of Clinical Information Retrieval by Large Language Models via Model Context Protocol_20250922|EHR-MCP Real-world Evaluation of Clinical Information Retrieval by Large Language Models via Model Context Protocol]] (79.6% similar)
- [[2025-09-19/MedVAL_ Toward Expert-Level Medical Text Validation with Language Models_20250919|MedVAL Toward Expert-Level Medical Text Validation with Language Models]] (79.4% similar)
- [[2025-09-22/Exploring Polyglot Harmony_ On Multilingual Data Allocation for Large Language Models Pretraining_20250922|Exploring Polyglot Harmony On Multilingual Data Allocation for Large Language Models Pretraining]] (78.0% similar)
- [[2025-09-19/Translate, then Detect_ Leveraging Machine Translation for Cross-Lingual Toxicity Classification_20250919|Translate, then Detect Leveraging Machine Translation for Cross-Lingual Toxicity Classification]] (77.7% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2508.16048v3 Announce Type: replace-cross 
Abstract: In machine translation (MT), health is a high-stakes domain characterised by widespread deployment and domain-specific vocabulary. However, there is a lack of MT evaluation datasets for low-resource languages in this domain. To address this gap, we introduce OpenWHO, a document-level parallel corpus of 2,978 documents and 26,824 sentences from the World Health Organization's e-learning platform. Sourced from expert-authored, professionally translated materials shielded from web-crawling, OpenWHO spans a diverse range of over 20 languages, of which nine are low-resource. Leveraging this new resource, we evaluate modern large language models (LLMs) against traditional MT models. Our findings reveal that LLMs consistently outperform traditional MT models, with Gemini 2.5 Flash achieving a +4.79 ChrF point improvement over NLLB-54B on our low-resource test set. Further, we investigate how LLM context utilisation affects accuracy, finding that the benefits of document-level translation are most pronounced in specialised domains like health. We release the OpenWHO corpus to encourage further research into low-resource MT in the health domain.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2508.16048v3 ë°œí‘œ ìœ í˜•: êµì²´-êµì°¨  
ì´ˆë¡: ê¸°ê³„ ë²ˆì—­(MT)ì—ì„œ ê±´ê°•ì€ ê´‘ë²”ìœ„í•œ ë°°í¬ì™€ ë„ë©”ì¸ íŠ¹í™” ì–´íœ˜ë¡œ íŠ¹ì§•ì§€ì–´ì§€ëŠ” ê³ ìœ„í—˜ ë¶„ì•¼ì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ ë¶„ì•¼ì˜ ì €ìì› ì–¸ì–´ì— ëŒ€í•œ MT í‰ê°€ ë°ì´í„°ì…‹ì€ ë¶€ì¡±í•©ë‹ˆë‹¤. ì´ ê²©ì°¨ë¥¼ í•´ì†Œí•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ì„¸ê³„ë³´ê±´ê¸°êµ¬(WHO)ì˜ e-ëŸ¬ë‹ í”Œë«í¼ì—ì„œ ìˆ˜ì§‘ëœ 2,978ê°œì˜ ë¬¸ì„œì™€ 26,824ê°œì˜ ë¬¸ì¥ìœ¼ë¡œ êµ¬ì„±ëœ ë¬¸ì„œ ìˆ˜ì¤€ì˜ ë³‘ë ¬ ì½”í¼ìŠ¤ì¸ OpenWHOë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ì´ ìë£ŒëŠ” ì›¹ í¬ë¡¤ë§ìœ¼ë¡œë¶€í„° ë³´í˜¸ëœ ì „ë¬¸ê°€ ì‘ì„± ë° ì „ë¬¸ ë²ˆì—­ ìë£Œì—ì„œ ìˆ˜ì§‘ë˜ì—ˆìœ¼ë©°, 20ê°œ ì´ìƒì˜ ë‹¤ì–‘í•œ ì–¸ì–´ë¥¼ í¬í•¨í•˜ê³  ìˆìœ¼ë©° ê·¸ ì¤‘ 9ê°œëŠ” ì €ìì› ì–¸ì–´ì…ë‹ˆë‹¤. ì´ ìƒˆë¡œìš´ ìì›ì„ í™œìš©í•˜ì—¬, ìš°ë¦¬ëŠ” í˜„ëŒ€ì˜ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ê³¼ ì „í†µì ì¸ MT ëª¨ë¸ì„ ë¹„êµ í‰ê°€í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì—°êµ¬ ê²°ê³¼, LLMì´ ì „í†µì ì¸ MT ëª¨ë¸ë³´ë‹¤ ì¼ê´€ë˜ê²Œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì´ë©°, Gemini 2.5 FlashëŠ” ì €ìì› í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ NLLB-54Bì— ë¹„í•´ +4.79 ChrF í¬ì¸íŠ¸ í–¥ìƒì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, LLMì˜ ë¬¸ë§¥ í™œìš©ì´ ì •í™•ë„ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì¡°ì‚¬í•œ ê²°ê³¼, ë¬¸ì„œ ìˆ˜ì¤€ ë²ˆì—­ì˜ ì´ì ì´ ê±´ê°•ê³¼ ê°™ì€ ì „ë¬¸í™”ëœ ë¶„ì•¼ì—ì„œ ê°€ì¥ ë‘ë“œëŸ¬ì§„ë‹¤ëŠ” ê²ƒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” ê±´ê°• ë¶„ì•¼ì˜ ì €ìì› MTì— ëŒ€í•œ ì¶”ê°€ ì—°êµ¬ë¥¼ ì¥ë ¤í•˜ê¸° ìœ„í•´ OpenWHO ì½”í¼ìŠ¤ë¥¼ ê³µê°œí•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì €ìë“¤ì´ ì„¸ê³„ë³´ê±´ê¸°êµ¬ì˜ e-ëŸ¬ë‹ í”Œë«í¼ì—ì„œ ìˆ˜ì§‘í•œ 2,978ê°œì˜ ë¬¸ì„œì™€ 26,824ê°œì˜ ë¬¸ì¥ìœ¼ë¡œ êµ¬ì„±ëœ OpenWHOë¼ëŠ” ë³‘ë ¬ ì½”í¼ìŠ¤ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ì´ ì½”í¼ìŠ¤ëŠ” 20ê°œ ì´ìƒì˜ ì–¸ì–´ë¥¼ í¬í•¨í•˜ë©°, ê·¸ì¤‘ 9ê°œëŠ” ì €ìì›ì´ ë¶€ì¡±í•œ ì–¸ì–´ì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ìµœì‹  ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ê³¼ ì „í†µì ì¸ ê¸°ê³„ ë²ˆì—­(MT) ëª¨ë¸ì„ í‰ê°€í•œ ê²°ê³¼, LLMsê°€ ì „í†µì ì¸ MT ëª¨ë¸ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. íŠ¹íˆ Gemini 2.5 Flash ëª¨ë¸ì´ NLLB-54B ëª¨ë¸ë³´ë‹¤ ì €ìì› ì–¸ì–´ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ ChrF ì ìˆ˜ê°€ 4.79ì  í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤. ë˜í•œ, ë¬¸ì„œ ìˆ˜ì¤€ ë²ˆì—­ì´ ê±´ê°•ê³¼ ê°™ì€ íŠ¹ìˆ˜ ë¶„ì•¼ì—ì„œ ë” íš¨ê³¼ì ì„ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. OpenWHO ì½”í¼ìŠ¤ë¥¼ ê³µê°œí•˜ì—¬ ê±´ê°• ë¶„ì•¼ì˜ ì €ìì› MT ì—°êµ¬ë¥¼ ì´‰ì§„í•˜ê³ ì í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. OpenWHOëŠ” ì„¸ê³„ë³´ê±´ê¸°êµ¬ì˜ e-ëŸ¬ë‹ í”Œë«í¼ì—ì„œ ìˆ˜ì§‘ëœ 2,978ê°œì˜ ë¬¸ì„œì™€ 26,824ê°œì˜ ë¬¸ì¥ìœ¼ë¡œ êµ¬ì„±ëœ ë¬¸ì„œ ìˆ˜ì¤€ì˜ ë³‘ë ¬ ì½”í¼ìŠ¤ì…ë‹ˆë‹¤.

- 2. OpenWHOëŠ” 20ê°œ ì´ìƒì˜ ë‹¤ì–‘í•œ ì–¸ì–´ë¥¼ í¬í•¨í•˜ë©°, ê·¸ ì¤‘ 9ê°œëŠ” ì €ìì› ì–¸ì–´ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

- 3. í˜„ëŒ€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ ì „í†µì ì¸ ê¸°ê³„ ë²ˆì—­(MT) ëª¨ë¸ë³´ë‹¤ ì¼ê´€ë˜ê²Œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì´ë©°, Gemini 2.5 FlashëŠ” ì €ìì› í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ NLLB-54Bë³´ë‹¤ +4.79 ChrF í¬ì¸íŠ¸ ê°œì„ ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.

- 4. ë¬¸ì„œ ìˆ˜ì¤€ ë²ˆì—­ì˜ ì´ì ì€ ê±´ê°•ê³¼ ê°™ì€ ì „ë¬¸ ë¶„ì•¼ì—ì„œ ê°€ì¥ ë‘ë“œëŸ¬ì§€ë©°, LLMì˜ ë¬¸ë§¥ í™œìš©ì´ ì •í™•ì„±ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì¡°ì‚¬í–ˆìŠµë‹ˆë‹¤.

- 5. OpenWHO ì½”í¼ìŠ¤ë¥¼ ê³µê°œí•˜ì—¬ ê±´ê°• ë¶„ì•¼ì˜ ì €ìì› ê¸°ê³„ ë²ˆì—­ì— ëŒ€í•œ ì¶”ê°€ ì—°êµ¬ë¥¼ ì¥ë ¤í•˜ê³ ì í•©ë‹ˆë‹¤.

---

*Generated on 2025-09-22 14:58:57*