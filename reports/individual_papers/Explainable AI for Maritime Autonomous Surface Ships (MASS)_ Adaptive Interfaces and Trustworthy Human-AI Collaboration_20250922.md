# Explainable AI for Maritime Autonomous Surface Ships (MASS): Adaptive Interfaces and Trustworthy Human-AI Collaboration

**Korean Title:** 해양 자율 수상 선박(MASS)을 위한 설명 가능한 인공지능: 적응형 인터페이스와 신뢰할 수 있는 인간-AI 협업

## 📋 메타데이터

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Trust Calibration

## 🔗 유사한 논문
- [[2025-09-18/From Sea to System_ Exploring User-Centered Explainable AI for Maritime Decision Support_20250918|From Sea to System Exploring User-Centered Explainable AI for Maritime Decision Support]] (83.3% similar)
- [[2025-09-22/Explainable AI-Enhanced Supervisory Control for Robust Multi-Agent Robotic Systems_20250922|Explainable AI-Enhanced Supervisory Control for Robust Multi-Agent Robotic Systems]] (82.9% similar)
- [[2025-09-19/Affordance-Based Disambiguation of Surgical Instructions for Collaborative Robot-Assisted Surgery_20250919|Affordance-Based Disambiguation of Surgical Instructions for Collaborative Robot-Assisted Surgery]] (80.3% similar)
- [[2025-09-18/The Cybersecurity of a Humanoid Robot_20250918|The Cybersecurity of a Humanoid Robot]] (80.0% similar)
- [[2025-09-18/Cybersecurity AI_ Humanoid Robots as Attack Vectors_20250918|Cybersecurity AI Humanoid Robots as Attack Vectors]] (79.6% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.15959v1 Announce Type: cross 
Abstract: Autonomous navigation in maritime domains is accelerating alongside advances in artificial intelligence, sensing, and connectivity. Opaque decision-making and poorly calibrated human-automation interaction remain key barriers to safe adoption. This article synthesizes 100 studies on automation transparency for Maritime Autonomous Surface Ships (MASS) spanning situation awareness (SA), human factors, interface design, and regulation. We (i) map the Guidance-Navigation-Control stack to shore-based operational modes -- remote supervision (RSM) and remote control (RCM) -- and identify where human unsafe control actions (Human-UCAs) concentrate in handover and emergency loops; (ii) summarize evidence that transparency features (decision rationales, alternatives, confidence/uncertainty, and rule-compliance indicators) improve understanding and support trust calibration, though reliability and predictability often dominate trust; (iii) distill design strategies for transparency at three layers: sensor/SA acquisition and fusion, HMI/eHMI presentation (textual/graphical overlays, color coding, conversational and immersive UIs), and engineer-facing processes (resilient interaction design, validation, and standardization). We integrate methods for Human-UCA identification (STPA-Cog + IDAC), quantitative trust/SA assessment, and operator workload monitoring, and outline regulatory and rule-based implications including COLREGs formalization and route exchange. We conclude with an adaptive transparency framework that couples operator state estimation with explainable decision support to reduce cognitive overload and improve takeover timeliness. The review highlights actionable figure-of-merit displays (e.g., CPA/TCPA risk bars, robustness heatmaps), transparent model outputs (rule traceability, confidence), and training pipelines (HIL/MIL, simulation) as near-term levers for safer MASS operations.

## 🔍 Abstract (한글 번역)

arXiv:2509.15959v1 발표 유형: 교차

초록: 해양 분야에서의 자율 항해는 인공지능, 센싱, 연결성의 발전과 함께 가속화되고 있습니다. 불투명한 의사 결정과 잘못 조정된 인간-자동화 상호작용은 안전한 채택의 주요 장애물로 남아 있습니다. 이 논문은 상황 인식(SA), 인간 요인, 인터페이스 설계, 규제를 아우르는 해상 자율 수상 선박(MASS)의 자동화 투명성에 관한 100개의 연구를 종합합니다. 우리는 (i) Guidance-Navigation-Control 스택을 육상 기반 운영 모드인 원격 감독(RSM)과 원격 제어(RCM)에 매핑하고, 인간의 안전하지 않은 제어 행동(Human-UCAs)이 인계 및 비상 루프에서 집중되는 지점을 식별합니다; (ii) 투명성 기능(의사 결정 근거, 대안, 신뢰도/불확실성, 규칙 준수 지표)이 이해를 개선하고 신뢰 조정을 지원한다는 증거를 요약하지만, 신뢰는 종종 신뢰성과 예측 가능성에 의해 지배됩니다; (iii) 투명성에 대한 설계 전략을 세 가지 계층으로 추출합니다: 센서/SA 획득 및 융합, HMI/eHMI 표현(텍스트/그래픽 오버레이, 색상 코딩, 대화형 및 몰입형 UI), 엔지니어 대상 프로세스(탄력적 상호작용 설계, 검증, 표준화). 우리는 Human-UCA 식별(STPA-Cog + IDAC), 정량적 신뢰/SA 평가, 운영자 작업 부하 모니터링을 위한 방법을 통합하고, COLREGs 공식화 및 경로 교환을 포함한 규제 및 규칙 기반의 함의를 개략적으로 설명합니다. 우리는 인지 과부하를 줄이고 인계 시기를 개선하기 위해 운영자 상태 추정과 설명 가능한 의사 결정 지원을 결합한 적응형 투명성 프레임워크로 결론을 내립니다. 이 리뷰는 안전한 MASS 운영을 위한 단기 레버로서 실행 가능한 성능 지표 디스플레이(예: CPA/TCPA 위험 바, 강건성 히트맵), 투명한 모델 출력(규칙 추적 가능성, 신뢰도), 교육 파이프라인(HIL/MIL, 시뮬레이션)을 강조합니다.

## 📝 요약

이 논문은 해양 자율 선박(MASS)의 자동화 투명성에 관한 100개의 연구를 종합하여 분석합니다. 주요 기여는 다음과 같습니다: (i) Guidance-Navigation-Control 스택을 원격 감독 및 원격 제어 모드에 매핑하고, 인간의 안전하지 않은 제어 행동이 주로 발생하는 지점을 식별합니다. (ii) 투명성 기능이 이해를 향상시키고 신뢰를 조정하는 데 도움이 된다는 증거를 요약합니다. (iii) 투명성을 위한 설계 전략을 센서/상황 인식, 사용자 인터페이스, 엔지니어링 프로세스의 세 가지 계층으로 구체화합니다. 또한, 인간의 안전하지 않은 제어 행동 식별 방법, 신뢰 및 상황 인식 평가, 작업 부하 모니터링을 통합하고, 규제 및 규칙 기반의 함의를 제시합니다. 최종적으로, 적응형 투명성 프레임워크를 제안하여 인지 과부하를 줄이고 인수 시기를 개선합니다. 논문은 MASS 운영의 안전성을 높이기 위한 실질적인 방안을 강조합니다.

## 🎯 주요 포인트

- 1. 해양 자율 운항 선박(MASS)의 투명성 향상을 위해 100개의 연구를 종합하여 상황 인식, 인간 요소, 인터페이스 설계 및 규제를 다루었습니다.

- 2. 원격 감독 및 원격 제어 모드에서 인간의 안전하지 않은 제어 행동이 집중되는 지점을 식별하고, 투명성 기능이 이해도와 신뢰 보정에 기여함을 요약했습니다.

- 3. 투명성 설계를 위한 전략을 센서/상황 인식 획득 및 융합, HMI/eHMI 표현, 엔지니어 중심 프로세스의 세 가지 계층으로 구체화했습니다.

- 4. 인간의 안전하지 않은 제어 행동 식별 방법과 신뢰/상황 인식 평가, 작업자 부담 모니터링을 통합하고, 규제 및 규칙 기반의 함의를 설명했습니다.

- 5. 적응형 투명성 프레임워크를 제안하여 운영자 상태 추정과 설명 가능한 의사결정 지원을 결합하여 인지 과부하를 줄이고 인수 시의 적시성을 개선했습니다.

---

*Generated on 2025-09-22 14:19:12*