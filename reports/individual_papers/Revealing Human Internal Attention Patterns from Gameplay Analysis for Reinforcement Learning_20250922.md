# Revealing Human Internal Attention Patterns from Gameplay Analysis for Reinforcement Learning

**Korean Title:** 게임 플레이 분석을 통한 강화 학습에서의 인간 내부 주의 패턴 공개

## 📋 메타데이터

## 📋 메타데이터

**Links**: [[reports/digests/daily_digest_20250922|2025-09-22]] [[keywords/evolved/Human Internal Attention Patterns|Human Internal Attention Patterns]] [[keywords/specific/Attention Mechanism|Attention Mechanism]] [[keywords/specific/Eye-tracking Data|Eye-tracking Data]] [[keywords/broad/Reinforcement Learning|Reinforcement Learning]] [[keywords/unique/Contextualized Task-Relevant Attention Networks|Contextualized Task-Relevant Attention Networks]] [[categories/cs.LG|cs.LG]] [[2025-09-19/Reinforcement Learning Agent for a 2D Shooter Game_20250919|Reinforcement Learning Agent for a 2D Shooter Game]] (82.2% similar) [[2025-09-22/Automated Cyber Defense with Generalizable Graph-based Reinforcement Learning Agents_20250922|Automated Cyber Defense with Generalizable Graph-based Reinforcement Learning Agents]] (81.2% similar) [[2025-09-19/Online Learning of Deceptive Policies under Intermittent Observation_20250919|Online Learning of Deceptive Policies under Intermittent Observation]] (80.6% similar)

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Internal Attention Patterns
**🔗 Specific Connectable**: Attention Mechanism, Eye-tracking Data
**🔬 Broad Technical**: Reinforcement Learning
**⭐ Unique Technical**: Contextualized Task-Relevant Attention Networks
## 🔗 유사한 논문
- [[2025-09-19/Reinforcement Learning Agent for a 2D Shooter Game_20250919|Reinforcement Learning Agent for a 2D Shooter Game]] (82.2% similar)
- [[2025-09-22/Automated Cyber Defense with Generalizable Graph-based Reinforcement Learning Agents_20250922|Automated Cyber Defense with Generalizable Graph-based Reinforcement Learning Agents]] (81.2% similar)
- [[2025-09-19/Online Learning of Deceptive Policies under Intermittent Observation_20250919|Online Learning of Deceptive Policies under Intermittent Observation]] (80.6% similar)
- [[2025-09-22/Attention Schema-based Attention Control (ASAC)_ A Cognitive-Inspired Approach for Attention Management in Transformers_20250922|Attention Schema-based Attention Control (ASAC) A Cognitive-Inspired Approach for Attention Management in Transformers]] (80.6% similar)
- [[2025-09-19/Continuous-Time Value Iteration for Multi-Agent Reinforcement Learning_20250919|Continuous-Time Value Iteration for Multi-Agent Reinforcement Learning]] (80.3% similar)


**ArXiv ID**: [2504.11118](https://arxiv.org/abs/2504.11118)
**Published**: 2025-09-22
**Category**: cs.LG
**PDF**: [Download](https://arxiv.org/pdf/2504.11118.pdf)


**ArXiv ID**: [2504.11118](https://arxiv.org/abs/2504.11118)
**Published**: 2025-09-22
**Category**: cs.LG
**PDF**: [Download](https://arxiv.org/pdf/2504.11118.pdf)

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Human Internal Attention Patterns
**🔗 Specific Connectable**: Attention Mechanism, Eye-tracking Data
**⭐ Unique Technical**: Contextualized Task-Relevant Attention Networks
**🔬 Broad Technical**: Reinforcement Learning

## 🏷️ 추출된 키워드



`Reinforcement Learning` • 

`Attention Mechanism` • 

`Eye-tracking Data` • 

`Contextualized Task-Relevant Attention Networks` • 

`Human Internal Attention Patterns`



## 🔗 유사한 논문

Similar papers will be displayed here based on embedding similarity.

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2504.11118v2 Announce Type: replace 
Abstract: This study introduces a novel method for revealing human internal attention patterns from gameplay data alone, leveraging offline attention techniques from reinforcement learning (RL). We propose contextualized, task-relevant (CTR) attention networks, which generate attention maps from both human and RL agent gameplay in Atari environments. To evaluate whether the human CTR maps reveal internal attention, we validate our model by quantitative and qualitative comparison to the agent maps as well as to a temporally integrated overt attention (TIOA) model based on human eye-tracking data. Our results show that human CTR maps are more sparse than the agent ones and align better with the TIOA maps. Following a qualitative visual comparison we conclude that they likely capture patterns of internal attention. As a further application, we use these maps to guide RL agents, finding that human internal attention-guided agents achieve slightly improved and more stable learning compared to baselines. This work advances the understanding of human-agent attention differences and provides a new approach for extracting and validating internal attention from behavioral data.

## 🔍 Abstract (한글 번역)

arXiv:2504.11118v2 발표 유형: 교체  
초록: 본 연구는 강화 학습(RL)의 오프라인 주의 기법을 활용하여 게임 플레이 데이터만으로 인간의 내부 주의 패턴을 드러내는 새로운 방법을 소개합니다. 우리는 Atari 환경에서 인간과 RL 에이전트의 게임 플레이로부터 주의 맵을 생성하는 맥락화된, 과제 관련(CTR) 주의 네트워크를 제안합니다. 인간 CTR 맵이 내부 주의를 드러내는지를 평가하기 위해, 우리는 에이전트 맵과 인간의 시선 추적 데이터를 기반으로 한 시간 통합 외부 주의(TIOA) 모델과의 정량적 및 정성적 비교를 통해 우리의 모델을 검증합니다. 우리의 결과는 인간 CTR 맵이 에이전트 맵보다 더 희소하며 TIOA 맵과 더 잘 일치함을 보여줍니다. 정성적 시각 비교를 통해 우리는 이들이 내부 주의 패턴을 포착할 가능성이 높다고 결론지었습니다. 추가적인 응용으로, 우리는 이러한 맵을 RL 에이전트를 안내하는 데 사용하여, 인간 내부 주의에 의해 안내된 에이전트가 기준선보다 약간 향상되고 더 안정적인 학습을 달성함을 발견했습니다. 이 연구는 인간-에이전트 주의 차이에 대한 이해를 발전시키고 행동 데이터로부터 내부 주의를 추출하고 검증하는 새로운 접근법을 제공합니다.

## 📝 요약

이 연구는 게임 플레이 데이터만을 활용하여 인간의 내부 주의 패턴을 밝혀내는 새로운 방법을 제안합니다. 강화 학습(RL)의 오프라인 주의 기법을 활용하여, 아타리 환경에서 인간과 RL 에이전트의 게임 플레이로부터 주의 맵을 생성하는 맥락화된, 과제 관련(CTR) 주의 네트워크를 제안합니다. 인간 CTR 맵이 내부 주의를 드러내는지를 평가하기 위해, 에이전트 맵 및 인간 시선 추적 데이터를 기반으로 한 시간 통합 외부 주의(TIOA) 모델과 정량적, 정성적으로 비교하여 모델을 검증했습니다. 결과적으로 인간 CTR 맵이 에이전트 맵보다 더 희소하고 TIOA 맵과 더 잘 일치함을 발견했습니다. 이러한 맵을 활용하여 RL 에이전트를 안내한 결과, 인간 내부 주의가 안내된 에이전트가 기준보다 약간 더 향상되고 안정적인 학습을 달성했습니다. 이 연구는 인간과 에이전트의 주의 차이를 이해하는 데 기여하며, 행동 데이터로부터 내부 주의를 추출하고 검증하는 새로운 접근법을 제공합니다.

## 🎯 주요 포인트


- 1. 본 연구는 강화 학습의 오프라인 주의 기법을 활용하여 게임 플레이 데이터만으로 인간의 내부 주의 패턴을 밝혀내는 새로운 방법을 소개합니다.

- 2. 제안된 CTR 주의 네트워크는 인간과 RL 에이전트의 게임 플레이에서 주의 맵을 생성하며, 이는 Atari 환경에서 적용됩니다.

- 3. 인간 CTR 맵은 에이전트 맵보다 더 희소하며, 인간의 시선 추적 데이터를 기반으로 한 TIOA 모델과 더 잘 일치하는 것으로 나타났습니다.

- 4. 인간 내부 주의가 반영된 에이전트는 기준보다 약간 개선된 안정적인 학습 성과를 보였습니다.

- 5. 이 연구는 인간과 에이전트 간 주의 차이를 이해하는 데 기여하며, 행동 데이터에서 내부 주의를 추출하고 검증하는 새로운 접근법을 제공합니다.


---

*Generated on 2025-09-22 15:57:35*