# Revealing Human Internal Attention Patterns from Gameplay Analysis for Reinforcement Learning

**Korean Title:** ê²Œì„ í”Œë ˆì´ ë¶„ì„ì„ í†µí•œ ê°•í™” í•™ìŠµì—ì„œì˜ ì¸ê°„ ë‚´ë¶€ ì£¼ì˜ íŒ¨í„´ ê³µê°œ

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[reports/digests/daily_digest_20250922|2025-09-22]] [[keywords/evolved/Human Internal Attention Patterns|Human Internal Attention Patterns]] [[keywords/specific/Attention Mechanism|Attention Mechanism]] [[keywords/specific/Eye-tracking Data|Eye-tracking Data]] [[keywords/broad/Reinforcement Learning|Reinforcement Learning]] [[keywords/unique/Contextualized Task-Relevant Attention Networks|Contextualized Task-Relevant Attention Networks]] [[categories/cs.LG|cs.LG]] [[2025-09-19/Reinforcement Learning Agent for a 2D Shooter Game_20250919|Reinforcement Learning Agent for a 2D Shooter Game]] (82.2% similar) [[2025-09-22/Automated Cyber Defense with Generalizable Graph-based Reinforcement Learning Agents_20250922|Automated Cyber Defense with Generalizable Graph-based Reinforcement Learning Agents]] (81.2% similar) [[2025-09-19/Online Learning of Deceptive Policies under Intermittent Observation_20250919|Online Learning of Deceptive Policies under Intermittent Observation]] (80.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Internal Attention Patterns
**ğŸ”— Specific Connectable**: Attention Mechanism, Eye-tracking Data
**ğŸ”¬ Broad Technical**: Reinforcement Learning
**â­ Unique Technical**: Contextualized Task-Relevant Attention Networks
## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Reinforcement Learning Agent for a 2D Shooter Game_20250919|Reinforcement Learning Agent for a 2D Shooter Game]] (82.2% similar)
- [[2025-09-22/Automated Cyber Defense with Generalizable Graph-based Reinforcement Learning Agents_20250922|Automated Cyber Defense with Generalizable Graph-based Reinforcement Learning Agents]] (81.2% similar)
- [[2025-09-19/Online Learning of Deceptive Policies under Intermittent Observation_20250919|Online Learning of Deceptive Policies under Intermittent Observation]] (80.6% similar)
- [[2025-09-22/Attention Schema-based Attention Control (ASAC)_ A Cognitive-Inspired Approach for Attention Management in Transformers_20250922|Attention Schema-based Attention Control (ASAC) A Cognitive-Inspired Approach for Attention Management in Transformers]] (80.6% similar)
- [[2025-09-19/Continuous-Time Value Iteration for Multi-Agent Reinforcement Learning_20250919|Continuous-Time Value Iteration for Multi-Agent Reinforcement Learning]] (80.3% similar)


**ArXiv ID**: [2504.11118](https://arxiv.org/abs/2504.11118)
**Published**: 2025-09-22
**Category**: cs.LG
**PDF**: [Download](https://arxiv.org/pdf/2504.11118.pdf)


**ArXiv ID**: [2504.11118](https://arxiv.org/abs/2504.11118)
**Published**: 2025-09-22
**Category**: cs.LG
**PDF**: [Download](https://arxiv.org/pdf/2504.11118.pdf)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Human Internal Attention Patterns
**ğŸ”— Specific Connectable**: Attention Mechanism, Eye-tracking Data
**â­ Unique Technical**: Contextualized Task-Relevant Attention Networks
**ğŸ”¬ Broad Technical**: Reinforcement Learning

## ğŸ·ï¸ ì¶”ì¶œëœ í‚¤ì›Œë“œ



`Reinforcement Learning` â€¢ 

`Attention Mechanism` â€¢ 

`Eye-tracking Data` â€¢ 

`Contextualized Task-Relevant Attention Networks` â€¢ 

`Human Internal Attention Patterns`



## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸

Similar papers will be displayed here based on embedding similarity.

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2504.11118v2 Announce Type: replace 
Abstract: This study introduces a novel method for revealing human internal attention patterns from gameplay data alone, leveraging offline attention techniques from reinforcement learning (RL). We propose contextualized, task-relevant (CTR) attention networks, which generate attention maps from both human and RL agent gameplay in Atari environments. To evaluate whether the human CTR maps reveal internal attention, we validate our model by quantitative and qualitative comparison to the agent maps as well as to a temporally integrated overt attention (TIOA) model based on human eye-tracking data. Our results show that human CTR maps are more sparse than the agent ones and align better with the TIOA maps. Following a qualitative visual comparison we conclude that they likely capture patterns of internal attention. As a further application, we use these maps to guide RL agents, finding that human internal attention-guided agents achieve slightly improved and more stable learning compared to baselines. This work advances the understanding of human-agent attention differences and provides a new approach for extracting and validating internal attention from behavioral data.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2504.11118v2 ë°œí‘œ ìœ í˜•: êµì²´  
ì´ˆë¡: ë³¸ ì—°êµ¬ëŠ” ê°•í™” í•™ìŠµ(RL)ì˜ ì˜¤í”„ë¼ì¸ ì£¼ì˜ ê¸°ë²•ì„ í™œìš©í•˜ì—¬ ê²Œì„ í”Œë ˆì´ ë°ì´í„°ë§Œìœ¼ë¡œ ì¸ê°„ì˜ ë‚´ë¶€ ì£¼ì˜ íŒ¨í„´ì„ ë“œëŸ¬ë‚´ëŠ” ìƒˆë¡œìš´ ë°©ë²•ì„ ì†Œê°œí•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” Atari í™˜ê²½ì—ì„œ ì¸ê°„ê³¼ RL ì—ì´ì „íŠ¸ì˜ ê²Œì„ í”Œë ˆì´ë¡œë¶€í„° ì£¼ì˜ ë§µì„ ìƒì„±í•˜ëŠ” ë§¥ë½í™”ëœ, ê³¼ì œ ê´€ë ¨(CTR) ì£¼ì˜ ë„¤íŠ¸ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì¸ê°„ CTR ë§µì´ ë‚´ë¶€ ì£¼ì˜ë¥¼ ë“œëŸ¬ë‚´ëŠ”ì§€ë¥¼ í‰ê°€í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ì—ì´ì „íŠ¸ ë§µê³¼ ì¸ê°„ì˜ ì‹œì„  ì¶”ì  ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì‹œê°„ í†µí•© ì™¸ë¶€ ì£¼ì˜(TIOA) ëª¨ë¸ê³¼ì˜ ì •ëŸ‰ì  ë° ì •ì„±ì  ë¹„êµë¥¼ í†µí•´ ìš°ë¦¬ì˜ ëª¨ë¸ì„ ê²€ì¦í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ê²°ê³¼ëŠ” ì¸ê°„ CTR ë§µì´ ì—ì´ì „íŠ¸ ë§µë³´ë‹¤ ë” í¬ì†Œí•˜ë©° TIOA ë§µê³¼ ë” ì˜ ì¼ì¹˜í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì •ì„±ì  ì‹œê° ë¹„êµë¥¼ í†µí•´ ìš°ë¦¬ëŠ” ì´ë“¤ì´ ë‚´ë¶€ ì£¼ì˜ íŒ¨í„´ì„ í¬ì°©í•  ê°€ëŠ¥ì„±ì´ ë†’ë‹¤ê³  ê²°ë¡ ì§€ì—ˆìŠµë‹ˆë‹¤. ì¶”ê°€ì ì¸ ì‘ìš©ìœ¼ë¡œ, ìš°ë¦¬ëŠ” ì´ëŸ¬í•œ ë§µì„ RL ì—ì´ì „íŠ¸ë¥¼ ì•ˆë‚´í•˜ëŠ” ë° ì‚¬ìš©í•˜ì—¬, ì¸ê°„ ë‚´ë¶€ ì£¼ì˜ì— ì˜í•´ ì•ˆë‚´ëœ ì—ì´ì „íŠ¸ê°€ ê¸°ì¤€ì„ ë³´ë‹¤ ì•½ê°„ í–¥ìƒë˜ê³  ë” ì•ˆì •ì ì¸ í•™ìŠµì„ ë‹¬ì„±í•¨ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ì¸ê°„-ì—ì´ì „íŠ¸ ì£¼ì˜ ì°¨ì´ì— ëŒ€í•œ ì´í•´ë¥¼ ë°œì „ì‹œí‚¤ê³  í–‰ë™ ë°ì´í„°ë¡œë¶€í„° ë‚´ë¶€ ì£¼ì˜ë¥¼ ì¶”ì¶œí•˜ê³  ê²€ì¦í•˜ëŠ” ìƒˆë¡œìš´ ì ‘ê·¼ë²•ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” ê²Œì„ í”Œë ˆì´ ë°ì´í„°ë§Œì„ í™œìš©í•˜ì—¬ ì¸ê°„ì˜ ë‚´ë¶€ ì£¼ì˜ íŒ¨í„´ì„ ë°í˜€ë‚´ëŠ” ìƒˆë¡œìš´ ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê°•í™” í•™ìŠµ(RL)ì˜ ì˜¤í”„ë¼ì¸ ì£¼ì˜ ê¸°ë²•ì„ í™œìš©í•˜ì—¬, ì•„íƒ€ë¦¬ í™˜ê²½ì—ì„œ ì¸ê°„ê³¼ RL ì—ì´ì „íŠ¸ì˜ ê²Œì„ í”Œë ˆì´ë¡œë¶€í„° ì£¼ì˜ ë§µì„ ìƒì„±í•˜ëŠ” ë§¥ë½í™”ëœ, ê³¼ì œ ê´€ë ¨(CTR) ì£¼ì˜ ë„¤íŠ¸ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì¸ê°„ CTR ë§µì´ ë‚´ë¶€ ì£¼ì˜ë¥¼ ë“œëŸ¬ë‚´ëŠ”ì§€ë¥¼ í‰ê°€í•˜ê¸° ìœ„í•´, ì—ì´ì „íŠ¸ ë§µ ë° ì¸ê°„ ì‹œì„  ì¶”ì  ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì‹œê°„ í†µí•© ì™¸ë¶€ ì£¼ì˜(TIOA) ëª¨ë¸ê³¼ ì •ëŸ‰ì , ì •ì„±ì ìœ¼ë¡œ ë¹„êµí•˜ì—¬ ëª¨ë¸ì„ ê²€ì¦í–ˆìŠµë‹ˆë‹¤. ê²°ê³¼ì ìœ¼ë¡œ ì¸ê°„ CTR ë§µì´ ì—ì´ì „íŠ¸ ë§µë³´ë‹¤ ë” í¬ì†Œí•˜ê³  TIOA ë§µê³¼ ë” ì˜ ì¼ì¹˜í•¨ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë§µì„ í™œìš©í•˜ì—¬ RL ì—ì´ì „íŠ¸ë¥¼ ì•ˆë‚´í•œ ê²°ê³¼, ì¸ê°„ ë‚´ë¶€ ì£¼ì˜ê°€ ì•ˆë‚´ëœ ì—ì´ì „íŠ¸ê°€ ê¸°ì¤€ë³´ë‹¤ ì•½ê°„ ë” í–¥ìƒë˜ê³  ì•ˆì •ì ì¸ í•™ìŠµì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ì¸ê°„ê³¼ ì—ì´ì „íŠ¸ì˜ ì£¼ì˜ ì°¨ì´ë¥¼ ì´í•´í•˜ëŠ” ë° ê¸°ì—¬í•˜ë©°, í–‰ë™ ë°ì´í„°ë¡œë¶€í„° ë‚´ë¶€ ì£¼ì˜ë¥¼ ì¶”ì¶œí•˜ê³  ê²€ì¦í•˜ëŠ” ìƒˆë¡œìš´ ì ‘ê·¼ë²•ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸


- 1. ë³¸ ì—°êµ¬ëŠ” ê°•í™” í•™ìŠµì˜ ì˜¤í”„ë¼ì¸ ì£¼ì˜ ê¸°ë²•ì„ í™œìš©í•˜ì—¬ ê²Œì„ í”Œë ˆì´ ë°ì´í„°ë§Œìœ¼ë¡œ ì¸ê°„ì˜ ë‚´ë¶€ ì£¼ì˜ íŒ¨í„´ì„ ë°í˜€ë‚´ëŠ” ìƒˆë¡œìš´ ë°©ë²•ì„ ì†Œê°œí•©ë‹ˆë‹¤.

- 2. ì œì•ˆëœ CTR ì£¼ì˜ ë„¤íŠ¸ì›Œí¬ëŠ” ì¸ê°„ê³¼ RL ì—ì´ì „íŠ¸ì˜ ê²Œì„ í”Œë ˆì´ì—ì„œ ì£¼ì˜ ë§µì„ ìƒì„±í•˜ë©°, ì´ëŠ” Atari í™˜ê²½ì—ì„œ ì ìš©ë©ë‹ˆë‹¤.

- 3. ì¸ê°„ CTR ë§µì€ ì—ì´ì „íŠ¸ ë§µë³´ë‹¤ ë” í¬ì†Œí•˜ë©°, ì¸ê°„ì˜ ì‹œì„  ì¶”ì  ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ TIOA ëª¨ë¸ê³¼ ë” ì˜ ì¼ì¹˜í•˜ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.

- 4. ì¸ê°„ ë‚´ë¶€ ì£¼ì˜ê°€ ë°˜ì˜ëœ ì—ì´ì „íŠ¸ëŠ” ê¸°ì¤€ë³´ë‹¤ ì•½ê°„ ê°œì„ ëœ ì•ˆì •ì ì¸ í•™ìŠµ ì„±ê³¼ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.

- 5. ì´ ì—°êµ¬ëŠ” ì¸ê°„ê³¼ ì—ì´ì „íŠ¸ ê°„ ì£¼ì˜ ì°¨ì´ë¥¼ ì´í•´í•˜ëŠ” ë° ê¸°ì—¬í•˜ë©°, í–‰ë™ ë°ì´í„°ì—ì„œ ë‚´ë¶€ ì£¼ì˜ë¥¼ ì¶”ì¶œí•˜ê³  ê²€ì¦í•˜ëŠ” ìƒˆë¡œìš´ ì ‘ê·¼ë²•ì„ ì œê³µí•©ë‹ˆë‹¤.


---

*Generated on 2025-09-22 15:57:35*