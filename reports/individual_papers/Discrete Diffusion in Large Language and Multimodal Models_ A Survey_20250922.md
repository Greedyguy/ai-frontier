# Discrete Diffusion in Large Language and Multimodal Models: A Survey

**Korean Title:** ëŒ€í˜• ì–¸ì–´ ë° ë‹¤ì¤‘ ëª¨ë‹¬ ëª¨ë¸ì—ì„œì˜ ì´ì‚° í™•ì‚°: ì¡°ì‚¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: Parallel Decoding, Denoising-based Generation

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Modular Machine Learning_ An Indispensable Path towards New-Generation Large Language Models_20250919|Modular Machine Learning An Indispensable Path towards New-Generation Large Language Models]] (86.3% similar)
- [[2025-09-18/From Automation to Autonomy_ A Survey on Large Language Models in Scientific Discovery_20250918|From Automation to Autonomy A Survey on Large Language Models in Scientific Discovery]] (85.7% similar)
- [[2025-09-19/Decoupled Proxy Alignment_ Mitigating Language Prior Conflict for Multimodal Alignment in MLLM_20250919|Decoupled Proxy Alignment Mitigating Language Prior Conflict for Multimodal Alignment in MLLM]] (85.5% similar)
- [[2025-09-19/DetectAnyLLM_ Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models_20250919|DetectAnyLLM Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models]] (85.5% similar)
- [[2025-09-18/Fast and Fluent Diffusion Language Models via Convolutional Decoding and Rejective Fine-tuning_20250918|Fast and Fluent Diffusion Language Models via Convolutional Decoding and Rejective Fine-tuning]] (84.7% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2506.13759v5 Announce Type: replace-cross 
Abstract: In this work, we provide a systematic survey of Discrete Diffusion Language Models (dLLMs) and Discrete Diffusion Multimodal Language Models (dMLLMs). Unlike autoregressive (AR) models, dLLMs and dMLLMs adopt a multi-token, parallel decoding paradigm using full attention and a denoising-based generation strategy. This paradigm naturally enables parallel generation, fine-grained output control, and dynamic perception. These capabilities are previously difficult to achieve with AR models. A growing number of industrial-scale proprietary d(M)LLMs, as well as a large number of open-source academic d(M)LLMs, have demonstrated performance comparable to their autoregressive counterparts, while achieving up to 10$\times$ acceleration in inference speed. These developments position discrete diffusion models as a promising alternative to intelligence based on the traditional autoregressive approach. In this work, we present a comprehensive overview of the research in the dLLM and dMLLM domains. We trace the historical development of dLLMs and dMLLMs, formalize the underlying mathematical frameworks, list commonly-used modeling methods, and categorize representative models. We further analyze key techniques for training, inference, quantization. We also discuss the trustworthy issues and summarize emerging applications across language, vision-language, and biological domains and etc.. We conclude by discussing future directions for research and deployment. Relative papers are collected in https://github.com/LiQiiiii/Awesome-Discrete-Diffusion-LLM_MLLM

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2506.13759v5 ë°œí‘œ ìœ í˜•: êµì°¨ êµì²´  
ì´ˆë¡: ì´ ì—°êµ¬ì—ì„œëŠ” ì´ì‚° í™•ì‚° ì–¸ì–´ ëª¨ë¸(dLLMs)ê³¼ ì´ì‚° í™•ì‚° ë‹¤ì¤‘ ëª¨ë“œ ì–¸ì–´ ëª¨ë¸(dMLLMs)ì— ëŒ€í•œ ì²´ê³„ì ì¸ ì¡°ì‚¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ìê¸°íšŒê·€(AR) ëª¨ë¸ê³¼ ë‹¬ë¦¬, dLLMsì™€ dMLLMsëŠ” ì „ì²´ ì£¼ì˜(attention)ì™€ ì¡ìŒ ì œê±° ê¸°ë°˜ ìƒì„± ì „ëµì„ ì‚¬ìš©í•˜ëŠ” ë‹¤ì¤‘ í† í°, ë³‘ë ¬ ë””ì½”ë”© íŒ¨ëŸ¬ë‹¤ì„ì„ ì±„íƒí•©ë‹ˆë‹¤. ì´ íŒ¨ëŸ¬ë‹¤ì„ì€ ìì—°ìŠ¤ëŸ½ê²Œ ë³‘ë ¬ ìƒì„±, ì„¸ë°€í•œ ì¶œë ¥ ì œì–´, ë™ì  ì¸ì‹ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ê¸°ëŠ¥ë“¤ì€ ì´ì „ì—ëŠ” AR ëª¨ë¸ë¡œ ë‹¬ì„±í•˜ê¸° ì–´ë ¤ì› ìŠµë‹ˆë‹¤. ì‚°ì—… ê·œëª¨ì˜ ë…ì  d(M)LLMsì™€ ë§ì€ ì˜¤í”ˆ ì†ŒìŠ¤ í•™ìˆ  d(M)LLMsê°€ ìê¸°íšŒê·€ ëª¨ë¸ê³¼ ë¹„êµí•  ë§Œí•œ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì—ˆìœ¼ë©°, ì¶”ë¡  ì†ë„ì—ì„œ ìµœëŒ€ 10ë°° ê°€ì†ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë°œì „ì€ ì „í†µì ì¸ ìê¸°íšŒê·€ ì ‘ê·¼ë²•ì— ê¸°ë°˜í•œ ì§€ëŠ¥ì— ëŒ€í•œ ìœ ë§í•œ ëŒ€ì•ˆìœ¼ë¡œ ì´ì‚° í™•ì‚° ëª¨ë¸ì„ ìœ„ì¹˜ì‹œí‚µë‹ˆë‹¤. ì´ ì—°êµ¬ì—ì„œëŠ” dLLMê³¼ dMLLM ë¶„ì•¼ì˜ ì—°êµ¬ì— ëŒ€í•œ í¬ê´„ì ì¸ ê°œìš”ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. dLLMsì™€ dMLLMsì˜ ì—­ì‚¬ì  ë°œì „ì„ ì¶”ì í•˜ê³ , ê¸°ë³¸ ìˆ˜í•™ì  í”„ë ˆì„ì›Œí¬ë¥¼ ê³µì‹í™”í•˜ë©°, ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ëª¨ë¸ë§ ë°©ë²•ì„ ë‚˜ì—´í•˜ê³ , ëŒ€í‘œì ì¸ ëª¨ë¸ì„ ë¶„ë¥˜í•©ë‹ˆë‹¤. ë˜í•œ, í›ˆë ¨, ì¶”ë¡ , ì–‘ìí™”ì— ëŒ€í•œ ì£¼ìš” ê¸°ìˆ ì„ ë¶„ì„í•©ë‹ˆë‹¤. ì‹ ë¢°ì„± ë¬¸ì œë¥¼ ë…¼ì˜í•˜ê³  ì–¸ì–´, ì‹œê°-ì–¸ì–´, ìƒë¬¼í•™ì  ë¶„ì•¼ ë“±ì—ì„œì˜ ìƒˆë¡œìš´ ì‘ìš©ì„ ìš”ì•½í•©ë‹ˆë‹¤. ì—°êµ¬ ë° ë°°í¬ì˜ ë¯¸ë˜ ë°©í–¥ì— ëŒ€í•´ ë…¼ì˜í•˜ë©° ê²°ë¡ ì„ ë§ºìŠµë‹ˆë‹¤. ê´€ë ¨ ë…¼ë¬¸ì€ https://github.com/LiQiiiii/Awesome-Discrete-Diffusion-LLM_MLLMì— ìˆ˜ì§‘ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì´ì‚° í™•ì‚° ì–¸ì–´ ëª¨ë¸(dLLM)ê³¼ ì´ì‚° í™•ì‚° ë‹¤ì¤‘ëª¨ë‹¬ ì–¸ì–´ ëª¨ë¸(dMLLM)ì— ëŒ€í•œ ì²´ê³„ì ì¸ ì¡°ì‚¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤. dLLMê³¼ dMLLMì€ ë‹¤ì¤‘ í† í° ë³‘ë ¬ ë””ì½”ë”©ê³¼ ë””ë…¸ì´ì§• ê¸°ë°˜ ìƒì„± ì „ëµì„ ì‚¬ìš©í•˜ì—¬, ê¸°ì¡´ì˜ ìê¸°íšŒê·€ ëª¨ë¸(AR)ê³¼ ë‹¬ë¦¬ ë³‘ë ¬ ìƒì„±, ì„¸ë°€í•œ ì¶œë ¥ ì œì–´, ë™ì  ì¸ì‹ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ëª¨ë¸ë“¤ì€ ìê¸°íšŒê·€ ëª¨ë¸ê³¼ ìœ ì‚¬í•œ ì„±ëŠ¥ì„ ë³´ì´ë©´ì„œë„ ìµœëŒ€ 10ë°° ë¹ ë¥¸ ì¶”ë¡  ì†ë„ë¥¼ ë‹¬ì„±í•©ë‹ˆë‹¤. ë…¼ë¬¸ì€ dLLMê³¼ dMLLMì˜ ì—­ì‚¬ì  ë°œì „, ìˆ˜í•™ì  í”„ë ˆì„ì›Œí¬, ì¼ë°˜ì ì¸ ëª¨ë¸ë§ ë°©ë²•, ëŒ€í‘œ ëª¨ë¸ ë¶„ë¥˜, í›ˆë ¨ ë° ì¶”ë¡  ê¸°ë²•ì„ ë¶„ì„í•˜ê³ , ì‹ ë¢°ì„± ë¬¸ì œì™€ ì–¸ì–´, ì‹œê°-ì–¸ì–´, ìƒë¬¼í•™ì  ë¶„ì•¼ì˜ ì‘ìš©ì„ ë…¼ì˜í•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ í–¥í›„ ì—°êµ¬ ë°©í–¥ì„ ì œì‹œí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë³¸ ë…¼ë¬¸ì€ Discrete Diffusion Language Models (dLLMs)ì™€ Discrete Diffusion Multimodal Language Models (dMLLMs)ì— ëŒ€í•œ ì²´ê³„ì ì¸ ì¡°ì‚¬ë¥¼ ì œê³µí•œë‹¤.

- 2. dLLMsì™€ dMLLMsëŠ” ë‹¤ì¤‘ í† í° ë³‘ë ¬ ë””ì½”ë”© íŒ¨ëŸ¬ë‹¤ì„ì„ ì±„íƒí•˜ì—¬ ë³‘ë ¬ ìƒì„±, ì„¸ë°€í•œ ì¶œë ¥ ì œì–´ ë° ë™ì  ì¸ì‹ì„ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤.

- 3. ì‚°ì—… ê·œëª¨ì˜ ë…ì ì  d(M)LLMsì™€ ë§ì€ ì˜¤í”ˆ ì†ŒìŠ¤ í•™ìˆ  d(M)LLMsëŠ” ìµœëŒ€ 10ë°°ì˜ ì¶”ë¡  ì†ë„ ê°€ì†ì„ ë‹¬ì„±í•˜ë©´ì„œë„ ì„±ëŠ¥ ë©´ì—ì„œ ìê°€íšŒê·€ ëª¨ë¸ê³¼ ë¹„êµí•  ë§Œí•˜ë‹¤.

- 4. ë³¸ ì—°êµ¬ì—ì„œëŠ” dLLMê³¼ dMLLMì˜ ì—­ì‚¬ì  ë°œì „, ìˆ˜í•™ì  í”„ë ˆì„ì›Œí¬, ì¼ë°˜ì ì¸ ëª¨ë¸ë§ ë°©ë²•, ëŒ€í‘œ ëª¨ë¸ì„ í¬ê´„ì ìœ¼ë¡œ ê°œê´€í•œë‹¤.

- 5. ì‹ ë¢°ì„± ë¬¸ì œì™€ ì–¸ì–´, ë¹„ì „-ì–¸ì–´, ìƒë¬¼í•™ì  ë„ë©”ì¸ ë“±ì—ì„œì˜ ìƒˆë¡œìš´ ì‘ìš©ì„ ë…¼ì˜í•˜ê³ , ì—°êµ¬ ë° ë°°í¬ì˜ ë¯¸ë˜ ë°©í–¥ì„ ì œì‹œí•œë‹¤.

---

*Generated on 2025-09-22 14:55:46*