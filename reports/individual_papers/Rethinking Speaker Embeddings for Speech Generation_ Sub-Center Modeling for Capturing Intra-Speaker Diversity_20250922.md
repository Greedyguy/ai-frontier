# Rethinking Speaker Embeddings for Speech Generation: Sub-Center Modeling for Capturing Intra-Speaker Diversity

**Korean Title:** ì—°ì„¤ ìƒì„±ì— ëŒ€í•œ í™”ì ì„ë² ë”© ì¬ê³ : í™”ì ë‚´ ë‹¤ì–‘ì„±ì„ í¬ì°©í•˜ê¸° ìœ„í•œ ì„œë¸Œ ì„¼í„° ëª¨ë¸ë§

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[reports/digests/daily_digest_20250922|2025-09-22]] [[keywords/evolved/Intra-Speaker Diversity|Intra-Speaker Diversity]] [[keywords/specific/Speaker Embeddings|Speaker Embeddings]] [[keywords/specific/Voice Conversion|Voice Conversion]] [[keywords/broad/Speech Generation|Speech Generation]] [[keywords/unique/Sub-Center Modeling|Sub-Center Modeling]] [[categories/cs.LG|cs.LG]] [[2025-09-18/Mitigating Intra-Speaker Variability in Diarization with Style-Controllable Speech Augmentation_20250918|Mitigating Intra-Speaker Variability in Diarization with Style-Controllable Speech Augmentation]] (84.9% similar) [[2025-09-19/Towards Human-like Multimodal Conversational Agent by Generating Engaging Speech_20250919|Towards Human-like Multimodal Conversational Agent by Generating Engaging Speech]] (81.0% similar) [[2025-09-22/Impact of Phonetics on Speaker Identity in Adversarial Voice Attack_20250922|Impact of Phonetics on Speaker Identity in Adversarial Voice Attack]] (79.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Intra-Speaker Diversity
**ğŸ”— Specific Connectable**: Voice Conversion
**ğŸ”¬ Broad Technical**: Speech Generation, Speaker Embeddings
**â­ Unique Technical**: Sub-Center Modeling
## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/Mitigating Intra-Speaker Variability in Diarization with Style-Controllable Speech Augmentation_20250918|Mitigating Intra-Speaker Variability in Diarization with Style-Controllable Speech Augmentation]] (84.9% similar)
- [[2025-09-19/Towards Human-like Multimodal Conversational Agent by Generating Engaging Speech_20250919|Towards Human-like Multimodal Conversational Agent by Generating Engaging Speech]] (81.0% similar)
- [[2025-09-22/Impact of Phonetics on Speaker Identity in Adversarial Voice Attack_20250922|Impact of Phonetics on Speaker Identity in Adversarial Voice Attack]] (79.8% similar)
- [[2025-09-19/Hybrid Autoregressive-Diffusion Model for Real-Time Sign Language Production_20250919|Hybrid Autoregressive-Diffusion Model for Real-Time Sign Language Production]] (79.1% similar)
- [[2025-09-18/TICL_ Text-Embedding KNN For Speech In-Context Learning Unlocks Speech Recognition Abilities of Large Multimodal Models_20250918|TICL Text-Embedding KNN For Speech In-Context Learning Unlocks Speech Recognition Abilities of Large Multimodal Models]] (78.9% similar)


**ArXiv ID**: [2407.04291](https://arxiv.org/abs/2407.04291)
**Published**: 2025-09-22
**Category**: cs.LG
**PDF**: [Download](https://arxiv.org/pdf/2407.04291.pdf)


**ArXiv ID**: [2407.04291](https://arxiv.org/abs/2407.04291)
**Published**: 2025-09-22
**Category**: cs.LG
**PDF**: [Download](https://arxiv.org/pdf/2407.04291.pdf)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Intra-Speaker Diversity
**ğŸ”— Specific Connectable**: Speaker Embeddings, Voice Conversion
**â­ Unique Technical**: Sub-Center Modeling
**ğŸ”¬ Broad Technical**: Speech Generation

## ğŸ·ï¸ ì¶”ì¶œëœ í‚¤ì›Œë“œ



`Speech Generation` â€¢ 

`Voice Conversion` â€¢ 

`Sub-Center Modeling` â€¢ 

`Intra-Speaker Diversity`



## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸

Similar papers will be displayed here based on embedding similarity.

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2407.04291v3 Announce Type: replace-cross 
Abstract: Modeling the rich prosodic variations inherent in human speech is essential for generating natural-sounding speech. While speaker embeddings are commonly used as conditioning inputs in personalized speech generation, they are typically optimized for speaker recognition, which encourages the loss of intra-speaker variation. This strategy makes them suboptimal for speech generation in terms of modeling the rich variations at the output speech distribution. In this work, we propose a novel speaker embedding network that employs multiple sub-centers per speaker class during training, instead of a single center as in conventional approaches. This sub-center modeling allows the embedding to capture a broader range of speaker-specific variations while maintaining speaker classification performance. We demonstrate the effectiveness of the proposed embeddings on a voice conversion task, showing improved naturalness and prosodic expressiveness in the synthesized speech.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2407.04291v3 ë°œí‘œ ìœ í˜•: êµì°¨ êµì²´  
ì´ˆë¡: ì¸ê°„ ìŒì„±ì— ë‚´ì¬ëœ í’ë¶€í•œ ìš´ìœ¨ ë³€í™”ë¥¼ ëª¨ë¸ë§í•˜ëŠ” ê²ƒì€ ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„±ì„ ìƒì„±í•˜ëŠ” ë° í•„ìˆ˜ì ì…ë‹ˆë‹¤. ê°œì¸í™”ëœ ìŒì„± ìƒì„±ì—ì„œ í™”ì ì„ë² ë”©ì€ ì¼ë°˜ì ìœ¼ë¡œ ì¡°ê±´ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©ë˜ì§€ë§Œ, ì´ëŠ” í™”ì ì¸ì‹ì„ ìœ„í•´ ìµœì í™”ë˜ì–´ ìˆì–´ í™”ì ë‚´ ë³€í™”ë¥¼ ìƒê²Œ ë§Œë“­ë‹ˆë‹¤. ì´ëŸ¬í•œ ì „ëµì€ ì¶œë ¥ ìŒì„± ë¶„í¬ì˜ í’ë¶€í•œ ë³€í™”ë¥¼ ëª¨ë¸ë§í•˜ëŠ” ì¸¡ë©´ì—ì„œ ìŒì„± ìƒì„±ì— ìµœì ì´ ì•„ë‹™ë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” ê¸°ì¡´ ì ‘ê·¼ ë°©ì‹ì—ì„œì™€ ê°™ì´ ë‹¨ì¼ ì¤‘ì‹¬ ëŒ€ì‹  í›ˆë ¨ ì¤‘ í™”ì í´ë˜ìŠ¤ë‹¹ ì—¬ëŸ¬ í•˜ìœ„ ì¤‘ì‹¬ì„ ì‚¬ìš©í•˜ëŠ” ìƒˆë¡œìš´ í™”ì ì„ë² ë”© ë„¤íŠ¸ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ í•˜ìœ„ ì¤‘ì‹¬ ëª¨ë¸ë§ì€ í™”ì ë¶„ë¥˜ ì„±ëŠ¥ì„ ìœ ì§€í•˜ë©´ì„œ ì„ë² ë”©ì´ í™”ì ê³ ìœ ì˜ ë³€í™”ë¥¼ ë” ë„“ê²Œ í¬ì°©í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì œì•ˆëœ ì„ë² ë”©ì˜ íš¨ê³¼ë¥¼ ìŒì„± ë³€í™˜ ì‘ì—…ì—ì„œ ì…ì¦í•˜ì˜€ìœ¼ë©°, í•©ì„±ëœ ìŒì„±ì—ì„œ ìì—°ìŠ¤ëŸ¬ì›€ê³¼ ìš´ìœ¨ í‘œí˜„ë ¥ì´ í–¥ìƒë¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì¸ê°„ ìŒì„±ì˜ í’ë¶€í•œ ìš´ìœ¨ ë³€í™”ë¥¼ ëª¨ë¸ë§í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„±ì„ ìƒì„±í•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ í™”ì ì„ë² ë”©ì€ ì£¼ë¡œ í™”ì ì¸ì‹ì— ìµœì í™”ë˜ì–´ ìˆì–´ í™”ì ë‚´ ë³€í™”ë¥¼ ì œëŒ€ë¡œ ë°˜ì˜í•˜ì§€ ëª»í•˜ëŠ” ë¬¸ì œì ì´ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ì €ìë“¤ì€ í™”ì í´ë˜ìŠ¤ë‹¹ ì—¬ëŸ¬ ê°œì˜ ì„œë¸Œì„¼í„°ë¥¼ ì‚¬ìš©í•˜ëŠ” ìƒˆë¡œìš´ í™”ì ì„ë² ë”© ë„¤íŠ¸ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ í™”ì ë¶„ë¥˜ ì„±ëŠ¥ì„ ìœ ì§€í•˜ë©´ì„œë„ í™”ì íŠ¹ìœ ì˜ ë‹¤ì–‘í•œ ë³€í™”ë¥¼ í¬ì°©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì œì•ˆëœ ì„ë² ë”©ì˜ íš¨ê³¼ëŠ” ìŒì„± ë³€í™˜ ì‘ì—…ì—ì„œ ì…ì¦ë˜ì—ˆìœ¼ë©°, ìƒì„±ëœ ìŒì„±ì˜ ìì—°ìŠ¤ëŸ¬ì›€ê³¼ ìš´ìœ¨ í‘œí˜„ë ¥ì´ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸


- 1. ì¸ê°„ ìŒì„±ì˜ í’ë¶€í•œ ìš´ìœ¨ ë³€í™”ë¥¼ ëª¨ë¸ë§í•˜ëŠ” ê²ƒì€ ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„± ìƒì„±ì„ ìœ„í•´ í•„ìˆ˜ì ì´ë‹¤.

- 2. ê¸°ì¡´ì˜ í™”ì ì„ë² ë”©ì€ í™”ì ì¸ì‹ì„ ìœ„í•´ ìµœì í™”ë˜ì–´ ìˆì–´ í™”ì ë‚´ ë³€í™”ë¥¼ ìƒê¸° ì‰½ë‹¤.

- 3. ë³¸ ì—°êµ¬ì—ì„œëŠ” í™”ì í´ë˜ìŠ¤ ë‹¹ ì—¬ëŸ¬ ê°œì˜ ì„œë¸Œ ì„¼í„°ë¥¼ ì‚¬ìš©í•˜ëŠ” ìƒˆë¡œìš´ í™”ì ì„ë² ë”© ë„¤íŠ¸ì›Œí¬ë¥¼ ì œì•ˆí•œë‹¤.

- 4. ì œì•ˆëœ ì„ë² ë”©ì€ í™”ì ë¶„ë¥˜ ì„±ëŠ¥ì„ ìœ ì§€í•˜ë©´ì„œ í™”ì íŠ¹ìœ ì˜ ë³€í™”ë¥¼ ë” ë„“ê²Œ í¬ì°©í•  ìˆ˜ ìˆë‹¤.

- 5. ìŒì„± ë³€í™˜ ì‘ì—…ì—ì„œ ì œì•ˆëœ ì„ë² ë”©ì˜ íš¨ê³¼ë¥¼ ì…ì¦í•˜ì˜€ìœ¼ë©°, í•©ì„±ëœ ìŒì„±ì˜ ìì—°ìŠ¤ëŸ¬ì›€ê³¼ ìš´ìœ¨ í‘œí˜„ë ¥ì´ í–¥ìƒë˜ì—ˆë‹¤.


---

*Generated on 2025-09-22 16:06:52*