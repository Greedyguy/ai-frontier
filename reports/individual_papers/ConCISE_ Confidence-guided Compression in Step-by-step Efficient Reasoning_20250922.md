# ConCISE: Confidence-guided Compression in Step-by-step Efficient Reasoning

**Korean Title:** ConCISE: ë‹¨ê³„ë³„ íš¨ìœ¨ì ì¸ ì¶”ë¡ ì—ì„œ ì‹ ë¢°ë„ ê¸°ë°˜ ì••ì¶•

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Confidence Guided Compression

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/Early Stopping Chain-of-thoughts in Large Language Models_20250918|Early Stopping Chain-of-thoughts in Large Language Models]] (87.0% similar)
- [[2025-09-17/Reasoning Efficiently Through Adaptive Chain-of-Thought Compression_ A Self-Optimizing Framework_20250917|Reasoning Efficiently Through Adaptive Chain-of-Thought Compression A Self-Optimizing Framework]] (86.9% similar)
- [[2025-09-19/Understanding the Thinking Process of Reasoning Models_ A Perspective from Schoenfeld's Episode Theory_20250919|Understanding the Thinking Process of Reasoning Models A Perspective from Schoenfeld's Episode Theory]] (85.3% similar)
- [[2025-09-22/FLARE_ Faithful Logic-Aided Reasoning and Exploration_20250922|FLARE Faithful Logic-Aided Reasoning and Exploration]] (84.2% similar)
- [[2025-09-17/Slim-SC_ Thought Pruning for Efficient Scaling with Self-Consistency_20250917|Slim-SC Thought Pruning for Efficient Scaling with Self-Consistency]] (83.4% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2505.04881v2 Announce Type: replace-cross 
Abstract: Large Reasoning Models (LRMs) perform strongly in complex reasoning tasks via Chain-of-Thought (CoT) prompting, but often suffer from verbose outputs, increasing computational overhead. Existing fine-tuning-based compression methods either operate post-hoc pruning, risking disruption to reasoning coherence, or rely on sampling-based selection, which fails to remove redundant content thoroughly. To address these limitations, this work begins by framing two key patterns of redundant reflection in LRMs--Confidence Deficit, wherein the model reflects on correct intermediate steps, and Termination Delay, where reflection continues after a verified, confident answer--through a confidence-guided perspective. Based on this, we introduce ConCISE (Confidence-guided Compression In Step-by-step Efficient Reasoning), a framework designed to generate concise reasoning chains, integrating Confidence Injection to boost reasoning confidence, and Early Stopping to terminate reasoning when confidence is sufficient. Extensive experiments demonstrate that compared to baseline methods, fine-tuning LRMs on ConCISE-generated data yields a better balance between compression and task performance, reducing length by up to approximately 50% under SimPO, while maintaining high task accuracy.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2505.04881v2 ë°œí‘œ ìœ í˜•: êµì°¨ êµì²´  
ì´ˆë¡: ëŒ€ê·œëª¨ ì¶”ë¡  ëª¨ë¸(LRMs)ì€ ì—°ì‡„ ì‚¬ê³ (Chain-of-Thought, CoT) ìœ ë„ë¥¼ í†µí•´ ë³µì¡í•œ ì¶”ë¡  ì‘ì—…ì—ì„œ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ì§€ë§Œ, ì¢…ì¢… ì¥í™©í•œ ì¶œë ¥ìœ¼ë¡œ ì¸í•´ ê³„ì‚°ì  ë¶€ë‹´ì´ ì¦ê°€í•˜ëŠ” ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ê¸°ì¡´ì˜ ë¯¸ì„¸ ì¡°ì • ê¸°ë°˜ ì••ì¶• ë°©ë²•ì€ ì‚¬í›„ ê°€ì§€ì¹˜ê¸°ë¥¼ ìˆ˜í–‰í•˜ì—¬ ì¶”ë¡ ì˜ ì¼ê´€ì„±ì„ í•´ì¹  ìœ„í—˜ì´ ìˆê±°ë‚˜, ìƒ˜í”Œë§ ê¸°ë°˜ ì„ íƒì— ì˜ì¡´í•˜ì—¬ ë¶ˆí•„ìš”í•œ ë‚´ìš©ì„ ì² ì €íˆ ì œê±°í•˜ì§€ ëª»í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ í•œê³„ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ë³¸ ì—°êµ¬ëŠ” LRMsì—ì„œì˜ ë‘ ê°€ì§€ ì£¼ìš” ì¤‘ë³µ ë°˜ì˜ íŒ¨í„´ì„ ìì‹ ê° ê²°í•(Confidence Deficit)ê³¼ ì¢…ë£Œ ì§€ì—°(Termination Delay)ìœ¼ë¡œ ì •ì˜í•©ë‹ˆë‹¤. ìì‹ ê° ê²°í•ì€ ëª¨ë¸ì´ ì˜¬ë°”ë¥¸ ì¤‘ê°„ ë‹¨ê³„ë¥¼ ë°˜ì˜í•˜ëŠ” ê²½ìš°ë¥¼, ì¢…ë£Œ ì§€ì—°ì€ í™•ì¸ëœ ìì‹ ê° ìˆëŠ” ë‹µë³€ ì´í›„ì—ë„ ë°˜ì˜ì´ ê³„ì†ë˜ëŠ” ê²½ìš°ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ, ìš°ë¦¬ëŠ” ìì‹ ê° ìœ ë„ ì••ì¶•ì„ í†µí•œ ë‹¨ê³„ë³„ íš¨ìœ¨ì  ì¶”ë¡ (ConCISE)ì´ë¼ëŠ” í”„ë ˆì„ì›Œí¬ë¥¼ ë„ì…í•˜ì—¬, ì¶”ë¡  ìì‹ ê°ì„ ë†’ì´ê¸° ìœ„í•œ ìì‹ ê° ì£¼ì…(Confidence Injection)ê³¼ ì¶©ë¶„í•œ ìì‹ ê°ì´ ìˆì„ ë•Œ ì¶”ë¡ ì„ ì¢…ë£Œí•˜ëŠ” ì¡°ê¸° ì¢…ë£Œ(Early Stopping)ë¥¼ í†µí•©í•˜ì—¬ ê°„ê²°í•œ ì¶”ë¡  ì²´ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤. ê´‘ë²”ìœ„í•œ ì‹¤í—˜ ê²°ê³¼, ConCISEë¡œ ìƒì„±ëœ ë°ì´í„°ë¡œ LRMsì„ ë¯¸ì„¸ ì¡°ì •í•˜ë©´, ê¸°ì¡´ ë°©ë²•ì— ë¹„í•´ ì••ì¶•ê³¼ ì‘ì—… ì„±ëŠ¥ ê°„ì˜ ê· í˜•ì´ ê°œì„ ë˜ë©°, SimPO í•˜ì—ì„œ ê¸¸ì´ë¥¼ ì•½ 50%ê¹Œì§€ ì¤„ì´ë©´ì„œë„ ë†’ì€ ì‘ì—… ì •í™•ë„ë¥¼ ìœ ì§€í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€ê·œëª¨ ì¶”ë¡  ëª¨ë¸(LRMs)ì˜ ë³µì¡í•œ ì¶”ë¡  ì‘ì—…ì—ì„œ ë°œìƒí•˜ëŠ” ì¥í™©í•œ ì¶œë ¥ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ConCISEë¼ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ì••ì¶• ë°©ë²•ì€ ì¶”ë¡ ì˜ ì¼ê´€ì„±ì„ í•´ì¹˜ê±°ë‚˜ ì¤‘ë³µ ë‚´ìš©ì„ ì™„ì „íˆ ì œê±°í•˜ì§€ ëª»í•˜ëŠ” í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤. ConCISEëŠ” Confidence Injectionê³¼ Early Stoppingì„ í†µí•´ ì¶”ë¡ ì˜ ìì‹ ê°ì„ ë†’ì´ê³  ë¶ˆí•„ìš”í•œ ë°˜ì˜ì„ ì¤„ì…ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ConCISEë¥¼ ì‚¬ìš©í•œ ëª¨ë¸ì€ ê¸°ì¡´ ë°©ë²•ì— ë¹„í•´ ì¶œë ¥ ê¸¸ì´ë¥¼ ìµœëŒ€ 50% ì¤„ì´ë©´ì„œë„ ë†’ì€ ì •í™•ë„ë¥¼ ìœ ì§€í•˜ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€ê·œëª¨ ì¶”ë¡  ëª¨ë¸(LRMs)ì€ ë³µì¡í•œ ì¶”ë¡  ì‘ì—…ì—ì„œ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë³´ì´ì§€ë§Œ, ì¥í™©í•œ ì¶œë ¥ìœ¼ë¡œ ì¸í•´ ê³„ì‚°ì  ë¶€ë‹´ì´ ì¦ê°€í•˜ëŠ” ë¬¸ì œê°€ ìˆë‹¤.

- 2. ê¸°ì¡´ì˜ ì••ì¶• ë°©ë²•ì€ ì¶”ë¡ ì˜ ì¼ê´€ì„±ì„ í•´ì¹  ìœ„í—˜ì´ ìˆëŠ” ì‚¬í›„ ê°€ì§€ì¹˜ê¸°ë‚˜ ì¤‘ë³µ ì½˜í…ì¸ ë¥¼ ì™„ì „íˆ ì œê±°í•˜ì§€ ëª»í•˜ëŠ” ìƒ˜í”Œë§ ê¸°ë°˜ ì„ íƒì— ì˜ì¡´í•œë‹¤.

- 3. ë³¸ ì—°êµ¬ëŠ” Confidence Deficitê³¼ Termination Delayë¼ëŠ” ë‘ ê°€ì§€ ì¤‘ë³µ ë°˜ì˜ íŒ¨í„´ì„ ì‹ë³„í•˜ê³ , ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ Confidence Injectionê³¼ Early Stoppingì„ í†µí•©í•œ ConCISE í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•œë‹¤.

- 4. ConCISEëŠ” ì¶”ë¡ ì˜ ìì‹ ê°ì„ ë†’ì´ê³ , ì¶©ë¶„í•œ ìì‹ ê°ì´ ìˆì„ ë•Œ ì¶”ë¡ ì„ ì¡°ê¸°ì— ì¢…ë£Œí•˜ì—¬ ê°„ê²°í•œ ì¶”ë¡  ì²´ì¸ì„ ìƒì„±í•œë‹¤.

- 5. ì‹¤í—˜ ê²°ê³¼, ConCISEë¥¼ ì‚¬ìš©í•œ ë¯¸ì„¸ ì¡°ì •ì€ ê¸°ì¡´ ë°©ë²•ì— ë¹„í•´ ì•½ 50%ì˜ ê¸¸ì´ ê°ì†Œì™€ ë†’ì€ ì‘ì—… ì •í™•ì„±ì„ ìœ ì§€í•˜ë©° ì••ì¶•ê³¼ ì‘ì—… ì„±ëŠ¥ ê°„ì˜ ê· í˜•ì„ ë” ì˜ ë§ì¶˜ë‹¤.

---

*Generated on 2025-09-22 14:46:55*