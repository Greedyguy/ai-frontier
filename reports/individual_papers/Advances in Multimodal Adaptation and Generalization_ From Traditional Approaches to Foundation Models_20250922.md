# Advances in Multimodal Adaptation and Generalization: From Traditional Approaches to Foundation Models

**Korean Title:** ë‹¤ì¤‘ ëª¨ë“œ ì ì‘ ë° ì¼ë°˜í™”ì˜ ë°œì „: ì „í†µì  ì ‘ê·¼ë²•ì—ì„œ ê¸°ì´ˆ ëª¨ë¸ê¹Œì§€

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Adaptation of Foundation Models

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/MMAPG_ A Training-Free Framework for Multimodal Multi-hop Question Answering via Adaptive Planning Graphs_20250922|MMAPG A Training-Free Framework for Multimodal Multi-hop Question Answering via Adaptive Planning Graphs]] (83.7% similar)
- [[2025-09-18/Singular Value Few-shot Adaptation of Vision-Language Models_20250918|Singular Value Few-shot Adaptation of Vision-Language Models]] (82.9% similar)
- [[2025-09-17/Class-invariant Test-Time Augmentation for Domain Generalization_20250917|Class-invariant Test-Time Augmentation for Domain Generalization]] (82.8% similar)
- [[2025-09-22/Towards deployment-centric multimodal AI beyond vision and language_20250922|Towards deployment-centric multimodal AI beyond vision and language]] (82.1% similar)
- [[2025-09-22/Beyond Spurious Signals_ Debiasing Multimodal Large Language Models via Counterfactual Inference and Adaptive Expert Routing_20250922|Beyond Spurious Signals Debiasing Multimodal Large Language Models via Counterfactual Inference and Adaptive Expert Routing]] (81.6% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2501.18592v4 Announce Type: replace-cross 
Abstract: In real-world scenarios, achieving domain adaptation and generalization poses significant challenges, as models must adapt to or generalize across unknown target distributions. Extending these capabilities to unseen multimodal distributions, i.e., multimodal domain adaptation and generalization, is even more challenging due to the distinct characteristics of different modalities. Significant progress has been made over the years, with applications ranging from action recognition to semantic segmentation. Besides, the recent advent of large-scale pre-trained multimodal foundation models, such as CLIP, has inspired works leveraging these models to enhance adaptation and generalization performances or adapting them to downstream tasks. This survey provides the first comprehensive review of recent advances from traditional approaches to foundation models, covering: (1) Multimodal domain adaptation; (2) Multimodal test-time adaptation; (3) Multimodal domain generalization; (4) Domain adaptation and generalization with the help of multimodal foundation models; and (5) Adaptation of multimodal foundation models. For each topic, we formally define the problem and thoroughly review existing methods. Additionally, we analyze relevant datasets and applications, highlighting open challenges and potential future research directions. We maintain an active repository that contains up-to-date literature at https://github.com/donghao51/Awesome-Multimodal-Adaptation.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2501.18592v4 ë°œí‘œ ìœ í˜•: êµì°¨ êµì²´  
ì´ˆë¡: ì‹¤ì œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ë„ë©”ì¸ ì ì‘ê³¼ ì¼ë°˜í™”ë¥¼ ë‹¬ì„±í•˜ëŠ” ê²ƒì€ ëª¨ë¸ì´ ì•Œë ¤ì§€ì§€ ì•Šì€ ëŒ€ìƒ ë¶„í¬ì— ì ì‘í•˜ê±°ë‚˜ ì´ë¥¼ ì¼ë°˜í™”í•´ì•¼ í•˜ë¯€ë¡œ ìƒë‹¹í•œ ë„ì „ ê³¼ì œë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ê¸°ëŠ¥ì„ ë³´ì§€ ëª»í•œ ë‹¤ì¤‘ ëª¨ë‹¬ ë¶„í¬, ì¦‰ ë‹¤ì¤‘ ëª¨ë‹¬ ë„ë©”ì¸ ì ì‘ ë° ì¼ë°˜í™”ë¡œ í™•ì¥í•˜ëŠ” ê²ƒì€ ì„œë¡œ ë‹¤ë¥¸ ëª¨ë‹¬ë¦¬í‹°ì˜ íŠ¹ì„± ë•Œë¬¸ì— ë”ìš± ì–´ë µìŠµë‹ˆë‹¤. í–‰ë™ ì¸ì‹ì—ì„œ ì˜ë¯¸ë¡ ì  ë¶„í• ì— ì´ë¥´ê¸°ê¹Œì§€ ë‹¤ì–‘í•œ ì‘ìš© ë¶„ì•¼ì—ì„œ ìˆ˜ë…„ê°„ ìƒë‹¹í•œ ì§„ì „ì´ ìˆì—ˆìŠµë‹ˆë‹¤. ë˜í•œ, CLIPê³¼ ê°™ì€ ëŒ€ê·œëª¨ ì‚¬ì „ í•™ìŠµëœ ë‹¤ì¤‘ ëª¨ë‹¬ ê¸°ì´ˆ ëª¨ë¸ì˜ ìµœê·¼ ì¶œí˜„ì€ ì´ëŸ¬í•œ ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ì ì‘ ë° ì¼ë°˜í™” ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê±°ë‚˜ ì´ë¥¼ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—…ì— ì ì‘ì‹œí‚¤ëŠ” ì—°êµ¬ì— ì˜ê°ì„ ì£¼ì—ˆìŠµë‹ˆë‹¤. ì´ ì„¤ë¬¸ ì¡°ì‚¬ëŠ” ì „í†µì ì¸ ì ‘ê·¼ ë°©ì‹ë¶€í„° ê¸°ì´ˆ ëª¨ë¸ì— ì´ë¥´ê¸°ê¹Œì§€ ìµœê·¼ì˜ ë°œì „ì„ í¬ê´„ì ìœ¼ë¡œ ê²€í† í•œ ì²« ë²ˆì§¸ ì—°êµ¬ë¡œ, (1) ë‹¤ì¤‘ ëª¨ë‹¬ ë„ë©”ì¸ ì ì‘; (2) ë‹¤ì¤‘ ëª¨ë‹¬ í…ŒìŠ¤íŠ¸ ì‹œ ì ì‘; (3) ë‹¤ì¤‘ ëª¨ë‹¬ ë„ë©”ì¸ ì¼ë°˜í™”; (4) ë‹¤ì¤‘ ëª¨ë‹¬ ê¸°ì´ˆ ëª¨ë¸ì„ í™œìš©í•œ ë„ë©”ì¸ ì ì‘ ë° ì¼ë°˜í™”; (5) ë‹¤ì¤‘ ëª¨ë‹¬ ê¸°ì´ˆ ëª¨ë¸ì˜ ì ì‘ì„ ë‹¤ë£¹ë‹ˆë‹¤. ê° ì£¼ì œì— ëŒ€í•´ ë¬¸ì œë¥¼ ê³µì‹ì ìœ¼ë¡œ ì •ì˜í•˜ê³  ê¸°ì¡´ ë°©ë²•ì„ ì² ì €íˆ ê²€í† í•©ë‹ˆë‹¤. ë˜í•œ, ê´€ë ¨ ë°ì´í„°ì…‹ê³¼ ì‘ìš© í”„ë¡œê·¸ë¨ì„ ë¶„ì„í•˜ê³ , í•´ê²°ë˜ì§€ ì•Šì€ ê³¼ì œì™€ ì ì¬ì ì¸ ë¯¸ë˜ ì—°êµ¬ ë°©í–¥ì„ ê°•ì¡°í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ìµœì‹  ë¬¸í—Œì„ í¬í•¨í•˜ëŠ” í™œì„± ì €ì¥ì†Œë¥¼ https://github.com/donghao51/Awesome-Multimodal-Adaptationì—ì„œ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì‹¤ì œ í™˜ê²½ì—ì„œ ë„ë©”ì¸ ì ì‘ ë° ì¼ë°˜í™”ì˜ ì–´ë ¤ì›€ì„ ë‹¤ë£¨ë©°, íŠ¹íˆ ë‹¤ì–‘í•œ ëª¨ë‹¬ë¦¬í‹°ì˜ íŠ¹ì„±ìœ¼ë¡œ ì¸í•´ ë”ìš± ë³µì¡í•œ ë‹¤ì¤‘ ëª¨ë‹¬ ë„ë©”ì¸ ì ì‘ ë° ì¼ë°˜í™”ì— ì¤‘ì ì„ ë‘¡ë‹ˆë‹¤. ìµœê·¼ ëŒ€ê·œëª¨ ì‚¬ì „ í•™ìŠµëœ ë‹¤ì¤‘ ëª¨ë‹¬ ëª¨ë¸(CLIP ë“±)ì˜ ë“±ì¥ì€ ì ì‘ ë° ì¼ë°˜í™” ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê±°ë‚˜ í•˜ìœ„ ì‘ì—…ì— ì ìš©í•˜ëŠ” ì—°êµ¬ë¥¼ ì´‰ì§„í–ˆìŠµë‹ˆë‹¤. ì´ ì„¤ë¬¸ ì—°êµ¬ëŠ” ì „í†µì  ì ‘ê·¼ë²•ë¶€í„° ìµœì‹  ëª¨ë¸ê¹Œì§€ì˜ ë°œì „ì„ í¬ê´„ì ìœ¼ë¡œ ê²€í† í•˜ë©°, ë‹¤ì¤‘ ëª¨ë‹¬ ë„ë©”ì¸ ì ì‘, í…ŒìŠ¤íŠ¸ ì‹œ ì ì‘, ì¼ë°˜í™”, ê·¸ë¦¬ê³  ê¸°ì´ˆ ëª¨ë¸ì„ í™œìš©í•œ ì ì‘ ë° ì¼ë°˜í™” ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤. ê° ì£¼ì œì— ëŒ€í•´ ë¬¸ì œ ì •ì˜ì™€ ê¸°ì¡´ ë°©ë²•ì„ ê²€í† í•˜ê³ , ê´€ë ¨ ë°ì´í„°ì…‹ê³¼ ì‘ìš©ì„ ë¶„ì„í•˜ë©°, í•´ê²°ë˜ì§€ ì•Šì€ ë¬¸ì œì™€ ë¯¸ë˜ ì—°êµ¬ ë°©í–¥ì„ ì œì‹œí•©ë‹ˆë‹¤. ìµœì‹  ë¬¸í—Œì„ í¬í•¨í•œ ë¦¬í¬ì§€í† ë¦¬ë¥¼ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì‹¤ì œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ë„ë©”ì¸ ì ì‘ ë° ì¼ë°˜í™”ëŠ” ë¯¸ì§€ì˜ ëŒ€ìƒ ë¶„í¬ì— ì ì‘í•˜ê±°ë‚˜ ì¼ë°˜í™”í•´ì•¼ í•˜ë¯€ë¡œ í° ë„ì „ ê³¼ì œë¥¼ ì œì‹œí•©ë‹ˆë‹¤.

- 2. ë¯¸ì§€ì˜ ë‹¤ì¤‘ ëª¨ë‹¬ ë¶„í¬ì— ëŒ€í•œ ì ì‘ ë° ì¼ë°˜í™”ëŠ” ì„œë¡œ ë‹¤ë¥¸ ëª¨ë‹¬ë¦¬í‹°ì˜ íŠ¹ì„± ë•Œë¬¸ì— ë”ìš± ì–´ë µìŠµë‹ˆë‹¤.

- 3. ìµœê·¼ ëŒ€ê·œëª¨ ì‚¬ì „ í•™ìŠµëœ ë‹¤ì¤‘ ëª¨ë‹¬ ê¸°ì´ˆ ëª¨ë¸ì˜ ë“±ì¥ì€ ì ì‘ ë° ì¼ë°˜í™” ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê±°ë‚˜ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—…ì— ì ì‘ì‹œí‚¤ëŠ” ì—°êµ¬ì— ì˜ê°ì„ ì£¼ì—ˆìŠµë‹ˆë‹¤.

- 4. ì´ ì„¤ë¬¸ ì¡°ì‚¬ëŠ” ì „í†µì ì¸ ì ‘ê·¼ ë°©ì‹ì—ì„œ ê¸°ì´ˆ ëª¨ë¸ì— ì´ë¥´ëŠ” ìµœê·¼ ë°œì „ì„ í¬ê´„ì ìœ¼ë¡œ ê²€í† í•©ë‹ˆë‹¤.

- 5. ê´€ë ¨ ë°ì´í„°ì…‹ ë° ì‘ìš© í”„ë¡œê·¸ë¨ì„ ë¶„ì„í•˜ê³ , í•´ê²°ë˜ì§€ ì•Šì€ ê³¼ì œì™€ ì ì¬ì ì¸ ë¯¸ë˜ ì—°êµ¬ ë°©í–¥ì„ ê°•ì¡°í•©ë‹ˆë‹¤.

---

*Generated on 2025-09-22 14:41:48*