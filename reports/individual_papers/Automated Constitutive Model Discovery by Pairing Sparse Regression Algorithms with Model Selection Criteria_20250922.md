# Automated Constitutive Model Discovery by Pairing Sparse Regression Algorithms with Model Selection Criteria

**Korean Title:** í¬ì†Œ íšŒê·€ ì•Œê³ ë¦¬ì¦˜ê³¼ ëª¨ë¸ ì„ íƒ ê¸°ì¤€ì„ ê²°í•©í•œ ìë™ êµ¬ì„± ëª¨ë¸ ë°œê²¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: Constitutive Model Discovery

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/An Equivariant Graph Network for Interpretable Nanoporous Materials Design_20250922|An Equivariant Graph Network for Interpretable Nanoporous Materials Design]] (79.7% similar)
- [[2025-09-19/MOLE_ Metadata Extraction and Validation in Scientific Papers Using LLMs_20250919|MOLE Metadata Extraction and Validation in Scientific Papers Using LLMs]] (79.2% similar)
- [[2025-09-18/Towards universal property prediction in Cartesian space_ TACE is all you need_20250918|Towards universal property prediction in Cartesian space TACE is all you need]] (78.5% similar)
- [[2025-09-18/Physics-Informed GCN-LSTM Framework for Long-Term Forecasting of 2D and 3D Microstructure Evolution_20250918|Physics-Informed GCN-LSTM Framework for Long-Term Forecasting of 2D and 3D Microstructure Evolution]] (78.2% similar)
- [[2025-09-19/Evolution of Kernels_ Automated RISC-V Kernel Optimization with Large Language Models_20250919|Evolution of Kernels Automated RISC-V Kernel Optimization with Large Language Models]] (77.4% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16040v1 Announce Type: new 
Abstract: The automated discovery of constitutive models from data has recently emerged as a promising alternative to the traditional model calibration paradigm. In this work, we present a fully automated framework for constitutive model discovery that systematically pairs three sparse regression algorithms (Least Absolute Shrinkage and Selection Operator (LASSO), Least Angle Regression (LARS), and Orthogonal Matching Pursuit (OMP)) with three model selection criteria: $K$-fold cross-validation (CV), Akaike Information Criterion (AIC), and Bayesian Information Criterion (BIC). This pairing yields nine distinct algorithms for model discovery and enables a systematic exploration of the trade-off between sparsity, predictive performance, and computational cost. While LARS serves as an efficient path-based solver for the $\ell_1$-constrained problem, OMP is introduced as a tractable heuristic for $\ell_0$-regularized selection. The framework is applied to both isotropic and anisotropic hyperelasticity, utilizing both synthetic and experimental datasets. Results reveal that all nine algorithm-criterion combinations perform consistently well for the discovery of isotropic and anisotropic materials, yielding highly accurate constitutive models. These findings broaden the range of viable discovery algorithms beyond $\ell_1$-based approaches such as LASSO.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.16040v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: ë°ì´í„°ë¡œë¶€í„° êµ¬ì„± ëª¨ë¸ì„ ìë™ìœ¼ë¡œ ë°œê²¬í•˜ëŠ” ë°©ë²•ì€ ìµœê·¼ ì „í†µì ì¸ ëª¨ë¸ ë³´ì • íŒ¨ëŸ¬ë‹¤ì„ì— ëŒ€í•œ ìœ ë§í•œ ëŒ€ì•ˆìœ¼ë¡œ ë¶€ìƒí•˜ê³  ìˆìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” êµ¬ì„± ëª¨ë¸ ë°œê²¬ì„ ìœ„í•œ ì™„ì „ ìë™í™”ëœ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì‹œí•˜ë©°, ì´ëŠ” ì„¸ ê°€ì§€ í¬ì†Œ íšŒê·€ ì•Œê³ ë¦¬ì¦˜(ìµœì†Œ ì ˆëŒ€ ìˆ˜ì¶• ë° ì„ íƒ ì—°ì‚°ì(LASSO), ìµœì†Œ ê° íšŒê·€(LARS), ì§êµ ë§¤ì¹­ ì¶”êµ¬(OMP))ë¥¼ ì„¸ ê°€ì§€ ëª¨ë¸ ì„ íƒ ê¸°ì¤€($K$-ê²¹ êµì°¨ ê²€ì¦(CV), Akaike ì •ë³´ ê¸°ì¤€(AIC), ë² ì´ì§€ì•ˆ ì •ë³´ ê¸°ì¤€(BIC))ê³¼ ì²´ê³„ì ìœ¼ë¡œ ì§ì§€ì–´ì¤ë‹ˆë‹¤. ì´ëŸ¬í•œ ì¡°í•©ì€ ëª¨ë¸ ë°œê²¬ì„ ìœ„í•œ ì•„í™‰ ê°€ì§€ ë…íŠ¹í•œ ì•Œê³ ë¦¬ì¦˜ì„ ì œê³µí•˜ë©°, í¬ì†Œì„±, ì˜ˆì¸¡ ì„±ëŠ¥, ê³„ì‚° ë¹„ìš© ê°„ì˜ ì ˆì¶©ì„ ì²´ê³„ì ìœ¼ë¡œ íƒìƒ‰í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤. LARSëŠ” $\ell_1$-ì œì•½ ë¬¸ì œì— ëŒ€í•œ íš¨ìœ¨ì ì¸ ê²½ë¡œ ê¸°ë°˜ í•´ë²•ìœ¼ë¡œ ì‘ìš©í•˜ëŠ” ë°˜ë©´, OMPëŠ” $\ell_0$-ì •ê·œí™” ì„ íƒì— ëŒ€í•œ ì‹¤ìš©ì ì¸ íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ ë„ì…ë©ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” í•©ì„± ë° ì‹¤í—˜ ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬ ë“±ë°©ì„± ë° ì´ë°©ì„± ì´ˆíƒ„ì„±ì— ì ìš©ë©ë‹ˆë‹¤. ê²°ê³¼ëŠ” ì•„í™‰ ê°€ì§€ ì•Œê³ ë¦¬ì¦˜-ê¸°ì¤€ ì¡°í•©ì´ ë“±ë°©ì„± ë° ì´ë°©ì„± ì¬ë£Œ ë°œê²¬ì— ëŒ€í•´ ì¼ê´€ë˜ê²Œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ë©°, ë§¤ìš° ì •í™•í•œ êµ¬ì„± ëª¨ë¸ì„ ì‚°ì¶œí•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŸ¬í•œ ë°œê²¬ì€ LASSOì™€ ê°™ì€ $\ell_1$ ê¸°ë°˜ ì ‘ê·¼ë²•ì„ ë„˜ì–´ì„œëŠ” ë‹¤ì–‘í•œ ìœ íš¨í•œ ë°œê²¬ ì•Œê³ ë¦¬ì¦˜ì˜ ë²”ìœ„ë¥¼ í™•ì¥í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë°ì´í„°ë¡œë¶€í„° êµ¬ì„± ëª¨ë¸ì„ ìë™ìœ¼ë¡œ ë°œê²¬í•˜ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. LASSO, LARS, OMP ì„¸ ê°€ì§€ í¬ì†Œ íšŒê·€ ì•Œê³ ë¦¬ì¦˜ê³¼ $K$-ê²¹ êµì°¨ ê²€ì¦, AIC, BIC ì„¸ ê°€ì§€ ëª¨ë¸ ì„ íƒ ê¸°ì¤€ì„ ì¡°í•©í•˜ì—¬ ì´ ì•„í™‰ ê°€ì§€ ì•Œê³ ë¦¬ì¦˜ì„ ê°œë°œí–ˆìŠµë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” í¬ì†Œì„±, ì˜ˆì¸¡ ì„±ëŠ¥, ê³„ì‚° ë¹„ìš© ê°„ì˜ ê· í˜•ì„ ì²´ê³„ì ìœ¼ë¡œ íƒìƒ‰í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤. íŠ¹íˆ, LARSëŠ” íš¨ìœ¨ì ì¸ ê²½ë¡œ ê¸°ë°˜ í•´ë²•ì„ ì œê³µí•˜ê³ , OMPëŠ” $\ell_0$-ì •ê·œí™” ì„ íƒì„ ìœ„í•œ ì‹¤ìš©ì ì¸ ë°©ë²•ìœ¼ë¡œ ì†Œê°œë©ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ë“±ë°©ì„± ë° ë¹„ë“±ë°©ì„± ì´ˆíƒ„ì„± ì¬ë£Œì— ì ìš©ë˜ì—ˆìœ¼ë©°, ëª¨ë“  ì•Œê³ ë¦¬ì¦˜-ê¸°ì¤€ ì¡°í•©ì´ ë†’ì€ ì •í™•ë„ì˜ êµ¬ì„± ëª¨ë¸ì„ ì¼ê´€ë˜ê²Œ ë°œê²¬í•˜ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” $\ell_1$ ê¸°ë°˜ ì ‘ê·¼ë²•ì„ ë„˜ì–´ ë‹¤ì–‘í•œ ë°œê²¬ ì•Œê³ ë¦¬ì¦˜ì˜ ê°€ëŠ¥ì„±ì„ í™•ì¥í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë°ì´í„° ê¸°ë°˜ì˜ êµ¬ì„± ëª¨ë¸ ìë™ ë°œê²¬ì´ ì „í†µì ì¸ ëª¨ë¸ ë³´ì • íŒ¨ëŸ¬ë‹¤ì„ì˜ ìœ ë§í•œ ëŒ€ì•ˆìœ¼ë¡œ ë¶€ìƒí•˜ê³  ìˆìŠµë‹ˆë‹¤.

- 2. ë³¸ ì—°êµ¬ëŠ” LASSO, LARS, OMP ì„¸ ê°€ì§€ í¬ì†Œ íšŒê·€ ì•Œê³ ë¦¬ì¦˜ê³¼ CV, AIC, BIC ì„¸ ê°€ì§€ ëª¨ë¸ ì„ íƒ ê¸°ì¤€ì„ ì²´ê³„ì ìœ¼ë¡œ ê²°í•©í•œ ì™„ì „ ìë™í™”ëœ êµ¬ì„± ëª¨ë¸ ë°œê²¬ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.

- 3. ì´ í”„ë ˆì„ì›Œí¬ëŠ” í¬ì†Œì„±, ì˜ˆì¸¡ ì„±ëŠ¥, ê³„ì‚° ë¹„ìš© ê°„ì˜ ê· í˜•ì„ ì²´ê³„ì ìœ¼ë¡œ íƒìƒ‰í•  ìˆ˜ ìˆëŠ” ì•„í™‰ ê°€ì§€ ì•Œê³ ë¦¬ì¦˜ì„ ì œê³µí•©ë‹ˆë‹¤.

- 4. ì œì•ˆëœ í”„ë ˆì„ì›Œí¬ëŠ” ë“±ë°©ì„± ë° ì´ë°©ì„± ì´ˆíƒ„ì„± ì†Œì¬ì— ì ìš©ë˜ì–´ ë§¤ìš° ì •í™•í•œ êµ¬ì„± ëª¨ë¸ì„ ë°œê²¬í•˜ëŠ” ë° ì„±ê³µí–ˆìŠµë‹ˆë‹¤.

- 5. ì—°êµ¬ ê²°ê³¼ëŠ” LASSOì™€ ê°™ì€ $\ell_1$ ê¸°ë°˜ ì ‘ê·¼ë²•ì„ ë„˜ì–´ ë‹¤ì–‘í•œ ë°œê²¬ ì•Œê³ ë¦¬ì¦˜ì˜ ê°€ëŠ¥ì„±ì„ í™•ì¥í•©ë‹ˆë‹¤.

---

*Generated on 2025-09-22 15:30:49*