# Mental Accounts for Actions: EWA-Inspired Attention in Decision Transformers

**Korean Title:** í–‰ë™ì— ëŒ€í•œ ì •ì‹ ì  ê³„ì¢Œ: ê²°ì • ë³€í™˜ê¸°ì—ì„œ EWA ì˜ê°ì„ ë°›ì€ ì£¼ì˜ë ¥

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Entropy-Regularized Training

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-17/Large Language Model-Empowered Decision Transformer for UAV-Enabled Data Collection_20250917|Large Language Model-Empowered Decision Transformer for UAV-Enabled Data Collection]] (80.7% similar)
- [[2025-09-22/Attention Schema-based Attention Control (ASAC)_ A Cognitive-Inspired Approach for Attention Management in Transformers_20250922|Attention Schema-based Attention Control (ASAC) A Cognitive-Inspired Approach for Attention Management in Transformers]] (80.3% similar)
- [[2025-09-22/AttentionDrop_ A Novel Regularization Method for Transformer Models_20250922|AttentionDrop A Novel Regularization Method for Transformer Models]] (80.1% similar)
- [[2025-09-17/TGPO_ Tree-Guided Preference Optimization for Robust Web Agent Reinforcement Learning_20250917|TGPO Tree-Guided Preference Optimization for Robust Web Agent Reinforcement Learning]] (80.0% similar)
- [[2025-09-18/TDRM_ Smooth Reward Models with Temporal Difference for LLM RL and Inference_20250918|TDRM Smooth Reward Models with Temporal Difference for LLM RL and Inference]] (79.9% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15498v1 Announce Type: new 
Abstract: Transformers have emerged as a compelling architecture for sequential decision-making by modeling trajectories via self-attention. In reinforcement learning (RL), they enable return-conditioned control without relying on value function approximation. Decision Transformers (DTs) exploit this by casting RL as supervised sequence modeling, but they are restricted to offline data and lack exploration. Online Decision Transformers (ODTs) address this limitation through entropy-regularized training on on-policy rollouts, offering a stable alternative to traditional RL methods like Soft Actor-Critic, which depend on bootstrapped targets and reward shaping. Despite these advantages, ODTs use standard attention, which lacks explicit memory of action-specific outcomes. This leads to inefficiencies in learning long-term action effectiveness. Inspired by cognitive models such as Experience-Weighted Attraction (EWA), we propose Experience-Weighted Attraction with Vector Quantization for Online Decision Transformers (EWA-VQ-ODT), a lightweight module that maintains per-action mental accounts summarizing recent successes and failures. Continuous actions are routed via direct grid lookup to a compact vector-quantized codebook, where each code stores a scalar attraction updated online through decay and reward-based reinforcement. These attractions modulate attention by biasing the columns associated with action tokens, requiring no change to the backbone or training objective. On standard continuous-control benchmarks, EWA-VQ-ODT improves sample efficiency and average return over ODT, particularly in early training. The module is computationally efficient, interpretable via per-code traces, and supported by theoretical guarantees that bound the attraction dynamics and its impact on attention drift.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15498v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” ìê¸° ì£¼ì˜ë¥¼ í†µí•´ ê¶¤ì ì„ ëª¨ë¸ë§í•˜ì—¬ ìˆœì°¨ì  ì˜ì‚¬ ê²°ì •ì— ë§¤ë ¥ì ì¸ ì•„í‚¤í…ì²˜ë¡œ ë¶€ìƒí–ˆìŠµë‹ˆë‹¤. ê°•í™” í•™ìŠµ(RL)ì—ì„œëŠ” ê°€ì¹˜ í•¨ìˆ˜ ê·¼ì‚¬ì— ì˜ì¡´í•˜ì§€ ì•Šê³  ë°˜í™˜ ì¡°ê±´ë¶€ ì œì–´ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. Decision Transformers(DTs)ëŠ” ì´ë¥¼ í™œìš©í•˜ì—¬ RLì„ ê°ë…ëœ ì‹œí€€ìŠ¤ ëª¨ë¸ë§ìœ¼ë¡œ ë³€í™˜í•˜ì§€ë§Œ, ì˜¤í”„ë¼ì¸ ë°ì´í„°ì— ì œí•œë˜ë©° íƒìƒ‰ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. Online Decision Transformers(ODTs)ëŠ” ì •ì±… ë¡¤ì•„ì›ƒì— ëŒ€í•œ ì—”íŠ¸ë¡œí”¼ ì •ê·œí™” í›ˆë ¨ì„ í†µí•´ ì´ ì œí•œì„ í•´ê²°í•˜ë©°, ë¶€íŠ¸ìŠ¤íŠ¸ë© íƒ€ê²Ÿê³¼ ë³´ìƒ í˜•ì„±ì— ì˜ì¡´í•˜ëŠ” Soft Actor-Criticê³¼ ê°™ì€ ì „í†µì ì¸ RL ë°©ë²•ì— ëŒ€í•œ ì•ˆì •ì ì¸ ëŒ€ì•ˆì„ ì œê³µí•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì¥ì ì—ë„ ë¶ˆêµ¬í•˜ê³ , ODTsëŠ” í–‰ë™ë³„ ê²°ê³¼ì— ëŒ€í•œ ëª…ì‹œì  ê¸°ì–µì´ ì—†ëŠ” í‘œì¤€ ì£¼ì˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ëŠ” ì¥ê¸°ì ì¸ í–‰ë™ íš¨ê³¼ í•™ìŠµì— ë¹„íš¨ìœ¨ì„±ì„ ì´ˆë˜í•©ë‹ˆë‹¤. Experience-Weighted Attraction(EWA)ì™€ ê°™ì€ ì¸ì§€ ëª¨ë¸ì—ì„œ ì˜ê°ì„ ë°›ì•„, ìš°ë¦¬ëŠ” Online Decision Transformersë¥¼ ìœ„í•œ ë²¡í„° ì–‘ìí™”ëœ ê²½í—˜ ê°€ì¤‘ ë§¤ë ¥ì„ ì œì•ˆí•©ë‹ˆë‹¤(EWA-VQ-ODT). ì´ ê²½ëŸ‰ ëª¨ë“ˆì€ ìµœê·¼ ì„±ê³µê³¼ ì‹¤íŒ¨ë¥¼ ìš”ì•½í•˜ëŠ” í–‰ë™ë³„ ì •ì‹  ê³„ì •ì„ ìœ ì§€í•©ë‹ˆë‹¤. ì—°ì†ì ì¸ í–‰ë™ì€ ì§ì ‘ì ì¸ ê·¸ë¦¬ë“œ ì¡°íšŒë¥¼ í†µí•´ ì••ì¶•ëœ ë²¡í„° ì–‘ìí™” ì½”ë“œë¶ìœ¼ë¡œ ë¼ìš°íŒ…ë˜ë©°, ê° ì½”ë“œëŠ” ê°ì‡ ì™€ ë³´ìƒ ê¸°ë°˜ ê°•í™”ë¡œ ì˜¨ë¼ì¸ ì—…ë°ì´íŠ¸ë˜ëŠ” ìŠ¤ì¹¼ë¼ ë§¤ë ¥ì„ ì €ì¥í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ë§¤ë ¥ì€ í–‰ë™ í† í°ê³¼ ê´€ë ¨ëœ ì—´ì— í¸í–¥ì„ ì£¼ì–´ ì£¼ì˜ë¥¼ ì¡°ì ˆí•˜ë©°, ë°±ë³¸ì´ë‚˜ í›ˆë ¨ ëª©í‘œì˜ ë³€ê²½ì´ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í‘œì¤€ ì—°ì† ì œì–´ ë²¤ì¹˜ë§ˆí¬ì—ì„œ EWA-VQ-ODTëŠ” íŠ¹íˆ ì´ˆê¸° í›ˆë ¨ì—ì„œ ODTì— ë¹„í•´ ìƒ˜í”Œ íš¨ìœ¨ì„±ê³¼ í‰ê·  ë°˜í™˜ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì´ ëª¨ë“ˆì€ ê³„ì‚°ì ìœ¼ë¡œ íš¨ìœ¨ì ì´ë©°, ì½”ë“œë³„ ì¶”ì ì„ í†µí•´ í•´ì„ ê°€ëŠ¥í•˜ê³ , ë§¤ë ¥ ì—­í•™ê³¼ ì£¼ì˜ ë“œë¦¬í”„íŠ¸ì— ëŒ€í•œ ì˜í–¥ì„ ì œí•œí•˜ëŠ” ì´ë¡ ì  ë³´ì¦ì— ì˜í•´ ì§€ì›ë©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” ìê¸° ì£¼ì˜ë¥¼ í†µí•´ ê²½ë¡œë¥¼ ëª¨ë¸ë§í•˜ì—¬ ìˆœì°¨ì  ì˜ì‚¬ê²°ì •ì— íš¨ê³¼ì ì¸ êµ¬ì¡°ë¡œ ë¶€ìƒí–ˆìŠµë‹ˆë‹¤. ê°•í™” í•™ìŠµ(RL)ì—ì„œ, ì´ëŠ” ê°€ì¹˜ í•¨ìˆ˜ ê·¼ì‚¬ ì—†ì´ ë°˜í™˜ ì¡°ê±´ë¶€ ì œì–´ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. Decision Transformers(DTs)ëŠ” ì´ë¥¼ í™œìš©í•˜ì—¬ RLì„ ì§€ë„ í•™ìŠµ ì‹œí€€ìŠ¤ ëª¨ë¸ë§ìœ¼ë¡œ ì „í™˜í•˜ì§€ë§Œ, ì˜¤í”„ë¼ì¸ ë°ì´í„°ì—ë§Œ êµ­í•œë˜ê³  íƒìƒ‰ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. Online Decision Transformers(ODTs)ëŠ” ì •ì±… ë¡¤ì•„ì›ƒì— ëŒ€í•œ ì—”íŠ¸ë¡œí”¼ ì •ê·œí™” í›ˆë ¨ì„ í†µí•´ ì´ ì œí•œì„ í•´ê²°í•˜ë©°, Soft Actor-Criticê³¼ ê°™ì€ ì „í†µì ì¸ RL ë°©ë²•ì— ë¹„í•´ ì•ˆì •ì ì¸ ëŒ€ì•ˆì„ ì œê³µí•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ODTsëŠ” í‘œì¤€ ì£¼ì˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í–‰ë™ë³„ ê²°ê³¼ì— ëŒ€í•œ ëª…ì‹œì  ê¸°ì–µì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ Experience-Weighted Attraction(EWA)ì—ì„œ ì˜ê°ì„ ë°›ì•„, ìš°ë¦¬ëŠ” Online Decision Transformersë¥¼ ìœ„í•œ Experience-Weighted Attraction with Vector Quantization(EWA-VQ-ODT)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ëª¨ë“ˆì€ ìµœê·¼ ì„±ê³µê³¼ ì‹¤íŒ¨ë¥¼ ìš”ì•½í•˜ëŠ” í–‰ë™ë³„ ì •ì‹  ê³„ì •ì„ ìœ ì§€í•˜ë©°, ì—°ì†ì ì¸ í–‰ë™ì„ ë²¡í„° ì–‘ìí™”ëœ ì½”ë“œë¶ìœ¼ë¡œ ë¼ìš°íŒ…í•˜ì—¬ ì£¼ì˜ë¥¼ ì¡°ì •í•©ë‹ˆë‹¤. EWA-VQ-ODTëŠ” ì´ˆê¸° í›ˆë ¨ì—ì„œ ìƒ˜í”Œ íš¨ìœ¨ì„±ê³¼ í‰ê·  ìˆ˜ìµì„ ê°œì„ í•˜ë©°, ê³„ì‚° íš¨ìœ¨ì ì´ê³  í•´ì„ ê°€ëŠ¥í•˜ë©°, ì´ë¡ ì  ë³´ì¥ì„ í†µí•´ ì£¼ì˜ ë“œë¦¬í”„íŠ¸ì— ëŒ€í•œ ì˜í–¥ì„ ì œí•œí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Decision TransformersëŠ” ê°•í™” í•™ìŠµì„ ê°ë… í•™ìŠµ ì‹œí€€ìŠ¤ ëª¨ë¸ë§ìœ¼ë¡œ ë³€í™˜í•˜ì§€ë§Œ, íƒìƒ‰ ê¸°ëŠ¥ì´ ë¶€ì¡±í•˜ê³  ì˜¤í”„ë¼ì¸ ë°ì´í„°ì—ë§Œ ì˜ì¡´í•©ë‹ˆë‹¤.

- 2. Online Decision TransformersëŠ” ì—”íŠ¸ë¡œí”¼ ì •ê·œí™”ëœ í›ˆë ¨ì„ í†µí•´ ì´ ì œí•œì„ ê·¹ë³µí•˜ë©°, ì „í†µì ì¸ ê°•í™” í•™ìŠµ ë°©ë²•ë³´ë‹¤ ì•ˆì •ì ì¸ ëŒ€ì•ˆì„ ì œê³µí•©ë‹ˆë‹¤.

- 3. Experience-Weighted Attraction with Vector Quantization for Online Decision Transformers (EWA-VQ-ODT)ëŠ” ê° í–‰ë™ì˜ ìµœê·¼ ì„±ê³µê³¼ ì‹¤íŒ¨ë¥¼ ìš”ì•½í•˜ëŠ” ê²½ëŸ‰ ëª¨ë“ˆë¡œ, í•™ìŠµ íš¨ìœ¨ì„±ì„ ê°œì„ í•©ë‹ˆë‹¤.

- 4. EWA-VQ-ODTëŠ” ì—°ì†ì ì¸ í–‰ë™ì„ ë²¡í„° ì–‘ìí™”ëœ ì½”ë“œë¶ìœ¼ë¡œ ë¼ìš°íŒ…í•˜ì—¬ ì£¼ì˜ë ¥ì„ ì¡°ì •í•˜ë©°, ê¸°ë³¸ êµ¬ì¡°ë‚˜ í›ˆë ¨ ëª©í‘œë¥¼ ë³€ê²½í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

- 5. EWA-VQ-ODTëŠ” í‘œì¤€ ì—°ì† ì œì–´ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìƒ˜í”Œ íš¨ìœ¨ì„±ê³¼ í‰ê·  ìˆ˜ìµì„ ê°œì„ í•˜ë©°, íŠ¹íˆ ì´ˆê¸° í›ˆë ¨ì—ì„œ ë‘ë“œëŸ¬ì§‘ë‹ˆë‹¤.

---

*Generated on 2025-09-22 15:16:45*