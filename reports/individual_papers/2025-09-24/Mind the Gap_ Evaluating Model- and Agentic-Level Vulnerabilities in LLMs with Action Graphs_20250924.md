<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T15:55:16.208545",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "AgentSeer",
    "Agentic Systems",
    "Action Graphs",
    "Semantic Vulnerability Mechanisms"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "AgentSeer": 0.8,
    "Agentic Systems": 0.78,
    "Action Graphs": 0.77,
    "Semantic Vulnerability Mechanisms": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Essential for linking discussions on advancements and vulnerabilities in AI systems.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "AgentSeer",
        "canonical": "AgentSeer",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Introduces a novel framework for evaluating agentic systems, crucial for understanding new methodologies.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Agentic Systems",
        "canonical": "Agentic Systems",
        "aliases": [
          "Agentic-Level Systems"
        ],
        "category": "evolved_concepts",
        "rationale": "Represents a shift in AI system design, linking to discussions on autonomy and decision-making.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Action Graphs",
        "canonical": "Action Graphs",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Key for understanding the structure of agentic executions, facilitating connections to graph-based analyses.",
        "novelty_score": 0.68,
        "connectivity_score": 0.75,
        "specificity_score": 0.78,
        "link_intent_score": 0.77
      },
      {
        "surface": "Semantic Vulnerability Mechanisms",
        "canonical": "Semantic Vulnerability Mechanisms",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Highlights a specific type of vulnerability, crucial for linking to security and risk assessment discussions.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.82,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "evaluation",
      "framework",
      "model-level",
      "agent-specific"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "AgentSeer",
      "resolved_canonical": "AgentSeer",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Agentic Systems",
      "resolved_canonical": "Agentic Systems",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Action Graphs",
      "resolved_canonical": "Action Graphs",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.75,
        "specificity": 0.78,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Semantic Vulnerability Mechanisms",
      "resolved_canonical": "Semantic Vulnerability Mechanisms",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.82,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Mind the Gap: Evaluating Model- and Agentic-Level Vulnerabilities in LLMs with Action Graphs

## 📋 메타데이터

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.04802.pdf)
**Category**: cs.CL
**Published**: 2025-09-24
**ArXiv ID**: [2509.04802](https://arxiv.org/abs/2509.04802)

## 🔗 유사한 논문
- [[2025-09-23/Mind the Gap_ Comparing Model- vs Agentic-Level Red Teaming with Action-Graph Observability on GPT-OSS-20B_20250923|Mind the Gap: Comparing Model- vs Agentic-Level Red Teaming with Action-Graph Observability on GPT-OSS-20B]] (91.3% similar)
- [[2025-09-23/Why Are Web AI Agents More Vulnerable Than Standalone LLMs? A Security Analysis_20250923|Why Are Web AI Agents More Vulnerable Than Standalone LLMs? A Security Analysis]] (86.9% similar)
- [[2025-09-19/Detecting Pipeline Failures through Fine-Grained Analysis of Web Agents_20250919|Detecting Pipeline Failures through Fine-Grained Analysis of Web Agents]] (84.9% similar)
- [[2025-09-19/AgentCompass_ Towards Reliable Evaluation of Agentic Workflows in Production_20250919|AgentCompass: Towards Reliable Evaluation of Agentic Workflows in Production]] (84.7% similar)
- [[2025-09-22/Diagnostics of cognitive failures in multi-agent expert systems using dynamic evaluation protocols and subsequent mutation of the processing context_20250922|Diagnostics of cognitive failures in multi-agent expert systems using dynamic evaluation protocols and subsequent mutation of the processing context]] (84.4% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Action Graphs|Action Graphs]]
**⚡ Unique Technical**: [[keywords/AgentSeer|AgentSeer]], [[keywords/Semantic Vulnerability Mechanisms|Semantic Vulnerability Mechanisms]]
**🚀 Evolved Concepts**: [[keywords/Agentic Systems|Agentic Systems]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.04802v2 Announce Type: replace 
Abstract: As large language models transition to agentic systems, current safety evaluation frameworks face critical gaps in assessing deployment-specific risks. We introduce AgentSeer, an observability-based evaluation framework that decomposes agentic executions into granular action and component graphs, enabling systematic agentic-situational assessment. Through cross-model validation on GPT-OSS-20B and Gemini-2.0-flash using HarmBench single turn and iterative refinement attacks, we demonstrate fundamental differences between model-level and agentic-level vulnerability profiles. Model-level evaluation reveals baseline differences: GPT-OSS-20B (39.47% ASR) versus Gemini-2.0-flash (50.00% ASR), with both models showing susceptibility to social engineering while maintaining logic-based attack resistance. However, agentic-level assessment exposes agent-specific risks invisible to traditional evaluation. We discover "agentic-only" vulnerabilities that emerge exclusively in agentic contexts, with tool-calling showing 24-60% higher ASR across both models. Cross-model analysis reveals universal agentic patterns, agent transfer operations as highest-risk tools, semantic rather than syntactic vulnerability mechanisms, and context-dependent attack effectiveness, alongside model-specific security profiles in absolute ASR levels and optimal injection strategies. Direct attack transfer from model-level to agentic contexts shows degraded performance (GPT-OSS-20B: 57% human injection ASR; Gemini-2.0-flash: 28%), while context-aware iterative attacks successfully compromise objectives that failed at model-level, confirming systematic evaluation gaps. These findings establish the urgent need for agentic-situation evaluation paradigms, with AgentSeer providing the standardized methodology and empirical validation.

## 📝 요약

이 논문은 대형 언어 모델이 에이전트 시스템으로 전환됨에 따라 기존 안전성 평가 체계의 한계를 지적하고, 새로운 평가 프레임워크인 AgentSeer를 제안합니다. AgentSeer는 에이전트 실행을 세부적인 행동 및 구성 요소 그래프로 분해하여 체계적인 상황 평가를 가능하게 합니다. GPT-OSS-20B와 Gemini-2.0-flash 모델을 대상으로 한 교차 모델 검증을 통해 모델 수준과 에이전트 수준의 취약성 프로파일 간의 근본적인 차이를 밝혀냈습니다. 특히 에이전트 수준의 평가에서는 전통적인 방법으로는 드러나지 않는 에이전트 특유의 위험이 발견되었습니다. 도구 호출 시 에이전트 전용 취약성이 나타나며, 모델 간 분석에서는 보편적인 에이전트 패턴과 문맥 의존적인 공격 효과가 확인되었습니다. 이러한 결과는 에이전트 상황 평가 패러다임의 필요성을 강조하며, AgentSeer가 표준화된 방법론과 실증적 검증을 제공함을 보여줍니다.

## 🎯 주요 포인트

- 1. AgentSeer는 에이전트 실행을 세분화하여 체계적인 평가를 가능하게 하는 관찰 기반 평가 프레임워크입니다.
- 2. 모델 수준과 에이전트 수준의 취약성 프로필이 근본적으로 다르며, 에이전트 수준의 평가에서 전통적인 평가로는 드러나지 않는 에이전트 특정 위험이 발견됩니다.
- 3. 에이전트 전용 취약성은 도구 호출에서 24-60% 더 높은 공격 성공률(ASR)을 보이며, 이는 에이전트 컨텍스트에서만 나타납니다.
- 4. 교차 모델 분석은 보편적인 에이전트 패턴과 문맥에 따라 공격 효과가 달라지는 것을 보여주며, 모델별 보안 프로필의 차이를 드러냅니다.
- 5. AgentSeer는 에이전트 상황 평가 패러다임의 필요성을 강조하며, 표준화된 방법론과 실증적 검증을 제공합니다.


---

*Generated on 2025-09-24 15:55:16*