<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T15:53:01.695464",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Chain-of-Thought Reasoning",
    "Step-by-step Prompting",
    "Translation Decomposition"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Chain-of-Thought Reasoning": 0.78,
    "Step-by-step Prompting": 0.72,
    "Translation Decomposition": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "As a foundational technology in the paper, it connects to a wide range of topics in NLP and AI.",
        "novelty_score": 0.35,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Chain-of-Thought reasoning",
        "canonical": "Chain-of-Thought Reasoning",
        "aliases": [
          "CoT reasoning"
        ],
        "category": "unique_technical",
        "rationale": "This technique is central to the paper's exploration of translation strategies.",
        "novelty_score": 0.7,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Step-by-step prompting",
        "canonical": "Step-by-step Prompting",
        "aliases": [
          "multi-step prompting"
        ],
        "category": "unique_technical",
        "rationale": "It represents a specific method of interacting with LLMs, relevant to the paper's findings.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.77,
        "link_intent_score": 0.72
      },
      {
        "surface": "Translation decomposition",
        "canonical": "Translation Decomposition",
        "aliases": [
          "decomposing translation"
        ],
        "category": "unique_technical",
        "rationale": "This concept is key to understanding the paper's critique of current translation methods.",
        "novelty_score": 0.68,
        "connectivity_score": 0.68,
        "specificity_score": 0.75,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "human-like reasoning",
      "performance gains",
      "empirical evidence"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.35,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Chain-of-Thought reasoning",
      "resolved_canonical": "Chain-of-Thought Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Step-by-step prompting",
      "resolved_canonical": "Step-by-step Prompting",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.77,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "Translation decomposition",
      "resolved_canonical": "Translation Decomposition",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.68,
        "specificity": 0.75,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# Please Translate Again: Two Simple Experiments on Whether Human-Like Reasoning Helps Translation

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2506.04521.pdf)
**Category**: cs.CL
**Published**: 2025-09-24
**ArXiv ID**: [2506.04521](https://arxiv.org/abs/2506.04521)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates_20250923|Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates]] (86.5% similar)
- [[2025-09-24/LightThinker_ Thinking Step-by-Step Compression_20250924|LightThinker: Thinking Step-by-Step Compression]] (83.8% similar)
- [[2025-09-23/EvoCoT_ Overcoming the Exploration Bottleneck in Reinforcement Learning_20250923|EvoCoT: Overcoming the Exploration Bottleneck in Reinforcement Learning]] (83.7% similar)
- [[2025-09-23/GPO_ Learning from Critical Steps to Improve LLM Reasoning_20250923|GPO: Learning from Critical Steps to Improve LLM Reasoning]] (83.5% similar)
- [[2025-09-22/Language Mixing in Reasoning Language Models_ Patterns, Impact, and Internal Causes_20250922|Language Mixing in Reasoning Language Models: Patterns, Impact, and Internal Causes]] (83.4% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**âš¡ Unique Technical**: [[keywords/Chain-of-Thought Reasoning|Chain-of-Thought Reasoning]], [[keywords/Step-by-step Prompting|Step-by-step Prompting]], [[keywords/Translation Decomposition|Translation Decomposition]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2506.04521v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) demonstrate strong reasoning capabilities for many tasks, often by explicitly decomposing the task via Chain-of-Thought (CoT) reasoning. Recent work on LLM-based translation designs hand-crafted prompts to decompose translation, or trains models to incorporate intermediate steps. Translating Step-by-step (Briakou et al., 2024), for instance, introduces a multi-step prompt with decomposition and refinement of translation with LLMs, which achieved state-of-the-art results on WMT24 test data. In this work, we scrutinise this strategy's effectiveness. Empirically, we find no clear evidence that performance gains stem from explicitly decomposing the translation process via CoT, at least for the models on test; and we show prompting LLMs to 'translate again' and self-refine yields even better results than human-like step-by-step prompting. While the decomposition influences translation behaviour, faithfulness to the decomposition has both positive and negative effects on translation. Our analysis therefore suggests a divergence between the optimal translation strategies for humans and LLMs.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ë²ˆì—­ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ì²´ì¸ ì˜¤ë¸Œ ì†ŒíŠ¸(Chain-of-Thought, CoT) ë°©ì‹ì˜ íš¨ê³¼ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤. ê¸°ì¡´ ì—°êµ¬ì—ì„œëŠ” ë²ˆì—­ ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ ë‚˜ëˆ„ì–´ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí–ˆìœ¼ë‚˜, ì‹¤í—˜ ê²°ê³¼ ì´ëŸ¬í•œ ë°©ë²•ì´ ì„±ëŠ¥ í–¥ìƒì˜ ì£¼ìš” ì›ì¸ì´ë¼ëŠ” ëª…í™•í•œ ì¦ê±°ëŠ” ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ëŒ€ì‹ , LLMì—ê²Œ ë²ˆì—­ì„ ë°˜ë³µí•˜ê³  ìŠ¤ìŠ¤ë¡œ ê°œì„ í•˜ë„ë¡ ìœ ë„í•˜ëŠ” ë°©ì‹ì´ ë” ë‚˜ì€ ê²°ê³¼ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤. ì´ëŠ” ì¸ê°„ê³¼ LLMì˜ ìµœì  ë²ˆì—­ ì „ëµì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì€ Chain-of-Thought(COT) ì¶”ë¡ ì„ í†µí•´ ë§ì€ ì‘ì—…ì—ì„œ ê°•ë ¥í•œ ì¶”ë¡  ëŠ¥ë ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
- 2. ë²ˆì—­ ì‘ì—…ì—ì„œ LLM ê¸°ë°˜ì˜ ë²ˆì—­ì€ ì¤‘ê°„ ë‹¨ê³„ë¥¼ í¬í•¨í•˜ë„ë¡ ëª¨ë¸ì„ í›ˆë ¨í•˜ê±°ë‚˜ ìˆ˜ì‘ì—…ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ë¥¼ ì„¤ê³„í•˜ì—¬ ë²ˆì—­ì„ ë¶„í•´í•©ë‹ˆë‹¤.
- 3. 'Step-by-step' ë²ˆì—­ ë°©ì‹ì€ LLMì„ ì‚¬ìš©í•˜ì—¬ ë²ˆì—­ì„ ë¶„í•´í•˜ê³  ì •ì œí•˜ëŠ” ë‹¤ë‹¨ê³„ í”„ë¡¬í”„íŠ¸ë¥¼ ë„ì…í•˜ì—¬ WMT24 í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ìµœì²¨ë‹¨ ê²°ê³¼ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.
- 4. ì—°êµ¬ ê²°ê³¼, ë²ˆì—­ ê³¼ì •ì—ì„œ CoTë¥¼ í†µí•œ ëª…ì‹œì  ë¶„í•´ê°€ ì„±ëŠ¥ í–¥ìƒì— ê¸°ì—¬í•œë‹¤ëŠ” ëª…í™•í•œ ì¦ê±°ëŠ” ì—†ì—ˆìœ¼ë©°, 'ë‹¤ì‹œ ë²ˆì—­'í•˜ê³  ìì²´ ì •ì œë¥¼ ìœ ë„í•˜ëŠ” í”„ë¡¬í”„íŠ¸ê°€ ë” ë‚˜ì€ ê²°ê³¼ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.
- 5. ë²ˆì—­ ë¶„í•´ëŠ” ë²ˆì—­ í–‰ë™ì— ì˜í–¥ì„ ë¯¸ì¹˜ë©°, ì¸ê°„ê³¼ LLMì˜ ìµœì  ë²ˆì—­ ì „ëµ ê°„ì˜ ì°¨ì´ê°€ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 15:53:01*