<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T14:00:10.903178",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Self-supervised Learning",
    "Masked Spectrogram Modeling",
    "Transformer",
    "Selective Structured State Space Models",
    "Audio Foundation Models"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Self-supervised Learning": 0.85,
    "Masked Spectrogram Modeling": 0.78,
    "Transformer": 0.8,
    "Selective Structured State Space Models": 0.75,
    "Audio Foundation Models": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "self-supervised learning",
        "canonical": "Self-supervised Learning",
        "aliases": [
          "SSL"
        ],
        "category": "specific_connectable",
        "rationale": "Self-supervised learning is a key approach in the paper, linking it to broader trends in machine learning.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "masked spectrogram modeling",
        "canonical": "Masked Spectrogram Modeling",
        "aliases": [
          "MSM"
        ],
        "category": "unique_technical",
        "rationale": "This is a unique approach discussed in the paper, relevant for audio representation learning.",
        "novelty_score": 0.72,
        "connectivity_score": 0.67,
        "specificity_score": 0.82,
        "link_intent_score": 0.78
      },
      {
        "surface": "Transformer",
        "canonical": "Transformer",
        "aliases": [],
        "category": "broad_technical",
        "rationale": "Transformers are central to the paper's discussion on neural architectures.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.8
      },
      {
        "surface": "Selective structured state space models",
        "canonical": "Selective Structured State Space Models",
        "aliases": [
          "S4 Models"
        ],
        "category": "unique_technical",
        "rationale": "These models represent a novel approach to sequence modeling in the context of the paper.",
        "novelty_score": 0.68,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      },
      {
        "surface": "audio foundation models",
        "canonical": "Audio Foundation Models",
        "aliases": [],
        "category": "evolved_concepts",
        "rationale": "The concept of audio foundation models is emerging and connects to broader AI model discussions.",
        "novelty_score": 0.65,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "deep neural representations",
      "recurrent sequence modeling"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "self-supervised learning",
      "resolved_canonical": "Self-supervised Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "masked spectrogram modeling",
      "resolved_canonical": "Masked Spectrogram Modeling",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.67,
        "specificity": 0.82,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Transformer",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Selective structured state space models",
      "resolved_canonical": "Selective Structured State Space Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "audio foundation models",
      "resolved_canonical": "Audio Foundation Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# An overview of neural architectures for self-supervised audio representation learning from masked spectrograms

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18691.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2509.18691](https://arxiv.org/abs/2509.18691)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Achilles' Heel of Mamba_ Essential difficulties of the Mamba architecture demonstrated by synthetic data_20250923|Achilles' Heel of Mamba: Essential difficulties of the Mamba architecture demonstrated by synthetic data]] (83.5% similar)
- [[2025-09-23/Scaling Efficient LLMs_20250923|Scaling Efficient LLMs]] (83.1% similar)
- [[2025-09-23/Inceptive Transformers_ Enhancing Contextual Representations through Multi-Scale Feature Learning Across Domains and Languages_20250923|Inceptive Transformers: Enhancing Contextual Representations through Multi-Scale Feature Learning Across Domains and Languages]] (82.1% similar)
- [[2025-09-22/Hierarchical Self-Attention_ Generalizing Neural Attention Mechanics to Multi-Scale Problems_20250922|Hierarchical Self-Attention: Generalizing Neural Attention Mechanics to Multi-Scale Problems]] (82.1% similar)
- [[2025-09-23/DeepInsert_ Early Layer Bypass for Efficient and Performant Multimodal Understanding_20250923|DeepInsert: Early Layer Bypass for Efficient and Performant Multimodal Understanding]] (81.9% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Transformer|Transformer]]
**ğŸ”— Specific Connectable**: [[keywords/Self-supervised Learning|Self-supervised Learning]]
**âš¡ Unique Technical**: [[keywords/Masked Spectrogram Modeling|Masked Spectrogram Modeling]], [[keywords/Selective Structured State Space Models|Selective Structured State Space Models]]
**ğŸš€ Evolved Concepts**: [[keywords/Audio Foundation Models|Audio Foundation Models]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18691v1 Announce Type: cross 
Abstract: In recent years, self-supervised learning has amassed significant interest for training deep neural representations without labeled data. One such self-supervised learning approach is masked spectrogram modeling, where the objective is to learn semantically rich contextual representations by predicting removed or hidden portions of the input audio spectrogram. With the Transformer neural architecture at its core, masked spectrogram modeling has emerged as the prominent approach for learning general purpose audio representations, a.k.a. audio foundation models. Meanwhile, addressing the issues of the Transformer architecture, in particular the underlying Scaled Dot-product Attention operation, which scales quadratically with input sequence length, has led to renewed interest in recurrent sequence modeling approaches. Among them, Selective structured state space models (such as Mamba) and extended Long Short-Term Memory (xLSTM) are the two most promising approaches which have experienced widespread adoption. While the body of work on these two topics continues to grow, there is currently a lack of an adequate overview encompassing the intersection of these topics. In this paper, we present a comprehensive overview of the aforementioned research domains, covering masked spectrogram modeling and the previously mentioned neural sequence modeling architectures, Mamba and xLSTM. Further, we compare Transformers, Mamba and xLSTM based masked spectrogram models in a unified, reproducible framework on ten diverse downstream audio classification tasks, which will help interested readers to make informed decisions regarding suitability of the evaluated approaches to adjacent applications.

## ğŸ“ ìš”ì•½

ìµœê·¼ ìê¸° ì§€ë„ í•™ìŠµì€ ë¼ë²¨ì´ ì—†ëŠ” ë°ì´í„°ë¡œ ì‹¬ì¸µ ì‹ ê²½ í‘œí˜„ì„ í•™ìŠµí•˜ëŠ” ë° í° ê´€ì‹¬ì„ ë°›ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ ì¤‘ í•˜ë‚˜ì¸ ë§ˆìŠ¤í¬ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ëª¨ë¸ë§ì€ ì…ë ¥ ì˜¤ë””ì˜¤ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ì˜ ìˆ¨ê²¨ì§„ ë¶€ë¶„ì„ ì˜ˆì¸¡í•˜ì—¬ ì˜ë¯¸ ìˆëŠ” ë¬¸ë§¥ í‘œí˜„ì„ í•™ìŠµí•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. Transformer ì‹ ê²½ë§ êµ¬ì¡°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ëŠ” ì´ ë°©ë²•ì€ ë²”ìš© ì˜¤ë””ì˜¤ í‘œí˜„ í•™ìŠµì˜ ì£¼ìš” ì ‘ê·¼ë²•ìœ¼ë¡œ ìë¦¬ ì¡ì•˜ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ Transformerì˜ Scaled Dot-product Attention ì—°ì‚°ì´ ì…ë ¥ ì‹œí€€ìŠ¤ ê¸¸ì´ì— ë”°ë¼ ì´ì°¨ì ìœ¼ë¡œ ì¦ê°€í•˜ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ì¬ê·€ì  ì‹œí€€ìŠ¤ ëª¨ë¸ë§ ì ‘ê·¼ë²•ì— ëŒ€í•œ ê´€ì‹¬ì´ ë‹¤ì‹œ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ, Mambaì™€ ê°™ì€ ì„ íƒì  êµ¬ì¡°ì  ìƒíƒœ ê³µê°„ ëª¨ë¸ê³¼ í™•ì¥ëœ LSTM(xLSTM)ì´ ì£¼ëª©ë°›ê³  ìˆìŠµë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì´ëŸ¬í•œ ì—°êµ¬ ì˜ì—­ì„ í¬ê´„ì ìœ¼ë¡œ ë‹¤ë£¨ê³ , Transformer, Mamba, xLSTM ê¸°ë°˜ì˜ ë§ˆìŠ¤í¬ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ëª¨ë¸ì„ ë‹¤ì–‘í•œ ì˜¤ë””ì˜¤ ë¶„ë¥˜ ì‘ì—…ì—ì„œ ë¹„êµí•˜ì—¬, ë…ìë“¤ì´ ê° ì ‘ê·¼ë²•ì˜ ì í•©ì„±ì„ í‰ê°€í•  ìˆ˜ ìˆë„ë¡ ë•ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ìê¸° ì§€ë„ í•™ìŠµì€ ë ˆì´ë¸”ì´ ì—†ëŠ” ë°ì´í„°ë¡œ ì‹¬ì¸µ ì‹ ê²½ í‘œí˜„ì„ í•™ìŠµí•˜ëŠ” ë° ì£¼ëª©ë°›ê³  ìˆìœ¼ë©°, ë§ˆìŠ¤í‚¹ëœ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ëª¨ë¸ë§ì´ ê·¸ ì¤‘ í•˜ë‚˜ë¡œ ë¶€ìƒí•˜ê³  ìˆë‹¤.
- 2. íŠ¸ëœìŠ¤í¬ë¨¸ ì‹ ê²½ë§ êµ¬ì¡°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ë§ˆìŠ¤í‚¹ëœ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ëª¨ë¸ë§ì€ ì¼ë°˜ ëª©ì ì˜ ì˜¤ë””ì˜¤ í‘œí˜„ í•™ìŠµì— ìˆì–´ ì¤‘ìš”í•œ ì ‘ê·¼ ë°©ì‹ìœ¼ë¡œ ìë¦¬ì¡ì•˜ë‹¤.
- 3. íŠ¸ëœìŠ¤í¬ë¨¸ êµ¬ì¡°ì˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì„ íƒì  êµ¬ì¡°ì  ìƒíƒœ ê³µê°„ ëª¨ë¸(Mamba)ê³¼ í™•ì¥ëœ ì¥ë‹¨ê¸° ë©”ëª¨ë¦¬(xLSTM)ê°€ ì£¼ëª©ë°›ê³  ìˆë‹¤.
- 4. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ë§ˆìŠ¤í‚¹ëœ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ëª¨ë¸ë§ê³¼ Mamba, xLSTM ë“±ì˜ ì‹ ê²½ë§ ì‹œí€€ìŠ¤ ëª¨ë¸ë§ ì•„í‚¤í…ì²˜ì— ëŒ€í•œ í¬ê´„ì ì¸ ê°œìš”ë¥¼ ì œì‹œí•œë‹¤.
- 5. íŠ¸ëœìŠ¤í¬ë¨¸, Mamba, xLSTM ê¸°ë°˜ì˜ ë§ˆìŠ¤í‚¹ëœ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ëª¨ë¸ì„ ë‹¤ì–‘í•œ ì˜¤ë””ì˜¤ ë¶„ë¥˜ ì‘ì—…ì—ì„œ ë¹„êµí•˜ì—¬ ê° ì ‘ê·¼ ë°©ì‹ì˜ ì í•©ì„±ì„ í‰ê°€í•œë‹¤.


---

*Generated on 2025-09-24 14:00:10*