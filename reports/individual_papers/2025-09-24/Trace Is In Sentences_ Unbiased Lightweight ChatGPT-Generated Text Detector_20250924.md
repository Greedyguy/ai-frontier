<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T15:40:12.693713",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Sentence Embeddings",
    "Self-supervised Learning",
    "Causal Graph",
    "Attention Mechanism"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Sentence Embeddings": 0.75,
    "Self-supervised Learning": 0.8,
    "Causal Graph": 0.7,
    "Attention Mechanism": 0.82
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "ChatGPT",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "OpenAI Chatbot"
        ],
        "category": "broad_technical",
        "rationale": "ChatGPT is a prominent example of a Large Language Model, providing a direct link to discussions around LLMs.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "sentence embeddings",
        "canonical": "Sentence Embeddings",
        "aliases": [
          "sentence vectors"
        ],
        "category": "unique_technical",
        "rationale": "Sentence embeddings are crucial for understanding text structure, offering a unique technical insight into text analysis.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      },
      {
        "surface": "contrastive learning",
        "canonical": "Self-supervised Learning",
        "aliases": [
          "contrastive training"
        ],
        "category": "specific_connectable",
        "rationale": "Contrastive learning is a form of self-supervised learning, enhancing connections to related learning paradigms.",
        "novelty_score": 0.55,
        "connectivity_score": 0.85,
        "specificity_score": 0.75,
        "link_intent_score": 0.8
      },
      {
        "surface": "causal graph",
        "canonical": "Causal Graph",
        "aliases": [
          "causal diagram"
        ],
        "category": "unique_technical",
        "rationale": "Causal graphs are used to isolate structural features, providing a unique perspective on data analysis.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.7
      },
      {
        "surface": "attention",
        "canonical": "Attention Mechanism",
        "aliases": [
          "attention model"
        ],
        "category": "specific_connectable",
        "rationale": "Attention mechanisms are foundational in modern NLP models, linking to a wide array of related research.",
        "novelty_score": 0.5,
        "connectivity_score": 0.88,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      }
    ],
    "ban_list_suggestions": [
      "word-level detectors",
      "modified text",
      "training data content"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "ChatGPT",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "sentence embeddings",
      "resolved_canonical": "Sentence Embeddings",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "contrastive learning",
      "resolved_canonical": "Self-supervised Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.85,
        "specificity": 0.75,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "causal graph",
      "resolved_canonical": "Causal Graph",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "attention",
      "resolved_canonical": "Attention Mechanism",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.88,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    }
  ]
}
-->

# Trace Is In Sentences: Unbiased Lightweight ChatGPT-Generated Text Detector

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18535.pdf)
**Category**: cs.CL
**Published**: 2025-09-24
**ArXiv ID**: [2509.18535](https://arxiv.org/abs/2509.18535)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Fine-Grained Detection of AI-Generated Text Using Sentence-Level Segmentation_20250923|Fine-Grained Detection of AI-Generated Text Using Sentence-Level Segmentation]] (88.3% similar)
- [[2025-09-24/Diversity Boosts AI-Generated Text Detection_20250924|Diversity Boosts AI-Generated Text Detection]] (86.1% similar)
- [[2025-09-22/DNA-DetectLLM_ Unveiling AI-Generated Text via a DNA-Inspired Mutation-Repair Paradigm_20250922|DNA-DetectLLM: Unveiling AI-Generated Text via a DNA-Inspired Mutation-Repair Paradigm]] (85.7% similar)
- [[2025-09-19/JU-NLP at Touch\'e_ Covert Advertisement in Conversational AI-Generation and Detection Strategies_20250919|JU-NLP at Touch\'e: Covert Advertisement in Conversational AI-Generation and Detection Strategies]] (83.4% similar)
- [[2025-09-18/AgentCTG_ Harnessing Multi-Agent Collaboration for Fine-Grained Precise Control in Text Generation_20250918|AgentCTG: Harnessing Multi-Agent Collaboration for Fine-Grained Precise Control in Text Generation]] (82.9% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Self-supervised Learning|Self-supervised Learning]], [[keywords/Attention Mechanism|Attention Mechanism]]
**âš¡ Unique Technical**: [[keywords/Sentence Embeddings|Sentence Embeddings]], [[keywords/Causal Graph|Causal Graph]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18535v1 Announce Type: new 
Abstract: The widespread adoption of ChatGPT has raised concerns about its misuse, highlighting the need for robust detection of AI-generated text. Current word-level detectors are vulnerable to paraphrasing or simple prompts (PSP), suffer from biases induced by ChatGPT's word-level patterns (CWP) and training data content, degrade on modified text, and often require large models or online LLM interaction. To tackle these issues, we introduce a novel task to detect both original and PSP-modified AI-generated texts, and propose a lightweight framework that classifies texts based on their internal structure, which remains invariant under word-level changes. Our approach encodes sentence embeddings from pre-trained language models and models their relationships via attention. We employ contrastive learning to mitigate embedding biases from autoregressive generation and incorporate a causal graph with counterfactual methods to isolate structural features from topic-related biases. Experiments on two curated datasets, including abstract comparisons and revised life FAQs, validate the effectiveness of our method.

## ğŸ“ ìš”ì•½

ChatGPTì˜ ì˜¤ìš© ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ AI ìƒì„± í…ìŠ¤íŠ¸ë¥¼ ê°ì§€í•˜ëŠ” ìƒˆë¡œìš´ ê³¼ì œë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë‹¨ì–´ ìˆ˜ì¤€ ê°ì§€ê¸°ëŠ” íŒ¨ëŸ¬í”„ë ˆì´ì§•ì— ì·¨ì•½í•˜ê³ , ChatGPTì˜ ë‹¨ì–´ íŒ¨í„´ê³¼ í›ˆë ¨ ë°ì´í„°ë¡œ ì¸í•œ í¸í–¥ì„ ê²ªìœ¼ë©°, ìˆ˜ì •ëœ í…ìŠ¤íŠ¸ì—ì„œ ì„±ëŠ¥ì´ ì €í•˜ë©ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ë‹¨ì–´ ìˆ˜ì¤€ì˜ ë³€í™”ì—ë„ ë¶ˆë³€ì¸ ë‚´ë¶€ êµ¬ì¡°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ë¶„ë¥˜í•˜ëŠ” ê²½ëŸ‰ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì‚¬ì „ í•™ìŠµëœ ì–¸ì–´ ëª¨ë¸ì˜ ë¬¸ì¥ ì„ë² ë”©ì„ ì¸ì½”ë”©í•˜ê³ , ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´ ê´€ê³„ë¥¼ ëª¨ë¸ë§í•©ë‹ˆë‹¤. ë˜í•œ, ëŒ€ì¡° í•™ìŠµì„ í†µí•´ ìƒì„± í¸í–¥ì„ ì™„í™”í•˜ê³ , ì¸ê³¼ ê·¸ë˜í”„ì™€ ë°˜ì‚¬ì‹¤ì  ë°©ë²•ì„ ì‚¬ìš©í•˜ì—¬ êµ¬ì¡°ì  íŠ¹ì§•ì„ ì£¼ì œ ê´€ë ¨ í¸í–¥ìœ¼ë¡œë¶€í„° ë¶„ë¦¬í•©ë‹ˆë‹¤. ë‘ ê°œì˜ ë°ì´í„°ì…‹ ì‹¤í—˜ì„ í†µí•´ ì œì•ˆëœ ë°©ë²•ì˜ íš¨ê³¼ë¥¼ ê²€ì¦í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ChatGPTì˜ ì˜¤ìš© ìš°ë ¤ë¡œ AI ìƒì„± í…ìŠ¤íŠ¸ë¥¼ ê°ì§€í•˜ëŠ” ê°•ë ¥í•œ ë°©ë²•ì˜ í•„ìš”ì„±ì´ ëŒ€ë‘ë˜ê³  ìˆë‹¤.
- 2. ê¸°ì¡´ì˜ ë‹¨ì–´ ìˆ˜ì¤€ íƒì§€ê¸°ëŠ” íŒ¨ëŸ¬í”„ë ˆì´ì§•ì´ë‚˜ ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ì— ì·¨ì•½í•˜ë©°, ëŒ€ê·œëª¨ ëª¨ë¸ì´ë‚˜ ì˜¨ë¼ì¸ LLM ìƒí˜¸ì‘ìš©ì´ í•„ìš”í•˜ë‹¤.
- 3. ë³¸ ì—°êµ¬ëŠ” ì›ë³¸ ë° ìˆ˜ì •ëœ AI ìƒì„± í…ìŠ¤íŠ¸ë¥¼ íƒì§€í•˜ëŠ” ìƒˆë¡œìš´ ê³¼ì œë¥¼ ì œì•ˆí•˜ê³ , ë‹¨ì–´ ìˆ˜ì¤€ ë³€ê²½ì—ë„ ë¶ˆë³€ì¸ ë‚´ë¶€ êµ¬ì¡°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ë¶„ë¥˜í•˜ëŠ” ê²½ëŸ‰ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•œë‹¤.
- 4. ì‚¬ì „ í•™ìŠµëœ ì–¸ì–´ ëª¨ë¸ì˜ ë¬¸ì¥ ì„ë² ë”©ì„ ì¸ì½”ë”©í•˜ê³ , ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´ ê´€ê³„ë¥¼ ëª¨ë¸ë§í•˜ì—¬ êµ¬ì¡°ì  íŠ¹ì§•ì„ ì£¼ì œ ê´€ë ¨ í¸í–¥ì—ì„œ ë¶„ë¦¬í•œë‹¤.
- 5. ë‘ ê°œì˜ íë ˆì´ì…˜ëœ ë°ì´í„°ì…‹ì—ì„œ ì‹¤í—˜ì„ í†µí•´ ì œì•ˆëœ ë°©ë²•ì˜ íš¨ê³¼ì„±ì„ ê²€ì¦í•˜ì˜€ë‹¤.


---

*Generated on 2025-09-24 15:40:12*