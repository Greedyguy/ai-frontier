<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T14:20:12.229113",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Explainable AI",
    "Rule Extraction",
    "SHAP",
    "RuleSHAP"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Explainable AI": 0.8,
    "Rule Extraction": 0.78,
    "SHAP": 0.82,
    "RuleSHAP": 0.88
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Central to the study, linking to a broad technical concept widely used in NLP.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Explainable AI",
        "canonical": "Explainable AI",
        "aliases": [
          "XAI"
        ],
        "category": "specific_connectable",
        "rationale": "Key to understanding and linking methods for bias detection in AI models.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Rule Extraction",
        "canonical": "Rule Extraction",
        "aliases": [
          "Rule Induction"
        ],
        "category": "unique_technical",
        "rationale": "A unique method proposed in the paper for bias detection, enhancing specificity.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "SHAP",
        "canonical": "SHAP",
        "aliases": [
          "Shapley Additive Explanations"
        ],
        "category": "specific_connectable",
        "rationale": "A specific method for model explanation, relevant for linking to explainability techniques.",
        "novelty_score": 0.5,
        "connectivity_score": 0.8,
        "specificity_score": 0.75,
        "link_intent_score": 0.82
      },
      {
        "surface": "RuleSHAP",
        "canonical": "RuleSHAP",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "A novel algorithm introduced in the paper, crucial for understanding the proposed solution.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.88
      }
    ],
    "ban_list_suggestions": [
      "misinformation",
      "heuristics",
      "bias"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Explainable AI",
      "resolved_canonical": "Explainable AI",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Rule Extraction",
      "resolved_canonical": "Rule Extraction",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "SHAP",
      "resolved_canonical": "SHAP",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.8,
        "specificity": 0.75,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "RuleSHAP",
      "resolved_canonical": "RuleSHAP",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.88
      }
    }
  ]
}
-->

# Can Global XAI Methods Reveal Injected Bias in LLMs? SHAP vs Rule Extraction vs RuleSHAP

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2505.11189.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2505.11189](https://arxiv.org/abs/2505.11189)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-17/Simulating a Bias Mitigation Scenario in Large Language Models_20250917|Simulating a Bias Mitigation Scenario in Large Language Models]] (84.7% similar)
- [[2025-09-23/Does Reasoning Introduce Bias? A Study of Social Bias Evaluation and Mitigation in LLM Reasoning_20250923|Does Reasoning Introduce Bias? A Study of Social Bias Evaluation and Mitigation in LLM Reasoning]] (84.7% similar)
- [[2025-09-22/Benchmarking Debiasing Methods for LLM-based Parameter Estimates_20250922|Benchmarking Debiasing Methods for LLM-based Parameter Estimates]] (84.3% similar)
- [[2025-09-23/Strategic Dishonesty Can Undermine AI Safety Evaluations of Frontier LLM_20250923|Strategic Dishonesty Can Undermine AI Safety Evaluations of Frontier LLM]] (84.2% similar)
- [[2025-09-22/Bias Beware_ The Impact of Cognitive Biases on LLM-Driven Product Recommendations_20250922|Bias Beware: The Impact of Cognitive Biases on LLM-Driven Product Recommendations]] (83.9% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Explainable AI|Explainable AI]], [[keywords/SHAP|SHAP]]
**âš¡ Unique Technical**: [[keywords/Rule Extraction|Rule Extraction]], [[keywords/RuleSHAP|RuleSHAP]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2505.11189v2 Announce Type: replace 
Abstract: Large language models (LLMs) can amplify misinformation, undermining societal goals like the UN SDGs. We study three documented drivers of misinformation (valence framing, information overload, and oversimplification) which are often shaped by one's default beliefs. Building on evidence that LLMs encode such defaults (e.g., "joy is positive," "math is complex") and can act as "bags of heuristics," we ask: can general belief-driven heuristics behind misinformative behaviour be recovered from LLMs as clear rules? A key obstacle is that global rule-extraction methods in explainable AI (XAI) are built for numerical inputs/outputs, not text. We address this by eliciting global LLM beliefs and mapping them to numerical scores via statistically reliable abstractions, thereby enabling off-the-shelf global XAI to detect belief-related heuristics in LLMs. To obtain ground truth, we hard-code bias-inducing nonlinear heuristics of increasing complexity (univariate, conjunctive, nonconvex) into popular LLMs (ChatGPT and Llama) via system instructions. This way, we find that RuleFit under-detects non-univariate biases, while global SHAP better approximates conjunctive ones but does not yield actionable rules. To bridge this gap, we propose RuleSHAP, a rule-extraction algorithm that couples global SHAP-value aggregations with rule induction to better capture non-univariate bias, improving heuristics detection over RuleFit by +94% (MRR@1) on average. Our results provide a practical pathway for revealing belief-driven biases in LLMs.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì´ ì˜ëª»ëœ ì •ë³´ë¥¼ ì¦í­ì‹œì¼œ ì‚¬íšŒì  ëª©í‘œë¥¼ ì €í•´í•  ìˆ˜ ìˆìŒì„ ì§€ì í•©ë‹ˆë‹¤. ì—°êµ¬ëŠ” ì˜ëª»ëœ ì •ë³´ì˜ ì£¼ìš” ì›ì¸ì¸ ê°ì •ì  í‹€, ì •ë³´ ê³¼ë¶€í•˜, ê³¼ë„í•œ ë‹¨ìˆœí™”ë¥¼ ì¡°ì‚¬í•©ë‹ˆë‹¤. LLMì´ ì´ëŸ¬í•œ ê¸°ë³¸ ì‹ ë…ì„ ì¸ì½”ë”©í•˜ê³  'íœ´ë¦¬ìŠ¤í‹±ì˜ ì§‘í•©'ìœ¼ë¡œ ì‘ìš©í•  ìˆ˜ ìˆë‹¤ëŠ” ì ì— ì°©ì•ˆí•˜ì—¬, ì´ëŸ¬í•œ íœ´ë¦¬ìŠ¤í‹±ì„ ëª…í™•í•œ ê·œì¹™ìœ¼ë¡œ ì¶”ì¶œí•  ìˆ˜ ìˆëŠ”ì§€ë¥¼ íƒêµ¬í•©ë‹ˆë‹¤. ê¸°ì¡´ ì„¤ëª… ê°€ëŠ¥í•œ AI(XAI) ë°©ë²•ì€ í…ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ìˆ˜ì¹˜ ì…ë ¥/ì¶œë ¥ì— ë§ì¶°ì ¸ ìˆì–´ ì´ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ LLMì˜ ê¸€ë¡œë²Œ ì‹ ë…ì„ ìˆ˜ì¹˜ ì ìˆ˜ë¡œ ë§¤í•‘í•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ LLMì˜ ì‹ ë… ê´€ë ¨ íœ´ë¦¬ìŠ¤í‹±ì„ íƒì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—°êµ¬ëŠ” ChatGPTì™€ Llamaì— í¸í–¥ì„ ìœ ë„í•˜ëŠ” ë¹„ì„ í˜• íœ´ë¦¬ìŠ¤í‹±ì„ í•˜ë“œì½”ë”©í•˜ì—¬, RuleFitê³¼ SHAPì˜ ì„±ëŠ¥ì„ ë¹„êµí•©ë‹ˆë‹¤. RuleFitì€ ë¹„ë‹¨ì¼ ë³€ìˆ˜ í¸í–¥ì„ ì˜ ê°ì§€í•˜ì§€ ëª»í•˜ì§€ë§Œ, SHAPëŠ” ê²°í•©ì  í¸í–¥ì„ ë” ì˜ í¬ì°©í•©ë‹ˆë‹¤. ì´ë¥¼ ê°œì„ í•˜ê¸° ìœ„í•´ RuleSHAP ì•Œê³ ë¦¬ì¦˜ì„ ì œì•ˆí•˜ì—¬ ë¹„ë‹¨ì¼ ë³€ìˆ˜ í¸í–¥ ê°ì§€ ì„±ëŠ¥ì„ í‰ê·  94% í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤. ì´ ê²°ê³¼ëŠ” LLMì˜ ì‹ ë… ê¸°ë°˜ í¸í–¥ì„ ë“œëŸ¬ë‚´ëŠ” ì‹¤ìš©ì  ê²½ë¡œë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ ì˜ëª»ëœ ì •ë³´ë¥¼ ì¦í­ì‹œì¼œ UN ì§€ì† ê°€ëŠ¥í•œ ê°œë°œ ëª©í‘œ(SDGs)ì™€ ê°™ì€ ì‚¬íšŒì  ëª©í‘œë¥¼ ì €í•´í•  ìˆ˜ ìˆë‹¤.
- 2. ì˜ëª»ëœ ì •ë³´ì˜ ì£¼ìš” ì›ì¸ìœ¼ë¡œëŠ” ê°ì •ì  í‹€, ì •ë³´ ê³¼ë¶€í•˜, ê³¼ë„í•œ ë‹¨ìˆœí™”ê°€ ìˆìœ¼ë©°, ì´ëŠ” ê°œì¸ì˜ ê¸°ë³¸ ì‹ ë…ì— ì˜í•´ í˜•ì„±ëœë‹¤.
- 3. LLMì˜ ì „ì—­ ì„¤ëª… ê°€ëŠ¥ ì¸ê³µì§€ëŠ¥(XAI) ë°©ë²•ì€ í…ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ìˆ˜ì¹˜ ì…ë ¥/ì¶œë ¥ì— ë§ì¶°ì ¸ ìˆì–´, ì‹ ë… ê´€ë ¨ íœ´ë¦¬ìŠ¤í‹±ì„ ê°ì§€í•˜ëŠ” ë° í•œê³„ê°€ ìˆë‹¤.
- 4. RuleSHAP ì•Œê³ ë¦¬ì¦˜ì€ ì „ì—­ SHAP ê°’ ì§‘ê³„ì™€ ê·œì¹™ ìœ ë„ë¥¼ ê²°í•©í•˜ì—¬ ë¹„ë‹¨ì¼ë³€ëŸ‰ í¸í–¥ì„ ë” ì˜ í¬ì°©í•˜ê³ , RuleFitë³´ë‹¤ í‰ê·  94% í–¥ìƒëœ íœ´ë¦¬ìŠ¤í‹± ê°ì§€ë¥¼ ì œê³µí•œë‹¤.
- 5. ì—°êµ¬ ê²°ê³¼ëŠ” LLMì—ì„œ ì‹ ë…ì— ê¸°ë°˜í•œ í¸í–¥ì„ ë“œëŸ¬ë‚´ëŠ” ì‹¤ì§ˆì ì¸ ê²½ë¡œë¥¼ ì œì‹œí•œë‹¤.


---

*Generated on 2025-09-24 14:20:12*