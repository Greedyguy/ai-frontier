<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T13:37:49.860564",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Neural Network",
    "Adiabatic Capacitive Neuron",
    "Dual Tree Single Clock",
    "TensorFlow",
    "Weight Quantization"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Neural Network": 0.85,
    "Adiabatic Capacitive Neuron": 0.78,
    "Dual Tree Single Clock": 0.77,
    "TensorFlow": 0.8,
    "Weight Quantization": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Artificial Neural Network",
        "canonical": "Neural Network",
        "aliases": [
          "ANN"
        ],
        "category": "broad_technical",
        "rationale": "Neural Networks are a foundational concept in machine learning, providing a strong link to related research.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Adiabatic Capacitive Neuron",
        "canonical": "Adiabatic Capacitive Neuron",
        "aliases": [
          "ACN"
        ],
        "category": "unique_technical",
        "rationale": "This is a specific technology discussed in the paper, crucial for understanding its unique contributions.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Dual Tree Single Clock",
        "canonical": "Dual Tree Single Clock",
        "aliases": [
          "DTSC"
        ],
        "category": "unique_technical",
        "rationale": "DTSC is a specific design architecture that is central to the paper's methodology.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      },
      {
        "surface": "TensorFlow",
        "canonical": "TensorFlow",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "TensorFlow is a widely used framework in machine learning, linking to a broad array of related works.",
        "novelty_score": 0.2,
        "connectivity_score": 0.85,
        "specificity_score": 0.5,
        "link_intent_score": 0.8
      },
      {
        "surface": "weight quantization",
        "canonical": "Weight Quantization",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Weight quantization is a key concept in optimizing neural network performance, relevant to the paper's focus.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "Artificial Neuron",
      "IC design"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Artificial Neural Network",
      "resolved_canonical": "Neural Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Adiabatic Capacitive Neuron",
      "resolved_canonical": "Adiabatic Capacitive Neuron",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Dual Tree Single Clock",
      "resolved_canonical": "Dual Tree Single Clock",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "TensorFlow",
      "resolved_canonical": "TensorFlow",
      "decision": "linked",
      "scores": {
        "novelty": 0.2,
        "connectivity": 0.85,
        "specificity": 0.5,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "weight quantization",
      "resolved_canonical": "Weight Quantization",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Weight Mapping Properties of a Dual Tree Single Clock Adiabatic Capacitive Neuron

## 📋 메타데이터

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18143.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2509.18143](https://arxiv.org/abs/2509.18143)

## 🔗 유사한 논문
- [[2025-09-23/Neuro-inspired Ensemble-to-Ensemble Communication Primitives for Sparse and Efficient ANNs_20250923|Neuro-inspired Ensemble-to-Ensemble Communication Primitives for Sparse and Efficient ANNs]] (84.0% similar)
- [[2025-09-22/Analog In-memory Training on General Non-ideal Resistive Elements_ The Impact of Response Functions_20250922|Analog In-memory Training on General Non-ideal Resistive Elements: The Impact of Response Functions]] (80.8% similar)
- [[2025-09-17/A Neural Network for the Identical Kuramoto Equation_ Architectural Considerations and Performance Evaluation_20250917|A Neural Network for the Identical Kuramoto Equation: Architectural Considerations and Performance Evaluation]] (80.5% similar)
- [[2025-09-23/Automated Labeling of Intracranial Arteries with Uncertainty Quantification Using Deep Learning_20250923|Automated Labeling of Intracranial Arteries with Uncertainty Quantification Using Deep Learning]] (80.1% similar)
- [[2025-09-23/An Efficient Dual-Line Decoder Network with Multi-Scale Convolutional Attention for Multi-organ Segmentation_20250923|An Efficient Dual-Line Decoder Network with Multi-Scale Convolutional Attention for Multi-organ Segmentation]] (79.8% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Neural Network|Neural Network]]
**🔗 Specific Connectable**: [[keywords/TensorFlow|TensorFlow]], [[keywords/Weight Quantization|Weight Quantization]]
**⚡ Unique Technical**: [[keywords/Adiabatic Capacitive Neuron|Adiabatic Capacitive Neuron]], [[keywords/Dual Tree Single Clock|Dual Tree Single Clock]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.18143v1 Announce Type: cross 
Abstract: Dual Tree Single Clock (DTSC) Adiabatic Capacitive Neuron (ACN) circuits offer the potential for highly energy-efficient Artificial Neural Network (ANN) computation in full custom analog IC designs. The efficient mapping of Artificial Neuron (AN) abstract weights, extracted from the software-trained ANNs, onto physical ACN capacitance values has, however, yet to be fully researched. In this paper, we explore the unexpected hidden complexities, challenges and properties of the mapping, as well as, the ramifications for IC designers in terms accuracy, design and implementation. We propose an optimal, AN to ACN methodology, that promotes smaller chip sizes and improved overall classification accuracy, necessary for successful practical deployment. Using TensorFlow and Larq software frameworks, we train three different ANN networks and map their weights into the energy-efficient DTSC ACN capacitance value domain to demonstrate 100% functional equivalency. Finally, we delve into the impact of weight quantization on ACN performance using novel metrics related to practical IC considerations, such as IC floor space and comparator decision-making efficacy.

## 📝 요약

이 논문은 Dual Tree Single Clock (DTSC) Adiabatic Capacitive Neuron (ACN) 회로를 활용한 에너지 효율적인 인공신경망(ANN) 계산 방법을 제안합니다. 소프트웨어로 훈련된 ANN의 가중치를 물리적 ACN 용량 값으로 매핑하는 과정에서의 복잡성과 도전 과제를 탐구하며, 이를 통해 IC 설계의 정확성과 구현에 미치는 영향을 분석합니다. 제안된 방법론은 칩 크기를 줄이고 분류 정확도를 향상시켜 실용적 배포에 적합합니다. TensorFlow와 Larq를 사용하여 세 가지 ANN 네트워크를 훈련하고, 이를 DTSC ACN 용량 값으로 매핑하여 100% 기능적 동등성을 입증합니다. 또한, 가중치 양자화가 ACN 성능에 미치는 영향을 IC 설계 관련 지표를 통해 분석합니다.

## 🎯 주요 포인트

- 1. Dual Tree Single Clock (DTSC) Adiabatic Capacitive Neuron (ACN) 회로는 에너지 효율적인 인공신경망(ANN) 계산을 가능하게 합니다.
- 2. 소프트웨어로 훈련된 ANN의 추상적인 가중치를 물리적인 ACN 커패시턴스 값으로 효율적으로 매핑하는 방법이 아직 충분히 연구되지 않았습니다.
- 3. 본 논문에서는 AN에서 ACN으로의 최적화된 매핑 방법론을 제안하여 칩 크기를 줄이고 분류 정확도를 향상시킵니다.
- 4. TensorFlow와 Larq 소프트웨어 프레임워크를 사용하여 세 가지 다른 ANN 네트워크를 훈련하고, 이들의 가중치를 DTSC ACN 커패시턴스 값으로 매핑하여 100% 기능적 동등성을 입증했습니다.
- 5. 가중치 양자화가 ACN 성능에 미치는 영향을 IC 설계와 관련된 새로운 지표를 통해 분석합니다.


---

*Generated on 2025-09-24 13:37:49*