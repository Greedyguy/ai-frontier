<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T15:48:34.138189",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Knowledge Graphs",
    "Contrastive Sentence Embedding",
    "Semantic Textual Similarity"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Knowledge Graphs": 0.82,
    "Contrastive Sentence Embedding": 0.78,
    "Semantic Textual Similarity": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Large Language Models"
        ],
        "category": "broad_technical",
        "rationale": "LLMs are central to the proposed method, linking to broader NLP advancements.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Knowledge Graphs",
        "canonical": "Knowledge Graphs",
        "aliases": [
          "KG",
          "Knowledge Graph"
        ],
        "category": "specific_connectable",
        "rationale": "Knowledge Graphs are used to enhance data diversity, connecting to semantic data structuring.",
        "novelty_score": 0.72,
        "connectivity_score": 0.79,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "Contrastive Sentence Embedding",
        "canonical": "Contrastive Sentence Embedding",
        "aliases": [
          "GCSE",
          "Gaussian-decayed Contrastive Sentence Embedding"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel method introduced in the paper, crucial for understanding the proposed approach.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.88,
        "link_intent_score": 0.78
      },
      {
        "surface": "Semantic Textual Similarity",
        "canonical": "Semantic Textual Similarity",
        "aliases": [
          "STS"
        ],
        "category": "specific_connectable",
        "rationale": "STS tasks are a key application area for the proposed method, linking to evaluation metrics in NLP.",
        "novelty_score": 0.55,
        "connectivity_score": 0.83,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "data augmentation",
      "synthetic samples"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Knowledge Graphs",
      "resolved_canonical": "Knowledge Graphs",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.79,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Contrastive Sentence Embedding",
      "resolved_canonical": "Contrastive Sentence Embedding",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.88,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Semantic Textual Similarity",
      "resolved_canonical": "Semantic Textual Similarity",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.83,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# Enhancing Unsupervised Sentence Embeddings via Knowledge-Driven Data Augmentation and Gaussian-Decayed Contrastive Learning

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2409.12887.pdf)
**Category**: cs.CL
**Published**: 2025-09-24
**ArXiv ID**: [2409.12887](https://arxiv.org/abs/2409.12887)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages_20250922|A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages]] (84.2% similar)
- [[2025-09-19/DetectAnyLLM_ Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models_20250919|DetectAnyLLM: Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models]] (84.0% similar)
- [[2025-09-19/Middo_ Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning_20250919|Middo: Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning]] (83.5% similar)
- [[2025-09-23/Evaluating the Effectiveness and Scalability of LLM-Based Data Augmentation for Retrieval_20250923|Evaluating the Effectiveness and Scalability of LLM-Based Data Augmentation for Retrieval]] (83.5% similar)
- [[2025-09-22/SEMMA_ A Semantic Aware Knowledge Graph Foundation Model_20250922|SEMMA: A Semantic Aware Knowledge Graph Foundation Model]] (83.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Knowledge Graphs|Knowledge Graphs]], [[keywords/Semantic Textual Similarity|Semantic Textual Similarity]]
**âš¡ Unique Technical**: [[keywords/Contrastive Sentence Embedding|Contrastive Sentence Embedding]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2409.12887v4 Announce Type: replace 
Abstract: Recently, using large language models (LLMs) for data augmentation has led to considerable improvements in unsupervised sentence embedding models. However, existing methods encounter two primary challenges: limited data diversity and high data noise. Current approaches often neglect fine-grained knowledge, such as entities and quantities, leading to insufficient diversity. Besides, unsupervised data frequently lacks discriminative information, and the generated synthetic samples may introduce noise. In this paper, we propose a pipeline-based data augmentation method via LLMs and introduce the Gaussian-decayed gradient-assisted Contrastive Sentence Embedding (GCSE) model to enhance unsupervised sentence embeddings. To tackle the issue of low data diversity, our pipeline utilizes knowledge graphs (KGs) to extract entities and quantities, enabling LLMs to generate more diverse samples. To address high data noise, the GCSE model uses a Gaussian-decayed function to limit the impact of false hard negative samples, enhancing the model's discriminative capability. Experimental results show that our approach achieves state-of-the-art performance in semantic textual similarity (STS) tasks, using fewer data samples and smaller LLMs, demonstrating its efficiency and robustness across various models.

## ğŸ“ ìš”ì•½

ìµœê·¼ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ í™œìš©í•œ ë°ì´í„° ì¦ê°•ì´ ë¹„ì§€ë„ ë¬¸ì¥ ì„ë² ë”© ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê¸°ì¡´ ë°©ë²•ì€ ë°ì´í„° ë‹¤ì–‘ì„±ê³¼ ë…¸ì´ì¦ˆ ë¬¸ì œë¥¼ ê²ªê³  ìˆìŠµë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” LLMì„ í†µí•œ íŒŒì´í”„ë¼ì¸ ê¸°ë°˜ ë°ì´í„° ì¦ê°• ë°©ë²•ê³¼ ê°€ìš°ì‹œì•ˆ ê°ì‡  ê¸°ìš¸ê¸° ë³´ì¡° ëŒ€ì¡° ë¬¸ì¥ ì„ë² ë”©(GCSE) ëª¨ë¸ì„ ì œì•ˆí•©ë‹ˆë‹¤. ë°ì´í„° ë‹¤ì–‘ì„±ì„ ë†’ì´ê¸° ìœ„í•´ ì§€ì‹ ê·¸ë˜í”„(KG)ë¥¼ í™œìš©í•˜ì—¬ ì—”í‹°í‹°ì™€ ìˆ˜ëŸ‰ì„ ì¶”ì¶œí•˜ê³ , LLMì´ ë” ë‹¤ì–‘í•œ ìƒ˜í”Œì„ ìƒì„±í•˜ë„ë¡ í•©ë‹ˆë‹¤. ë˜í•œ, GCSE ëª¨ë¸ì€ ê°€ìš°ì‹œì•ˆ ê°ì‡  í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ ì˜ëª»ëœ í•˜ë“œ ë„¤ê±°í‹°ë¸Œ ìƒ˜í”Œì˜ ì˜í–¥ì„ ì¤„ì—¬ ëª¨ë¸ì˜ ë³€ë³„ë ¥ì„ ê°•í™”í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì€ ì ì€ ë°ì´í„°ì™€ ì‘ì€ LLMì„ ì‚¬ìš©í•˜ë©´ì„œë„ ì˜ë¯¸ì  í…ìŠ¤íŠ¸ ìœ ì‚¬ì„±(STS) ê³¼ì œì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ì—¬ íš¨ìœ¨ì„±ê³¼ ê°•ê±´ì„±ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì„ í™œìš©í•œ ë°ì´í„° ì¦ê°•ì´ ë¹„ì§€ë„ ë¬¸ì¥ ì„ë² ë”© ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.
- 2. ê¸°ì¡´ ë°©ë²•ë“¤ì€ ë°ì´í„° ë‹¤ì–‘ì„±ê³¼ ë°ì´í„° ë…¸ì´ì¦ˆ ë¬¸ì œë¥¼ ê²ªê³  ìˆìœ¼ë©°, ì„¸ë°€í•œ ì§€ì‹(ì˜ˆ: ì—”í‹°í‹°, ìˆ˜ëŸ‰)ì„ ê°„ê³¼í•˜ì—¬ ë‹¤ì–‘ì„±ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.
- 3. ì œì•ˆëœ ë°©ë²•ì€ ì§€ì‹ ê·¸ë˜í”„(KGs)ë¥¼ í™œìš©í•˜ì—¬ LLMsê°€ ë” ë‹¤ì–‘í•œ ìƒ˜í”Œì„ ìƒì„±í•˜ë„ë¡ í•˜ê³ , Gaussian-decayed í•¨ìˆ˜ë¡œ ë…¸ì´ì¦ˆ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤.
- 4. Gaussian-decayed gradient-assisted Contrastive Sentence Embedding (GCSE) ëª¨ë¸ì€ ì˜ëª»ëœ í•˜ë“œ ë„¤ê±°í‹°ë¸Œ ìƒ˜í”Œì˜ ì˜í–¥ì„ ì œí•œí•˜ì—¬ ëª¨ë¸ì˜ íŒë³„ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
- 5. ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì€ ì ì€ ë°ì´í„° ìƒ˜í”Œê³¼ ë” ì‘ì€ LLMsë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ë¯¸ì  í…ìŠ¤íŠ¸ ìœ ì‚¬ì„±(STS) ì‘ì—…ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 15:48:34*