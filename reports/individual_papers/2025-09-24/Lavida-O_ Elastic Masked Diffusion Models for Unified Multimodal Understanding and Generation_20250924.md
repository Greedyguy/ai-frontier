<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T16:19:46.055135",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Masked Diffusion Model",
    "Elastic Mixture-of-Transformer",
    "Multimodal Learning",
    "Vision-Language Model",
    "Image Editing"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Masked Diffusion Model": 0.78,
    "Elastic Mixture-of-Transformer": 0.8,
    "Multimodal Learning": 0.85,
    "Vision-Language Model": 0.82,
    "Image Editing": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Masked Diffusion Model",
        "canonical": "Masked Diffusion Model",
        "aliases": [
          "MDM"
        ],
        "category": "unique_technical",
        "rationale": "Represents a novel approach in multimodal tasks, linking image understanding and generation.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Elastic Mixture-of-Transformer architecture",
        "canonical": "Elastic Mixture-of-Transformer",
        "aliases": [
          "Elastic Transformer"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a new architecture that enhances training and sampling efficiency.",
        "novelty_score": 0.82,
        "connectivity_score": 0.72,
        "specificity_score": 0.88,
        "link_intent_score": 0.8
      },
      {
        "surface": "Multimodal",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal"
        ],
        "category": "specific_connectable",
        "rationale": "Connects to the broader field of integrating multiple data types for learning.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Vision-Language",
        "canonical": "Vision-Language Model",
        "aliases": [
          "Vision-Language"
        ],
        "category": "evolved_concepts",
        "rationale": "Represents the intersection of visual and textual data processing, a key aspect of the paper.",
        "novelty_score": 0.55,
        "connectivity_score": 0.9,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "Image Editing",
        "canonical": "Image Editing",
        "aliases": [
          "ImgEdit"
        ],
        "category": "specific_connectable",
        "rationale": "A specific application of the proposed model, relevant for practical implementations.",
        "novelty_score": 0.5,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "task"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Masked Diffusion Model",
      "resolved_canonical": "Masked Diffusion Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Elastic Mixture-of-Transformer architecture",
      "resolved_canonical": "Elastic Mixture-of-Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.82,
        "connectivity": 0.72,
        "specificity": 0.88,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Multimodal",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Vision-Language",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.9,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Image Editing",
      "resolved_canonical": "Image Editing",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Lavida-O: Elastic Masked Diffusion Models for Unified Multimodal Understanding and Generation

## 📋 메타데이터

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19244.pdf)
**Category**: cs.CV
**Published**: 2025-09-24
**ArXiv ID**: [2509.19244](https://arxiv.org/abs/2509.19244)

## 🔗 유사한 논문
- [[2025-09-24/LongLLaVA_ Scaling Multi-modal LLMs to 1000 Images Efficiently via a Hybrid Architecture_20250924|LongLLaVA: Scaling Multi-modal LLMs to 1000 Images Efficiently via a Hybrid Architecture]] (83.5% similar)
- [[2025-09-19/UnifiedVisual_ A Framework for Constructing Unified Vision-Language Datasets_20250919|UnifiedVisual: A Framework for Constructing Unified Vision-Language Datasets]] (83.4% similar)
- [[2025-09-18/LLM-I_ LLMs are Naturally Interleaved Multimodal Creators_20250918|LLM-I: LLMs are Naturally Interleaved Multimodal Creators]] (83.1% similar)
- [[2025-09-23/FOCUS_ Unified Vision-Language Modeling for Interactive Editing Driven by Referential Segmentation_20250923|FOCUS: Unified Vision-Language Modeling for Interactive Editing Driven by Referential Segmentation]] (83.1% similar)
- [[2025-09-22/MaskAttn-SDXL_ Controllable Region-Level Text-To-Image Generation_20250922|MaskAttn-SDXL: Controllable Region-Level Text-To-Image Generation]] (82.9% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]], [[keywords/Image Editing|Image Editing]]
**⚡ Unique Technical**: [[keywords/Masked Diffusion Model|Masked Diffusion Model]], [[keywords/Elastic Mixture-of-Transformer|Elastic Mixture-of-Transformer]]
**🚀 Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.19244v1 Announce Type: new 
Abstract: We proposed Lavida-O, a unified multi-modal Masked Diffusion Model (MDM) capable of image understanding and generation tasks. Unlike existing multimodal diffsion language models such as MMaDa and Muddit which only support simple image-level understanding tasks and low-resolution image generation, Lavida-O exhibits many new capabilities such as object grounding, image-editing, and high-resolution (1024px) image synthesis. It is also the first unified MDM that uses its understanding capabilities to improve image generation and editing results through planning and iterative self-reflection. To allow effective and efficient training and sampling, Lavida-O ntroduces many novel techniques such as Elastic Mixture-of-Transformer architecture, universal text conditioning, and stratified sampling. \ours~achieves state-of-the-art performance on a wide range of benchmarks such as RefCOCO object grounding, GenEval text-to-image generation, and ImgEdit image editing, outperforming existing autoregressive and continuous diffusion models such as Qwen2.5-VL and FluxKontext-dev, while offering considerable speedup at inference.

## 📝 요약

Lavida-O는 이미지 이해와 생성 작업을 수행할 수 있는 통합 멀티모달 마스크 확산 모델(MDM)입니다. 기존 모델들이 단순 이미지 이해와 저해상도 이미지 생성에 그쳤다면, Lavida-O는 객체 연결, 이미지 편집, 고해상도 이미지 합성(1024px) 등의 새로운 기능을 제공합니다. 특히, 이해 능력을 활용해 이미지 생성과 편집 결과를 개선하는 계획 및 반복적 자기 반성을 수행하는 최초의 통합 MDM입니다. 효과적인 학습과 샘플링을 위해 Elastic Mixture-of-Transformer 아키텍처, 범용 텍스트 조건화, 계층적 샘플링 등의 기술을 도입했습니다. Lavida-O는 RefCOCO 객체 연결, GenEval 텍스트-이미지 생성, ImgEdit 이미지 편집 등 다양한 벤치마크에서 최첨단 성능을 달성하며, 기존 모델들보다 빠른 추론 속도를 제공합니다.

## 🎯 주요 포인트

- 1. Lavida-O는 이미지 이해 및 생성 작업을 수행할 수 있는 통합 멀티모달 마스크 확산 모델(MDM)입니다.
- 2. Lavida-O는 객체 그라운딩, 이미지 편집, 고해상도(1024px) 이미지 합성 등 새로운 기능을 제공합니다.
- 3. Lavida-O는 이해 능력을 활용하여 이미지 생성 및 편집 결과를 계획 및 반복적 자기 반성을 통해 개선합니다.
- 4. Elastic Mixture-of-Transformer 아키텍처, 범용 텍스트 조건화, 계층적 샘플링과 같은 새로운 기술을 도입하여 효율적인 학습 및 샘플링을 가능하게 합니다.
- 5. Lavida-O는 RefCOCO 객체 그라운딩, GenEval 텍스트-이미지 생성, ImgEdit 이미지 편집 등 다양한 벤치마크에서 최첨단 성능을 달성하며, 기존 모델보다 추론 속도를 크게 향상시킵니다.


---

*Generated on 2025-09-24 16:19:46*