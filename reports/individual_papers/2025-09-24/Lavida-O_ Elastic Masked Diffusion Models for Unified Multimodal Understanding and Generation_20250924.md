<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T16:19:46.055135",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Masked Diffusion Model",
    "Elastic Mixture-of-Transformer",
    "Multimodal Learning",
    "Vision-Language Model",
    "Image Editing"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Masked Diffusion Model": 0.78,
    "Elastic Mixture-of-Transformer": 0.8,
    "Multimodal Learning": 0.85,
    "Vision-Language Model": 0.82,
    "Image Editing": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Masked Diffusion Model",
        "canonical": "Masked Diffusion Model",
        "aliases": [
          "MDM"
        ],
        "category": "unique_technical",
        "rationale": "Represents a novel approach in multimodal tasks, linking image understanding and generation.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Elastic Mixture-of-Transformer architecture",
        "canonical": "Elastic Mixture-of-Transformer",
        "aliases": [
          "Elastic Transformer"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a new architecture that enhances training and sampling efficiency.",
        "novelty_score": 0.82,
        "connectivity_score": 0.72,
        "specificity_score": 0.88,
        "link_intent_score": 0.8
      },
      {
        "surface": "Multimodal",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal"
        ],
        "category": "specific_connectable",
        "rationale": "Connects to the broader field of integrating multiple data types for learning.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Vision-Language",
        "canonical": "Vision-Language Model",
        "aliases": [
          "Vision-Language"
        ],
        "category": "evolved_concepts",
        "rationale": "Represents the intersection of visual and textual data processing, a key aspect of the paper.",
        "novelty_score": 0.55,
        "connectivity_score": 0.9,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "Image Editing",
        "canonical": "Image Editing",
        "aliases": [
          "ImgEdit"
        ],
        "category": "specific_connectable",
        "rationale": "A specific application of the proposed model, relevant for practical implementations.",
        "novelty_score": 0.5,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "task"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Masked Diffusion Model",
      "resolved_canonical": "Masked Diffusion Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Elastic Mixture-of-Transformer architecture",
      "resolved_canonical": "Elastic Mixture-of-Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.82,
        "connectivity": 0.72,
        "specificity": 0.88,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Multimodal",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Vision-Language",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.9,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Image Editing",
      "resolved_canonical": "Image Editing",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Lavida-O: Elastic Masked Diffusion Models for Unified Multimodal Understanding and Generation

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19244.pdf)
**Category**: cs.CV
**Published**: 2025-09-24
**ArXiv ID**: [2509.19244](https://arxiv.org/abs/2509.19244)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-24/LongLLaVA_ Scaling Multi-modal LLMs to 1000 Images Efficiently via a Hybrid Architecture_20250924|LongLLaVA: Scaling Multi-modal LLMs to 1000 Images Efficiently via a Hybrid Architecture]] (83.5% similar)
- [[2025-09-19/UnifiedVisual_ A Framework for Constructing Unified Vision-Language Datasets_20250919|UnifiedVisual: A Framework for Constructing Unified Vision-Language Datasets]] (83.4% similar)
- [[2025-09-18/LLM-I_ LLMs are Naturally Interleaved Multimodal Creators_20250918|LLM-I: LLMs are Naturally Interleaved Multimodal Creators]] (83.1% similar)
- [[2025-09-23/FOCUS_ Unified Vision-Language Modeling for Interactive Editing Driven by Referential Segmentation_20250923|FOCUS: Unified Vision-Language Modeling for Interactive Editing Driven by Referential Segmentation]] (83.1% similar)
- [[2025-09-22/MaskAttn-SDXL_ Controllable Region-Level Text-To-Image Generation_20250922|MaskAttn-SDXL: Controllable Region-Level Text-To-Image Generation]] (82.9% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]], [[keywords/Image Editing|Image Editing]]
**âš¡ Unique Technical**: [[keywords/Masked Diffusion Model|Masked Diffusion Model]], [[keywords/Elastic Mixture-of-Transformer|Elastic Mixture-of-Transformer]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19244v1 Announce Type: new 
Abstract: We proposed Lavida-O, a unified multi-modal Masked Diffusion Model (MDM) capable of image understanding and generation tasks. Unlike existing multimodal diffsion language models such as MMaDa and Muddit which only support simple image-level understanding tasks and low-resolution image generation, Lavida-O exhibits many new capabilities such as object grounding, image-editing, and high-resolution (1024px) image synthesis. It is also the first unified MDM that uses its understanding capabilities to improve image generation and editing results through planning and iterative self-reflection. To allow effective and efficient training and sampling, Lavida-O ntroduces many novel techniques such as Elastic Mixture-of-Transformer architecture, universal text conditioning, and stratified sampling. \ours~achieves state-of-the-art performance on a wide range of benchmarks such as RefCOCO object grounding, GenEval text-to-image generation, and ImgEdit image editing, outperforming existing autoregressive and continuous diffusion models such as Qwen2.5-VL and FluxKontext-dev, while offering considerable speedup at inference.

## ğŸ“ ìš”ì•½

Lavida-OëŠ” ì´ë¯¸ì§€ ì´í•´ì™€ ìƒì„± ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” í†µí•© ë©€í‹°ëª¨ë‹¬ ë§ˆìŠ¤í¬ í™•ì‚° ëª¨ë¸(MDM)ì…ë‹ˆë‹¤. ê¸°ì¡´ ëª¨ë¸ë“¤ì´ ë‹¨ìˆœ ì´ë¯¸ì§€ ì´í•´ì™€ ì €í•´ìƒë„ ì´ë¯¸ì§€ ìƒì„±ì— ê·¸ì³¤ë‹¤ë©´, Lavida-OëŠ” ê°ì²´ ì—°ê²°, ì´ë¯¸ì§€ í¸ì§‘, ê³ í•´ìƒë„ ì´ë¯¸ì§€ í•©ì„±(1024px) ë“±ì˜ ìƒˆë¡œìš´ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. íŠ¹íˆ, ì´í•´ ëŠ¥ë ¥ì„ í™œìš©í•´ ì´ë¯¸ì§€ ìƒì„±ê³¼ í¸ì§‘ ê²°ê³¼ë¥¼ ê°œì„ í•˜ëŠ” ê³„íš ë° ë°˜ë³µì  ìê¸° ë°˜ì„±ì„ ìˆ˜í–‰í•˜ëŠ” ìµœì´ˆì˜ í†µí•© MDMì…ë‹ˆë‹¤. íš¨ê³¼ì ì¸ í•™ìŠµê³¼ ìƒ˜í”Œë§ì„ ìœ„í•´ Elastic Mixture-of-Transformer ì•„í‚¤í…ì²˜, ë²”ìš© í…ìŠ¤íŠ¸ ì¡°ê±´í™”, ê³„ì¸µì  ìƒ˜í”Œë§ ë“±ì˜ ê¸°ìˆ ì„ ë„ì…í–ˆìŠµë‹ˆë‹¤. Lavida-OëŠ” RefCOCO ê°ì²´ ì—°ê²°, GenEval í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ìƒì„±, ImgEdit ì´ë¯¸ì§€ í¸ì§‘ ë“± ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ë©°, ê¸°ì¡´ ëª¨ë¸ë“¤ë³´ë‹¤ ë¹ ë¥¸ ì¶”ë¡  ì†ë„ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Lavida-OëŠ” ì´ë¯¸ì§€ ì´í•´ ë° ìƒì„± ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” í†µí•© ë©€í‹°ëª¨ë‹¬ ë§ˆìŠ¤í¬ í™•ì‚° ëª¨ë¸(MDM)ì…ë‹ˆë‹¤.
- 2. Lavida-OëŠ” ê°ì²´ ê·¸ë¼ìš´ë”©, ì´ë¯¸ì§€ í¸ì§‘, ê³ í•´ìƒë„(1024px) ì´ë¯¸ì§€ í•©ì„± ë“± ìƒˆë¡œìš´ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
- 3. Lavida-OëŠ” ì´í•´ ëŠ¥ë ¥ì„ í™œìš©í•˜ì—¬ ì´ë¯¸ì§€ ìƒì„± ë° í¸ì§‘ ê²°ê³¼ë¥¼ ê³„íš ë° ë°˜ë³µì  ìê¸° ë°˜ì„±ì„ í†µí•´ ê°œì„ í•©ë‹ˆë‹¤.
- 4. Elastic Mixture-of-Transformer ì•„í‚¤í…ì²˜, ë²”ìš© í…ìŠ¤íŠ¸ ì¡°ê±´í™”, ê³„ì¸µì  ìƒ˜í”Œë§ê³¼ ê°™ì€ ìƒˆë¡œìš´ ê¸°ìˆ ì„ ë„ì…í•˜ì—¬ íš¨ìœ¨ì ì¸ í•™ìŠµ ë° ìƒ˜í”Œë§ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
- 5. Lavida-OëŠ” RefCOCO ê°ì²´ ê·¸ë¼ìš´ë”©, GenEval í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ìƒì„±, ImgEdit ì´ë¯¸ì§€ í¸ì§‘ ë“± ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ë©°, ê¸°ì¡´ ëª¨ë¸ë³´ë‹¤ ì¶”ë¡  ì†ë„ë¥¼ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤.


---

*Generated on 2025-09-24 16:19:46*