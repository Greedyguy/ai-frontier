<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T14:11:52.861860",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Adversarial Examples",
    "Domain Generalization",
    "Jailbreaking Large Language Models",
    "Deep Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Adversarial Examples": 0.78,
    "Domain Generalization": 0.79,
    "Jailbreaking Large Language Models": 0.81,
    "Deep Learning": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "adversarial examples",
        "canonical": "Adversarial Examples",
        "aliases": [
          "adversarial attacks"
        ],
        "category": "specific_connectable",
        "rationale": "Adversarial examples are crucial for understanding vulnerabilities in deep learning models, linking to robustness strategies.",
        "novelty_score": 0.65,
        "connectivity_score": 0.85,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "domain generalization",
        "canonical": "Domain Generalization",
        "aliases": [
          "distribution generalization"
        ],
        "category": "specific_connectable",
        "rationale": "Domain generalization is key for training models that perform well on unseen data, enhancing cross-domain learning links.",
        "novelty_score": 0.68,
        "connectivity_score": 0.82,
        "specificity_score": 0.77,
        "link_intent_score": 0.79
      },
      {
        "surface": "jailbreaking large language models",
        "canonical": "Jailbreaking Large Language Models",
        "aliases": [
          "LLM jailbreaking"
        ],
        "category": "unique_technical",
        "rationale": "This concept is emerging as a critical area of study for ensuring the ethical use of language models.",
        "novelty_score": 0.72,
        "connectivity_score": 0.78,
        "specificity_score": 0.85,
        "link_intent_score": 0.81
      },
      {
        "surface": "deep learning",
        "canonical": "Deep Learning",
        "aliases": [
          "DL"
        ],
        "category": "broad_technical",
        "rationale": "Deep learning is a foundational concept that connects various advanced topics in the paper.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "robustness properties",
      "training paradigms",
      "certification algorithms"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "adversarial examples",
      "resolved_canonical": "Adversarial Examples",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.85,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "domain generalization",
      "resolved_canonical": "Domain Generalization",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.82,
        "specificity": 0.77,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "jailbreaking large language models",
      "resolved_canonical": "Jailbreaking Large Language Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.78,
        "specificity": 0.85,
        "link_intent": 0.81
      }
    },
    {
      "candidate_surface": "deep learning",
      "resolved_canonical": "Deep Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Algorithms for Adversarially Robust Deep Learning

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19100.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2509.19100](https://arxiv.org/abs/2509.19100)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Sugar-Coated Poison_ Benign Generation Unlocks LLM Jailbreaking_20250923|Sugar-Coated Poison: Benign Generation Unlocks LLM Jailbreaking]] (88.7% similar)
- [[2025-09-23/Large Language Models for Cyber Security_ A Systematic Literature Review_20250923|Large Language Models for Cyber Security: A Systematic Literature Review]] (87.3% similar)
- [[2025-09-19/Enterprise AI Must Enforce Participant-Aware Access Control_20250919|Enterprise AI Must Enforce Participant-Aware Access Control]] (85.5% similar)
- [[2025-09-23/Reasoning-to-Defend_ Safety-Aware Reasoning Can Defend Large Language Models from Jailbreaking_20250923|Reasoning-to-Defend: Safety-Aware Reasoning Can Defend Large Language Models from Jailbreaking]] (85.4% similar)
- [[2025-09-22/Activation Space Interventions Can Be Transferred Between Large Language Models_20250922|Activation Space Interventions Can Be Transferred Between Large Language Models]] (85.4% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Deep Learning|Deep Learning]]
**ğŸ”— Specific Connectable**: [[keywords/Adversarial Examples|Adversarial Examples]], [[keywords/Domain Generalization|Domain Generalization]]
**âš¡ Unique Technical**: [[keywords/Jailbreaking Large Language Models|Jailbreaking Large Language Models]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19100v1 Announce Type: cross 
Abstract: Given the widespread use of deep learning models in safety-critical applications, ensuring that the decisions of such models are robust against adversarial exploitation is of fundamental importance. In this thesis, we discuss recent progress toward designing algorithms that exhibit desirable robustness properties. First, we discuss the problem of adversarial examples in computer vision, for which we introduce new technical results, training paradigms, and certification algorithms. Next, we consider the problem of domain generalization, wherein the task is to train neural networks to generalize from a family of training distributions to unseen test distributions. We present new algorithms that achieve state-of-the-art generalization in medical imaging, molecular identification, and image classification. Finally, we study the setting of jailbreaking large language models (LLMs), wherein an adversarial user attempts to design prompts that elicit objectionable content from an LLM. We propose new attacks and defenses, which represent the frontier of progress toward designing robust language-based agents.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì•ˆì „ì´ ì¤‘ìš”í•œ ì‘ìš© ë¶„ì•¼ì—ì„œ ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ ê²°ì •ì´ ì ëŒ€ì  ê³µê²©ì— ëŒ€í•´ ê²¬ê³ í•˜ë„ë¡ ë³´ì¥í•˜ëŠ” ë°©ë²•ì„ ì—°êµ¬í•©ë‹ˆë‹¤. ë¨¼ì €, ì»´í“¨í„° ë¹„ì „ì—ì„œì˜ ì ëŒ€ì  ì˜ˆì œ ë¬¸ì œë¥¼ ë‹¤ë£¨ë©°, ìƒˆë¡œìš´ ê¸°ìˆ  ê²°ê³¼, í›ˆë ¨ íŒ¨ëŸ¬ë‹¤ì„, ì¸ì¦ ì•Œê³ ë¦¬ì¦˜ì„ ì œì‹œí•©ë‹ˆë‹¤. ë˜í•œ, ë„ë©”ì¸ ì¼ë°˜í™” ë¬¸ì œë¥¼ ë‹¤ë£¨ì–´, ì˜ë£Œ ì˜ìƒ, ë¶„ì ì‹ë³„, ì´ë¯¸ì§€ ë¶„ë¥˜ì—ì„œ ìµœì²¨ë‹¨ ì¼ë°˜í™”ë¥¼ ë‹¬ì„±í•˜ëŠ” ìƒˆë¡œìš´ ì•Œê³ ë¦¬ì¦˜ì„ ì†Œê°œí•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ, ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ íƒˆì˜¥ ìƒí™©ì„ ì—°êµ¬í•˜ì—¬, ì ëŒ€ì  ì‚¬ìš©ìê°€ LLMì—ì„œ ë¶€ì ì ˆí•œ ì½˜í…ì¸ ë¥¼ ìœ ë„í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì„¤ê³„í•˜ëŠ” ë¬¸ì œë¥¼ ë‹¤ë£¨ê³ , ì´ì— ëŒ€í•œ ìƒˆë¡œìš´ ê³µê²© ë° ë°©ì–´ ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì•ˆì „ì´ ì¤‘ìš”í•œ ì‘ìš© ë¶„ì•¼ì—ì„œ ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ ê²°ì •ì´ ì ëŒ€ì  ê³µê²©ì— ëŒ€í•´ ê²¬ê³ í•˜ë„ë¡ ë³´ì¥í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤.
- 2. ì»´í“¨í„° ë¹„ì „ì—ì„œ ì ëŒ€ì  ì˜ˆì œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ê¸°ìˆ  ê²°ê³¼, í›ˆë ¨ íŒ¨ëŸ¬ë‹¤ì„, ì¸ì¦ ì•Œê³ ë¦¬ì¦˜ì„ ì†Œê°œí•œë‹¤.
- 3. ë„ë©”ì¸ ì¼ë°˜í™” ë¬¸ì œë¥¼ ë‹¤ë£¨ë©°, ìƒˆë¡œìš´ ì•Œê³ ë¦¬ì¦˜ì„ í†µí•´ ì˜ë£Œ ì˜ìƒ, ë¶„ì ì‹ë³„, ì´ë¯¸ì§€ ë¶„ë¥˜ì—ì„œ ìµœì²¨ë‹¨ ì¼ë°˜í™”ë¥¼ ë‹¬ì„±í•œë‹¤.
- 4. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ íƒˆì˜¥ ìƒí™©ì„ ì—°êµ¬í•˜ë©°, ì ëŒ€ì  ì‚¬ìš©ìê°€ LLMì—ì„œ ë°˜ëŒ€ë˜ëŠ” ì½˜í…ì¸ ë¥¼ ìœ ë„í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì„¤ê³„í•˜ëŠ” ë¬¸ì œë¥¼ ë‹¤ë£¬ë‹¤.
- 5. ê²¬ê³ í•œ ì–¸ì–´ ê¸°ë°˜ ì—ì´ì „íŠ¸ë¥¼ ì„¤ê³„í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ê³µê²© ë° ë°©ì–´ ë°©ë²•ì„ ì œì•ˆí•œë‹¤.


---

*Generated on 2025-09-24 14:11:52*