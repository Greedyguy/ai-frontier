<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T13:55:56.632844",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Natural Language Processing",
    "Fine-Tuning",
    "Low-Rank Adaptation",
    "Sensitivity-Aware Adaptation",
    "Quality-Aware Sampling"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Natural Language Processing": 0.8,
    "Fine-Tuning": 0.9,
    "Low-Rank Adaptation": 0.85,
    "Sensitivity-Aware Adaptation": 0.75,
    "Quality-Aware Sampling": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Natural Language Processing",
        "canonical": "Natural Language Processing",
        "aliases": [
          "NLP"
        ],
        "category": "broad_technical",
        "rationale": "This is a fundamental domain for the discussed fine-tuning methods, providing a broad context for linking.",
        "novelty_score": 0.2,
        "connectivity_score": 0.9,
        "specificity_score": 0.5,
        "link_intent_score": 0.8
      },
      {
        "surface": "fine-tuning",
        "canonical": "Fine-Tuning",
        "aliases": [
          "model adaptation"
        ],
        "category": "specific_connectable",
        "rationale": "Fine-tuning is central to the paper's methodology, offering strong linkage to related adaptation techniques.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.9
      },
      {
        "surface": "low-rank adaptation",
        "canonical": "Low-Rank Adaptation",
        "aliases": [
          "low-rank model adaptation"
        ],
        "category": "unique_technical",
        "rationale": "This is a specific technique introduced in the paper, crucial for understanding the proposed method.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.85
      },
      {
        "surface": "sensitivity-aware",
        "canonical": "Sensitivity-Aware Adaptation",
        "aliases": [
          "sensitivity-based tuning"
        ],
        "category": "unique_technical",
        "rationale": "This concept is novel and central to the paper's approach, offering a new perspective on model adaptation.",
        "novelty_score": 0.8,
        "connectivity_score": 0.5,
        "specificity_score": 0.9,
        "link_intent_score": 0.75
      },
      {
        "surface": "quality-aware sampling",
        "canonical": "Quality-Aware Sampling",
        "aliases": [
          "data-quality sampling"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel component of the proposed method, emphasizing the importance of data quality in model training.",
        "novelty_score": 0.7,
        "connectivity_score": 0.55,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "experiment"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Natural Language Processing",
      "resolved_canonical": "Natural Language Processing",
      "decision": "linked",
      "scores": {
        "novelty": 0.2,
        "connectivity": 0.9,
        "specificity": 0.5,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "fine-tuning",
      "resolved_canonical": "Fine-Tuning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.9
      }
    },
    {
      "candidate_surface": "low-rank adaptation",
      "resolved_canonical": "Low-Rank Adaptation",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "sensitivity-aware",
      "resolved_canonical": "Sensitivity-Aware Adaptation",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.5,
        "specificity": 0.9,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "quality-aware sampling",
      "resolved_canonical": "Quality-Aware Sampling",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.55,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# TsqLoRA: Towards Sensitivity and Quality Low-Rank Adaptation for Efficient Fine-Tuning

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18585.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2509.18585](https://arxiv.org/abs/2509.18585)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/RefLoRA_ Refactored Low-Rank Adaptation for Efficient Fine-Tuning of Large Models_20250923|RefLoRA: Refactored Low-Rank Adaptation for Efficient Fine-Tuning of Large Models]] (86.7% similar)
- [[2025-09-23/Robust Federated Finetuning of LLMs via Alternating Optimization of LoRA_20250923|Robust Federated Finetuning of LLMs via Alternating Optimization of LoRA]] (86.1% similar)
- [[2025-09-23/TASO_ Task-Aligned Sparse Optimization for Parameter-Efficient Model Adaptation_20250923|TASO: Task-Aligned Sparse Optimization for Parameter-Efficient Model Adaptation]] (85.1% similar)
- [[2025-09-23/SEQR_ Secure and Efficient QR-based LoRA Routing_20250923|SEQR: Secure and Efficient QR-based LoRA Routing]] (84.2% similar)
- [[2025-09-22/Sparsity May Be All You Need_ Sparse Random Parameter Adaptation_20250922|Sparsity May Be All You Need: Sparse Random Parameter Adaptation]] (83.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Natural Language Processing|Natural Language Processing]]
**ğŸ”— Specific Connectable**: [[keywords/Fine-Tuning|Fine-Tuning]]
**âš¡ Unique Technical**: [[keywords/Low-Rank Adaptation|Low-Rank Adaptation]], [[keywords/Sensitivity-Aware Adaptation|Sensitivity-Aware Adaptation]], [[keywords/Quality-Aware Sampling|Quality-Aware Sampling]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18585v1 Announce Type: cross 
Abstract: Fine-tuning large pre-trained models for downstream tasks has become a fundamental approach in natural language processing. Fully fine-tuning all model parameters is computationally expensive and memory-intensive, especially in resource-constrained environments. Existing parameter-efficient fine-tuning methods reduce the number of trainable parameters but typically overlook the varying sensitivity of different model layers and the importance of training data. In this work, we propose TsqLoRA, a novel method that integrates data-quality-driven selection with sensitivity-aware low-rank adaptation, consisted of two main components: a quality-aware sampling mechanism for selecting the most informative training data, and a dynamic rank allocation module that adjusts the rank of each layer based on its sensitivity to parameter updates. The experimental results demonstrate that TsqLoRA improves fine-tuning efficiency while maintaining or even improving performance on a variety of NLP tasks. Our code will be available at https://github.com/Benjamin-Ricky/TsqLoRA.

## ğŸ“ ìš”ì•½

ëŒ€ê·œëª¨ ì‚¬ì „ í•™ìŠµ ëª¨ë¸ì˜ íŒŒì¸íŠœë‹ì€ ìì—°ì–´ ì²˜ë¦¬ì—ì„œ ì¤‘ìš”í•œ ì ‘ê·¼ë²•ì´ì§€ë§Œ, ëª¨ë“  ëª¨ë¸ íŒŒë¼ë¯¸í„°ë¥¼ ì™„ì „íˆ íŒŒì¸íŠœë‹í•˜ëŠ” ê²ƒì€ ë¹„ìš©ì´ ë§ì´ ë“¤ê³  ë©”ëª¨ë¦¬ë¥¼ ë§ì´ ì†Œëª¨í•©ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ TsqLoRAë¼ëŠ” ìƒˆë¡œìš´ ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. TsqLoRAëŠ” ë°ì´í„° í’ˆì§ˆ ê¸°ë°˜ ì„ íƒê³¼ ë¯¼ê°ë„ ì¸ì‹ ì €ë­í¬ ì ì‘ì„ í†µí•©í•˜ì—¬, ì •ë³´ê°€ í’ë¶€í•œ í•™ìŠµ ë°ì´í„°ë¥¼ ì„ íƒí•˜ëŠ” í’ˆì§ˆ ì¸ì‹ ìƒ˜í”Œë§ ë©”ì»¤ë‹ˆì¦˜ê³¼ ê° ì¸µì˜ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ ë¯¼ê°ë„ì— ë”°ë¼ ë­í¬ë¥¼ ì¡°ì •í•˜ëŠ” ë™ì  ë­í¬ í• ë‹¹ ëª¨ë“ˆë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, TsqLoRAëŠ” ë‹¤ì–‘í•œ NLP ê³¼ì œì—ì„œ ì„±ëŠ¥ì„ ìœ ì§€í•˜ê±°ë‚˜ í–¥ìƒì‹œí‚¤ë©´ì„œ íŒŒì¸íŠœë‹ íš¨ìœ¨ì„±ì„ ê°œì„ í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. TsqLoRAëŠ” ë°ì´í„° í’ˆì§ˆ ê¸°ë°˜ ì„ íƒê³¼ ë¯¼ê°ë„ ì¸ì‹ ì €ë­í¬ ì ì‘ì„ í†µí•©í•œ ìƒˆë¡œìš´ ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤.
- 2. ì´ ë°©ë²•ì€ ì •ë³´ì„±ì´ ë†’ì€ í›ˆë ¨ ë°ì´í„°ë¥¼ ì„ íƒí•˜ëŠ” í’ˆì§ˆ ì¸ì‹ ìƒ˜í”Œë§ ë©”ì»¤ë‹ˆì¦˜ì„ í¬í•¨í•©ë‹ˆë‹¤.
- 3. ê° ë ˆì´ì–´ì˜ ë¯¼ê°ë„ì— ë”°ë¼ ë­í¬ë¥¼ ì¡°ì •í•˜ëŠ” ë™ì  ë­í¬ í• ë‹¹ ëª¨ë“ˆì„ ì œê³µí•©ë‹ˆë‹¤.
- 4. TsqLoRAëŠ” ë‹¤ì–‘í•œ NLP ì‘ì—…ì—ì„œ ì„±ëŠ¥ì„ ìœ ì§€í•˜ê±°ë‚˜ í–¥ìƒì‹œí‚¤ë©´ì„œë„ ë¯¸ì„¸ ì¡°ì • íš¨ìœ¨ì„±ì„ ê°œì„ í•©ë‹ˆë‹¤.
- 5. TsqLoRAì˜ ì½”ë“œëŠ” https://github.com/Benjamin-Ricky/TsqLoRAì—ì„œ ì œê³µë  ì˜ˆì •ì…ë‹ˆë‹¤.


---

*Generated on 2025-09-24 13:55:56*