<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T15:52:26.585450",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Misinformation Propagation",
    "Mathematical Reasoning",
    "Factual Corrections"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Misinformation Propagation": 0.88,
    "Mathematical Reasoning": 0.8,
    "Factual Corrections": 0.82
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Central to the study, linking to broader discussions on AI models.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Misinformation Propagation",
        "canonical": "Misinformation Propagation",
        "aliases": [
          "Misinformation Spread"
        ],
        "category": "unique_technical",
        "rationale": "Key focus of the paper, offering a unique angle on LLM challenges.",
        "novelty_score": 0.75,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.88
      },
      {
        "surface": "Mathematical Reasoning",
        "canonical": "Mathematical Reasoning",
        "aliases": [
          "Math Reasoning"
        ],
        "category": "specific_connectable",
        "rationale": "Specific application area of LLMs, relevant for linking to reasoning studies.",
        "novelty_score": 0.5,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Factual Corrections",
        "canonical": "Factual Corrections",
        "aliases": [
          "Fact Correction"
        ],
        "category": "unique_technical",
        "rationale": "Addresses a specific intervention strategy in LLM reasoning.",
        "novelty_score": 0.65,
        "connectivity_score": 0.6,
        "specificity_score": 0.75,
        "link_intent_score": 0.82
      }
    ],
    "ban_list_suggestions": [
      "reasoning process",
      "accuracy drops"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Misinformation Propagation",
      "resolved_canonical": "Misinformation Propagation",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "Mathematical Reasoning",
      "resolved_canonical": "Mathematical Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Factual Corrections",
      "resolved_canonical": "Factual Corrections",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.6,
        "specificity": 0.75,
        "link_intent": 0.82
      }
    }
  ]
}
-->

# Unraveling Misinformation Propagation in LLM Reasoning

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2505.18555.pdf)
**Category**: cs.CL
**Published**: 2025-09-24
**ArXiv ID**: [2505.18555](https://arxiv.org/abs/2505.18555)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/No Need for Explanations_ LLMs can implicitly learn from mistakes in-context_20250923|No Need for Explanations: LLMs can implicitly learn from mistakes in-context]] (91.1% similar)
- [[2025-09-24/Thinking in a Crowd_ How Auxiliary Information Shapes LLM Reasoning_20250924|Thinking in a Crowd: How Auxiliary Information Shapes LLM Reasoning]] (87.0% similar)
- [[2025-09-23/Neither Stochastic Parroting nor AGI_ LLMs Solve Tasks through Context-Directed Extrapolation from Training Data Priors_20250923|Neither Stochastic Parroting nor AGI: LLMs Solve Tasks through Context-Directed Extrapolation from Training Data Priors]] (86.3% similar)
- [[2025-09-22/Are LLMs Better Formalizers than Solvers on Complex Problems?_20250922|Are LLMs Better Formalizers than Solvers on Complex Problems?]] (85.8% similar)
- [[2025-09-23/Does Reasoning Introduce Bias? A Study of Social Bias Evaluation and Mitigation in LLM Reasoning_20250923|Does Reasoning Introduce Bias? A Study of Social Bias Evaluation and Mitigation in LLM Reasoning]] (85.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Mathematical Reasoning|Mathematical Reasoning]]
**âš¡ Unique Technical**: [[keywords/Misinformation Propagation|Misinformation Propagation]], [[keywords/Factual Corrections|Factual Corrections]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2505.18555v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) have demonstrated impressive capabilities in reasoning, positioning them as promising tools for supporting human problem-solving. However, what happens when their performance is affected by misinformation, i.e., incorrect inputs introduced by users due to oversights or gaps in knowledge? Such misinformation is prevalent in real-world interactions with LLMs, yet how it propagates within LLMs' reasoning process remains underexplored. Focusing on mathematical reasoning, we present a comprehensive analysis of how misinformation affects intermediate reasoning steps and final answers. We also examine how effectively LLMs can correct misinformation when explicitly instructed to do so. Even with explicit instructions, LLMs succeed less than half the time in rectifying misinformation, despite possessing correct internal knowledge, leading to significant accuracy drops (10.02% - 72.20%), and the degradation holds with thinking models (4.30% - 19.97%). Further analysis shows that applying factual corrections early in the reasoning process most effectively reduces misinformation propagation, and fine-tuning on synthesized data with early-stage corrections significantly improves reasoning factuality. Our work offers a practical approach to mitigating misinformation propagation.

## ğŸ“ ìš”ì•½

ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ ë›°ì–´ë‚œ ì¶”ë¡  ëŠ¥ë ¥ì„ ë³´ì´ë©° ì¸ê°„ ë¬¸ì œ í•´ê²°ì„ ì§€ì›í•˜ëŠ” ë„êµ¬ë¡œ ì£¼ëª©ë°›ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì‚¬ìš©ì ì…ë ¥ ì˜¤ë¥˜ë¡œ ì¸í•œ ì˜ëª»ëœ ì •ë³´ê°€ ëª¨ë¸ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì€ ì¶©ë¶„íˆ íƒêµ¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ëŠ” ìˆ˜í•™ì  ì¶”ë¡ ì—ì„œ ì˜ëª»ëœ ì •ë³´ê°€ ì¤‘ê°„ ì¶”ë¡  ë‹¨ê³„ì™€ ìµœì¢… ë‹µë³€ì— ì–´ë–»ê²Œ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ë¥¼ ë¶„ì„í•˜ê³ , LLMì´ ëª…ì‹œì  ì§€ì‹œë¥¼ ë°›ì„ ë•Œ ì˜ëª»ëœ ì •ë³´ë¥¼ ì–¼ë§ˆë‚˜ íš¨ê³¼ì ìœ¼ë¡œ ìˆ˜ì •í•  ìˆ˜ ìˆëŠ”ì§€ë¥¼ ì¡°ì‚¬í–ˆìŠµë‹ˆë‹¤. LLMì€ ë‚´ë¶€ì ìœ¼ë¡œ ì˜¬ë°”ë¥¸ ì§€ì‹ì„ ê°€ì§€ê³  ìˆìŒì—ë„ ë¶ˆêµ¬í•˜ê³ , ëª…ì‹œì  ì§€ì‹œì—ë„ ë¶ˆêµ¬í•˜ê³  ì˜ëª»ëœ ì •ë³´ë¥¼ ìˆ˜ì •í•˜ëŠ” ë° ì ˆë°˜ ì´í•˜ì˜ ì„±ê³µë¥ ì„ ë³´ì˜€ìœ¼ë©°, ì´ëŠ” ì •í™•ë„ì— í° ì˜í–¥ì„ ë¯¸ì³¤ìŠµë‹ˆë‹¤. ì´ˆê¸° ë‹¨ê³„ì—ì„œ ì‚¬ì‹¤ì  ìˆ˜ì •ì„ ì ìš©í•˜ë©´ ì˜ëª»ëœ ì •ë³´ì˜ ì „íŒŒë¥¼ ê°€ì¥ íš¨ê³¼ì ìœ¼ë¡œ ì¤„ì¼ ìˆ˜ ìˆìœ¼ë©°, ì´ˆê¸° ë‹¨ê³„ ìˆ˜ì •ì´ í¬í•¨ëœ í•©ì„± ë°ì´í„°ë¡œ ë¯¸ì„¸ ì¡°ì •í•˜ë©´ ì¶”ë¡ ì˜ ì‚¬ì‹¤ì„±ì„ í¬ê²Œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ëŠ” ì˜ëª»ëœ ì •ë³´ ì „íŒŒë¥¼ ì¤„ì´ëŠ” ì‹¤ì§ˆì ì¸ ì ‘ê·¼ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì€ ì¸ê°„ ë¬¸ì œ í•´ê²°ì„ ì§€ì›í•˜ëŠ” ìœ ë§í•œ ë„êµ¬ë¡œì„œì˜ ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì£¼ê³  ìˆì§€ë§Œ, ì˜ëª»ëœ ì •ë³´ê°€ ëª¨ë¸ì˜ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì€ ì¶©ë¶„íˆ íƒêµ¬ë˜ì§€ ì•Šì•˜ë‹¤.
- 2. ìˆ˜í•™ì  ì¶”ë¡ ì— ì´ˆì ì„ ë§ì¶°, ì˜ëª»ëœ ì •ë³´ê°€ ì¤‘ê°„ ì¶”ë¡  ë‹¨ê³„ì™€ ìµœì¢… ë‹µë³€ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•˜ì˜€ë‹¤.
- 3. LLMsëŠ” ëª…ì‹œì ì¸ ì§€ì‹œê°€ ì£¼ì–´ì ¸ë„ ì˜ëª»ëœ ì •ë³´ë¥¼ ìˆ˜ì •í•˜ëŠ” ë° ì ˆë°˜ ì´í•˜ì˜ ì„±ê³µë¥ ì„ ë³´ì´ë©°, ì´ëŠ” ì •í™•ë„ì— í° ì˜í–¥ì„ ë¯¸ì¹œë‹¤.
- 4. ì¶”ë¡  ê³¼ì • ì´ˆê¸°ì— ì‚¬ì‹¤ì„ êµì •í•˜ëŠ” ê²ƒì´ ì˜ëª»ëœ ì •ë³´ì˜ ì „íŒŒë¥¼ ê°€ì¥ íš¨ê³¼ì ìœ¼ë¡œ ì¤„ì´ë©°, ì´ˆê¸° ë‹¨ê³„ êµì •ìœ¼ë¡œ í•©ì„± ë°ì´í„°ë¥¼ ë¯¸ì„¸ ì¡°ì •í•˜ë©´ ì¶”ë¡ ì˜ ì‚¬ì‹¤ì„±ì´ í¬ê²Œ í–¥ìƒëœë‹¤.
- 5. ë³¸ ì—°êµ¬ëŠ” ì˜ëª»ëœ ì •ë³´ ì „íŒŒë¥¼ ì™„í™”í•˜ê¸° ìœ„í•œ ì‹¤ì§ˆì ì¸ ì ‘ê·¼ë²•ì„ ì œì‹œí•œë‹¤.


---

*Generated on 2025-09-24 15:52:26*