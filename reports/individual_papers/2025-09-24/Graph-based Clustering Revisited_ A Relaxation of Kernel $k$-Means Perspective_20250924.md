<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T14:56:12.255492",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Graph Clustering",
    "Spectral Clustering",
    "Doubly Stochastic Matrix",
    "Kernel k-Means",
    "Block Diagonal Regularization"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Graph Clustering": 0.78,
    "Spectral Clustering": 0.79,
    "Doubly Stochastic Matrix": 0.77,
    "Kernel k-Means": 0.75,
    "Block Diagonal Regularization": 0.74
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "graph-based clustering",
        "canonical": "Graph Clustering",
        "aliases": [
          "graph clustering"
        ],
        "category": "specific_connectable",
        "rationale": "Graph Clustering is a foundational concept that connects to various graph-based algorithms and methods.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.72,
        "link_intent_score": 0.78
      },
      {
        "surface": "spectral clustering",
        "canonical": "Spectral Clustering",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Spectral Clustering is a well-known method in machine learning, linking to various graph and clustering techniques.",
        "novelty_score": 0.46,
        "connectivity_score": 0.85,
        "specificity_score": 0.8,
        "link_intent_score": 0.79
      },
      {
        "surface": "doubly stochastic normalization",
        "canonical": "Doubly Stochastic Matrix",
        "aliases": [
          "doubly stochastic matrices"
        ],
        "category": "unique_technical",
        "rationale": "Doubly Stochastic Matrices are crucial in optimization and clustering, providing a unique technical perspective.",
        "novelty_score": 0.68,
        "connectivity_score": 0.72,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      },
      {
        "surface": "kernel k-means",
        "canonical": "Kernel k-Means",
        "aliases": [
          "kernel kmeans"
        ],
        "category": "specific_connectable",
        "rationale": "Kernel k-Means is a variant of k-means clustering that is widely used in machine learning.",
        "novelty_score": 0.52,
        "connectivity_score": 0.83,
        "specificity_score": 0.78,
        "link_intent_score": 0.75
      },
      {
        "surface": "block diagonal regularization",
        "canonical": "Block Diagonal Regularization",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Block Diagonal Regularization is a novel technique enhancing clustering performance, offering a unique technical approach.",
        "novelty_score": 0.71,
        "connectivity_score": 0.69,
        "specificity_score": 0.82,
        "link_intent_score": 0.74
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "graph-based clustering",
      "resolved_canonical": "Graph Clustering",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.72,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "spectral clustering",
      "resolved_canonical": "Spectral Clustering",
      "decision": "linked",
      "scores": {
        "novelty": 0.46,
        "connectivity": 0.85,
        "specificity": 0.8,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "doubly stochastic normalization",
      "resolved_canonical": "Doubly Stochastic Matrix",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.72,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "kernel k-means",
      "resolved_canonical": "Kernel k-Means",
      "decision": "linked",
      "scores": {
        "novelty": 0.52,
        "connectivity": 0.83,
        "specificity": 0.78,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "block diagonal regularization",
      "resolved_canonical": "Block Diagonal Regularization",
      "decision": "linked",
      "scores": {
        "novelty": 0.71,
        "connectivity": 0.69,
        "specificity": 0.82,
        "link_intent": 0.74
      }
    }
  ]
}
-->

# Graph-based Clustering Revisited: A Relaxation of Kernel $k$-Means Perspective

## 📋 메타데이터

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18826.pdf)
**Category**: cs.LG
**Published**: 2025-09-24
**ArXiv ID**: [2509.18826](https://arxiv.org/abs/2509.18826)

## 🔗 유사한 논문
- [[2025-09-23/Accurate and Efficient Low-Rank Model Merging in Core Space_20250923|Accurate and Efficient Low-Rank Model Merging in Core Space]] (82.4% similar)
- [[2025-09-23/Robust Federated Finetuning of LLMs via Alternating Optimization of LoRA_20250923|Robust Federated Finetuning of LLMs via Alternating Optimization of LoRA]] (81.5% similar)
- [[2025-09-17/Decentralized Optimization with Topology-Independent Communication_20250917|Decentralized Optimization with Topology-Independent Communication]] (81.0% similar)
- [[2025-09-23/RefLoRA_ Refactored Low-Rank Adaptation for Efficient Fine-Tuning of Large Models_20250923|RefLoRA: Refactored Low-Rank Adaptation for Efficient Fine-Tuning of Large Models]] (80.9% similar)
- [[2025-09-24/Subspace Clustering of Subspaces_ Unifying Canonical Correlation Analysis and Subspace Clustering_20250924|Subspace Clustering of Subspaces: Unifying Canonical Correlation Analysis and Subspace Clustering]] (80.7% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Graph Clustering|Graph Clustering]], [[keywords/Spectral Clustering|Spectral Clustering]], [[keywords/Kernel k-Means|Kernel k-Means]]
**⚡ Unique Technical**: [[keywords/Doubly Stochastic Matrix|Doubly Stochastic Matrix]], [[keywords/Block Diagonal Regularization|Block Diagonal Regularization]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.18826v1 Announce Type: new 
Abstract: The well-known graph-based clustering methods, including spectral clustering, symmetric non-negative matrix factorization, and doubly stochastic normalization, can be viewed as relaxations of the kernel $k$-means approach. However, we posit that these methods excessively relax their inherent low-rank, nonnegative, doubly stochastic, and orthonormal constraints to ensure numerical feasibility, potentially limiting their clustering efficacy. In this paper, guided by our theoretical analyses, we propose \textbf{Lo}w-\textbf{R}ank \textbf{D}oubly stochastic clustering (\textbf{LoRD}), a model that only relaxes the orthonormal constraint to derive a probabilistic clustering results. Furthermore, we theoretically establish the equivalence between orthogonality and block diagonality under the doubly stochastic constraint. By integrating \textbf{B}lock diagonal regularization into LoRD, expressed as the maximization of the Frobenius norm, we propose \textbf{B-LoRD}, which further enhances the clustering performance. To ensure numerical solvability, we transform the non-convex doubly stochastic constraint into a linear convex constraint through the introduction of a class probability parameter. We further theoretically demonstrate the gradient Lipschitz continuity of our LoRD and B-LoRD enables the proposal of a globally convergent projected gradient descent algorithm for their optimization. Extensive experiments validate the effectiveness of our approaches. The code is publicly available at https://github.com/lwl-learning/LoRD.

## 📝 요약

이 논문에서는 기존의 그래프 기반 클러스터링 방법들이 본래의 저차원, 비음수, 이중 확률적, 직교 제약 조건을 과도하게 완화하여 클러스터링 효율성을 제한할 수 있다고 주장합니다. 저자들은 직교 제약만을 완화하여 확률적 클러스터링 결과를 도출하는 LoRD(저차원 이중 확률적 클러스터링) 모델을 제안합니다. 또한, 이중 확률적 제약 하에서 직교성과 블록 대각성의 동등성을 이론적으로 입증하고, Frobenius 노름을 최대화하는 블록 대각 정규화를 통합한 B-LoRD를 제안하여 클러스터링 성능을 향상시킵니다. 비볼록 이중 확률적 제약을 선형 볼록 제약으로 변환하여 수치적 해를 보장하고, 이론적으로 LoRD와 B-LoRD의 전역 수렴을 보장하는 투영 경사 하강 알고리즘을 제안합니다. 실험 결과는 제안된 방법의 효과성을 입증하며, 코드는 공개되어 있습니다.

## 🎯 주요 포인트

- 1. 기존의 그래프 기반 클러스터링 방법들은 커널 $k$-평균 접근법의 완화로 볼 수 있으며, 이들은 본래의 저순위, 비음수, 이중 확률, 직교 제약을 과도하게 완화하여 클러스터링 효율성을 제한할 수 있다.
- 2. 본 연구에서는 직교 제약만을 완화하여 확률적 클러스터링 결과를 도출하는 저순위 이중 확률 클러스터링(LoRD) 모델을 제안한다.
- 3. 이중 확률 제약 하에서 직교성과 블록 대각성의 동등성을 이론적으로 확립하고, Frobenius 노름의 최대화를 통해 블록 대각 정규화를 통합한 B-LoRD를 제안하여 클러스터링 성능을 향상시킨다.
- 4. 비볼록 이중 확률 제약을 선형 볼록 제약으로 변환하여 수치적 해결 가능성을 보장하고, LoRD와 B-LoRD의 최적화를 위한 전역 수렴 투영 경사 하강 알고리즘을 제안한다.
- 5. 광범위한 실험을 통해 제안된 방법들의 효과성을 검증하였으며, 코드는 공개적으로 이용 가능하다.


---

*Generated on 2025-09-24 14:56:12*