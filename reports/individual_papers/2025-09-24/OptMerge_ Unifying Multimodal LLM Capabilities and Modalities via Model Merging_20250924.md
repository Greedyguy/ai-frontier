<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T14:20:50.746535",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multimodal Learning",
    "Model Merging",
    "Vision-Language Model",
    "Omni-language Model"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multimodal Learning": 0.85,
    "Model Merging": 0.79,
    "Vision-Language Model": 0.82,
    "Omni-language Model": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multimodal LLMs",
        "canonical": "Multimodal Learning",
        "aliases": [
          "MLLMs",
          "Multimodal Large Language Models"
        ],
        "category": "specific_connectable",
        "rationale": "Multimodal Learning is a trending concept that connects various modalities, enhancing the understanding of complex data interactions.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.78,
        "link_intent_score": 0.85
      },
      {
        "surface": "Model Merging",
        "canonical": "Model Merging",
        "aliases": [
          "Merging Models"
        ],
        "category": "unique_technical",
        "rationale": "Model Merging is a novel approach to combine expert models, which is crucial for advancing multimodal capabilities.",
        "novelty_score": 0.72,
        "connectivity_score": 0.67,
        "specificity_score": 0.81,
        "link_intent_score": 0.79
      },
      {
        "surface": "Vision-Language",
        "canonical": "Vision-Language Model",
        "aliases": [
          "Vision-Language Models"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-Language Models are essential for integrating visual and textual data, a key aspect of multimodal systems.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.75,
        "link_intent_score": 0.82
      },
      {
        "surface": "Omni-language model",
        "canonical": "Omni-language Model",
        "aliases": [
          "Universal Language Model"
        ],
        "category": "unique_technical",
        "rationale": "The Omni-language Model represents a comprehensive approach to unify multiple language modalities, pushing the boundaries of language understanding.",
        "novelty_score": 0.68,
        "connectivity_score": 0.6,
        "specificity_score": 0.83,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "benchmark",
      "tasks",
      "performance gain"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multimodal LLMs",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.78,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Model Merging",
      "resolved_canonical": "Model Merging",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.67,
        "specificity": 0.81,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Vision-Language",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.75,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Omni-language model",
      "resolved_canonical": "Omni-language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.6,
        "specificity": 0.83,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# OptMerge: Unifying Multimodal LLM Capabilities and Modalities via Model Merging

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2505.19892.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2505.19892](https://arxiv.org/abs/2505.19892)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/AIMMerging_ Adaptive Iterative Model Merging Using Training Trajectories for Language Model Continual Learning_20250923|AIMMerging: Adaptive Iterative Model Merging Using Training Trajectories for Language Model Continual Learning]] (88.1% similar)
- [[2025-09-23/Both Text and Images Leaked! A Systematic Analysis of Data Contamination in Multimodal LLM_20250923|Both Text and Images Leaked! A Systematic Analysis of Data Contamination in Multimodal LLM]] (86.9% similar)
- [[2025-09-19/Modular Machine Learning_ An Indispensable Path towards New-Generation Large Language Models_20250919|Modular Machine Learning: An Indispensable Path towards New-Generation Large Language Models]] (86.6% similar)
- [[2025-09-19/Decoupled Proxy Alignment_ Mitigating Language Prior Conflict for Multimodal Alignment in MLLM_20250919|Decoupled Proxy Alignment: Mitigating Language Prior Conflict for Multimodal Alignment in MLLM]] (86.6% similar)
- [[2025-09-23/LEO-MINI_ An Efficient Multimodal Large Language Model using Conditional Token Reduction and Mixture of Multi-Modal Experts_20250923|LEO-MINI: An Efficient Multimodal Large Language Model using Conditional Token Reduction and Mixture of Multi-Modal Experts]] (86.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**âš¡ Unique Technical**: [[keywords/Model Merging|Model Merging]], [[keywords/Omni-language Model|Omni-language Model]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2505.19892v2 Announce Type: replace 
Abstract: Foundation models update slowly due to resource-intensive training, whereas domain-specific models evolve rapidly between releases. Model merging seeks to combine multiple expert models into a single, more capable model, reducing storage and serving costs while supporting decentralized development. Despite its potential, previous studies have primarily focused on merging visual classification models or Large Language Models (LLMs) for code and math tasks. Recently, Multimodal LLMs (MLLMs) that extend LLMs through large-scale multimodal training have gained traction. However, there lacks a benchmark for model merging research that clearly divides the tasks for MLLM training and evaluation. In this paper, $\textbf{(i)}$ we introduce a model merging benchmark for MLLMs, which includes multiple tasks such as VQA, Geometry, Chart, OCR, and Grounding, studying both LoRA and full fine-tuning models. Moreover, we explore how model merging can combine different modalities (e.g., vision-language, audio-language, and video-language models), moving toward the Omni-language model. $\textbf{(ii)}$ We implement 10 model merging algorithms on the benchmark. Furthermore, we propose a novel method that removes noise from task vectors and robustly optimizes the merged vector based on a loss defined over task vector interactions, achieving an average performance gain of 2.48%. $\textbf{(iii)}$ We find that model merging offers a promising way for building improved MLLMs without requiring training data. Our results also demonstrate that the complementarity among multiple modalities outperforms individual modalities.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë©€í‹°ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(MMLM)ì˜ ëª¨ë¸ ë³‘í•© ì—°êµ¬ë¥¼ ìœ„í•œ ë²¤ì¹˜ë§ˆí¬ë¥¼ ì œì•ˆí•˜ë©°, VQA, ê¸°í•˜í•™, ì°¨íŠ¸, OCR, ê·¸ë¼ìš´ë”© ë“±ì˜ ë‹¤ì–‘í•œ ê³¼ì œë¥¼ í¬í•¨í•©ë‹ˆë‹¤. ì—°êµ¬ì—ì„œëŠ” LoRA ë° ì „ì²´ ë¯¸ì„¸ ì¡°ì • ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ ë³‘í•©ì´ ì–´ë–»ê²Œ ë‹¤ì–‘í•œ ëª¨ë‹¬ë¦¬í‹°ë¥¼ ê²°í•©í•  ìˆ˜ ìˆëŠ”ì§€ íƒêµ¬í•©ë‹ˆë‹¤. 10ê°œì˜ ëª¨ë¸ ë³‘í•© ì•Œê³ ë¦¬ì¦˜ì„ ë²¤ì¹˜ë§ˆí¬ì— êµ¬í˜„í•˜ê³ , ì¡ìŒì„ ì œê±°í•˜ê³  ê³¼ì œ ë²¡í„° ìƒí˜¸ì‘ìš©ì— ê¸°ë°˜í•œ ì†ì‹¤ì„ í†µí•´ ë³‘í•© ë²¡í„°ë¥¼ ìµœì í™”í•˜ëŠ” ìƒˆë¡œìš´ ë°©ë²•ì„ ì œì•ˆí•˜ì—¬ í‰ê·  2.48%ì˜ ì„±ëŠ¥ í–¥ìƒì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” í›ˆë ¨ ë°ì´í„° ì—†ì´ë„ í–¥ìƒëœ MMLMì„ êµ¬ì¶•í•  ìˆ˜ ìˆëŠ” ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì£¼ë©°, ì—¬ëŸ¬ ëª¨ë‹¬ë¦¬í‹°ì˜ ìƒí˜¸ë³´ì™„ì„±ì´ ê°œë³„ ëª¨ë‹¬ë¦¬í‹°ë¥¼ ëŠ¥ê°€í•¨ì„ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëª¨ë¸ ë³‘í•©ì€ ì—¬ëŸ¬ ì „ë¬¸ê°€ ëª¨ë¸ì„ ê²°í•©í•˜ì—¬ ì €ì¥ ë° ì„œë¹„ìŠ¤ ë¹„ìš©ì„ ì¤„ì´ê³  ë¶„ì‚° ê°œë°œì„ ì§€ì›í•˜ëŠ” ë°©ë²•ì´ë‹¤.
- 2. MLLM(ë©€í‹°ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸) ë³‘í•© ì—°êµ¬ë¥¼ ìœ„í•œ ë²¤ì¹˜ë§ˆí¬ë¥¼ ì†Œê°œí•˜ë©°, VQA, ê¸°í•˜í•™, ì°¨íŠ¸, OCR, ê·¸ë¼ìš´ë”© ë“±ì˜ ë‹¤ì–‘í•œ ì‘ì—…ì„ í¬í•¨í•œë‹¤.
- 3. ëª¨ë¸ ë³‘í•©ì€ ë¹„ì „-ì–¸ì–´, ì˜¤ë””ì˜¤-ì–¸ì–´, ë¹„ë””ì˜¤-ì–¸ì–´ ëª¨ë¸ ë“± ë‹¤ì–‘í•œ ëª¨ë‹¬ë¦¬í‹°ë¥¼ ê²°í•©í•˜ì—¬ ì˜´ë‹ˆ-ì–¸ì–´ ëª¨ë¸ë¡œ ë°œì „í•  ìˆ˜ ìˆë‹¤.
- 4. 10ê°œì˜ ëª¨ë¸ ë³‘í•© ì•Œê³ ë¦¬ì¦˜ì„ êµ¬í˜„í•˜ê³ , ì¡ìŒ ì œê±° ë° ì‘ì—… ë²¡í„° ìƒí˜¸ì‘ìš© ê¸°ë°˜ ìµœì í™” ë°©ë²•ì„ ì œì•ˆí•˜ì—¬ í‰ê·  ì„±ëŠ¥ì„ 2.48% í–¥ìƒì‹œì¼°ë‹¤.
- 5. ëª¨ë¸ ë³‘í•©ì€ í›ˆë ¨ ë°ì´í„° ì—†ì´ë„ ê°œì„ ëœ MLLMì„ êµ¬ì¶•í•  ìˆ˜ ìˆëŠ” ìœ ë§í•œ ë°©ë²•ì´ë©°, ì—¬ëŸ¬ ëª¨ë‹¬ë¦¬í‹°ì˜ ìƒí˜¸ë³´ì™„ì„±ì´ ê°œë³„ ëª¨ë‹¬ë¦¬í‹°ë³´ë‹¤ ìš°ìˆ˜í•˜ë‹¤.


---

*Generated on 2025-09-24 14:20:50*