<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T16:14:33.378502",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Transformer",
    "Segment Anything Model",
    "Zero-Shot Learning",
    "Class Activation Maps",
    "Food Image Segmentation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Transformer": 0.8,
    "Segment Anything Model": 0.78,
    "Zero-Shot Learning": 0.79,
    "Class Activation Maps": 0.75,
    "Food Image Segmentation": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Vision Transformers",
        "canonical": "Transformer",
        "aliases": [
          "ViTs",
          "Vision Transformer"
        ],
        "category": "broad_technical",
        "rationale": "Vision Transformers are a key component in the proposed method, linking to broader Transformer applications.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Segment Anything Model",
        "canonical": "Segment Anything Model",
        "aliases": [
          "SAM"
        ],
        "category": "unique_technical",
        "rationale": "SAM is central to the segmentation approach, offering a unique method for image analysis.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Zero-Shot Capabilities",
        "canonical": "Zero-Shot Learning",
        "aliases": [
          "Zero-Shot"
        ],
        "category": "specific_connectable",
        "rationale": "Zero-Shot Learning is a trending concept that enhances the model's adaptability without additional training.",
        "novelty_score": 0.5,
        "connectivity_score": 0.82,
        "specificity_score": 0.77,
        "link_intent_score": 0.79
      },
      {
        "surface": "Class Activation Maps",
        "canonical": "Class Activation Maps",
        "aliases": [
          "CAMs"
        ],
        "category": "unique_technical",
        "rationale": "CAMs are crucial for generating prompts in the segmentation process, linking to model interpretability.",
        "novelty_score": 0.68,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      },
      {
        "surface": "Food Image Segmentation",
        "canonical": "Food Image Segmentation",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This is the specific application domain of the study, crucial for linking to related datasets and methods.",
        "novelty_score": 0.72,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "image preprocessing techniques",
      "multi-mask scenario"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Vision Transformers",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Segment Anything Model",
      "resolved_canonical": "Segment Anything Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Zero-Shot Capabilities",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.82,
        "specificity": 0.77,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Class Activation Maps",
      "resolved_canonical": "Class Activation Maps",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Food Image Segmentation",
      "resolved_canonical": "Food Image Segmentation",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Weakly Supervised Food Image Segmentation using Vision Transformers and Segment Anything Model

## 📋 메타데이터

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19028.pdf)
**Category**: cs.CV
**Published**: 2025-09-24
**ArXiv ID**: [2509.19028](https://arxiv.org/abs/2509.19028)

## 🔗 유사한 논문
- [[2025-09-24/Lightweight Vision Transformer with Window and Spatial Attention for Food Image Classification_20250924|Lightweight Vision Transformer with Window and Spatial Attention for Food Image Classification]] (88.0% similar)
- [[2025-09-23/SAM-DCE_ Addressing Token Uniformity and Semantic Over-Smoothing in Medical Segmentation_20250923|SAM-DCE: Addressing Token Uniformity and Semantic Over-Smoothing in Medical Segmentation]] (85.0% similar)
- [[2025-09-23/BiPrompt-SAM_ Enhancing Image Segmentation via Explicit Selection between Point and Text Prompts_20250923|BiPrompt-SAM: Enhancing Image Segmentation via Explicit Selection between Point and Text Prompts]] (83.9% similar)
- [[2025-09-22/TASAM_ Terrain-and-Aware Segment Anything Model for Temporal-Scale Remote Sensing Segmentation_20250922|TASAM: Terrain-and-Aware Segment Anything Model for Temporal-Scale Remote Sensing Segmentation]] (83.8% similar)
- [[2025-09-24/HyPSAM_ Hybrid Prompt-driven Segment Anything Model for RGB-Thermal Salient Object Detection_20250924|HyPSAM: Hybrid Prompt-driven Segment Anything Model for RGB-Thermal Salient Object Detection]] (82.5% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Transformer|Transformer]]
**🔗 Specific Connectable**: [[keywords/Zero-Shot Learning|Zero-Shot Learning]]
**⚡ Unique Technical**: [[keywords/Segment Anything Model|Segment Anything Model]], [[keywords/Class Activation Maps|Class Activation Maps]], [[keywords/Food Image Segmentation|Food Image Segmentation]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.19028v1 Announce Type: new 
Abstract: In this paper, we propose a weakly supervised semantic segmentation approach for food images which takes advantage of the zero-shot capabilities and promptability of the Segment Anything Model (SAM) along with the attention mechanisms of Vision Transformers (ViTs). Specifically, we use class activation maps (CAMs) from ViTs to generate prompts for SAM, resulting in masks suitable for food image segmentation. The ViT model, a Swin Transformer, is trained exclusively using image-level annotations, eliminating the need for pixel-level annotations during training. Additionally, to enhance the quality of the SAM-generated masks, we examine the use of image preprocessing techniques in combination with single-mask and multi-mask SAM generation strategies. The methodology is evaluated on the FoodSeg103 dataset, generating an average of 2.4 masks per image (excluding background), and achieving an mIoU of 0.54 for the multi-mask scenario. We envision the proposed approach as a tool to accelerate food image annotation tasks or as an integrated component in food and nutrition tracking applications.

## 📝 요약

이 논문에서는 음식 이미지의 약한 지도 학습 기반 의미 분할 방법을 제안합니다. Segment Anything Model (SAM)의 제로샷 기능과 Vision Transformers (ViTs)의 주의 메커니즘을 활용하여, ViTs의 클래스 활성화 맵(CAM)을 사용해 SAM에 대한 프롬프트를 생성하고, 이를 통해 음식 이미지에 적합한 마스크를 생성합니다. Swin Transformer 기반의 ViT 모델은 이미지 수준의 주석만으로 훈련되어 픽셀 수준의 주석이 필요하지 않습니다. 또한, SAM 생성 마스크의 품질을 향상시키기 위해 이미지 전처리 기법과 단일 및 다중 마스크 생성 전략을 검토합니다. 이 방법론은 FoodSeg103 데이터셋에서 평가되었으며, 이미지당 평균 2.4개의 마스크를 생성하고 다중 마스크 시나리오에서 mIoU 0.54를 달성했습니다. 제안된 접근법은 음식 이미지 주석 작업을 가속화하거나 음식 및 영양 추적 애플리케이션에 통합될 수 있는 도구로 활용될 수 있습니다.

## 🎯 주요 포인트

- 1. 본 논문에서는 Segment Anything Model (SAM)과 Vision Transformers (ViTs)의 주의 메커니즘을 활용한 약지도 음식 이미지 의미 분할 방법을 제안합니다.
- 2. Swin Transformer 기반 ViT 모델을 이미지 수준의 주석만으로 훈련하여 픽셀 수준의 주석이 필요하지 않습니다.
- 3. ViTs의 클래스 활성화 맵(CAMs)을 사용하여 SAM에 대한 프롬프트를 생성하고, 이를 통해 음식 이미지 분할에 적합한 마스크를 생성합니다.
- 4. SAM 생성 마스크의 품질을 향상시키기 위해 이미지 전처리 기법과 단일 마스크 및 다중 마스크 SAM 생성 전략을 결합하여 사용합니다.
- 5. 제안된 방법론은 FoodSeg103 데이터셋에서 평균 2.4개의 마스크를 생성하고, 다중 마스크 시나리오에서 0.54의 mIoU를 달성했습니다.


---

*Generated on 2025-09-24 16:14:33*