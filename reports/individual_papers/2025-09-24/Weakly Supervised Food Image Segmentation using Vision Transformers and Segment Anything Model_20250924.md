<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T16:14:33.378502",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Transformer",
    "Segment Anything Model",
    "Zero-Shot Learning",
    "Class Activation Maps",
    "Food Image Segmentation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Transformer": 0.8,
    "Segment Anything Model": 0.78,
    "Zero-Shot Learning": 0.79,
    "Class Activation Maps": 0.75,
    "Food Image Segmentation": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Vision Transformers",
        "canonical": "Transformer",
        "aliases": [
          "ViTs",
          "Vision Transformer"
        ],
        "category": "broad_technical",
        "rationale": "Vision Transformers are a key component in the proposed method, linking to broader Transformer applications.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Segment Anything Model",
        "canonical": "Segment Anything Model",
        "aliases": [
          "SAM"
        ],
        "category": "unique_technical",
        "rationale": "SAM is central to the segmentation approach, offering a unique method for image analysis.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Zero-Shot Capabilities",
        "canonical": "Zero-Shot Learning",
        "aliases": [
          "Zero-Shot"
        ],
        "category": "specific_connectable",
        "rationale": "Zero-Shot Learning is a trending concept that enhances the model's adaptability without additional training.",
        "novelty_score": 0.5,
        "connectivity_score": 0.82,
        "specificity_score": 0.77,
        "link_intent_score": 0.79
      },
      {
        "surface": "Class Activation Maps",
        "canonical": "Class Activation Maps",
        "aliases": [
          "CAMs"
        ],
        "category": "unique_technical",
        "rationale": "CAMs are crucial for generating prompts in the segmentation process, linking to model interpretability.",
        "novelty_score": 0.68,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      },
      {
        "surface": "Food Image Segmentation",
        "canonical": "Food Image Segmentation",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This is the specific application domain of the study, crucial for linking to related datasets and methods.",
        "novelty_score": 0.72,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "image preprocessing techniques",
      "multi-mask scenario"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Vision Transformers",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Segment Anything Model",
      "resolved_canonical": "Segment Anything Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Zero-Shot Capabilities",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.82,
        "specificity": 0.77,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Class Activation Maps",
      "resolved_canonical": "Class Activation Maps",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Food Image Segmentation",
      "resolved_canonical": "Food Image Segmentation",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Weakly Supervised Food Image Segmentation using Vision Transformers and Segment Anything Model

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19028.pdf)
**Category**: cs.CV
**Published**: 2025-09-24
**ArXiv ID**: [2509.19028](https://arxiv.org/abs/2509.19028)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-24/Lightweight Vision Transformer with Window and Spatial Attention for Food Image Classification_20250924|Lightweight Vision Transformer with Window and Spatial Attention for Food Image Classification]] (88.0% similar)
- [[2025-09-23/SAM-DCE_ Addressing Token Uniformity and Semantic Over-Smoothing in Medical Segmentation_20250923|SAM-DCE: Addressing Token Uniformity and Semantic Over-Smoothing in Medical Segmentation]] (85.0% similar)
- [[2025-09-23/BiPrompt-SAM_ Enhancing Image Segmentation via Explicit Selection between Point and Text Prompts_20250923|BiPrompt-SAM: Enhancing Image Segmentation via Explicit Selection between Point and Text Prompts]] (83.9% similar)
- [[2025-09-22/TASAM_ Terrain-and-Aware Segment Anything Model for Temporal-Scale Remote Sensing Segmentation_20250922|TASAM: Terrain-and-Aware Segment Anything Model for Temporal-Scale Remote Sensing Segmentation]] (83.8% similar)
- [[2025-09-24/HyPSAM_ Hybrid Prompt-driven Segment Anything Model for RGB-Thermal Salient Object Detection_20250924|HyPSAM: Hybrid Prompt-driven Segment Anything Model for RGB-Thermal Salient Object Detection]] (82.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Transformer|Transformer]]
**ğŸ”— Specific Connectable**: [[keywords/Zero-Shot Learning|Zero-Shot Learning]]
**âš¡ Unique Technical**: [[keywords/Segment Anything Model|Segment Anything Model]], [[keywords/Class Activation Maps|Class Activation Maps]], [[keywords/Food Image Segmentation|Food Image Segmentation]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19028v1 Announce Type: new 
Abstract: In this paper, we propose a weakly supervised semantic segmentation approach for food images which takes advantage of the zero-shot capabilities and promptability of the Segment Anything Model (SAM) along with the attention mechanisms of Vision Transformers (ViTs). Specifically, we use class activation maps (CAMs) from ViTs to generate prompts for SAM, resulting in masks suitable for food image segmentation. The ViT model, a Swin Transformer, is trained exclusively using image-level annotations, eliminating the need for pixel-level annotations during training. Additionally, to enhance the quality of the SAM-generated masks, we examine the use of image preprocessing techniques in combination with single-mask and multi-mask SAM generation strategies. The methodology is evaluated on the FoodSeg103 dataset, generating an average of 2.4 masks per image (excluding background), and achieving an mIoU of 0.54 for the multi-mask scenario. We envision the proposed approach as a tool to accelerate food image annotation tasks or as an integrated component in food and nutrition tracking applications.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì—ì„œëŠ” ìŒì‹ ì´ë¯¸ì§€ì˜ ì•½í•œ ì§€ë„ í•™ìŠµ ê¸°ë°˜ ì˜ë¯¸ ë¶„í•  ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. Segment Anything Model (SAM)ì˜ ì œë¡œìƒ· ê¸°ëŠ¥ê³¼ Vision Transformers (ViTs)ì˜ ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì„ í™œìš©í•˜ì—¬, ViTsì˜ í´ë˜ìŠ¤ í™œì„±í™” ë§µ(CAM)ì„ ì‚¬ìš©í•´ SAMì— ëŒ€í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•˜ê³ , ì´ë¥¼ í†µí•´ ìŒì‹ ì´ë¯¸ì§€ì— ì í•©í•œ ë§ˆìŠ¤í¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. Swin Transformer ê¸°ë°˜ì˜ ViT ëª¨ë¸ì€ ì´ë¯¸ì§€ ìˆ˜ì¤€ì˜ ì£¼ì„ë§Œìœ¼ë¡œ í›ˆë ¨ë˜ì–´ í”½ì…€ ìˆ˜ì¤€ì˜ ì£¼ì„ì´ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë˜í•œ, SAM ìƒì„± ë§ˆìŠ¤í¬ì˜ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ê¸°ë²•ê³¼ ë‹¨ì¼ ë° ë‹¤ì¤‘ ë§ˆìŠ¤í¬ ìƒì„± ì „ëµì„ ê²€í† í•©ë‹ˆë‹¤. ì´ ë°©ë²•ë¡ ì€ FoodSeg103 ë°ì´í„°ì…‹ì—ì„œ í‰ê°€ë˜ì—ˆìœ¼ë©°, ì´ë¯¸ì§€ë‹¹ í‰ê·  2.4ê°œì˜ ë§ˆìŠ¤í¬ë¥¼ ìƒì„±í•˜ê³  ë‹¤ì¤‘ ë§ˆìŠ¤í¬ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ mIoU 0.54ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. ì œì•ˆëœ ì ‘ê·¼ë²•ì€ ìŒì‹ ì´ë¯¸ì§€ ì£¼ì„ ì‘ì—…ì„ ê°€ì†í™”í•˜ê±°ë‚˜ ìŒì‹ ë° ì˜ì–‘ ì¶”ì  ì• í”Œë¦¬ì¼€ì´ì…˜ì— í†µí•©ë  ìˆ˜ ìˆëŠ” ë„êµ¬ë¡œ í™œìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” Segment Anything Model (SAM)ê³¼ Vision Transformers (ViTs)ì˜ ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì„ í™œìš©í•œ ì•½ì§€ë„ ìŒì‹ ì´ë¯¸ì§€ ì˜ë¯¸ ë¶„í•  ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤.
- 2. Swin Transformer ê¸°ë°˜ ViT ëª¨ë¸ì„ ì´ë¯¸ì§€ ìˆ˜ì¤€ì˜ ì£¼ì„ë§Œìœ¼ë¡œ í›ˆë ¨í•˜ì—¬ í”½ì…€ ìˆ˜ì¤€ì˜ ì£¼ì„ì´ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
- 3. ViTsì˜ í´ë˜ìŠ¤ í™œì„±í™” ë§µ(CAMs)ì„ ì‚¬ìš©í•˜ì—¬ SAMì— ëŒ€í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•˜ê³ , ì´ë¥¼ í†µí•´ ìŒì‹ ì´ë¯¸ì§€ ë¶„í• ì— ì í•©í•œ ë§ˆìŠ¤í¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
- 4. SAM ìƒì„± ë§ˆìŠ¤í¬ì˜ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ê¸°ë²•ê³¼ ë‹¨ì¼ ë§ˆìŠ¤í¬ ë° ë‹¤ì¤‘ ë§ˆìŠ¤í¬ SAM ìƒì„± ì „ëµì„ ê²°í•©í•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤.
- 5. ì œì•ˆëœ ë°©ë²•ë¡ ì€ FoodSeg103 ë°ì´í„°ì…‹ì—ì„œ í‰ê·  2.4ê°œì˜ ë§ˆìŠ¤í¬ë¥¼ ìƒì„±í•˜ê³ , ë‹¤ì¤‘ ë§ˆìŠ¤í¬ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ 0.54ì˜ mIoUë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 16:14:33*