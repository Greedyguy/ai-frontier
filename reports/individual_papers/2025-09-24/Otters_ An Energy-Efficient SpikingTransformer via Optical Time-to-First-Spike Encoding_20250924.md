<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T14:57:40.362177",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Neural Network",
    "Optoelectronic Synapse",
    "Time-to-First-Spike Encoding",
    "Transformer"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Neural Network": 0.85,
    "Optoelectronic Synapse": 0.78,
    "Time-to-First-Spike Encoding": 0.82,
    "Transformer": 0.88
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Spiking Neural Networks",
        "canonical": "Neural Network",
        "aliases": [
          "SNN",
          "Spiking Networks"
        ],
        "category": "broad_technical",
        "rationale": "Links to the broader category of neural networks, which is foundational for understanding the paper's context.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Optoelectronic Synapse",
        "canonical": "Optoelectronic Synapse",
        "aliases": [
          "Optical Synapse",
          "Indium Oxide Synapse"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel hardware component crucial for the paper's proposed energy-efficient computation.",
        "novelty_score": 0.92,
        "connectivity_score": 0.67,
        "specificity_score": 0.91,
        "link_intent_score": 0.78
      },
      {
        "surface": "Time-to-First-Spike Encoding",
        "canonical": "Time-to-First-Spike Encoding",
        "aliases": [
          "TTFS Encoding"
        ],
        "category": "unique_technical",
        "rationale": "A specific encoding method central to the paper's energy efficiency claims.",
        "novelty_score": 0.85,
        "connectivity_score": 0.72,
        "specificity_score": 0.89,
        "link_intent_score": 0.82
      },
      {
        "surface": "Transformer",
        "canonical": "Transformer",
        "aliases": [],
        "category": "broad_technical",
        "rationale": "Connects to a widely recognized architecture, facilitating integration with existing knowledge graphs.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.88
      }
    ],
    "ban_list_suggestions": [
      "energy efficiency",
      "state-of-the-art",
      "hardware-software co-design"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Spiking Neural Networks",
      "resolved_canonical": "Neural Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Optoelectronic Synapse",
      "resolved_canonical": "Optoelectronic Synapse",
      "decision": "linked",
      "scores": {
        "novelty": 0.92,
        "connectivity": 0.67,
        "specificity": 0.91,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Time-to-First-Spike Encoding",
      "resolved_canonical": "Time-to-First-Spike Encoding",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.72,
        "specificity": 0.89,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Transformer",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.88
      }
    }
  ]
}
-->

# Otters: An Energy-Efficient SpikingTransformer via Optical Time-to-First-Spike Encoding

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18968.pdf)
**Category**: cs.LG
**Published**: 2025-09-24
**ArXiv ID**: [2509.18968](https://arxiv.org/abs/2509.18968)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/CSDformer_ A Conversion Method for Fully Spike-Driven Transformer_20250923|CSDformer: A Conversion Method for Fully Spike-Driven Transformer]] (85.1% similar)
- [[2025-09-22/SPACE_ SPike-Aware Consistency Enhancement for Test-Time Adaptation in Spiking Neural Networks_20250922|SPACE: SPike-Aware Consistency Enhancement for Test-Time Adaptation in Spiking Neural Networks]] (84.5% similar)
- [[2025-09-23/Incorporating the Refractory Period into Spiking Neural Networks through Spike-Triggered Threshold Dynamics_20250923|Incorporating the Refractory Period into Spiking Neural Networks through Spike-Triggered Threshold Dynamics]] (83.8% similar)
- [[2025-09-23/Neuro-inspired Ensemble-to-Ensemble Communication Primitives for Sparse and Efficient ANNs_20250923|Neuro-inspired Ensemble-to-Ensemble Communication Primitives for Sparse and Efficient ANNs]] (82.4% similar)
- [[2025-09-22/Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs_20250922|Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs]] (81.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Neural Network|Neural Network]], [[keywords/Transformer|Transformer]]
**âš¡ Unique Technical**: [[keywords/Optoelectronic Synapse|Optoelectronic Synapse]], [[keywords/Time-to-First-Spike Encoding|Time-to-First-Spike Encoding]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18968v1 Announce Type: new 
Abstract: Spiking neural networks (SNNs) promise high energy efficiency, particularly with time-to-first-spike (TTFS) encoding, which maximizes sparsity by emitting at most one spike per neuron. However, such energy advantage is often unrealized because inference requires evaluating a temporal decay function and subsequent multiplication with the synaptic weights. This paper challenges this costly approach by repurposing a physical hardware `bug', namely, the natural signal decay in optoelectronic devices, as the core computation of TTFS. We fabricated a custom indium oxide optoelectronic synapse, showing how its natural physical decay directly implements the required temporal function. By treating the device's analog output as the fused product of the synaptic weight and temporal decay, optoelectronic synaptic TTFS (named Otters) eliminates these expensive digital operations. To use the Otters paradigm in complex architectures like the transformer, which are challenging to train directly due to the sparsity issue, we introduce a novel quantized neural network-to-SNN conversion algorithm. This complete hardware-software co-design enables our model to achieve state-of-the-art accuracy across seven GLUE benchmark datasets and demonstrates a 1.77$\times$ improvement in energy efficiency over previous leading SNNs, based on a comprehensive analysis of compute, data movement, and memory access costs using energy measurements from a commercial 22nm process. Our work thus establishes a new paradigm for energy-efficient SNNs, translating fundamental device physics directly into powerful computational primitives. All codes and data are open source.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ìŠ¤íŒŒì´í‚¹ ì‹ ê²½ë§(SNN)ì˜ ì—ë„ˆì§€ íš¨ìœ¨ì„±ì„ ë†’ì´ê¸° ìœ„í•´ ìƒˆë¡œìš´ í•˜ë“œì›¨ì–´-ì†Œí”„íŠ¸ì›¨ì–´ ê³µë™ ì„¤ê³„ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ SNNì€ ì‹œê°„-ì²«-ìŠ¤íŒŒì´í¬(TTFS) ì¸ì½”ë”©ì„ í†µí•´ ì—ë„ˆì§€ë¥¼ ì ˆì•½í•˜ì§€ë§Œ, ì‹œê°„ì  ê°ì‡  í•¨ìˆ˜ì™€ ì‹œëƒ…ìŠ¤ ê°€ì¤‘ì¹˜ì˜ ê³±ì…ˆì´ í•„ìš”í•´ ì‹¤ì œë¡œëŠ” ë¹„íš¨ìœ¨ì ì…ë‹ˆë‹¤. ì €ìë“¤ì€ ì¸ë“ ì‚°í™”ë¬¼ ê´‘ì „ì ì‹œëƒ…ìŠ¤ë¥¼ ì œì‘í•˜ì—¬ ìì—°ì ì¸ ì‹ í˜¸ ê°ì‡ ë¥¼ TTFSì˜ í•µì‹¬ ì—°ì‚°ìœ¼ë¡œ í™œìš©í–ˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë³µì¡í•œ ì‹ ê²½ë§ êµ¬ì¡°ì—ì„œë„ íš¨ìœ¨ì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ìƒˆë¡œìš´ ì–‘ìí™” ì‹ ê²½ë§-ìŠ¤íŒŒì´í‚¹ ì‹ ê²½ë§ ë³€í™˜ ì•Œê³ ë¦¬ì¦˜ì„ ê°œë°œí–ˆìŠµë‹ˆë‹¤. ì´ ë°©ë²•ì€ GLUE ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì—ì„œ ìµœì²¨ë‹¨ ì •í™•ë„ë¥¼ ë‹¬ì„±í–ˆìœ¼ë©°, ê¸°ì¡´ SNN ëŒ€ë¹„ ì—ë„ˆì§€ íš¨ìœ¨ì„±ì„ 1.77ë°° ê°œì„ í–ˆìŠµë‹ˆë‹¤. ëª¨ë“  ì½”ë“œì™€ ë°ì´í„°ëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ë¡œ ì œê³µë©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ìŠ¤íŒŒì´í‚¹ ì‹ ê²½ë§(SNN)ì˜ ì—ë„ˆì§€ íš¨ìœ¨ì„±ì„ ë†’ì´ê¸° ìœ„í•´ ìì—°ì ì¸ ì‹ í˜¸ ê°ì‡ ë¥¼ í™œìš©í•œ ì˜µí† ì „ì ì‹œëƒ…ìŠ¤ë¥¼ ê°œë°œí–ˆìŠµë‹ˆë‹¤.
- 2. ì˜µí† ì „ì ì‹œëƒ…ìŠ¤ì˜ ìì—°ì  ë¬¼ë¦¬ì  ê°ì‡ ë¥¼ í†µí•´ ì‹œê°„-ì²«-ìŠ¤íŒŒì´í¬(TTFS) ì¸ì½”ë”©ì˜ í•µì‹¬ ì—°ì‚°ì„ êµ¬í˜„í•˜ì—¬ ë””ì§€í„¸ ì—°ì‚° ë¹„ìš©ì„ ì ˆê°í–ˆìŠµë‹ˆë‹¤.
- 3. ë³µì¡í•œ ì•„í‚¤í…ì²˜ì—ì„œì˜ í¬ì†Œì„± ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ìƒˆë¡œìš´ ì–‘ìí™” ì‹ ê²½ë§-ìŠ¤íŒŒì´í‚¹ ì‹ ê²½ë§ ë³€í™˜ ì•Œê³ ë¦¬ì¦˜ì„ ë„ì…í–ˆìŠµë‹ˆë‹¤.
- 4. ì œì•ˆëœ í•˜ë“œì›¨ì–´-ì†Œí”„íŠ¸ì›¨ì–´ ê³µë™ ì„¤ê³„ë¥¼ í†µí•´ GLUE ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì—ì„œ ìµœì²¨ë‹¨ ì •í™•ë„ë¥¼ ë‹¬ì„±í•˜ê³ , ì´ì „ SNN ëŒ€ë¹„ ì—ë„ˆì§€ íš¨ìœ¨ì„±ì„ 1.77ë°° ê°œì„ í–ˆìŠµë‹ˆë‹¤.
- 5. ë³¸ ì—°êµ¬ëŠ” ê¸°ì´ˆì ì¸ ì¥ì¹˜ ë¬¼ë¦¬í•™ì„ ê°•ë ¥í•œ ê³„ì‚° ì›ë¦¬ë¡œ ì§ì ‘ ë³€í™˜í•˜ì—¬ ì—ë„ˆì§€ íš¨ìœ¨ì ì¸ SNNì˜ ìƒˆë¡œìš´ íŒ¨ëŸ¬ë‹¤ì„ì„ ì œì‹œí•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 14:57:40*