<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T15:20:44.483138",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Reproducing Kernel Hilbert Space",
    "Tikhonov Regularization",
    "Operator Theory",
    "Persistence of Excitation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Reproducing Kernel Hilbert Space": 0.78,
    "Tikhonov Regularization": 0.77,
    "Operator Theory": 0.7,
    "Persistence of Excitation": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Reproducing Kernel Hilbert Space",
        "canonical": "Reproducing Kernel Hilbert Space",
        "aliases": [
          "RKHS"
        ],
        "category": "unique_technical",
        "rationale": "Central to the paper's methodology, linking to advanced mathematical frameworks.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Tikhonov regularization",
        "canonical": "Tikhonov Regularization",
        "aliases": [
          "Tikhonov path"
        ],
        "category": "specific_connectable",
        "rationale": "A specific regularization technique that connects to broader statistical learning methods.",
        "novelty_score": 0.58,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      },
      {
        "surface": "operator theory",
        "canonical": "Operator Theory",
        "aliases": [],
        "category": "broad_technical",
        "rationale": "Provides a mathematical foundation for analyzing algorithms in the paper.",
        "novelty_score": 0.55,
        "connectivity_score": 0.68,
        "specificity_score": 0.72,
        "link_intent_score": 0.7
      },
      {
        "surface": "persistence of excitation",
        "canonical": "Persistence of Excitation",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "A unique condition introduced in the paper, crucial for algorithm stability.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.88,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "non-stationary data",
      "mean square consistency"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Reproducing Kernel Hilbert Space",
      "resolved_canonical": "Reproducing Kernel Hilbert Space",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Tikhonov regularization",
      "resolved_canonical": "Tikhonov Regularization",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "operator theory",
      "resolved_canonical": "Operator Theory",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.68,
        "specificity": 0.72,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "persistence of excitation",
      "resolved_canonical": "Persistence of Excitation",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.88,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# Online Regularized Statistical Learning in Reproducing Kernel Hilbert Space With Non-Stationary Data

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2404.03211.pdf)
**Category**: cs.LG
**Published**: 2025-09-24
**ArXiv ID**: [2404.03211](https://arxiv.org/abs/2404.03211)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/A non-smooth regularization framework for learning over multitask graphs_20250923|A non-smooth regularization framework for learning over multitask graphs]] (83.2% similar)
- [[2025-09-22/Adaptive Algorithms with Sharp Convergence Rates for Stochastic Hierarchical Optimization_20250922|Adaptive Algorithms with Sharp Convergence Rates for Stochastic Hierarchical Optimization]] (81.0% similar)
- [[2025-09-19/Multi-Fidelity Hybrid Reinforcement Learning via Information Gain Maximization_20250919|Multi-Fidelity Hybrid Reinforcement Learning via Information Gain Maximization]] (80.8% similar)
- [[2025-09-24/Diagonal Linear Networks and the Lasso Regularization Path_20250924|Diagonal Linear Networks and the Lasso Regularization Path]] (80.5% similar)
- [[2025-09-18/Probabilistic and nonlinear compressive sensing_20250918|Probabilistic and nonlinear compressive sensing]] (80.4% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Operator Theory|Operator Theory]]
**ğŸ”— Specific Connectable**: [[keywords/Tikhonov Regularization|Tikhonov Regularization]]
**âš¡ Unique Technical**: [[keywords/Reproducing Kernel Hilbert Space|Reproducing Kernel Hilbert Space]], [[keywords/Persistence of Excitation|Persistence of Excitation]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2404.03211v5 Announce Type: replace 
Abstract: We study the convergence of recursive regularized learning algorithms in the reproducing kernel Hilbert space (RKHS) with dependent and non-stationary online data streams. Firstly, we introduce the concept of random Tikhonov regularization path and decompose the tracking error of the algorithm's output for the regularization path into random difference equations in RKHS, whose non-homogeneous terms are martingale difference sequences. Investigating the mean square asymptotic stability of the equations, we show that if the regularization path is slowly time-varying, then the algorithm's output achieves mean square consistency with the regularization path. Leveraging operator theory, particularly the monotonicity of the inverses of operators and the spectral decomposition of compact operators, we introduce the RKHS persistence of excitation condition (i.e. there exists a fixed-length time period, such that the conditional expectation of the operators induced by the input data accumulated over every period has a uniformly strictly positive compact lower bound) and develop a dominated convergence method to prove the mean square consistency between the algorithm's output and an unknown function. Finally, for independent and non-identically distributed data streams, the algorithm achieves the mean square consistency if the input data's marginal probability measures are slowly time-varying and the average measure over each fixed-length time period has a uniformly strictly positive lower bound.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì¢…ì†ì ì´ê³  ë¹„ì •ìƒì ì¸ ì˜¨ë¼ì¸ ë°ì´í„° ìŠ¤íŠ¸ë¦¼ì—ì„œ ì¬ê·€ì  ì •ê·œí™” í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì˜ ìˆ˜ë ´ì„±ì„ ì—°êµ¬í•©ë‹ˆë‹¤. ì£¼ìš” ê¸°ì—¬ëŠ” ëœë¤ í‹°í˜¸ë…¸í”„ ì •ê·œí™” ê²½ë¡œ ê°œë…ì„ ë„ì…í•˜ê³ , ì•Œê³ ë¦¬ì¦˜ ì¶œë ¥ì˜ ì¶”ì  ì˜¤ì°¨ë¥¼ RKHSì—ì„œ ëœë¤ ì°¨ë¶„ ë°©ì •ì‹ìœ¼ë¡œ ë¶„í•´í•œ ê²ƒì…ë‹ˆë‹¤. ë¹„ê· ì§ˆ í•­ì€ ë§ˆíŒ…ê²Œì¼ ì°¨ë¶„ ì‹œí€€ìŠ¤ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. í‰ê·  ì œê³± ë¹„ëŒ€ì¹­ ì•ˆì •ì„±ì„ ì¡°ì‚¬í•˜ì—¬ ì •ê·œí™” ê²½ë¡œê°€ ì²œì²œíˆ ë³€í•  ê²½ìš° ì•Œê³ ë¦¬ì¦˜ ì¶œë ¥ì´ í‰ê·  ì œê³± ì¼ê´€ì„±ì„ ë‹¬ì„±í•¨ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ë˜í•œ, ì—°ì‚°ì ì´ë¡ ê³¼ RKHS ìê·¹ ì§€ì† ì¡°ê±´ì„ í™œìš©í•˜ì—¬ ì•Œê³ ë¦¬ì¦˜ ì¶œë ¥ê³¼ ë¯¸ì§€ í•¨ìˆ˜ ê°„ì˜ í‰ê·  ì œê³± ì¼ê´€ì„±ì„ ì¦ëª…í–ˆìŠµë‹ˆë‹¤. ë…ë¦½ì ì´ê³  ë¹„ë™ì¼ ë¶„í¬ ë°ì´í„° ìŠ¤íŠ¸ë¦¼ì˜ ê²½ìš°, ì…ë ¥ ë°ì´í„°ì˜ ì£¼ë³€ í™•ë¥  ì¸¡ì •ì´ ì²œì²œíˆ ë³€í•˜ê³ , ê° ê³ ì • ê¸¸ì´ ê¸°ê°„ ë™ì•ˆì˜ í‰ê·  ì¸¡ì •ì´ ì–‘ì˜ í•˜í•œì„ ê°€ì§€ë©´ ì•Œê³ ë¦¬ì¦˜ì€ í‰ê·  ì œê³± ì¼ê´€ì„±ì„ ë‹¬ì„±í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì¬ìƒ ì»¤ë„ íë² ë¥´íŠ¸ ê³µê°„(RKHS)ì—ì„œ ì˜ì¡´ì ì´ê³  ë¹„ì •ìƒì ì¸ ì˜¨ë¼ì¸ ë°ì´í„° ìŠ¤íŠ¸ë¦¼ì„ ëŒ€ìƒìœ¼ë¡œ í•œ ì¬ê·€ì  ì •ê·œí™” í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì˜ ìˆ˜ë ´ì„±ì„ ì—°êµ¬í•©ë‹ˆë‹¤.
- 2. ëœë¤ í‹°í˜¸ë…¸í”„ ì •ê·œí™” ê²½ë¡œì˜ ê°œë…ì„ ë„ì…í•˜ê³ , ì•Œê³ ë¦¬ì¦˜ ì¶œë ¥ì˜ ì¶”ì  ì˜¤ë¥˜ë¥¼ RKHSì˜ ëœë¤ ì°¨ë¶„ ë°©ì •ì‹ìœ¼ë¡œ ë¶„í•´í•©ë‹ˆë‹¤.
- 3. ì—°ì‚°ì ì´ë¡ ì„ í™œìš©í•˜ì—¬ RKHS ìê·¹ ì§€ì† ì¡°ê±´ì„ ë„ì…í•˜ê³ , ì•Œê³ ë¦¬ì¦˜ ì¶œë ¥ê³¼ ë¯¸ì§€ í•¨ìˆ˜ ê°„ì˜ í‰ê·  ì œê³± ì¼ê´€ì„±ì„ ì¦ëª…í•©ë‹ˆë‹¤.
- 4. ë…ë¦½ì ì´ê³  ë¹„ë™ì¼ ë¶„í¬ ë°ì´í„° ìŠ¤íŠ¸ë¦¼ì˜ ê²½ìš°, ì…ë ¥ ë°ì´í„°ì˜ ì£¼ë³€ í™•ë¥  ì¸¡ì •ì´ ì²œì²œíˆ ì‹œê°„ì— ë”°ë¼ ë³€í™”í•˜ë©´ ì•Œê³ ë¦¬ì¦˜ì€ í‰ê·  ì œê³± ì¼ê´€ì„±ì„ ë‹¬ì„±í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 15:20:44*