<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T14:04:32.826981",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Text Slider",
    "LoRA Adapters",
    "Diffusion Models",
    "Multi-concept Composition"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Text Slider": 0.78,
    "LoRA Adapters": 0.77,
    "Diffusion Models": 0.85,
    "Multi-concept Composition": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Text Slider",
        "canonical": "Text Slider",
        "aliases": [
          "Continuous Concept Control"
        ],
        "category": "unique_technical",
        "rationale": "Text Slider is a novel framework for continuous concept control in image and video synthesis, offering significant improvements in efficiency and flexibility.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.88,
        "link_intent_score": 0.78
      },
      {
        "surface": "LoRA Adapters",
        "canonical": "LoRA Adapters",
        "aliases": [
          "Low-Rank Adaptation Adapters"
        ],
        "category": "unique_technical",
        "rationale": "LoRA Adapters are a key component in enabling efficient continuous control in pre-trained text encoders, relevant for linking advancements in model adaptation.",
        "novelty_score": 0.8,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      },
      {
        "surface": "Diffusion Models",
        "canonical": "Diffusion Models",
        "aliases": [
          "Diffusion-based Synthesis"
        ],
        "category": "broad_technical",
        "rationale": "Diffusion Models are central to recent advancements in image and video synthesis, providing a foundational concept for linking related research.",
        "novelty_score": 0.55,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Multi-concept Composition",
        "canonical": "Multi-concept Composition",
        "aliases": [
          "Conceptual Blending"
        ],
        "category": "specific_connectable",
        "rationale": "Multi-concept Composition is crucial for enabling flexible and fine-grained manipulation in synthesis tasks, facilitating connections to multimodal research.",
        "novelty_score": 0.75,
        "connectivity_score": 0.78,
        "specificity_score": 0.8,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "Concept Slider",
      "Attribute Control",
      "training time",
      "GPU memory"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Text Slider",
      "resolved_canonical": "Text Slider",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.88,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "LoRA Adapters",
      "resolved_canonical": "LoRA Adapters",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Diffusion Models",
      "resolved_canonical": "Diffusion Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Multi-concept Composition",
      "resolved_canonical": "Multi-concept Composition",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.78,
        "specificity": 0.8,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Text Slider: Efficient and Plug-and-Play Continuous Concept Control for Image/Video Synthesis via LoRA Adapters

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18831.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2509.18831](https://arxiv.org/abs/2509.18831)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/MaskAttn-SDXL_ Controllable Region-Level Text-To-Image Generation_20250922|MaskAttn-SDXL: Controllable Region-Level Text-To-Image Generation]] (81.4% similar)
- [[2025-09-23/VidCLearn_ A Continual Learning Approach for Text-to-Video Generation_20250923|VidCLearn: A Continual Learning Approach for Text-to-Video Generation]] (81.0% similar)
- [[2025-09-23/CLIP-IN_ Enhancing Fine-Grained Visual Understanding in CLIP via Instruction Editing Data and Long Captions_20250923|CLIP-IN: Enhancing Fine-Grained Visual Understanding in CLIP via Instruction Editing Data and Long Captions]] (80.2% similar)
- [[2025-09-23/In-Context Edit_ Enabling Instructional Image Editing with In-Context Generation in Large Scale Diffusion Transformer_20250923|In-Context Edit: Enabling Instructional Image Editing with In-Context Generation in Large Scale Diffusion Transformer]] (80.2% similar)
- [[2025-09-23/FG-Attn_ Leveraging Fine-Grained Sparsity In Diffusion Transformers_20250923|FG-Attn: Leveraging Fine-Grained Sparsity In Diffusion Transformers]] (80.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Diffusion Models|Diffusion Models]]
**ğŸ”— Specific Connectable**: [[keywords/Multi-concept Composition|Multi-concept Composition]]
**âš¡ Unique Technical**: [[keywords/Text Slider|Text Slider]], [[keywords/LoRA Adapters|LoRA Adapters]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18831v1 Announce Type: cross 
Abstract: Recent advances in diffusion models have significantly improved image and video synthesis. In addition, several concept control methods have been proposed to enable fine-grained, continuous, and flexible control over free-form text prompts. However, these methods not only require intensive training time and GPU memory usage to learn the sliders or embeddings but also need to be retrained for different diffusion backbones, limiting their scalability and adaptability. To address these limitations, we introduce Text Slider, a lightweight, efficient and plug-and-play framework that identifies low-rank directions within a pre-trained text encoder, enabling continuous control of visual concepts while significantly reducing training time, GPU memory consumption, and the number of trainable parameters. Furthermore, Text Slider supports multi-concept composition and continuous control, enabling fine-grained and flexible manipulation in both image and video synthesis. We show that Text Slider enables smooth and continuous modulation of specific attributes while preserving the original spatial layout and structure of the input. Text Slider achieves significantly better efficiency: 5$\times$ faster training than Concept Slider and 47$\times$ faster than Attribute Control, while reducing GPU memory usage by nearly 2$\times$ and 4$\times$, respectively.

## ğŸ“ ìš”ì•½

ìµœê·¼ í™•ì‚° ëª¨ë¸ì˜ ë°œì „ì€ ì´ë¯¸ì§€ì™€ ë¹„ë””ì˜¤ í•©ì„±ì„ í¬ê²Œ ê°œì„ í–ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê¸°ì¡´ì˜ ê°œë… ì œì–´ ë°©ë²•ì€ ë§ì€ í›ˆë ¨ ì‹œê°„ê³¼ GPU ë©”ëª¨ë¦¬ë¥¼ ìš”êµ¬í•˜ë©°, ë‹¤ì–‘í•œ í™•ì‚° ë°±ë³¸ì— ëŒ€í•´ ì¬í›ˆë ¨ì´ í•„ìš”í•´ í™•ì¥ì„±ê³¼ ì ì‘ì„±ì´ ì œí•œë©ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ì‚¬ì „ í›ˆë ¨ëœ í…ìŠ¤íŠ¸ ì¸ì½”ë” ë‚´ì—ì„œ ì €ì°¨ì› ë°©í–¥ì„ ì‹ë³„í•˜ì—¬ ì‹œê°ì  ê°œë…ì„ ì—°ì†ì ìœ¼ë¡œ ì œì–´í•  ìˆ˜ ìˆëŠ” ê²½ëŸ‰ì˜ íš¨ìœ¨ì ì¸ í”„ë ˆì„ì›Œí¬ì¸ Text Sliderë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. Text SliderëŠ” í›ˆë ¨ ì‹œê°„ê³¼ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ í¬ê²Œ ì¤„ì´ê³ , ë‹¤ì¤‘ ê°œë… êµ¬ì„±ê³¼ ì—°ì† ì œì–´ë¥¼ ì§€ì›í•˜ì—¬ ì´ë¯¸ì§€ì™€ ë¹„ë””ì˜¤ í•©ì„±ì—ì„œ ì„¸ë°€í•˜ê³  ìœ ì—°í•œ ì¡°ì‘ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, Text SliderëŠ” ê¸°ì¡´ ë°©ë²•ë³´ë‹¤ í›¨ì”¬ íš¨ìœ¨ì ì´ë©°, í›ˆë ¨ ì†ë„ëŠ” Concept Sliderë³´ë‹¤ 5ë°°, Attribute Controlë³´ë‹¤ 47ë°° ë¹ ë¥´ê³ , GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ë„ ê°ê° 2ë°°, 4ë°° ì¤„ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Text SliderëŠ” ì‚¬ì „ í›ˆë ¨ëœ í…ìŠ¤íŠ¸ ì¸ì½”ë” ë‚´ì˜ ì €ë­í¬ ë°©í–¥ì„ ì‹ë³„í•˜ì—¬ ì‹œê°ì  ê°œë…ì˜ ì—°ì†ì  ì œì–´ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ë©°, í›ˆë ¨ ì‹œê°„, GPU ë©”ëª¨ë¦¬ ì†Œë¹„, í•™ìŠµ ê°€ëŠ¥í•œ ë§¤ê°œë³€ìˆ˜ ìˆ˜ë¥¼ í¬ê²Œ ì¤„ì…ë‹ˆë‹¤.
- 2. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ì´ë¯¸ì§€ì™€ ë¹„ë””ì˜¤ í•©ì„±ì—ì„œ ë‹¤ì¤‘ ê°œë… êµ¬ì„± ë° ì—°ì† ì œì–´ë¥¼ ì§€ì›í•˜ì—¬ ì„¸ë°€í•˜ê³  ìœ ì—°í•œ ì¡°ì‘ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
- 3. Text SliderëŠ” íŠ¹ì • ì†ì„±ì˜ ë¶€ë“œëŸ½ê³  ì—°ì†ì ì¸ ë³€ì¡°ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ë©´ì„œ ì…ë ¥ì˜ ì›ë˜ ê³µê°„ ë ˆì´ì•„ì›ƒê³¼ êµ¬ì¡°ë¥¼ ë³´ì¡´í•©ë‹ˆë‹¤.
- 4. Text SliderëŠ” Concept Sliderë³´ë‹¤ 5ë°°, Attribute Controlë³´ë‹¤ 47ë°° ë¹ ë¥¸ í›ˆë ¨ ì†ë„ë¥¼ ë‹¬ì„±í•˜ë©°, GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ê°ê° ê±°ì˜ 2ë°°, 4ë°° ì¤„ì…ë‹ˆë‹¤.


---

*Generated on 2025-09-24 14:04:32*