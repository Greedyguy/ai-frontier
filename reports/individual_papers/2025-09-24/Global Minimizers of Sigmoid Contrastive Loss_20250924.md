<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T13:53:32.656475",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Self-supervised Learning",
    "Sigmoid Contrastive Loss",
    "SigLIP",
    "Spherical Codes",
    "Modality Gap"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Self-supervised Learning": 0.8,
    "Sigmoid Contrastive Loss": 0.78,
    "SigLIP": 0.77,
    "Spherical Codes": 0.72,
    "Modality Gap": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "contrastive pretraining",
        "canonical": "Self-supervised Learning",
        "aliases": [
          "contrastive learning",
          "contrastive training"
        ],
        "category": "specific_connectable",
        "rationale": "Contrastive pretraining is a key technique in self-supervised learning, enhancing connectivity with related models and methods.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Sigmoid Contrastive Loss",
        "canonical": "Sigmoid Contrastive Loss",
        "aliases": [
          "sigmoid loss",
          "contrastive sigmoid"
        ],
        "category": "unique_technical",
        "rationale": "This loss function is central to the paper's contributions and offers a unique perspective on contrastive learning.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "SigLIP",
        "canonical": "SigLIP",
        "aliases": [
          "SigLIP model",
          "SigLIP2"
        ],
        "category": "unique_technical",
        "rationale": "SigLIP models are a focal point of the paper, representing a novel approach in the field.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      },
      {
        "surface": "spherical codes",
        "canonical": "Spherical Codes",
        "aliases": [
          "spherical coding"
        ],
        "category": "specific_connectable",
        "rationale": "Spherical codes are relevant for understanding the geometric aspects of the model configurations discussed.",
        "novelty_score": 0.65,
        "connectivity_score": 0.75,
        "specificity_score": 0.78,
        "link_intent_score": 0.72
      },
      {
        "surface": "modality gap",
        "canonical": "Modality Gap",
        "aliases": [
          "modality difference"
        ],
        "category": "unique_technical",
        "rationale": "Understanding the modality gap is crucial for improving model performance across different data types.",
        "novelty_score": 0.68,
        "connectivity_score": 0.7,
        "specificity_score": 0.82,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "temperature",
      "bias",
      "trainable"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "contrastive pretraining",
      "resolved_canonical": "Self-supervised Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Sigmoid Contrastive Loss",
      "resolved_canonical": "Sigmoid Contrastive Loss",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "SigLIP",
      "resolved_canonical": "SigLIP",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "spherical codes",
      "resolved_canonical": "Spherical Codes",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.75,
        "specificity": 0.78,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "modality gap",
      "resolved_canonical": "Modality Gap",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.7,
        "specificity": 0.82,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Global Minimizers of Sigmoid Contrastive Loss

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18552.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2509.18552](https://arxiv.org/abs/2509.18552)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-17/Consistent View Alignment Improves Foundation Models for 3D Medical Image Segmentation_20250917|Consistent View Alignment Improves Foundation Models for 3D Medical Image Segmentation]] (82.7% similar)
- [[2025-09-22/Gradient Alignment in Physics-informed Neural Networks_ A Second-Order Optimization Perspective_20250922|Gradient Alignment in Physics-informed Neural Networks: A Second-Order Optimization Perspective]] (82.5% similar)
- [[2025-09-23/Guiding Cross-Modal Representations with MLLM Priors via Preference Alignment_20250923|Guiding Cross-Modal Representations with MLLM Priors via Preference Alignment]] (82.4% similar)
- [[2025-09-23/Depth Edge Alignment Loss_ DEALing with Depth in Weakly Supervised Semantic Segmentation_20250923|Depth Edge Alignment Loss: DEALing with Depth in Weakly Supervised Semantic Segmentation]] (81.7% similar)
- [[2025-09-22/Global Pre-fixing, Local Adjusting_ A Simple yet Effective Contrastive Strategy for Continual Learning_20250922|Global Pre-fixing, Local Adjusting: A Simple yet Effective Contrastive Strategy for Continual Learning]] (81.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Self-supervised Learning|Self-supervised Learning]], [[keywords/Spherical Codes|Spherical Codes]]
**âš¡ Unique Technical**: [[keywords/Sigmoid Contrastive Loss|Sigmoid Contrastive Loss]], [[keywords/SigLIP|SigLIP]], [[keywords/Modality Gap|Modality Gap]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18552v1 Announce Type: cross 
Abstract: The meta-task of obtaining and aligning representations through contrastive pretraining is steadily gaining importance since its introduction in CLIP and ALIGN. In this paper we theoretically explain the advantages of synchronizing with trainable inverse temperature and bias under the sigmoid loss, as implemented in the recent SigLIP and SigLIP2 models of Google DeepMind. Temperature and bias can drive the loss function to zero for a rich class of configurations that we call $(\mathsf{m}, \mathsf{b}_{\mathsf{rel}})$-Constellations. $(\mathsf{m}, \mathsf{b}_{\mathsf{rel}})$-Constellations are a novel combinatorial object related to spherical codes and are parametrized by a margin $\mathsf{m}$ and relative bias $\mathsf{b}_{\mathsf{rel}}$. We use our characterization of constellations to theoretically justify the success of SigLIP on retrieval, to explain the modality gap present in SigLIP, and to identify the necessary dimension for producing high-quality representations. Finally, we propose a reparameterization of the sigmoid loss with explicit relative bias, which improves training dynamics in experiments with synthetic data.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€ì¡°ì  ì‚¬ì „ í•™ìŠµì„ í†µí•´ í‘œí˜„ì„ ì–»ê³  ì •ë ¬í•˜ëŠ” ë©”íƒ€ ì‘ì—…ì˜ ì¤‘ìš”ì„±ì„ ì„¤ëª…í•©ë‹ˆë‹¤. Google DeepMindì˜ SigLIP ë° SigLIP2 ëª¨ë¸ì—ì„œ ì‚¬ìš©ëœ ì‹œê·¸ëª¨ì´ë“œ ì†ì‹¤ í•¨ìˆ˜ì˜ ê°€ë³€ ì˜¨ë„ì™€ ë°”ì´ì–´ìŠ¤ë¥¼ ë™ê¸°í™”í•˜ëŠ” ì´ì ì´ ì´ë¡ ì ìœ¼ë¡œ ì„¤ëª…ë©ë‹ˆë‹¤. ì €ìëŠ” $(\mathsf{m}, \mathsf{b}_{\mathsf{rel}})$-ë³„ìë¦¬ë¼ëŠ” ìƒˆë¡œìš´ ì¡°í•© ê°ì²´ë¥¼ ì†Œê°œí•˜ë©°, ì´ëŠ” êµ¬ë©´ ì½”ë“œì™€ ê´€ë ¨ì´ ìˆê³  ë§ˆì§„ $\mathsf{m}$ê³¼ ìƒëŒ€ ë°”ì´ì–´ìŠ¤ $\mathsf{b}_{\mathsf{rel}}$ë¡œ ë§¤ê°œë³€ìˆ˜í™”ë©ë‹ˆë‹¤. ì´ëŸ¬í•œ ë³„ìë¦¬ë¥¼ í†µí•´ SigLIPì˜ ê²€ìƒ‰ ì„±ê³µì„ ì´ë¡ ì ìœ¼ë¡œ ì •ë‹¹í™”í•˜ê³ , SigLIPì—ì„œ ë‚˜íƒ€ë‚˜ëŠ” ëª¨ë‹¬ë¦¬í‹° ê²©ì°¨ë¥¼ ì„¤ëª…í•˜ë©°, ê³ í’ˆì§ˆ í‘œí˜„ì„ ìƒì„±í•˜ê¸° ìœ„í•œ í•„ìˆ˜ ì°¨ì›ì„ ì‹ë³„í•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ, ìƒëŒ€ ë°”ì´ì–´ìŠ¤ë¥¼ ëª…ì‹œì ìœ¼ë¡œ í¬í•¨í•œ ì‹œê·¸ëª¨ì´ë“œ ì†ì‹¤ì˜ ì¬ë§¤ê°œë³€ìˆ˜ë¥¼ ì œì•ˆí•˜ì—¬ í•©ì„± ë°ì´í„° ì‹¤í—˜ì—ì„œ í•™ìŠµ ì—­í•™ì„ ê°œì„ í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€ì¡°ì  ì‚¬ì „ í›ˆë ¨ì„ í†µí•œ í‘œí˜„ íšë“ ë° ì •ë ¬ì˜ ì¤‘ìš”ì„±ì´ CLIP ë° ALIGNì˜ ë„ì… ì´í›„ ì ì  ì»¤ì§€ê³  ìˆìŠµë‹ˆë‹¤.
- 2. SigLIP ë° SigLIP2 ëª¨ë¸ì—ì„œ êµ¬í˜„ëœ ì‹œê·¸ëª¨ì´ë“œ ì†ì‹¤ í•˜ì˜ í•™ìŠµ ê°€ëŠ¥í•œ ì—­ì˜¨ë„ ë° ë°”ì´ì–´ìŠ¤ ë™ê¸°í™”ì˜ ì´ì ì„ ì´ë¡ ì ìœ¼ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤.
- 3. $(\mathsf{m}, \mathsf{b}_{\mathsf{rel}})$-Constellationsë¼ëŠ” ìƒˆë¡œìš´ ì¡°í•© ê°ì²´ë¥¼ ë„ì…í•˜ì—¬ SigLIPì˜ ê²€ìƒ‰ ì„±ê³µì„ ì´ë¡ ì ìœ¼ë¡œ ì •ë‹¹í™”í•©ë‹ˆë‹¤.
- 4. SigLIPì—ì„œ ë‚˜íƒ€ë‚˜ëŠ” ëª¨ë‹¬ë¦¬í‹° ê²©ì°¨ë¥¼ ì„¤ëª…í•˜ê³  ê³ í’ˆì§ˆ í‘œí˜„ ìƒì„±ì„ ìœ„í•œ í•„ìš”í•œ ì°¨ì›ì„ ì‹ë³„í•©ë‹ˆë‹¤.
- 5. ëª…ì‹œì  ìƒëŒ€ ë°”ì´ì–´ìŠ¤ë¥¼ ì‚¬ìš©í•œ ì‹œê·¸ëª¨ì´ë“œ ì†ì‹¤ì˜ ì¬ë§¤ê°œë³€ìˆ˜ë¥¼ ì œì•ˆí•˜ì—¬ í•©ì„± ë°ì´í„° ì‹¤í—˜ì—ì„œ í›ˆë ¨ ì—­í•™ì„ ê°œì„ í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 13:53:32*