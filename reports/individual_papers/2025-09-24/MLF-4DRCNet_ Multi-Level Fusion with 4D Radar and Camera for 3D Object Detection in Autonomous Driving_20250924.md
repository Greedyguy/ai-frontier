<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T16:04:13.087648",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "4D Radar",
    "Multi-Level Fusion",
    "Attention Mechanism",
    "3D Object Detection",
    "Hierarchical Scene Fusion Pooling"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "4D Radar": 0.78,
    "Multi-Level Fusion": 0.77,
    "Attention Mechanism": 0.8,
    "3D Object Detection": 0.75,
    "Hierarchical Scene Fusion Pooling": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "4D Radar",
        "canonical": "4D Radar",
        "aliases": [
          "4D millimeter-wave radar"
        ],
        "category": "unique_technical",
        "rationale": "4D Radar is a crucial sensor technology in autonomous driving, offering unique data dimensions that enhance object detection capabilities.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.82,
        "link_intent_score": 0.78
      },
      {
        "surface": "Multi-Level Fusion",
        "canonical": "Multi-Level Fusion",
        "aliases": [
          "multi-level integration"
        ],
        "category": "unique_technical",
        "rationale": "Multi-Level Fusion is a novel approach in sensor data integration, enhancing the depth and accuracy of 3D object detection.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      },
      {
        "surface": "Attention Mechanism",
        "canonical": "Attention Mechanism",
        "aliases": [
          "deformable attention"
        ],
        "category": "specific_connectable",
        "rationale": "Attention Mechanism is a key component in enhancing feature representation and integration in multimodal systems.",
        "novelty_score": 0.55,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "3D Object Detection",
        "canonical": "3D Object Detection",
        "aliases": [
          "3D detection"
        ],
        "category": "broad_technical",
        "rationale": "3D Object Detection is a fundamental task in autonomous driving, linking various sensor technologies and fusion methods.",
        "novelty_score": 0.4,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.75
      },
      {
        "surface": "Hierarchical Scene Fusion Pooling",
        "canonical": "Hierarchical Scene Fusion Pooling",
        "aliases": [
          "HSFP"
        ],
        "category": "unique_technical",
        "rationale": "This method enhances scene understanding by dynamically integrating multi-scale features, crucial for advanced perception systems.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "4D Radar",
      "resolved_canonical": "4D Radar",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.82,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Multi-Level Fusion",
      "resolved_canonical": "Multi-Level Fusion",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Attention Mechanism",
      "resolved_canonical": "Attention Mechanism",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "3D Object Detection",
      "resolved_canonical": "3D Object Detection",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Hierarchical Scene Fusion Pooling",
      "resolved_canonical": "Hierarchical Scene Fusion Pooling",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# MLF-4DRCNet: Multi-Level Fusion with 4D Radar and Camera for 3D Object Detection in Autonomous Driving

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18613.pdf)
**Category**: cs.CV
**Published**: 2025-09-24
**ArXiv ID**: [2509.18613](https://arxiv.org/abs/2509.18613)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/PAN_ Pillars-Attention-Based Network for 3D Object Detection_20250922|PAN: Pillars-Attention-Based Network for 3D Object Detection]] (88.7% similar)
- [[2025-09-23/RCTDistill_ Cross-Modal Knowledge Distillation Framework for Radar-Camera 3D Object Detection with Temporal Fusion_20250923|RCTDistill: Cross-Modal Knowledge Distillation Framework for Radar-Camera 3D Object Detection with Temporal Fusion]] (87.3% similar)
- [[2025-09-23/MRADNET_ a Compact Radar Object Detector with MetaFormer_20250923|MRADNET: a Compact Radar Object Detector with MetaFormer]] (85.6% similar)
- [[2025-09-22/RadarGaussianDet3D_ An Efficient and Effective Gaussian-based 3D Detector with 4D Automotive Radars_20250922|RadarGaussianDet3D: An Efficient and Effective Gaussian-based 3D Detector with 4D Automotive Radars]] (85.4% similar)
- [[2025-09-22/DAOcc_ 3D Object Detection Assisted Multi-Sensor Fusion for 3D Occupancy Prediction_20250922|DAOcc: 3D Object Detection Assisted Multi-Sensor Fusion for 3D Occupancy Prediction]] (85.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/3D Object Detection|3D Object Detection]]
**ğŸ”— Specific Connectable**: [[keywords/Attention Mechanism|Attention Mechanism]]
**âš¡ Unique Technical**: [[keywords/4D Radar|4D Radar]], [[keywords/Multi-Level Fusion|Multi-Level Fusion]], [[keywords/Hierarchical Scene Fusion Pooling|Hierarchical Scene Fusion Pooling]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18613v1 Announce Type: new 
Abstract: The emerging 4D millimeter-wave radar, measuring the range, azimuth, elevation, and Doppler velocity of objects, is recognized for its cost-effectiveness and robustness in autonomous driving. Nevertheless, its point clouds exhibit significant sparsity and noise, restricting its standalone application in 3D object detection. Recent 4D radar-camera fusion methods have provided effective perception. Most existing approaches, however, adopt explicit Bird's-Eye-View fusion paradigms originally designed for LiDAR-camera fusion, neglecting radar's inherent drawbacks. Specifically, they overlook the sparse and incomplete geometry of radar point clouds and restrict fusion to coarse scene-level integration. To address these problems, we propose MLF-4DRCNet, a novel two-stage framework for 3D object detection via multi-level fusion of 4D radar and camera images. Our model incorporates the point-, scene-, and proposal-level multi-modal information, enabling comprehensive feature representation. It comprises three crucial components: the Enhanced Radar Point Encoder (ERPE) module, the Hierarchical Scene Fusion Pooling (HSFP) module, and the Proposal-Level Fusion Enhancement (PLFE) module. Operating at the point-level, ERPE densities radar point clouds with 2D image instances and encodes them into voxels via the proposed Triple-Attention Voxel Feature Encoder. HSFP dynamically integrates multi-scale voxel features with 2D image features using deformable attention to capture scene context and adopts pooling to the fused features. PLFE refines region proposals by fusing image features, and further integrates with the pooled features from HSFP. Experimental results on the View-of-Delft (VoD) and TJ4DRadSet datasets demonstrate that MLF-4DRCNet achieves the state-of-the-art performance. Notably, it attains performance comparable to LiDAR-based models on the VoD dataset.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ 4D ë°€ë¦¬ë¯¸í„°íŒŒ ë ˆì´ë”ì™€ ì¹´ë©”ë¼ ì´ë¯¸ì§€ë¥¼ ìœµí•©í•˜ì—¬ 3D ê°ì²´ íƒì§€ë¥¼ ìˆ˜í–‰í•˜ëŠ” MLF-4DRCNetì´ë¼ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë°©ë²•ë“¤ì´ ë ˆì´ë”ì˜ í¬ì†Œì„±ê³¼ ë¶ˆì™„ì „í•œ ê¸°í•˜í•™ì  íŠ¹ì„±ì„ ê°„ê³¼í•˜ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ì´ ëª¨ë¸ì€ í¬ì¸íŠ¸, ì¥ë©´, ì œì•ˆ ìˆ˜ì¤€ì˜ ë‹¤ì¤‘ ëª¨ë‹¬ ì •ë³´ë¥¼ í†µí•©í•˜ì—¬ í¬ê´„ì ì¸ íŠ¹ì§• í‘œí˜„ì„ ì œê³µí•©ë‹ˆë‹¤. ì£¼ìš” êµ¬ì„± ìš”ì†Œë¡œëŠ” í–¥ìƒëœ ë ˆì´ë” í¬ì¸íŠ¸ ì¸ì½”ë”(ERPE), ê³„ì¸µì  ì¥ë©´ ìœµí•© í’€ë§(HSFP), ì œì•ˆ ìˆ˜ì¤€ ìœµí•© ê°•í™”(PLFE) ëª¨ë“ˆì´ í¬í•¨ë©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì´ ëª¨ë¸ì€ View-of-Delft (VoD) ë° TJ4DRadSet ë°ì´í„°ì…‹ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìœ¼ë©°, íŠ¹íˆ VoD ë°ì´í„°ì…‹ì—ì„œ LiDAR ê¸°ë°˜ ëª¨ë¸ê³¼ ìœ ì‚¬í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. 4D ë°€ë¦¬ë¯¸í„°íŒŒ ë ˆì´ë”ëŠ” ììœ¨ ì£¼í–‰ì—ì„œ ë¹„ìš© íš¨ìœ¨ì„±ê³¼ ê°•ê±´ì„±ìœ¼ë¡œ ì£¼ëª©ë°›ì§€ë§Œ, í¬ì¸íŠ¸ í´ë¼ìš°ë“œì˜ í¬ì†Œì„±ê³¼ ë…¸ì´ì¦ˆë¡œ ì¸í•´ ë‹¨ë… 3D ê°ì²´ íƒì§€ì—ëŠ” ì œí•œì´ ìˆë‹¤.
- 2. ê¸°ì¡´ì˜ 4D ë ˆì´ë”-ì¹´ë©”ë¼ ìœµí•© ë°©ë²•ì€ LiDAR-ì¹´ë©”ë¼ ìœµí•©ì— ë§ì¶°ì§„ Bird's-Eye-View ë°©ì‹ì„ ì±„íƒí•˜ì—¬ ë ˆì´ë”ì˜ ê³ ìœ í•œ ë‹¨ì ì„ ê°„ê³¼í•œë‹¤.
- 3. MLF-4DRCNetì€ 4D ë ˆì´ë”ì™€ ì¹´ë©”ë¼ ì´ë¯¸ì§€ë¥¼ ë‹¤ì¤‘ ìˆ˜ì¤€ìœ¼ë¡œ ìœµí•©í•˜ì—¬ 3D ê°ì²´ íƒì§€ë¥¼ ìˆ˜í–‰í•˜ëŠ” ìƒˆë¡œìš´ ì´ë‹¨ê³„ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•œë‹¤.
- 4. ì œì•ˆëœ ëª¨ë¸ì€ í–¥ìƒëœ ë ˆì´ë” í¬ì¸íŠ¸ ì¸ì½”ë”(ERPE), ê³„ì¸µì  ì¥ë©´ ìœµí•© í’€ë§(HSFP), ì œì•ˆ ìˆ˜ì¤€ ìœµí•© ê°•í™”(PLFE) ëª¨ë“ˆë¡œ êµ¬ì„±ëœë‹¤.
- 5. View-of-Delft (VoD) ë° TJ4DRadSet ë°ì´í„°ì…‹ ì‹¤í—˜ ê²°ê³¼, MLF-4DRCNetì€ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ë©°, VoD ë°ì´í„°ì…‹ì—ì„œ LiDAR ê¸°ë°˜ ëª¨ë¸ê³¼ ìœ ì‚¬í•œ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤.


---

*Generated on 2025-09-24 16:04:13*