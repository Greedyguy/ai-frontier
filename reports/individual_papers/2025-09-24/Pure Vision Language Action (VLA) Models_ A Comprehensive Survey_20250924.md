<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T14:08:52.967249",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Vision-Language Action",
    "Generalizable Robotics",
    "Autoregression-Based Methods",
    "Reinforcement Learning",
    "Diffusion-Based Methods"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Vision-Language Action": 0.82,
    "Generalizable Robotics": 0.7,
    "Autoregression-Based Methods": 0.78,
    "Reinforcement Learning": 0.8,
    "Diffusion-Based Methods": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Vision Language Action",
        "canonical": "Vision-Language Action",
        "aliases": [
          "VLA"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-Language Action models represent a novel integration of vision, language, and action, crucial for linking to advancements in robotics and AI.",
        "novelty_score": 0.85,
        "connectivity_score": 0.78,
        "specificity_score": 0.88,
        "link_intent_score": 0.82
      },
      {
        "surface": "generalizable robotics",
        "canonical": "Generalizable Robotics",
        "aliases": [
          "generalized robotics"
        ],
        "category": "unique_technical",
        "rationale": "This concept links to the broader goal of developing adaptable robotic systems, a key area of innovation.",
        "novelty_score": 0.72,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      },
      {
        "surface": "autoregression-based",
        "canonical": "Autoregression-Based Methods",
        "aliases": [
          "autoregressive methods"
        ],
        "category": "specific_connectable",
        "rationale": "Autoregression-based methods are crucial for understanding sequential decision-making processes in VLA models.",
        "novelty_score": 0.6,
        "connectivity_score": 0.75,
        "specificity_score": 0.72,
        "link_intent_score": 0.78
      },
      {
        "surface": "reinforcement-based",
        "canonical": "Reinforcement Learning",
        "aliases": [
          "reinforcement-based methods"
        ],
        "category": "broad_technical",
        "rationale": "Reinforcement learning is a foundational approach in VLA models, linking to broader AI and machine learning research.",
        "novelty_score": 0.55,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "diffusion-based",
        "canonical": "Diffusion-Based Methods",
        "aliases": [
          "diffusion models"
        ],
        "category": "specific_connectable",
        "rationale": "Diffusion-based methods are emerging techniques in VLA, offering new pathways for model development.",
        "novelty_score": 0.68,
        "connectivity_score": 0.7,
        "specificity_score": 0.75,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "experiment"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Vision Language Action",
      "resolved_canonical": "Vision-Language Action",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.78,
        "specificity": 0.88,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "generalizable robotics",
      "resolved_canonical": "Generalizable Robotics",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "autoregression-based",
      "resolved_canonical": "Autoregression-Based Methods",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.75,
        "specificity": 0.72,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "reinforcement-based",
      "resolved_canonical": "Reinforcement Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "diffusion-based",
      "resolved_canonical": "Diffusion-Based Methods",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.7,
        "specificity": 0.75,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Pure Vision Language Action (VLA) Models: A Comprehensive Survey

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19012.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2509.19012](https://arxiv.org/abs/2509.19012)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Evo-0_ Vision-Language-Action Model with Implicit Spatial Understanding_20250923|Evo-0: Vision-Language-Action Model with Implicit Spatial Understanding]] (88.9% similar)
- [[2025-09-24/VLA-LPAF_ Lightweight Perspective-Adaptive Fusion for Vision-Language-Action to Enable More Unconstrained Robotic Manipulation_20250924|VLA-LPAF: Lightweight Perspective-Adaptive Fusion for Vision-Language-Action to Enable More Unconstrained Robotic Manipulation]] (88.4% similar)
- [[2025-09-22/A Vision-Language-Action-Critic Model for Robotic Real-World Reinforcement Learning_20250922|A Vision-Language-Action-Critic Model for Robotic Real-World Reinforcement Learning]] (88.3% similar)
- [[2025-09-24/Eva-VLA_ Evaluating Vision-Language-Action Models' Robustness Under Real-World Physical Variations_20250924|Eva-VLA: Evaluating Vision-Language-Action Models' Robustness Under Real-World Physical Variations]] (87.6% similar)
- [[2025-09-19/CollabVLA_ Self-Reflective Vision-Language-Action Model Dreaming Together with Human_20250919|CollabVLA: Self-Reflective Vision-Language-Action Model Dreaming Together with Human]] (87.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Reinforcement Learning|Reinforcement Learning]]
**ğŸ”— Specific Connectable**: [[keywords/Autoregression-Based Methods|Autoregression-Based Methods]], [[keywords/Diffusion-Based Methods|Diffusion-Based Methods]]
**âš¡ Unique Technical**: [[keywords/Generalizable Robotics|Generalizable Robotics]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Action|Vision-Language Action]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19012v1 Announce Type: cross 
Abstract: The emergence of Vision Language Action (VLA) models marks a paradigm shift from traditional policy-based control to generalized robotics, reframing Vision Language Models (VLMs) from passive sequence generators into active agents for manipulation and decision-making in complex, dynamic environments. This survey delves into advanced VLA methods, aiming to provide a clear taxonomy and a systematic, comprehensive review of existing research. It presents a comprehensive analysis of VLA applications across different scenarios and classifies VLA approaches into several paradigms: autoregression-based, diffusion-based, reinforcement-based, hybrid, and specialized methods; while examining their motivations, core strategies, and implementations in detail. In addition, foundational datasets, benchmarks, and simulation platforms are introduced. Building on the current VLA landscape, the review further proposes perspectives on key challenges and future directions to advance research in VLA models and generalizable robotics. By synthesizing insights from over three hundred recent studies, this survey maps the contours of this rapidly evolving field and highlights the opportunities and challenges that will shape the development of scalable, general-purpose VLA methods.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ Vision Language Action (VLA) ëª¨ë¸ì˜ ë°œì „ì„ ë‹¤ë£¨ë©°, ì „í†µì ì¸ ì •ì±… ê¸°ë°˜ ì œì–´ì—ì„œ ì¼ë°˜í™”ëœ ë¡œë´‡ ê³µí•™ìœ¼ë¡œì˜ ì „í™˜ì„ ì„¤ëª…í•©ë‹ˆë‹¤. VLA ëª¨ë¸ì€ ë³µì¡í•˜ê³  ë™ì ì¸ í™˜ê²½ì—ì„œ ì¡°ì‘ ë° ì˜ì‚¬ê²°ì •ì„ ìˆ˜í–‰í•˜ëŠ” ëŠ¥ë™ì  ì—ì´ì „íŠ¸ë¡œì„œì˜ ì—­í• ì„ ê°•ì¡°í•©ë‹ˆë‹¤. ë…¼ë¬¸ì€ VLA ë°©ë²•ë¡ ì„ ìë™íšŒê·€, í™•ì‚°, ê°•í™”í•™ìŠµ ê¸°ë°˜, í•˜ì´ë¸Œë¦¬ë“œ ë° íŠ¹ìˆ˜ ë°©ë²•ìœ¼ë¡œ ë¶„ë¥˜í•˜ê³ , ê° ì ‘ê·¼ë²•ì˜ ë™ê¸°, í•µì‹¬ ì „ëµ ë° êµ¬í˜„ì„ ìƒì„¸íˆ ë¶„ì„í•©ë‹ˆë‹¤. ë˜í•œ, ì£¼ìš” ë°ì´í„°ì…‹, ë²¤ì¹˜ë§ˆí¬, ì‹œë®¬ë ˆì´ì…˜ í”Œë«í¼ì„ ì†Œê°œí•˜ë©°, VLA ëª¨ë¸ ì—°êµ¬ì˜ ì£¼ìš” ê³¼ì œì™€ ë¯¸ë˜ ë°©í–¥ì„ ì œì‹œí•©ë‹ˆë‹¤. 300ì—¬ ê°œì˜ ìµœê·¼ ì—°êµ¬ë¥¼ ì¢…í•©í•˜ì—¬ VLA ë¶„ì•¼ì˜ ë°œì „ ê°€ëŠ¥ì„±ê³¼ ë„ì „ ê³¼ì œë¥¼ ì¡°ë§í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Vision Language Action (VLA) ëª¨ë¸ì˜ ë“±ì¥ì€ ì „í†µì ì¸ ì •ì±… ê¸°ë°˜ ì œì–´ì—ì„œ ì¼ë°˜í™”ëœ ë¡œë´‡ ê³µí•™ìœ¼ë¡œì˜ íŒ¨ëŸ¬ë‹¤ì„ ì „í™˜ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
- 2. VLA ì ‘ê·¼ë²•ì€ ìê°€ íšŒê·€ ê¸°ë°˜, í™•ì‚° ê¸°ë°˜, ê°•í™” ê¸°ë°˜, í•˜ì´ë¸Œë¦¬ë“œ ë° íŠ¹ìˆ˜í™”ëœ ë°©ë²• ë“± ì—¬ëŸ¬ íŒ¨ëŸ¬ë‹¤ì„ìœ¼ë¡œ ë¶„ë¥˜ë©ë‹ˆë‹¤.
- 3. VLA ëª¨ë¸ì˜ ì—°êµ¬ë¥¼ ë°œì „ì‹œí‚¤ê¸° ìœ„í•œ ì£¼ìš” ê³¼ì œì™€ ë¯¸ë˜ ë°©í–¥ì— ëŒ€í•œ ê´€ì ì„ ì œì‹œí•©ë‹ˆë‹¤.
- 4. 300ê°œ ì´ìƒì˜ ìµœê·¼ ì—°êµ¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ VLA ë¶„ì•¼ì˜ ë°œì „ ê¸°íšŒë¥¼ ì¡°ë§í•˜ê³  ìˆìŠµë‹ˆë‹¤.
- 5. VLA ëª¨ë¸ì˜ ì‘ìš© ì‚¬ë¡€ì™€ ê¸°ì´ˆ ë°ì´í„°ì…‹, ë²¤ì¹˜ë§ˆí¬, ì‹œë®¬ë ˆì´ì…˜ í”Œë«í¼ì„ ì†Œê°œí•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 14:08:52*