<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T14:40:31.228414",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Federated Learning",
    "Multimodal Learning",
    "Low-Rank Adaptation",
    "Modality Incompleteness"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Federated Learning": 0.78,
    "Multimodal Learning": 0.82,
    "Low-Rank Adaptation": 0.79,
    "Modality Incompleteness": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Federated Learning",
        "canonical": "Federated Learning",
        "aliases": [
          "FL"
        ],
        "category": "broad_technical",
        "rationale": "Federated Learning is a key concept in the paper, connecting it to decentralized model training.",
        "novelty_score": 0.45,
        "connectivity_score": 0.85,
        "specificity_score": 0.65,
        "link_intent_score": 0.78
      },
      {
        "surface": "Multimodal Data",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal"
        ],
        "category": "specific_connectable",
        "rationale": "Multimodal Learning is central to the paper's focus on handling multiple data types.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.72,
        "link_intent_score": 0.82
      },
      {
        "surface": "Low-Rank Adaptation",
        "canonical": "Low-Rank Adaptation",
        "aliases": [
          "LoRA"
        ],
        "category": "unique_technical",
        "rationale": "LoRA is a unique adaptation method crucial for the paper's approach to fine-tuning.",
        "novelty_score": 0.68,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.79
      },
      {
        "surface": "Missing Modalities",
        "canonical": "Modality Incompleteness",
        "aliases": [
          "Incomplete Modalities"
        ],
        "category": "unique_technical",
        "rationale": "Addressing missing modalities is a unique challenge tackled by the proposed framework.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.78,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "experiment"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Federated Learning",
      "resolved_canonical": "Federated Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.85,
        "specificity": 0.65,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Multimodal Data",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.72,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Low-Rank Adaptation",
      "resolved_canonical": "Low-Rank Adaptation",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Missing Modalities",
      "resolved_canonical": "Modality Incompleteness",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.78,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# FediLoRA: Heterogeneous LoRA for Federated Multimodal Fine-tuning under Missing Modalities

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.06984.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2509.06984](https://arxiv.org/abs/2509.06984)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Robust Federated Finetuning of LLMs via Alternating Optimization of LoRA_20250923|Robust Federated Finetuning of LLMs via Alternating Optimization of LoRA]] (91.3% similar)
- [[2025-09-18/Adaptive LoRA Experts Allocation and Selection for Federated Fine-Tuning_20250918|Adaptive LoRA Experts Allocation and Selection for Federated Fine-Tuning]] (89.5% similar)
- [[2025-09-24/LoRALib_ A Standardized Benchmark for Evaluating LoRA-MoE Methods_20250924|LoRALib: A Standardized Benchmark for Evaluating LoRA-MoE Methods]] (88.0% similar)
- [[2025-09-23/RefLoRA_ Refactored Low-Rank Adaptation for Efficient Fine-Tuning of Large Models_20250923|RefLoRA: Refactored Low-Rank Adaptation for Efficient Fine-Tuning of Large Models]] (85.8% similar)
- [[2025-09-22/Sparsity May Be All You Need_ Sparse Random Parameter Adaptation_20250922|Sparsity May Be All You Need: Sparse Random Parameter Adaptation]] (84.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Federated Learning|Federated Learning]]
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**âš¡ Unique Technical**: [[keywords/Low-Rank Adaptation|Low-Rank Adaptation]], [[keywords/Modality Incompleteness|Modality Incompleteness]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.06984v2 Announce Type: replace-cross 
Abstract: Foundation models have demonstrated remarkable performance across a wide range of tasks, yet their large parameter sizes pose challenges for practical deployment, especially in decentralized environments. Parameter-efficient fine-tuning (PEFT), such as Low-Rank Adaptation (LoRA), reduces local computing and memory overhead, making it attractive for federated learning. However, existing federated LoRA methods typically assume uniform rank configurations and unimodal inputs, overlooking two key real-world challenges: (1) heterogeneous client resources have different LoRA ranks, and (2) multimodal data settings with potentially missing modalities. In this work, we propose FediLoRA, a simple yet effective framework for federated multimodal fine-tuning under heterogeneous LoRA ranks and missing modalities. FediLoRA introduces a dimension-wise aggregation strategy that reweights LoRA updates without information dilution during aggregation. It also includes a lightweight layer-wise model editing method that selectively incorporates global parameters to repair local components which improves both client and global model performances. Experimental results on three multimodal benchmark datasets demonstrate that FediLoRA achieves superior performance over competitive baselines in both global and personalized settings, particularly in the presence of modality incompleteness.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€ê·œëª¨ íŒŒë¼ë¯¸í„° í¬ê¸°ë¡œ ì¸í•´ ì‹¤ìš©ì ì¸ ë°°í¬ì— ì–´ë ¤ì›€ì„ ê²ªëŠ” ê¸°ì´ˆ ëª¨ë¸ì„ ìœ„í•œ íŒŒë¼ë¯¸í„° íš¨ìœ¨ì  ë¯¸ì„¸ ì¡°ì •(PEFT) ë°©ë²•ë¡ ì„ ì œì•ˆí•©ë‹ˆë‹¤. íŠ¹íˆ, FediLoRAë¼ëŠ” í”„ë ˆì„ì›Œí¬ë¥¼ í†µí•´ ì´ì¢… í´ë¼ì´ì–¸íŠ¸ ìì›ê³¼ ë‹¤ì¤‘ ëª¨ë‹¬ ë°ì´í„° í™˜ê²½ì—ì„œì˜ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤. FediLoRAëŠ” LoRA ì—…ë°ì´íŠ¸ë¥¼ ì •ë³´ ì†ì‹¤ ì—†ì´ ì¬ì¡°ì •í•˜ëŠ” ì°¨ì›ë³„ ì§‘ê³„ ì „ëµê³¼, ê¸€ë¡œë²Œ íŒŒë¼ë¯¸í„°ë¥¼ ì„ íƒì ìœ¼ë¡œ í†µí•©í•˜ì—¬ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê²½ëŸ‰ ë ˆì´ì–´ í¸ì§‘ ë°©ë²•ì„ ë„ì…í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, FediLoRAëŠ” ì„¸ ê°€ì§€ ë‹¤ì¤‘ ëª¨ë‹¬ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì—ì„œ ê¸°ì¡´ ë°©ë²•ë“¤ë³´ë‹¤ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. FediLoRAëŠ” ì´ì§ˆì ì¸ LoRA ë­í¬ì™€ ëˆ„ë½ëœ ëª¨ë‹¬ë¦¬í‹°ê°€ ìˆëŠ” í™˜ê²½ì—ì„œ ì—°í•© ë©€í‹°ëª¨ë‹¬ ë¯¸ì„¸ ì¡°ì •ì„ ìœ„í•œ íš¨ê³¼ì ì¸ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.
- 2. FediLoRAëŠ” ì •ë³´ í¬ì„ ì—†ì´ LoRA ì—…ë°ì´íŠ¸ë¥¼ ì¬ê°€ì¤‘í•˜ëŠ” ì°¨ì›ë³„ ì§‘ê³„ ì „ëµì„ ë„ì…í•©ë‹ˆë‹¤.
- 3. FediLoRAëŠ” ê²½ëŸ‰ì˜ ë ˆì´ì–´ë³„ ëª¨ë¸ í¸ì§‘ ë°©ë²•ì„ í†µí•´ ê¸€ë¡œë²Œ íŒŒë¼ë¯¸í„°ë¥¼ ì„ íƒì ìœ¼ë¡œ í†µí•©í•˜ì—¬ ë¡œì»¬ êµ¬ì„± ìš”ì†Œë¥¼ ìˆ˜ì •í•˜ê³ , í´ë¼ì´ì–¸íŠ¸ ë° ê¸€ë¡œë²Œ ëª¨ë¸ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
- 4. ì„¸ ê°€ì§€ ë©€í‹°ëª¨ë‹¬ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì— ëŒ€í•œ ì‹¤í—˜ ê²°ê³¼, FediLoRAëŠ” ëª¨ë‹¬ë¦¬í‹° ë¶ˆì™„ì „ì„±ì´ ìˆëŠ” ìƒí™©ì—ì„œë„ ê¸€ë¡œë²Œ ë° ê°œì¸í™” ì„¤ì •ì—ì„œ ê²½ìŸë ¥ ìˆëŠ” ê¸°ì¤€ì„ ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.


---

*Generated on 2025-09-24 14:40:31*