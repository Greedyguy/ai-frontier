<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T15:53:47.235516",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Adversarial Text",
    "Heavy-Tailed Distribution",
    "Student's t-distribution",
    "RAID Benchmark"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Adversarial Text": 0.78,
    "Heavy-Tailed Distribution": 0.72,
    "Student's t-distribution": 0.8,
    "RAID Benchmark": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Connects to existing discussions on the capabilities and challenges of large language models.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Adversarial Machine-Generated Text",
        "canonical": "Adversarial Text",
        "aliases": [
          "Adversarial Text Generation"
        ],
        "category": "unique_technical",
        "rationale": "Highlights a specific challenge in detecting machine-generated text, crucial for linking to adversarial learning.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Heavy-Tailed Statistical Artifacts",
        "canonical": "Heavy-Tailed Distribution",
        "aliases": [
          "Heavy-Tailed Statistics"
        ],
        "category": "unique_technical",
        "rationale": "Essential for understanding the statistical basis of the proposed detection method.",
        "novelty_score": 0.68,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.72
      },
      {
        "surface": "Student's t-distribution",
        "canonical": "Student's t-distribution",
        "aliases": [
          "t-distribution"
        ],
        "category": "specific_connectable",
        "rationale": "Central to the paper's novel approach, linking to statistical methods in machine learning.",
        "novelty_score": 0.5,
        "connectivity_score": 0.75,
        "specificity_score": 0.78,
        "link_intent_score": 0.8
      },
      {
        "surface": "RAID Benchmark",
        "canonical": "RAID Benchmark",
        "aliases": [
          "RAID Dataset"
        ],
        "category": "unique_technical",
        "rationale": "Provides a basis for evaluating adversarial text detection methods, linking to benchmarking discussions.",
        "novelty_score": 0.7,
        "connectivity_score": 0.55,
        "specificity_score": 0.82,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Adversarial Machine-Generated Text",
      "resolved_canonical": "Adversarial Text",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Heavy-Tailed Statistical Artifacts",
      "resolved_canonical": "Heavy-Tailed Distribution",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "Student's t-distribution",
      "resolved_canonical": "Student's t-distribution",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.75,
        "specificity": 0.78,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "RAID Benchmark",
      "resolved_canonical": "RAID Benchmark",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.55,
        "specificity": 0.82,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# T-Detect: Tail-Aware Statistical Normalization for Robust Detection of Adversarial Machine-Generated Text

## 📋 메타데이터

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2507.23577.pdf)
**Category**: cs.CL
**Published**: 2025-09-24
**ArXiv ID**: [2507.23577](https://arxiv.org/abs/2507.23577)

## 🔗 유사한 논문
- [[2025-09-19/DetectAnyLLM_ Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models_20250919|DetectAnyLLM: Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models]] (86.3% similar)
- [[2025-09-24/Diversity Boosts AI-Generated Text Detection_20250924|Diversity Boosts AI-Generated Text Detection]] (85.3% similar)
- [[2025-09-22/DNA-DetectLLM_ Unveiling AI-Generated Text via a DNA-Inspired Mutation-Repair Paradigm_20250922|DNA-DetectLLM: Unveiling AI-Generated Text via a DNA-Inspired Mutation-Repair Paradigm]] (85.3% similar)
- [[2025-09-22/Tag&Tab_ Pretraining Data Detection in Large Language Models Using Keyword-Based Membership Inference Attack_20250922|Tag&Tab: Pretraining Data Detection in Large Language Models Using Keyword-Based Membership Inference Attack]] (83.7% similar)
- [[2025-09-24/Trace Is In Sentences_ Unbiased Lightweight ChatGPT-Generated Text Detector_20250924|Trace Is In Sentences: Unbiased Lightweight ChatGPT-Generated Text Detector]] (83.4% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Student's t-distribution|Student's t-distribution]]
**⚡ Unique Technical**: [[keywords/Adversarial Text|Adversarial Text]], [[keywords/Heavy-Tailed Distribution|Heavy-Tailed Distribution]], [[keywords/RAID Benchmark|RAID Benchmark]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2507.23577v2 Announce Type: replace 
Abstract: Large language models (LLMs) have shown the capability to generate fluent and logical content, presenting significant challenges to machine-generated text detection, particularly text polished by adversarial perturbations such as paraphrasing. Current zero-shot detectors often employ Gaussian distributions as statistical measure for computing detection thresholds, which falters when confronted with the heavy-tailed statistical artifacts characteristic of adversarial or non-native English texts. In this paper, we introduce T-Detect, a novel detection method that fundamentally redesigns the curvature-based detectors. Our primary innovation is the replacement of standard Gaussian normalization with a heavy-tailed discrepancy score derived from the Student's t-distribution. This approach is theoretically grounded in the empirical observation that adversarial texts exhibit significant leptokurtosis, rendering traditional statistical assumptions inadequate. T-Detect computes a detection score by normalizing the log-likelihood of a passage against the expected moments of a t-distribution, providing superior resilience to statistical outliers. We validate our approach on the challenging RAID benchmark for adversarial text and the comprehensive HART dataset. Experiments show that T-Detect provides a consistent performance uplift over strong baselines, improving AUROC by up to 3.9\% in targeted domains. When integrated into a two-dimensional detection framework (CT), our method achieves state-of-the-art performance, with an AUROC of 0.926 on the Books domain of RAID. Our contributions are a new, theoretically-justified statistical foundation for text detection, an ablation-validated method that demonstrates superior robustness, and a comprehensive analysis of its performance under adversarial conditions. Ours code are released at https://github.com/ResearAI/t-detect.

## 📝 요약

대형 언어 모델(LLM)이 생성하는 유창하고 논리적인 콘텐츠는 기계 생성 텍스트 탐지에 어려움을 줍니다. 특히, 패러프레이징과 같은 적대적 변형으로 다듬어진 텍스트는 탐지가 어렵습니다. 기존의 탐지기는 종종 가우시안 분포를 사용하지만, 이는 적대적 텍스트의 무거운 꼬리 분포 특성 때문에 한계를 보입니다. 본 논문에서는 T-Detect라는 새로운 탐지 방법을 소개합니다. 이 방법은 기존의 곡률 기반 탐지기를 재설계하여, 표준 가우시안 정규화를 스튜던트 t-분포에서 파생된 무거운 꼬리 불일치 점수로 대체합니다. T-Detect는 로그 가능도를 t-분포의 기대 모멘트로 정규화하여 통계적 이상치에 대한 강한 내성을 제공합니다. RAID 및 HART 데이터셋에서의 실험 결과, T-Detect는 기존 방법보다 AUROC를 최대 3.9% 개선하며, RAID의 Books 도메인에서 AUROC 0.926을 기록했습니다. 본 연구는 새로운 통계적 기반을 제시하고, 적대적 조건에서도 뛰어난 성능을 입증했습니다.

## 🎯 주요 포인트

- 1. T-Detect는 기존의 곡률 기반 탐지기를 근본적으로 재설계하여, 표준 가우시안 정규화를 Student's t-분포에서 파생된 heavy-tailed 불일치 점수로 대체합니다.
- 2. T-Detect는 로그 가능도를 t-분포의 예상 모멘트에 대해 정규화하여 탐지 점수를 계산하며, 통계적 이상치에 대한 뛰어난 내성을 제공합니다.
- 3. T-Detect는 RAID 벤치마크와 HART 데이터셋에서 강력한 기준선 대비 AUROC를 최대 3.9%까지 향상시키며, 특히 RAID의 Books 도메인에서 AUROC 0.926을 기록했습니다.
- 4. 이 연구는 이론적으로 정당화된 새로운 통계적 기반을 제공하며, 적대적 조건에서도 뛰어난 성능을 보이는 방법을 제시합니다.


---

*Generated on 2025-09-24 15:53:47*