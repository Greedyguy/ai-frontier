<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T16:31:04.381339",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Earth Observation Foundation Models",
    "Transformer",
    "Neural Network",
    "Mamba State-Space Models",
    "Few-Shot Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Earth Observation Foundation Models": 0.78,
    "Transformer": 0.81,
    "Neural Network": 0.79,
    "Mamba State-Space Models": 0.77,
    "Few-Shot Learning": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Earth Observation Foundation Models",
        "canonical": "Earth Observation Foundation Models",
        "aliases": [
          "EO Foundation Models"
        ],
        "category": "unique_technical",
        "rationale": "This is a specific type of foundation model tailored for Earth observation data, which is central to the paper's contributions.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Vision Transformers",
        "canonical": "Transformer",
        "aliases": [
          "ViT"
        ],
        "category": "broad_technical",
        "rationale": "Vision Transformers are a specific application of Transformers in computer vision, linking to broader Transformer research.",
        "novelty_score": 0.4,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.81
      },
      {
        "surface": "U-Net Convolutional Neural Network",
        "canonical": "Neural Network",
        "aliases": [
          "U-Net CNN"
        ],
        "category": "broad_technical",
        "rationale": "U-Net is a specific architecture within the broader category of neural networks, relevant for image segmentation tasks.",
        "novelty_score": 0.45,
        "connectivity_score": 0.82,
        "specificity_score": 0.68,
        "link_intent_score": 0.79
      },
      {
        "surface": "Mamba State-Space Models",
        "canonical": "Mamba State-Space Models",
        "aliases": [
          "Mamba SSM"
        ],
        "category": "unique_technical",
        "rationale": "Mamba SSMs are a novel approach discussed in the paper, offering a unique perspective on state-space modeling.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      },
      {
        "surface": "Few-Shot Learning",
        "canonical": "Few-Shot Learning",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Few-Shot Learning is a trending concept relevant to the paper's exploration of fine-tuning models with minimal labeled data.",
        "novelty_score": 0.55,
        "connectivity_score": 0.85,
        "specificity_score": 0.75,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "pretraining dataset",
      "downstream tasks",
      "PhilEO Bench"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Earth Observation Foundation Models",
      "resolved_canonical": "Earth Observation Foundation Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Vision Transformers",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.81
      }
    },
    {
      "candidate_surface": "U-Net Convolutional Neural Network",
      "resolved_canonical": "Neural Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.82,
        "specificity": 0.68,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Mamba State-Space Models",
      "resolved_canonical": "Mamba State-Space Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Few-Shot Learning",
      "resolved_canonical": "Few-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.85,
        "specificity": 0.75,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# Earth Observation Foundation Model PhilEO: Pretraining on the MajorTOM and FastTOM Datasets

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2506.14765.pdf)
**Category**: cs.CV
**Published**: 2025-09-24
**ArXiv ID**: [2506.14765](https://arxiv.org/abs/2506.14765)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/TESSERA_ Precomputed FAIR Global Pixel Embeddings for Earth Representation and Analysis_20250922|TESSERA: Precomputed FAIR Global Pixel Embeddings for Earth Representation and Analysis]] (82.6% similar)
- [[2025-09-24/MOMEMTO_ Patch-based Memory Gate Model in Time Series Foundation Model_20250924|MOMEMTO: Patch-based Memory Gate Model in Time Series Foundation Model]] (81.4% similar)
- [[2025-09-23/StefaLand_ An Efficient Geoscience Foundation Model That Improves Dynamic Land-Surface Predictions_20250923|StefaLand: An Efficient Geoscience Foundation Model That Improves Dynamic Land-Surface Predictions]] (80.4% similar)
- [[2025-09-23/Less is More_ Unlocking Specialization of Time Series Foundation Models via Structured Pruning_20250923|Less is More: Unlocking Specialization of Time Series Foundation Models via Structured Pruning]] (80.4% similar)
- [[2025-09-23/DeepInsert_ Early Layer Bypass for Efficient and Performant Multimodal Understanding_20250923|DeepInsert: Early Layer Bypass for Efficient and Performant Multimodal Understanding]] (80.4% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Transformer|Transformer]], [[keywords/Neural Network|Neural Network]]
**ğŸ”— Specific Connectable**: [[keywords/Few-Shot Learning|Few-Shot Learning]]
**âš¡ Unique Technical**: [[keywords/Earth Observation Foundation Models|Earth Observation Foundation Models]], [[keywords/Mamba State-Space Models|Mamba State-Space Models]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2506.14765v4 Announce Type: replace 
Abstract: Today, Earth Observation (EO) satellites generate massive volumes of data. To fully exploit this, it is essential to pretrain EO Foundation Models (FMs) on large unlabeled datasets, enabling efficient fine-tuning for downstream tasks with minimal labeled data. In this paper, we study scaling-up FMs: we train our models on the pretraining dataset MajorTOM 23TB which includes all regions, and the performance on average is competitive versus models pretrained on more specialized datasets which are substantially smaller and include only land. The additional data of oceans and ice do not decrease the performance on land-focused downstream tasks. These results indicate that large FMs trained on global datasets for a wider variety of downstream tasks can be useful for downstream applications that only require a subset of the information included in their training. The second contribution is the exploration of U-Net Convolutional Neural Network (CNN), Vision Transformers (ViT), and Mamba State-Space Models (SSM) as FMs. U-Net captures local correlations amongst pixels, while ViT and Mamba capture local and distant correlations. We develop various models using different architectures, including U-Net, ViT, and Mamba, and different number of parameters. We evaluate the FLoating-point OPerations (FLOPs) needed by the models. We fine-tune on the PhilEO Bench for different downstream tasks: roads, buildings, and land cover. For most n-shots for roads and buildings, U-Net 200M-2T outperforms the other models. Using Mamba, we achieve comparable results on the downstream tasks, with less computational expenses. We also compare with the recent FM TerraMind which we evaluate on PhilEO Bench.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì§€êµ¬ ê´€ì¸¡ ìœ„ì„± ë°ì´í„°ì˜ íš¨ìœ¨ì  í™œìš©ì„ ìœ„í•´ ëŒ€ê·œëª¨ ë¹„ì§€ë„ ë°ì´í„°ì…‹ì„ ê¸°ë°˜ìœ¼ë¡œ EO Foundation Models(FMs)ì„ ì‚¬ì „ í•™ìŠµí•˜ëŠ” ë°©ë²•ì„ ì—°êµ¬í•©ë‹ˆë‹¤. MajorTOM 23TB ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•´ ë‹¤ì–‘í•œ ì§€ì—­ì„ í¬í•¨í•œ ëª¨ë¸ì„ í•™ìŠµí•œ ê²°ê³¼, íŠ¹ì • ì§€ì—­ì— íŠ¹í™”ëœ ì‘ì€ ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµí•œ ëª¨ë¸ê³¼ ìœ ì‚¬í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ì´ëŠ” ëŒ€ê·œëª¨ ê¸€ë¡œë²Œ ë°ì´í„°ì…‹ì„ í™œìš©í•œ FMsì´ ë‹¤ì–‘í•œ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—…ì— ìœ ìš©í•  ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤. ë˜í•œ, U-Net, Vision Transformers(ViT), Mamba State-Space Models(SSM)ì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ì–‘í•œ ëª¨ë¸ì„ ê°œë°œí•˜ê³ , PhilEO Benchì—ì„œ ë„ë¡œ, ê±´ë¬¼, í† ì§€ í”¼ë³µ ë“±ì˜ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—…ì— ëŒ€í•´ í‰ê°€í–ˆìŠµë‹ˆë‹¤. U-Net 200M-2T ëª¨ë¸ì´ ëŒ€ë¶€ë¶„ì˜ ê²½ìš° ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë©°, Mamba ëª¨ë¸ì€ ì ì€ ê³„ì‚° ë¹„ìš©ìœ¼ë¡œë„ ìœ ì‚¬í•œ ê²°ê³¼ë¥¼ ì–»ì—ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€ê·œëª¨ì˜ ë¯¸í‘œê¸° ë°ì´í„°ì…‹ì¸ MajorTOM 23TBë¥¼ ì‚¬ìš©í•˜ì—¬ EO Foundation Models(FMs)ì„ ì‚¬ì „ í•™ìŠµí•¨ìœ¼ë¡œì¨, ì ì€ ì–‘ì˜ ë¼ë²¨ë§ëœ ë°ì´í„°ë¡œë„ íš¨ìœ¨ì ì¸ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.
- 2. í•´ì–‘ê³¼ ë¹™í•˜ ë°ì´í„°ë¥¼ í¬í•¨í•œ ëŒ€ê·œëª¨ ê¸€ë¡œë²Œ ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµëœ FMsëŠ” ìœ¡ì§€ ì¤‘ì‹¬ì˜ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—… ì„±ëŠ¥ì„ ì €í•´í•˜ì§€ ì•Šìœ¼ë©°, ë‹¤ì–‘í•œ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—…ì— ìœ ìš©í•˜ë‹¤.
- 3. U-Net, Vision Transformers(ViT), Mamba State-Space Models(SSM) ë“± ë‹¤ì–‘í•œ ì•„í‚¤í…ì²˜ë¥¼ íƒêµ¬í•˜ì—¬, ê° ëª¨ë¸ì˜ FLOPsë¥¼ í‰ê°€í•˜ê³  ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—…ì— ë§ì¶° ë¯¸ì„¸ ì¡°ì •í•˜ì˜€ë‹¤.
- 4. U-Net 200M-2T ëª¨ë¸ì€ ë„ë¡œ ë° ê±´ë¬¼ ê´€ë ¨ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—…ì—ì„œ ëŒ€ë¶€ë¶„ì˜ n-shotì—ì„œ ë‹¤ë¥¸ ëª¨ë¸ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤.
- 5. Mamba ëª¨ë¸ì€ ì ì€ ê³„ì‚° ë¹„ìš©ìœ¼ë¡œë„ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—…ì—ì„œ ë¹„êµ ê°€ëŠ¥í•œ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ì˜€ë‹¤.


---

*Generated on 2025-09-24 16:31:04*