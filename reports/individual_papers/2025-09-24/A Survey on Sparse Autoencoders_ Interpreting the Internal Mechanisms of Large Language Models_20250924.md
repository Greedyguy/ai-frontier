<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T14:30:55.752401",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Sparse Autoencoder",
    "Large Language Model",
    "Mechanistic Interpretability",
    "Input-based Explanation",
    "Output-based Explanation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Sparse Autoencoder": 0.78,
    "Large Language Model": 0.85,
    "Mechanistic Interpretability": 0.82,
    "Input-based Explanation": 0.77,
    "Output-based Explanation": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Sparse Autoencoders",
        "canonical": "Sparse Autoencoder",
        "aliases": [
          "SAE"
        ],
        "category": "unique_technical",
        "rationale": "Sparse Autoencoders are central to the paper's focus on interpreting LLMs and offer a unique technical perspective.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are a foundational element of the study and connect to a wide range of NLP research.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Mechanistic Interpretability",
        "canonical": "Mechanistic Interpretability",
        "aliases": [
          "Interpretability"
        ],
        "category": "specific_connectable",
        "rationale": "Mechanistic Interpretability is a specific approach explored in the paper, linking to broader interpretability research.",
        "novelty_score": 0.68,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.82
      },
      {
        "surface": "Input-based Explanation Methods",
        "canonical": "Input-based Explanation",
        "aliases": [
          "Input-based Methods"
        ],
        "category": "unique_technical",
        "rationale": "This method is a unique technical approach discussed in the paper, relevant for understanding SAE features.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.78,
        "link_intent_score": 0.77
      },
      {
        "surface": "Output-based Explanation Methods",
        "canonical": "Output-based Explanation",
        "aliases": [
          "Output-based Methods"
        ],
        "category": "unique_technical",
        "rationale": "This method complements input-based explanations, providing a comprehensive view of SAE feature interpretation.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.78,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "approach"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Sparse Autoencoders",
      "resolved_canonical": "Sparse Autoencoder",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Mechanistic Interpretability",
      "resolved_canonical": "Mechanistic Interpretability",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Input-based Explanation Methods",
      "resolved_canonical": "Input-based Explanation",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.78,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Output-based Explanation Methods",
      "resolved_canonical": "Output-based Explanation",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.78,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# A Survey on Sparse Autoencoders: Interpreting the Internal Mechanisms of Large Language Models

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2503.05613.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2503.05613](https://arxiv.org/abs/2503.05613)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-24/Safe-SAIL_ Towards a Fine-grained Safety Landscape of Large Language Models via Sparse Autoencoder Interpretation Framework_20250924|Safe-SAIL: Towards a Fine-grained Safety Landscape of Large Language Models via Sparse Autoencoder Interpretation Framework]] (89.3% similar)
- [[2025-09-19/Large Multi-modal Models Can Interpret Features in Large Multi-modal Models_20250919|Large Multi-modal Models Can Interpret Features in Large Multi-modal Models]] (86.6% similar)
- [[2025-09-23/Group-SAE_ Efficient Training of Sparse Autoencoders for Large Language Models via Layer Groups_20250923|Group-SAE: Efficient Training of Sparse Autoencoders for Large Language Models via Layer Groups]] (86.4% similar)
- [[2025-09-24/Can LLMs Explain Themselves Counterfactually?_20250924|Can LLMs Explain Themselves Counterfactually?]] (85.0% similar)
- [[2025-09-19/Opening the Black Box_ Interpretable LLMs via Semantic Resonance Architecture_20250919|Opening the Black Box: Interpretable LLMs via Semantic Resonance Architecture]] (84.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Mechanistic Interpretability|Mechanistic Interpretability]]
**âš¡ Unique Technical**: [[keywords/Sparse Autoencoder|Sparse Autoencoder]], [[keywords/Input-based Explanation|Input-based Explanation]], [[keywords/Output-based Explanation|Output-based Explanation]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2503.05613v3 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) have transformed natural language processing, yet their internal mechanisms remain largely opaque. Recently, mechanistic interpretability has attracted significant attention from the research community as a means to understand the inner workings of LLMs. Among various mechanistic interpretability approaches, Sparse Autoencoders (SAEs) have emerged as a promising method due to their ability to disentangle the complex, superimposed features within LLMs into more interpretable components. This paper presents a comprehensive survey of SAEs for interpreting and understanding the internal workings of LLMs. Our major contributions include: (1) exploring the technical framework of SAEs, covering basic architecture, design improvements, and effective training strategies; (2) examining different approaches to explaining SAE features, categorized into input-based and output-based explanation methods; (3) discussing evaluation methods for assessing SAE performance, covering both structural and functional metrics; and (4) investigating real-world applications of SAEs in understanding and manipulating LLM behaviors.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ë‚´ë¶€ ì‘ë™ ë°©ì‹ì„ ì´í•´í•˜ê¸° ìœ„í•œ ê¸°ê³„ì  í•´ì„ ê°€ëŠ¥ì„± ì—°êµ¬ì—ì„œ í¬ì†Œ ì˜¤í† ì¸ì½”ë”(SAE)ì˜ ì—­í• ì„ ì¢…í•©ì ìœ¼ë¡œ ì¡°ì‚¬í•©ë‹ˆë‹¤. ì£¼ìš” ê¸°ì—¬ë¡œëŠ” (1) SAEì˜ ê¸°ìˆ ì  í”„ë ˆì„ì›Œí¬ íƒìƒ‰, (2) ì…ë ¥ ê¸°ë°˜ ë° ì¶œë ¥ ê¸°ë°˜ ì„¤ëª… ë°©ë²•ìœ¼ë¡œ ë¶„ë¥˜ëœ SAE íŠ¹ì§• ì„¤ëª… ì ‘ê·¼ë²• ê²€í† , (3) êµ¬ì¡°ì  ë° ê¸°ëŠ¥ì  ì§€í‘œë¥¼ í¬í•¨í•œ SAE ì„±ëŠ¥ í‰ê°€ ë°©ë²• ë…¼ì˜, (4) LLMì˜ í–‰ë™ ì´í•´ ë° ì¡°ì‘ì—ì„œ SAEì˜ ì‹¤ì œ ì‘ìš© ì‚¬ë¡€ ì¡°ì‚¬ ë“±ì´ ìˆìŠµë‹ˆë‹¤. SAEëŠ” LLMì˜ ë³µì¡í•œ íŠ¹ì§•ì„ í•´ì„ ê°€ëŠ¥í•œ êµ¬ì„± ìš”ì†Œë¡œ ë¶„ë¦¬í•˜ëŠ” ë° ìœ ë§í•œ ë°©ë²•ìœ¼ë¡œ ì£¼ëª©ë°›ê³  ìˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì˜ ë‚´ë¶€ ë©”ì»¤ë‹ˆì¦˜ì„ ì´í•´í•˜ê¸° ìœ„í•œ ê¸°ë²•ìœ¼ë¡œ í¬ì†Œ ì˜¤í† ì¸ì½”ë”(SAEs)ê°€ ì£¼ëª©ë°›ê³  ìˆë‹¤.
- 2. SAEsëŠ” LLMsì˜ ë³µì¡í•œ íŠ¹ì§•ì„ ë” í•´ì„ ê°€ëŠ¥í•œ êµ¬ì„± ìš”ì†Œë¡œ ë¶„ë¦¬í•˜ëŠ” ë° íš¨ê³¼ì ì´ë‹¤.
- 3. ì´ ë…¼ë¬¸ì€ SAEsì˜ ê¸°ìˆ ì  í”„ë ˆì„ì›Œí¬, ì„¤ê³„ ê°œì„  ë° íš¨ê³¼ì ì¸ í›ˆë ¨ ì „ëµì„ íƒêµ¬í•œë‹¤.
- 4. SAEsì˜ íŠ¹ì§•ì„ ì„¤ëª…í•˜ëŠ” ì…ë ¥ ê¸°ë°˜ ë° ì¶œë ¥ ê¸°ë°˜ ë°©ë²•ì„ ê²€í† í•œë‹¤.
- 5. SAEsì˜ ì„±ëŠ¥ í‰ê°€ ë°©ë²•ê³¼ ì‹¤ì œ ì‘ìš© ì‚¬ë¡€ë¥¼ ì¡°ì‚¬í•œë‹¤.


---

*Generated on 2025-09-24 14:30:55*