<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T14:30:55.752401",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Sparse Autoencoder",
    "Large Language Model",
    "Mechanistic Interpretability",
    "Input-based Explanation",
    "Output-based Explanation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Sparse Autoencoder": 0.78,
    "Large Language Model": 0.85,
    "Mechanistic Interpretability": 0.82,
    "Input-based Explanation": 0.77,
    "Output-based Explanation": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Sparse Autoencoders",
        "canonical": "Sparse Autoencoder",
        "aliases": [
          "SAE"
        ],
        "category": "unique_technical",
        "rationale": "Sparse Autoencoders are central to the paper's focus on interpreting LLMs and offer a unique technical perspective.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are a foundational element of the study and connect to a wide range of NLP research.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Mechanistic Interpretability",
        "canonical": "Mechanistic Interpretability",
        "aliases": [
          "Interpretability"
        ],
        "category": "specific_connectable",
        "rationale": "Mechanistic Interpretability is a specific approach explored in the paper, linking to broader interpretability research.",
        "novelty_score": 0.68,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.82
      },
      {
        "surface": "Input-based Explanation Methods",
        "canonical": "Input-based Explanation",
        "aliases": [
          "Input-based Methods"
        ],
        "category": "unique_technical",
        "rationale": "This method is a unique technical approach discussed in the paper, relevant for understanding SAE features.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.78,
        "link_intent_score": 0.77
      },
      {
        "surface": "Output-based Explanation Methods",
        "canonical": "Output-based Explanation",
        "aliases": [
          "Output-based Methods"
        ],
        "category": "unique_technical",
        "rationale": "This method complements input-based explanations, providing a comprehensive view of SAE feature interpretation.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.78,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "approach"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Sparse Autoencoders",
      "resolved_canonical": "Sparse Autoencoder",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Mechanistic Interpretability",
      "resolved_canonical": "Mechanistic Interpretability",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Input-based Explanation Methods",
      "resolved_canonical": "Input-based Explanation",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.78,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Output-based Explanation Methods",
      "resolved_canonical": "Output-based Explanation",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.78,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# A Survey on Sparse Autoencoders: Interpreting the Internal Mechanisms of Large Language Models

## 📋 메타데이터

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2503.05613.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2503.05613](https://arxiv.org/abs/2503.05613)

## 🔗 유사한 논문
- [[2025-09-24/Safe-SAIL_ Towards a Fine-grained Safety Landscape of Large Language Models via Sparse Autoencoder Interpretation Framework_20250924|Safe-SAIL: Towards a Fine-grained Safety Landscape of Large Language Models via Sparse Autoencoder Interpretation Framework]] (89.3% similar)
- [[2025-09-19/Large Multi-modal Models Can Interpret Features in Large Multi-modal Models_20250919|Large Multi-modal Models Can Interpret Features in Large Multi-modal Models]] (86.6% similar)
- [[2025-09-23/Group-SAE_ Efficient Training of Sparse Autoencoders for Large Language Models via Layer Groups_20250923|Group-SAE: Efficient Training of Sparse Autoencoders for Large Language Models via Layer Groups]] (86.4% similar)
- [[2025-09-24/Can LLMs Explain Themselves Counterfactually?_20250924|Can LLMs Explain Themselves Counterfactually?]] (85.0% similar)
- [[2025-09-19/Opening the Black Box_ Interpretable LLMs via Semantic Resonance Architecture_20250919|Opening the Black Box: Interpretable LLMs via Semantic Resonance Architecture]] (84.5% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Mechanistic Interpretability|Mechanistic Interpretability]]
**⚡ Unique Technical**: [[keywords/Sparse Autoencoder|Sparse Autoencoder]], [[keywords/Input-based Explanation|Input-based Explanation]], [[keywords/Output-based Explanation|Output-based Explanation]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2503.05613v3 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) have transformed natural language processing, yet their internal mechanisms remain largely opaque. Recently, mechanistic interpretability has attracted significant attention from the research community as a means to understand the inner workings of LLMs. Among various mechanistic interpretability approaches, Sparse Autoencoders (SAEs) have emerged as a promising method due to their ability to disentangle the complex, superimposed features within LLMs into more interpretable components. This paper presents a comprehensive survey of SAEs for interpreting and understanding the internal workings of LLMs. Our major contributions include: (1) exploring the technical framework of SAEs, covering basic architecture, design improvements, and effective training strategies; (2) examining different approaches to explaining SAE features, categorized into input-based and output-based explanation methods; (3) discussing evaluation methods for assessing SAE performance, covering both structural and functional metrics; and (4) investigating real-world applications of SAEs in understanding and manipulating LLM behaviors.

## 📝 요약

이 논문은 대형 언어 모델(LLM)의 내부 작동 방식을 이해하기 위한 기계적 해석 가능성 연구에서 희소 오토인코더(SAE)의 역할을 종합적으로 조사합니다. 주요 기여로는 (1) SAE의 기술적 프레임워크 탐색, (2) 입력 기반 및 출력 기반 설명 방법으로 분류된 SAE 특징 설명 접근법 검토, (3) 구조적 및 기능적 지표를 포함한 SAE 성능 평가 방법 논의, (4) LLM의 행동 이해 및 조작에서 SAE의 실제 응용 사례 조사 등이 있습니다. SAE는 LLM의 복잡한 특징을 해석 가능한 구성 요소로 분리하는 데 유망한 방법으로 주목받고 있습니다.

## 🎯 주요 포인트

- 1. 대형 언어 모델(LLMs)의 내부 메커니즘을 이해하기 위한 기법으로 희소 오토인코더(SAEs)가 주목받고 있다.
- 2. SAEs는 LLMs의 복잡한 특징을 더 해석 가능한 구성 요소로 분리하는 데 효과적이다.
- 3. 이 논문은 SAEs의 기술적 프레임워크, 설계 개선 및 효과적인 훈련 전략을 탐구한다.
- 4. SAEs의 특징을 설명하는 입력 기반 및 출력 기반 방법을 검토한다.
- 5. SAEs의 성능 평가 방법과 실제 응용 사례를 조사한다.


---

*Generated on 2025-09-24 14:30:55*