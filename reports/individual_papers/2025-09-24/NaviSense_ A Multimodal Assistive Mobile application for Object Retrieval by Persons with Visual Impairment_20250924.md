<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T13:59:36.940252",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Vision-Language Model",
    "Augmented Reality",
    "LiDAR",
    "Conversational AI",
    "Real-time Audio-Haptic Guidance"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Vision-Language Model": 0.85,
    "Augmented Reality": 0.8,
    "LiDAR": 0.75,
    "Conversational AI": 0.78,
    "Real-time Audio-Haptic Guidance": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Vision-Language Models",
        "canonical": "Vision-Language Model",
        "aliases": [
          "Vision-Language",
          "VLM"
        ],
        "category": "evolved_concepts",
        "rationale": "Links to recent advances in integrating visual and language data for AI applications.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.72,
        "link_intent_score": 0.85
      },
      {
        "surface": "Augmented Reality",
        "canonical": "Augmented Reality",
        "aliases": [
          "AR"
        ],
        "category": "broad_technical",
        "rationale": "Provides a bridge between physical and digital worlds, enhancing user interaction.",
        "novelty_score": 0.45,
        "connectivity_score": 0.78,
        "specificity_score": 0.65,
        "link_intent_score": 0.8
      },
      {
        "surface": "LiDAR",
        "canonical": "LiDAR",
        "aliases": [
          "Light Detection and Ranging"
        ],
        "category": "unique_technical",
        "rationale": "Critical for spatial awareness and object detection in assistive technologies.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      },
      {
        "surface": "Conversational AI",
        "canonical": "Conversational AI",
        "aliases": [
          "Chatbot",
          "Dialogue Systems"
        ],
        "category": "specific_connectable",
        "rationale": "Facilitates natural language interaction, crucial for accessibility in assistive applications.",
        "novelty_score": 0.6,
        "connectivity_score": 0.82,
        "specificity_score": 0.7,
        "link_intent_score": 0.78
      },
      {
        "surface": "Real-time Audio-Haptic Guidance",
        "canonical": "Real-time Audio-Haptic Guidance",
        "aliases": [
          "Audio-Haptic Feedback"
        ],
        "category": "unique_technical",
        "rationale": "Innovative feedback mechanism enhancing navigation for visually impaired users.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "assistive technologies",
      "object retrieval"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Vision-Language Models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.72,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Augmented Reality",
      "resolved_canonical": "Augmented Reality",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.78,
        "specificity": 0.65,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "LiDAR",
      "resolved_canonical": "LiDAR",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Conversational AI",
      "resolved_canonical": "Conversational AI",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.82,
        "specificity": 0.7,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Real-time Audio-Haptic Guidance",
      "resolved_canonical": "Real-time Audio-Haptic Guidance",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# NaviSense: A Multimodal Assistive Mobile application for Object Retrieval by Persons with Visual Impairment

## 📋 메타데이터

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18672.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2509.18672](https://arxiv.org/abs/2509.18672)

## 🔗 유사한 논문
- [[2025-09-18/Embodied Navigation Foundation Model_20250918|Embodied Navigation Foundation Model]] (81.9% similar)
- [[2025-09-18/FSR-VLN_ Fast and Slow Reasoning for Vision-Language Navigation with Hierarchical Multi-modal Scene Graph_20250918|FSR-VLN: Fast and Slow Reasoning for Vision-Language Navigation with Hierarchical Multi-modal Scene Graph]] (81.4% similar)
- [[2025-09-23/Audio-Guided Dynamic Modality Fusion with Stereo-Aware Attention for Audio-Visual Navigation_20250923|Audio-Guided Dynamic Modality Fusion with Stereo-Aware Attention for Audio-Visual Navigation]] (81.0% similar)
- [[2025-09-18/VSE-MOT_ Multi-Object Tracking in Low-Quality Video Scenes Guided by Visual Semantic Enhancement_20250918|VSE-MOT: Multi-Object Tracking in Low-Quality Video Scenes Guided by Visual Semantic Enhancement]] (80.8% similar)
- [[2025-09-23/Sight Over Site_ Perception-Aware Reinforcement Learning for Efficient Robotic Inspection_20250923|Sight Over Site: Perception-Aware Reinforcement Learning for Efficient Robotic Inspection]] (80.8% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Augmented Reality|Augmented Reality]]
**🔗 Specific Connectable**: [[keywords/Conversational AI|Conversational AI]]
**⚡ Unique Technical**: [[keywords/LiDAR|LiDAR]], [[keywords/Real-time Audio-Haptic Guidance|Real-time Audio-Haptic Guidance]]
**🚀 Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.18672v1 Announce Type: cross 
Abstract: People with visual impairments often face significant challenges in locating and retrieving objects in their surroundings. Existing assistive technologies present a trade-off: systems that offer precise guidance typically require pre-scanning or support only fixed object categories, while those with open-world object recognition lack spatial feedback for reaching the object. To address this gap, we introduce 'NaviSense', a mobile assistive system that combines conversational AI, vision-language models, augmented reality (AR), and LiDAR to support open-world object detection with real-time audio-haptic guidance. Users specify objects via natural language and receive continuous spatial feedback to navigate toward the target without needing prior setup. Designed with insights from a formative study and evaluated with 12 blind and low-vision participants, NaviSense significantly reduced object retrieval time and was preferred over existing tools, demonstrating the value of integrating open-world perception with precise, accessible guidance.

## 📝 요약

시각 장애인은 주변 물체를 찾고 회수하는 데 어려움을 겪습니다. 기존 보조 기술은 정밀한 안내를 위해 사전 스캔이 필요하거나 고정된 물체 범주만 지원하는 반면, 개방형 객체 인식 시스템은 공간 피드백이 부족합니다. 이를 해결하기 위해 'NaviSense'라는 모바일 보조 시스템을 개발했습니다. 이 시스템은 대화형 AI, 비전-언어 모델, 증강 현실(AR), LiDAR를 결합하여 실시간 음성-촉각 안내와 함께 개방형 객체 탐지를 지원합니다. 사용자는 자연어로 물체를 지정하고 지속적인 공간 피드백을 받아 목표물로 안내받습니다. 사전 설정이 필요 없으며, 12명의 시각 장애인을 대상으로 한 평가에서 NaviSense는 물체 회수 시간을 크게 줄였고 기존 도구보다 선호되었습니다. 이는 개방형 인식과 정밀한 안내의 통합 가치가 있음을 보여줍니다.

## 🎯 주요 포인트

- 1. NaviSense는 시각 장애인을 위한 모바일 보조 시스템으로, 대화형 AI, 비전-언어 모델, 증강 현실(AR), LiDAR를 결합하여 실시간 오디오-촉각 안내를 제공합니다.
- 2. 사용자는 자연어로 객체를 지정하고, 사전 설정 없이도 목표물로 이동할 수 있는 지속적인 공간 피드백을 받습니다.
- 3. 형성 연구의 통찰을 바탕으로 설계된 NaviSense는 12명의 시각 장애 참가자들과의 평가에서 객체 검색 시간을 크게 단축시켰습니다.
- 4. NaviSense는 기존 도구보다 선호되었으며, 개방형 세계 인식과 정밀하고 접근 가능한 안내의 통합 가치를 입증했습니다.


---

*Generated on 2025-09-24 13:59:36*