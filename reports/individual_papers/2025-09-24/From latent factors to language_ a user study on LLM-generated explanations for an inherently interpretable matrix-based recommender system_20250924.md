<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T13:31:15.313277",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Explainable AI",
    "Matrix Factorization",
    "User-Centered Design"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Explainable AI": 0.82,
    "Matrix Factorization": 0.78,
    "User-Centered Design": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Language Model"
        ],
        "category": "broad_technical",
        "rationale": "LLMs are central to the paper's methodology and are a key concept in modern AI research.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.72,
        "link_intent_score": 0.85
      },
      {
        "surface": "Explainable AI",
        "canonical": "Explainable AI",
        "aliases": [
          "XAI",
          "Interpretable AI"
        ],
        "category": "specific_connectable",
        "rationale": "The paper focuses on generating explanations, making Explainable AI a critical linking concept.",
        "novelty_score": 0.58,
        "connectivity_score": 0.79,
        "specificity_score": 0.81,
        "link_intent_score": 0.82
      },
      {
        "surface": "Matrix Factorization",
        "canonical": "Matrix Factorization",
        "aliases": [
          "Constrained Matrix Factorization"
        ],
        "category": "unique_technical",
        "rationale": "Matrix Factorization is the core mathematical technique used in the recommendation model.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "User-Centered Approach",
        "canonical": "User-Centered Design",
        "aliases": [
          "User-Centered Methodology"
        ],
        "category": "evolved_concepts",
        "rationale": "The study's focus on user feedback aligns with the principles of User-Centered Design.",
        "novelty_score": 0.66,
        "connectivity_score": 0.68,
        "specificity_score": 0.77,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance",
      "study"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.72,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Explainable AI",
      "resolved_canonical": "Explainable AI",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.79,
        "specificity": 0.81,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Matrix Factorization",
      "resolved_canonical": "Matrix Factorization",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "User-Centered Approach",
      "resolved_canonical": "User-Centered Design",
      "decision": "linked",
      "scores": {
        "novelty": 0.66,
        "connectivity": 0.68,
        "specificity": 0.77,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# From latent factors to language: a user study on LLM-generated explanations for an inherently interpretable matrix-based recommender system

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18980.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2509.18980](https://arxiv.org/abs/2509.18980)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Challenging the Evaluator_ LLM Sycophancy Under User Rebuttal_20250923|Challenging the Evaluator: LLM Sycophancy Under User Rebuttal]] (86.3% similar)
- [[2025-09-22/Quantifying Uncertainty in Natural Language Explanations of Large Language Models for Question Answering_20250922|Quantifying Uncertainty in Natural Language Explanations of Large Language Models for Question Answering]] (86.1% similar)
- [[2025-09-23/See What I Mean? CUE_ A Cognitive Model of Understanding Explanations_20250923|See What I Mean? CUE: A Cognitive Model of Understanding Explanations]] (85.3% similar)
- [[2025-09-23/No Need for Explanations_ LLMs can implicitly learn from mistakes in-context_20250923|No Need for Explanations: LLMs can implicitly learn from mistakes in-context]] (85.1% similar)
- [[2025-09-22/Bias Beware_ The Impact of Cognitive Biases on LLM-Driven Product Recommendations_20250922|Bias Beware: The Impact of Cognitive Biases on LLM-Driven Product Recommendations]] (84.9% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Explainable AI|Explainable AI]]
**âš¡ Unique Technical**: [[keywords/Matrix Factorization|Matrix Factorization]]
**ğŸš€ Evolved Concepts**: [[keywords/User-Centered Design|User-Centered Design]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18980v1 Announce Type: new 
Abstract: We investigate whether large language models (LLMs) can generate effective, user-facing explanations from a mathematically interpretable recommendation model. The model is based on constrained matrix factorization, where user types are explicitly represented and predicted item scores share the same scale as observed ratings, making the model's internal representations and predicted scores directly interpretable. This structure is translated into natural language explanations using carefully designed LLM prompts. Many works in explainable AI rely on automatic evaluation metrics, which often fail to capture users' actual needs and perceptions. In contrast, we adopt a user-centered approach: we conduct a study with 326 participants who assessed the quality of the explanations across five key dimensions-transparency, effectiveness, persuasion, trust, and satisfaction-as well as the recommendations themselves.To evaluate how different explanation strategies are perceived, we generate multiple explanation types from the same underlying model, varying the input information provided to the LLM. Our analysis reveals that all explanation types are generally well received, with moderate statistical differences between strategies. User comments further underscore how participants react to each type of explanation, offering complementary insights beyond the quantitative results.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì´ ìˆ˜í•™ì ìœ¼ë¡œ í•´ì„ ê°€ëŠ¥í•œ ì¶”ì²œ ëª¨ë¸ë¡œë¶€í„° íš¨ê³¼ì ì¸ ì‚¬ìš©ì ì¤‘ì‹¬ ì„¤ëª…ì„ ìƒì„±í•  ìˆ˜ ìˆëŠ”ì§€ë¥¼ ì—°êµ¬í•©ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ì œí•œëœ í–‰ë ¬ ë¶„í•´ì— ê¸°ë°˜í•˜ì—¬ ì‚¬ìš©ì ìœ í˜•ì„ ëª…ì‹œì ìœ¼ë¡œ í‘œí˜„í•˜ê³ , ì˜ˆì¸¡ëœ ì•„ì´í…œ ì ìˆ˜ê°€ ê´€ì°°ëœ í‰ê°€ì™€ ë™ì¼í•œ ì²™ë„ë¥¼ ê³µìœ í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ëª¨ë¸ì˜ ë‚´ë¶€ í‘œí˜„ê³¼ ì˜ˆì¸¡ ì ìˆ˜ë¥¼ ì§ì ‘ í•´ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìì—°ì–´ ì„¤ëª…ì€ ì‹ ì¤‘í•˜ê²Œ ì„¤ê³„ëœ LLM í”„ë¡¬í”„íŠ¸ë¥¼ í†µí•´ ìƒì„±ë©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ì„¤ëª… ê°€ëŠ¥í•œ AI ì—°êµ¬ëŠ” ìë™ í‰ê°€ ì§€í‘œì— ì˜ì¡´í•˜ì§€ë§Œ, ì´ëŠ” ì‚¬ìš©ìì˜ ì‹¤ì œ ìš”êµ¬ì™€ ì¸ì‹ì„ ì˜ ë°˜ì˜í•˜ì§€ ëª»í•©ë‹ˆë‹¤. ë³¸ ì—°êµ¬ëŠ” ì‚¬ìš©ì ì¤‘ì‹¬ ì ‘ê·¼ ë°©ì‹ì„ ì±„íƒí•˜ì—¬ 326ëª…ì˜ ì°¸ê°€ìê°€ ì„¤ëª…ì˜ íˆ¬ëª…ì„±, íš¨ê³¼ì„±, ì„¤ë“ë ¥, ì‹ ë¢°ë„, ë§Œì¡±ë„ ë° ì¶”ì²œ í’ˆì§ˆì„ í‰ê°€í–ˆìŠµë‹ˆë‹¤. ë‹¤ì–‘í•œ ì…ë ¥ ì •ë³´ë¥¼ LLMì— ì œê³µí•˜ì—¬ ì—¬ëŸ¬ ì„¤ëª… ìœ í˜•ì„ ìƒì„±í•˜ê³ , ì´ë“¤ì˜ ì¸ì‹ì„ ë¶„ì„í–ˆìŠµë‹ˆë‹¤. ëª¨ë“  ì„¤ëª… ìœ í˜•ì´ ëŒ€ì²´ë¡œ ê¸ì •ì ìœ¼ë¡œ í‰ê°€ë˜ì—ˆìœ¼ë©°, ì „ëµ ê°„ì˜ í†µê³„ì  ì°¨ì´ëŠ” ë¯¸ë¯¸í–ˆìŠµë‹ˆë‹¤. ì‚¬ìš©ì ì˜ê²¬ì€ ì •ëŸ‰ì  ê²°ê³¼ë¥¼ ë³´ì™„í•˜ëŠ” ì¶”ê°€ì ì¸ í†µì°°ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì´ ìˆ˜í•™ì ìœ¼ë¡œ í•´ì„ ê°€ëŠ¥í•œ ì¶”ì²œ ëª¨ë¸ë¡œë¶€í„° íš¨ê³¼ì ì¸ ì‚¬ìš©ì ì§€í–¥ ì„¤ëª…ì„ ìƒì„±í•  ìˆ˜ ìˆëŠ”ì§€ë¥¼ ì¡°ì‚¬í•©ë‹ˆë‹¤.
- 2. ì œì•½ í–‰ë ¬ ë¶„í•´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ëª¨ë¸ì€ ì‚¬ìš©ì ìœ í˜•ì„ ëª…ì‹œì ìœ¼ë¡œ í‘œí˜„í•˜ê³  ì˜ˆì¸¡ëœ í•­ëª© ì ìˆ˜ê°€ ê´€ì°°ëœ í‰ê°€ì™€ ê°™ì€ ì²™ë„ë¥¼ ê³µìœ í•˜ì—¬ ëª¨ë¸ì˜ ë‚´ë¶€ í‘œí˜„ê³¼ ì˜ˆì¸¡ ì ìˆ˜ë¥¼ ì§ì ‘ í•´ì„í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.
- 3. ì‚¬ìš©ì ì¤‘ì‹¬ ì ‘ê·¼ ë°©ì‹ì„ ì±„íƒí•˜ì—¬ 326ëª…ì˜ ì°¸ê°€ìê°€ ì„¤ëª…ì˜ íˆ¬ëª…ì„±, íš¨ê³¼ì„±, ì„¤ë“ë ¥, ì‹ ë¢°, ë§Œì¡±ë„ ë° ì¶”ì²œì˜ ì§ˆì„ í‰ê°€í•˜ëŠ” ì—°êµ¬ë¥¼ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.
- 4. ë™ì¼í•œ ëª¨ë¸ì—ì„œ ë‹¤ì–‘í•œ ì„¤ëª… ìœ í˜•ì„ ìƒì„±í•˜ì—¬ ì„œë¡œ ë‹¤ë¥¸ ì„¤ëª… ì „ëµì´ ì–´ë–»ê²Œ ì¸ì‹ë˜ëŠ”ì§€ë¥¼ í‰ê°€í–ˆìŠµë‹ˆë‹¤.
- 5. ëª¨ë“  ì„¤ëª… ìœ í˜•ì´ ëŒ€ì²´ë¡œ ê¸ì •ì ìœ¼ë¡œ ë°›ì•„ë“¤ì—¬ì¡Œìœ¼ë©°, ì „ëµ ê°„ì— ì¤‘ê°„ ì •ë„ì˜ í†µê³„ì  ì°¨ì´ê°€ ìˆìŒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 13:31:15*