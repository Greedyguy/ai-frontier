<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T14:28:49.615670",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Change Detection",
    "Remote Sensing",
    "Knowledge Distillation",
    "Multi-Teacher Knowledge Distillation",
    "Change Area Ratio"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Change Detection": 0.78,
    "Remote Sensing": 0.72,
    "Knowledge Distillation": 0.8,
    "Multi-Teacher Knowledge Distillation": 0.77,
    "Change Area Ratio": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Change Detection",
        "canonical": "Change Detection",
        "aliases": [
          "CD"
        ],
        "category": "unique_technical",
        "rationale": "Change Detection is a core concept in remote sensing and is central to the paper's contributions.",
        "novelty_score": 0.65,
        "connectivity_score": 0.75,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Remote Sensing",
        "canonical": "Remote Sensing",
        "aliases": [],
        "category": "broad_technical",
        "rationale": "Remote Sensing is the field within which the study is conducted, providing context for the dataset and methods.",
        "novelty_score": 0.55,
        "connectivity_score": 0.8,
        "specificity_score": 0.7,
        "link_intent_score": 0.72
      },
      {
        "surface": "Knowledge Distillation",
        "canonical": "Knowledge Distillation",
        "aliases": [
          "KD"
        ],
        "category": "specific_connectable",
        "rationale": "Knowledge Distillation is a key technique used in the proposed framework, linking to broader machine learning practices.",
        "novelty_score": 0.6,
        "connectivity_score": 0.85,
        "specificity_score": 0.78,
        "link_intent_score": 0.8
      },
      {
        "surface": "Multi-Teacher Knowledge Distillation",
        "canonical": "Multi-Teacher Knowledge Distillation",
        "aliases": [
          "MTKD"
        ],
        "category": "unique_technical",
        "rationale": "This specific framework is a novel contribution of the paper, enhancing the connectivity to related distillation techniques.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.77
      },
      {
        "surface": "Change Area Ratio",
        "canonical": "Change Area Ratio",
        "aliases": [
          "CAR"
        ],
        "category": "unique_technical",
        "rationale": "Change Area Ratio is a novel metric introduced in the paper, crucial for understanding the partitioning strategy.",
        "novelty_score": 0.68,
        "connectivity_score": 0.6,
        "specificity_score": 0.88,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "Earth observation",
      "high-resolution",
      "dataset"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Change Detection",
      "resolved_canonical": "Change Detection",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.75,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Remote Sensing",
      "resolved_canonical": "Remote Sensing",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.8,
        "specificity": 0.7,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "Knowledge Distillation",
      "resolved_canonical": "Knowledge Distillation",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.85,
        "specificity": 0.78,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Multi-Teacher Knowledge Distillation",
      "resolved_canonical": "Multi-Teacher Knowledge Distillation",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Change Area Ratio",
      "resolved_canonical": "Change Area Ratio",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.6,
        "specificity": 0.88,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# JL1-CD: A New Benchmark for Remote Sensing Change Detection and a Robust Multi-Teacher Knowledge Distillation Framework

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2502.13407.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2502.13407](https://arxiv.org/abs/2502.13407)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/DC-Mamba_ Bi-temporal deformable alignment and scale-sparse enhancement for remote sensing change detection_20250922|DC-Mamba: Bi-temporal deformable alignment and scale-sparse enhancement for remote sensing change detection]] (82.6% similar)
- [[2025-09-22/Semantic Change Detection of Roads and Bridges_ A Fine-grained Dataset and Multimodal Frequency-driven Detector_20250922|Semantic Change Detection of Roads and Bridges: A Fine-grained Dataset and Multimodal Frequency-driven Detector]] (82.2% similar)
- [[2025-09-24/MMCD_ Multi-Modal Collaborative Decision-Making for Connected Autonomy with Knowledge Distillation_20250924|MMCD: Multi-Modal Collaborative Decision-Making for Connected Autonomy with Knowledge Distillation]] (81.2% similar)
- [[2025-09-22/RSCC_ A Large-Scale Remote Sensing Change Caption Dataset for Disaster Events_20250922|RSCC: A Large-Scale Remote Sensing Change Caption Dataset for Disaster Events]] (80.9% similar)
- [[2025-09-24/A Single Image Is All You Need_ Zero-Shot Anomaly Localization Without Training Data_20250924|A Single Image Is All You Need: Zero-Shot Anomaly Localization Without Training Data]] (80.4% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Remote Sensing|Remote Sensing]]
**ğŸ”— Specific Connectable**: [[keywords/Knowledge Distillation|Knowledge Distillation]]
**âš¡ Unique Technical**: [[keywords/Change Detection|Change Detection]], [[keywords/Multi-Teacher Knowledge Distillation|Multi-Teacher Knowledge Distillation]], [[keywords/Change Area Ratio|Change Area Ratio]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2502.13407v4 Announce Type: replace-cross 
Abstract: Change detection (CD) in remote sensing images plays a vital role in Earth observation. However, the scarcity of high-resolution, comprehensive open-source datasets and the difficulty in achieving robust performance across varying change types remain major challenges. To address these issues, we introduce JL1-CD, a large-scale, sub-meter CD dataset consisting of 5,000 image pairs. We further propose a novel Origin-Partition (O-P) strategy and integrate it into a Multi-Teacher Knowledge Distillation (MTKD) framework to enhance CD performance. The O-P strategy partitions the training set by Change Area Ratio (CAR) and trains specialized teacher models on each subset. The MTKD framework then distills complementary knowledge from these teachers into a single student model, enabling improved detection results across diverse CAR scenarios without additional inference cost. Our MTKD approach demonstrated strong performance in the 2024 ``Jilin-1'' Cup challenge, ranking first in the preliminary and second in the final rounds. Extensive experiments on the JL1-CD and SYSU-CD datasets show that the MTKD framework consistently improves the performance of CD models with various network architectures and parameter sizes, establishing new state-of-the-art results. Code and dataset are available at https://github.com/circleLZY/MTKD-CD.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì›ê²© íƒì‚¬ ì´ë¯¸ì§€ì—ì„œ ë³€í™” íƒì§€ë¥¼ ê°œì„ í•˜ê¸° ìœ„í•´ ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ JL1-CDì™€ ìƒˆë¡œìš´ Origin-Partition(O-P) ì „ëµì„ ì œì•ˆí•©ë‹ˆë‹¤. O-P ì „ëµì€ ë³€í™” ì˜ì—­ ë¹„ìœ¨(CAR)ì— ë”°ë¼ í›ˆë ¨ ì„¸íŠ¸ë¥¼ ë‚˜ëˆ„ê³ , ê° ë¶€ë¶„ì— íŠ¹í™”ëœ êµì‚¬ ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë‹¤ì¤‘ êµì‚¬ ì§€ì‹ ì¦ë¥˜(MTKD) í”„ë ˆì„ì›Œí¬ë¥¼ êµ¬ì¶•í•˜ì—¬ ë‹¤ì–‘í•œ CAR ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. MTKD ì ‘ê·¼ë²•ì€ 2024 "Jilin-1" ì»µ ì±Œë¦°ì§€ì—ì„œ ìš°ìˆ˜í•œ ì„±ê³¼ë¥¼ ë³´ì˜€ìœ¼ë©°, ë‹¤ì–‘í•œ ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°ì™€ íŒŒë¼ë¯¸í„° í¬ê¸°ì—ì„œ ì¼ê´€ëœ ì„±ëŠ¥ í–¥ìƒì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤. ì½”ë“œì™€ ë°ì´í„°ì…‹ì€ ê³µê°œë˜ì–´ ìˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì›ê²© íƒì‚¬ ì´ë¯¸ì§€ì—ì„œ ë³€í™” íƒì§€ëŠ” ì§€êµ¬ ê´€ì¸¡ì— ì¤‘ìš”í•œ ì—­í• ì„ í•˜ì§€ë§Œ, ê³ í•´ìƒë„ ë° í¬ê´„ì ì¸ ì˜¤í”ˆ ì†ŒìŠ¤ ë°ì´í„°ì…‹ì˜ ë¶€ì¡±ê³¼ ë‹¤ì–‘í•œ ë³€í™” ìœ í˜•ì— ëŒ€í•œ ê°•ë ¥í•œ ì„±ëŠ¥ ë‹¬ì„±ì´ ì£¼ìš” ê³¼ì œì…ë‹ˆë‹¤.
- 2. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ 5,000ê°œì˜ ì´ë¯¸ì§€ ìŒìœ¼ë¡œ êµ¬ì„±ëœ ëŒ€ê·œëª¨ ì„œë¸Œë¯¸í„° CD ë°ì´í„°ì…‹ì¸ JL1-CDë¥¼ ì†Œê°œí•©ë‹ˆë‹¤.
- 3. Origin-Partition (O-P) ì „ëµì„ ì œì•ˆí•˜ê³  ì´ë¥¼ Multi-Teacher Knowledge Distillation (MTKD) í”„ë ˆì„ì›Œí¬ì— í†µí•©í•˜ì—¬ CD ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
- 4. MTKD ì ‘ê·¼ë²•ì€ 2024 "Jilin-1" Cup ì±Œë¦°ì§€ì—ì„œ ì˜ˆë¹„ ë¼ìš´ë“œ 1ìœ„, ìµœì¢… ë¼ìš´ë“œ 2ìœ„ë¥¼ ê¸°ë¡í•˜ë©° ê°•ë ¥í•œ ì„±ëŠ¥ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.
- 5. JL1-CD ë° SYSU-CD ë°ì´í„°ì…‹ì— ëŒ€í•œ ê´‘ë²”ìœ„í•œ ì‹¤í—˜ì„ í†µí•´ MTKD í”„ë ˆì„ì›Œí¬ê°€ ë‹¤ì–‘í•œ ë„¤íŠ¸ì›Œí¬ ì•„í‚¤í…ì²˜ì™€ íŒŒë¼ë¯¸í„° í¬ê¸°ì˜ CD ëª¨ë¸ ì„±ëŠ¥ì„ ì¼ê´€ë˜ê²Œ í–¥ìƒì‹œí‚´ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.


---

*Generated on 2025-09-24 14:28:49*