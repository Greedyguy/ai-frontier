<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T13:44:56.960576",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Knowledge Graph",
    "Unified Medical Language System",
    "Reward Model",
    "Diagnostic Reasoning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Knowledge Graph": 0.89,
    "Unified Medical Language System": 0.78,
    "Reward Model": 0.82,
    "Diagnostic Reasoning": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Large Language Models"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's exploration of diagnostic reasoning and reward modeling.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Knowledge Graphs",
        "canonical": "Knowledge Graph",
        "aliases": [
          "KG",
          "Knowledge Graphs"
        ],
        "category": "specific_connectable",
        "rationale": "Key to the paper's approach of integrating structured biomedical knowledge.",
        "novelty_score": 0.58,
        "connectivity_score": 0.92,
        "specificity_score": 0.78,
        "link_intent_score": 0.89
      },
      {
        "surface": "Unified Medical Language System",
        "canonical": "Unified Medical Language System",
        "aliases": [
          "UMLS"
        ],
        "category": "unique_technical",
        "rationale": "Specific knowledge graph used for biomedical knowledge representation.",
        "novelty_score": 0.72,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Reward Model",
        "canonical": "Reward Model",
        "aliases": [
          "Reward Modeling"
        ],
        "category": "specific_connectable",
        "rationale": "Central concept for evaluating knowledge graph reasoning paths.",
        "novelty_score": 0.6,
        "connectivity_score": 0.8,
        "specificity_score": 0.77,
        "link_intent_score": 0.82
      },
      {
        "surface": "Diagnostic Reasoning",
        "canonical": "Diagnostic Reasoning",
        "aliases": [
          "Clinical Reasoning"
        ],
        "category": "unique_technical",
        "rationale": "The primary application domain for the proposed knowledge graph-based approach.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.82,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Knowledge Graphs",
      "resolved_canonical": "Knowledge Graph",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.92,
        "specificity": 0.78,
        "link_intent": 0.89
      }
    },
    {
      "candidate_surface": "Unified Medical Language System",
      "resolved_canonical": "Unified Medical Language System",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Reward Model",
      "resolved_canonical": "Reward Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.8,
        "specificity": 0.77,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Diagnostic Reasoning",
      "resolved_canonical": "Diagnostic Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.82,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Brittleness and Promise: Knowledge Graph Based Reward Modeling for Diagnostic Reasoning

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18316.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2509.18316](https://arxiv.org/abs/2509.18316)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Temporal Reasoning with Large Language Models Augmented by Evolving Knowledge Graphs_20250922|Temporal Reasoning with Large Language Models Augmented by Evolving Knowledge Graphs]] (86.4% similar)
- [[2025-09-23/Evaluation of Causal Reasoning for Large Language Models in Contextualized Clinical Scenarios of Laboratory Test Interpretation_20250923|Evaluation of Causal Reasoning for Large Language Models in Contextualized Clinical Scenarios of Laboratory Test Interpretation]] (86.1% similar)
- [[2025-09-22/Reward Hacking Mitigation using Verifiable Composite Rewards_20250922|Reward Hacking Mitigation using Verifiable Composite Rewards]] (86.0% similar)
- [[2025-09-23/How Is LLM Reasoning Distracted by Irrelevant Context? An Analysis Using a Controlled Benchmark_20250923|How Is LLM Reasoning Distracted by Irrelevant Context? An Analysis Using a Controlled Benchmark]] (85.9% similar)
- [[2025-09-23/Large Language Models Meet Knowledge Graphs for Question Answering_ Synthesis and Opportunities_20250923|Large Language Models Meet Knowledge Graphs for Question Answering: Synthesis and Opportunities]] (85.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Knowledge Graph|Knowledge Graph]], [[keywords/Reward Model|Reward Model]]
**âš¡ Unique Technical**: [[keywords/Unified Medical Language System|Unified Medical Language System]], [[keywords/Diagnostic Reasoning|Diagnostic Reasoning]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18316v1 Announce Type: cross 
Abstract: Large language models (LLMs) show promise for diagnostic reasoning but often lack reliable, knowledge grounded inference. Knowledge graphs (KGs), such as the Unified Medical Language System (UMLS), offer structured biomedical knowledge that can support trustworthy reasoning. Prior approaches typically integrate KGs via retrieval augmented generation or fine tuning, inserting KG content into prompts rather than enabling structured reasoning. We explore an alternative paradigm: treating the LLM as a reward model of KG reasoning paths, where the model learns to judge whether a candidate path leads to correct diagnosis for a given patient input. This approach is inspired by recent work that leverages reward training to enhance model reasoning abilities, and grounded in computational theory, which suggests that verifying a solution is often easier than generating one from scratch. It also parallels physicians' diagnostic assessment, where they judge which sequences of findings and intermediate conditions most plausibly support a diagnosis. We first systematically evaluate five task formulation for knowledge path judging and eight training paradigm. Second, we test whether the path judging abilities generalize to downstream diagnostic tasks, including diagnosis summarization and medical question answering. Experiments with three open source instruct-tuned LLMs reveal both promise and brittleness: while specific reward optimization and distillation lead to strong path-judging performance, the transferability to downstream tasks remain weak. Our finding provides the first systematic assessment of "reward model style" reasoning over clinical KGs, offering insights into how structured, reward-based supervision influences diagnostic reasoning in GenAI systems for healthcare.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì§„ë‹¨ ì¶”ë¡  ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ì§€ì‹ ê·¸ë˜í”„(KG)ë¥¼ í™œìš©í•˜ëŠ” ìƒˆë¡œìš´ ì ‘ê·¼ ë°©ì‹ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ ë°©ë²•ì€ KGë¥¼ ë‹¨ìˆœíˆ ì •ë³´ ê²€ìƒ‰ì´ë‚˜ ë¯¸ì„¸ ì¡°ì •ì— ì‚¬ìš©í–ˆìœ¼ë‚˜, ë³¸ ì—°êµ¬ëŠ” LLMì„ KG ì¶”ë¡  ê²½ë¡œì˜ ë³´ìƒ ëª¨ë¸ë¡œ ì·¨ê¸‰í•˜ì—¬ í™˜ì ì…ë ¥ì— ëŒ€í•œ ì˜¬ë°”ë¥¸ ì§„ë‹¨ ê²½ë¡œë¥¼ íŒë‹¨í•˜ë„ë¡ í•™ìŠµì‹œí‚µë‹ˆë‹¤. ì´ëŠ” ìµœê·¼ ë³´ìƒ í•™ìŠµì„ í†µí•œ ëª¨ë¸ ì¶”ë¡  ëŠ¥ë ¥ í–¥ìƒ ì—°êµ¬ì— ì˜ê°ì„ ë°›ì•˜ìœ¼ë©°, ì˜ì‚¬ë“¤ì´ ì§„ë‹¨ì„ í‰ê°€í•˜ëŠ” ë°©ì‹ê³¼ ìœ ì‚¬í•©ë‹ˆë‹¤. ì—°êµ¬ëŠ” ë‹¤ì„¯ ê°€ì§€ ì‘ì—… í˜•ì‹ê³¼ ì—¬ëŸ ê°€ì§€ í•™ìŠµ íŒ¨ëŸ¬ë‹¤ì„ì„ í‰ê°€í•˜ê³ , ê²½ë¡œ íŒë‹¨ ëŠ¥ë ¥ì´ ì§„ë‹¨ ìš”ì•½ ë° ì˜ë£Œ ì§ˆë¬¸ ì‘ë‹µê³¼ ê°™ì€ í•˜ìœ„ ì‘ì—…ì— ì¼ë°˜í™”ë˜ëŠ”ì§€ë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, íŠ¹ì • ë³´ìƒ ìµœì í™”ì™€ ì¦ë¥˜ëŠ” ê°•ë ¥í•œ ê²½ë¡œ íŒë‹¨ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë‚˜, í•˜ìœ„ ì‘ì—…ìœ¼ë¡œì˜ ì „ì´ ê°€ëŠ¥ì„±ì€ ì•½í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ì„ìƒ KGì—ì„œì˜ "ë³´ìƒ ëª¨ë¸ ìŠ¤íƒ€ì¼" ì¶”ë¡ ì— ëŒ€í•œ ì²´ê³„ì ì¸ í‰ê°€ë¥¼ ì œê³µí•˜ë©°, GenAI ì‹œìŠ¤í…œì˜ ì§„ë‹¨ ì¶”ë¡ ì— ëŒ€í•œ í†µì°°ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ ì§„ë‹¨ ì¶”ë¡ ì— ìœ ë§í•˜ì§€ë§Œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì§€ì‹ ê¸°ë°˜ì˜ ì¶”ë¡ ì´ ë¶€ì¡±í•˜ë‹¤.
- 2. ì§€ì‹ ê·¸ë˜í”„(KG)ëŠ” êµ¬ì¡°í™”ëœ ìƒë¬¼ ì˜í•™ ì§€ì‹ì„ ì œê³µí•˜ì—¬ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¶”ë¡ ì„ ì§€ì›í•  ìˆ˜ ìˆë‹¤.
- 3. LLMì„ KG ì¶”ë¡  ê²½ë¡œì˜ ë³´ìƒ ëª¨ë¸ë¡œ ì·¨ê¸‰í•˜ì—¬ í™˜ì ì…ë ¥ì— ëŒ€í•œ ì˜¬ë°”ë¥¸ ì§„ë‹¨ìœ¼ë¡œ ì´ì–´ì§€ëŠ” ê²½ë¡œë¥¼ íŒë‹¨í•˜ëŠ” ë°©ì‹ì„ íƒêµ¬í•œë‹¤.
- 4. ë³´ìƒ ìµœì í™”ì™€ ì¦ë¥˜ëŠ” ê²½ë¡œ íŒë‹¨ ì„±ëŠ¥ì„ ê°•í™”í•˜ì§€ë§Œ, í•˜ìœ„ ì§„ë‹¨ ì‘ì—…ìœ¼ë¡œì˜ ì „ì´ ê°€ëŠ¥ì„±ì€ ì•½í•˜ë‹¤.
- 5. ì„ìƒ KGì— ëŒ€í•œ "ë³´ìƒ ëª¨ë¸ ìŠ¤íƒ€ì¼" ì¶”ë¡ ì˜ ì²´ê³„ì ì¸ í‰ê°€ë¥¼ í†µí•´ GenAI ì‹œìŠ¤í…œì˜ ì§„ë‹¨ ì¶”ë¡ ì— ëŒ€í•œ í†µì°°ì„ ì œê³µí•œë‹¤.


---

*Generated on 2025-09-24 13:44:56*