<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T15:43:13.335361",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Multi-Hierarchical Feature Detection",
    "DeBERTa-based Semantic Analysis",
    "Syntactic Parsing",
    "Statistical Probability Features"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Multi-Hierarchical Feature Detection": 0.78,
    "DeBERTa-based Semantic Analysis": 0.7,
    "Syntactic Parsing": 0.72,
    "Statistical Probability Features": 0.68
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Model",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's focus on AI text detection, providing a strong link to existing research in language models.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.8,
        "link_intent_score": 0.85
      },
      {
        "surface": "Multi-Hierarchical Feature Detection",
        "canonical": "Multi-Hierarchical Feature Detection",
        "aliases": [
          "MHFD"
        ],
        "category": "unique_technical",
        "rationale": "Represents the novel method introduced in the paper, crucial for understanding the specific approach taken.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.88,
        "link_intent_score": 0.78
      },
      {
        "surface": "DeBERTa-based semantic analysis",
        "canonical": "DeBERTa-based Semantic Analysis",
        "aliases": [
          "DeBERTa Semantic Analysis"
        ],
        "category": "specific_connectable",
        "rationale": "Highlights a specific technique used in the study, linking to broader semantic analysis methods.",
        "novelty_score": 0.6,
        "connectivity_score": 0.75,
        "specificity_score": 0.82,
        "link_intent_score": 0.7
      },
      {
        "surface": "syntactic parsing",
        "canonical": "Syntactic Parsing",
        "aliases": [
          "Syntax Parsing"
        ],
        "category": "specific_connectable",
        "rationale": "A key component of the feature integration approach, connecting to foundational NLP techniques.",
        "novelty_score": 0.5,
        "connectivity_score": 0.78,
        "specificity_score": 0.8,
        "link_intent_score": 0.72
      },
      {
        "surface": "statistical probability features",
        "canonical": "Statistical Probability Features",
        "aliases": [
          "Statistical Features"
        ],
        "category": "specific_connectable",
        "rationale": "Essential for understanding the statistical aspect of the feature integration, linking to statistical methods in AI.",
        "novelty_score": 0.55,
        "connectivity_score": 0.7,
        "specificity_score": 0.75,
        "link_intent_score": 0.68
      }
    ],
    "ban_list_suggestions": [
      "AI text detection",
      "performance gains",
      "computational costs"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Model",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.8,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Multi-Hierarchical Feature Detection",
      "resolved_canonical": "Multi-Hierarchical Feature Detection",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.88,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "DeBERTa-based semantic analysis",
      "resolved_canonical": "DeBERTa-based Semantic Analysis",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.75,
        "specificity": 0.82,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "syntactic parsing",
      "resolved_canonical": "Syntactic Parsing",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.78,
        "specificity": 0.8,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "statistical probability features",
      "resolved_canonical": "Statistical Probability Features",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.7,
        "specificity": 0.75,
        "link_intent": 0.68
      }
    }
  ]
}
-->

# Multi-Hierarchical Feature Detection for Large Language Model Generated Text

## 📋 메타데이터

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18862.pdf)
**Category**: cs.CL
**Published**: 2025-09-24
**ArXiv ID**: [2509.18862](https://arxiv.org/abs/2509.18862)

## 🔗 유사한 논문
- [[2025-09-19/DetectAnyLLM_ Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models_20250919|DetectAnyLLM: Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models]] (86.2% similar)
- [[2025-09-22/DNA-DetectLLM_ Unveiling AI-Generated Text via a DNA-Inspired Mutation-Repair Paradigm_20250922|DNA-DetectLLM: Unveiling AI-Generated Text via a DNA-Inspired Mutation-Repair Paradigm]] (84.4% similar)
- [[2025-09-23/Retrieval Enhanced Feedback via In-context Neural Error-book_20250923|Retrieval Enhanced Feedback via In-context Neural Error-book]] (83.9% similar)
- [[2025-09-22/Can Large Language Models Infer Causal Relationships from Real-World Text?_20250922|Can Large Language Models Infer Causal Relationships from Real-World Text?]] (83.9% similar)
- [[2025-09-22/Real, Fake, or Manipulated? Detecting Machine-Influenced Text_20250922|Real, Fake, or Manipulated? Detecting Machine-Influenced Text]] (83.8% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/DeBERTa-based Semantic Analysis|DeBERTa-based Semantic Analysis]], [[keywords/Syntactic Parsing|Syntactic Parsing]], [[keywords/Statistical Probability Features|Statistical Probability Features]]
**⚡ Unique Technical**: [[keywords/Multi-Hierarchical Feature Detection|Multi-Hierarchical Feature Detection]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.18862v1 Announce Type: new 
Abstract: With the rapid advancement of large language model technology, there is growing interest in whether multi-feature approaches can significantly improve AI text detection beyond what single neural models achieve. While intuition suggests that combining semantic, syntactic, and statistical features should provide complementary signals, this assumption has not been rigorously tested with modern LLM-generated text. This paper provides a systematic empirical investigation of multi-hierarchical feature integration for AI text detection, specifically testing whether the computational overhead of combining multiple feature types is justified by performance gains. We implement MHFD (Multi-Hierarchical Feature Detection), integrating DeBERTa-based semantic analysis, syntactic parsing, and statistical probability features through adaptive fusion. Our investigation reveals important negative results: despite theoretical expectations, multi-feature integration provides minimal benefits (0.4-0.5% improvement) while incurring substantial computational costs (4.2x overhead), suggesting that modern neural language models may already capture most relevant detection signals efficiently. Experimental results on multiple benchmark datasets demonstrate that the MHFD method achieves 89.7% accuracy in in-domain detection and maintains 84.2% stable performance in cross-domain detection, showing modest improvements of 0.4-2.6% over existing methods.

## 📝 요약

이 논문은 대형 언어 모델 기술의 발전에 따라 AI 텍스트 감지에서 다중 특징 접근법이 단일 신경망 모델을 넘어서는 성능 향상을 가져올 수 있는지를 조사합니다. 연구에서는 DeBERTa 기반의 의미 분석, 구문 분석, 통계적 확률 특징을 통합한 MHFD(Multi-Hierarchical Feature Detection) 방법을 구현했습니다. 실험 결과, 다중 특징 통합이 이론적 기대와 달리 성능 향상에 미미한 기여(0.4-0.5% 개선)를 하며, 상당한 계산 비용(4.2배 증가)을 초래한다는 중요한 부정적 결과를 발견했습니다. 이는 현대 신경 언어 모델이 이미 대부분의 관련 감지 신호를 효율적으로 포착하고 있음을 시사합니다. MHFD 방법은 여러 벤치마크 데이터셋에서 89.7%의 정확도를 기록하고, 교차 도메인 감지에서 84.2%의 안정적인 성능을 유지하며 기존 방법 대비 0.4-2.6%의 소폭 향상을 보였습니다.

## 🎯 주요 포인트

- 1. 대형 언어 모델 기술의 발전으로 다중 특징 접근법이 AI 텍스트 탐지 성능을 향상시킬 수 있는지에 대한 관심이 증가하고 있습니다.
- 2. 본 연구는 현대 LLM 생성 텍스트에 대해 다중 계층적 특징 통합의 효과를 체계적으로 조사하였습니다.
- 3. MHFD 방법은 다양한 특징을 통합하여 89.7%의 인도메인 탐지 정확도와 84.2%의 크로스도메인 탐지 성능을 달성했습니다.
- 4. 다중 특징 통합은 이론적 기대와 달리 성능 향상이 미미하며(0.4-0.5% 개선), 상당한 계산 비용(4.2배 증가)을 초래합니다.
- 5. 현대 신경 언어 모델은 이미 대부분의 관련 탐지 신호를 효과적으로 포착하고 있을 가능성이 있습니다.


---

*Generated on 2025-09-24 15:43:13*