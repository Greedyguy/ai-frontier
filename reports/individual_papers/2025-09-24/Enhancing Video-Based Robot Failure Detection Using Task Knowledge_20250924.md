<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T16:34:25.195592",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Video-Based Failure Detection",
    "Spatio-Temporal Knowledge",
    "Task-Relevant Objects",
    "Data Augmentation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Video-Based Failure Detection": 0.78,
    "Spatio-Temporal Knowledge": 0.8,
    "Task-Relevant Objects": 0.75,
    "Data Augmentation": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "video-based failure detection",
        "canonical": "Video-Based Failure Detection",
        "aliases": [
          "video failure detection",
          "video-based detection"
        ],
        "category": "unique_technical",
        "rationale": "This concept is central to the paper's contribution and is specific to the domain of robotics.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "spatio-temporal knowledge",
        "canonical": "Spatio-Temporal Knowledge",
        "aliases": [
          "spatio-temporal information",
          "spatial and temporal knowledge"
        ],
        "category": "specific_connectable",
        "rationale": "This concept is crucial for understanding the method's application in robotics and links to broader topics in AI.",
        "novelty_score": 0.68,
        "connectivity_score": 0.82,
        "specificity_score": 0.77,
        "link_intent_score": 0.8
      },
      {
        "surface": "task-relevant objects",
        "canonical": "Task-Relevant Objects",
        "aliases": [
          "task objects",
          "relevant objects"
        ],
        "category": "specific_connectable",
        "rationale": "Understanding task-relevant objects is essential for contextualizing the robot's actions, linking to object recognition.",
        "novelty_score": 0.64,
        "connectivity_score": 0.79,
        "specificity_score": 0.72,
        "link_intent_score": 0.75
      },
      {
        "surface": "data augmentation method",
        "canonical": "Data Augmentation",
        "aliases": [
          "augmentation method",
          "data augmentation technique"
        ],
        "category": "broad_technical",
        "rationale": "Data augmentation is a widely applicable technique in machine learning, enhancing model performance.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.6,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "execution failures",
      "safe operation modes",
      "recovery strategies",
      "task replanning"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "video-based failure detection",
      "resolved_canonical": "Video-Based Failure Detection",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "spatio-temporal knowledge",
      "resolved_canonical": "Spatio-Temporal Knowledge",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.82,
        "specificity": 0.77,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "task-relevant objects",
      "resolved_canonical": "Task-Relevant Objects",
      "decision": "linked",
      "scores": {
        "novelty": 0.64,
        "connectivity": 0.79,
        "specificity": 0.72,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "data augmentation method",
      "resolved_canonical": "Data Augmentation",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.6,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# Enhancing Video-Based Robot Failure Detection Using Task Knowledge

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2508.18705.pdf)
**Category**: cs.CV
**Published**: 2025-09-24
**ArXiv ID**: [2508.18705](https://arxiv.org/abs/2508.18705)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/KRAST_ Knowledge-Augmented Robotic Action Recognition with Structured Text for Vision-Language Models_20250923|KRAST: Knowledge-Augmented Robotic Action Recognition with Structured Text for Vision-Language Models]] (84.0% similar)
- [[2025-09-23/Look, Focus, Act_ Efficient and Robust Robot Learning via Human Gaze and Foveated Vision Transformers_20250923|Look, Focus, Act: Efficient and Robust Robot Learning via Human Gaze and Foveated Vision Transformers]] (82.2% similar)
- [[2025-09-23/Sight Over Site_ Perception-Aware Reinforcement Learning for Efficient Robotic Inspection_20250923|Sight Over Site: Perception-Aware Reinforcement Learning for Efficient Robotic Inspection]] (81.7% similar)
- [[2025-09-19/Learning Discrete Abstractions for Visual Rearrangement Tasks Using Vision-Guided Graph Coloring_20250919|Learning Discrete Abstractions for Visual Rearrangement Tasks Using Vision-Guided Graph Coloring]] (81.6% similar)
- [[2025-09-22/Data-Efficient Learning for Generalizable Surgical Video Understanding_20250922|Data-Efficient Learning for Generalizable Surgical Video Understanding]] (81.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Data Augmentation|Data Augmentation]]
**ğŸ”— Specific Connectable**: [[keywords/Spatio-Temporal Knowledge|Spatio-Temporal Knowledge]], [[keywords/Task-Relevant Objects|Task-Relevant Objects]]
**âš¡ Unique Technical**: [[keywords/Video-Based Failure Detection|Video-Based Failure Detection]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2508.18705v2 Announce Type: replace-cross 
Abstract: Robust robotic task execution hinges on the reliable detection of execution failures in order to trigger safe operation modes, recovery strategies, or task replanning. However, many failure detection methods struggle to provide meaningful performance when applied to a variety of real-world scenarios. In this paper, we propose a video-based failure detection approach that uses spatio-temporal knowledge in the form of the actions the robot performs and task-relevant objects within the field of view. Both pieces of information are available in most robotic scenarios and can thus be readily obtained. We demonstrate the effectiveness of our approach on three datasets that we amend, in part, with additional annotations of the aforementioned task-relevant knowledge. In light of the results, we also propose a data augmentation method that improves performance by applying variable frame rates to different parts of the video. We observe an improvement from 77.9 to 80.0 in F1 score on the ARMBench dataset without additional computational expense and an additional increase to 81.4 with test-time augmentation. The results emphasize the importance of spatio-temporal information during failure detection and suggest further investigation of suitable heuristics in future implementations. Code and annotations are available.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë¡œë´‡ ì‘ì—… ìˆ˜í–‰ ì¤‘ ë°œìƒí•  ìˆ˜ ìˆëŠ” ì‹¤íŒ¨ë¥¼ ê°ì§€í•˜ëŠ” ë¹„ë””ì˜¤ ê¸°ë°˜ ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ë¡œë´‡ì˜ í–‰ë™ê³¼ ì‘ì—… ê´€ë ¨ ê°ì²´ì— ëŒ€í•œ ì‹œê³µê°„ì  ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ ë‹¤ì–‘í•œ ì‹¤ì œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œì˜ ì‹¤íŒ¨ ê°ì§€ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì„¸ ê°€ì§€ ë°ì´í„°ì…‹ì—ì„œì˜ ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì€ F1 ì ìˆ˜ë¥¼ 77.9ì—ì„œ 80.0ìœ¼ë¡œ, í…ŒìŠ¤íŠ¸ ì‹œ ë°ì´í„° ì¦ê°•ì„ í†µí•´ 81.4ê¹Œì§€ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ì‹¤íŒ¨ ê°ì§€ì—ì„œ ì‹œê³µê°„ ì •ë³´ì˜ ì¤‘ìš”ì„±ì„ ê°•ì¡°í•˜ë©°, í–¥í›„ ì ì ˆí•œ íœ´ë¦¬ìŠ¤í‹± íƒìƒ‰ì˜ í•„ìš”ì„±ì„ ì œì‹œí•©ë‹ˆë‹¤. ì½”ë“œì™€ ì£¼ì„ì€ ê³µê°œë˜ì–´ ìˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë¡œë´‡ ì‘ì—… ì‹¤í–‰ì˜ ì‹¤íŒ¨ ê°ì§€ëŠ” ì•ˆì „í•œ ì‘ë™ ëª¨ë“œ, ë³µêµ¬ ì „ëµ, ë˜ëŠ” ì‘ì—… ì¬ê³„íšì„ ìœ ë„í•˜ëŠ” ë° ì¤‘ìš”í•©ë‹ˆë‹¤.
- 2. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ë¡œë´‡ì˜ í–‰ë™ê³¼ ì‘ì—… ê´€ë ¨ ê°ì²´ì˜ ì‹œê³µê°„ì  ì •ë³´ë¥¼ í™œìš©í•œ ë¹„ë””ì˜¤ ê¸°ë°˜ ì‹¤íŒ¨ ê°ì§€ ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤.
- 3. ì œì•ˆëœ ë°©ë²•ì€ ì„¸ ê°€ì§€ ë°ì´í„°ì…‹ì—ì„œ íš¨ê³¼ì ì„ì„ ì…ì¦í•˜ì˜€ìœ¼ë©°, ë°ì´í„° ì¦ê°• ë°©ë²•ì„ í†µí•´ ì„±ëŠ¥ì„ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.
- 4. ARMBench ë°ì´í„°ì…‹ì—ì„œ F1 ì ìˆ˜ê°€ 77.9ì—ì„œ 80.0ìœ¼ë¡œ ê°œì„ ë˜ì—ˆìœ¼ë©°, í…ŒìŠ¤íŠ¸ ì‹œ ì¦ê°•ì„ í†µí•´ 81.4ê¹Œì§€ ì¦ê°€í–ˆìŠµë‹ˆë‹¤.
- 5. ì—°êµ¬ ê²°ê³¼ëŠ” ì‹¤íŒ¨ ê°ì§€ ì‹œ ì‹œê³µê°„ ì •ë³´ì˜ ì¤‘ìš”ì„±ì„ ê°•ì¡°í•˜ë©°, í–¥í›„ êµ¬í˜„ì—ì„œ ì ì ˆí•œ íœ´ë¦¬ìŠ¤í‹±ì˜ ì¶”ê°€ ì—°êµ¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 16:34:25*