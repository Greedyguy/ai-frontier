<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T14:00:55.614799",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Bisimulation Metric",
    "Markov Decision Process",
    "Policy Transfer",
    "State Aggregation",
    "Sample Complexity"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Bisimulation Metric": 0.78,
    "Markov Decision Process": 0.8,
    "Policy Transfer": 0.77,
    "State Aggregation": 0.75,
    "Sample Complexity": 0.74
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "bisimulation metric",
        "canonical": "Bisimulation Metric",
        "aliases": [
          "BSM"
        ],
        "category": "unique_technical",
        "rationale": "Bisimulation Metric is central to the paper's theoretical contributions and connects to existing work in reinforcement learning.",
        "novelty_score": 0.65,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Markov decision process",
        "canonical": "Markov Decision Process",
        "aliases": [
          "MDP"
        ],
        "category": "broad_technical",
        "rationale": "Markov Decision Process is a foundational concept in reinforcement learning and essential for understanding the paper's context.",
        "novelty_score": 0.4,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "policy transfer",
        "canonical": "Policy Transfer",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Policy Transfer is a specific application of the generalized bisimulation metric, relevant for linking to transfer learning discussions.",
        "novelty_score": 0.55,
        "connectivity_score": 0.78,
        "specificity_score": 0.72,
        "link_intent_score": 0.77
      },
      {
        "surface": "state aggregation",
        "canonical": "State Aggregation",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "State Aggregation is a key concept in the paper that benefits from the generalized bisimulation metric, enhancing connectivity to related topics.",
        "novelty_score": 0.58,
        "connectivity_score": 0.76,
        "specificity_score": 0.73,
        "link_intent_score": 0.75
      },
      {
        "surface": "sample complexity",
        "canonical": "Sample Complexity",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Sample Complexity is crucial for understanding the efficiency of the proposed metric in estimation tasks.",
        "novelty_score": 0.5,
        "connectivity_score": 0.79,
        "specificity_score": 0.71,
        "link_intent_score": 0.74
      }
    ],
    "ban_list_suggestions": [
      "optimal value functions",
      "numerical results"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "bisimulation metric",
      "resolved_canonical": "Bisimulation Metric",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Markov decision process",
      "resolved_canonical": "Markov Decision Process",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "policy transfer",
      "resolved_canonical": "Policy Transfer",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.78,
        "specificity": 0.72,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "state aggregation",
      "resolved_canonical": "State Aggregation",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.76,
        "specificity": 0.73,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "sample complexity",
      "resolved_canonical": "Sample Complexity",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.79,
        "specificity": 0.71,
        "link_intent": 0.74
      }
    }
  ]
}
-->

# A Generalized Bisimulation Metric of State Similarity between Markov Decision Processes: From Theoretical Propositions to Applications

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18714.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2509.18714](https://arxiv.org/abs/2509.18714)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Revisiting Bisimulation Metric for Robust Representations in Reinforcement Learning_20250923|Revisiting Bisimulation Metric for Robust Representations in Reinforcement Learning]] (86.2% similar)
- [[2025-09-23/Near-Optimal Sample Complexity Bounds for Constrained Average-Reward MDPs_20250923|Near-Optimal Sample Complexity Bounds for Constrained Average-Reward MDPs]] (81.0% similar)
- [[2025-09-22/Policy Gradient Optimzation for Bayesian-Risk MDPs with General Convex Losses_20250922|Policy Gradient Optimzation for Bayesian-Risk MDPs with General Convex Losses]] (80.8% similar)
- [[2025-09-22/Gaussian process policy iteration with additive Schwarz acceleration for forward and inverse HJB and mean field game problems_20250922|Gaussian process policy iteration with additive Schwarz acceleration for forward and inverse HJB and mean field game problems]] (80.5% similar)
- [[2025-09-18/Bellman Optimality of Average-Reward Robust Markov Decision Processes with a Constant Gain_20250918|Bellman Optimality of Average-Reward Robust Markov Decision Processes with a Constant Gain]] (80.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Markov Decision Process|Markov Decision Process]]
**ğŸ”— Specific Connectable**: [[keywords/Policy Transfer|Policy Transfer]], [[keywords/State Aggregation|State Aggregation]], [[keywords/Sample Complexity|Sample Complexity]]
**âš¡ Unique Technical**: [[keywords/Bisimulation Metric|Bisimulation Metric]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18714v1 Announce Type: cross 
Abstract: The bisimulation metric (BSM) is a powerful tool for computing state similarities within a Markov decision process (MDP), revealing that states closer in BSM have more similar optimal value functions. While BSM has been successfully utilized in reinforcement learning (RL) for tasks like state representation learning and policy exploration, its application to multiple-MDP scenarios, such as policy transfer, remains challenging. Prior work has attempted to generalize BSM to pairs of MDPs, but a lack of rigorous analysis of its mathematical properties has limited further theoretical progress. In this work, we formally establish a generalized bisimulation metric (GBSM) between pairs of MDPs, which is rigorously proven with the three fundamental properties: GBSM symmetry, inter-MDP triangle inequality, and the distance bound on identical state spaces. Leveraging these properties, we theoretically analyse policy transfer, state aggregation, and sampling-based estimation in MDPs, obtaining explicit bounds that are strictly tighter than those derived from the standard BSM. Additionally, GBSM provides a closed-form sample complexity for estimation, improving upon existing asymptotic results based on BSM. Numerical results validate our theoretical findings and demonstrate the effectiveness of GBSM in multi-MDP scenarios.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë§ˆë¥´ì½”í”„ ê²°ì • ê³¼ì •(MDP) ë‚´ ìƒíƒœ ìœ ì‚¬ì„±ì„ ì¸¡ì •í•˜ëŠ” ê°•ë ¥í•œ ë„êµ¬ì¸ ë¹„ì‹œë®¬ë ˆì´ì…˜ ë©”íŠ¸ë¦­(BSM)ì„ ë‹¤ì¤‘ MDP ì‹œë‚˜ë¦¬ì˜¤ì— ì ìš©í•˜ê¸° ìœ„í•œ ì¼ë°˜í™”ëœ ë¹„ì‹œë®¬ë ˆì´ì…˜ ë©”íŠ¸ë¦­(GBSM)ì„ ì œì•ˆí•©ë‹ˆë‹¤. GBSMì€ MDP ìŒ ê°„ì˜ ëŒ€ì¹­ì„±, ì‚¼ê° ë¶€ë“±ì‹, ë™ì¼ ìƒíƒœ ê³µê°„ì—ì„œì˜ ê±°ë¦¬ ì œí•œì´ë¼ëŠ” ì„¸ ê°€ì§€ ê¸°ë³¸ ì†ì„±ì„ ì—„ë°€íˆ ì¦ëª…í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì •ì±… ì „ì´, ìƒíƒœ ì§‘ê³„, ìƒ˜í”Œë§ ê¸°ë°˜ ì¶”ì •ì— ëŒ€í•œ ì´ë¡ ì  ë¶„ì„ì„ ìˆ˜í–‰í•˜ë©°, ê¸°ì¡´ BSMë³´ë‹¤ ë” ì—„ê²©í•œ ê²½ê³„ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ë˜í•œ, GBSMì€ ìƒ˜í”Œ ë³µì¡ì„±ì˜ ëª…í™•í•œ í˜•íƒœë¥¼ ì œê³µí•˜ì—¬ ê¸°ì¡´ì˜ BSM ê¸°ë°˜ ê²°ê³¼ë¥¼ ê°œì„ í•©ë‹ˆë‹¤. ìˆ˜ì¹˜ ê²°ê³¼ëŠ” ì´ë¡ ì  ë°œê²¬ì„ ë’·ë°›ì¹¨í•˜ë©°, ë‹¤ì¤‘ MDP ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ GBSMì˜ íš¨ê³¼ë¥¼ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì¼ë°˜í™”ëœ ë¹„ì‹œë®¬ë ˆì´ì…˜ ë©”íŠ¸ë¦­(GBSM)ì„ í†µí•´ MDP ìŒ ê°„ì˜ ìƒíƒœ ìœ ì‚¬ì„±ì„ ì •ëŸ‰í™”í•˜ê³ , GBSMì˜ ëŒ€ì¹­ì„±, ì‚¼ê° ë¶€ë“±ì‹, ë™ì¼ ìƒíƒœ ê³µê°„ì—ì„œì˜ ê±°ë¦¬ ì œí•œì„ ì¦ëª…í–ˆìŠµë‹ˆë‹¤.
- 2. GBSMì„ í™œìš©í•˜ì—¬ ì •ì±… ì „ì´, ìƒíƒœ ì§‘ê³„, ìƒ˜í”Œë§ ê¸°ë°˜ ì¶”ì •ì„ ì´ë¡ ì ìœ¼ë¡œ ë¶„ì„í•˜ê³ , ê¸°ì¡´ BSMë³´ë‹¤ ë” ì—„ê²©í•œ ëª…ì‹œì  ê²½ê³„ë¥¼ ë„ì¶œí–ˆìŠµë‹ˆë‹¤.
- 3. GBSMì€ ìƒ˜í”Œ ë³µì¡ì„±ì˜ íì‡„í˜• í•´ë¥¼ ì œê³µí•˜ì—¬ ê¸°ì¡´ BSM ê¸°ë°˜ì˜ ì ê·¼ì  ê²°ê³¼ë¥¼ ê°œì„ í–ˆìŠµë‹ˆë‹¤.
- 4. ìˆ˜ì¹˜ì  ê²°ê³¼ëŠ” GBSMì˜ ì´ë¡ ì  ë°œê²¬ì„ ê²€ì¦í•˜ê³ , ë‹¤ì¤‘ MDP ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ GBSMì˜ íš¨ê³¼ì„±ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 14:00:55*