<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T13:47:54.513615",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "AI Risk Management",
    "Large Language Model",
    "FAIR Model",
    "Data Protection",
    "Information Security"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "AI Risk Management": 0.85,
    "Large Language Model": 0.7,
    "FAIR Model": 0.8,
    "Data Protection": 0.75,
    "Information Security": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "artificial intelligence risk management",
        "canonical": "AI Risk Management",
        "aliases": [
          "AI Risk",
          "AI Risk Handling"
        ],
        "category": "unique_technical",
        "rationale": "This term is central to the paper and connects various aspects of AI risk, providing a comprehensive view on managing AI-related uncertainties.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.85
      },
      {
        "surface": "large language models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "Large language models are a key component in AI systems, relevant for understanding AI risk in context.",
        "novelty_score": 0.4,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.7
      },
      {
        "surface": "FAIR model",
        "canonical": "FAIR Model",
        "aliases": [
          "FAIR Framework"
        ],
        "category": "specific_connectable",
        "rationale": "The FAIR model is crucial for quantifying uncertainty in AI risk management, linking to broader risk management strategies.",
        "novelty_score": 0.6,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "data protection",
        "canonical": "Data Protection",
        "aliases": [
          "Data Privacy"
        ],
        "category": "specific_connectable",
        "rationale": "Data protection is a critical dimension of AI risk, connecting legal and technical aspects of AI systems.",
        "novelty_score": 0.5,
        "connectivity_score": 0.8,
        "specificity_score": 0.65,
        "link_intent_score": 0.75
      },
      {
        "surface": "information security",
        "canonical": "Information Security",
        "aliases": [
          "InfoSec"
        ],
        "category": "specific_connectable",
        "rationale": "Information security is essential for managing AI risks, linking to both operational and technical risk dimensions.",
        "novelty_score": 0.5,
        "connectivity_score": 0.78,
        "specificity_score": 0.7,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "metrics",
      "models",
      "decision-making"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "artificial intelligence risk management",
      "resolved_canonical": "AI Risk Management",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "large language models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "FAIR model",
      "resolved_canonical": "FAIR Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "data protection",
      "resolved_canonical": "Data Protection",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.8,
        "specificity": 0.65,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "information security",
      "resolved_canonical": "Information Security",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.78,
        "specificity": 0.7,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# An Artificial Intelligence Value at Risk Approach: Metrics and Models

## 📋 메타데이터

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18394.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2509.18394](https://arxiv.org/abs/2509.18394)

## 🔗 유사한 논문
- [[2025-09-22/Who is Responsible When AI Fails? Mapping Causes, Entities, and Consequences of AI Privacy and Ethical Incidents_20250922|Who is Responsible When AI Fails? Mapping Causes, Entities, and Consequences of AI Privacy and Ethical Incidents]] (86.0% similar)
- [[2025-09-18/Position_ AI Safety Must Embrace an Antifragile Perspective_20250918|Position: AI Safety Must Embrace an Antifragile Perspective]] (84.3% similar)
- [[2025-09-22/Algorithmic Fairness_ Not a Purely Technical but Socio-Technical Property_20250922|Algorithmic Fairness: Not a Purely Technical but Socio-Technical Property]] (83.8% similar)
- [[2025-09-23/Towards a Transparent and Interpretable AI Model for Medical Image Classifications_20250923|Towards a Transparent and Interpretable AI Model for Medical Image Classifications]] (83.2% similar)
- [[2025-09-24/Perceptions of AI Across Sectors_ A Comparative Review of Public Attitudes_20250924|Perceptions of AI Across Sectors: A Comparative Review of Public Attitudes]] (82.9% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/FAIR Model|FAIR Model]], [[keywords/Data Protection|Data Protection]], [[keywords/Information Security|Information Security]]
**⚡ Unique Technical**: [[keywords/AI Risk Management|AI Risk Management]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.18394v1 Announce Type: cross 
Abstract: Artificial intelligence risks are multidimensional in nature, as the same risk scenarios may have legal, operational, and financial risk dimensions. With the emergence of new AI regulations, the state of the art of artificial intelligence risk management seems to be highly immature due to upcoming AI regulations. Despite the appearance of several methodologies and generic criteria, it is rare to find guidelines with real implementation value, considering that the most important issue is customizing artificial intelligence risk metrics and risk models for specific AI risk scenarios. Furthermore, the financial departments, legal departments and Government Risk Compliance teams seem to remain unaware of many technical aspects of AI systems, in which data scientists and AI engineers emerge as the most appropriate implementers. It is crucial to decompose the problem of artificial intelligence risk in several dimensions: data protection, fairness, accuracy, robustness, and information security. Consequently, the main task is developing adequate metrics and risk models that manage to reduce uncertainty for decision-making in order to take informed decisions concerning the risk management of AI systems.
  The purpose of this paper is to orientate AI stakeholders about the depths of AI risk management. Although it is not extremely technical, it requires a basic knowledge of risk management, quantifying uncertainty, the FAIR model, machine learning, large language models and AI context engineering. The examples presented pretend to be very basic and understandable, providing simple ideas that can be developed regarding specific AI customized environments. There are many issues to solve in AI risk management, and this paper will present a holistic overview of the inter-dependencies of AI risks, and how to model them together, within risk scenarios.

## 📝 요약

이 논문은 인공지능(AI) 위험 관리의 복잡성과 다차원성을 다룹니다. AI 위험은 법적, 운영적, 재정적 측면을 포함하며, 새로운 AI 규제의 등장으로 인해 현재의 위험 관리 수준은 미성숙한 상태입니다. 논문은 AI 위험 시나리오에 맞춘 맞춤형 위험 지표와 모델 개발의 중요성을 강조하며, 데이터 보호, 공정성, 정확성, 견고성, 정보 보안 등 여러 차원에서 AI 위험을 분해할 필요성을 제시합니다. 또한, 재무, 법무 부서 및 정부 위험 관리 팀이 AI 시스템의 기술적 측면에 대한 이해가 부족하다고 지적하며, 데이터 과학자와 AI 엔지니어가 적합한 구현자로 부상하고 있음을 언급합니다. 논문은 AI 이해관계자들에게 위험 관리의 깊이를 안내하고, 기본적인 위험 관리 지식과 AI 맥락 엔지니어링에 대한 이해를 요구합니다. 다양한 AI 맞춤 환경에서 적용 가능한 간단한 아이디어를 제공하며, AI 위험의 상호 의존성을 전체적으로 조망합니다.

## 🎯 주요 포인트

- 1. 인공지능 위험은 법적, 운영적, 재정적 측면을 포함한 다차원적인 특성을 지니고 있다.
- 2. 새로운 AI 규제로 인해 인공지능 위험 관리의 성숙도가 낮으며, 특정 AI 위험 시나리오에 맞춘 맞춤형 위험 지표와 모델이 필요하다.
- 3. 데이터 보호, 공정성, 정확성, 강건성, 정보 보안 등 여러 차원으로 인공지능 위험 문제를 분해하는 것이 중요하다.
- 4. AI 시스템의 위험 관리를 위해 적절한 지표와 위험 모델을 개발하여 의사결정의 불확실성을 줄이는 것이 주요 과제이다.
- 5. 이 논문은 AI 이해관계자들에게 AI 위험 관리의 깊이를 안내하고, AI 위험의 상호 의존성을 전체적으로 조망한다.


---

*Generated on 2025-09-24 13:47:54*