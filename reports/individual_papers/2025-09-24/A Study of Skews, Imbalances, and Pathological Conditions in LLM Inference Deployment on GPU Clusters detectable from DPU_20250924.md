<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T14:45:01.963952",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "DPU-assisted Framework",
    "Tensor-parallel Inference",
    "Load Imbalance"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "DPU-assisted Framework": 0.7,
    "Tensor-parallel Inference": 0.82,
    "Load Imbalance": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Large Transformer-based Language Models"
        ],
        "category": "broad_technical",
        "rationale": "Connects to the broader field of language model research and applications.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "DPU-assisted framework",
        "canonical": "DPU-assisted Framework",
        "aliases": [
          "Data Processing Unit Framework"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel approach for leveraging DPUs in inference tasks, which is specific to this study.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      },
      {
        "surface": "Tensor-parallel inference",
        "canonical": "Tensor-parallel Inference",
        "aliases": [
          "Multi-node Tensor Inference"
        ],
        "category": "specific_connectable",
        "rationale": "Highlights a specific inference strategy relevant to distributed computing environments.",
        "novelty_score": 0.55,
        "connectivity_score": 0.78,
        "specificity_score": 0.72,
        "link_intent_score": 0.82
      },
      {
        "surface": "Load imbalance",
        "canonical": "Load Imbalance",
        "aliases": [
          "Load Skew",
          "Imbalance"
        ],
        "category": "specific_connectable",
        "rationale": "Key issue in distributed computing that affects performance, relevant for optimization studies.",
        "novelty_score": 0.4,
        "connectivity_score": 0.85,
        "specificity_score": 0.65,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "runtime efficiency",
      "throughput degradation",
      "latency spikes"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "DPU-assisted framework",
      "resolved_canonical": "DPU-assisted Framework",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Tensor-parallel inference",
      "resolved_canonical": "Tensor-parallel Inference",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.78,
        "specificity": 0.72,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Load imbalance",
      "resolved_canonical": "Load Imbalance",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.85,
        "specificity": 0.65,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# A Study of Skews, Imbalances, and Pathological Conditions in LLM Inference Deployment on GPU Clusters detectable from DPU

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18114.pdf)
**Category**: cs.LG
**Published**: 2025-09-24
**ArXiv ID**: [2509.18114](https://arxiv.org/abs/2509.18114)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Characterizing the Efficiency of Distributed Training_ A Power, Performance, and Thermal Perspective_20250922|Characterizing the Efficiency of Distributed Training: A Power, Performance, and Thermal Perspective]] (85.4% similar)
- [[2025-09-24/Intra-DP_ A High Performance Collaborative Inference System for Mobile Edge Computing_20250924|Intra-DP: A High Performance Collaborative Inference System for Mobile Edge Computing]] (83.8% similar)
- [[2025-09-23/PDTrim_ Targeted Pruning for Prefill-Decode Disaggregation in Inference_20250923|PDTrim: Targeted Pruning for Prefill-Decode Disaggregation in Inference]] (83.3% similar)
- [[2025-09-23/Robust LLM Training Infrastructure at ByteDance_20250923|Robust LLM Training Infrastructure at ByteDance]] (83.0% similar)
- [[2025-09-23/70% Size, 100% Accuracy_ Lossless LLM Compression for Efficient GPU Inference via Dynamic-Length Float_20250923|70% Size, 100% Accuracy: Lossless LLM Compression for Efficient GPU Inference via Dynamic-Length Float]] (82.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Tensor-parallel Inference|Tensor-parallel Inference]], [[keywords/Load Imbalance|Load Imbalance]]
**âš¡ Unique Technical**: [[keywords/DPU-assisted Framework|DPU-assisted Framework]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18114v1 Announce Type: new 
Abstract: Autoregressive inference in large transformer-based language models (LLMs) presents significant challenges for runtime efficiency, particularly during the decode phase where load imbalance across GPU shards can cause throughput degradation and latency spikes. A DPU-assisted framework leveraged by BlueField-3 Data Processing Units can enable real-time detection and mitigation of load imbalance in multi-node tensor-parallel inference. By offloading monitoring tasks to the DPU and analyzing GPU telemetry and inter-node communication patterns, the resulting system can provide actionable feedback to inference controllers and schedulers. The goal of this study is three-fold i) identify the reported skews/imbalances/pathological conditions that arise in muti-GPU execution of a) LLM tensor computing (both during training and inference), b) identify their impact on computational performance, and c) make a critical assessment if those can be tracked for potential mitigation from a DPU network.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€ê·œëª¨ íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ ì–¸ì–´ ëª¨ë¸(LLM)ì—ì„œì˜ ì˜¤í† ë¦¬ê·¸ë ˆì‹œë¸Œ ì¶”ë¡  ì‹œ ë°œìƒí•˜ëŠ” GPU ê°„ ë¶€í•˜ ë¶ˆê· í˜• ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ DPU(ë°ì´í„° ì²˜ë¦¬ ì¥ì¹˜)ë¥¼ í™œìš©í•œ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. BlueField-3 DPUë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì‹œê°„ìœ¼ë¡œ ë¶€í•˜ ë¶ˆê· í˜•ì„ ê°ì§€í•˜ê³  ì™„í™”í•  ìˆ˜ ìˆìœ¼ë©°, GPU í…”ë ˆë©”íŠ¸ë¦¬ì™€ ë…¸ë“œ ê°„ í†µì‹  íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬ ì¶”ë¡  ì»¨íŠ¸ë¡¤ëŸ¬ì™€ ìŠ¤ì¼€ì¤„ëŸ¬ì— ìœ ìš©í•œ í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤. ì—°êµ¬ì˜ ì£¼ìš” ëª©í‘œëŠ” ë‹¤ì¤‘ GPU í™˜ê²½ì—ì„œ ë°œìƒí•˜ëŠ” ë¶ˆê· í˜• ë° ë³‘ë¦¬ì  ì¡°ê±´ì„ ì‹ë³„í•˜ê³ , ì´ë“¤ì´ ê³„ì‚° ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ í‰ê°€í•˜ë©°, DPU ë„¤íŠ¸ì›Œí¬ë¥¼ í†µí•´ ì´ëŸ¬í•œ ë¬¸ì œë¥¼ ì¶”ì í•˜ê³  ì™„í™”í•  ìˆ˜ ìˆëŠ”ì§€ë¥¼ ë¹„íŒì ìœ¼ë¡œ í‰ê°€í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€ê·œëª¨ íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ ì–¸ì–´ ëª¨ë¸ì—ì„œ ìíšŒê·€ ì¶”ë¡  ì‹œ GPU ìƒ¤ë“œ ê°„ ë¶€í•˜ ë¶ˆê· í˜•ì´ ì‹¤í–‰ íš¨ìœ¨ì„±ì— ì˜í–¥ì„ ë¯¸ì¹œë‹¤.
- 2. BlueField-3 ë°ì´í„° ì²˜ë¦¬ ì¥ì¹˜ë¥¼ í™œìš©í•œ DPU ì§€ì› í”„ë ˆì„ì›Œí¬ëŠ” ë©€í‹° ë…¸ë“œ í…ì„œ ë³‘ë ¬ ì¶”ë¡ ì—ì„œ ë¶€í•˜ ë¶ˆê· í˜•ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ê°ì§€í•˜ê³  ì™„í™”í•  ìˆ˜ ìˆë‹¤.
- 3. DPUì— ëª¨ë‹ˆí„°ë§ ì‘ì—…ì„ ì˜¤í”„ë¡œë“œí•˜ê³  GPU ì›ê²© ì¸¡ì • ë° ë…¸ë“œ ê°„ í†µì‹  íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬ ì¶”ë¡  ì œì–´ê¸°ì™€ ìŠ¤ì¼€ì¤„ëŸ¬ì— ì‹¤í–‰ ê°€ëŠ¥í•œ í”¼ë“œë°±ì„ ì œê³µí•  ìˆ˜ ìˆë‹¤.
- 4. ì—°êµ¬ì˜ ëª©í‘œëŠ” ë‹¤ì¤‘ GPU ì‹¤í–‰ì—ì„œ ë°œìƒí•˜ëŠ” ë¶ˆê· í˜• ë° ë³‘ë¦¬í•™ì  ì¡°ê±´ì„ ì‹ë³„í•˜ê³ , ì´ë“¤ì´ ê³„ì‚° ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ í‰ê°€í•˜ë©°, DPU ë„¤íŠ¸ì›Œí¬ë¥¼ í†µí•´ ì´ë¥¼ ì¶”ì í•˜ì—¬ ì™„í™”í•  ìˆ˜ ìˆëŠ”ì§€ ë¹„íŒì ìœ¼ë¡œ í‰ê°€í•˜ëŠ” ê²ƒì´ë‹¤.


---

*Generated on 2025-09-24 14:45:01*