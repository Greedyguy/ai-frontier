<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T16:34:00.221149",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "3D Human Pose Estimation",
    "Human Mesh Recovery",
    "LiDAR Point Clouds",
    "Evaluation Metrics"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "3D Human Pose Estimation": 0.8,
    "Human Mesh Recovery": 0.78,
    "LiDAR Point Clouds": 0.75,
    "Evaluation Metrics": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "3D human pose estimation",
        "canonical": "3D Human Pose Estimation",
        "aliases": [
          "3D pose estimation",
          "human pose estimation"
        ],
        "category": "unique_technical",
        "rationale": "This is a core technical term specific to the field of computer vision and LiDAR applications.",
        "novelty_score": 0.75,
        "connectivity_score": 0.78,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "human mesh recovery",
        "canonical": "Human Mesh Recovery",
        "aliases": [
          "mesh recovery",
          "3D mesh recovery"
        ],
        "category": "unique_technical",
        "rationale": "It represents a specific task in reconstructing human shapes from point clouds, crucial for linking related studies.",
        "novelty_score": 0.7,
        "connectivity_score": 0.72,
        "specificity_score": 0.82,
        "link_intent_score": 0.78
      },
      {
        "surface": "LiDAR point clouds",
        "canonical": "LiDAR Point Clouds",
        "aliases": [
          "LiDAR data",
          "point clouds"
        ],
        "category": "broad_technical",
        "rationale": "LiDAR point clouds are fundamental data types in 3D modeling and computer vision, connecting to a wide range of applications.",
        "novelty_score": 0.6,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.75
      },
      {
        "surface": "evaluation metrics",
        "canonical": "Evaluation Metrics",
        "aliases": [
          "metrics",
          "performance metrics"
        ],
        "category": "specific_connectable",
        "rationale": "Standardized metrics are essential for comparing methods, facilitating connections across different studies.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "method",
      "approach",
      "comparison"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "3D human pose estimation",
      "resolved_canonical": "3D Human Pose Estimation",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.78,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "human mesh recovery",
      "resolved_canonical": "Human Mesh Recovery",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.72,
        "specificity": 0.82,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "LiDAR point clouds",
      "resolved_canonical": "LiDAR Point Clouds",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "evaluation metrics",
      "resolved_canonical": "Evaluation Metrics",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# 3D Human Pose and Shape Estimation from LiDAR Point Clouds: A Review

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.12197.pdf)
**Category**: cs.CV
**Published**: 2025-09-24
**ArXiv ID**: [2509.12197](https://arxiv.org/abs/2509.12197)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/PoseBench3D_ A Cross-Dataset Analysis Framework for 3D Human Pose Estimation via Pose Lifting Networks_20250923|PoseBench3D: A Cross-Dataset Analysis Framework for 3D Human Pose Estimation via Pose Lifting Networks]] (86.4% similar)
- [[2025-09-24/RS3DBench_ A Comprehensive Benchmark for 3D Spatial Perception in Remote Sensing_20250924|RS3DBench: A Comprehensive Benchmark for 3D Spatial Perception in Remote Sensing]] (81.2% similar)
- [[2025-09-19/Semantic-LiDAR-Inertial-Wheel Odometry Fusion for Robust Localization in Large-Scale Dynamic Environments_20250919|Semantic-LiDAR-Inertial-Wheel Odometry Fusion for Robust Localization in Large-Scale Dynamic Environments]] (80.7% similar)
- [[2025-09-23/L2M-Reg_ Building-level Uncertainty-aware Registration of Outdoor LiDAR Point Clouds and Semantic 3D City Models_20250923|L2M-Reg: Building-level Uncertainty-aware Registration of Outdoor LiDAR Point Clouds and Semantic 3D City Models]] (80.4% similar)
- [[2025-09-24/Towards Robust LiDAR Localization_ Deep Learning-based Uncertainty Estimation_20250924|Towards Robust LiDAR Localization: Deep Learning-based Uncertainty Estimation]] (80.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/LiDAR Point Clouds|LiDAR Point Clouds]]
**ğŸ”— Specific Connectable**: [[keywords/Evaluation Metrics|Evaluation Metrics]]
**âš¡ Unique Technical**: [[keywords/3D Human Pose Estimation|3D Human Pose Estimation]], [[keywords/Human Mesh Recovery|Human Mesh Recovery]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.12197v2 Announce Type: replace 
Abstract: In this paper, we present a comprehensive review of 3D human pose estimation and human mesh recovery from in-the-wild LiDAR point clouds. We compare existing approaches across several key dimensions, and propose a structured taxonomy to classify these methods. Following this taxonomy, we analyze each method's strengths, limitations, and design choices. In addition, (i) we perform a quantitative comparison of the three most widely used datasets, detailing their characteristics; (ii) we compile unified definitions of all evaluation metrics; and (iii) we establish benchmark tables for both tasks on these datasets to enable fair comparisons and promote progress in the field. We also outline open challenges and research directions critical for advancing LiDAR-based 3D human understanding. Moreover, we maintain an accompanying webpage that organizes papers according to our taxonomy and continuously update it with new studies: https://github.com/valeoai/3D-Human-Pose-Shape-Estimation-from-LiDAR

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì•¼ì™¸ LiDAR í¬ì¸íŠ¸ í´ë¼ìš°ë“œì—ì„œ 3D ì¸ê°„ ìì„¸ ì¶”ì • ë° ì¸ê°„ ë©”ì‰¬ ë³µêµ¬ì— ëŒ€í•œ í¬ê´„ì ì¸ ë¦¬ë·°ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ê¸°ì¡´ ì ‘ê·¼ ë°©ì‹ì„ ì—¬ëŸ¬ ì°¨ì›ì—ì„œ ë¹„êµí•˜ê³ , ì´ë¥¼ ë¶„ë¥˜í•˜ê¸° ìœ„í•œ ì²´ê³„ì ì¸ ë¶„ë¥˜ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê° ë°©ë²•ì˜ ê°•ì ê³¼ í•œê³„, ì„¤ê³„ ì„ íƒì„ ë¶„ì„í•˜ë©°, ì„¸ ê°€ì§€ ì£¼ìš” ë°ì´í„°ì…‹ì˜ ì •ëŸ‰ì  ë¹„êµ, í‰ê°€ ì§€í‘œì˜ í†µì¼ëœ ì •ì˜, ë²¤ì¹˜ë§ˆí¬ í…Œì´ë¸”ì„ ì œì‹œí•˜ì—¬ ê³µì •í•œ ë¹„êµì™€ ì—°êµ¬ ë°œì „ì„ ë„ëª¨í•©ë‹ˆë‹¤. ë˜í•œ, LiDAR ê¸°ë°˜ 3D ì¸ê°„ ì´í•´ë¥¼ ìœ„í•œ ì—°êµ¬ ë°©í–¥ê³¼ ê³¼ì œë¥¼ ì œì‹œí•˜ê³ , ê´€ë ¨ ë…¼ë¬¸ì„ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•œ ì›¹í˜ì´ì§€ë¥¼ ìš´ì˜í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë³¸ ë…¼ë¬¸ì€ ì•¼ì™¸ LiDAR í¬ì¸íŠ¸ í´ë¼ìš°ë“œì—ì„œ 3D ì¸ê°„ ìì„¸ ì¶”ì • ë° ì¸ê°„ ë©”ì‰¬ ë³µêµ¬ì— ëŒ€í•œ í¬ê´„ì ì¸ ë¦¬ë·°ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
- 2. ê¸°ì¡´ ì ‘ê·¼ ë°©ì‹ì„ ì—¬ëŸ¬ ì£¼ìš” ì°¨ì›ì—ì„œ ë¹„êµí•˜ê³ , ì´ë¥¼ ë¶„ë¥˜í•˜ê¸° ìœ„í•œ ì²´ê³„ì ì¸ ë¶„ë¥˜ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤.
- 3. ì„¸ ê°€ì§€ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ë°ì´í„°ì…‹ì˜ íŠ¹ì„±ì„ ìƒì„¸íˆ ì„¤ëª…í•˜ë©° ì •ëŸ‰ì  ë¹„êµë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
- 4. ëª¨ë“  í‰ê°€ ì§€í‘œì˜ í†µì¼ëœ ì •ì˜ë¥¼ ìˆ˜ì§‘í•˜ê³ , ë°ì´í„°ì…‹ì— ëŒ€í•œ ë²¤ì¹˜ë§ˆí¬ í…Œì´ë¸”ì„ ì„¤ì •í•˜ì—¬ ê³µì •í•œ ë¹„êµì™€ ë¶„ì•¼ì˜ ë°œì „ì„ ì´‰ì§„í•©ë‹ˆë‹¤.
- 5. LiDAR ê¸°ë°˜ 3D ì¸ê°„ ì´í•´ë¥¼ ë°œì „ì‹œí‚¤ê¸° ìœ„í•œ ê°œë°©í˜• ê³¼ì œì™€ ì—°êµ¬ ë°©í–¥ì„ ì œì‹œí•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 16:34:00*