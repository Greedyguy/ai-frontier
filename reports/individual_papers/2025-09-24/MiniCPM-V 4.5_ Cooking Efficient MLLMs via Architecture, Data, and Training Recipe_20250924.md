<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T14:47:53.507064",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multimodal Learning",
    "3D-Resampler",
    "VideoMME",
    "Reinforcement Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multimodal Learning": 0.82,
    "3D-Resampler": 0.71,
    "VideoMME": 0.69,
    "Reinforcement Learning": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multimodal Large Language Models",
        "canonical": "Multimodal Learning",
        "aliases": [
          "MLLMs"
        ],
        "category": "specific_connectable",
        "rationale": "Multimodal Learning is a trending area that bridges vision and language, making it highly connectable in the context of AI development.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "3D-Resampler model architecture",
        "canonical": "3D-Resampler",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This is a novel architecture specific to the paper, offering unique insights into efficient model design.",
        "novelty_score": 0.72,
        "connectivity_score": 0.65,
        "specificity_score": 0.81,
        "link_intent_score": 0.71
      },
      {
        "surface": "VideoMME benchmark",
        "canonical": "VideoMME",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "The VideoMME benchmark is a specific evaluation metric that can link to performance comparisons in multimodal models.",
        "novelty_score": 0.68,
        "connectivity_score": 0.59,
        "specificity_score": 0.79,
        "link_intent_score": 0.69
      },
      {
        "surface": "hybrid reinforcement learning strategy",
        "canonical": "Reinforcement Learning",
        "aliases": [
          "hybrid RL"
        ],
        "category": "broad_technical",
        "rationale": "Reinforcement Learning is a foundational concept that supports the paper's methodology, linking to broader AI strategies.",
        "novelty_score": 0.45,
        "connectivity_score": 0.83,
        "specificity_score": 0.7,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "efficiency",
      "performance",
      "method"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multimodal Large Language Models",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "3D-Resampler model architecture",
      "resolved_canonical": "3D-Resampler",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.65,
        "specificity": 0.81,
        "link_intent": 0.71
      }
    },
    {
      "candidate_surface": "VideoMME benchmark",
      "resolved_canonical": "VideoMME",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.59,
        "specificity": 0.79,
        "link_intent": 0.69
      }
    },
    {
      "candidate_surface": "hybrid reinforcement learning strategy",
      "resolved_canonical": "Reinforcement Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.83,
        "specificity": 0.7,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# MiniCPM-V 4.5: Cooking Efficient MLLMs via Architecture, Data, and Training Recipe

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18154.pdf)
**Category**: cs.LG
**Published**: 2025-09-24
**ArXiv ID**: [2509.18154](https://arxiv.org/abs/2509.18154)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/LEO-MINI_ An Efficient Multimodal Large Language Model using Conditional Token Reduction and Mixture of Multi-Modal Experts_20250923|LEO-MINI: An Efficient Multimodal Large Language Model using Conditional Token Reduction and Mixture of Multi-Modal Experts]] (85.5% similar)
- [[2025-09-24/Qianfan-VL_ Domain-Enhanced Universal Vision-Language Models_20250924|Qianfan-VL: Domain-Enhanced Universal Vision-Language Models]] (84.9% similar)
- [[2025-09-23/MCP_ A Control-Theoretic Orchestration Framework for Synergistic Efficiency and Interpretability in Multimodal Large Language Models_20250923|MCP: A Control-Theoretic Orchestration Framework for Synergistic Efficiency and Interpretability in Multimodal Large Language Models]] (84.6% similar)
- [[2025-09-23/When Big Models Train Small Ones_ Label-Free Model Parity Alignment for Efficient Visual Question Answering using Small VLMs_20250923|When Big Models Train Small Ones: Label-Free Model Parity Alignment for Efficient Visual Question Answering using Small VLMs]] (84.3% similar)
- [[2025-09-24/LCMF_ Lightweight Cross-Modality Mambaformer for Embodied Robotics VQA_20250924|LCMF: Lightweight Cross-Modality Mambaformer for Embodied Robotics VQA]] (84.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Reinforcement Learning|Reinforcement Learning]]
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**âš¡ Unique Technical**: [[keywords/3D-Resampler|3D-Resampler]], [[keywords/VideoMME|VideoMME]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18154v1 Announce Type: new 
Abstract: Multimodal Large Language Models (MLLMs) are undergoing rapid progress and represent the frontier of AI development. However, their training and inference efficiency have emerged as a core bottleneck in making MLLMs more accessible and scalable. To address the challenges, we present MiniCPM-V 4.5, an 8B parameter model designed for high efficiency and strong performance. We introduce three core improvements in model architecture, data strategy and training method: a unified 3D-Resampler model architecture for highly compact encoding over images and videos, a unified learning paradigm for document knowledge and text recognition without heavy data engineering, and a hybrid reinforcement learning strategy for proficiency in both short and long reasoning modes. Comprehensive experimental results in OpenCompass evaluation show that MiniCPM-V 4.5 surpasses widely used proprietary models such as GPT-4o-latest, and significantly larger open-source models such as Qwen2.5-VL 72B. Notably, the strong performance is achieved with remarkable efficiency. For example, on the widely adopted VideoMME benchmark, MiniCPM-V 4.5 achieves state-of-the-art performance among models under 30B size, using just 46.7\% GPU memory cost and 8.7\% inference time of Qwen2.5-VL 7B.

## ğŸ“ ìš”ì•½

MiniCPM-V 4.5ëŠ” 8ì–µ ê°œì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ê°€ì§„ ëª¨ë¸ë¡œ, ë©€í‹°ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(MLLM)ì˜ íš¨ìœ¨ì„±ê³¼ ì„±ëŠ¥ì„ ê°œì„ í•˜ê¸° ìœ„í•´ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ì´ë¯¸ì§€ì™€ ë¹„ë””ì˜¤ì˜ íš¨ìœ¨ì ì¸ ì¸ì½”ë”©ì„ ìœ„í•œ 3D-Resampler ì•„í‚¤í…ì²˜, ë¬¸ì„œ ì§€ì‹ ë° í…ìŠ¤íŠ¸ ì¸ì‹ì„ ìœ„í•œ í†µí•© í•™ìŠµ íŒ¨ëŸ¬ë‹¤ì„, ê·¸ë¦¬ê³  ì§§ê³  ê¸´ ì¶”ë¡  ëª¨ë“œ ëª¨ë‘ì— ëŠ¥ìˆ™í•œ í•˜ì´ë¸Œë¦¬ë“œ ê°•í™” í•™ìŠµ ì „ëµì„ ë„ì…í–ˆìŠµë‹ˆë‹¤. OpenCompass í‰ê°€ì—ì„œ MiniCPM-V 4.5ëŠ” GPT-4o-latestì™€ ê°™ì€ ìƒìš© ëª¨ë¸ ë° Qwen2.5-VL 72Bì™€ ê°™ì€ ëŒ€ê·œëª¨ ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ì„ ëŠ¥ê°€í•˜ëŠ” ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. íŠ¹íˆ, VideoMME ë²¤ì¹˜ë§ˆí¬ì—ì„œ 30ì–µ ë¯¸ë§Œ í¬ê¸°ì˜ ëª¨ë¸ ì¤‘ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ë©´ì„œë„ GPU ë©”ëª¨ë¦¬ ë¹„ìš©ê³¼ ì¶”ë¡  ì‹œê°„ì„ í¬ê²Œ ì ˆê°í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. MiniCPM-V 4.5ëŠ” 8B íŒŒë¼ë¯¸í„° ëª¨ë¸ë¡œ, íš¨ìœ¨ì„±ê³¼ ì„±ëŠ¥ì„ ë™ì‹œì— ë†’ì´ê¸° ìœ„í•´ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.
- 2. ëª¨ë¸ ì•„í‚¤í…ì²˜, ë°ì´í„° ì „ëµ, í›ˆë ¨ ë°©ë²•ì—ì„œì˜ ê°œì„ ì„ í†µí•´ ì´ë¯¸ì§€ì™€ ë¹„ë””ì˜¤ì˜ ì¸ì½”ë”©ì„ ìœ„í•œ 3D-Resampler ëª¨ë¸ ì•„í‚¤í…ì²˜ë¥¼ ë„ì…í–ˆìŠµë‹ˆë‹¤.
- 3. ë¬¸ì„œ ì§€ì‹ê³¼ í…ìŠ¤íŠ¸ ì¸ì‹ì„ ìœ„í•œ í†µí•© í•™ìŠµ íŒ¨ëŸ¬ë‹¤ì„ì„ í†µí•´ ë³µì¡í•œ ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ ì—†ì´ í•™ìŠµì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
- 4. ì§§ê³  ê¸´ ì¶”ë¡  ëª¨ë“œ ëª¨ë‘ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ê¸° ìœ„í•´ í•˜ì´ë¸Œë¦¬ë“œ ê°•í™” í•™ìŠµ ì „ëµì„ ì±„íƒí–ˆìŠµë‹ˆë‹¤.
- 5. MiniCPM-V 4.5ëŠ” VideoMME ë²¤ì¹˜ë§ˆí¬ì—ì„œ 30B ì´í•˜ ëª¨ë¸ ì¤‘ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ê¸°ë¡í•˜ë©°, GPU ë©”ëª¨ë¦¬ ë¹„ìš©ê³¼ ì¶”ë¡  ì‹œê°„ì„ í¬ê²Œ ì ˆê°í–ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 14:47:53*