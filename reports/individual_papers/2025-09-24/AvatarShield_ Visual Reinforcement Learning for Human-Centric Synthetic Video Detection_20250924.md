<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T14:34:15.937619",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "AvatarShield",
    "Human-Centric Synthetic Video",
    "Multimodal Learning",
    "Large Language Model",
    "Group Relative Policy Optimization"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "AvatarShield": 0.78,
    "Human-Centric Synthetic Video": 0.75,
    "Multimodal Learning": 0.8,
    "Large Language Model": 0.85,
    "Group Relative Policy Optimization": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "AvatarShield",
        "canonical": "AvatarShield",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "As a novel framework, AvatarShield represents a unique approach to synthetic video detection, offering potential for future research connections.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.78
      },
      {
        "surface": "Human-Centric Synthetic Video",
        "canonical": "Human-Centric Synthetic Video",
        "aliases": [
          "Synthetic Human Video"
        ],
        "category": "unique_technical",
        "rationale": "This term captures the focus on synthetic video content involving human figures, which is central to the paper's contributions.",
        "novelty_score": 0.7,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.75
      },
      {
        "surface": "Multimodal",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal"
        ],
        "category": "specific_connectable",
        "rationale": "The framework's use of multiple data types aligns with the concept of multimodal learning, facilitating connections to related research.",
        "novelty_score": 0.4,
        "connectivity_score": 0.85,
        "specificity_score": 0.65,
        "link_intent_score": 0.8
      },
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "LLMs are integral to the detection framework, providing a basis for reasoning capabilities in the system.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Group Relative Policy Optimization",
        "canonical": "Group Relative Policy Optimization",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This optimization technique is a novel component of the proposed framework, offering a new angle for exploration in reinforcement learning.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "AvatarShield",
      "resolved_canonical": "AvatarShield",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Human-Centric Synthetic Video",
      "resolved_canonical": "Human-Centric Synthetic Video",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Multimodal",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.85,
        "specificity": 0.65,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Group Relative Policy Optimization",
      "resolved_canonical": "Group Relative Policy Optimization",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# AvatarShield: Visual Reinforcement Learning for Human-Centric Synthetic Video Detection

## 📋 메타데이터

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2505.15173.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2505.15173](https://arxiv.org/abs/2505.15173)

## 🔗 유사한 논문
- [[2025-09-24/Diversity Boosts AI-Generated Text Detection_20250924|Diversity Boosts AI-Generated Text Detection]] (83.9% similar)
- [[2025-09-19/FMGS-Avatar_ Mesh-Guided 2D Gaussian Splatting with Foundation Model Priors for 3D Monocular Avatar Reconstruction_20250919|FMGS-Avatar: Mesh-Guided 2D Gaussian Splatting with Foundation Model Priors for 3D Monocular Avatar Reconstruction]] (83.1% similar)
- [[2025-09-22/TT-DF_ A Large-Scale Diffusion-Based Dataset and Benchmark for Human Body Forgery Detection_20250922|TT-DF: A Large-Scale Diffusion-Based Dataset and Benchmark for Human Body Forgery Detection]] (82.5% similar)
- [[2025-09-22/DNA-DetectLLM_ Unveiling AI-Generated Text via a DNA-Inspired Mutation-Repair Paradigm_20250922|DNA-DetectLLM: Unveiling AI-Generated Text via a DNA-Inspired Mutation-Repair Paradigm]] (82.4% similar)
- [[2025-09-23/MaskedManipulator_ Versatile Whole-Body Manipulation_20250923|MaskedManipulator: Versatile Whole-Body Manipulation]] (82.2% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**⚡ Unique Technical**: [[keywords/AvatarShield|AvatarShield]], [[keywords/Human-Centric Synthetic Video|Human-Centric Synthetic Video]], [[keywords/Group Relative Policy Optimization|Group Relative Policy Optimization]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2505.15173v3 Announce Type: replace-cross 
Abstract: Recent advances in Artificial Intelligence Generated Content have led to highly realistic synthetic videos, particularly in human-centric scenarios involving speech, gestures, and full-body motion, posing serious threats to information authenticity and public trust. Unlike DeepFake techniques that focus on localized facial manipulation, human-centric video generation methods can synthesize entire human bodies with controllable movements, enabling complex interactions with environments, objects, and even other people. However, existing detection methods largely overlook the growing risks posed by such full-body synthetic content. Meanwhile, a growing body of research has explored leveraging LLMs for interpretable fake detection, aiming to explain decisions in natural language. Yet these approaches heavily depend on supervised fine-tuning, which introduces limitations such as annotation bias, hallucinated supervision, and weakened generalization. To address these challenges, we propose AvatarShield, a novel multimodal human-centric synthetic video detection framework that eliminates the need for dense textual supervision by adopting Group Relative Policy Optimization, enabling LLMs to develop reasoning capabilities from simple binary labels. Our architecture combines a discrete vision tower for high-level semantic inconsistencies and a residual extractor for fine-grained artifact analysis. We further introduce FakeHumanVid, a large-scale benchmark containing 15K real and synthetic videos across nine state-of-the-art human generation methods driven by text, pose, or audio. Extensive experiments demonstrate that AvatarShield outperforms existing methods in both in-domain and cross-domain settings.

## 📝 요약

최근 인공지능 생성 콘텐츠의 발전으로 인해 인간 중심의 시나리오에서 매우 현실적인 합성 비디오가 생성되고 있으며, 이는 정보의 진위성과 대중의 신뢰에 심각한 위협을 가하고 있습니다. 기존의 탐지 방법은 이러한 전신 합성 콘텐츠의 위험을 간과하고 있습니다. 이를 해결하기 위해, 우리는 AvatarShield라는 새로운 다중 모달 인간 중심 합성 비디오 탐지 프레임워크를 제안합니다. 이 프레임워크는 밀집된 텍스트 감독 없이 그룹 상대 정책 최적화를 채택하여 LLM이 단순한 이진 레이블에서 추론 능력을 개발할 수 있게 합니다. 우리의 아키텍처는 고수준의 의미론적 불일치를 위한 이산 비전 타워와 세밀한 인공물 분석을 위한 잔여 추출기를 결합합니다. 또한, 텍스트, 자세, 오디오에 의해 구동되는 9가지 최첨단 인간 생성 방법을 포함한 15,000개의 실제 및 합성 비디오로 구성된 대규모 벤치마크인 FakeHumanVid를 소개합니다. 광범위한 실험 결과, AvatarShield는 기존 방법보다 도메인 내 및 도메인 간 설정 모두에서 우수한 성능을 보였습니다.

## 🎯 주요 포인트

- 1. 인공지능 생성 콘텐츠의 발전으로 인해 인간 중심의 시나리오에서 매우 현실적인 합성 비디오가 생성되며, 정보의 진위성과 공공 신뢰에 심각한 위협을 초래하고 있습니다.
- 2. 기존의 DeepFake 기술과 달리, 인간 중심 비디오 생성 방법은 전체 인체를 합성하여 환경, 객체, 심지어 다른 사람과의 복잡한 상호작용을 가능하게 합니다.
- 3. 이러한 전체 인체 합성 콘텐츠의 위험성을 간과하는 기존 탐지 방법의 한계를 극복하기 위해, 우리는 AvatarShield라는 새로운 멀티모달 인간 중심 합성 비디오 탐지 프레임워크를 제안합니다.
- 4. AvatarShield는 조밀한 텍스트 감독 없이 그룹 상대 정책 최적화를 채택하여 LLM이 간단한 이진 레이블로부터 추론 능력을 개발할 수 있도록 합니다.
- 5. FakeHumanVid라는 대규모 벤치마크를 도입하여 15,000개의 실제 및 합성 비디오를 포함하고 있으며, AvatarShield는 기존 방법들보다 뛰어난 성능을 보여줍니다.


---

*Generated on 2025-09-24 14:34:15*