<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T14:11:36.940631",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Personalized Question Answering",
    "Pathways of Thoughts",
    "Reasoning Trajectories"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.8,
    "Personalized Question Answering": 0.75,
    "Pathways of Thoughts": 0.78,
    "Reasoning Trajectories": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Model",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "Central to the proposed method, connecting it to existing LLM research.",
        "novelty_score": 0.4,
        "connectivity_score": 0.85,
        "specificity_score": 0.65,
        "link_intent_score": 0.8
      },
      {
        "surface": "Personalized Question Answering",
        "canonical": "Personalized Question Answering",
        "aliases": [
          "Personalized QA"
        ],
        "category": "unique_technical",
        "rationale": "Focus of the paper, highlighting a niche area in QA systems.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      },
      {
        "surface": "Pathways of Thoughts",
        "canonical": "Pathways of Thoughts",
        "aliases": [
          "PoT"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel inference-stage method specific to this research.",
        "novelty_score": 0.85,
        "connectivity_score": 0.55,
        "specificity_score": 0.9,
        "link_intent_score": 0.78
      },
      {
        "surface": "Reasoning Trajectories",
        "canonical": "Reasoning Trajectories",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Describes the diverse reasoning paths explored by the method.",
        "novelty_score": 0.65,
        "connectivity_score": 0.5,
        "specificity_score": 0.75,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Model",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.85,
        "specificity": 0.65,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Personalized Question Answering",
      "resolved_canonical": "Personalized Question Answering",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Pathways of Thoughts",
      "resolved_canonical": "Pathways of Thoughts",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.55,
        "specificity": 0.9,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Reasoning Trajectories",
      "resolved_canonical": "Reasoning Trajectories",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.5,
        "specificity": 0.75,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# Pathways of Thoughts: Multi-Directional Thinking for Long-form Personalized Question Answering

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19094.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2509.19094](https://arxiv.org/abs/2509.19094)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/LaMP-QA_ A Benchmark for Personalized Long-form Question Answering_20250923|LaMP-QA: A Benchmark for Personalized Long-form Question Answering]] (90.1% similar)
- [[2025-09-23/QA-prompting_ Improving Summarization with Large Language Models using Question-Answering_20250923|QA-prompting: Improving Summarization with Large Language Models using Question-Answering]] (85.2% similar)
- [[2025-09-23/RephQA_ Evaluating Readability of Large Language Models in Public Health Question Answering_20250923|RephQA: Evaluating Readability of Large Language Models in Public Health Question Answering]] (84.2% similar)
- [[2025-09-23/A Survey of Personalized Large Language Models_ Progress and Future Directions_20250923|A Survey of Personalized Large Language Models: Progress and Future Directions]] (84.1% similar)
- [[2025-09-22/MMAPG_ A Training-Free Framework for Multimodal Multi-hop Question Answering via Adaptive Planning Graphs_20250922|MMAPG: A Training-Free Framework for Multimodal Multi-hop Question Answering via Adaptive Planning Graphs]] (84.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**âš¡ Unique Technical**: [[keywords/Personalized Question Answering|Personalized Question Answering]], [[keywords/Pathways of Thoughts|Pathways of Thoughts]], [[keywords/Reasoning Trajectories|Reasoning Trajectories]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19094v1 Announce Type: cross 
Abstract: Personalization is essential for adapting question answering (QA) systems to user-specific information needs, thereby improving both accuracy and user satisfaction. However, personalized QA remains relatively underexplored due to challenges such as inferring preferences from long, noisy, and implicit contexts, and generating responses that are simultaneously correct, contextually appropriate, and aligned with user expectations and background knowledge. To address these challenges, we propose Pathways of Thoughts (PoT), an inference-stage method that applies to any large language model (LLM) without requiring task-specific fine-tuning. The approach models the reasoning of an LLM as an iterative decision process, where the model dynamically selects among cognitive operations such as reasoning, revision, personalization, and clarification. This enables exploration of multiple reasoning trajectories, producing diverse candidate responses that capture different perspectives. PoT then aggregates and reweights these candidates according to inferred user preferences, yielding a final personalized response that benefits from the complementary strengths of diverse reasoning paths. Experiments on the LaMP-QA benchmark for personalized QA show that PoT consistently outperforms competitive baselines, achieving up to a 13.1% relative improvement. Human evaluation corroborates these results, with annotators preferring outputs from PoT in 66% of cases and reporting ties in only 15% of cases.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ê°œì¸í™”ëœ ì§ˆë¬¸ ì‘ë‹µ ì‹œìŠ¤í…œ(QA)ì˜ ë°œì „ì„ ìœ„í•´ 'Pathways of Thoughts (PoT)'ë¼ëŠ” ë°©ë²•ë¡ ì„ ì œì•ˆí•©ë‹ˆë‹¤. PoTëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì¶”ë¡  ê³¼ì •ì„ ë°˜ë³µì  ì˜ì‚¬ ê²°ì • ê³¼ì •ìœ¼ë¡œ ëª¨ë¸ë§í•˜ì—¬, ì¶”ë¡ , ìˆ˜ì •, ê°œì¸í™”, ëª…í™•í™” ë“±ì˜ ì¸ì§€ì  ì‘ì—…ì„ ë™ì ìœ¼ë¡œ ì„ íƒí•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë‹¤ì–‘í•œ ì¶”ë¡  ê²½ë¡œë¥¼ íƒìƒ‰í•˜ê³ , ì‚¬ìš©ì ì„ í˜¸ì— ë§ì¶˜ ê°œì¸í™”ëœ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤. LaMP-QA ë²¤ì¹˜ë§ˆí¬ ì‹¤í—˜ì—ì„œ PoTëŠ” ê¸°ì¡´ ë°©ë²•ë“¤ë³´ë‹¤ ìµœëŒ€ 13.1% ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë©°, ì¸ê°„ í‰ê°€ì—ì„œë„ 66%ì˜ ì„ í˜¸ë„ë¥¼ ì–»ì—ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ê°œì¸í™”ëœ ì§ˆë¬¸ ì‘ë‹µ ì‹œìŠ¤í…œì€ ì‚¬ìš©ì ë§ì¶¤í˜• ì •ë³´ ìš”êµ¬ì— ì ì‘í•˜ì—¬ ì •í™•ì„±ê³¼ ì‚¬ìš©ì ë§Œì¡±ë„ë¥¼ í–¥ìƒì‹œí‚¨ë‹¤.
- 2. Pathways of Thoughts (PoT)ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì— ì ìš© ê°€ëŠ¥í•œ ì¶”ë¡  ë‹¨ê³„ ë°©ë²•ìœ¼ë¡œ, íŠ¹ì • ì‘ì—…ì— ëŒ€í•œ ë¯¸ì„¸ ì¡°ì • ì—†ì´ ê°œì¸í™”ëœ ì‘ë‹µì„ ìƒì„±í•œë‹¤.
- 3. PoTëŠ” ë‹¤ì–‘í•œ ì¸ì§€ ì‘ì—…ì„ í†µí•´ ì—¬ëŸ¬ ì¶”ë¡  ê²½ë¡œë¥¼ íƒìƒ‰í•˜ê³ , ì‚¬ìš©ì ì„ í˜¸ì— ë”°ë¼ í›„ë³´ ì‘ë‹µì„ ì§‘ê³„ ë° ì¬ê°€ì¤‘í•˜ì—¬ ìµœì¢… ê°œì¸í™”ëœ ì‘ë‹µì„ ì œê³µí•œë‹¤.
- 4. LaMP-QA ë²¤ì¹˜ë§ˆí¬ ì‹¤í—˜ì—ì„œ PoTëŠ” ìµœëŒ€ 13.1%ì˜ ìƒëŒ€ì  ê°œì„ ì„ ë³´ì´ë©° ê²½ìŸë ¥ ìˆëŠ” ê¸°ì¤€ ëª¨ë¸ë“¤ì„ ëŠ¥ê°€í•œë‹¤.
- 5. ì¸ê°„ í‰ê°€ì—ì„œ PoTì˜ ê²°ê³¼ë¬¼ì´ 66%ì˜ ì‚¬ë¡€ì—ì„œ ì„ í˜¸ë˜ì—ˆìœ¼ë©°, 15%ì˜ ì‚¬ë¡€ì—ì„œ ë™ì ìœ¼ë¡œ í‰ê°€ë˜ì—ˆë‹¤.


---

*Generated on 2025-09-24 14:11:36*