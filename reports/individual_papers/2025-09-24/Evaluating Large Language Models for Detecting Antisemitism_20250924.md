<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T13:44:41.252378",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Guided Chain-of-Thought",
    "Semantic Divergence",
    "Antisemitic Content Detection",
    "In-Context Definition"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Guided Chain-of-Thought": 0.8,
    "Semantic Divergence": 0.78,
    "Antisemitic Content Detection": 0.82,
    "In-Context Definition": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Large Language Models"
        ],
        "category": "broad_technical",
        "rationale": "Central to the study, connecting to other works on language models.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Guided-CoT",
        "canonical": "Guided Chain-of-Thought",
        "aliases": [
          "Guided-CoT"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel prompting technique specific to this study.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "semantic divergence",
        "canonical": "Semantic Divergence",
        "aliases": [
          "semantic difference",
          "meaning divergence"
        ],
        "category": "specific_connectable",
        "rationale": "Key to understanding model errors and rationale differences.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "antisemitic content",
        "canonical": "Antisemitic Content Detection",
        "aliases": [
          "antisemitism detection",
          "hateful content detection"
        ],
        "category": "unique_technical",
        "rationale": "Specific application of LLMs in detecting hate speech.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.82
      },
      {
        "surface": "in-context definition",
        "canonical": "In-Context Definition",
        "aliases": [
          "contextual definition",
          "in-situ definition"
        ],
        "category": "specific_connectable",
        "rationale": "Important for understanding the policy guidelines used.",
        "novelty_score": 0.6,
        "connectivity_score": 0.7,
        "specificity_score": 0.75,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "decoding configuration",
      "model sizes",
      "reasoning capability"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Guided-CoT",
      "resolved_canonical": "Guided Chain-of-Thought",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "semantic divergence",
      "resolved_canonical": "Semantic Divergence",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "antisemitic content",
      "resolved_canonical": "Antisemitic Content Detection",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "in-context definition",
      "resolved_canonical": "In-Context Definition",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.7,
        "specificity": 0.75,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Evaluating Large Language Models for Detecting Antisemitism

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18293.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2509.18293](https://arxiv.org/abs/2509.18293)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/It Depends_ Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge_20250922|It Depends: Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge]] (86.8% similar)
- [[2025-09-23/Sugar-Coated Poison_ Benign Generation Unlocks LLM Jailbreaking_20250923|Sugar-Coated Poison: Benign Generation Unlocks LLM Jailbreaking]] (86.6% similar)
- [[2025-09-23/Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates_20250923|Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates]] (86.2% similar)
- [[2025-09-23/Adaptive Distraction_ Probing LLM Contextual Robustness with Automated Tree Search_20250923|Adaptive Distraction: Probing LLM Contextual Robustness with Automated Tree Search]] (86.0% similar)
- [[2025-09-23/MIST_ Jailbreaking Black-box Large Language Models via Iterative Semantic Tuning_20250923|MIST: Jailbreaking Black-box Large Language Models via Iterative Semantic Tuning]] (86.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Semantic Divergence|Semantic Divergence]], [[keywords/In-Context Definition|In-Context Definition]]
**âš¡ Unique Technical**: [[keywords/Guided Chain-of-Thought|Guided Chain-of-Thought]], [[keywords/Antisemitic Content Detection|Antisemitic Content Detection]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18293v1 Announce Type: cross 
Abstract: Detecting hateful content is a challenging and important problem. Automated tools, like machine-learning models, can help, but they require continuous training to adapt to the ever-changing landscape of social media. In this work, we evaluate eight open-source LLMs' capability to detect antisemitic content, specifically leveraging in-context definition as a policy guideline. We explore various prompting techniques and design a new CoT-like prompt, Guided-CoT. Guided-CoT handles the in-context policy well, increasing performance across all evaluated models, regardless of decoding configuration, model sizes, or reasoning capability. Notably, Llama 3.1 70B outperforms fine-tuned GPT-3.5. Additionally, we examine LLM errors and introduce metrics to quantify semantic divergence in model-generated rationales, revealing notable differences and paradoxical behaviors among LLMs. Our experiments highlight the differences observed across LLMs' utility, explainability, and reliability.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” ì¦ì˜¤ ë°œì–¸ íƒì§€ë¥¼ ìœ„í•œ ìë™í™” ë„êµ¬ì˜ ì¤‘ìš”ì„±ì„ ê°•ì¡°í•˜ë©°, íŠ¹íˆ ë°˜ìœ ëŒ€ì£¼ì˜ ì½˜í…ì¸  íƒì§€ì— ì´ˆì ì„ ë§ì¶”ê³  ìˆìŠµë‹ˆë‹¤. ì—°êµ¬ì—ì„œëŠ” 8ê°œì˜ ì˜¤í”ˆì†ŒìŠ¤ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê³ , ì •ì±… ì§€ì¹¨ìœ¼ë¡œì„œì˜ ë§¥ë½ ë‚´ ì •ì˜ë¥¼ í™œìš©í•˜ì—¬ ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸ ê¸°ë²•ì„ íƒêµ¬í•©ë‹ˆë‹¤. ìƒˆë¡œìš´ CoT ìœ ì‚¬ í”„ë¡¬í”„íŠ¸ì¸ Guided-CoTë¥¼ ì„¤ê³„í•˜ì—¬ ëª¨ë“  í‰ê°€ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œì¼°ìœ¼ë©°, íŠ¹íˆ Llama 3.1 70B ëª¨ë¸ì´ ë¯¸ì„¸ ì¡°ì •ëœ GPT-3.5ë¥¼ ëŠ¥ê°€í•˜ëŠ” ì„±ê³¼ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤. ë˜í•œ, ëª¨ë¸ ì˜¤ë¥˜ë¥¼ ë¶„ì„í•˜ê³  ëª¨ë¸ ìƒì„± ë…¼ë¦¬ì˜ ì˜ë¯¸ì  ì°¨ì´ë¥¼ ì •ëŸ‰í™”í•˜ëŠ” ì§€í‘œë¥¼ ë„ì…í•˜ì—¬ LLM ê°„ì˜ ìœ ìš©ì„±, ì„¤ëª… ê°€ëŠ¥ì„±, ì‹ ë¢°ì„±ì˜ ì°¨ì´ë¥¼ ê°•ì¡°í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì¦ì˜¤ì„± ì½˜í…ì¸  íƒì§€ëŠ” ë„ì „ì ì´ë©´ì„œë„ ì¤‘ìš”í•œ ë¬¸ì œì´ë©°, ìë™í™” ë„êµ¬ì¸ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì´ ì´ë¥¼ ë•ì§€ë§Œ ì§€ì†ì ì¸ í›ˆë ¨ì´ í•„ìš”í•©ë‹ˆë‹¤.
- 2. ë³¸ ì—°êµ¬ì—ì„œëŠ” ë°˜ìœ ëŒ€ì£¼ì˜ ì½˜í…ì¸ ë¥¼ íƒì§€í•˜ê¸° ìœ„í•´ 8ê°œì˜ ì˜¤í”ˆì†ŒìŠ¤ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê³ , ë§¥ë½ ë‚´ ì •ì˜ë¥¼ ì •ì±… ì§€ì¹¨ìœ¼ë¡œ í™œìš©í–ˆìŠµë‹ˆë‹¤.
- 3. ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸ ê¸°ë²•ì„ íƒêµ¬í•˜ê³  ìƒˆë¡œìš´ CoT ìœ ì‚¬ í”„ë¡¬í”„íŠ¸ì¸ Guided-CoTë¥¼ ì„¤ê³„í•˜ì—¬ ëª¨ë“  í‰ê°€ëœ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.
- 4. Llama 3.1 70B ëª¨ë¸ì´ ë¯¸ì„¸ ì¡°ì •ëœ GPT-3.5ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.
- 5. LLMì˜ ì˜¤ë¥˜ë¥¼ ë¶„ì„í•˜ê³  ëª¨ë¸ ìƒì„± ë…¼ë¦¬ì˜ ì˜ë¯¸ì  ì°¨ì´ë¥¼ ì •ëŸ‰í™”í•˜ëŠ” ì§€í‘œë¥¼ ë„ì…í•˜ì—¬ LLM ê°„ì˜ ìœ ìš©ì„±, ì„¤ëª… ê°€ëŠ¥ì„±, ì‹ ë¢°ì„±ì˜ ì°¨ì´ë¥¼ ê°•ì¡°í–ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 13:44:41*