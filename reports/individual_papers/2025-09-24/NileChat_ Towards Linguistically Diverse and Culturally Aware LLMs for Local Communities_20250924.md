<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T15:51:58.444739",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Retrieval Augmented Generation",
    "Cultural and Values Alignment",
    "Low-resource Languages",
    "Synthetic Data Generation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Retrieval Augmented Generation": 0.88,
    "Cultural and Values Alignment": 0.8,
    "Low-resource Languages": 0.82,
    "Synthetic Data Generation": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's focus on enhancing language models for diverse communities.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Retrieval-augmented pre-training",
        "canonical": "Retrieval Augmented Generation",
        "aliases": [
          "RAG"
        ],
        "category": "specific_connectable",
        "rationale": "Highlights a specific technique used in the paper for improving language models.",
        "novelty_score": 0.7,
        "connectivity_score": 0.8,
        "specificity_score": 0.85,
        "link_intent_score": 0.88
      },
      {
        "surface": "Cultural and values alignment",
        "canonical": "Cultural and Values Alignment",
        "aliases": [
          "Cultural Alignment"
        ],
        "category": "unique_technical",
        "rationale": "A unique focus of the paper, emphasizing the adaptation of models to local cultures.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "Low-resource languages",
        "canonical": "Low-resource Languages",
        "aliases": [
          "Underrepresented Languages"
        ],
        "category": "specific_connectable",
        "rationale": "Key to understanding the paper's focus on linguistic diversity.",
        "novelty_score": 0.55,
        "connectivity_score": 0.78,
        "specificity_score": 0.7,
        "link_intent_score": 0.82
      },
      {
        "surface": "Synthetic data generation",
        "canonical": "Synthetic Data Generation",
        "aliases": [
          "Synthetic Data"
        ],
        "category": "unique_technical",
        "rationale": "Describes a method used in the paper to create training data for language models.",
        "novelty_score": 0.65,
        "connectivity_score": 0.72,
        "specificity_score": 0.75,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "methodology",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Retrieval-augmented pre-training",
      "resolved_canonical": "Retrieval Augmented Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.8,
        "specificity": 0.85,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "Cultural and values alignment",
      "resolved_canonical": "Cultural and Values Alignment",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Low-resource languages",
      "resolved_canonical": "Low-resource Languages",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.78,
        "specificity": 0.7,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Synthetic data generation",
      "resolved_canonical": "Synthetic Data Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.72,
        "specificity": 0.75,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# NileChat: Towards Linguistically Diverse and Culturally Aware LLMs for Local Communities

## 📋 메타데이터

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2505.18383.pdf)
**Category**: cs.CL
**Published**: 2025-09-24
**ArXiv ID**: [2505.18383](https://arxiv.org/abs/2505.18383)

## 🔗 유사한 논문
- [[2025-09-24/Cross-Cultural Transfer of Commonsense Reasoning in LLMs_ Evidence from the Arab World_20250924|Cross-Cultural Transfer of Commonsense Reasoning in LLMs: Evidence from the Arab World]] (86.8% similar)
- [[2025-09-22/A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages_20250922|A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages]] (85.8% similar)
- [[2025-09-23/MAKIEval_ A Multilingual Automatic WiKidata-based Framework for Cultural Awareness Evaluation for LLMs_20250923|MAKIEval: A Multilingual Automatic WiKidata-based Framework for Cultural Awareness Evaluation for LLMs]] (85.5% similar)
- [[2025-09-22/CultureScope_ A Dimensional Lens for Probing Cultural Understanding in LLMs_20250922|CultureScope: A Dimensional Lens for Probing Cultural Understanding in LLMs]] (84.6% similar)
- [[2025-09-23/Robust Native Language Identification through Agentic Decomposition_20250923|Robust Native Language Identification through Agentic Decomposition]] (84.3% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Retrieval Augmented Generation|Retrieval Augmented Generation]], [[keywords/Low-resource Languages|Low-resource Languages]]
**⚡ Unique Technical**: [[keywords/Cultural and Values Alignment|Cultural and Values Alignment]], [[keywords/Synthetic Data Generation|Synthetic Data Generation]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2505.18383v3 Announce Type: replace 
Abstract: Enhancing the linguistic capabilities of Large Language Models (LLMs) to include low-resource languages is a critical research area. Current research directions predominantly rely on synthetic data generated by translating English corpora, which, while demonstrating promising linguistic understanding and translation abilities, often results in models aligned with source language culture. These models frequently fail to represent the cultural heritage and values of local communities. This work proposes a methodology to create both synthetic and retrieval-based pre-training data tailored to a specific community, considering its (i) language, (ii) cultural heritage, and (iii) cultural values. We demonstrate our methodology using Egyptian and Moroccan dialects as testbeds, chosen for their linguistic and cultural richness and current underrepresentation in LLMs. As a proof-of-concept, we develop NileChat, a 3B parameter Egyptian and Moroccan Arabic LLM adapted for Egyptian and Moroccan communities, incorporating their language, cultural heritage, and values. Our results on various understanding, translation, and cultural and values alignment benchmarks show that NileChat outperforms existing Arabic-aware LLMs of similar size and performs on par with larger models. This work addresses Arabic dialect in LLMs with a focus on cultural and values alignment via controlled synthetic data generation and retrieval-augmented pre-training for Moroccan Darija and Egyptian Arabic, including Arabizi variants, advancing Arabic NLP for low-resource communities. We share our methods, data, and models with the community to promote the inclusion and coverage of more diverse communities in cultural LLM development: https://github.com/UBC-NLP/nilechat .

## 📝 요약

이 연구는 대형 언어 모델(LLM)의 언어적 역량을 저자원 언어로 확장하는 방법론을 제안합니다. 기존 연구는 주로 영어 코퍼스를 번역한 합성 데이터를 사용하지만, 이는 종종 원본 언어의 문화에 맞춰진 모델을 생성하여 지역 사회의 문화유산과 가치를 제대로 반영하지 못합니다. 본 연구는 특정 지역 사회의 언어, 문화유산, 문화적 가치를 고려한 합성 및 검색 기반 사전 학습 데이터를 생성하는 방법론을 제안합니다. 이집트와 모로코 방언을 테스트베드로 사용하여, 이집트 및 모로코 커뮤니티에 적합한 3B 파라미터의 NileChat 모델을 개발했습니다. NileChat은 다양한 이해, 번역, 문화 및 가치 정렬 벤치마크에서 기존 아랍어 인식 LLM보다 우수한 성능을 보였으며, 더 큰 모델과 비슷한 성능을 발휘했습니다. 이 연구는 모로코 다리자와 이집트 아랍어, 아라비지 변형을 포함하여 아랍어 방언의 문화 및 가치 정렬을 중점으로 한 LLM 개발을 통해 저자원 커뮤니티를 위한 아랍어 NLP를 발전시킵니다. 연구 방법, 데이터 및 모델은 커뮤니티와 공유되어 다양한 커뮤니티의 문화적 LLM 개발을 촉진합니다.

## 🎯 주요 포인트

- 1. 대형 언어 모델(LLM)의 언어적 능력을 저자원 언어로 확장하는 것이 중요한 연구 분야입니다.
- 2. 기존 연구는 주로 영어 코퍼스를 번역하여 생성된 합성 데이터에 의존하지만, 이는 종종 출처 언어의 문화에 맞춰진 모델을 초래합니다.
- 3. 본 연구는 특정 지역 사회의 언어, 문화유산, 문화적 가치를 고려한 합성 및 검색 기반 사전 훈련 데이터를 생성하는 방법론을 제안합니다.
- 4. 이집트와 모로코 방언을 테스트베드로 사용하여 NileChat이라는 3B 파라미터의 이집트 및 모로코 아랍어 LLM을 개발하였으며, 이는 기존 아랍어 인식 LLM보다 우수한 성능을 보입니다.
- 5. 본 연구는 모로코 다리자와 이집트 아랍어를 포함한 아랍어 방언의 문화 및 가치 정렬을 중점으로 하여 저자원 커뮤니티를 위한 아랍어 NLP를 발전시킵니다.


---

*Generated on 2025-09-24 15:51:58*