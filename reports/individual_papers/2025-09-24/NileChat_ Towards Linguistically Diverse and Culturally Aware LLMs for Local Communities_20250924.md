<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T15:51:58.444739",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Retrieval Augmented Generation",
    "Cultural and Values Alignment",
    "Low-resource Languages",
    "Synthetic Data Generation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Retrieval Augmented Generation": 0.88,
    "Cultural and Values Alignment": 0.8,
    "Low-resource Languages": 0.82,
    "Synthetic Data Generation": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's focus on enhancing language models for diverse communities.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Retrieval-augmented pre-training",
        "canonical": "Retrieval Augmented Generation",
        "aliases": [
          "RAG"
        ],
        "category": "specific_connectable",
        "rationale": "Highlights a specific technique used in the paper for improving language models.",
        "novelty_score": 0.7,
        "connectivity_score": 0.8,
        "specificity_score": 0.85,
        "link_intent_score": 0.88
      },
      {
        "surface": "Cultural and values alignment",
        "canonical": "Cultural and Values Alignment",
        "aliases": [
          "Cultural Alignment"
        ],
        "category": "unique_technical",
        "rationale": "A unique focus of the paper, emphasizing the adaptation of models to local cultures.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "Low-resource languages",
        "canonical": "Low-resource Languages",
        "aliases": [
          "Underrepresented Languages"
        ],
        "category": "specific_connectable",
        "rationale": "Key to understanding the paper's focus on linguistic diversity.",
        "novelty_score": 0.55,
        "connectivity_score": 0.78,
        "specificity_score": 0.7,
        "link_intent_score": 0.82
      },
      {
        "surface": "Synthetic data generation",
        "canonical": "Synthetic Data Generation",
        "aliases": [
          "Synthetic Data"
        ],
        "category": "unique_technical",
        "rationale": "Describes a method used in the paper to create training data for language models.",
        "novelty_score": 0.65,
        "connectivity_score": 0.72,
        "specificity_score": 0.75,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "methodology",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Retrieval-augmented pre-training",
      "resolved_canonical": "Retrieval Augmented Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.8,
        "specificity": 0.85,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "Cultural and values alignment",
      "resolved_canonical": "Cultural and Values Alignment",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Low-resource languages",
      "resolved_canonical": "Low-resource Languages",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.78,
        "specificity": 0.7,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Synthetic data generation",
      "resolved_canonical": "Synthetic Data Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.72,
        "specificity": 0.75,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# NileChat: Towards Linguistically Diverse and Culturally Aware LLMs for Local Communities

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2505.18383.pdf)
**Category**: cs.CL
**Published**: 2025-09-24
**ArXiv ID**: [2505.18383](https://arxiv.org/abs/2505.18383)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-24/Cross-Cultural Transfer of Commonsense Reasoning in LLMs_ Evidence from the Arab World_20250924|Cross-Cultural Transfer of Commonsense Reasoning in LLMs: Evidence from the Arab World]] (86.8% similar)
- [[2025-09-22/A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages_20250922|A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages]] (85.8% similar)
- [[2025-09-23/MAKIEval_ A Multilingual Automatic WiKidata-based Framework for Cultural Awareness Evaluation for LLMs_20250923|MAKIEval: A Multilingual Automatic WiKidata-based Framework for Cultural Awareness Evaluation for LLMs]] (85.5% similar)
- [[2025-09-22/CultureScope_ A Dimensional Lens for Probing Cultural Understanding in LLMs_20250922|CultureScope: A Dimensional Lens for Probing Cultural Understanding in LLMs]] (84.6% similar)
- [[2025-09-23/Robust Native Language Identification through Agentic Decomposition_20250923|Robust Native Language Identification through Agentic Decomposition]] (84.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Retrieval Augmented Generation|Retrieval Augmented Generation]], [[keywords/Low-resource Languages|Low-resource Languages]]
**âš¡ Unique Technical**: [[keywords/Cultural and Values Alignment|Cultural and Values Alignment]], [[keywords/Synthetic Data Generation|Synthetic Data Generation]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2505.18383v3 Announce Type: replace 
Abstract: Enhancing the linguistic capabilities of Large Language Models (LLMs) to include low-resource languages is a critical research area. Current research directions predominantly rely on synthetic data generated by translating English corpora, which, while demonstrating promising linguistic understanding and translation abilities, often results in models aligned with source language culture. These models frequently fail to represent the cultural heritage and values of local communities. This work proposes a methodology to create both synthetic and retrieval-based pre-training data tailored to a specific community, considering its (i) language, (ii) cultural heritage, and (iii) cultural values. We demonstrate our methodology using Egyptian and Moroccan dialects as testbeds, chosen for their linguistic and cultural richness and current underrepresentation in LLMs. As a proof-of-concept, we develop NileChat, a 3B parameter Egyptian and Moroccan Arabic LLM adapted for Egyptian and Moroccan communities, incorporating their language, cultural heritage, and values. Our results on various understanding, translation, and cultural and values alignment benchmarks show that NileChat outperforms existing Arabic-aware LLMs of similar size and performs on par with larger models. This work addresses Arabic dialect in LLMs with a focus on cultural and values alignment via controlled synthetic data generation and retrieval-augmented pre-training for Moroccan Darija and Egyptian Arabic, including Arabizi variants, advancing Arabic NLP for low-resource communities. We share our methods, data, and models with the community to promote the inclusion and coverage of more diverse communities in cultural LLM development: https://github.com/UBC-NLP/nilechat .

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì–¸ì–´ì  ì—­ëŸ‰ì„ ì €ìì› ì–¸ì–´ë¡œ í™•ì¥í•˜ëŠ” ë°©ë²•ë¡ ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ ì—°êµ¬ëŠ” ì£¼ë¡œ ì˜ì–´ ì½”í¼ìŠ¤ë¥¼ ë²ˆì—­í•œ í•©ì„± ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì§€ë§Œ, ì´ëŠ” ì¢…ì¢… ì›ë³¸ ì–¸ì–´ì˜ ë¬¸í™”ì— ë§ì¶°ì§„ ëª¨ë¸ì„ ìƒì„±í•˜ì—¬ ì§€ì—­ ì‚¬íšŒì˜ ë¬¸í™”ìœ ì‚°ê³¼ ê°€ì¹˜ë¥¼ ì œëŒ€ë¡œ ë°˜ì˜í•˜ì§€ ëª»í•©ë‹ˆë‹¤. ë³¸ ì—°êµ¬ëŠ” íŠ¹ì • ì§€ì—­ ì‚¬íšŒì˜ ì–¸ì–´, ë¬¸í™”ìœ ì‚°, ë¬¸í™”ì  ê°€ì¹˜ë¥¼ ê³ ë ¤í•œ í•©ì„± ë° ê²€ìƒ‰ ê¸°ë°˜ ì‚¬ì „ í•™ìŠµ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ë°©ë²•ë¡ ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ì§‘íŠ¸ì™€ ëª¨ë¡œì½” ë°©ì–¸ì„ í…ŒìŠ¤íŠ¸ë² ë“œë¡œ ì‚¬ìš©í•˜ì—¬, ì´ì§‘íŠ¸ ë° ëª¨ë¡œì½” ì»¤ë®¤ë‹ˆí‹°ì— ì í•©í•œ 3B íŒŒë¼ë¯¸í„°ì˜ NileChat ëª¨ë¸ì„ ê°œë°œí–ˆìŠµë‹ˆë‹¤. NileChatì€ ë‹¤ì–‘í•œ ì´í•´, ë²ˆì—­, ë¬¸í™” ë° ê°€ì¹˜ ì •ë ¬ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ê¸°ì¡´ ì•„ëì–´ ì¸ì‹ LLMë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë©°, ë” í° ëª¨ë¸ê³¼ ë¹„ìŠ·í•œ ì„±ëŠ¥ì„ ë°œíœ˜í–ˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ëª¨ë¡œì½” ë‹¤ë¦¬ìì™€ ì´ì§‘íŠ¸ ì•„ëì–´, ì•„ë¼ë¹„ì§€ ë³€í˜•ì„ í¬í•¨í•˜ì—¬ ì•„ëì–´ ë°©ì–¸ì˜ ë¬¸í™” ë° ê°€ì¹˜ ì •ë ¬ì„ ì¤‘ì ìœ¼ë¡œ í•œ LLM ê°œë°œì„ í†µí•´ ì €ìì› ì»¤ë®¤ë‹ˆí‹°ë¥¼ ìœ„í•œ ì•„ëì–´ NLPë¥¼ ë°œì „ì‹œí‚µë‹ˆë‹¤. ì—°êµ¬ ë°©ë²•, ë°ì´í„° ë° ëª¨ë¸ì€ ì»¤ë®¤ë‹ˆí‹°ì™€ ê³µìœ ë˜ì–´ ë‹¤ì–‘í•œ ì»¤ë®¤ë‹ˆí‹°ì˜ ë¬¸í™”ì  LLM ê°œë°œì„ ì´‰ì§„í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì–¸ì–´ì  ëŠ¥ë ¥ì„ ì €ìì› ì–¸ì–´ë¡œ í™•ì¥í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•œ ì—°êµ¬ ë¶„ì•¼ì…ë‹ˆë‹¤.
- 2. ê¸°ì¡´ ì—°êµ¬ëŠ” ì£¼ë¡œ ì˜ì–´ ì½”í¼ìŠ¤ë¥¼ ë²ˆì—­í•˜ì—¬ ìƒì„±ëœ í•©ì„± ë°ì´í„°ì— ì˜ì¡´í•˜ì§€ë§Œ, ì´ëŠ” ì¢…ì¢… ì¶œì²˜ ì–¸ì–´ì˜ ë¬¸í™”ì— ë§ì¶°ì§„ ëª¨ë¸ì„ ì´ˆë˜í•©ë‹ˆë‹¤.
- 3. ë³¸ ì—°êµ¬ëŠ” íŠ¹ì • ì§€ì—­ ì‚¬íšŒì˜ ì–¸ì–´, ë¬¸í™”ìœ ì‚°, ë¬¸í™”ì  ê°€ì¹˜ë¥¼ ê³ ë ¤í•œ í•©ì„± ë° ê²€ìƒ‰ ê¸°ë°˜ ì‚¬ì „ í›ˆë ¨ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ë°©ë²•ë¡ ì„ ì œì•ˆí•©ë‹ˆë‹¤.
- 4. ì´ì§‘íŠ¸ì™€ ëª¨ë¡œì½” ë°©ì–¸ì„ í…ŒìŠ¤íŠ¸ë² ë“œë¡œ ì‚¬ìš©í•˜ì—¬ NileChatì´ë¼ëŠ” 3B íŒŒë¼ë¯¸í„°ì˜ ì´ì§‘íŠ¸ ë° ëª¨ë¡œì½” ì•„ëì–´ LLMì„ ê°œë°œí•˜ì˜€ìœ¼ë©°, ì´ëŠ” ê¸°ì¡´ ì•„ëì–´ ì¸ì‹ LLMë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.
- 5. ë³¸ ì—°êµ¬ëŠ” ëª¨ë¡œì½” ë‹¤ë¦¬ìì™€ ì´ì§‘íŠ¸ ì•„ëì–´ë¥¼ í¬í•¨í•œ ì•„ëì–´ ë°©ì–¸ì˜ ë¬¸í™” ë° ê°€ì¹˜ ì •ë ¬ì„ ì¤‘ì ìœ¼ë¡œ í•˜ì—¬ ì €ìì› ì»¤ë®¤ë‹ˆí‹°ë¥¼ ìœ„í•œ ì•„ëì–´ NLPë¥¼ ë°œì „ì‹œí‚µë‹ˆë‹¤.


---

*Generated on 2025-09-24 15:51:58*