<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T13:43:55.112859",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Public Perception of AI",
    "Institutional Trust in AI",
    "AI Ethics",
    "AI Governance"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Public Perception of AI": 0.72,
    "Institutional Trust in AI": 0.71,
    "AI Ethics": 0.78,
    "AI Governance": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "public attitudes toward AI",
        "canonical": "Public Perception of AI",
        "aliases": [
          "AI Public Opinion",
          "AI Attitudes"
        ],
        "category": "evolved_concepts",
        "rationale": "Understanding public perception is crucial for linking AI technology with societal impact studies.",
        "novelty_score": 0.55,
        "connectivity_score": 0.78,
        "specificity_score": 0.68,
        "link_intent_score": 0.72
      },
      {
        "surface": "institutional trust",
        "canonical": "Institutional Trust in AI",
        "aliases": [
          "Trust in AI Institutions"
        ],
        "category": "unique_technical",
        "rationale": "Institutional trust is a key factor in AI adoption and governance discussions.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.75,
        "link_intent_score": 0.71
      },
      {
        "surface": "ethical concerns",
        "canonical": "AI Ethics",
        "aliases": [
          "Ethical Issues in AI"
        ],
        "category": "specific_connectable",
        "rationale": "AI ethics is a critical area for linking technical development with societal values.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "responsible AI governance",
        "canonical": "AI Governance",
        "aliases": [
          "Governance of AI",
          "AI Policy"
        ],
        "category": "evolved_concepts",
        "rationale": "AI governance frameworks are essential for linking policy and regulatory discussions.",
        "novelty_score": 0.58,
        "connectivity_score": 0.82,
        "specificity_score": 0.77,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "artificial intelligence",
      "public administration",
      "healthcare",
      "education",
      "security"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "public attitudes toward AI",
      "resolved_canonical": "Public Perception of AI",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.78,
        "specificity": 0.68,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "institutional trust",
      "resolved_canonical": "Institutional Trust in AI",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.75,
        "link_intent": 0.71
      }
    },
    {
      "candidate_surface": "ethical concerns",
      "resolved_canonical": "AI Ethics",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "responsible AI governance",
      "resolved_canonical": "AI Governance",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.82,
        "specificity": 0.77,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Perceptions of AI Across Sectors: A Comparative Review of Public Attitudes

## 📋 메타데이터

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18233.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2509.18233](https://arxiv.org/abs/2509.18233)

## 🔗 유사한 논문
- [[2025-09-22/Who is Responsible When AI Fails? Mapping Causes, Entities, and Consequences of AI Privacy and Ethical Incidents_20250922|Who is Responsible When AI Fails? Mapping Causes, Entities, and Consequences of AI Privacy and Ethical Incidents]] (85.1% similar)
- [[2025-09-22/The Great AI Witch Hunt_ Reviewers Perception and (Mis)Conception of Generative AI in Research Writing_20250922|The Great AI Witch Hunt: Reviewers Perception and (Mis)Conception of Generative AI in Research Writing]] (83.0% similar)
- [[2025-09-23/"I think this is fair''_ Uncovering the Complexities of Stakeholder Decision-Making in AI Fairness Assessment_20250923|"I think this is fair'': Uncovering the Complexities of Stakeholder Decision-Making in AI Fairness Assessment]] (82.6% similar)
- [[2025-09-22/Algorithmic Fairness_ Not a Purely Technical but Socio-Technical Property_20250922|Algorithmic Fairness: Not a Purely Technical but Socio-Technical Property]] (82.5% similar)
- [[2025-09-22/From Development to Deployment of AI-assisted Telehealth and Screening for Vision- and Hearing-threatening diseases in resource-constrained settings_ Field Observations, Challenges and Way Forward_20250922|From Development to Deployment of AI-assisted Telehealth and Screening for Vision- and Hearing-threatening diseases in resource-constrained settings: Field Observations, Challenges and Way Forward]] (82.4% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/AI Ethics|AI Ethics]]
**⚡ Unique Technical**: [[keywords/Institutional Trust in AI|Institutional Trust in AI]]
**🚀 Evolved Concepts**: [[keywords/Public Perception of AI|Public Perception of AI]], [[keywords/AI Governance|AI Governance]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.18233v1 Announce Type: cross 
Abstract: This paper offers a domain-mediated comparative review of 251 studies on public attitudes toward AI, published between 2011 and 2025. Drawing on a systematic literature review, we analyse how different factors including perceived benefits and concerns (or risks) shape public acceptance of - or resistance to - artificial intelligence across domains and use-cases, including healthcare, education, security, public administration, generative AI, and autonomous vehicles. The analysis highlights recurring patterns in individual, contextual, and technical factors influencing perception, while also tracing variations in institutional trust, perceived fairness, and ethical concerns. We show that the public perception in AI is shaped not only by technical design or performance but also by sector-specific considerations as well as imaginaries, cultural narratives, and historical legacies. This comparative approach offers a foundation for developing more tailored and context-sensitive strategies for responsible AI governance.

## 📝 요약

이 논문은 2011년부터 2025년까지 발표된 인공지능(AI)에 대한 대중의 태도를 다룬 251개의 연구를 비교 분석합니다. 체계적인 문헌 검토를 통해 의료, 교육, 보안, 공공 행정, 생성 AI, 자율주행차 등 다양한 분야에서 인공지능 수용 또는 저항에 영향을 미치는 요인들을 분석했습니다. 연구는 개인적, 맥락적, 기술적 요인들이 인식에 미치는 영향을 강조하며, 기관 신뢰, 공정성 인식, 윤리적 우려의 변화를 추적합니다. AI에 대한 대중의 인식은 기술적 설계나 성능뿐만 아니라 분야별 고려사항, 문화적 서사, 역사적 유산에 의해 형성된다는 것을 보여줍니다. 이러한 비교 접근법은 책임 있는 AI 거버넌스를 위한 맞춤형 전략 개발의 기초를 제공합니다.

## 🎯 주요 포인트

- 1. 2011년부터 2025년까지 발표된 251개의 연구를 대상으로 AI에 대한 대중의 태도를 비교 분석했습니다.
- 2. AI 수용 또는 저항에 영향을 미치는 요인으로 인식된 이점과 우려(위험)를 분석했습니다.
- 3. 개인적, 맥락적, 기술적 요인이 AI에 대한 인식에 미치는 반복적인 패턴을 강조했습니다.
- 4. AI에 대한 대중의 인식은 기술적 설계나 성능뿐만 아니라 분야별 고려사항, 상상, 문화적 서사, 역사적 유산에 의해 형성됩니다.
- 5. 이 비교적 접근법은 책임 있는 AI 거버넌스를 위한 맞춤형 및 맥락 민감한 전략 개발의 기초를 제공합니다.


---

*Generated on 2025-09-24 13:43:55*