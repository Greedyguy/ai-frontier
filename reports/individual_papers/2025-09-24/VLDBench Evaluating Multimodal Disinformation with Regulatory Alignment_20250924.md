<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T15:49:23.585806",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "VLDBench",
    "Multimodal Disinformation",
    "Vision-Language Model",
    "AI Governance Framework"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "VLDBench": 0.8,
    "Multimodal Disinformation": 0.85,
    "Vision-Language Model": 0.88,
    "AI Governance Framework": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "VLDBench",
        "canonical": "VLDBench",
        "aliases": [
          "Vision-Language Disinformation Detection Benchmark"
        ],
        "category": "unique_technical",
        "rationale": "VLDBench is a unique benchmark specifically designed for evaluating multimodal disinformation, providing a new resource for AI research.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "Multimodal Disinformation",
        "canonical": "Multimodal Disinformation",
        "aliases": [
          "Multimodal Fake News"
        ],
        "category": "specific_connectable",
        "rationale": "Understanding multimodal disinformation is crucial for developing models that can handle complex data types, enhancing connectivity with related research.",
        "novelty_score": 0.7,
        "connectivity_score": 0.85,
        "specificity_score": 0.8,
        "link_intent_score": 0.85
      },
      {
        "surface": "Vision-Language Models",
        "canonical": "Vision-Language Model",
        "aliases": [
          "VLMs"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-Language Models represent an evolved concept in AI, crucial for linking research on multimodal data processing.",
        "novelty_score": 0.6,
        "connectivity_score": 0.9,
        "specificity_score": 0.75,
        "link_intent_score": 0.88
      },
      {
        "surface": "AI Governance Frameworks",
        "canonical": "AI Governance Framework",
        "aliases": [
          "AI Risk Management"
        ],
        "category": "broad_technical",
        "rationale": "AI Governance Frameworks are essential for aligning AI development with ethical standards, providing a broad technical context.",
        "novelty_score": 0.55,
        "connectivity_score": 0.7,
        "specificity_score": 0.65,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "disinformation",
      "benchmark",
      "text-image pairs"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "VLDBench",
      "resolved_canonical": "VLDBench",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Multimodal Disinformation",
      "resolved_canonical": "Multimodal Disinformation",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.85,
        "specificity": 0.8,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Vision-Language Models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.9,
        "specificity": 0.75,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "AI Governance Frameworks",
      "resolved_canonical": "AI Governance Framework",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.7,
        "specificity": 0.65,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# VLDBench Evaluating Multimodal Disinformation with Regulatory Alignment

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2502.11361.pdf)
**Category**: cs.CL
**Published**: 2025-09-24
**ArXiv ID**: [2502.11361](https://arxiv.org/abs/2502.11361)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/VLA-Mark_ A cross modal watermark for large vision-language alignment model_20250922|VLA-Mark: A cross modal watermark for large vision-language alignment model]] (83.3% similar)
- [[2025-09-19/Rationality Check! Benchmarking the Rationality of Large Language Models_20250919|Rationality Check! Benchmarking the Rationality of Large Language Models]] (82.9% similar)
- [[2025-09-24/VIR-Bench_ Evaluating Geospatial and Temporal Understanding of MLLMs via Travel Video Itinerary Reconstruction_20250924|VIR-Bench: Evaluating Geospatial and Temporal Understanding of MLLMs via Travel Video Itinerary Reconstruction]] (82.6% similar)
- [[2025-09-17/VCBench_ Benchmarking LLMs in Venture Capital_20250917|VCBench: Benchmarking LLMs in Venture Capital]] (82.6% similar)
- [[2025-09-23/OpenGVL - Benchmarking Visual Temporal Progress for Data Curation_20250923|OpenGVL - Benchmarking Visual Temporal Progress for Data Curation]] (82.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/AI Governance Framework|AI Governance Framework]]
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Disinformation|Multimodal Disinformation]]
**âš¡ Unique Technical**: [[keywords/VLDBench|VLDBench]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2502.11361v4 Announce Type: replace 
Abstract: Detecting disinformation that blends manipulated text and images has become increasingly challenging, as AI tools make synthetic content easy to generate and disseminate. While most existing AI safety benchmarks focus on single modality misinformation (i.e., false content shared without intent to deceive), intentional multimodal disinformation, such as propaganda or conspiracy theories that imitate credible news, remains largely unaddressed. We introduce the Vision-Language Disinformation Detection Benchmark (VLDBench), the first large-scale resource supporting both unimodal (text-only) and multimodal (text + image) disinformation detection. VLDBench comprises approximately 62,000 labeled text-image pairs across 13 categories, curated from 58 news outlets. Using a semi-automated pipeline followed by expert review, 22 domain experts invested over 500 hours to produce high-quality annotations with substantial inter-annotator agreement. Evaluations of state-of-the-art Large Language Models (LLMs) and Vision-Language Models (VLMs) on VLDBench show that incorporating visual cues improves detection accuracy by 5 to 35 percentage points over text-only models. VLDBench provides data and code for evaluation, fine-tuning, and robustness testing to support disinformation analysis. Developed in alignment with AI governance frameworks (e.g., the MIT AI Risk Repository), VLDBench offers a principled foundation for advancing trustworthy disinformation detection in multimodal media.
  Project: https://vectorinstitute.github.io/VLDBench/ Dataset: https://huggingface.co/datasets/vector-institute/VLDBench Code: https://github.com/VectorInstitute/VLDBench

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì¡°ì‘ëœ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ ê²°í•©í•œ í—ˆìœ„ ì •ë³´ë¥¼ íƒì§€í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ì¸ VLDBenchë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ì´ëŠ” í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ê°€ ê²°í•©ëœ ë©€í‹°ëª¨ë‹¬ í—ˆìœ„ ì •ë³´ íƒì§€ë¥¼ ì§€ì›í•˜ëŠ” ìµœì´ˆì˜ ëŒ€ê·œëª¨ ìì›ìœ¼ë¡œ, 13ê°œ ì¹´í…Œê³ ë¦¬ì—ì„œ ì•½ 62,000ê°œì˜ ë¼ë²¨ë§ëœ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ìŒì„ í¬í•¨í•©ë‹ˆë‹¤. 22ëª…ì˜ ë„ë©”ì¸ ì „ë¬¸ê°€ê°€ 500ì‹œê°„ ì´ìƒì„ íˆ¬ìí•˜ì—¬ ë†’ì€ í’ˆì§ˆì˜ ì£¼ì„ì„ ì‘ì„±í–ˆìœ¼ë©°, ìµœì‹  ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ê³¼ ë¹„ì „-ì–¸ì–´ ëª¨ë¸ì„ í‰ê°€í•œ ê²°ê³¼, ì‹œê°ì  ë‹¨ì„œë¥¼ í¬í•¨í•˜ë©´ í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸ì— ë¹„í•´ íƒì§€ ì •í™•ë„ê°€ 5~35% í¬ì¸íŠ¸ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤. VLDBenchëŠ” AI ê±°ë²„ë„ŒìŠ¤ í”„ë ˆì„ì›Œí¬ì— ë”°ë¼ ê°œë°œë˜ì–´ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë©€í‹°ëª¨ë‹¬ ë¯¸ë””ì–´ í—ˆìœ„ ì •ë³´ íƒì§€ë¥¼ ìœ„í•œ ê¸°ë°˜ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. VLDBenchëŠ” í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ ê²°í•©í•œ ë©€í‹°ëª¨ë‹¬ í—ˆìœ„ì •ë³´ íƒì§€ë¥¼ ì§€ì›í•˜ëŠ” ìµœì´ˆì˜ ëŒ€ê·œëª¨ ë²¤ì¹˜ë§ˆí¬ì…ë‹ˆë‹¤.
- 2. ì´ ë²¤ì¹˜ë§ˆí¬ëŠ” 13ê°œ ì¹´í…Œê³ ë¦¬ì—ì„œ ì•½ 62,000ê°œì˜ ë ˆì´ë¸”ì´ ì§€ì •ëœ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ìŒìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
- 3. VLDBenchëŠ” ì‹œê°ì  ë‹¨ì„œë¥¼ í¬í•¨í•  ë•Œ íƒì§€ ì •í™•ë„ê°€ 5~35% í¬ì¸íŠ¸ í–¥ìƒëœë‹¤ëŠ” í‰ê°€ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
- 4. ì´ ë²¤ì¹˜ë§ˆí¬ëŠ” AI ê±°ë²„ë„ŒìŠ¤ í”„ë ˆì„ì›Œí¬ì™€ì˜ ì •ë ¬ì„ í†µí•´ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” í—ˆìœ„ì •ë³´ íƒì§€ë¥¼ ìœ„í•œ ê¸°ë°˜ì„ ì œê³µí•©ë‹ˆë‹¤.
- 5. VLDBenchëŠ” ë°ì´í„°ì™€ ì½”ë“œë¥¼ ì œê³µí•˜ì—¬ í‰ê°€, ë¯¸ì„¸ ì¡°ì • ë° ê°•ê±´ì„± í…ŒìŠ¤íŠ¸ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 15:49:23*