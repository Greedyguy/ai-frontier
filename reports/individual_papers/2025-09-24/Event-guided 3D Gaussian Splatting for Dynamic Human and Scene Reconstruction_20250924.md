<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T16:02:26.161174",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "3D Gaussian Splatting",
    "Event Camera",
    "Human-Scene Reconstruction",
    "Event-Guided Loss"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "3D Gaussian Splatting": 0.8,
    "Event Camera": 0.82,
    "Human-Scene Reconstruction": 0.75,
    "Event-Guided Loss": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "3D Gaussian Splatting",
        "canonical": "3D Gaussian Splatting",
        "aliases": [
          "Gaussian Splatting"
        ],
        "category": "unique_technical",
        "rationale": "This technique is central to the paper's method and offers a unique approach to human-scene reconstruction.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "Event Camera",
        "canonical": "Event Camera",
        "aliases": [
          "Dynamic Vision Sensor"
        ],
        "category": "specific_connectable",
        "rationale": "Event cameras are crucial for handling fast motion and reducing blur, linking to dynamic vision research.",
        "novelty_score": 0.7,
        "connectivity_score": 0.78,
        "specificity_score": 0.85,
        "link_intent_score": 0.82
      },
      {
        "surface": "Human-Scene Reconstruction",
        "canonical": "Human-Scene Reconstruction",
        "aliases": [
          "Dynamic Human Reconstruction"
        ],
        "category": "broad_technical",
        "rationale": "This is the core application area of the paper, relevant to computer vision and 3D modeling fields.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.75
      },
      {
        "surface": "Event-Guided Loss",
        "canonical": "Event-Guided Loss",
        "aliases": [
          "Event-Based Loss"
        ],
        "category": "unique_technical",
        "rationale": "The event-guided loss is a novel contribution that enhances reconstruction fidelity, especially in dynamic scenes.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "monocular videos",
      "motion blur",
      "PSNR/SSIM",
      "LPIPS"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "3D Gaussian Splatting",
      "resolved_canonical": "3D Gaussian Splatting",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Event Camera",
      "resolved_canonical": "Event Camera",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.78,
        "specificity": 0.85,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Human-Scene Reconstruction",
      "resolved_canonical": "Human-Scene Reconstruction",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Event-Guided Loss",
      "resolved_canonical": "Event-Guided Loss",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# Event-guided 3D Gaussian Splatting for Dynamic Human and Scene Reconstruction

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18566.pdf)
**Category**: cs.CV
**Published**: 2025-09-24
**ArXiv ID**: [2509.18566](https://arxiv.org/abs/2509.18566)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/FMGS-Avatar_ Mesh-Guided 2D Gaussian Splatting with Foundation Model Priors for 3D Monocular Avatar Reconstruction_20250919|FMGS-Avatar: Mesh-Guided 2D Gaussian Splatting with Foundation Model Priors for 3D Monocular Avatar Reconstruction]] (86.6% similar)
- [[2025-09-23/ProDyG_ Progressive Dynamic Scene Reconstruction via Gaussian Splatting from Monocular Videos_20250923|ProDyG: Progressive Dynamic Scene Reconstruction via Gaussian Splatting from Monocular Videos]] (86.3% similar)
- [[2025-09-22/MS-GS_ Multi-Appearance Sparse-View 3D Gaussian Splatting in the Wild_20250922|MS-GS: Multi-Appearance Sparse-View 3D Gaussian Splatting in the Wild]] (84.8% similar)
- [[2025-09-22/Recovering Parametric Scenes from Very Few Time-of-Flight Pixels_20250922|Recovering Parametric Scenes from Very Few Time-of-Flight Pixels]] (84.6% similar)
- [[2025-09-23/Uni3C_ Unifying Precisely 3D-Enhanced Camera and Human Motion Controls for Video Generation_20250923|Uni3C: Unifying Precisely 3D-Enhanced Camera and Human Motion Controls for Video Generation]] (84.4% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Human-Scene Reconstruction|Human-Scene Reconstruction]]
**ğŸ”— Specific Connectable**: [[keywords/Event Camera|Event Camera]]
**âš¡ Unique Technical**: [[keywords/3D Gaussian Splatting|3D Gaussian Splatting]], [[keywords/Event-Guided Loss|Event-Guided Loss]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18566v1 Announce Type: new 
Abstract: Reconstructing dynamic humans together with static scenes from monocular videos remains difficult, especially under fast motion, where RGB frames suffer from motion blur. Event cameras exhibit distinct advantages, e.g., microsecond temporal resolution, making them a superior sensing choice for dynamic human reconstruction. Accordingly, we present a novel event-guided human-scene reconstruction framework that jointly models human and scene from a single monocular event camera via 3D Gaussian Splatting. Specifically, a unified set of 3D Gaussians carries a learnable semantic attribute; only Gaussians classified as human undergo deformation for animation, while scene Gaussians stay static. To combat blur, we propose an event-guided loss that matches simulated brightness changes between consecutive renderings with the event stream, improving local fidelity in fast-moving regions. Our approach removes the need for external human masks and simplifies managing separate Gaussian sets. On two benchmark datasets, ZJU-MoCap-Blur and MMHPSD-Blur, it delivers state-of-the-art human-scene reconstruction, with notable gains over strong baselines in PSNR/SSIM and reduced LPIPS, especially for high-speed subjects.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë‹¨ì•ˆ ë¹„ë””ì˜¤ì—ì„œ ì—­ë™ì ì¸ ì¸ê°„ê³¼ ì •ì  ì¥ë©´ì„ ì¬êµ¬ì„±í•˜ëŠ” ë¬¸ì œë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. íŠ¹íˆ ë¹ ë¥¸ ì›€ì§ì„ìœ¼ë¡œ ì¸í•´ ë°œìƒí•˜ëŠ” ëª¨ì…˜ ë¸”ëŸ¬ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ë§ˆì´í¬ë¡œì´ˆ ë‹¨ìœ„ì˜ ì‹œê°„ í•´ìƒë„ë¥¼ ì œê³µí•˜ëŠ” ì´ë²¤íŠ¸ ì¹´ë©”ë¼ë¥¼ í™œìš©í•œ ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” 3D Gaussian Splattingì„ í†µí•´ ì¸ê°„ê³¼ ì¥ë©´ì„ ëª¨ë¸ë§í•˜ë©°, ì¸ê°„ìœ¼ë¡œ ë¶„ë¥˜ëœ ê°€ìš°ì‹œì•ˆë§Œ ë³€í˜•ë˜ì–´ ì• ë‹ˆë©”ì´ì…˜ì„ êµ¬í˜„í•©ë‹ˆë‹¤. ëª¨ì…˜ ë¸”ëŸ¬ë¥¼ ì¤„ì´ê¸° ìœ„í•´ ì´ë²¤íŠ¸ ìœ ë„ ì†ì‹¤ì„ ë„ì…í•˜ì—¬, ì—°ì† ë Œë”ë§ ê°„ì˜ ë°ê¸° ë³€í™”ë¥¼ ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼ê³¼ ì¼ì¹˜ì‹œí‚µë‹ˆë‹¤. ì´ ë°©ë²•ì€ ì™¸ë¶€ ì¸ê°„ ë§ˆìŠ¤í¬ê°€ í•„ìš” ì—†ìœ¼ë©°, ë³„ë„ì˜ ê°€ìš°ì‹œì•ˆ ì„¸íŠ¸ë¥¼ ê´€ë¦¬í•˜ëŠ” ë³µì¡ì„±ì„ ì¤„ì…ë‹ˆë‹¤. ì œì•ˆëœ ë°©ë²•ì€ ZJU-MoCap-Blur ë° MMHPSD-Blur ë°ì´í„°ì…‹ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë³´ì´ë©°, íŠ¹íˆ ê³ ì† ì›€ì§ì„ì—ì„œ PSNR/SSIM ë° LPIPSì—ì„œ ê°•ë ¥í•œ ê¸°ì¤€ì„ ë³´ë‹¤ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë‹¨ì•ˆ ë¹„ë””ì˜¤ì—ì„œ ì—­ë™ì ì¸ ì¸ê°„ê³¼ ì •ì  ì¥ë©´ì„ ì¬êµ¬ì„±í•˜ëŠ” ê²ƒì€ íŠ¹íˆ ë¹ ë¥¸ ì›€ì§ì„ì—ì„œ ì–´ë ¤ì›€ì„ ê²ªì§€ë§Œ, ì´ë²¤íŠ¸ ì¹´ë©”ë¼ëŠ” ë§ˆì´í¬ë¡œì´ˆ ë‹¨ìœ„ì˜ ì‹œê°„ í•´ìƒë„ë¥¼ ì œê³µí•˜ì—¬ ì´ë¥¼ ê·¹ë³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- 2. ì œì•ˆëœ í”„ë ˆì„ì›Œí¬ëŠ” ë‹¨ì¼ ë‹¨ì•ˆ ì´ë²¤íŠ¸ ì¹´ë©”ë¼ë¥¼ í†µí•´ 3D ê°€ìš°ì‹œì•ˆ ìŠ¤í”Œë˜íŒ…ì„ ì‚¬ìš©í•˜ì—¬ ì¸ê°„ê³¼ ì¥ë©´ì„ ê³µë™ìœ¼ë¡œ ëª¨ë¸ë§í•©ë‹ˆë‹¤.
- 3. ì´ë²¤íŠ¸ ìœ ë„ ì†ì‹¤ì„ í†µí•´ ì—°ì† ë Œë”ë§ ê°„ì˜ ë°ê¸° ë³€í™”ë¥¼ ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼ê³¼ ì¼ì¹˜ì‹œì¼œ ë¹ ë¥´ê²Œ ì›€ì§ì´ëŠ” ì˜ì—­ì˜ ì§€ì—­ì  ì¶©ì‹¤ë„ë¥¼ ê°œì„ í•©ë‹ˆë‹¤.
- 4. ì™¸ë¶€ ì¸ê°„ ë§ˆìŠ¤í¬ê°€ í•„ìš”í•˜ì§€ ì•Šìœ¼ë©°, ë³„ë„ì˜ ê°€ìš°ì‹œì•ˆ ì„¸íŠ¸ë¥¼ ê´€ë¦¬í•˜ëŠ” ë³µì¡ì„±ì„ ì¤„ì…ë‹ˆë‹¤.
- 5. ZJU-MoCap-Blur ë° MMHPSD-Blur ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì—ì„œ PSNR/SSIM ë° LPIPSì—ì„œ ê°•ë ¥í•œ ê¸°ì¤€ì„  ëŒ€ë¹„ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.


---

*Generated on 2025-09-24 16:02:26*