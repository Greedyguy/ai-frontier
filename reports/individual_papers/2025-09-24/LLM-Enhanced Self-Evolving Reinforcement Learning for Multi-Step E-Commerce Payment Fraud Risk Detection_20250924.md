<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T14:54:44.342705",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Reinforcement Learning",
    "Zero-Shot Learning",
    "Markov Decision Process"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Reinforcement Learning": 0.82,
    "Zero-Shot Learning": 0.79,
    "Markov Decision Process": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Large Language Models"
        ],
        "category": "broad_technical",
        "rationale": "LLMs are central to the paper's approach and connect to various advanced AI applications.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Reinforcement Learning",
        "canonical": "Reinforcement Learning",
        "aliases": [
          "RL"
        ],
        "category": "broad_technical",
        "rationale": "Reinforcement Learning is a key component of the proposed method, linking to many AI optimization techniques.",
        "novelty_score": 0.4,
        "connectivity_score": 0.85,
        "specificity_score": 0.75,
        "link_intent_score": 0.82
      },
      {
        "surface": "Zero-Shot Capability",
        "canonical": "Zero-Shot Learning",
        "aliases": [
          "Zero-Shot"
        ],
        "category": "specific_connectable",
        "rationale": "Zero-Shot Learning highlights the model's ability to generalize without prior examples, a trending topic in AI.",
        "novelty_score": 0.65,
        "connectivity_score": 0.78,
        "specificity_score": 0.8,
        "link_intent_score": 0.79
      },
      {
        "surface": "Markov Decision Process",
        "canonical": "Markov Decision Process",
        "aliases": [
          "MDP"
        ],
        "category": "specific_connectable",
        "rationale": "MDP is crucial for understanding the multi-step decision framework used in the paper.",
        "novelty_score": 0.55,
        "connectivity_score": 0.77,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Reinforcement Learning",
      "resolved_canonical": "Reinforcement Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.85,
        "specificity": 0.75,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Zero-Shot Capability",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.78,
        "specificity": 0.8,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Markov Decision Process",
      "resolved_canonical": "Markov Decision Process",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.77,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# LLM-Enhanced Self-Evolving Reinforcement Learning for Multi-Step E-Commerce Payment Fraud Risk Detection

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18719.pdf)
**Category**: cs.LG
**Published**: 2025-09-24
**ArXiv ID**: [2509.18719](https://arxiv.org/abs/2509.18719)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Reinforcement Learning Meets Large Language Models_ A Survey of Advancements and Applications Across the LLM Lifecycle_20250923|Reinforcement Learning Meets Large Language Models: A Survey of Advancements and Applications Across the LLM Lifecycle]] (87.1% similar)
- [[2025-09-23/ConfClip_ Confidence-Weighted and Clipped Reward for Reinforcement Learning in LLMs_20250923|ConfClip: Confidence-Weighted and Clipped Reward for Reinforcement Learning in LLMs]] (85.9% similar)
- [[2025-09-24/Reinforcement Learning on Pre-Training Data_20250924|Reinforcement Learning on Pre-Training Data]] (85.7% similar)
- [[2025-09-19/Zero-Shot LLMs in Human-in-the-Loop RL_ Replacing Human Feedback for Reward Shaping_20250919|Zero-Shot LLMs in Human-in-the-Loop RL: Replacing Human Feedback for Reward Shaping]] (85.2% similar)
- [[2025-09-22/Entropy-Regularized Process Reward Model_20250922|Entropy-Regularized Process Reward Model]] (84.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]], [[keywords/Reinforcement Learning|Reinforcement Learning]]
**ğŸ”— Specific Connectable**: [[keywords/Zero-Shot Learning|Zero-Shot Learning]], [[keywords/Markov Decision Process|Markov Decision Process]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18719v1 Announce Type: new 
Abstract: This paper presents a novel approach to e-commerce payment fraud detection by integrating reinforcement learning (RL) with Large Language Models (LLMs). By framing transaction risk as a multi-step Markov Decision Process (MDP), RL optimizes risk detection across multiple payment stages. Crafting effective reward functions, essential for RL model success, typically requires significant human expertise due to the complexity and variability in design. LLMs, with their advanced reasoning and coding capabilities, are well-suited to refine these functions, offering improvements over traditional methods. Our approach leverages LLMs to iteratively enhance reward functions, achieving better fraud detection accuracy and demonstrating zero-shot capability. Experiments with real-world data confirm the effectiveness, robustness, and resilience of our LLM-enhanced RL framework through long-term evaluations, underscoring the potential of LLMs in advancing industrial RL applications.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ê°•í™” í•™ìŠµ(RL)ê³¼ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ ê²°í•©í•˜ì—¬ ì „ììƒê±°ë˜ ê²°ì œ ì‚¬ê¸° íƒì§€ë¥¼ í˜ì‹ ì ìœ¼ë¡œ ê°œì„ í•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê±°ë˜ ìœ„í—˜ì„ ë‹¤ë‹¨ê³„ ë§ˆë¥´ì½”í”„ ê²°ì • ê³¼ì •(MDP)ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì—¬ëŸ¬ ê²°ì œ ë‹¨ê³„ì—ì„œ ìœ„í—˜ íƒì§€ë¥¼ ìµœì í™”í•©ë‹ˆë‹¤. RL ëª¨ë¸ì˜ ì„±ê³µì„ ìœ„í•´ ì¤‘ìš”í•œ ë³´ìƒ í•¨ìˆ˜ ì„¤ê³„ëŠ” ë³µì¡ì„±ê³¼ ë³€ë™ì„± ë•Œë¬¸ì— ìƒë‹¹í•œ ì „ë¬¸ ì§€ì‹ì„ ìš”êµ¬í•˜ì§€ë§Œ, LLMì€ ì´ë¥¼ ê°œì„ í•˜ì—¬ ì „í†µì ì¸ ë°©ë²•ë³´ë‹¤ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. LLMì„ í™œìš©í•´ ë³´ìƒ í•¨ìˆ˜ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ê°œì„ í•¨ìœ¼ë¡œì¨ ì‚¬ê¸° íƒì§€ ì •í™•ë„ë¥¼ ë†’ì´ê³ , ì œë¡œìƒ· ëŠ¥ë ¥ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤. ì‹¤ì œ ë°ì´í„° ì‹¤í—˜ì„ í†µí•´ LLM ê°•í™” RL í”„ë ˆì„ì›Œí¬ì˜ íš¨ê³¼ì™€ ê°•ì¸í•¨ì„ í™•ì¸í–ˆìœ¼ë©°, ì‚°ì—… RL ì‘ìš© ë¶„ì•¼ì—ì„œ LLMì˜ ì ì¬ë ¥ì„ ê°•ì¡°í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì´ ë…¼ë¬¸ì€ ê°•í™” í•™ìŠµ(RL)ê³¼ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ í†µí•©í•˜ì—¬ ì „ì ìƒê±°ë˜ ê²°ì œ ì‚¬ê¸° íƒì§€ë¥¼ ê°œì„ í•˜ëŠ” ìƒˆë¡œìš´ ì ‘ê·¼ ë°©ì‹ì„ ì œì•ˆí•©ë‹ˆë‹¤.
- 2. ê±°ë˜ ìœ„í—˜ì„ ë‹¤ë‹¨ê³„ ë§ˆë¥´ì½”í”„ ê²°ì • í”„ë¡œì„¸ìŠ¤(MDP)ë¡œ ì„¤ì •í•˜ì—¬ RLì´ ì—¬ëŸ¬ ê²°ì œ ë‹¨ê³„ì—ì„œ ìœ„í—˜ íƒì§€ë¥¼ ìµœì í™”í•©ë‹ˆë‹¤.
- 3. LLMì€ ë³µì¡í•˜ê³  ë‹¤ì–‘í•œ ë³´ìƒ í•¨ìˆ˜ ì„¤ê³„ì—ì„œ ì „í†µì ì¸ ë°©ë²•ë³´ë‹¤ ê°œì„ ëœ ê¸°ëŠ¥ì„ ì œê³µí•˜ì—¬ RL ëª¨ë¸ì˜ ì„±ê³µì„ ë•ìŠµë‹ˆë‹¤.
- 4. ì‹¤ì œ ë°ì´í„° ì‹¤í—˜ì„ í†µí•´ LLMì´ ê°•í™”ëœ RL í”„ë ˆì„ì›Œí¬ì˜ íš¨ê³¼, ê²¬ê³ ì„± ë° íšŒë³µë ¥ì„ ì¥ê¸°ì ìœ¼ë¡œ í‰ê°€í•˜ì—¬ ì…ì¦í–ˆìŠµë‹ˆë‹¤.
- 5. LLMì˜ ì œë¡œìƒ· ëŠ¥ë ¥ì„ í™œìš©í•˜ì—¬ ë³´ìƒ í•¨ìˆ˜ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ê°œì„ í•¨ìœ¼ë¡œì¨ ì‚¬ê¸° íƒì§€ ì •í™•ë„ë¥¼ ë†’ì˜€ìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 14:54:44*