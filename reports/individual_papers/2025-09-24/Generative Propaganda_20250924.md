<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T14:14:09.681134",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Generative Propaganda",
    "Deepfakes",
    "Efficiency Gains in AI Communication",
    "AI Threat Models"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Generative Propaganda": 0.9,
    "Deepfakes": 0.8,
    "Efficiency Gains in AI Communication": 0.75,
    "AI Threat Models": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Generative Propaganda",
        "canonical": "Generative Propaganda",
        "aliases": [
          "AI-driven Propaganda",
          "Automated Propaganda"
        ],
        "category": "unique_technical",
        "rationale": "This term represents a novel application of AI in the context of shaping public opinion, which is central to the paper's theme.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.88,
        "link_intent_score": 0.9
      },
      {
        "surface": "Deepfakes",
        "canonical": "Deepfakes",
        "aliases": [
          "Synthetic Media",
          "AI-generated Media"
        ],
        "category": "specific_connectable",
        "rationale": "Deepfakes are a well-known application of AI that directly relates to the paper's focus on misuse and intervention strategies.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Efficiency Gains",
        "canonical": "Efficiency Gains in AI Communication",
        "aliases": [
          "AI Efficiency",
          "Communication Efficiency"
        ],
        "category": "evolved_concepts",
        "rationale": "The concept of efficiency gains in AI communication is significant for understanding the broader impact of AI applications.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.7,
        "link_intent_score": 0.75
      },
      {
        "surface": "Threat Models",
        "canonical": "AI Threat Models",
        "aliases": [
          "Security Threat Models",
          "Risk Models"
        ],
        "category": "specific_connectable",
        "rationale": "Threat models are crucial for understanding and mitigating the risks associated with AI misuse, as discussed in the paper.",
        "novelty_score": 0.55,
        "connectivity_score": 0.8,
        "specificity_score": 0.75,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "public opinion",
      "interviews",
      "real-world settings"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Generative Propaganda",
      "resolved_canonical": "Generative Propaganda",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.88,
        "link_intent": 0.9
      }
    },
    {
      "candidate_surface": "Deepfakes",
      "resolved_canonical": "Deepfakes",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Efficiency Gains",
      "resolved_canonical": "Efficiency Gains in AI Communication",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.7,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Threat Models",
      "resolved_canonical": "AI Threat Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.8,
        "specificity": 0.75,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# Generative Propaganda

## 📋 메타데이터

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19147.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2509.19147](https://arxiv.org/abs/2509.19147)

## 🔗 유사한 논문
- [[2025-09-24/Zero-Shot Visual Deepfake Detection_ Can AI Predict and Prevent Fake Content Before It's Created?_20250924|Zero-Shot Visual Deepfake Detection: Can AI Predict and Prevent Fake Content Before It's Created?]] (85.9% similar)
- [[2025-09-23/Is It Certainly a Deepfake? Reliability Analysis in Detection & Generation Ecosystem_20250923|Is It Certainly a Deepfake? Reliability Analysis in Detection & Generation Ecosystem]] (83.4% similar)
- [[2025-09-24/Anecdoctoring_ Automated Red-Teaming Across Language and Place_20250924|Anecdoctoring: Automated Red-Teaming Across Language and Place]] (83.1% similar)
- [[2025-09-22/The Great AI Witch Hunt_ Reviewers Perception and (Mis)Conception of Generative AI in Research Writing_20250922|The Great AI Witch Hunt: Reviewers Perception and (Mis)Conception of Generative AI in Research Writing]] (82.2% similar)
- [[2025-09-19/JU-NLP at Touch\'e_ Covert Advertisement in Conversational AI-Generation and Detection Strategies_20250919|JU-NLP at Touch\'e: Covert Advertisement in Conversational AI-Generation and Detection Strategies]] (81.8% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Deepfakes|Deepfakes]], [[keywords/AI Threat Models|AI Threat Models]]
**⚡ Unique Technical**: [[keywords/Generative Propaganda|Generative Propaganda]]
**🚀 Evolved Concepts**: [[keywords/Efficiency Gains in AI Communication|Efficiency Gains in AI Communication]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.19147v1 Announce Type: cross 
Abstract: Generative propaganda is the use of generative artificial intelligence (AI) to shape public opinion. To characterize its use in real-world settings, we conducted interviews with defenders (e.g., factcheckers, journalists, officials) in Taiwan and creators (e.g., influencers, political consultants, advertisers) as well as defenders in India, centering two places characterized by high levels of online propaganda. The term "deepfakes", we find, exerts outsized discursive power in shaping defenders' expectations of misuse and, in turn, the interventions that are prioritized. To better characterize the space of generative propaganda, we develop a taxonomy that distinguishes between obvious versus hidden and promotional versus derogatory use. Deception was neither the main driver nor the main impact vector of AI's use; instead, Indian creators sought to persuade rather than to deceive, often making AI's use obvious in order to reduce legal and reputational risks, while Taiwan's defenders saw deception as a subset of broader efforts to distort the prevalence of strategic narratives online. AI was useful and used, however, in producing efficiency gains in communicating across languages and modes, and in evading human and algorithmic detection. Security researchers should reconsider threat models to clearly differentiate deepfakes from promotional and obvious uses, to complement and bolster the social factors that constrain misuse by internal actors, and to counter efficiency gains globally.

## 📝 요약

생성적 선전은 생성적 인공지능(AI)을 활용하여 대중의 의견을 형성하는 것을 의미합니다. 본 연구는 대만과 인도의 사실 확인자, 언론인, 인플루언서 등을 인터뷰하여 실제 사례를 분석하였습니다. 연구 결과, "딥페이크"라는 용어가 방어자들의 오용에 대한 기대와 우선시되는 개입에 큰 영향을 미친다는 것을 발견했습니다. 우리는 생성적 선전의 유형을 명확히 하기 위해 명백한 사용과 숨겨진 사용, 홍보적 사용과 비방적 사용을 구분하는 분류 체계를 개발했습니다. 인도의 창작자들은 AI를 사용하여 설득을 목표로 하였으며, 대만의 방어자들은 AI 사용을 전략적 내러티브 왜곡의 일환으로 보았습니다. AI는 언어와 모드를 넘나드는 효율성 향상에 기여했으며, 보안 연구자들은 딥페이크와 홍보적 사용을 명확히 구분하여 내적 행위자의 오용을 억제하는 사회적 요인을 강화해야 한다고 제안합니다.

## 🎯 주요 포인트

- 1. 생성적 선전은 생성적 인공지능(AI)을 활용하여 대중의 의견을 형성하는 것을 의미한다.
- 2. 대만과 인도의 사례 연구를 통해 생성적 선전의 사용을 분석하고, 방어자와 창작자의 관점을 조사하였다.
- 3. "딥페이크"라는 용어는 방어자들의 오용에 대한 기대와 우선시되는 개입에 큰 영향을 미친다.
- 4. 인도에서는 AI의 사용이 법적 및 평판적 위험을 줄이기 위해 설득을 목적으로 하며, 대만에서는 전략적 내러티브 왜곡의 일환으로 간주된다.
- 5. 보안 연구자들은 딥페이크와 홍보적, 명백한 사용을 명확히 구분하여 내부 행위자에 의한 오용을 억제하는 사회적 요인을 보완해야 한다.


---

*Generated on 2025-09-24 14:14:09*