<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T13:31:02.850886",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Agent Hallucinations",
    "Taxonomy of Agent Hallucinations",
    "Hallucination Mitigation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Agent Hallucinations": 0.78,
    "Taxonomy of Agent Hallucinations": 0.77,
    "Hallucination Mitigation": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "LLM-based agents",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM agents"
        ],
        "category": "broad_technical",
        "rationale": "Connects to the broader concept of Large Language Models, which is central to the paper's discussion on hallucinations.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "hallucination issues",
        "canonical": "Agent Hallucinations",
        "aliases": [
          "hallucinations in agents",
          "hallucination problems"
        ],
        "category": "unique_technical",
        "rationale": "Focuses on a specific problem within LLM-based agents, crucial for understanding and addressing system reliability.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "taxonomy of hallucinations",
        "canonical": "Taxonomy of Agent Hallucinations",
        "aliases": [
          "hallucination taxonomy"
        ],
        "category": "unique_technical",
        "rationale": "Provides a structured framework for understanding different types of hallucinations, aiding in systematic study and mitigation.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      },
      {
        "surface": "hallucination mitigation",
        "canonical": "Hallucination Mitigation",
        "aliases": [
          "mitigation of hallucinations"
        ],
        "category": "specific_connectable",
        "rationale": "Key approach for improving the reliability of LLM-based agents, linking to methods and future research directions.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.78,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "workflow",
      "system design",
      "task execution"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "LLM-based agents",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "hallucination issues",
      "resolved_canonical": "Agent Hallucinations",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "taxonomy of hallucinations",
      "resolved_canonical": "Taxonomy of Agent Hallucinations",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "hallucination mitigation",
      "resolved_canonical": "Hallucination Mitigation",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.78,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# LLM-based Agents Suffer from Hallucinations: A Survey of Taxonomy, Methods, and Directions

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18970.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2509.18970](https://arxiv.org/abs/2509.18970)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/How Large Language Models are Designed to Hallucinate_20250923|How Large Language Models are Designed to Hallucinate]] (88.8% similar)
- [[2025-09-23/Generalizability of Large Language Model-Based Agents_ A Comprehensive Survey_20250923|Generalizability of Large Language Model-Based Agents: A Comprehensive Survey]] (86.9% similar)
- [[2025-09-23/Overhearing LLM Agents_ A Survey, Taxonomy, and Roadmap_20250923|Overhearing LLM Agents: A Survey, Taxonomy, and Roadmap]] (85.1% similar)
- [[2025-09-22/Knowledge-Driven Hallucination in Large Language Models_ An Empirical Study on Process Modeling_20250922|Knowledge-Driven Hallucination in Large Language Models: An Empirical Study on Process Modeling]] (84.5% similar)
- [[2025-09-23/Runaway is Ashamed, But Helpful_ On the Early-Exit Behavior of Large Language Model-based Agents in Embodied Environments_20250923|Runaway is Ashamed, But Helpful: On the Early-Exit Behavior of Large Language Model-based Agents in Embodied Environments]] (84.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Hallucination Mitigation|Hallucination Mitigation]]
**âš¡ Unique Technical**: [[keywords/Agent Hallucinations|Agent Hallucinations]], [[keywords/Taxonomy of Agent Hallucinations|Taxonomy of Agent Hallucinations]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18970v1 Announce Type: new 
Abstract: Driven by the rapid advancements of Large Language Models (LLMs), LLM-based agents have emerged as powerful intelligent systems capable of human-like cognition, reasoning, and interaction. These agents are increasingly being deployed across diverse real-world applications, including student education, scientific research, and financial analysis. However, despite their remarkable potential, LLM-based agents remain vulnerable to hallucination issues, which can result in erroneous task execution and undermine the reliability of the overall system design. Addressing this critical challenge requires a deep understanding and a systematic consolidation of recent advances on LLM-based agents. To this end, we present the first comprehensive survey of hallucinations in LLM-based agents. By carefully analyzing the complete workflow of agents, we propose a new taxonomy that identifies different types of agent hallucinations occurring at different stages. Furthermore, we conduct an in-depth examination of eighteen triggering causes underlying the emergence of agent hallucinations. Through a detailed review of a large number of existing studies, we summarize approaches for hallucination mitigation and detection, and highlight promising directions for future research. We hope this survey will inspire further efforts toward addressing hallucinations in LLM-based agents, ultimately contributing to the development of more robust and reliable agent systems.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ì—ì´ì „íŠ¸ì˜ í™˜ê° ë¬¸ì œë¥¼ ë‹¤ë£¨ë©°, ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ì²´ê³„ì ì¸ ì ‘ê·¼ì„ ì œì•ˆí•©ë‹ˆë‹¤. LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ëŠ” ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œìš©ë˜ì§€ë§Œ, í™˜ê°ìœ¼ë¡œ ì¸í•´ ì˜ëª»ëœ ì‘ì—… ìˆ˜í–‰ì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ëŠ” ì—ì´ì „íŠ¸ì˜ ì „ì²´ ì›Œí¬í”Œë¡œìš°ë¥¼ ë¶„ì„í•˜ì—¬ í™˜ê°ì˜ ìœ í˜•ì„ ë¶„ë¥˜í•˜ê³ , í™˜ê°ì„ ìœ ë°œí•˜ëŠ” 18ê°€ì§€ ì›ì¸ì„ ì‹¬ì¸µì ìœ¼ë¡œ ì¡°ì‚¬í•©ë‹ˆë‹¤. ë˜í•œ, í™˜ê° ì™„í™” ë° íƒì§€ë¥¼ ìœ„í•œ ê¸°ì¡´ ì—°êµ¬ë¥¼ ê²€í† í•˜ê³ , í–¥í›„ ì—°êµ¬ ë°©í–¥ì„ ì œì‹œí•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë” ê²¬ê³ í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ê°œë°œì— ê¸°ì—¬í•˜ê³ ì í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM) ê¸°ë°˜ ì—ì´ì „íŠ¸ëŠ” ì¸ê°„ê³¼ ìœ ì‚¬í•œ ì¸ì§€, ì¶”ë¡ , ìƒí˜¸ì‘ìš©ì´ ê°€ëŠ¥í•œ ì§€ëŠ¥í˜• ì‹œìŠ¤í…œìœ¼ë¡œ ë°œì „í•˜ê³  ìˆë‹¤.
- 2. LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ëŠ” í•™ìƒ êµìœ¡, ê³¼í•™ ì—°êµ¬, ê¸ˆìœµ ë¶„ì„ ë“± ë‹¤ì–‘í•œ ì‹¤ì œ ì‘ìš© ë¶„ì•¼ì— í™œìš©ë˜ê³  ìˆë‹¤.
- 3. LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ëŠ” í™˜ê° ë¬¸ì œë¡œ ì¸í•´ ì˜ëª»ëœ ì‘ì—… ìˆ˜í–‰ê³¼ ì‹œìŠ¤í…œ ì‹ ë¢°ì„± ì €í•˜ì˜ ìœ„í—˜ì´ ìˆë‹¤.
- 4. ë³¸ ë…¼ë¬¸ì€ LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ì˜ í™˜ê° ë¬¸ì œë¥¼ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ê³  ìƒˆë¡œìš´ ë¶„ë¥˜ ì²´ê³„ë¥¼ ì œì•ˆí•œë‹¤.
- 5. í™˜ê° ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ì™„í™” ë° íƒì§€ ì ‘ê·¼ë²•ì„ ìš”ì•½í•˜ê³ , í–¥í›„ ì—°êµ¬ ë°©í–¥ì„ ì œì‹œí•œë‹¤.


---

*Generated on 2025-09-24 13:31:02*