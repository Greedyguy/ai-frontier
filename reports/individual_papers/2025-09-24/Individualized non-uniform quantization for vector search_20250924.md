<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T14:52:29.278681",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Non-uniform Vector Quantization",
    "Embedding Vectors",
    "Vector Search",
    "High-Dimensionality"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Non-uniform Vector Quantization": 0.78,
    "Embedding Vectors": 0.7,
    "Vector Search": 0.75,
    "High-Dimensionality": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "non-uniform vector quantization",
        "canonical": "Non-uniform Vector Quantization",
        "aliases": [
          "NVQ"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel technique introduced in the paper, offering a new approach to vector compression.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.88,
        "link_intent_score": 0.78
      },
      {
        "surface": "embedding vectors",
        "canonical": "Embedding Vectors",
        "aliases": [
          "vector embeddings"
        ],
        "category": "broad_technical",
        "rationale": "Embedding vectors are fundamental to the paper's discussion on vector search and compression.",
        "novelty_score": 0.45,
        "connectivity_score": 0.72,
        "specificity_score": 0.6,
        "link_intent_score": 0.7
      },
      {
        "surface": "vector search",
        "canonical": "Vector Search",
        "aliases": [
          "vector retrieval"
        ],
        "category": "specific_connectable",
        "rationale": "Vector search is a key application area for the proposed quantization technique.",
        "novelty_score": 0.5,
        "connectivity_score": 0.8,
        "specificity_score": 0.7,
        "link_intent_score": 0.75
      },
      {
        "surface": "high-dimensionality",
        "canonical": "High-Dimensionality",
        "aliases": [
          "high-dimensional"
        ],
        "category": "specific_connectable",
        "rationale": "High-dimensionality is a critical challenge addressed by the quantization technique.",
        "novelty_score": 0.55,
        "connectivity_score": 0.68,
        "specificity_score": 0.65,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "retrieving large vectors",
      "computational cost"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "non-uniform vector quantization",
      "resolved_canonical": "Non-uniform Vector Quantization",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.88,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "embedding vectors",
      "resolved_canonical": "Embedding Vectors",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.72,
        "specificity": 0.6,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "vector search",
      "resolved_canonical": "Vector Search",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.8,
        "specificity": 0.7,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "high-dimensionality",
      "resolved_canonical": "High-Dimensionality",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.68,
        "specificity": 0.65,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# Individualized non-uniform quantization for vector search

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18471.pdf)
**Category**: cs.LG
**Published**: 2025-09-24
**ArXiv ID**: [2509.18471](https://arxiv.org/abs/2509.18471)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-24/SBVR_ Summation of BitVector Representation for Efficient LLM Quantization_20250924|SBVR: Summation of BitVector Representation for Efficient LLM Quantization]] (82.3% similar)
- [[2025-09-22/Triplet Loss Based Quantum Encoding for Class Separability_20250922|Triplet Loss Based Quantum Encoding for Class Separability]] (82.0% similar)
- [[2025-09-23/GuidedQuant_ Large Language Model Quantization via Exploiting End Loss Guidance_20250923|GuidedQuant: Large Language Model Quantization via Exploiting End Loss Guidance]] (81.8% similar)
- [[2025-09-23/QVGen_ Pushing the Limit of Quantized Video Generative Models_20250923|QVGen: Pushing the Limit of Quantized Video Generative Models]] (81.6% similar)
- [[2025-09-23/VQToken_ Neural Discrete Token Representation Learning for Extreme Token Reduction in Video Large Language Models_20250923|VQToken: Neural Discrete Token Representation Learning for Extreme Token Reduction in Video Large Language Models]] (81.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Embedding Vectors|Embedding Vectors]]
**ğŸ”— Specific Connectable**: [[keywords/Vector Search|Vector Search]], [[keywords/High-Dimensionality|High-Dimensionality]]
**âš¡ Unique Technical**: [[keywords/Non-uniform Vector Quantization|Non-uniform Vector Quantization]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18471v1 Announce Type: new 
Abstract: Embedding vectors are widely used for representing unstructured data and searching through it for semantically similar items. However, the large size of these vectors, due to their high-dimensionality, creates problems for modern vector search techniques: retrieving large vectors from memory/storage is expensive and their footprint is costly. In this work, we present NVQ (non-uniform vector quantization), a new vector compression technique that is computationally and spatially efficient in the high-fidelity regime. The core in NVQ is to use novel parsimonious and computationally efficient nonlinearities for building non-uniform vector quantizers. Critically, these quantizers are \emph{individually} learned for each indexed vector. Our experimental results show that NVQ exhibits improved accuracy compared to the state of the art with a minimal computational cost.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” ë¹„ì •í˜• ë°ì´í„°ë¥¼ í‘œí˜„í•˜ê³  ìœ ì‚¬ í•­ëª©ì„ ê²€ìƒ‰í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ì„ë² ë”© ë²¡í„°ì˜ ê³ ì°¨ì›ì„±ìœ¼ë¡œ ì¸í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ NVQ(ë¹„ê· ì¼ ë²¡í„° ì–‘ìí™”)ë¼ëŠ” ìƒˆë¡œìš´ ë²¡í„° ì••ì¶• ê¸°ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. NVQëŠ” ê³ ì¶©ì‹¤ë„ í™˜ê²½ì—ì„œ ê³„ì‚° ë° ê³µê°„ íš¨ìœ¨ì„±ì„ ì œê³µí•˜ë©°, ê° ë²¡í„°ì— ëŒ€í•´ ê°œë³„ì ìœ¼ë¡œ í•™ìŠµëœ ë¹„ê· ì¼ ë²¡í„° ì–‘ìê¸°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, NVQëŠ” ìµœì†Œí•œì˜ ê³„ì‚° ë¹„ìš©ìœ¼ë¡œ ê¸°ì¡´ ê¸°ìˆ  ëŒ€ë¹„ í–¥ìƒëœ ì •í™•ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. NVQëŠ” ë¹„ê· ì¼ ë²¡í„° ì–‘ìí™”ë¥¼ í†µí•´ ê³ ì°¨ì› ë²¡í„°ì˜ í¬ê¸°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì••ì¶•í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.
- 2. NVQëŠ” ê° ë²¡í„°ì— ëŒ€í•´ ê°œë³„ì ìœ¼ë¡œ í•™ìŠµëœ ìƒˆë¡œìš´ ë¹„ì„ í˜•ì„±ì„ ì‚¬ìš©í•˜ì—¬ ë²¡í„° ì–‘ìí™”ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
- 3. ì‹¤í—˜ ê²°ê³¼, NVQëŠ” ìµœì†Œí•œì˜ ê³„ì‚° ë¹„ìš©ìœ¼ë¡œ ê¸°ì¡´ ê¸°ìˆ  ëŒ€ë¹„ í–¥ìƒëœ ì •í™•ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
- 4. NVQëŠ” ë†’ì€ ì •í™•ì„±ì„ ìœ ì§€í•˜ë©´ì„œë„ ê³„ì‚° ë° ê³µê°„ íš¨ìœ¨ì„±ì„ ì œê³µí•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 14:52:29*