<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T14:01:28.149635",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multi-View Universal Manipulation Interface",
    "Imitation Learning",
    "Handheld Grippers",
    "Third-Person Perspective"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multi-View Universal Manipulation Interface": 0.89,
    "Imitation Learning": 0.78,
    "Handheld Grippers": 0.84,
    "Third-Person Perspective": 0.82
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multi-View Universal Manipulation Interface",
        "canonical": "Multi-View Universal Manipulation Interface",
        "aliases": [
          "MV-UMI"
        ],
        "category": "unique_technical",
        "rationale": "This is a unique framework introduced in the paper, central to the research and not found in existing vocabularies.",
        "novelty_score": 0.85,
        "connectivity_score": 0.68,
        "specificity_score": 0.92,
        "link_intent_score": 0.89
      },
      {
        "surface": "imitation learning",
        "canonical": "Imitation Learning",
        "aliases": [
          "behavior cloning"
        ],
        "category": "broad_technical",
        "rationale": "Imitation learning is a foundational concept in machine learning, relevant to the paper's focus on learning from demonstrations.",
        "novelty_score": 0.45,
        "connectivity_score": 0.87,
        "specificity_score": 0.65,
        "link_intent_score": 0.78
      },
      {
        "surface": "handheld grippers",
        "canonical": "Handheld Grippers",
        "aliases": [
          "portable grippers"
        ],
        "category": "specific_connectable",
        "rationale": "Handheld grippers are a key component in the paper's methodology, enabling cross-embodiment learning.",
        "novelty_score": 0.72,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.84
      },
      {
        "surface": "third-person perspective",
        "canonical": "Third-Person Perspective",
        "aliases": [
          "external view"
        ],
        "category": "specific_connectable",
        "rationale": "The integration of a third-person perspective is crucial for overcoming limitations in data collection, as discussed in the paper.",
        "novelty_score": 0.6,
        "connectivity_score": 0.7,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      }
    ],
    "ban_list_suggestions": [
      "robot manipulation policies",
      "data collection",
      "scene understanding"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multi-View Universal Manipulation Interface",
      "resolved_canonical": "Multi-View Universal Manipulation Interface",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.68,
        "specificity": 0.92,
        "link_intent": 0.89
      }
    },
    {
      "candidate_surface": "imitation learning",
      "resolved_canonical": "Imitation Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.87,
        "specificity": 0.65,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "handheld grippers",
      "resolved_canonical": "Handheld Grippers",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.84
      }
    },
    {
      "candidate_surface": "third-person perspective",
      "resolved_canonical": "Third-Person Perspective",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.7,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    }
  ]
}
-->

# MV-UMI: A Scalable Multi-View Interface for Cross-Embodiment Learning

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18757.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2509.18757](https://arxiv.org/abs/2509.18757)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/GP3_ A 3D Geometry-Aware Policy with Multi-View Images for Robotic Manipulation_20250922|GP3: A 3D Geometry-Aware Policy with Multi-View Images for Robotic Manipulation]] (85.2% similar)
- [[2025-09-19/M4Diffuser_ Multi-View Diffusion Policy with Manipulability-Aware Control for Robust Mobile Manipulation_20250919|M4Diffuser: Multi-View Diffusion Policy with Manipulability-Aware Control for Robust Mobile Manipulation]] (84.9% similar)
- [[2025-09-23/KungfuBot2_ Learning Versatile Motion Skills for Humanoid Whole-Body Control_20250923|KungfuBot2: Learning Versatile Motion Skills for Humanoid Whole-Body Control]] (84.8% similar)
- [[2025-09-23/UniSkill_ Imitating Human Videos via Cross-Embodiment Skill Representations_20250923|UniSkill: Imitating Human Videos via Cross-Embodiment Skill Representations]] (84.4% similar)
- [[2025-09-18/Embracing Bulky Objects with Humanoid Robots_ Whole-Body Manipulation with Reinforcement Learning_20250918|Embracing Bulky Objects with Humanoid Robots: Whole-Body Manipulation with Reinforcement Learning]] (84.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Imitation Learning|Imitation Learning]]
**ğŸ”— Specific Connectable**: [[keywords/Handheld Grippers|Handheld Grippers]], [[keywords/Third-Person Perspective|Third-Person Perspective]]
**âš¡ Unique Technical**: [[keywords/Multi-View Universal Manipulation Interface|Multi-View Universal Manipulation Interface]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18757v1 Announce Type: cross 
Abstract: Recent advances in imitation learning have shown great promise for developing robust robot manipulation policies from demonstrations. However, this promise is contingent on the availability of diverse, high-quality datasets, which are not only challenging and costly to collect but are often constrained to a specific robot embodiment. Portable handheld grippers have recently emerged as intuitive and scalable alternatives to traditional robotic teleoperation methods for data collection. However, their reliance solely on first-person view wrist-mounted cameras often creates limitations in capturing sufficient scene contexts. In this paper, we present MV-UMI (Multi-View Universal Manipulation Interface), a framework that integrates a third-person perspective with the egocentric camera to overcome this limitation. This integration mitigates domain shifts between human demonstration and robot deployment, preserving the cross-embodiment advantages of handheld data-collection devices. Our experimental results, including an ablation study, demonstrate that our MV-UMI framework improves performance in sub-tasks requiring broad scene understanding by approximately 47% across 3 tasks, confirming the effectiveness of our approach in expanding the range of feasible manipulation tasks that can be learned using handheld gripper systems, without compromising the cross-embodiment advantages inherent to such systems.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë‹¤ì–‘í•œ ì‹œì ì˜ ì¹´ë©”ë¼ë¥¼ í™œìš©í•œ ë¡œë´‡ ì¡°ì‘ ì •ì±… ê°œë°œì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ íœ´ëŒ€ìš© ê·¸ë¦¬í¼ëŠ” ì†ëª© ì¹´ë©”ë¼ì— ì˜ì¡´í•˜ì—¬ ì¥ë©´ì„ ì¶©ë¶„íˆ í¬ì°©í•˜ì§€ ëª»í•˜ëŠ” í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ë³¸ ì—°êµ¬ì—ì„œëŠ” 1ì¸ì¹­ ì‹œì ê³¼ 3ì¸ì¹­ ì‹œì ì„ í†µí•©í•œ MV-UMI í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ì¸ê°„ ì‹œì—°ê³¼ ë¡œë´‡ ë°°ì¹˜ ê°„ì˜ ë„ë©”ì¸ ì°¨ì´ë¥¼ ì¤„ì´ê³ , ë‹¤ì–‘í•œ ë¡œë´‡ í˜•íƒœì— ì ìš© ê°€ëŠ¥í•œ ë°ì´í„° ìˆ˜ì§‘ì˜ ì¥ì ì„ ìœ ì§€í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, MV-UMIëŠ” ì¥ë©´ ì´í•´ê°€ í•„ìš”í•œ ì‘ì—…ì—ì„œ ì•½ 47%ì˜ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ì´ëŠ” íœ´ëŒ€ìš© ê·¸ë¦¬í¼ ì‹œìŠ¤í…œì„ í™œìš©í•œ ì¡°ì‘ ì‘ì—…ì˜ ë²”ìœ„ë¥¼ í™•ì¥í•˜ëŠ” ë° íš¨ê³¼ì ì„ì„ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëª¨ë°© í•™ìŠµì˜ ë°œì „ì€ ì‹œì—°ì„ í†µí•´ ê°•ë ¥í•œ ë¡œë´‡ ì¡°ì‘ ì •ì±…ì„ ê°œë°œí•˜ëŠ” ë° ìœ ë§í•˜ì§€ë§Œ, ì´ëŠ” ë‹¤ì–‘í•œ ê³ í’ˆì§ˆ ë°ì´í„°ì…‹ì˜ ê°€ìš©ì„±ì— ë‹¬ë ¤ ìˆë‹¤.
- 2. íœ´ëŒ€ìš© ê·¸ë¦¬í¼ëŠ” ì „í†µì ì¸ ë¡œë´‡ ì›ê²© ì¡°ì‘ ë°©ë²•ì— ëŒ€í•œ ì§ê´€ì ì´ê³  í™•ì¥ ê°€ëŠ¥í•œ ëŒ€ì•ˆìœ¼ë¡œ ë¶€ìƒí•˜ê³  ìˆë‹¤.
- 3. MV-UMI í”„ë ˆì„ì›Œí¬ëŠ” 1ì¸ì¹­ ì‹œì ì˜ ì¹´ë©”ë¼ì™€ 3ì¸ì¹­ ì‹œì ì„ í†µí•©í•˜ì—¬ ì¥ë©´ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì¶©ë¶„íˆ í¬ì°©í•˜ëŠ” ë° ìˆì–´ ê¸°ì¡´ì˜ í•œê³„ë¥¼ ê·¹ë³µí•œë‹¤.
- 4. ì‹¤í—˜ ê²°ê³¼ì— ë”°ë¥´ë©´ MV-UMIëŠ” ê´‘ë²”ìœ„í•œ ì¥ë©´ ì´í•´ê°€ í•„ìš”í•œ í•˜ìœ„ ì‘ì—…ì—ì„œ ì•½ 47%ì˜ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì—¬ì¤€ë‹¤.
- 5. MV-UMIëŠ” íœ´ëŒ€ìš© ê·¸ë¦¬í¼ ì‹œìŠ¤í…œì˜ êµì°¨ êµ¬í˜„ ì´ì ì„ ìœ ì§€í•˜ë©´ì„œ í•™ìŠµ ê°€ëŠ¥í•œ ì¡°ì‘ ì‘ì—…ì˜ ë²”ìœ„ë¥¼ í™•ì¥í•˜ëŠ” ë° íš¨ê³¼ì ì´ë‹¤.


---

*Generated on 2025-09-24 14:01:28*