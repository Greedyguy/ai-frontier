<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T14:28:16.911975",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "DeepResonance",
    "Multimodal Learning",
    "Transformer",
    "Music Understanding",
    "Multi-way Instruction Tuning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "DeepResonance": 0.8,
    "Multimodal Learning": 0.85,
    "Transformer": 0.75,
    "Music Understanding": 0.78,
    "Multi-way Instruction Tuning": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "DeepResonance",
        "canonical": "DeepResonance",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "DeepResonance is a novel model specifically designed for multimodal music understanding, providing a unique point of reference.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "Multimodal",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal"
        ],
        "category": "specific_connectable",
        "rationale": "Multimodal Learning is central to the paper's methodology, linking music, text, image, and video data.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.78,
        "link_intent_score": 0.85
      },
      {
        "surface": "Transformer",
        "canonical": "Transformer",
        "aliases": [],
        "category": "broad_technical",
        "rationale": "Transformers are a fundamental technology used in the model's architecture for modality fusion.",
        "novelty_score": 0.4,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.75
      },
      {
        "surface": "Music Understanding",
        "canonical": "Music Understanding",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Music Understanding is the primary application domain of the proposed model, providing a specific focus for linking.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Multi-way Instruction Tuning",
        "canonical": "Multi-way Instruction Tuning",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This tuning method is a novel approach in the paper, enhancing the model's ability to integrate multiple modalities.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "improvements"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "DeepResonance",
      "resolved_canonical": "DeepResonance",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Multimodal",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.78,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Transformer",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Music Understanding",
      "resolved_canonical": "Music Understanding",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Multi-way Instruction Tuning",
      "resolved_canonical": "Multi-way Instruction Tuning",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# DeepResonance: Enhancing Multimodal Music Understanding via Music-centric Multi-way Instruction Tuning

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2502.12623.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2502.12623](https://arxiv.org/abs/2502.12623)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Opening the Black Box_ Interpretable LLMs via Semantic Resonance Architecture_20250919|Opening the Black Box: Interpretable LLMs via Semantic Resonance Architecture]] (83.7% similar)
- [[2025-09-19/Music4All A+A_ A Multimodal Dataset for Music Information Retrieval Tasks_20250919|Music4All A+A: A Multimodal Dataset for Music Information Retrieval Tasks]] (83.4% similar)
- [[2025-09-24/Explore the Reinforcement Learning for the LLM based ASR and TTS system_20250924|Explore the Reinforcement Learning for the LLM based ASR and TTS system]] (83.3% similar)
- [[2025-09-19/Large Multi-modal Models Can Interpret Features in Large Multi-modal Models_20250919|Large Multi-modal Models Can Interpret Features in Large Multi-modal Models]] (83.3% similar)
- [[2025-09-19/Middo_ Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning_20250919|Middo: Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning]] (83.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Transformer|Transformer]]
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**âš¡ Unique Technical**: [[keywords/DeepResonance|DeepResonance]], [[keywords/Music Understanding|Music Understanding]], [[keywords/Multi-way Instruction Tuning|Multi-way Instruction Tuning]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2502.12623v3 Announce Type: replace-cross 
Abstract: Recent advancements in music large language models (LLMs) have significantly improved music understanding tasks, which involve the model's ability to analyze and interpret various musical elements. These improvements primarily focused on integrating both music and text inputs. However, the potential of incorporating additional modalities such as images, videos and textual music features to enhance music understanding remains unexplored. To bridge this gap, we propose DeepResonance, a multimodal music understanding LLM fine-tuned via multi-way instruction tuning with multi-way aligned music, text, image, and video data. To this end, we construct Music4way-MI2T, Music4way-MV2T, and Music4way-Any2T, three 4-way training and evaluation datasets designed to enable DeepResonance to integrate both visual and textual music feature content. We also introduce multi-sampled ImageBind embeddings and a pre-LLM fusion Transformer to enhance modality fusion prior to input into text LLMs, tailoring for multi-way instruction tuning. Our model achieves state-of-the-art performances across six music understanding tasks, highlighting the benefits of the auxiliary modalities and the structural superiority of DeepResonance. We open-source the codes, models and datasets we constructed: github.com/sony/DeepResonance.

## ğŸ“ ìš”ì•½

ìµœê·¼ ìŒì•… ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ë°œì „ì€ ìŒì•… ì´í•´ ì‘ì—…ì„ í¬ê²Œ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ë¯¸ì§€, ë¹„ë””ì˜¤, í…ìŠ¤íŠ¸ ìŒì•… íŠ¹ì§• ë“± ì¶”ê°€ì ì¸ ëª¨ë‹¬ë¦¬í‹°ë¥¼ í™œìš©í•œ ì—°êµ¬ëŠ” ë¶€ì¡±í–ˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” DeepResonanceë¼ëŠ” ë©€í‹°ëª¨ë‹¬ ìŒì•… ì´í•´ LLMì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ìŒì•…, í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ë¹„ë””ì˜¤ ë°ì´í„°ë¥¼ í†µí•©í•˜ì—¬ ë©€í‹°ì›¨ì´ ì§€ì‹œ ì¡°ì •ì„ í†µí•´ ë¯¸ì„¸ ì¡°ì •ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ Music4way-MI2T, Music4way-MV2T, Music4way-Any2Të¼ëŠ” ì„¸ ê°€ì§€ 4-way í›ˆë ¨ ë° í‰ê°€ ë°ì´í„°ì…‹ì„ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, ë©€í‹° ìƒ˜í”Œë§ëœ ImageBind ì„ë² ë”©ê³¼ ì‚¬ì „ LLM ìœµí•© íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ ë„ì…í•˜ì—¬ ëª¨ë‹¬ë¦¬í‹° ìœµí•©ì„ ê°•í™”í–ˆìŠµë‹ˆë‹¤. DeepResonanceëŠ” ì—¬ì„¯ ê°€ì§€ ìŒì•… ì´í•´ ì‘ì—…ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìœ¼ë©°, ë³´ì¡° ëª¨ë‹¬ë¦¬í‹°ì˜ ì´ì ê³¼ ëª¨ë¸ì˜ êµ¬ì¡°ì  ìš°ìˆ˜ì„±ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì½”ë“œ, ëª¨ë¸, ë°ì´í„°ì…‹ì„ ì˜¤í”ˆ ì†ŒìŠ¤ë¡œ ê³µê°œí–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ìŒì•… ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ìµœê·¼ ë°œì „ì€ ìŒì•… ì´í•´ ì‘ì—…ì—ì„œ ëª¨ë¸ì˜ ë¶„ì„ ë° í•´ì„ ëŠ¥ë ¥ì„ í¬ê²Œ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.
- 2. DeepResonanceëŠ” ìŒì•…, í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ë¹„ë””ì˜¤ ë°ì´í„°ë¥¼ í†µí•©í•˜ì—¬ ë‹¤ì¤‘ ë°©ì‹ì˜ ì§€ì‹œ íŠœë‹ì„ í†µí•´ ë¯¸ì„¸ ì¡°ì •ëœ ë‹¤ì¤‘ ëª¨ë‹¬ ìŒì•… ì´í•´ LLMì…ë‹ˆë‹¤.
- 3. Music4way-MI2T, Music4way-MV2T, Music4way-Any2Të¼ëŠ” ì„¸ ê°€ì§€ 4-way í›ˆë ¨ ë° í‰ê°€ ë°ì´í„°ì…‹ì„ êµ¬ì¶•í•˜ì—¬ DeepResonanceê°€ ì‹œê°ì  ë° í…ìŠ¤íŠ¸ ìŒì•… íŠ¹ì§• ì½˜í…ì¸ ë¥¼ í†µí•©í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„í–ˆìŠµë‹ˆë‹¤.
- 4. ë‹¤ì¤‘ ìƒ˜í”Œë§ëœ ImageBind ì„ë² ë”©ê³¼ ì‚¬ì „ LLM ìœµí•© Transformerë¥¼ ë„ì…í•˜ì—¬ í…ìŠ¤íŠ¸ LLMì— ì…ë ¥í•˜ê¸° ì „ì— ëª¨ë‹¬ë¦¬í‹° ìœµí•©ì„ ê°•í™”í–ˆìŠµë‹ˆë‹¤.
- 5. DeepResonanceëŠ” ì—¬ì„¯ ê°€ì§€ ìŒì•… ì´í•´ ì‘ì—…ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìœ¼ë©°, ë³´ì¡° ëª¨ë‹¬ë¦¬í‹°ì™€ êµ¬ì¡°ì  ìš°ìˆ˜ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 14:28:16*