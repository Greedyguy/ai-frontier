<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T14:28:16.911975",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "DeepResonance",
    "Multimodal Learning",
    "Transformer",
    "Music Understanding",
    "Multi-way Instruction Tuning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "DeepResonance": 0.8,
    "Multimodal Learning": 0.85,
    "Transformer": 0.75,
    "Music Understanding": 0.78,
    "Multi-way Instruction Tuning": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "DeepResonance",
        "canonical": "DeepResonance",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "DeepResonance is a novel model specifically designed for multimodal music understanding, providing a unique point of reference.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "Multimodal",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal"
        ],
        "category": "specific_connectable",
        "rationale": "Multimodal Learning is central to the paper's methodology, linking music, text, image, and video data.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.78,
        "link_intent_score": 0.85
      },
      {
        "surface": "Transformer",
        "canonical": "Transformer",
        "aliases": [],
        "category": "broad_technical",
        "rationale": "Transformers are a fundamental technology used in the model's architecture for modality fusion.",
        "novelty_score": 0.4,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.75
      },
      {
        "surface": "Music Understanding",
        "canonical": "Music Understanding",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Music Understanding is the primary application domain of the proposed model, providing a specific focus for linking.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Multi-way Instruction Tuning",
        "canonical": "Multi-way Instruction Tuning",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This tuning method is a novel approach in the paper, enhancing the model's ability to integrate multiple modalities.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "improvements"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "DeepResonance",
      "resolved_canonical": "DeepResonance",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Multimodal",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.78,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Transformer",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Music Understanding",
      "resolved_canonical": "Music Understanding",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Multi-way Instruction Tuning",
      "resolved_canonical": "Multi-way Instruction Tuning",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# DeepResonance: Enhancing Multimodal Music Understanding via Music-centric Multi-way Instruction Tuning

## 📋 메타데이터

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2502.12623.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2502.12623](https://arxiv.org/abs/2502.12623)

## 🔗 유사한 논문
- [[2025-09-19/Opening the Black Box_ Interpretable LLMs via Semantic Resonance Architecture_20250919|Opening the Black Box: Interpretable LLMs via Semantic Resonance Architecture]] (83.7% similar)
- [[2025-09-19/Music4All A+A_ A Multimodal Dataset for Music Information Retrieval Tasks_20250919|Music4All A+A: A Multimodal Dataset for Music Information Retrieval Tasks]] (83.4% similar)
- [[2025-09-24/Explore the Reinforcement Learning for the LLM based ASR and TTS system_20250924|Explore the Reinforcement Learning for the LLM based ASR and TTS system]] (83.3% similar)
- [[2025-09-19/Large Multi-modal Models Can Interpret Features in Large Multi-modal Models_20250919|Large Multi-modal Models Can Interpret Features in Large Multi-modal Models]] (83.3% similar)
- [[2025-09-19/Middo_ Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning_20250919|Middo: Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning]] (83.1% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Transformer|Transformer]]
**🔗 Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**⚡ Unique Technical**: [[keywords/DeepResonance|DeepResonance]], [[keywords/Music Understanding|Music Understanding]], [[keywords/Multi-way Instruction Tuning|Multi-way Instruction Tuning]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2502.12623v3 Announce Type: replace-cross 
Abstract: Recent advancements in music large language models (LLMs) have significantly improved music understanding tasks, which involve the model's ability to analyze and interpret various musical elements. These improvements primarily focused on integrating both music and text inputs. However, the potential of incorporating additional modalities such as images, videos and textual music features to enhance music understanding remains unexplored. To bridge this gap, we propose DeepResonance, a multimodal music understanding LLM fine-tuned via multi-way instruction tuning with multi-way aligned music, text, image, and video data. To this end, we construct Music4way-MI2T, Music4way-MV2T, and Music4way-Any2T, three 4-way training and evaluation datasets designed to enable DeepResonance to integrate both visual and textual music feature content. We also introduce multi-sampled ImageBind embeddings and a pre-LLM fusion Transformer to enhance modality fusion prior to input into text LLMs, tailoring for multi-way instruction tuning. Our model achieves state-of-the-art performances across six music understanding tasks, highlighting the benefits of the auxiliary modalities and the structural superiority of DeepResonance. We open-source the codes, models and datasets we constructed: github.com/sony/DeepResonance.

## 📝 요약

최근 음악 대형 언어 모델(LLM)의 발전은 음악 이해 작업을 크게 향상시켰습니다. 그러나 이미지, 비디오, 텍스트 음악 특징 등 추가적인 모달리티를 활용한 연구는 부족했습니다. 이를 해결하기 위해, 우리는 DeepResonance라는 멀티모달 음악 이해 LLM을 제안합니다. 이 모델은 음악, 텍스트, 이미지, 비디오 데이터를 통합하여 멀티웨이 지시 조정을 통해 미세 조정되었습니다. 이를 위해 Music4way-MI2T, Music4way-MV2T, Music4way-Any2T라는 세 가지 4-way 훈련 및 평가 데이터셋을 구축했습니다. 또한, 멀티 샘플링된 ImageBind 임베딩과 사전 LLM 융합 트랜스포머를 도입하여 모달리티 융합을 강화했습니다. DeepResonance는 여섯 가지 음악 이해 작업에서 최첨단 성능을 달성했으며, 보조 모달리티의 이점과 모델의 구조적 우수성을 입증했습니다. 우리는 코드, 모델, 데이터셋을 오픈 소스로 공개했습니다.

## 🎯 주요 포인트

- 1. 음악 대형 언어 모델(LLM)의 최근 발전은 음악 이해 작업에서 모델의 분석 및 해석 능력을 크게 향상시켰습니다.
- 2. DeepResonance는 음악, 텍스트, 이미지, 비디오 데이터를 통합하여 다중 방식의 지시 튜닝을 통해 미세 조정된 다중 모달 음악 이해 LLM입니다.
- 3. Music4way-MI2T, Music4way-MV2T, Music4way-Any2T라는 세 가지 4-way 훈련 및 평가 데이터셋을 구축하여 DeepResonance가 시각적 및 텍스트 음악 특징 콘텐츠를 통합할 수 있도록 설계했습니다.
- 4. 다중 샘플링된 ImageBind 임베딩과 사전 LLM 융합 Transformer를 도입하여 텍스트 LLM에 입력하기 전에 모달리티 융합을 강화했습니다.
- 5. DeepResonance는 여섯 가지 음악 이해 작업에서 최첨단 성능을 달성했으며, 보조 모달리티와 구조적 우수성을 강조합니다.


---

*Generated on 2025-09-24 14:28:16*