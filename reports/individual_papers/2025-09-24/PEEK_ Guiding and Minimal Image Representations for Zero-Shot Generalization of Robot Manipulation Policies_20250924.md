<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T13:44:20.711901",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Zero-Shot Learning",
    "Vision-Language Model",
    "Policy-agnostic Extraction of Essential Keypoints",
    "End-effector Paths"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Zero-Shot Learning": 0.85,
    "Vision-Language Model": 0.89,
    "Policy-agnostic Extraction of Essential Keypoints": 0.8,
    "End-effector Paths": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Zero-Shot Generalization",
        "canonical": "Zero-Shot Learning",
        "aliases": [
          "Zero-Shot"
        ],
        "category": "specific_connectable",
        "rationale": "Zero-shot learning is crucial for understanding how the model generalizes without prior examples, directly linking to existing research on learning paradigms.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.8,
        "link_intent_score": 0.85
      },
      {
        "surface": "Vision-Language Models",
        "canonical": "Vision-Language Model",
        "aliases": [
          "VLMs"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-language models are central to the paper's approach, providing a bridge between visual and linguistic data processing.",
        "novelty_score": 0.6,
        "connectivity_score": 0.9,
        "specificity_score": 0.78,
        "link_intent_score": 0.89
      },
      {
        "surface": "PEEK",
        "canonical": "Policy-agnostic Extraction of Essential Keypoints",
        "aliases": [
          "PEEK"
        ],
        "category": "unique_technical",
        "rationale": "PEEK is a novel method introduced in the paper, representing a unique contribution to robot manipulation policy generalization.",
        "novelty_score": 0.85,
        "connectivity_score": 0.7,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "End-effector Paths",
        "canonical": "End-effector Paths",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "End-effector paths are a specific technical aspect of the manipulation policies, crucial for understanding action execution.",
        "novelty_score": 0.65,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "robot",
      "manipulation",
      "policy"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Zero-Shot Generalization",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.8,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Vision-Language Models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.9,
        "specificity": 0.78,
        "link_intent": 0.89
      }
    },
    {
      "candidate_surface": "PEEK",
      "resolved_canonical": "Policy-agnostic Extraction of Essential Keypoints",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.7,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "End-effector Paths",
      "resolved_canonical": "End-effector Paths",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# PEEK: Guiding and Minimal Image Representations for Zero-Shot Generalization of Robot Manipulation Policies

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18282.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2509.18282](https://arxiv.org/abs/2509.18282)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Latent Policy Steering with Embodiment-Agnostic Pretrained World Models_20250923|Latent Policy Steering with Embodiment-Agnostic Pretrained World Models]] (86.7% similar)
- [[2025-09-18/Robot Control Stack_ A Lean Ecosystem for Robot Learning at Scale_20250918|Robot Control Stack: A Lean Ecosystem for Robot Learning at Scale]] (86.2% similar)
- [[2025-09-22/GP3_ A 3D Geometry-Aware Policy with Multi-View Images for Robotic Manipulation_20250922|GP3: A 3D Geometry-Aware Policy with Multi-View Images for Robotic Manipulation]] (85.7% similar)
- [[2025-09-22/A Vision-Language-Action-Critic Model for Robotic Real-World Reinforcement Learning_20250922|A Vision-Language-Action-Critic Model for Robotic Real-World Reinforcement Learning]] (85.4% similar)
- [[2025-09-22/PVPO_ Pre-Estimated Value-Based Policy Optimization for Agentic Reasoning_20250922|PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic Reasoning]] (84.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Zero-Shot Learning|Zero-Shot Learning]]
**âš¡ Unique Technical**: [[keywords/Policy-agnostic Extraction of Essential Keypoints|Policy-agnostic Extraction of Essential Keypoints]], [[keywords/End-effector Paths|End-effector Paths]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18282v1 Announce Type: cross 
Abstract: Robotic manipulation policies often fail to generalize because they must simultaneously learn where to attend, what actions to take, and how to execute them. We argue that high-level reasoning about where and what can be offloaded to vision-language models (VLMs), leaving policies to specialize in how to act. We present PEEK (Policy-agnostic Extraction of Essential Keypoints), which fine-tunes VLMs to predict a unified point-based intermediate representation: 1. end-effector paths specifying what actions to take, and 2. task-relevant masks indicating where to focus. These annotations are directly overlaid onto robot observations, making the representation policy-agnostic and transferable across architectures. To enable scalable training, we introduce an automatic annotation pipeline, generating labeled data across 20+ robot datasets spanning 9 embodiments. In real-world evaluations, PEEK consistently boosts zero-shot generalization, including a 41.4x real-world improvement for a 3D policy trained only in simulation, and 2-3.5x gains for both large VLAs and small manipulation policies. By letting VLMs absorb semantic and visual complexity, PEEK equips manipulation policies with the minimal cues they need--where, what, and how. Website at https://peek-robot.github.io/.

## ğŸ“ ìš”ì•½

ë¡œë´‡ ì¡°ì‘ ì •ì±…ì€ ì¼ë°˜í™”ì— ì–´ë ¤ì›€ì„ ê²ªëŠ”ë°, ì´ëŠ” ì–´ë””ì— ì£¼ëª©í•˜ê³  ì–´ë–¤ í–‰ë™ì„ ì·¨í•˜ë©° ì–´ë–»ê²Œ ì‹¤í–‰í• ì§€ë¥¼ ë™ì‹œì— í•™ìŠµí•´ì•¼ í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” ê³ ì°¨ì›ì  ì¶”ë¡ ì„ ì‹œê°-ì–¸ì–´ ëª¨ë¸(VLMs)ì— ë§¡ê¸°ê³ , ì •ì±…ì€ í–‰ë™ ì‹¤í–‰ì— ì§‘ì¤‘í•˜ë„ë¡ ì œì•ˆí•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ PEEK(Policy-agnostic Extraction of Essential Keypoints)ë¥¼ ì†Œê°œí•˜ë©°, VLMsë¥¼ ë¯¸ì„¸ ì¡°ì •í•˜ì—¬ í†µí•©ëœ ì¤‘ê°„ í‘œí˜„ì„ ì˜ˆì¸¡í•˜ë„ë¡ í•©ë‹ˆë‹¤. ì´ í‘œí˜„ì€ ë¡œë´‡ ê´€ì°°ì— ì§ì ‘ ì ìš©ë˜ì–´ ì •ì±…ì— êµ¬ì• ë°›ì§€ ì•Šê³  ë‹¤ì–‘í•œ êµ¬ì¡°ì— ì „ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ìë™ ì£¼ì„ íŒŒì´í”„ë¼ì¸ì„ ë„ì…í•´ 20ê°œ ì´ìƒì˜ ë¡œë´‡ ë°ì´í„°ì…‹ì—ì„œ ì£¼ì„ ë°ì´í„°ë¥¼ ìƒì„±í•˜ë©°, ì‹¤ì œ í‰ê°€ì—ì„œ PEEKëŠ” ì œë¡œìƒ· ì¼ë°˜í™”ë¥¼ í¬ê²Œ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤. ì‹œë®¬ë ˆì´ì…˜ì—ì„œë§Œ í›ˆë ¨ëœ 3D ì •ì±…ì˜ ê²½ìš° 41.4ë°°, ëŒ€í˜• VLAì™€ ì†Œí˜• ì¡°ì‘ ì •ì±…ì—ì„œëŠ” 2-3.5ë°°ì˜ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì˜€ìŠµë‹ˆë‹¤. PEEKëŠ” ì‹œê° ë° ì˜ë¯¸ì  ë³µì¡ì„±ì„ VLMsì— í¡ìˆ˜ì‹œì¼œ ì¡°ì‘ ì •ì±…ì— í•„ìš”í•œ ìµœì†Œí•œì˜ ë‹¨ì„œë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë¡œë´‡ ì¡°ì‘ ì •ì±…ì˜ ì¼ë°˜í™” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì‹œê°-ì–¸ì–´ ëª¨ë¸(VLMs)ì„ í™œìš©í•˜ì—¬ ê³ ìˆ˜ì¤€ì˜ 'ì–´ë””'ì™€ 'ë¬´ì—‡'ì— ëŒ€í•œ ì¶”ë¡ ì„ ë‹´ë‹¹í•˜ê²Œ í•˜ê³ , ì •ì±…ì€ 'ì–´ë–»ê²Œ' í–‰ë™í• ì§€ë¥¼ ì „ë¬¸í™”í•˜ë„ë¡ ì œì•ˆí•©ë‹ˆë‹¤.
- 2. PEEK(Policy-agnostic Extraction of Essential Keypoints)ì€ VLMsë¥¼ ë¯¸ì„¸ ì¡°ì •í•˜ì—¬ í†µí•©ëœ ì  ê¸°ë°˜ ì¤‘ê°„ í‘œí˜„ì„ ì˜ˆì¸¡í•˜ë„ë¡ í•˜ë©°, ì´ëŠ” ë¡œë´‡ ê´€ì°°ì— ì§ì ‘ ì˜¤ë²„ë ˆì´ë˜ì–´ ì •ì±…ì— êµ¬ì• ë°›ì§€ ì•Šê³  ë‹¤ì–‘í•œ ì•„í‚¤í…ì²˜ì— ì „ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
- 3. ìë™ ì£¼ì„ íŒŒì´í”„ë¼ì¸ì„ ë„ì…í•˜ì—¬ 9ê°œì˜ êµ¬í˜„ì„ í¬í•¨í•œ 20ê°œ ì´ìƒì˜ ë¡œë´‡ ë°ì´í„° ì„¸íŠ¸ì—ì„œ ë¼ë²¨ì´ ì§€ì •ëœ ë°ì´í„°ë¥¼ ìƒì„±í•¨ìœ¼ë¡œì¨ ëŒ€ê·œëª¨ í•™ìŠµì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
- 4. ì‹¤ì œ í‰ê°€ì—ì„œ PEEKëŠ” ì‹œë®¬ë ˆì´ì…˜ì—ì„œë§Œ í›ˆë ¨ëœ 3D ì •ì±…ì˜ 41.4ë°° ì‹¤ì„¸ê³„ ê°œì„ ì„ í¬í•¨í•˜ì—¬, ëŒ€í˜• VLAì™€ ì†Œí˜• ì¡°ì‘ ì •ì±… ëª¨ë‘ì—ì„œ 2-3.5ë°°ì˜ ì œë¡œìƒ· ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
- 5. PEEKëŠ” VLMsê°€ ì˜ë¯¸ì  ë° ì‹œê°ì  ë³µì¡ì„±ì„ í¡ìˆ˜í•˜ê²Œ í•˜ì—¬ ì¡°ì‘ ì •ì±…ì— í•„ìš”í•œ ìµœì†Œí•œì˜ ë‹¨ì„œ(ì–´ë””, ë¬´ì—‡, ì–´ë–»ê²Œ)ë¥¼ ì œê³µí•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 13:44:20*