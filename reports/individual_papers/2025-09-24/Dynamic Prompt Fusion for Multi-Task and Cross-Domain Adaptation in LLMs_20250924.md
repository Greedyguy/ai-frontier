<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T15:03:27.433617",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Dynamic Prompt Fusion",
    "Multi-Task Learning",
    "Cross-Domain Adaptation",
    "Task Interference"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Dynamic Prompt Fusion": 0.7,
    "Multi-Task Learning": 0.8,
    "Cross-Domain Adaptation": 0.78,
    "Task Interference": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Large Language Models"
        ],
        "category": "broad_technical",
        "rationale": "Essential for linking discussions on advanced natural language processing techniques.",
        "novelty_score": 0.2,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Dynamic Prompt Fusion",
        "canonical": "Dynamic Prompt Fusion",
        "aliases": [
          "Prompt Fusion",
          "Dynamic Prompt Scheduling"
        ],
        "category": "unique_technical",
        "rationale": "Represents a novel technique introduced in the paper for improving multi-task learning.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      },
      {
        "surface": "Multi-Task Learning",
        "canonical": "Multi-Task Learning",
        "aliases": [
          "MTL"
        ],
        "category": "specific_connectable",
        "rationale": "Central to the paper's approach and widely applicable in machine learning contexts.",
        "novelty_score": 0.3,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Cross-Domain Adaptation",
        "canonical": "Cross-Domain Adaptation",
        "aliases": [
          "Domain Adaptation"
        ],
        "category": "specific_connectable",
        "rationale": "Key concept for linking studies on model generalization across different domains.",
        "novelty_score": 0.4,
        "connectivity_score": 0.75,
        "specificity_score": 0.75,
        "link_intent_score": 0.78
      },
      {
        "surface": "Task Interference",
        "canonical": "Task Interference",
        "aliases": [
          "Negative Transfer"
        ],
        "category": "unique_technical",
        "rationale": "Important for understanding challenges in multi-task learning environments.",
        "novelty_score": 0.65,
        "connectivity_score": 0.6,
        "specificity_score": 0.78,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance",
      "model stability",
      "transferability"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.2,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Dynamic Prompt Fusion",
      "resolved_canonical": "Dynamic Prompt Fusion",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Multi-Task Learning",
      "resolved_canonical": "Multi-Task Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Cross-Domain Adaptation",
      "resolved_canonical": "Cross-Domain Adaptation",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.75,
        "specificity": 0.75,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Task Interference",
      "resolved_canonical": "Task Interference",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.6,
        "specificity": 0.78,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# Dynamic Prompt Fusion for Multi-Task and Cross-Domain Adaptation in LLMs

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18113.pdf)
**Category**: cs.LG
**Published**: 2025-09-24
**ArXiv ID**: [2509.18113](https://arxiv.org/abs/2509.18113)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Inceptive Transformers_ Enhancing Contextual Representations through Multi-Scale Feature Learning Across Domains and Languages_20250923|Inceptive Transformers: Enhancing Contextual Representations through Multi-Scale Feature Learning Across Domains and Languages]] (84.6% similar)
- [[2025-09-23/DeepInsert_ Early Layer Bypass for Efficient and Performant Multimodal Understanding_20250923|DeepInsert: Early Layer Bypass for Efficient and Performant Multimodal Understanding]] (84.1% similar)
- [[2025-09-23/A non-smooth regularization framework for learning over multitask graphs_20250923|A non-smooth regularization framework for learning over multitask graphs]] (83.1% similar)
- [[2025-09-23/Mitigating Strategy-Selection Bias in Reasoning for More Effective Test-Time Scaling_20250923|Mitigating Strategy-Selection Bias in Reasoning for More Effective Test-Time Scaling]] (83.0% similar)
- [[2025-09-23/MCP_ A Control-Theoretic Orchestration Framework for Synergistic Efficiency and Interpretability in Multimodal Large Language Models_20250923|MCP: A Control-Theoretic Orchestration Framework for Synergistic Efficiency and Interpretability in Multimodal Large Language Models]] (82.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Multi-Task Learning|Multi-Task Learning]], [[keywords/Cross-Domain Adaptation|Cross-Domain Adaptation]]
**âš¡ Unique Technical**: [[keywords/Dynamic Prompt Fusion|Dynamic Prompt Fusion]], [[keywords/Task Interference|Task Interference]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18113v1 Announce Type: cross 
Abstract: This study addresses the generalization limitations commonly observed in large language models under multi-task and cross-domain settings. Unlike prior methods such as SPoT, which depends on fixed prompt templates, our study introduces a unified multi-task learning framework with dynamic prompt scheduling mechanism. By introducing a prompt pool and a task-aware scheduling strategy, the method dynamically combines and aligns prompts for different tasks. This enhances the model's ability to capture semantic differences across tasks. During prompt fusion, the model uses task embeddings and a gating mechanism to finely control the prompt signals. This ensures alignment between prompt content and task-specific demands. At the same time, it builds flexible sharing pathways across tasks. In addition, the proposed optimization objective centers on joint multi-task learning. It incorporates an automatic learning strategy for scheduling weights, which effectively mitigates task interference and negative transfer. To evaluate the effectiveness of the method, a series of sensitivity experiments were conducted. These experiments examined the impact of prompt temperature parameters and task number variation. The results confirm the advantages of the proposed mechanism in maintaining model stability and enhancing transferability. Experimental findings show that the prompt scheduling method significantly improves performance on a range of language understanding and knowledge reasoning tasks. These results fully demonstrate its applicability and effectiveness in unified multi-task modeling and cross-domain adaptation.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ì¼ë°˜í™” í•œê³„ë¥¼ ë‹¤ë£¨ë©°, ê³ ì •ëœ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì— ì˜ì¡´í•˜ëŠ” ê¸°ì¡´ ë°©ë²•ê³¼ ë‹¬ë¦¬ ë™ì  í”„ë¡¬í”„íŠ¸ ìŠ¤ì¼€ì¤„ë§ ë©”ì»¤ë‹ˆì¦˜ì„ ê°–ì¶˜ í†µí•© ë©€í‹°íƒœìŠ¤í¬ í•™ìŠµ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ í’€ê³¼ íƒœìŠ¤í¬ ì¸ì‹ ìŠ¤ì¼€ì¤„ë§ ì „ëµì„ ë„ì…í•˜ì—¬ ë‹¤ì–‘í•œ íƒœìŠ¤í¬ì— ë§ì¶° í”„ë¡¬í”„íŠ¸ë¥¼ ë™ì ìœ¼ë¡œ ì¡°í•©í•˜ê³  ì •ë ¬í•¨ìœ¼ë¡œì¨ ëª¨ë¸ì˜ íƒœìŠ¤í¬ ê°„ ì˜ë¯¸ ì°¨ì´ í¬ì°© ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ ìœµí•© ì‹œ íƒœìŠ¤í¬ ì„ë² ë”©ê³¼ ê²Œì´íŒ… ë©”ì»¤ë‹ˆì¦˜ì„ ì‚¬ìš©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ì‹ í˜¸ë¥¼ ì„¸ë°€í•˜ê²Œ ì œì–´í•˜ë©°, íƒœìŠ¤í¬ ê°„ ìœ ì—°í•œ ê³µìœ  ê²½ë¡œë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤. ë˜í•œ, ìë™ í•™ìŠµ ì „ëµì„ í†µí•´ íƒœìŠ¤í¬ ê°„ ê°„ì„­ì„ ì¤„ì´ê³  ë¶€ì •ì  ì „ì´ë¥¼ ì™„í™”í•˜ëŠ” ìµœì í™” ëª©í‘œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ í”„ë¡¬í”„íŠ¸ ìŠ¤ì¼€ì¤„ë§ ë°©ë²•ì´ ì–¸ì–´ ì´í•´ ë° ì§€ì‹ ì¶”ë¡  íƒœìŠ¤í¬ì—ì„œ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚¤ë©°, í†µí•© ë©€í‹°íƒœìŠ¤í¬ ëª¨ë¸ë§ ë° ë„ë©”ì¸ ê°„ ì ì‘ì— íš¨ê³¼ì ì„ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë³¸ ì—°êµ¬ëŠ” ê³ ì •ëœ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì— ì˜ì¡´í•˜ëŠ” ê¸°ì¡´ ë°©ë²•ê³¼ ë‹¬ë¦¬, ë™ì  í”„ë¡¬í”„íŠ¸ ìŠ¤ì¼€ì¤„ë§ ë©”ì»¤ë‹ˆì¦˜ì„ ê°–ì¶˜ í†µí•© ë©€í‹°íƒœìŠ¤í¬ í•™ìŠµ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.
- 2. í”„ë¡¬í”„íŠ¸ í’€ê³¼ ì‘ì—… ì¸ì‹ ìŠ¤ì¼€ì¤„ë§ ì „ëµì„ í†µí•´ ë‹¤ì–‘í•œ ì‘ì—…ì— ëŒ€í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ë™ì ìœ¼ë¡œ ê²°í•© ë° ì •ë ¬í•˜ì—¬ ì‘ì—… ê°„ ì˜ë¯¸ì  ì°¨ì´ë¥¼ í¬ì°©í•˜ëŠ” ëª¨ë¸ì˜ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
- 3. í”„ë¡¬í”„íŠ¸ ìœµí•© ê³¼ì •ì—ì„œ ì‘ì—… ì„ë² ë”©ê³¼ ê²Œì´íŒ… ë©”ì»¤ë‹ˆì¦˜ì„ ì‚¬ìš©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ì‹ í˜¸ë¥¼ ì„¸ë°€í•˜ê²Œ ì œì–´í•˜ê³ , ì‘ì—…ë³„ ìš”êµ¬ ì‚¬í•­ê³¼ì˜ ì •ë ¬ì„ ë³´ì¥í•©ë‹ˆë‹¤.
- 4. ì œì•ˆëœ ìµœì í™” ëª©í‘œëŠ” ê³µë™ ë©€í‹°íƒœìŠ¤í¬ í•™ìŠµì— ì¤‘ì ì„ ë‘ë©°, ìë™ í•™ìŠµ ì „ëµì„ í†µí•´ ì‘ì—… ê°„ì„­ê³¼ ë¶€ì •ì  ì „ì´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì™„í™”í•©ë‹ˆë‹¤.
- 5. ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ í”„ë¡¬í”„íŠ¸ ìŠ¤ì¼€ì¤„ë§ ë°©ë²•ì´ ì–¸ì–´ ì´í•´ ë° ì§€ì‹ ì¶”ë¡  ì‘ì—…ì—ì„œ ì„±ëŠ¥ì„ í¬ê²Œ ê°œì„ í•˜ë©°, í†µí•© ë©€í‹°íƒœìŠ¤í¬ ëª¨ë¸ë§ ë° í¬ë¡œìŠ¤ ë„ë©”ì¸ ì ì‘ì—ì„œì˜ ì ìš© ê°€ëŠ¥ì„±ê³¼ íš¨ê³¼ì„±ì„ ì…ì¦í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 15:03:27*