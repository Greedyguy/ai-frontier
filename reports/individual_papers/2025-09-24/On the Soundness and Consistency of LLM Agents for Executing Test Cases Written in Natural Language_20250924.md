<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T14:13:33.208281",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Natural Language Test Case",
    "Execution Consistency",
    "Six Sigma",
    "Meta Llama 3.1 70B"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Natural Language Test Case": 0.78,
    "Execution Consistency": 0.77,
    "Six Sigma": 0.7,
    "Meta Llama 3.1 70B": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Large Language Models"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's focus on executing natural language test cases.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Natural Language Test Cases",
        "canonical": "Natural Language Test Case",
        "aliases": [
          "NL Test Cases"
        ],
        "category": "unique_technical",
        "rationale": "Key concept introduced for testing GUI applications using natural language.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Execution Consistency",
        "canonical": "Execution Consistency",
        "aliases": [
          "Consistency in Execution"
        ],
        "category": "unique_technical",
        "rationale": "Addresses the reliability of test case execution, a critical issue discussed in the paper.",
        "novelty_score": 0.68,
        "connectivity_score": 0.7,
        "specificity_score": 0.75,
        "link_intent_score": 0.77
      },
      {
        "surface": "Six Sigma",
        "canonical": "Six Sigma",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Referenced as a quality benchmark for evaluating test execution.",
        "novelty_score": 0.4,
        "connectivity_score": 0.72,
        "specificity_score": 0.65,
        "link_intent_score": 0.7
      },
      {
        "surface": "Meta Llama 3.1 70B",
        "canonical": "Meta Llama 3.1 70B",
        "aliases": [
          "Llama 3.1 70B"
        ],
        "category": "unique_technical",
        "rationale": "Specific LLM evaluated in the study, highlighting its performance in test execution.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "test case",
      "execution",
      "agent"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Natural Language Test Cases",
      "resolved_canonical": "Natural Language Test Case",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Execution Consistency",
      "resolved_canonical": "Execution Consistency",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.7,
        "specificity": 0.75,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Six Sigma",
      "resolved_canonical": "Six Sigma",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.72,
        "specificity": 0.65,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Meta Llama 3.1 70B",
      "resolved_canonical": "Meta Llama 3.1 70B",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# On the Soundness and Consistency of LLM Agents for Executing Test Cases Written in Natural Language

## 📋 메타데이터

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19136.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2509.19136](https://arxiv.org/abs/2509.19136)

## 🔗 유사한 논문
- [[2025-09-18/An LLM Agentic Approach for Legal-Critical Software_ A Case Study for Tax Prep Software_20250918|An LLM Agentic Approach for Legal-Critical Software: A Case Study for Tax Prep Software]] (84.7% similar)
- [[2025-09-19/From Capabilities to Performance_ Evaluating Key Functional Properties of LLM Architectures in Penetration Testing_20250919|From Capabilities to Performance: Evaluating Key Functional Properties of LLM Architectures in Penetration Testing]] (84.1% similar)
- [[2025-09-19/An LLM-based multi-agent framework for agile effort estimation_20250919|An LLM-based multi-agent framework for agile effort estimation]] (83.9% similar)
- [[2025-09-23/Large Language Models Badly Generalize across Option Length, Problem Types, and Irrelevant Noun Replacements_20250923|Large Language Models Badly Generalize across Option Length, Problem Types, and Irrelevant Noun Replacements]] (83.1% similar)
- [[2025-09-23/Evaluating CxG Generalisation in LLMs via Construction-Based NLI Fine Tuning_20250923|Evaluating CxG Generalisation in LLMs via Construction-Based NLI Fine Tuning]] (83.0% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Six Sigma|Six Sigma]]
**⚡ Unique Technical**: [[keywords/Natural Language Test Case|Natural Language Test Case]], [[keywords/Execution Consistency|Execution Consistency]], [[keywords/Meta Llama 3.1 70B|Meta Llama 3.1 70B]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.19136v1 Announce Type: cross 
Abstract: The use of natural language (NL) test cases for validating graphical user interface (GUI) applications is emerging as a promising direction to manually written executable test scripts, which are costly to develop and difficult to maintain. Recent advances in large language models (LLMs) have opened the possibility of the direct execution of NL test cases by LLM agents. This paper investigates this direction, focusing on the impact on NL test case unsoundness and on test case execution consistency. NL test cases are inherently unsound, as they may yield false failures due to ambiguous instructions or unpredictable agent behaviour. Furthermore, repeated executions of the same NL test case may lead to inconsistent outcomes, undermining test reliability. To address these challenges, we propose an algorithm for executing NL test cases with guardrail mechanisms and specialised agents that dynamically verify the correct execution of each test step. We introduce measures to evaluate the capabilities of LLMs in test execution and one measure to quantify execution consistency. We propose a definition of weak unsoundness to characterise contexts in which NL test case execution remains acceptable, with respect to the industrial quality levels Six Sigma. Our experimental evaluation with eight publicly available LLMs, ranging from 3B to 70B parameters, demonstrates both the potential and current limitations of current LLM agents for GUI testing. Our experiments show that Meta Llama 3.1 70B demonstrates acceptable capabilities in NL test case execution with high execution consistency (above the level 3-sigma). We provide prototype tools, test suites, and results.

## 📝 요약

이 논문은 자연어(NL) 테스트 케이스를 활용한 그래픽 사용자 인터페이스(GUI) 애플리케이션 검증의 가능성을 탐구합니다. 최근 대형 언어 모델(LLM)의 발전으로 NL 테스트 케이스의 직접 실행이 가능해졌습니다. 그러나 NL 테스트 케이스는 모호한 지시나 예측 불가능한 에이전트 행동으로 인해 잘못된 실패를 초래할 수 있으며, 반복 실행 시 일관성이 떨어질 수 있습니다. 이를 해결하기 위해, 각 테스트 단계의 정확한 실행을 동적으로 검증하는 알고리즘과 특화된 에이전트를 제안합니다. 실험 결과, Meta Llama 3.1 70B 모델이 높은 실행 일관성을 보이며 NL 테스트 케이스 실행에 적합함을 확인했습니다. 논문은 프로토타입 도구, 테스트 스위트 및 결과를 제공합니다.

## 🎯 주요 포인트

- 1. 자연어 테스트 케이스를 활용한 GUI 애플리케이션 검증은 수작업 테스트 스크립트의 대안으로 주목받고 있습니다.
- 2. 대형 언어 모델(LLM)의 발전으로 자연어 테스트 케이스의 직접 실행이 가능해졌습니다.
- 3. 자연어 테스트 케이스는 모호한 지시나 예측 불가능한 에이전트 행동으로 인해 불완전성이 존재합니다.
- 4. 반복 실행 시 결과의 일관성이 떨어질 수 있어 테스트 신뢰성을 저해할 수 있습니다.
- 5. Meta Llama 3.1 70B 모델은 높은 실행 일관성을 보이며, GUI 테스트에서 수용 가능한 성능을 보여줍니다.


---

*Generated on 2025-09-24 14:13:33*