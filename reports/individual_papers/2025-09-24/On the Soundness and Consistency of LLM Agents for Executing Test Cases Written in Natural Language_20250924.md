<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T14:13:33.208281",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Natural Language Test Case",
    "Execution Consistency",
    "Six Sigma",
    "Meta Llama 3.1 70B"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Natural Language Test Case": 0.78,
    "Execution Consistency": 0.77,
    "Six Sigma": 0.7,
    "Meta Llama 3.1 70B": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Large Language Models"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's focus on executing natural language test cases.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Natural Language Test Cases",
        "canonical": "Natural Language Test Case",
        "aliases": [
          "NL Test Cases"
        ],
        "category": "unique_technical",
        "rationale": "Key concept introduced for testing GUI applications using natural language.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Execution Consistency",
        "canonical": "Execution Consistency",
        "aliases": [
          "Consistency in Execution"
        ],
        "category": "unique_technical",
        "rationale": "Addresses the reliability of test case execution, a critical issue discussed in the paper.",
        "novelty_score": 0.68,
        "connectivity_score": 0.7,
        "specificity_score": 0.75,
        "link_intent_score": 0.77
      },
      {
        "surface": "Six Sigma",
        "canonical": "Six Sigma",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Referenced as a quality benchmark for evaluating test execution.",
        "novelty_score": 0.4,
        "connectivity_score": 0.72,
        "specificity_score": 0.65,
        "link_intent_score": 0.7
      },
      {
        "surface": "Meta Llama 3.1 70B",
        "canonical": "Meta Llama 3.1 70B",
        "aliases": [
          "Llama 3.1 70B"
        ],
        "category": "unique_technical",
        "rationale": "Specific LLM evaluated in the study, highlighting its performance in test execution.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "test case",
      "execution",
      "agent"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Natural Language Test Cases",
      "resolved_canonical": "Natural Language Test Case",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Execution Consistency",
      "resolved_canonical": "Execution Consistency",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.7,
        "specificity": 0.75,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Six Sigma",
      "resolved_canonical": "Six Sigma",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.72,
        "specificity": 0.65,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Meta Llama 3.1 70B",
      "resolved_canonical": "Meta Llama 3.1 70B",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# On the Soundness and Consistency of LLM Agents for Executing Test Cases Written in Natural Language

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19136.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2509.19136](https://arxiv.org/abs/2509.19136)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/An LLM Agentic Approach for Legal-Critical Software_ A Case Study for Tax Prep Software_20250918|An LLM Agentic Approach for Legal-Critical Software: A Case Study for Tax Prep Software]] (84.7% similar)
- [[2025-09-19/From Capabilities to Performance_ Evaluating Key Functional Properties of LLM Architectures in Penetration Testing_20250919|From Capabilities to Performance: Evaluating Key Functional Properties of LLM Architectures in Penetration Testing]] (84.1% similar)
- [[2025-09-19/An LLM-based multi-agent framework for agile effort estimation_20250919|An LLM-based multi-agent framework for agile effort estimation]] (83.9% similar)
- [[2025-09-23/Large Language Models Badly Generalize across Option Length, Problem Types, and Irrelevant Noun Replacements_20250923|Large Language Models Badly Generalize across Option Length, Problem Types, and Irrelevant Noun Replacements]] (83.1% similar)
- [[2025-09-23/Evaluating CxG Generalisation in LLMs via Construction-Based NLI Fine Tuning_20250923|Evaluating CxG Generalisation in LLMs via Construction-Based NLI Fine Tuning]] (83.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Six Sigma|Six Sigma]]
**âš¡ Unique Technical**: [[keywords/Natural Language Test Case|Natural Language Test Case]], [[keywords/Execution Consistency|Execution Consistency]], [[keywords/Meta Llama 3.1 70B|Meta Llama 3.1 70B]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19136v1 Announce Type: cross 
Abstract: The use of natural language (NL) test cases for validating graphical user interface (GUI) applications is emerging as a promising direction to manually written executable test scripts, which are costly to develop and difficult to maintain. Recent advances in large language models (LLMs) have opened the possibility of the direct execution of NL test cases by LLM agents. This paper investigates this direction, focusing on the impact on NL test case unsoundness and on test case execution consistency. NL test cases are inherently unsound, as they may yield false failures due to ambiguous instructions or unpredictable agent behaviour. Furthermore, repeated executions of the same NL test case may lead to inconsistent outcomes, undermining test reliability. To address these challenges, we propose an algorithm for executing NL test cases with guardrail mechanisms and specialised agents that dynamically verify the correct execution of each test step. We introduce measures to evaluate the capabilities of LLMs in test execution and one measure to quantify execution consistency. We propose a definition of weak unsoundness to characterise contexts in which NL test case execution remains acceptable, with respect to the industrial quality levels Six Sigma. Our experimental evaluation with eight publicly available LLMs, ranging from 3B to 70B parameters, demonstrates both the potential and current limitations of current LLM agents for GUI testing. Our experiments show that Meta Llama 3.1 70B demonstrates acceptable capabilities in NL test case execution with high execution consistency (above the level 3-sigma). We provide prototype tools, test suites, and results.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ìì—°ì–´(NL) í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ í™œìš©í•œ ê·¸ë˜í”½ ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤(GUI) ì• í”Œë¦¬ì¼€ì´ì…˜ ê²€ì¦ì˜ ê°€ëŠ¥ì„±ì„ íƒêµ¬í•©ë‹ˆë‹¤. ìµœê·¼ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ë°œì „ìœ¼ë¡œ NL í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ì˜ ì§ì ‘ ì‹¤í–‰ì´ ê°€ëŠ¥í•´ì¡ŒìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ NL í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ëŠ” ëª¨í˜¸í•œ ì§€ì‹œë‚˜ ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ í–‰ë™ìœ¼ë¡œ ì¸í•´ ì˜ëª»ëœ ì‹¤íŒ¨ë¥¼ ì´ˆë˜í•  ìˆ˜ ìˆìœ¼ë©°, ë°˜ë³µ ì‹¤í–‰ ì‹œ ì¼ê´€ì„±ì´ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ê° í…ŒìŠ¤íŠ¸ ë‹¨ê³„ì˜ ì •í™•í•œ ì‹¤í–‰ì„ ë™ì ìœ¼ë¡œ ê²€ì¦í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ê³¼ íŠ¹í™”ëœ ì—ì´ì „íŠ¸ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, Meta Llama 3.1 70B ëª¨ë¸ì´ ë†’ì€ ì‹¤í–‰ ì¼ê´€ì„±ì„ ë³´ì´ë©° NL í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‹¤í–‰ì— ì í•©í•¨ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ë…¼ë¬¸ì€ í”„ë¡œí† íƒ€ì… ë„êµ¬, í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ë° ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ìì—°ì–´ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ í™œìš©í•œ GUI ì• í”Œë¦¬ì¼€ì´ì…˜ ê²€ì¦ì€ ìˆ˜ì‘ì—… í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ì˜ ëŒ€ì•ˆìœ¼ë¡œ ì£¼ëª©ë°›ê³  ìˆìŠµë‹ˆë‹¤.
- 2. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ë°œì „ìœ¼ë¡œ ìì—°ì–´ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ì˜ ì§ì ‘ ì‹¤í–‰ì´ ê°€ëŠ¥í•´ì¡ŒìŠµë‹ˆë‹¤.
- 3. ìì—°ì–´ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ëŠ” ëª¨í˜¸í•œ ì§€ì‹œë‚˜ ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ í–‰ë™ìœ¼ë¡œ ì¸í•´ ë¶ˆì™„ì „ì„±ì´ ì¡´ì¬í•©ë‹ˆë‹¤.
- 4. ë°˜ë³µ ì‹¤í–‰ ì‹œ ê²°ê³¼ì˜ ì¼ê´€ì„±ì´ ë–¨ì–´ì§ˆ ìˆ˜ ìˆì–´ í…ŒìŠ¤íŠ¸ ì‹ ë¢°ì„±ì„ ì €í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- 5. Meta Llama 3.1 70B ëª¨ë¸ì€ ë†’ì€ ì‹¤í–‰ ì¼ê´€ì„±ì„ ë³´ì´ë©°, GUI í…ŒìŠ¤íŠ¸ì—ì„œ ìˆ˜ìš© ê°€ëŠ¥í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.


---

*Generated on 2025-09-24 14:13:33*