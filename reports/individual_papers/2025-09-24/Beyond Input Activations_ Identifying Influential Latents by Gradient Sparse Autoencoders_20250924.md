<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T14:33:43.139831",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Sparse Autoencoder",
    "Gradient Sparse Autoencoder",
    "Large Language Model",
    "Causal Influence"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Sparse Autoencoder": 0.75,
    "Gradient Sparse Autoencoder": 0.8,
    "Large Language Model": 0.7,
    "Causal Influence": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Sparse Autoencoders",
        "canonical": "Sparse Autoencoder",
        "aliases": [
          "SAE"
        ],
        "category": "unique_technical",
        "rationale": "Sparse Autoencoders are central to the paper's methodology and offer a unique perspective on model interpretation.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      },
      {
        "surface": "Gradient Sparse Autoencoder",
        "canonical": "Gradient Sparse Autoencoder",
        "aliases": [
          "GradSAE"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel method for identifying influential latents, crucial for understanding the paper's contribution.",
        "novelty_score": 0.85,
        "connectivity_score": 0.6,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are the primary context in which the paper's methods are applied.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.7
      },
      {
        "surface": "Causal Influence",
        "canonical": "Causal Influence",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Understanding causal influence is key to the paper's exploration of latent feature impact.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.75,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Sparse Autoencoders",
      "resolved_canonical": "Sparse Autoencoder",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Gradient Sparse Autoencoder",
      "resolved_canonical": "Gradient Sparse Autoencoder",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.6,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Causal Influence",
      "resolved_canonical": "Causal Influence",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.75,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# Beyond Input Activations: Identifying Influential Latents by Gradient Sparse Autoencoders

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2505.08080.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2505.08080](https://arxiv.org/abs/2505.08080)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-24/A Survey on Sparse Autoencoders_ Interpreting the Internal Mechanisms of Large Language Models_20250924|A Survey on Sparse Autoencoders: Interpreting the Internal Mechanisms of Large Language Models]] (88.4% similar)
- [[2025-09-23/Group-SAE_ Efficient Training of Sparse Autoencoders for Large Language Models via Layer Groups_20250923|Group-SAE: Efficient Training of Sparse Autoencoders for Large Language Models via Layer Groups]] (85.0% similar)
- [[2025-09-24/Safe-SAIL_ Towards a Fine-grained Safety Landscape of Large Language Models via Sparse Autoencoder Interpretation Framework_20250924|Safe-SAIL: Towards a Fine-grained Safety Landscape of Large Language Models via Sparse Autoencoder Interpretation Framework]] (84.1% similar)
- [[2025-09-24/Amortized Latent Steering_ Low-Cost Alternative to Test-Time Optimization_20250924|Amortized Latent Steering: Low-Cost Alternative to Test-Time Optimization]] (80.8% similar)
- [[2025-09-19/Opening the Black Box_ Interpretable LLMs via Semantic Resonance Architecture_20250919|Opening the Black Box: Interpretable LLMs via Semantic Resonance Architecture]] (80.7% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Causal Influence|Causal Influence]]
**âš¡ Unique Technical**: [[keywords/Sparse Autoencoder|Sparse Autoencoder]], [[keywords/Gradient Sparse Autoencoder|Gradient Sparse Autoencoder]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2505.08080v2 Announce Type: replace-cross 
Abstract: Sparse Autoencoders (SAEs) have recently emerged as powerful tools for interpreting and steering the internal representations of large language models (LLMs). However, conventional approaches to analyzing SAEs typically rely solely on input-side activations, without considering the causal influence between each latent feature and the model's output. This work is built on two key hypotheses: (1) activated latents do not contribute equally to the construction of the model's output, and (2) only latents with high causal influence are effective for model steering. To validate these hypotheses, we propose Gradient Sparse Autoencoder (GradSAE), a simple yet effective method that identifies the most influential latents by incorporating output-side gradient information.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ë‚´ë¶€ í‘œí˜„ì„ í•´ì„í•˜ê³  ì¡°ì •í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” í¬ì†Œ ì˜¤í† ì¸ì½”ë”(SAE)ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ Gradient Sparse Autoencoder(GradSAE)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ SAE ë¶„ì„ì€ ì…ë ¥ í™œì„±í™”ì—ë§Œ ì˜ì¡´í–ˆì§€ë§Œ, ì´ ì—°êµ¬ëŠ” ì ì¬ íŠ¹ì§•ê³¼ ëª¨ë¸ ì¶œë ¥ ê°„ì˜ ì¸ê³¼ì  ì˜í–¥ì„ ê³ ë ¤í•©ë‹ˆë‹¤. ì£¼ìš” ê¸°ì—¬ëŠ” (1) í™œì„±í™”ëœ ì ì¬ íŠ¹ì§•ë“¤ì´ ëª¨ë¸ ì¶œë ¥ì— ë™ì¼í•˜ê²Œ ê¸°ì—¬í•˜ì§€ ì•Šìœ¼ë©°, (2) ë†’ì€ ì¸ê³¼ì  ì˜í–¥ì„ ê°€ì§„ ì ì¬ íŠ¹ì§•ë§Œì´ ëª¨ë¸ ì¡°ì •ì— íš¨ê³¼ì ì´ë¼ëŠ” ê°€ì„¤ì„ ê²€ì¦í•œ ê²ƒì…ë‹ˆë‹¤. GradSAEëŠ” ì¶œë ¥ ì¸¡ì˜ ê·¸ë˜ë””ì–¸íŠ¸ ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ ê°€ì¥ ì˜í–¥ë ¥ ìˆëŠ” ì ì¬ íŠ¹ì§•ì„ ì‹ë³„í•˜ëŠ” ê°„ë‹¨í•˜ë©´ì„œë„ íš¨ê³¼ì ì¸ ë°©ë²•ë¡ ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. í¬ì†Œ ì˜¤í† ì¸ì½”ë”(SAE)ëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ë‚´ë¶€ í‘œí˜„ì„ í•´ì„í•˜ê³  ì¡°ì •í•˜ëŠ” ë° ìœ ìš©í•œ ë„êµ¬ë¡œ ë¶€ìƒí•˜ê³  ìˆë‹¤.
- 2. ê¸°ì¡´ SAE ë¶„ì„ ë°©ë²•ì€ ì…ë ¥ ì¸¡ í™œì„±í™”ì—ë§Œ ì˜ì¡´í•˜ë©°, ê° ì ì¬ íŠ¹ì§•ê³¼ ëª¨ë¸ ì¶œë ¥ ê°„ì˜ ì¸ê³¼ì  ì˜í–¥ì„ ê³ ë ¤í•˜ì§€ ì•ŠëŠ”ë‹¤.
- 3. ë³¸ ì—°êµ¬ëŠ” í™œì„±í™”ëœ ì ì¬ ë³€ìˆ˜ë“¤ì´ ëª¨ë¸ ì¶œë ¥ êµ¬ì„±ì— ë™ì¼í•˜ê²Œ ê¸°ì—¬í•˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ê°€ì„¤ì„ ì œì‹œí•œë‹¤.
- 4. ë†’ì€ ì¸ê³¼ì  ì˜í–¥ì„ ê°€ì§„ ì ì¬ ë³€ìˆ˜ë§Œì´ ëª¨ë¸ ì¡°ì •ì— íš¨ê³¼ì ì´ë¼ëŠ” ê°€ì„¤ì„ ì œì‹œí•œë‹¤.
- 5. GradSAEëŠ” ì¶œë ¥ ì¸¡ ê¸°ìš¸ê¸° ì •ë³´ë¥¼ í†µí•©í•˜ì—¬ ê°€ì¥ ì˜í–¥ë ¥ ìˆëŠ” ì ì¬ ë³€ìˆ˜ë¥¼ ì‹ë³„í•˜ëŠ” ê°„ë‹¨í•˜ë©´ì„œë„ íš¨ê³¼ì ì¸ ë°©ë²•ì´ë‹¤.


---

*Generated on 2025-09-24 14:33:43*