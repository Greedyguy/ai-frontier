<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T16:33:47.082856",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Vision-Language Model",
    "Chain-of-Thought Reasoning",
    "Multimodal Learning",
    "Language-aware Group Relative Policy Optimization",
    "Supervised Fine-Tuning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Vision-Language Model": 0.85,
    "Chain-of-Thought Reasoning": 0.78,
    "Multimodal Learning": 0.82,
    "Language-aware Group Relative Policy Optimization": 0.8,
    "Supervised Fine-Tuning": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Vision Language Model",
        "canonical": "Vision-Language Model",
        "aliases": [
          "VLM"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-Language Models are central to the paper's focus on multilingual visual question answering.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.78,
        "link_intent_score": 0.85
      },
      {
        "surface": "Chain-of-Thought",
        "canonical": "Chain-of-Thought Reasoning",
        "aliases": [
          "CoT"
        ],
        "category": "unique_technical",
        "rationale": "Chain-of-Thought reasoning is a unique approach highlighted for enhancing interpretability and reasoning.",
        "novelty_score": 0.65,
        "connectivity_score": 0.72,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Multimodal Reasoning",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal"
        ],
        "category": "specific_connectable",
        "rationale": "Multimodal reasoning is crucial for integrating visual and textual information in the framework.",
        "novelty_score": 0.58,
        "connectivity_score": 0.84,
        "specificity_score": 0.75,
        "link_intent_score": 0.82
      },
      {
        "surface": "Language-aware Group Relative Policy Optimization",
        "canonical": "Language-aware Group Relative Policy Optimization",
        "aliases": [
          "GRPO"
        ],
        "category": "unique_technical",
        "rationale": "This optimization technique is a novel contribution of the paper, enhancing model training.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Supervised Fine-Tuning",
        "canonical": "Supervised Fine-Tuning",
        "aliases": [
          "SFT"
        ],
        "category": "broad_technical",
        "rationale": "Supervised Fine-Tuning is a fundamental training method used in the paper's framework.",
        "novelty_score": 0.4,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "real-world applications",
      "public datasets",
      "accuracy improvements"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Vision Language Model",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.78,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Chain-of-Thought",
      "resolved_canonical": "Chain-of-Thought Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.72,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Multimodal Reasoning",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.84,
        "specificity": 0.75,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Language-aware Group Relative Policy Optimization",
      "resolved_canonical": "Language-aware Group Relative Policy Optimization",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Supervised Fine-Tuning",
      "resolved_canonical": "Supervised Fine-Tuning",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# LaV-CoT: Language-Aware Visual CoT with Multi-Aspect Reward Optimization for Real-World Multilingual VQA

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.10026.pdf)
**Category**: cs.CV
**Published**: 2025-09-24
**ArXiv ID**: [2509.10026](https://arxiv.org/abs/2509.10026)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Cache-of-Thought_ Master-Apprentice Framework for Cost-Effective Vision Language Model Reasoning_20250922|Cache-of-Thought: Master-Apprentice Framework for Cost-Effective Vision Language Model Reasoning]] (87.6% similar)
- [[2025-09-23/EvoCoT_ Overcoming the Exploration Bottleneck in Reinforcement Learning_20250923|EvoCoT: Overcoming the Exploration Bottleneck in Reinforcement Learning]] (87.5% similar)
- [[2025-09-24/CODI_ Compressing Chain-of-Thought into Continuous Space via Self-Distillation_20250924|CODI: Compressing Chain-of-Thought into Continuous Space via Self-Distillation]] (85.4% similar)
- [[2025-09-23/Open Vision Reasoner_ Transferring Linguistic Cognitive Behavior for Visual Reasoning_20250923|Open Vision Reasoner: Transferring Linguistic Cognitive Behavior for Visual Reasoning]] (84.6% similar)
- [[2025-09-18/Uni-cot_ Towards Unified Chain-of-Thought Reasoning Across Text and Vision_20250918|Uni-cot: Towards Unified Chain-of-Thought Reasoning Across Text and Vision]] (84.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Supervised Fine-Tuning|Supervised Fine-Tuning]]
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**âš¡ Unique Technical**: [[keywords/Chain-of-Thought Reasoning|Chain-of-Thought Reasoning]], [[keywords/Language-aware Group Relative Policy Optimization|Language-aware Group Relative Policy Optimization]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.10026v2 Announce Type: replace 
Abstract: As large vision language models (VLMs) advance, their capabilities in multilingual visual question answering (mVQA) have significantly improved. Chain-of-thought (CoT) reasoning has been proven to enhance interpretability and complex reasoning. However, most existing approaches rely primarily on textual CoT and provide limited support for multilingual multimodal reasoning, constraining their deployment in real-world applications. To address this gap, we introduce \textbf{LaV-CoT}, the first Language-aware Visual CoT framework with Multi-Aspect Reward Optimization. LaV-CoT incorporates an interpretable multi-stage reasoning pipeline consisting of Text Summary with Bounding Box (BBox), Language Identification, Spatial Object-level Captioning, and Step-by-step Logical Reasoning. Following this reasoning pipeline, we design an automated data curation method that generates multilingual CoT annotations through iterative generation, correction, and refinement, enabling scalable and high-quality training data. To improve reasoning and generalization, LaV-CoT adopts a two-stage training paradigm combining Supervised Fine-Tuning (SFT) with Language-aware Group Relative Policy Optimization (GRPO), guided by verifiable multi-aspect rewards including language consistency, structural accuracy, and semantic alignment. Extensive evaluations on public datasets including MMMB, Multilingual MMBench, and MTVQA show that LaV-CoT achieves up to ~9.5% accuracy improvements over open-source baselines of similar size and even surpasses models with 2$\times$ larger scales by ~2.6%. Moreover, LaV-CoT outperforms advanced proprietary models such as GPT-4o-0513 and Gemini-2.5-flash. We further conducted an online A/B test to validate our method on real-world data, highlighting its effectiveness for industrial deployment. Our code is available at this link: \href{https://github.com/HJNVR/LaV-CoT}

## ğŸ“ ìš”ì•½

LaV-CoTëŠ” ë‹¤êµ­ì–´ ì‹œê° ì§ˆë¬¸ ì‘ë‹µ(mVQA)ì—ì„œ ë‹¤êµ­ì–´ ë©€í‹°ëª¨ë‹¬ ì¶”ë¡ ì„ ì§€ì›í•˜ëŠ” ìµœì´ˆì˜ ì–¸ì–´ ì¸ì‹ ì‹œê°ì  ì‚¬ê³  ì²´ì¸(CoT) í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” í…ìŠ¤íŠ¸ ìš”ì•½, ì–¸ì–´ ì‹ë³„, ê³µê°„ ê°ì²´ ìˆ˜ì¤€ ìº¡ì…˜, ë‹¨ê³„ë³„ ë…¼ë¦¬ì  ì¶”ë¡ ì„ í¬í•¨í•œ ë‹¤ë‹¨ê³„ ì¶”ë¡  íŒŒì´í”„ë¼ì¸ì„ í†µí•´ í•´ì„ ê°€ëŠ¥ì„±ì„ ë†’ì…ë‹ˆë‹¤. LaV-CoTëŠ” ë°˜ë³µì ì¸ ìƒì„±, ìˆ˜ì •, ì •ì œë¥¼ í†µí•´ ë‹¤êµ­ì–´ CoT ì£¼ì„ì„ ìƒì„±í•˜ëŠ” ìë™ ë°ì´í„° íë ˆì´ì…˜ ë°©ë²•ì„ ì„¤ê³„í•˜ì—¬ ê³ í’ˆì§ˆì˜ í•™ìŠµ ë°ì´í„°ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ë˜í•œ, ì–¸ì–´ ì¼ê´€ì„±, êµ¬ì¡°ì  ì •í™•ì„±, ì˜ë¯¸ì  ì •ë ¬ì„ í¬í•¨í•œ ë‹¤ë©´ì  ë³´ìƒ ìµœì í™”ë¥¼ í†µí•´ ì¶”ë¡  ë° ì¼ë°˜í™”ë¥¼ ê°œì„ í•©ë‹ˆë‹¤. ê³µê°œ ë°ì´í„°ì…‹ í‰ê°€ ê²°ê³¼, LaV-CoTëŠ” ìœ ì‚¬ í¬ê¸°ì˜ ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ ëŒ€ë¹„ ìµœëŒ€ 9.5%ì˜ ì •í™•ë„ í–¥ìƒì„ ë³´ì˜€ìœ¼ë©°, 2ë°° í° ëª¨ë¸ë³´ë‹¤ë„ 2.6% ë” ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë‚˜íƒ€ëƒˆìŠµë‹ˆë‹¤. ë˜í•œ, LaV-CoTëŠ” GPT-4o-0513 ë° Gemini-2.5-flashì™€ ê°™ì€ ê³ ê¸‰ ë…ì  ëª¨ë¸ì„ ëŠ¥ê°€í–ˆìŠµë‹ˆë‹¤. ì˜¨ë¼ì¸ A/B í…ŒìŠ¤íŠ¸ë¥¼ í†µí•´ ì‚°ì—…ì  ë°°í¬ì˜ íš¨ê³¼ì„±ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. LaV-CoTëŠ” ë‹¤ì¤‘ ì¸¡ë©´ ë³´ìƒ ìµœì í™”ë¥¼ í†µí•´ ë‹¤êµ­ì–´ ì‹œê°ì  ì§ˆë¬¸ ì‘ë‹µ(mVQA)ì—ì„œ í•´ì„ ê°€ëŠ¥ì„±ê³¼ ë³µì¡í•œ ì¶”ë¡ ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
- 2. LaV-CoTëŠ” í…ìŠ¤íŠ¸ ìš”ì•½, ì–¸ì–´ ì‹ë³„, ê³µê°„ ê°ì²´ ìˆ˜ì¤€ ìº¡ì…˜, ë‹¨ê³„ë³„ ë…¼ë¦¬ì  ì¶”ë¡ ìœ¼ë¡œ êµ¬ì„±ëœ ë‹¤ë‹¨ê³„ ì¶”ë¡  íŒŒì´í”„ë¼ì¸ì„ í¬í•¨í•©ë‹ˆë‹¤.
- 3. ìë™ ë°ì´í„° íë ˆì´ì…˜ ë°©ë²•ì„ í†µí•´ ë‹¤êµ­ì–´ CoT ì£¼ì„ì„ ìƒì„±í•˜ì—¬ í™•ì¥ ê°€ëŠ¥í•˜ê³  ê³ í’ˆì§ˆì˜ í•™ìŠµ ë°ì´í„°ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
- 4. LaV-CoTëŠ” ì–¸ì–´ ì¼ê´€ì„±, êµ¬ì¡°ì  ì •í™•ì„±, ì˜ë¯¸ì  ì •ë ¬ì„ í¬í•¨í•œ ë‹¤ì¤‘ ì¸¡ë©´ ë³´ìƒì„ í†µí•´ ë‘ ë‹¨ê³„ì˜ í•™ìŠµ íŒ¨ëŸ¬ë‹¤ì„ì„ ì±„íƒí•˜ì—¬ ì¶”ë¡ ê³¼ ì¼ë°˜í™”ë¥¼ ê°œì„ í•©ë‹ˆë‹¤.
- 5. LaV-CoTëŠ” ê³µê°œ ë°ì´í„°ì…‹ì—ì„œ ìœ ì‚¬í•œ í¬ê¸°ì˜ ì˜¤í”ˆ ì†ŒìŠ¤ ëª¨ë¸ë³´ë‹¤ ìµœëŒ€ 9.5% ì •í™•ë„ í–¥ìƒì„ ë‹¬ì„±í•˜ë©°, ìƒìš© ëª¨ë¸ë³´ë‹¤ë„ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.


---

*Generated on 2025-09-24 16:33:47*