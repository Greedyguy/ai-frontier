<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T15:39:32.736244",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Persian Literary Text Generation",
    "Torrance Tests of Creative Thinking",
    "Culturally Relevant Expressions",
    "Literary Devices"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.78,
    "Persian Literary Text Generation": 0.79,
    "Torrance Tests of Creative Thinking": 0.75,
    "Culturally Relevant Expressions": 0.73,
    "Literary Devices": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Connects to existing discussions on the capabilities and limitations of LLMs across languages.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.78
      },
      {
        "surface": "Persian Literary Text Generation",
        "canonical": "Persian Literary Text Generation",
        "aliases": [
          "Persian Text Generation"
        ],
        "category": "unique_technical",
        "rationale": "Focuses on a specific application of LLMs in a non-English context, highlighting cultural relevance.",
        "novelty_score": 0.72,
        "connectivity_score": 0.64,
        "specificity_score": 0.82,
        "link_intent_score": 0.79
      },
      {
        "surface": "Torrance Tests of Creative Thinking",
        "canonical": "Torrance Tests of Creative Thinking",
        "aliases": [
          "TTCT"
        ],
        "category": "unique_technical",
        "rationale": "Provides a standardized method for assessing creativity, linking to creativity evaluation frameworks.",
        "novelty_score": 0.68,
        "connectivity_score": 0.59,
        "specificity_score": 0.78,
        "link_intent_score": 0.75
      },
      {
        "surface": "Culturally Relevant Expressions",
        "canonical": "Culturally Relevant Expressions",
        "aliases": [
          "Cultural Expressions"
        ],
        "category": "unique_technical",
        "rationale": "Highlights the importance of cultural context in text generation, relevant for cross-cultural NLP studies.",
        "novelty_score": 0.65,
        "connectivity_score": 0.61,
        "specificity_score": 0.77,
        "link_intent_score": 0.73
      },
      {
        "surface": "Literary Devices",
        "canonical": "Literary Devices",
        "aliases": [
          "Simile",
          "Metaphor",
          "Hyperbole",
          "Antithesis"
        ],
        "category": "specific_connectable",
        "rationale": "Links to studies on how LLMs understand and generate complex literary constructs.",
        "novelty_score": 0.55,
        "connectivity_score": 0.83,
        "specificity_score": 0.7,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Persian Literary Text Generation",
      "resolved_canonical": "Persian Literary Text Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.64,
        "specificity": 0.82,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Torrance Tests of Creative Thinking",
      "resolved_canonical": "Torrance Tests of Creative Thinking",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.59,
        "specificity": 0.78,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Culturally Relevant Expressions",
      "resolved_canonical": "Culturally Relevant Expressions",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.61,
        "specificity": 0.77,
        "link_intent": 0.73
      }
    },
    {
      "candidate_surface": "Literary Devices",
      "resolved_canonical": "Literary Devices",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.83,
        "specificity": 0.7,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Evaluating the Creativity of LLMs in Persian Literary Text Generation

## 📋 메타데이터

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18401.pdf)
**Category**: cs.CL
**Published**: 2025-09-24
**ArXiv ID**: [2509.18401](https://arxiv.org/abs/2509.18401)

## 🔗 유사한 논문
- [[2025-09-22/A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages_20250922|A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages]] (86.0% similar)
- [[2025-09-22/Creative Preference Optimization_20250922|Creative Preference Optimization]] (85.8% similar)
- [[2025-09-23/MAKIEval_ A Multilingual Automatic WiKidata-based Framework for Cultural Awareness Evaluation for LLMs_20250923|MAKIEval: A Multilingual Automatic WiKidata-based Framework for Cultural Awareness Evaluation for LLMs]] (83.8% similar)
- [[2025-09-22/Benchmark of stylistic variation in LLM-generated texts_20250922|Benchmark of stylistic variation in LLM-generated texts]] (83.8% similar)
- [[2025-09-23/Measuring Scalar Constructs in Social Science with LLMs_20250923|Measuring Scalar Constructs in Social Science with LLMs]] (83.2% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Literary Devices|Literary Devices]]
**⚡ Unique Technical**: [[keywords/Persian Literary Text Generation|Persian Literary Text Generation]], [[keywords/Torrance Tests of Creative Thinking|Torrance Tests of Creative Thinking]], [[keywords/Culturally Relevant Expressions|Culturally Relevant Expressions]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.18401v1 Announce Type: new 
Abstract: Large language models (LLMs) have demonstrated notable creative abilities in generating literary texts, including poetry and short stories. However, prior research has primarily centered on English, with limited exploration of non-English literary traditions and without standardized methods for assessing creativity. In this paper, we evaluate the capacity of LLMs to generate Persian literary text enriched with culturally relevant expressions. We build a dataset of user-generated Persian literary spanning 20 diverse topics and assess model outputs along four creativity dimensions-originality, fluency, flexibility, and elaboration-by adapting the Torrance Tests of Creative Thinking. To reduce evaluation costs, we adopt an LLM as a judge for automated scoring and validate its reliability against human judgments using intraclass correlation coefficients, observing strong agreement. In addition, we analyze the models' ability to understand and employ four core literary devices: simile, metaphor, hyperbole, and antithesis. Our results highlight both the strengths and limitations of LLMs in Persian literary text generation, underscoring the need for further refinement.

## 📝 요약

이 논문은 대형 언어 모델(LLM)의 페르시아 문학 텍스트 생성 능력을 평가합니다. 연구는 20개의 다양한 주제를 포함하는 사용자 생성 페르시아 문학 데이터셋을 구축하고, 창의성의 네 가지 차원(독창성, 유창성, 융통성, 정교함)에서 모델 출력을 평가합니다. 평가 비용을 줄이기 위해 LLM을 자동 채점자로 사용하고, 인간 평가와의 신뢰성을 검증하여 높은 일치를 보였습니다. 또한, 비유, 은유, 과장, 대조의 네 가지 문학적 장치 사용 능력을 분석했습니다. 결과는 LLM의 페르시아 문학 텍스트 생성의 강점과 한계를 강조하며, 추가 개선의 필요성을 시사합니다.

## 🎯 주요 포인트

- 1. 대형 언어 모델(LLM)은 문학 텍스트 생성에서 창의적인 능력을 보여주었으나, 비영어권 문학 전통에 대한 연구는 제한적이었다.
- 2. 본 연구는 LLM이 페르시아 문학 텍스트를 생성하는 능력을 평가하며, 문화적으로 관련된 표현을 포함하도록 했다.
- 3. 창의성 평가를 위해 Torrance Tests of Creative Thinking을 변형하여 독창성, 유창성, 융통성, 정교성의 네 가지 차원에서 모델 출력을 평가했다.
- 4. 평가 비용을 줄이기 위해 LLM을 자동 채점의 판사로 채택하고, 인간 판단과의 신뢰성을 검증하여 강한 일치를 관찰했다.
- 5. LLM이 비유, 은유, 과장, 대조의 네 가지 핵심 문학 장치를 이해하고 사용하는 능력을 분석했다.


---

*Generated on 2025-09-24 15:39:32*