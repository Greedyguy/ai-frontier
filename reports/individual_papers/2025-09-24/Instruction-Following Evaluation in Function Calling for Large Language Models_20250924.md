<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T13:25:31.854400",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Function Calling",
    "Large Language Model",
    "Instruction Following",
    "Benchmark",
    "Formatting Rules"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Function Calling": 0.75,
    "Large Language Model": 0.8,
    "Instruction Following": 0.78,
    "Benchmark": 0.7,
    "Formatting Rules": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Function Calling",
        "canonical": "Function Calling",
        "aliases": [
          "Function Invocation"
        ],
        "category": "unique_technical",
        "rationale": "Function calling is a core capability being evaluated, making it a unique technical focus of the paper.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      },
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "Central to the evaluation, connecting to broader discussions on AI capabilities.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.5,
        "link_intent_score": 0.8
      },
      {
        "surface": "Instruction Following",
        "canonical": "Instruction Following",
        "aliases": [
          "Adherence to Instructions"
        ],
        "category": "unique_technical",
        "rationale": "The paper introduces a benchmark specifically for evaluating instruction following, highlighting its unique focus.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.75,
        "link_intent_score": 0.78
      },
      {
        "surface": "Benchmark",
        "canonical": "Benchmark",
        "aliases": [
          "Evaluation Framework"
        ],
        "category": "specific_connectable",
        "rationale": "Benchmarks are crucial for evaluating AI models, providing a direct link to performance assessments.",
        "novelty_score": 0.4,
        "connectivity_score": 0.85,
        "specificity_score": 0.6,
        "link_intent_score": 0.7
      },
      {
        "surface": "Formatting Rules",
        "canonical": "Formatting Rules",
        "aliases": [
          "Format Adherence"
        ],
        "category": "unique_technical",
        "rationale": "The paper highlights the importance of adhering to specific formatting rules, a unique aspect of the evaluation.",
        "novelty_score": 0.68,
        "connectivity_score": 0.6,
        "specificity_score": 0.78,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Function Calling",
      "resolved_canonical": "Function Calling",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.5,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Instruction Following",
      "resolved_canonical": "Instruction Following",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.75,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Benchmark",
      "resolved_canonical": "Benchmark",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.85,
        "specificity": 0.6,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Formatting Rules",
      "resolved_canonical": "Formatting Rules",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.6,
        "specificity": 0.78,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# Instruction-Following Evaluation in Function Calling for Large Language Models

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18420.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2509.18420](https://arxiv.org/abs/2509.18420)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/EquiBench_ Benchmarking Large Language Models' Reasoning about Program Semantics via Equivalence Checking_20250923|EquiBench: Benchmarking Large Language Models' Reasoning about Program Semantics via Equivalence Checking]] (83.1% similar)
- [[2025-09-23/From Scores to Steps_ Diagnosing and Improving LLM Performance in Evidence-Based Medical Calculations_20250923|From Scores to Steps: Diagnosing and Improving LLM Performance in Evidence-Based Medical Calculations]] (81.7% similar)
- [[2025-09-18/Self-Guided Function Calling in Large Language Models via Stepwise Experience Recall_20250918|Self-Guided Function Calling in Large Language Models via Stepwise Experience Recall]] (81.1% similar)
- [[2025-09-19/Ticket-Bench_ A Kickoff for Multilingual and Regionalized Agent Evaluation_20250919|Ticket-Bench: A Kickoff for Multilingual and Regionalized Agent Evaluation]] (81.0% similar)
- [[2025-09-23/Digging Into the Internal_ Causality-Based Analysis of LLM Function Calling_20250923|Digging Into the Internal: Causality-Based Analysis of LLM Function Calling]] (80.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Benchmark|Benchmark]]
**âš¡ Unique Technical**: [[keywords/Function Calling|Function Calling]], [[keywords/Instruction Following|Instruction Following]], [[keywords/Formatting Rules|Formatting Rules]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18420v1 Announce Type: new 
Abstract: Function calling is a core capability of large language models, essential for AI agents. Existing benchmarks such as the Berkeley Function Calling Leaderboard (BFCL), tau^2-Bench (arXiv:2506.07982), and ACEBench (arXiv:2501.12851) evaluate argument correctness but do not test adherence to format instructions embedded in parameter descriptions, such as enclosing values in double quotes or using ISO date formats.
  We introduce IFEval-FC, a benchmark inspired by IFEval (arXiv:2311.07911) that assesses precise instruction following in function calling. IFEval-FC encodes verifiable formats directly within JSON schema descriptions, for example specifying that a value must not contain punctuation. It includes 750 test cases, each consisting of a function with an embedded format for one of its input parameters and a corresponding user query. Evaluation is fully algorithmic, ensuring objectivity, reproducibility, and scalability.
  Our results show that even state-of-the-art proprietary models, including GPT-5 and Claude 4.1 Opus, frequently fail to follow basic formatting rules, highlighting a practical limitation for real-world agent systems. The complete codebase and data are publicly available at https://github.com/Skripkon/IFEval-FC.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ í•µì‹¬ ê¸°ëŠ¥ì¸ í•¨ìˆ˜ í˜¸ì¶œì—ì„œ í˜•ì‹ ì§€ì¹¨ ì¤€ìˆ˜ ì—¬ë¶€ë¥¼ í‰ê°€í•˜ëŠ” ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ IFEval-FCë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ê¸°ì¡´ ë²¤ì¹˜ë§ˆí¬ëŠ” ì¸ìˆ˜ì˜ ì •í™•ì„±ë§Œ í‰ê°€í•˜ì§€ë§Œ, IFEval-FCëŠ” JSON ìŠ¤í‚¤ë§ˆë¥¼ í†µí•´ í˜•ì‹ ì§€ì¹¨ ì¤€ìˆ˜ ì—¬ë¶€ë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤. 750ê°œì˜ í…ŒìŠ¤íŠ¸ ì‚¬ë¡€ë¥¼ í¬í•¨í•˜ë©°, ì•Œê³ ë¦¬ì¦˜ì  í‰ê°€ë¥¼ í†µí•´ ê°ê´€ì„±ê³¼ ì¬í˜„ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤. ì—°êµ¬ ê²°ê³¼, ìµœì‹  ëª¨ë¸ë“¤ë„ ê¸°ë³¸ í˜•ì‹ ê·œì¹™ì„ ìì£¼ ìœ„ë°˜í•˜ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚˜, ì‹¤ì œ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì—ì„œì˜ í•œê³„ë¥¼ ë“œëŸ¬ëƒ…ë‹ˆë‹¤. ì „ì²´ ì½”ë“œì™€ ë°ì´í„°ëŠ” ê³µê°œë˜ì–´ ìˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. IFEval-FCëŠ” í•¨ìˆ˜ í˜¸ì¶œì—ì„œ ì •í™•í•œ ì§€ì¹¨ ì¤€ìˆ˜ë¥¼ í‰ê°€í•˜ëŠ” ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ë¡œ, JSON ìŠ¤í‚¤ë§ˆ ì„¤ëª… ë‚´ì— ê²€ì¦ ê°€ëŠ¥í•œ í˜•ì‹ì„ ì¸ì½”ë”©í•©ë‹ˆë‹¤.
- 2. IFEval-FCëŠ” 750ê°œì˜ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ í¬í•¨í•˜ë©°, ê° ì¼€ì´ìŠ¤ëŠ” ì…ë ¥ ë§¤ê°œë³€ìˆ˜ì— ëŒ€í•œ í˜•ì‹ì´ ë‚´ì¥ëœ í•¨ìˆ˜ì™€ ì‚¬ìš©ì ì¿¼ë¦¬ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.
- 3. í‰ê°€ ê³¼ì •ì€ ì™„ì „íˆ ì•Œê³ ë¦¬ì¦˜ì ìœ¼ë¡œ ì´ë£¨ì–´ì ¸ ê°ê´€ì„±, ì¬í˜„ì„±, í™•ì¥ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤.
- 4. ìµœì‹  ëª¨ë¸ì¸ GPT-5ì™€ Claude 4.1 Opusì¡°ì°¨ ê¸°ë³¸ì ì¸ í˜•ì‹ ê·œì¹™ì„ ìì£¼ ë”°ë¥´ì§€ ëª»í•˜ë©°, ì´ëŠ” ì‹¤ì œ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì—ì„œì˜ ì‹¤ìš©ì  í•œê³„ë¥¼ ë“œëŸ¬ëƒ…ë‹ˆë‹¤.
- 5. ì „ì²´ ì½”ë“œë² ì´ìŠ¤ì™€ ë°ì´í„°ëŠ” ê³µê°œì ìœ¼ë¡œ ì œê³µë˜ë©°, GitHubì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 13:25:31*