<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T13:41:50.180159",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Qianfan-VL",
    "Vision-Language Model",
    "Domain Enhancement",
    "Multimodal Learning",
    "Chain-of-Thought Reasoning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Qianfan-VL": 0.78,
    "Vision-Language Model": 0.82,
    "Domain Enhancement": 0.77,
    "Multimodal Learning": 0.8,
    "Chain-of-Thought Reasoning": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Qianfan-VL",
        "canonical": "Qianfan-VL",
        "aliases": [
          "Qianfan-VL-8B",
          "Qianfan-VL-70B"
        ],
        "category": "unique_technical",
        "rationale": "Qianfan-VL represents a specific series of multimodal models with unique domain-enhancement techniques.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.78
      },
      {
        "surface": "Vision-Language Models",
        "canonical": "Vision-Language Model",
        "aliases": [
          "Vision-Language"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-Language Models are a key focus of the paper and align with trending concepts in AI.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.8,
        "link_intent_score": 0.82
      },
      {
        "surface": "Domain Enhancement",
        "canonical": "Domain Enhancement",
        "aliases": [
          "Domain-Enhanced"
        ],
        "category": "unique_technical",
        "rationale": "Domain Enhancement is a central technique in the paper, critical for improving model performance.",
        "novelty_score": 0.7,
        "connectivity_score": 0.75,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      },
      {
        "surface": "Multimodal Large Language Models",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal Models"
        ],
        "category": "specific_connectable",
        "rationale": "The paper focuses on multimodal capabilities, linking to broader trends in AI research.",
        "novelty_score": 0.5,
        "connectivity_score": 0.9,
        "specificity_score": 0.78,
        "link_intent_score": 0.8
      },
      {
        "surface": "Chain-of-Thought Capabilities",
        "canonical": "Chain-of-Thought Reasoning",
        "aliases": [
          "Chain-of-Thought"
        ],
        "category": "specific_connectable",
        "rationale": "Chain-of-Thought Reasoning is a specific technique highlighted for its impact on reasoning tasks.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.82,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "state-of-the-art",
      "performance",
      "methodology"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Qianfan-VL",
      "resolved_canonical": "Qianfan-VL",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Vision-Language Models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.8,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Domain Enhancement",
      "resolved_canonical": "Domain Enhancement",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.75,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Multimodal Large Language Models",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.9,
        "specificity": 0.78,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Chain-of-Thought Capabilities",
      "resolved_canonical": "Chain-of-Thought Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.82,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Qianfan-VL: Domain-Enhanced Universal Vision-Language Models

## 📋 메타데이터

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18189.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2509.18189](https://arxiv.org/abs/2509.18189)

## 🔗 유사한 논문
- [[2025-09-19/UnifiedVisual_ A Framework for Constructing Unified Vision-Language Datasets_20250919|UnifiedVisual: A Framework for Constructing Unified Vision-Language Datasets]] (83.7% similar)
- [[2025-09-18/SAIL-VL2 Technical Report_20250918|SAIL-VL2 Technical Report]] (83.3% similar)
- [[2025-09-19/ScaleCUA_ Scaling Open-Source Computer Use Agents with Cross-Platform Data_20250919|ScaleCUA: Scaling Open-Source Computer Use Agents with Cross-Platform Data]] (83.2% similar)
- [[2025-09-23/Open Vision Reasoner_ Transferring Linguistic Cognitive Behavior for Visual Reasoning_20250923|Open Vision Reasoner: Transferring Linguistic Cognitive Behavior for Visual Reasoning]] (83.1% similar)
- [[2025-09-23/Seeing is Believing? Mitigating OCR Hallucinations in Multimodal Large Language Models_20250923|Seeing is Believing? Mitigating OCR Hallucinations in Multimodal Large Language Models]] (82.1% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]], [[keywords/Chain-of-Thought Reasoning|Chain-of-Thought Reasoning]]
**⚡ Unique Technical**: [[keywords/Qianfan-VL|Qianfan-VL]], [[keywords/Domain Enhancement|Domain Enhancement]]
**🚀 Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.18189v1 Announce Type: cross 
Abstract: We present Qianfan-VL, a series of multimodal large language models ranging from 3B to 70B parameters, achieving state-of-the-art performance through innovative domain enhancement techniques. Our approach employs multi-stage progressive training and high-precision data synthesis pipelines, which prove to be critical technologies for enhancing domain-specific capabilities while maintaining strong general performance. Qianfan-VL achieves comparable results to leading open-source models on general benchmarks, with state-of-the-art performance on benchmarks such as CCBench, SEEDBench IMG, ScienceQA, and MMStar. The domain enhancement strategy delivers significant advantages in OCR and document understanding, validated on both public benchmarks (OCRBench 873, DocVQA 94.75%) and in-house evaluations. Notably, Qianfan-VL-8B and 70B variants incorporate long chain-of-thought capabilities, demonstrating superior performance on mathematical reasoning (MathVista 78.6%) and logical inference tasks. All models are trained entirely on Baidu's Kunlun P800 chips, validating the capability of large-scale AI infrastructure to train SOTA-level multimodal models with over 90% scaling efficiency on 5000 chips for a single task. This work establishes an effective methodology for developing domain-enhanced multimodal models suitable for diverse enterprise deployment scenarios.

## 📝 요약

Qianfan-VL은 3억에서 700억 개의 매개변수를 가진 다중 모달 대형 언어 모델 시리즈로, 혁신적인 도메인 강화 기법을 통해 최첨단 성능을 달성했습니다. 다단계 점진적 훈련과 고정밀 데이터 합성 파이프라인을 활용하여 도메인 특화 능력을 강화하면서도 일반 성능을 유지합니다. 이 모델은 CCBench, SEEDBench IMG, ScienceQA, MMStar 등에서 최첨단 성능을 보였으며, OCR 및 문서 이해 분야에서도 뛰어난 성과를 입증했습니다. 특히 Qianfan-VL-8B와 70B 모델은 수학적 추론 및 논리적 추론 작업에서 우수한 성능을 보여줍니다. 모든 모델은 Baidu의 Kunlun P800 칩에서 훈련되어 대규모 AI 인프라의 효율성을 입증했습니다. 이 연구는 다양한 기업 배포 시나리오에 적합한 도메인 강화 다중 모달 모델 개발 방법론을 제시합니다.

## 🎯 주요 포인트

- 1. Qianfan-VL은 3B에서 70B 파라미터의 멀티모달 대형 언어 모델로, 혁신적인 도메인 강화 기술을 통해 최첨단 성능을 달성했습니다.
- 2. 다단계 점진적 훈련과 고정밀 데이터 합성 파이프라인을 사용하여 도메인 특화 기능을 강화하면서도 강력한 일반 성능을 유지합니다.
- 3. Qianfan-VL은 CCBench, SEEDBench IMG, ScienceQA, MMStar 등의 벤치마크에서 최첨단 성능을 보여줍니다.
- 4. 도메인 강화 전략은 OCR 및 문서 이해에서 상당한 이점을 제공하며, OCRBench 873 및 DocVQA 94.75%와 같은 공공 벤치마크에서 검증되었습니다.
- 5. Baidu의 Kunlun P800 칩에서 모든 모델이 훈련되었으며, 5000개의 칩을 사용하여 단일 작업에서 90% 이상의 확장 효율성을 달성했습니다.


---

*Generated on 2025-09-24 13:41:50*