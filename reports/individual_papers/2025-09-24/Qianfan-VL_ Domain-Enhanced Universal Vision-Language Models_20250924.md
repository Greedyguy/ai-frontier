<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T13:41:50.180159",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Qianfan-VL",
    "Vision-Language Model",
    "Domain Enhancement",
    "Multimodal Learning",
    "Chain-of-Thought Reasoning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Qianfan-VL": 0.78,
    "Vision-Language Model": 0.82,
    "Domain Enhancement": 0.77,
    "Multimodal Learning": 0.8,
    "Chain-of-Thought Reasoning": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Qianfan-VL",
        "canonical": "Qianfan-VL",
        "aliases": [
          "Qianfan-VL-8B",
          "Qianfan-VL-70B"
        ],
        "category": "unique_technical",
        "rationale": "Qianfan-VL represents a specific series of multimodal models with unique domain-enhancement techniques.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.78
      },
      {
        "surface": "Vision-Language Models",
        "canonical": "Vision-Language Model",
        "aliases": [
          "Vision-Language"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-Language Models are a key focus of the paper and align with trending concepts in AI.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.8,
        "link_intent_score": 0.82
      },
      {
        "surface": "Domain Enhancement",
        "canonical": "Domain Enhancement",
        "aliases": [
          "Domain-Enhanced"
        ],
        "category": "unique_technical",
        "rationale": "Domain Enhancement is a central technique in the paper, critical for improving model performance.",
        "novelty_score": 0.7,
        "connectivity_score": 0.75,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      },
      {
        "surface": "Multimodal Large Language Models",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal Models"
        ],
        "category": "specific_connectable",
        "rationale": "The paper focuses on multimodal capabilities, linking to broader trends in AI research.",
        "novelty_score": 0.5,
        "connectivity_score": 0.9,
        "specificity_score": 0.78,
        "link_intent_score": 0.8
      },
      {
        "surface": "Chain-of-Thought Capabilities",
        "canonical": "Chain-of-Thought Reasoning",
        "aliases": [
          "Chain-of-Thought"
        ],
        "category": "specific_connectable",
        "rationale": "Chain-of-Thought Reasoning is a specific technique highlighted for its impact on reasoning tasks.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.82,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "state-of-the-art",
      "performance",
      "methodology"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Qianfan-VL",
      "resolved_canonical": "Qianfan-VL",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Vision-Language Models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.8,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Domain Enhancement",
      "resolved_canonical": "Domain Enhancement",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.75,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Multimodal Large Language Models",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.9,
        "specificity": 0.78,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Chain-of-Thought Capabilities",
      "resolved_canonical": "Chain-of-Thought Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.82,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Qianfan-VL: Domain-Enhanced Universal Vision-Language Models

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18189.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2509.18189](https://arxiv.org/abs/2509.18189)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/UnifiedVisual_ A Framework for Constructing Unified Vision-Language Datasets_20250919|UnifiedVisual: A Framework for Constructing Unified Vision-Language Datasets]] (83.7% similar)
- [[2025-09-18/SAIL-VL2 Technical Report_20250918|SAIL-VL2 Technical Report]] (83.3% similar)
- [[2025-09-19/ScaleCUA_ Scaling Open-Source Computer Use Agents with Cross-Platform Data_20250919|ScaleCUA: Scaling Open-Source Computer Use Agents with Cross-Platform Data]] (83.2% similar)
- [[2025-09-23/Open Vision Reasoner_ Transferring Linguistic Cognitive Behavior for Visual Reasoning_20250923|Open Vision Reasoner: Transferring Linguistic Cognitive Behavior for Visual Reasoning]] (83.1% similar)
- [[2025-09-23/Seeing is Believing? Mitigating OCR Hallucinations in Multimodal Large Language Models_20250923|Seeing is Believing? Mitigating OCR Hallucinations in Multimodal Large Language Models]] (82.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]], [[keywords/Chain-of-Thought Reasoning|Chain-of-Thought Reasoning]]
**âš¡ Unique Technical**: [[keywords/Qianfan-VL|Qianfan-VL]], [[keywords/Domain Enhancement|Domain Enhancement]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18189v1 Announce Type: cross 
Abstract: We present Qianfan-VL, a series of multimodal large language models ranging from 3B to 70B parameters, achieving state-of-the-art performance through innovative domain enhancement techniques. Our approach employs multi-stage progressive training and high-precision data synthesis pipelines, which prove to be critical technologies for enhancing domain-specific capabilities while maintaining strong general performance. Qianfan-VL achieves comparable results to leading open-source models on general benchmarks, with state-of-the-art performance on benchmarks such as CCBench, SEEDBench IMG, ScienceQA, and MMStar. The domain enhancement strategy delivers significant advantages in OCR and document understanding, validated on both public benchmarks (OCRBench 873, DocVQA 94.75%) and in-house evaluations. Notably, Qianfan-VL-8B and 70B variants incorporate long chain-of-thought capabilities, demonstrating superior performance on mathematical reasoning (MathVista 78.6%) and logical inference tasks. All models are trained entirely on Baidu's Kunlun P800 chips, validating the capability of large-scale AI infrastructure to train SOTA-level multimodal models with over 90% scaling efficiency on 5000 chips for a single task. This work establishes an effective methodology for developing domain-enhanced multimodal models suitable for diverse enterprise deployment scenarios.

## ğŸ“ ìš”ì•½

Qianfan-VLì€ 3ì–µì—ì„œ 700ì–µ ê°œì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ê°€ì§„ ë‹¤ì¤‘ ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ ì‹œë¦¬ì¦ˆë¡œ, í˜ì‹ ì ì¸ ë„ë©”ì¸ ê°•í™” ê¸°ë²•ì„ í†µí•´ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. ë‹¤ë‹¨ê³„ ì ì§„ì  í›ˆë ¨ê³¼ ê³ ì •ë°€ ë°ì´í„° í•©ì„± íŒŒì´í”„ë¼ì¸ì„ í™œìš©í•˜ì—¬ ë„ë©”ì¸ íŠ¹í™” ëŠ¥ë ¥ì„ ê°•í™”í•˜ë©´ì„œë„ ì¼ë°˜ ì„±ëŠ¥ì„ ìœ ì§€í•©ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ CCBench, SEEDBench IMG, ScienceQA, MMStar ë“±ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë©°, OCR ë° ë¬¸ì„œ ì´í•´ ë¶„ì•¼ì—ì„œë„ ë›°ì–´ë‚œ ì„±ê³¼ë¥¼ ì…ì¦í–ˆìŠµë‹ˆë‹¤. íŠ¹íˆ Qianfan-VL-8Bì™€ 70B ëª¨ë¸ì€ ìˆ˜í•™ì  ì¶”ë¡  ë° ë…¼ë¦¬ì  ì¶”ë¡  ì‘ì—…ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ëª¨ë“  ëª¨ë¸ì€ Baiduì˜ Kunlun P800 ì¹©ì—ì„œ í›ˆë ¨ë˜ì–´ ëŒ€ê·œëª¨ AI ì¸í”„ë¼ì˜ íš¨ìœ¨ì„±ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ë‹¤ì–‘í•œ ê¸°ì—… ë°°í¬ ì‹œë‚˜ë¦¬ì˜¤ì— ì í•©í•œ ë„ë©”ì¸ ê°•í™” ë‹¤ì¤‘ ëª¨ë‹¬ ëª¨ë¸ ê°œë°œ ë°©ë²•ë¡ ì„ ì œì‹œí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Qianfan-VLì€ 3Bì—ì„œ 70B íŒŒë¼ë¯¸í„°ì˜ ë©€í‹°ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ë¡œ, í˜ì‹ ì ì¸ ë„ë©”ì¸ ê°•í™” ê¸°ìˆ ì„ í†µí•´ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.
- 2. ë‹¤ë‹¨ê³„ ì ì§„ì  í›ˆë ¨ê³¼ ê³ ì •ë°€ ë°ì´í„° í•©ì„± íŒŒì´í”„ë¼ì¸ì„ ì‚¬ìš©í•˜ì—¬ ë„ë©”ì¸ íŠ¹í™” ê¸°ëŠ¥ì„ ê°•í™”í•˜ë©´ì„œë„ ê°•ë ¥í•œ ì¼ë°˜ ì„±ëŠ¥ì„ ìœ ì§€í•©ë‹ˆë‹¤.
- 3. Qianfan-VLì€ CCBench, SEEDBench IMG, ScienceQA, MMStar ë“±ì˜ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
- 4. ë„ë©”ì¸ ê°•í™” ì „ëµì€ OCR ë° ë¬¸ì„œ ì´í•´ì—ì„œ ìƒë‹¹í•œ ì´ì ì„ ì œê³µí•˜ë©°, OCRBench 873 ë° DocVQA 94.75%ì™€ ê°™ì€ ê³µê³µ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ê²€ì¦ë˜ì—ˆìŠµë‹ˆë‹¤.
- 5. Baiduì˜ Kunlun P800 ì¹©ì—ì„œ ëª¨ë“  ëª¨ë¸ì´ í›ˆë ¨ë˜ì—ˆìœ¼ë©°, 5000ê°œì˜ ì¹©ì„ ì‚¬ìš©í•˜ì—¬ ë‹¨ì¼ ì‘ì—…ì—ì„œ 90% ì´ìƒì˜ í™•ì¥ íš¨ìœ¨ì„±ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 13:41:50*