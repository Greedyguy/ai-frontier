<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T14:18:32.962295",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "On-Manifold Exploration",
    "Latent Representation",
    "Robotic Manipulation",
    "Policy Self-Improvement"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "On-Manifold Exploration": 0.8,
    "Latent Representation": 0.72,
    "Robotic Manipulation": 0.75,
    "Policy Self-Improvement": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "On-Manifold Exploration",
        "canonical": "On-Manifold Exploration",
        "aliases": [
          "Manifold Exploration"
        ],
        "category": "unique_technical",
        "rationale": "This concept is central to the paper's approach and offers a novel method for enhancing exploration in robotic policies.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "Latent Representation",
        "canonical": "Latent Representation",
        "aliases": [
          "Compact Latent Space"
        ],
        "category": "broad_technical",
        "rationale": "Latent representations are critical for understanding the structured space in which exploration occurs, linking to broader machine learning concepts.",
        "novelty_score": 0.55,
        "connectivity_score": 0.78,
        "specificity_score": 0.7,
        "link_intent_score": 0.72
      },
      {
        "surface": "Robotic Manipulation",
        "canonical": "Robotic Manipulation",
        "aliases": [
          "Robot Manipulation"
        ],
        "category": "specific_connectable",
        "rationale": "This is a specific application area for the proposed method, connecting to existing work in robotics.",
        "novelty_score": 0.6,
        "connectivity_score": 0.85,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      },
      {
        "surface": "Policy Self-Improvement",
        "canonical": "Policy Self-Improvement",
        "aliases": [
          "Self-Improving Policies"
        ],
        "category": "unique_technical",
        "rationale": "The concept of self-improvement in policies is a unique contribution of the paper, relevant for linking to adaptive learning strategies.",
        "novelty_score": 0.78,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "action mode collapse",
      "random perturbations",
      "task success rates"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "On-Manifold Exploration",
      "resolved_canonical": "On-Manifold Exploration",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Latent Representation",
      "resolved_canonical": "Latent Representation",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.78,
        "specificity": 0.7,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "Robotic Manipulation",
      "resolved_canonical": "Robotic Manipulation",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.85,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Policy Self-Improvement",
      "resolved_canonical": "Policy Self-Improvement",
      "decision": "linked",
      "scores": {
        "novelty": 0.78,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# SOE: Sample-Efficient Robot Policy Self-Improvement via On-Manifold Exploration

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19292.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2509.19292](https://arxiv.org/abs/2509.19292)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-24/PEEK_ Guiding and Minimal Image Representations for Zero-Shot Generalization of Robot Manipulation Policies_20250924|PEEK: Guiding and Minimal Image Representations for Zero-Shot Generalization of Robot Manipulation Policies]] (83.5% similar)
- [[2025-09-23/Sight Over Site_ Perception-Aware Reinforcement Learning for Efficient Robotic Inspection_20250923|Sight Over Site: Perception-Aware Reinforcement Learning for Efficient Robotic Inspection]] (83.0% similar)
- [[2025-09-23/Latent Policy Steering with Embodiment-Agnostic Pretrained World Models_20250923|Latent Policy Steering with Embodiment-Agnostic Pretrained World Models]] (82.6% similar)
- [[2025-09-23/Sample-Efficient Reinforcement Learning with Symmetry-Guided Demonstrations for Robotic Manipulation_20250923|Sample-Efficient Reinforcement Learning with Symmetry-Guided Demonstrations for Robotic Manipulation]] (82.2% similar)
- [[2025-09-23/Safe Guaranteed Dynamics Exploration with Probabilistic Models_20250923|Safe Guaranteed Dynamics Exploration with Probabilistic Models]] (81.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Latent Representation|Latent Representation]]
**ğŸ”— Specific Connectable**: [[keywords/Robotic Manipulation|Robotic Manipulation]]
**âš¡ Unique Technical**: [[keywords/On-Manifold Exploration|On-Manifold Exploration]], [[keywords/Policy Self-Improvement|Policy Self-Improvement]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19292v1 Announce Type: cross 
Abstract: Intelligent agents progress by continually refining their capabilities through actively exploring environments. Yet robot policies often lack sufficient exploration capability due to action mode collapse. Existing methods that encourage exploration typically rely on random perturbations, which are unsafe and induce unstable, erratic behaviors, thereby limiting their effectiveness. We propose Self-Improvement via On-Manifold Exploration (SOE), a framework that enhances policy exploration and improvement in robotic manipulation. SOE learns a compact latent representation of task-relevant factors and constrains exploration to the manifold of valid actions, ensuring safety, diversity, and effectiveness. It can be seamlessly integrated with arbitrary policy models as a plug-in module, augmenting exploration without degrading the base policy performance. Moreover, the structured latent space enables human-guided exploration, further improving efficiency and controllability. Extensive experiments in both simulation and real-world tasks demonstrate that SOE consistently outperforms prior methods, achieving higher task success rates, smoother and safer exploration, and superior sample efficiency. These results establish on-manifold exploration as a principled approach to sample-efficient policy self-improvement. Project website: https://ericjin2002.github.io/SOE

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë¡œë´‡ ì¡°ì‘ì—ì„œ ì •ì±… íƒìƒ‰ê³¼ ê°œì„ ì„ ìœ„í•œ ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ì¸ SOE(Self-Improvement via On-Manifold Exploration)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ ë°©ë²•ë“¤ì€ ë¬´ì‘ìœ„ ë³€ë™ì— ì˜ì¡´í•˜ì—¬ ë¶ˆì•ˆì •í•œ í–‰ë™ì„ ì´ˆë˜í•˜ëŠ” ë°˜ë©´, SOEëŠ” ì‘ì—… ê´€ë ¨ ìš”ì†Œì˜ ì ì¬ í‘œí˜„ì„ í•™ìŠµí•˜ê³  ìœ íš¨í•œ í–‰ë™ì˜ ë‹¤ì–‘ì²´ì— íƒìƒ‰ì„ ì œí•œí•˜ì—¬ ì•ˆì „ì„±ê³¼ ë‹¤ì–‘ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ì„ì˜ì˜ ì •ì±… ëª¨ë¸ì— í”ŒëŸ¬ê·¸ì¸ ëª¨ë“ˆë¡œ í†µí•© ê°€ëŠ¥í•˜ë©°, ê¸°ë³¸ ì •ì±… ì„±ëŠ¥ì„ ì €í•˜ì‹œí‚¤ì§€ ì•Šê³  íƒìƒ‰ì„ ê°•í™”í•©ë‹ˆë‹¤. ë˜í•œ, êµ¬ì¡°í™”ëœ ì ì¬ ê³µê°„ì„ í†µí•´ ì¸ê°„ì´ íƒìƒ‰ì„ ì•ˆë‚´í•  ìˆ˜ ìˆì–´ íš¨ìœ¨ì„±ê³¼ ì œì–´ì„±ì„ ë†’ì…ë‹ˆë‹¤. ì‹œë®¬ë ˆì´ì…˜ ë° ì‹¤ì œ ì‘ì—…ì—ì„œì˜ ì‹¤í—˜ ê²°ê³¼, SOEëŠ” ê¸°ì¡´ ë°©ë²•ë³´ë‹¤ ë†’ì€ ì‘ì—… ì„±ê³µë¥ ê³¼ ì•ˆì „í•˜ê³  ë§¤ë„ëŸ¬ìš´ íƒìƒ‰, ë›°ì–´ë‚œ ìƒ˜í”Œ íš¨ìœ¨ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŸ¬í•œ ê²°ê³¼ëŠ” ë‹¤ì–‘ì²´ ê¸°ë°˜ íƒìƒ‰ì´ ìƒ˜í”Œ íš¨ìœ¨ì ì¸ ì •ì±… ìê¸° ê°œì„ ì„ ìœ„í•œ ì›ì¹™ì ì¸ ì ‘ê·¼ë²•ì„ì„ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. SOEëŠ” ë¡œë´‡ ì¡°ì‘ì—ì„œ ì •ì±… íƒìƒ‰ê³¼ ê°œì„ ì„ ê°•í™”í•˜ëŠ” í”„ë ˆì„ì›Œí¬ë¡œ, ìœ íš¨í•œ í–‰ë™ì˜ ë§¤ë‹ˆí´ë“œì— íƒìƒ‰ì„ ì œí•œí•˜ì—¬ ì•ˆì „ì„±ê³¼ ë‹¤ì–‘ì„±, íš¨ê³¼ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤.
- 2. SOEëŠ” ì„ì˜ì˜ ì •ì±… ëª¨ë¸ê³¼ í”ŒëŸ¬ê·¸ì¸ ëª¨ë“ˆë¡œ í†µí•©ë  ìˆ˜ ìˆì–´, ê¸°ë³¸ ì •ì±… ì„±ëŠ¥ì„ ì €í•˜ì‹œí‚¤ì§€ ì•Šìœ¼ë©´ì„œ íƒìƒ‰ì„ ì¦ëŒ€ì‹œí‚µë‹ˆë‹¤.
- 3. êµ¬ì¡°í™”ëœ ì ì¬ ê³µê°„ì€ ì¸ê°„ì´ íƒìƒ‰ì„ ì•ˆë‚´í•  ìˆ˜ ìˆê²Œ í•˜ì—¬ íš¨ìœ¨ì„±ê³¼ ì œì–´ ê°€ëŠ¥ì„±ì„ ë”ìš± í–¥ìƒì‹œí‚µë‹ˆë‹¤.
- 4. ì‹œë®¬ë ˆì´ì…˜ ë° ì‹¤ì œ ì‘ì—…ì—ì„œì˜ ê´‘ë²”ìœ„í•œ ì‹¤í—˜ ê²°ê³¼, SOEëŠ” ì´ì „ ë°©ë²•ë“¤ë³´ë‹¤ ì¼ê´€ë˜ê²Œ ë†’ì€ ì‘ì—… ì„±ê³µë¥ ê³¼ ë¶€ë“œëŸ½ê³  ì•ˆì „í•œ íƒìƒ‰, ìš°ìˆ˜í•œ ìƒ˜í”Œ íš¨ìœ¨ì„±ì„ ë‹¬ì„±í•©ë‹ˆë‹¤.
- 5. ë§¤ë‹ˆí´ë“œ íƒìƒ‰ì€ ìƒ˜í”Œ íš¨ìœ¨ì ì¸ ì •ì±… ìê¸° ê°œì„ ì„ ìœ„í•œ ì›ì¹™ì ì¸ ì ‘ê·¼ë²•ìœ¼ë¡œ ìë¦¬ ì¡ì•˜ìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 14:18:32*