<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T16:10:37.663354",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Segment Anything Model",
    "Point Prompt Defender",
    "Deep Q-Network",
    "Adversarial Reinforcement Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Segment Anything Model": 0.9,
    "Point Prompt Defender": 0.85,
    "Deep Q-Network": 0.8,
    "Adversarial Reinforcement Learning": 0.9
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Segment Anything Model",
        "canonical": "Segment Anything Model",
        "aliases": [
          "SAM"
        ],
        "category": "unique_technical",
        "rationale": "This model is central to the paper's proposed framework and its optimization, making it a unique technical concept.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.9
      },
      {
        "surface": "Point Prompt Defender",
        "canonical": "Point Prompt Defender",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "The framework introduced in the paper, crucial for understanding the adversarial approach to prompt optimization.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.9,
        "link_intent_score": 0.85
      },
      {
        "surface": "Deep Q-Networks",
        "canonical": "Deep Q-Network",
        "aliases": [
          "DQN"
        ],
        "category": "specific_connectable",
        "rationale": "A key machine learning technique used in the paper, facilitating connections with reinforcement learning topics.",
        "novelty_score": 0.4,
        "connectivity_score": 0.8,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "adversarial reinforcement learning",
        "canonical": "Adversarial Reinforcement Learning",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "The paper's method relies on this approach, linking it to broader adversarial and reinforcement learning research.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.75,
        "link_intent_score": 0.9
      }
    ],
    "ban_list_suggestions": [
      "prompt",
      "environment",
      "agent"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Segment Anything Model",
      "resolved_canonical": "Segment Anything Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.9
      }
    },
    {
      "candidate_surface": "Point Prompt Defender",
      "resolved_canonical": "Point Prompt Defender",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.9,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Deep Q-Networks",
      "resolved_canonical": "Deep Q-Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.8,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "adversarial reinforcement learning",
      "resolved_canonical": "Adversarial Reinforcement Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.75,
        "link_intent": 0.9
      }
    }
  ]
}
-->

# Attack for Defense: Adversarial Agents for Point Prompt Optimization Empowering Segment Anything Model

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18891.pdf)
**Category**: cs.CV
**Published**: 2025-09-24
**ArXiv ID**: [2509.18891](https://arxiv.org/abs/2509.18891)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/BiPrompt-SAM_ Enhancing Image Segmentation via Explicit Selection between Point and Text Prompts_20250923|BiPrompt-SAM: Enhancing Image Segmentation via Explicit Selection between Point and Text Prompts]] (87.5% similar)
- [[2025-09-24/HyPSAM_ Hybrid Prompt-driven Segment Anything Model for RGB-Thermal Salient Object Detection_20250924|HyPSAM: Hybrid Prompt-driven Segment Anything Model for RGB-Thermal Salient Object Detection]] (84.5% similar)
- [[2025-09-23/SAM-DCE_ Addressing Token Uniformity and Semantic Over-Smoothing in Medical Segmentation_20250923|SAM-DCE: Addressing Token Uniformity and Semantic Over-Smoothing in Medical Segmentation]] (84.3% similar)
- [[2025-09-19/A Multi-Agent LLM Defense Pipeline Against Prompt Injection Attacks_20250919|A Multi-Agent LLM Defense Pipeline Against Prompt Injection Attacks]] (83.8% similar)
- [[2025-09-23/DescriptorMedSAM_ Language-Image Fusion with Multi-Aspect Text Guidance for Medical Image Segmentation_20250923|DescriptorMedSAM: Language-Image Fusion with Multi-Aspect Text Guidance for Medical Image Segmentation]] (83.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Deep Q-Network|Deep Q-Network]], [[keywords/Adversarial Reinforcement Learning|Adversarial Reinforcement Learning]]
**âš¡ Unique Technical**: [[keywords/Segment Anything Model|Segment Anything Model]], [[keywords/Point Prompt Defender|Point Prompt Defender]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18891v1 Announce Type: new 
Abstract: Prompt quality plays a critical role in the performance of the Segment Anything Model (SAM), yet existing approaches often rely on heuristic or manually crafted prompts, limiting scalability and generalization. In this paper, we propose Point Prompt Defender, an adversarial reinforcement learning framework that adopts an attack-for-defense paradigm to automatically optimize point prompts. We construct a task-agnostic point prompt environment by representing image patches as nodes in a dual-space graph, where edges encode both physical and semantic distances. Within this environment, an attacker agent learns to activate a subset of prompts that maximally degrade SAM's segmentation performance, while a defender agent learns to suppress these disruptive prompts and restore accuracy. Both agents are trained using Deep Q-Networks with a reward signal based on segmentation quality variation. During inference, only the defender is deployed to refine arbitrary coarse prompt sets, enabling enhanced SAM segmentation performance across diverse tasks without retraining. Extensive experiments show that Point Prompt Defender effectively improves SAM's robustness and generalization, establishing a flexible, interpretable, and plug-and-play framework for prompt-based segmentation.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì—ì„œëŠ” Segment Anything Model (SAM)ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ Point Prompt Defenderë¼ëŠ” í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ëŠ” ê³µê²©-ë°©ì–´ íŒ¨ëŸ¬ë‹¤ì„ì„ ì±„íƒí•œ ì ëŒ€ì  ê°•í™” í•™ìŠµ ë°©ë²•ìœ¼ë¡œ, ìë™ìœ¼ë¡œ í¬ì¸íŠ¸ í”„ë¡¬í”„íŠ¸ë¥¼ ìµœì í™”í•©ë‹ˆë‹¤. ì´ë¯¸ì§€ íŒ¨ì¹˜ë¥¼ ì´ì¤‘ ê³µê°„ ê·¸ë˜í”„ì˜ ë…¸ë“œë¡œ í‘œí˜„í•˜ì—¬ ë¬¼ë¦¬ì  ë° ì˜ë¯¸ì  ê±°ë¦¬ë¥¼ ì¸ì½”ë”©í•˜ê³ , ê³µê²©ì ì—ì´ì „íŠ¸ëŠ” SAMì˜ ì„±ëŠ¥ì„ ì €í•˜ì‹œí‚¤ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ í™œì„±í™”í•˜ë©°, ë°©ì–´ì ì—ì´ì „íŠ¸ëŠ” ì´ë¥¼ ì–µì œí•˜ì—¬ ì •í™•ì„±ì„ íšŒë³µí•©ë‹ˆë‹¤. ë‘ ì—ì´ì „íŠ¸ëŠ” Deep Q-Networksë¥¼ ì‚¬ìš©í•´ í•™ìŠµí•˜ë©°, ë°©ì–´ìëŠ” ë‹¤ì–‘í•œ ì‘ì—…ì—ì„œ SAMì˜ ì„¸ë¶„í™” ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, Point Prompt DefenderëŠ” SAMì˜ ê²¬ê³ ì„±ê³¼ ì¼ë°˜í™”ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ê°œì„ í•˜ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Segment Anything Model(SAM)ì˜ ì„±ëŠ¥ì€ í”„ë¡¬í”„íŠ¸ì˜ í’ˆì§ˆì— í¬ê²Œ ì˜ì¡´í•˜ë©°, ê¸°ì¡´ ì ‘ê·¼ë²•ì€ ì£¼ë¡œ ìˆ˜ì‘ì—…ìœ¼ë¡œ ë§Œë“¤ì–´ì§„ í”„ë¡¬í”„íŠ¸ì— ì˜ì¡´í•˜ì—¬ í™•ì¥ì„±ê³¼ ì¼ë°˜í™”ì— í•œê³„ê°€ ìˆë‹¤.
- 2. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ê³µê²©-ë°©ì–´ íŒ¨ëŸ¬ë‹¤ì„ì„ ì±„íƒí•˜ì—¬ í¬ì¸íŠ¸ í”„ë¡¬í”„íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ìµœì í™”í•˜ëŠ” ì ëŒ€ì  ê°•í™” í•™ìŠµ í”„ë ˆì„ì›Œí¬ì¸ Point Prompt Defenderë¥¼ ì œì•ˆí•œë‹¤.
- 3. ì´ë¯¸ì§€ íŒ¨ì¹˜ë¥¼ ì´ì¤‘ ê³µê°„ ê·¸ë˜í”„ì˜ ë…¸ë“œë¡œ í‘œí˜„í•˜ì—¬ ë¬¼ë¦¬ì  ë° ì˜ë¯¸ì  ê±°ë¦¬ë¥¼ ì¸ì½”ë”©í•˜ëŠ” í”„ë¡¬í”„íŠ¸ í™˜ê²½ì„ êµ¬ì¶•í•˜ê³ , ê³µê²©ì ì—ì´ì „íŠ¸ì™€ ë°©ì–´ì ì—ì´ì „íŠ¸ê°€ ê°ê° í”„ë¡¬í”„íŠ¸ë¥¼ í™œì„±í™” ë° ì–µì œí•˜ì—¬ ì„¸ê·¸ë¨¼íŠ¸ ì„±ëŠ¥ì„ ì¡°ì ˆí•œë‹¤.
- 4. ë°©ì–´ì ì—ì´ì „íŠ¸ëŠ” Deep Q-Networksë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµí•˜ë©°, ì¶”ë¡  ì‹œì—ëŠ” ë°©ì–´ìë§Œ ë°°ì¹˜ë˜ì–´ ë‹¤ì–‘í•œ ì‘ì—…ì—ì„œ SAMì˜ ì„¸ê·¸ë¨¼íŠ¸ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¨ë‹¤.
- 5. ê´‘ë²”ìœ„í•œ ì‹¤í—˜ ê²°ê³¼, Point Prompt DefenderëŠ” SAMì˜ ê²¬ê³ ì„±ê³¼ ì¼ë°˜í™”ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ê°œì„ í•˜ë©°, í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ì„¸ë¶„í™”ë¥¼ ìœ„í•œ ìœ ì—°í•˜ê³  í•´ì„ ê°€ëŠ¥í•˜ë©° í”ŒëŸ¬ê·¸ ì•¤ í”Œë ˆì´ ê°€ëŠ¥í•œ í”„ë ˆì„ì›Œí¬ë¥¼ í™•ë¦½í•œë‹¤.


---

*Generated on 2025-09-24 16:10:37*