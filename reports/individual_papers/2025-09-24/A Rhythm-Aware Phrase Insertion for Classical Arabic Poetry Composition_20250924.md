<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T13:51:21.815606",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "ByT5",
    "Arabic Poetry Composition",
    "Transformer",
    "Conditional Denoising Objective",
    "Curriculum Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "ByT5": 0.78,
    "Arabic Poetry Composition": 0.82,
    "Transformer": 0.85,
    "Conditional Denoising Objective": 0.7,
    "Curriculum Learning": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "ByT5",
        "canonical": "ByT5",
        "aliases": [
          "Byte-Level T5"
        ],
        "category": "unique_technical",
        "rationale": "ByT5 is a specific model used in the study, crucial for understanding the methodology.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Arabic Poetry Composition",
        "canonical": "Arabic Poetry Composition",
        "aliases": [
          "Classical Arabic Poetry"
        ],
        "category": "unique_technical",
        "rationale": "This is the primary application domain of the study, linking cultural and technical aspects.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.9,
        "link_intent_score": 0.82
      },
      {
        "surface": "Transformer-based model",
        "canonical": "Transformer",
        "aliases": [
          "Transformer Model"
        ],
        "category": "broad_technical",
        "rationale": "Transformers are foundational to the model architecture used in the study.",
        "novelty_score": 0.4,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Conditional Denoising Objective",
        "canonical": "Conditional Denoising Objective",
        "aliases": [
          "Denoising Objective"
        ],
        "category": "unique_technical",
        "rationale": "This objective is key to the model's training process, relevant for technical linkage.",
        "novelty_score": 0.7,
        "connectivity_score": 0.5,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      },
      {
        "surface": "Curriculum Learning Strategy",
        "canonical": "Curriculum Learning",
        "aliases": [
          "Curriculum Strategy"
        ],
        "category": "specific_connectable",
        "rationale": "Curriculum learning is a strategic approach that enhances model training, relevant for linking learning strategies.",
        "novelty_score": 0.6,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "methodology",
      "approach",
      "results",
      "potential"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "ByT5",
      "resolved_canonical": "ByT5",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Arabic Poetry Composition",
      "resolved_canonical": "Arabic Poetry Composition",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.9,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Transformer-based model",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Conditional Denoising Objective",
      "resolved_canonical": "Conditional Denoising Objective",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.5,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Curriculum Learning Strategy",
      "resolved_canonical": "Curriculum Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# A Rhythm-Aware Phrase Insertion for Classical Arabic Poetry Composition

## 📋 메타데이터

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18514.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2509.18514](https://arxiv.org/abs/2509.18514)

## 🔗 유사한 논문
- [[2025-09-22/mucAI at BAREC Shared Task 2025_ Towards Uncertainty Aware Arabic Readability Assessment_20250922|mucAI at BAREC Shared Task 2025: Towards Uncertainty Aware Arabic Readability Assessment]] (81.1% similar)
- [[2025-09-23/AutoArabic_ A Three-Stage Framework for Localizing Video-Text Retrieval Benchmarks_20250923|AutoArabic: A Three-Stage Framework for Localizing Video-Text Retrieval Benchmarks]] (80.1% similar)
- [[2025-09-17/Exploring Data and Parameter Efficient Strategies for Arabic Dialect Identifications_20250917|Exploring Data and Parameter Efficient Strategies for Arabic Dialect Identifications]] (80.0% similar)
- [[2025-09-17/Hala Technical Report_ Building Arabic-Centric Instruction & Translation Models at Scale_20250917|Hala Technical Report: Building Arabic-Centric Instruction & Translation Models at Scale]] (79.0% similar)
- [[2025-09-23/Data Augmentation for Maltese NLP using Transliterated and Machine Translated Arabic Data_20250923|Data Augmentation for Maltese NLP using Transliterated and Machine Translated Arabic Data]] (78.8% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Transformer|Transformer]]
**🔗 Specific Connectable**: [[keywords/Curriculum Learning|Curriculum Learning]]
**⚡ Unique Technical**: [[keywords/ByT5|ByT5]], [[keywords/Arabic Poetry Composition|Arabic Poetry Composition]], [[keywords/Conditional Denoising Objective|Conditional Denoising Objective]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.18514v1 Announce Type: cross 
Abstract: This paper presents a methodology for inserting phrases in Arabic poems to conform to a specific rhythm using ByT5, a byte-level multilingual transformer-based model. Our work discusses a rule-based grapheme-to-beat transformation tailored for extracting the rhythm from fully diacritized Arabic script. Our approach employs a conditional denoising objective to fine-tune ByT5, where the model reconstructs masked words to match a target rhythm. We adopt a curriculum learning strategy, pre-training on a general Arabic dataset before fine-tuning on poetic dataset, and explore cross-lingual transfer from English to Arabic. Experimental results demonstrate that our models achieve high rhythmic alignment while maintaining semantic coherence. The proposed model has the potential to be used in co-creative applications in the process of composing classical Arabic poems.

## 📝 요약

이 논문은 ByT5라는 다국어 변환기 모델을 활용하여 아랍어 시에 특정 리듬을 맞추기 위한 구문 삽입 방법론을 제시합니다. 완전한 모음 부호가 있는 아랍어 대본에서 리듬을 추출하기 위한 규칙 기반의 음소 변환을 논의하며, ByT5를 미세 조정하기 위해 조건부 노이즈 제거 목표를 사용합니다. 일반 아랍어 데이터셋으로 사전 학습 후 시 데이터셋으로 미세 조정하는 커리큘럼 학습 전략과 영어에서 아랍어로의 언어 간 전이를 탐구합니다. 실험 결과, 모델은 높은 리듬 정렬과 의미적 일관성을 유지하며, 고전 아랍어 시 작문 과정에서 공동 창작 애플리케이션에 활용될 가능성을 보여줍니다.

## 🎯 주요 포인트

- 1. ByT5 모델을 활용하여 아랍어 시에 특정 리듬을 맞추기 위한 구문 삽입 방법론을 제시합니다.
- 2. 완전한 모음 표기가 된 아랍어 대본에서 리듬을 추출하기 위한 규칙 기반의 음소-박자 변환을 논의합니다.
- 3. 조건부 노이즈 제거 목표를 통해 ByT5를 미세 조정하여 목표 리듬에 맞게 마스킹된 단어를 재구성합니다.
- 4. 일반 아랍어 데이터셋으로 사전 학습 후 시적 데이터셋으로 미세 조정하는 커리큘럼 학습 전략을 채택하고, 영어에서 아랍어로의 교차 언어 전이를 탐구합니다.
- 5. 실험 결과, 제안된 모델이 높은 리듬 정렬과 의미적 일관성을 유지함을 보여줍니다.


---

*Generated on 2025-09-24 13:51:21*