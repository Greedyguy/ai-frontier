<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T16:04:56.230091",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Understanding-in-Generation",
    "Text-to-Image Generation",
    "Chain-of-Thought",
    "Image Editing"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Understanding-in-Generation": 0.8,
    "Text-to-Image Generation": 0.85,
    "Chain-of-Thought": 0.78,
    "Image Editing": 0.65
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Understanding-in-Generation",
        "canonical": "Understanding-in-Generation",
        "aliases": [
          "UiG"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel framework introduced in the paper, crucial for linking to new research on generative models.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "text-to-image generation",
        "canonical": "Text-to-Image Generation",
        "aliases": [
          "T2I Generation"
        ],
        "category": "specific_connectable",
        "rationale": "A key application area that connects with both NLP and computer vision fields.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Chain-of-Thought",
        "canonical": "Chain-of-Thought",
        "aliases": [
          "CoT"
        ],
        "category": "specific_connectable",
        "rationale": "A reasoning method that is gaining traction in AI research, relevant for linking reasoning and generative models.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Image Editing",
        "canonical": "Image Editing",
        "aliases": [],
        "category": "broad_technical",
        "rationale": "A fundamental process in the proposed framework, linking to broader image processing techniques.",
        "novelty_score": 0.3,
        "connectivity_score": 0.7,
        "specificity_score": 0.6,
        "link_intent_score": 0.65
      }
    ],
    "ban_list_suggestions": [
      "enhancing",
      "performance",
      "process"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Understanding-in-Generation",
      "resolved_canonical": "Understanding-in-Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "text-to-image generation",
      "resolved_canonical": "Text-to-Image Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Chain-of-Thought",
      "resolved_canonical": "Chain-of-Thought",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Image Editing",
      "resolved_canonical": "Image Editing",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.7,
        "specificity": 0.6,
        "link_intent": 0.65
      }
    }
  ]
}
-->

# Understanding-in-Generation: Reinforcing Generative Capability of Unified Model via Infusing Understanding into Generation

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18639.pdf)
**Category**: cs.CV
**Published**: 2025-09-24
**ArXiv ID**: [2509.18639](https://arxiv.org/abs/2509.18639)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/Uni-cot_ Towards Unified Chain-of-Thought Reasoning Across Text and Vision_20250918|Uni-cot: Towards Unified Chain-of-Thought Reasoning Across Text and Vision]] (86.4% similar)
- [[2025-09-22/AcT2I_ Evaluating and Improving Action Depiction in Text-to-Image Models_20250922|AcT2I: Evaluating and Improving Action Depiction in Text-to-Image Models]] (84.8% similar)
- [[2025-09-19/TIDE_ Achieving Balanced Subject-Driven Image Generation via Target-Instructed Diffusion Enhancement_20250919|TIDE: Achieving Balanced Subject-Driven Image Generation via Target-Instructed Diffusion Enhancement]] (83.6% similar)
- [[2025-09-19/Reconstruction Alignment Improves Unified Multimodal Models_20250919|Reconstruction Alignment Improves Unified Multimodal Models]] (82.9% similar)
- [[2025-09-23/MEF_ A Systematic Evaluation Framework for Text-to-Image Models_20250923|MEF: A Systematic Evaluation Framework for Text-to-Image Models]] (82.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Image Editing|Image Editing]]
**ğŸ”— Specific Connectable**: [[keywords/Text-to-Image Generation|Text-to-Image Generation]], [[keywords/Chain-of-Thought|Chain-of-Thought]]
**âš¡ Unique Technical**: [[keywords/Understanding-in-Generation|Understanding-in-Generation]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18639v1 Announce Type: new 
Abstract: Recent works have made notable advancements in enhancing unified models for text-to-image generation through the Chain-of-Thought (CoT). However, these reasoning methods separate the processes of understanding and generation, which limits their ability to guide the reasoning of unified models in addressing the deficiencies of their generative capabilities. To this end, we propose a novel reasoning framework for unified models, Understanding-in-Generation (UiG), which harnesses the robust understanding capabilities of unified models to reinforce their performance in image generation. The core insight of our UiG is to integrate generative guidance by the strong understanding capabilities during the reasoning process, thereby mitigating the limitations of generative abilities. To achieve this, we introduce "Image Editing" as a bridge to infuse understanding into the generation process. Initially, we verify the generated image and incorporate the understanding of unified models into the editing instructions. Subsequently, we enhance the generated image step by step, gradually infusing the understanding into the generation process. Our UiG framework demonstrates a significant performance improvement in text-to-image generation over existing text-to-image reasoning methods, e.g., a 3.92% gain on the long prompt setting of the TIIF benchmark. The project code: https://github.com/QC-LY/UiG

## ğŸ“ ìš”ì•½

ìµœê·¼ ì—°êµ¬ì—ì„œëŠ” Chain-of-Thought(CoT)ë¥¼ í†µí•´ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ìƒì„± í†µí•© ëª¨ë¸ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° ì£¼ëª©í•  ë§Œí•œ ì§„ì „ì„ ì´ë£¨ì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê¸°ì¡´ì˜ ì¶”ë¡  ë°©ë²•ì€ ì´í•´ì™€ ìƒì„± ê³¼ì •ì„ ë¶„ë¦¬í•˜ì—¬, ìƒì„± ëŠ¥ë ¥ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” í†µí•© ëª¨ë¸ì˜ ê°•ë ¥í•œ ì´í•´ ëŠ¥ë ¥ì„ í™œìš©í•˜ì—¬ ì´ë¯¸ì§€ ìƒì„± ì„±ëŠ¥ì„ ê°•í™”í•˜ëŠ” ìƒˆë¡œìš´ ì¶”ë¡  í”„ë ˆì„ì›Œí¬ì¸ Understanding-in-Generation(UiG)ì„ ì œì•ˆí•©ë‹ˆë‹¤. UiGì˜ í•µì‹¬ì€ ì´í•´ ëŠ¥ë ¥ì„ ìƒì„± ê³¼ì •ì— í†µí•©í•˜ì—¬ ìƒì„± ëŠ¥ë ¥ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ "ì´ë¯¸ì§€ í¸ì§‘"ì„ ë„ì…í•˜ì—¬ ìƒì„± ê³¼ì •ì— ì´í•´ë¥¼ ì£¼ì…í•©ë‹ˆë‹¤. ì´ˆê¸°ì—ëŠ” ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ ê²€ì¦í•˜ê³ , í†µí•© ëª¨ë¸ì˜ ì´í•´ë¥¼ í¸ì§‘ ì§€ì¹¨ì— ë°˜ì˜í•©ë‹ˆë‹¤. ì´í›„ ë‹¨ê³„ì ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ê°œì„ í•˜ì—¬ ì´í•´ë¥¼ ìƒì„± ê³¼ì •ì— ì ì§„ì ìœ¼ë¡œ í†µí•©í•©ë‹ˆë‹¤. UiG í”„ë ˆì„ì›Œí¬ëŠ” ê¸°ì¡´ ë°©ë²•ì— ë¹„í•´ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ìƒì„± ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œì¼°ìœ¼ë©°, TIIF ë²¤ì¹˜ë§ˆí¬ì˜ ê¸´ í”„ë¡¬í”„íŠ¸ ì„¤ì •ì—ì„œ 3.92%ì˜ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ìµœê·¼ ì—°êµ¬ë“¤ì€ Chain-of-Thought(CoT)ì„ í†µí•´ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ìƒì„± í†µí•© ëª¨ë¸ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° ì£¼ëª©í•  ë§Œí•œ ë°œì „ì„ ì´ë£¨ì—ˆë‹¤.
- 2. ê¸°ì¡´ì˜ ì¶”ë¡  ë°©ë²•ì€ ì´í•´ì™€ ìƒì„± ê³¼ì •ì„ ë¶„ë¦¬í•˜ì—¬ í†µí•© ëª¨ë¸ì˜ ìƒì„± ëŠ¥ë ¥ ê²°í•¨ì„ í•´ê²°í•˜ëŠ” ë° í•œê³„ê°€ ìˆë‹¤.
- 3. ìƒˆë¡œìš´ ì¶”ë¡  í”„ë ˆì„ì›Œí¬ì¸ Understanding-in-Generation(UiG)ì„ ì œì•ˆí•˜ì—¬ í†µí•© ëª¨ë¸ì˜ ê°•ë ¥í•œ ì´í•´ ëŠ¥ë ¥ì„ í™œìš©í•´ ì´ë¯¸ì§€ ìƒì„± ì„±ëŠ¥ì„ ê°•í™”í•œë‹¤.
- 4. UiGì˜ í•µì‹¬ì€ ì´í•´ ëŠ¥ë ¥ì„ ìƒì„± ê³¼ì •ì— í†µí•©í•˜ì—¬ ìƒì„± ëŠ¥ë ¥ì˜ í•œê³„ë¥¼ ì™„í™”í•˜ëŠ” ê²ƒì´ë‹¤.
- 5. UiG í”„ë ˆì„ì›Œí¬ëŠ” ê¸°ì¡´ì˜ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ì¶”ë¡  ë°©ë²•ì— ë¹„í•´ ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë˜ì—ˆìœ¼ë©°, TIIF ë²¤ì¹˜ë§ˆí¬ì˜ ê¸´ í”„ë¡¬í”„íŠ¸ ì„¤ì •ì—ì„œ 3.92%ì˜ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì˜€ë‹¤.


---

*Generated on 2025-09-24 16:04:56*