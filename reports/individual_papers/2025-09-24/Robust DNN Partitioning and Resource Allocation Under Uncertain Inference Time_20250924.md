<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T15:32:30.447735",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Neural Network Partitioning",
    "Resource Allocation",
    "Chance-Constrained Programming",
    "Penalty Convex-Concave Procedure"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Neural Network Partitioning": 0.82,
    "Resource Allocation": 0.79,
    "Chance-Constrained Programming": 0.75,
    "Penalty Convex-Concave Procedure": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "DNN Partitioning",
        "canonical": "Neural Network Partitioning",
        "aliases": [
          "Deep Neural Network Partitioning"
        ],
        "category": "specific_connectable",
        "rationale": "Partitioning is a critical aspect of optimizing neural networks for edge computing, enhancing connectivity with resource allocation studies.",
        "novelty_score": 0.65,
        "connectivity_score": 0.78,
        "specificity_score": 0.8,
        "link_intent_score": 0.82
      },
      {
        "surface": "Resource Allocation",
        "canonical": "Resource Allocation",
        "aliases": [
          "Resource Management"
        ],
        "category": "broad_technical",
        "rationale": "Resource allocation is a fundamental concept in optimizing computational tasks, linking well with studies on system optimization.",
        "novelty_score": 0.55,
        "connectivity_score": 0.85,
        "specificity_score": 0.6,
        "link_intent_score": 0.79
      },
      {
        "surface": "Chance-Constrained Programming",
        "canonical": "Chance-Constrained Programming",
        "aliases": [
          "CCP"
        ],
        "category": "unique_technical",
        "rationale": "This method is uniquely applied to handle uncertainty in optimization problems, offering novel insights into probabilistic constraints.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.75
      },
      {
        "surface": "Penalty Convex-Concave Procedure",
        "canonical": "Penalty Convex-Concave Procedure",
        "aliases": [
          "PCCP"
        ],
        "category": "unique_technical",
        "rationale": "PCCP is a specialized optimization technique relevant for solving non-linear programming problems, enhancing specificity in optimization discussions.",
        "novelty_score": 0.72,
        "connectivity_score": 0.6,
        "specificity_score": 0.88,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "inference time",
      "task processing",
      "energy consumption"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "DNN Partitioning",
      "resolved_canonical": "Neural Network Partitioning",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.78,
        "specificity": 0.8,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Resource Allocation",
      "resolved_canonical": "Resource Allocation",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.85,
        "specificity": 0.6,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Chance-Constrained Programming",
      "resolved_canonical": "Chance-Constrained Programming",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Penalty Convex-Concave Procedure",
      "resolved_canonical": "Penalty Convex-Concave Procedure",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.6,
        "specificity": 0.88,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# Robust DNN Partitioning and Resource Allocation Under Uncertain Inference Time

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2503.21476.pdf)
**Category**: cs.LG
**Published**: 2025-09-24
**ArXiv ID**: [2503.21476](https://arxiv.org/abs/2503.21476)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Joint Optimization of Memory Frequency, Computing Frequency, Transmission Power and Task Offloading for Energy-efficient DNN Inference_20250923|Joint Optimization of Memory Frequency, Computing Frequency, Transmission Power and Task Offloading for Energy-efficient DNN Inference]] (87.4% similar)
- [[2025-09-24/Intra-DP_ A High Performance Collaborative Inference System for Mobile Edge Computing_20250924|Intra-DP: A High Performance Collaborative Inference System for Mobile Edge Computing]] (86.3% similar)
- [[2025-09-23/Evaluating the Energy Efficiency of NPU-Accelerated Machine Learning Inference on Embedded Microcontrollers_20250923|Evaluating the Energy Efficiency of NPU-Accelerated Machine Learning Inference on Embedded Microcontrollers]] (83.3% similar)
- [[2025-09-23/Unified Framework for Pre-trained Neural Network Compression via Decomposition and Optimized Rank Selection_20250923|Unified Framework for Pre-trained Neural Network Compression via Decomposition and Optimized Rank Selection]] (82.7% similar)
- [[2025-09-18/Data-Driven Distributed Optimization via Aggregative Tracking and Deep-Learning_20250918|Data-Driven Distributed Optimization via Aggregative Tracking and Deep-Learning]] (82.4% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Resource Allocation|Resource Allocation]]
**ğŸ”— Specific Connectable**: [[keywords/Neural Network Partitioning|Neural Network Partitioning]]
**âš¡ Unique Technical**: [[keywords/Chance-Constrained Programming|Chance-Constrained Programming]], [[keywords/Penalty Convex-Concave Procedure|Penalty Convex-Concave Procedure]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2503.21476v2 Announce Type: replace-cross 
Abstract: In edge intelligence systems, deep neural network (DNN) partitioning and data offloading can provide real-time task inference for resource-constrained mobile devices. However, the inference time of DNNs is typically uncertain and cannot be precisely determined in advance, presenting significant challenges in ensuring timely task processing within deadlines. To address the uncertain inference time, we propose a robust optimization scheme to minimize the total energy consumption of mobile devices while meeting task probabilistic deadlines. The scheme only requires the mean and variance information of the inference time, without any prediction methods or distribution functions. The problem is formulated as a mixed-integer nonlinear programming (MINLP) that involves jointly optimizing the DNN model partitioning and the allocation of local CPU/GPU frequencies and uplink bandwidth. To tackle the problem, we first decompose the original problem into two subproblems: resource allocation and DNN model partitioning. Subsequently, the two subproblems with probability constraints are equivalently transformed into deterministic optimization problems using the chance-constrained programming (CCP) method. Finally, the convex optimization technique and the penalty convex-concave procedure (PCCP) technique are employed to obtain the optimal solution of the resource allocation subproblem and a stationary point of the DNN model partitioning subproblem, respectively. The proposed algorithm leverages real-world data from popular hardware platforms and is evaluated on widely used DNN models. Extensive simulations show that our proposed algorithm effectively addresses the inference time uncertainty with probabilistic deadline guarantees while minimizing the energy consumption of mobile devices.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì—£ì§€ ì¸í…”ë¦¬ì „ìŠ¤ ì‹œìŠ¤í…œì—ì„œ ìì› ì œì•½ì´ ìˆëŠ” ëª¨ë°”ì¼ ê¸°ê¸°ë¥¼ ìœ„í•œ DNN ë¶„í•  ë° ë°ì´í„° ì˜¤í”„ë¡œë”©ì„ í†µí•´ ì‹¤ì‹œê°„ ì‘ì—… ì¶”ë¡ ì„ ì œê³µí•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. DNNì˜ ì¶”ë¡  ì‹œê°„ì´ ë¶ˆí™•ì‹¤í•˜ì—¬ ì‘ì—… ê¸°í•œì„ ë§ì¶”ëŠ” ë° ì–´ë ¤ì›€ì´ ìˆëŠ”ë°, ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ í‰ê·  ë° ë¶„ì‚° ì •ë³´ë§Œìœ¼ë¡œ ëª¨ë°”ì¼ ê¸°ê¸°ì˜ ì—ë„ˆì§€ ì†Œë¹„ë¥¼ ìµœì†Œí™”í•˜ë©´ì„œ ì‘ì—…ì˜ í™•ë¥ ì  ê¸°í•œì„ ì¶©ì¡±ì‹œí‚¤ëŠ” ê°•ê±´ ìµœì í™” ë°©ì•ˆì„ ì œì‹œí•©ë‹ˆë‹¤. ë¬¸ì œëŠ” í˜¼í•© ì •ìˆ˜ ë¹„ì„ í˜• í”„ë¡œê·¸ë˜ë°(MINLP)ìœ¼ë¡œ ê³µì‹í™”ë˜ë©°, DNN ëª¨ë¸ ë¶„í• ê³¼ ë¡œì»¬ CPU/GPU ì£¼íŒŒìˆ˜ ë° ì—…ë§í¬ ëŒ€ì—­í­ í• ë‹¹ì„ ê³µë™ ìµœì í™”í•©ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ìì› í• ë‹¹ê³¼ DNN ëª¨ë¸ ë¶„í• ì˜ ë‘ í•˜ìœ„ ë¬¸ì œë¡œ ë¶„í•´í•˜ê³ , í™•ë¥  ì œì•½ í”„ë¡œê·¸ë˜ë°(CCP) ë°©ë²•ì„ ì‚¬ìš©í•´ ê²°ì •ë¡ ì  ìµœì í™” ë¬¸ì œë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ìµœì¢…ì ìœ¼ë¡œ ë³¼ë¡ ìµœì í™” ê¸°ë²•ê³¼ í˜ë„í‹° ë³¼ë¡-ì˜¤ëª© ì ˆì°¨(PCCP)ë¥¼ í™œìš©í•´ ìµœì  í•´ë¥¼ ë„ì¶œí•©ë‹ˆë‹¤. ì œì•ˆëœ ì•Œê³ ë¦¬ì¦˜ì€ ì‹¤ì œ í•˜ë“œì›¨ì–´ í”Œë«í¼ì˜ ë°ì´í„°ë¥¼ í™œìš©í•˜ë©°, ë‹¤ì–‘í•œ DNN ëª¨ë¸ì—ì„œ í‰ê°€ë˜ì–´ ì—ë„ˆì§€ ì†Œë¹„ë¥¼ ìµœì†Œí™”í•˜ë©´ì„œ ì¶”ë¡  ì‹œê°„ì˜ ë¶ˆí™•ì‹¤ì„±ì„ íš¨ê³¼ì ìœ¼ë¡œ í•´ê²°í•¨ì„ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì—£ì§€ ì¸í…”ë¦¬ì „ìŠ¤ ì‹œìŠ¤í…œì—ì„œ DNN ë¶„í•  ë° ë°ì´í„° ì˜¤í”„ë¡œë”©ì€ ìì› ì œì•½ì´ ìˆëŠ” ëª¨ë°”ì¼ ì¥ì¹˜ì— ì‹¤ì‹œê°„ ì‘ì—… ì¶”ë¡ ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- 2. DNNì˜ ì¶”ë¡  ì‹œê°„ì€ ë¶ˆí™•ì‹¤í•˜ë©° ì‚¬ì „ì— ì •í™•íˆ ê²°ì •í•  ìˆ˜ ì—†ì–´ ê¸°í•œ ë‚´ì— ì‘ì—…ì„ ì²˜ë¦¬í•˜ëŠ” ë° ì–´ë ¤ì›€ì´ ìˆìŠµë‹ˆë‹¤.
- 3. ìš°ë¦¬ëŠ” ì‘ì—…ì˜ í™•ë¥ ì  ê¸°í•œì„ ì¶©ì¡±í•˜ë©´ì„œ ëª¨ë°”ì¼ ì¥ì¹˜ì˜ ì´ ì—ë„ˆì§€ ì†Œë¹„ë¥¼ ìµœì†Œí™”í•˜ëŠ” ê°•ê±´ ìµœì í™” ë°©ì•ˆì„ ì œì•ˆí•©ë‹ˆë‹¤.
- 4. ë¬¸ì œëŠ” DNN ëª¨ë¸ ë¶„í• ê³¼ ë¡œì»¬ CPU/GPU ì£¼íŒŒìˆ˜ ë° ì—…ë§í¬ ëŒ€ì—­í­ í• ë‹¹ì„ ê³µë™ìœ¼ë¡œ ìµœì í™”í•˜ëŠ” í˜¼í•© ì •ìˆ˜ ë¹„ì„ í˜• í”„ë¡œê·¸ë˜ë°(MINLP)ìœ¼ë¡œ ê³µì‹í™”ë©ë‹ˆë‹¤.
- 5. ì œì•ˆëœ ì•Œê³ ë¦¬ì¦˜ì€ ì‹¤ì œ í•˜ë“œì›¨ì–´ í”Œë«í¼ì˜ ë°ì´í„°ë¥¼ í™œìš©í•˜ë©°, ê´‘ë²”ìœ„í•œ ì‹œë®¬ë ˆì´ì…˜ì„ í†µí•´ ì—ë„ˆì§€ ì†Œë¹„ë¥¼ ìµœì†Œí™”í•˜ë©´ì„œ ì¶”ë¡  ì‹œê°„ ë¶ˆí™•ì‹¤ì„±ì„ íš¨ê³¼ì ìœ¼ë¡œ í•´ê²°í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 15:32:30*