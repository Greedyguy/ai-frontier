<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T15:09:33.203279",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Election-related Knowledge",
    "Demographic Steering",
    "Implicit Predictions"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Election-related Knowledge": 0.78,
    "Demographic Steering": 0.8,
    "Implicit Predictions": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Central to the study, connecting to broader discussions on AI's role in elections.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Election-related knowledge",
        "canonical": "Election-related Knowledge",
        "aliases": [
          "Election Knowledge"
        ],
        "category": "unique_technical",
        "rationale": "Specific to the study's focus on how LLMs handle electoral information.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Demographic steering",
        "canonical": "Demographic Steering",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Highlights the study's analysis of LLM responses influenced by demographic factors.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Implicit predictions",
        "canonical": "Implicit Predictions",
        "aliases": [
          "Model Predictions"
        ],
        "category": "unique_technical",
        "rationale": "Focuses on the models' ability to predict election outcomes, a novel aspect of the study.",
        "novelty_score": 0.68,
        "connectivity_score": 0.7,
        "specificity_score": 0.75,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "election season",
      "platforms",
      "methodology"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Election-related knowledge",
      "resolved_canonical": "Election-related Knowledge",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Demographic steering",
      "resolved_canonical": "Demographic Steering",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Implicit predictions",
      "resolved_canonical": "Implicit Predictions",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.7,
        "specificity": 0.75,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Large-Scale, Longitudinal Study of Large Language Models During the 2024 US Election Season

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18446.pdf)
**Category**: cs.LG
**Published**: 2025-09-24
**ArXiv ID**: [2509.18446](https://arxiv.org/abs/2509.18446)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Measuring Scalar Constructs in Social Science with LLMs_20250923|Measuring Scalar Constructs in Social Science with LLMs]] (84.3% similar)
- [[2025-09-22/Predicting Language Models' Success at Zero-Shot Probabilistic Prediction_20250922|Predicting Language Models' Success at Zero-Shot Probabilistic Prediction]] (83.7% similar)
- [[2025-09-23/Steering Towards Fairness_ Mitigating Political Bias in LLMs_20250923|Steering Towards Fairness: Mitigating Political Bias in LLMs]] (82.6% similar)
- [[2025-09-24/From Parameters to Performance_ A Data-Driven Study on LLM Structure and Development_20250924|From Parameters to Performance: A Data-Driven Study on LLM Structure and Development]] (82.4% similar)
- [[2025-09-19/Adding LLMs to the psycholinguistic norming toolbox_ A practical guide to getting the most out of human ratings_20250919|Adding LLMs to the psycholinguistic norming toolbox: A practical guide to getting the most out of human ratings]] (82.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**âš¡ Unique Technical**: [[keywords/Election-related Knowledge|Election-related Knowledge]], [[keywords/Demographic Steering|Demographic Steering]], [[keywords/Implicit Predictions|Implicit Predictions]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18446v1 Announce Type: cross 
Abstract: The 2024 US presidential election is the first major contest to occur in the US since the popularization of large language models (LLMs). Building on lessons from earlier shifts in media (most notably social media's well studied role in targeted messaging and political polarization) this moment raises urgent questions about how LLMs may shape the information ecosystem and influence political discourse. While platforms have announced some election safeguards, how well they work in practice remains unclear. Against this backdrop, we conduct a large-scale, longitudinal study of 12 models, queried using a structured survey with over 12,000 questions on a near-daily cadence from July through November 2024. Our design systematically varies content and format, resulting in a rich dataset that enables analyses of the models' behavior over time (e.g., across model updates), sensitivity to steering, responsiveness to instructions, and election-related knowledge and "beliefs." In the latter half of our work, we perform four analyses of the dataset that (i) study the longitudinal variation of model behavior during election season, (ii) illustrate the sensitivity of election-related responses to demographic steering, (iii) interrogate the models' beliefs about candidates' attributes, and (iv) reveal the models' implicit predictions of the election outcome. To facilitate future evaluations of LLMs in electoral contexts, we detail our methodology, from question generation to the querying pipeline and third-party tooling. We also publicly release our dataset at https://huggingface.co/datasets/sarahcen/llm-election-data-2024

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ 2024ë…„ ë¯¸êµ­ ëŒ€í†µë ¹ ì„ ê±°ì™€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì˜í–¥ë ¥ì„ ì—°êµ¬í•©ë‹ˆë‹¤. ì—°êµ¬ì§„ì€ 12ê°œì˜ ëª¨ë¸ì„ ëŒ€ìƒìœ¼ë¡œ 2024ë…„ 7ì›”ë¶€í„° 11ì›”ê¹Œì§€ 12,000ê°œ ì´ìƒì˜ ì§ˆë¬¸ì„ í†µí•´ ëŒ€ê·œëª¨ ì¢…ë‹¨ ì—°êµ¬ë¥¼ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. ì—°êµ¬ëŠ” ëª¨ë¸ì˜ í–‰ë™ ë³€í™”, ì§€ì‹œ ë¯¼ê°ì„±, ì„ ê±° ê´€ë ¨ ì§€ì‹ ë° "ì‹ ë…"ì„ ë¶„ì„í–ˆìŠµë‹ˆë‹¤. ì£¼ìš” ë°œê²¬ì‚¬í•­ìœ¼ë¡œëŠ” (i) ì„ ê±° ê¸°ê°„ ë™ì•ˆ ëª¨ë¸ í–‰ë™ì˜ ë³€í™”, (ii) ì¸êµ¬ í†µê³„ì  ì¡°ì‘ì— ëŒ€í•œ ë¯¼ê°ì„±, (iii) í›„ë³´ ì†ì„±ì— ëŒ€í•œ ëª¨ë¸ì˜ ì‹ ë…, (iv) ì•”ë¬µì  ì„ ê±° ê²°ê³¼ ì˜ˆì¸¡ì´ í¬í•¨ë©ë‹ˆë‹¤. ì—°êµ¬ ë°©ë²•ë¡ ê³¼ ë°ì´í„°ì…‹ì€ ê³µê°œë˜ì–´ í–¥í›„ ì—°êµ¬ì— ê¸°ì—¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. 2024ë…„ ë¯¸êµ­ ëŒ€í†µë ¹ ì„ ê±°ëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ëŒ€ì¤‘í™” ì´í›„ ì²˜ìŒìœ¼ë¡œ ì¹˜ëŸ¬ì§€ëŠ” ì£¼ìš” ì„ ê±°ë¡œ, LLMì´ ì •ë³´ ìƒíƒœê³„ì™€ ì •ì¹˜ì  ë‹´ë¡ ì— ë¯¸ì¹  ì˜í–¥ì— ëŒ€í•œ ê¸´ê¸‰í•œ ì§ˆë¬¸ì´ ì œê¸°ëœë‹¤.
- 2. ì—°êµ¬ëŠ” 2024ë…„ 7ì›”ë¶€í„° 11ì›”ê¹Œì§€ 12ê°œ ëª¨ë¸ì„ ëŒ€ìƒìœ¼ë¡œ 12,000ê°œ ì´ìƒì˜ ì§ˆë¬¸ì„ í†µí•´ ëŒ€ê·œëª¨, ì¢…ë‹¨ì  ì¡°ì‚¬ë¥¼ ìˆ˜í–‰í•˜ì—¬ ëª¨ë¸ì˜ í–‰ë™ ë³€í™”ë¥¼ ë¶„ì„í•œë‹¤.
- 3. ë°ì´í„°ì…‹ ë¶„ì„ì„ í†µí•´ ì„ ê±° ì‹œì¦Œ ë™ì•ˆ ëª¨ë¸ í–‰ë™ì˜ ì¢…ë‹¨ì  ë³€í™”, ì¸êµ¬í†µê³„í•™ì  ì¡°ì‘ì— ëŒ€í•œ ë¯¼ê°ì„±, í›„ë³´ ì†ì„±ì— ëŒ€í•œ ëª¨ë¸ì˜ ì‹ ë…, ì„ ê±° ê²°ê³¼ì— ëŒ€í•œ ì•”ë¬µì  ì˜ˆì¸¡ì„ ì—°êµ¬í•œë‹¤.
- 4. ì—°êµ¬ëŠ” ì„ ê±° ê´€ë ¨ ë§¥ë½ì—ì„œ LLMì˜ í‰ê°€ë¥¼ ë•ê¸° ìœ„í•´ ì§ˆë¬¸ ìƒì„±ë¶€í„° ì¿¼ë¦¬ íŒŒì´í”„ë¼ì¸ ë° íƒ€ì‚¬ ë„êµ¬ê¹Œì§€ì˜ ë°©ë²•ë¡ ì„ ìƒì„¸íˆ ì„¤ëª…í•˜ê³ , ë°ì´í„°ì…‹ì„ ê³µê°œí•œë‹¤.


---

*Generated on 2025-09-24 15:09:33*