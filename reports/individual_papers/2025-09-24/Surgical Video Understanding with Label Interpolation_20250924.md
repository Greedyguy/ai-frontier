<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T16:09:23.792170",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Robot-assisted Surgery",
    "Multi-task Learning",
    "Optical Flow-based Segmentation",
    "Surgical Instrument Segmentation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Robot-assisted Surgery": 0.8,
    "Multi-task Learning": 0.75,
    "Optical Flow-based Segmentation": 0.7,
    "Surgical Instrument Segmentation": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Robot-assisted surgery",
        "canonical": "Robot-assisted Surgery",
        "aliases": [
          "RAS"
        ],
        "category": "unique_technical",
        "rationale": "This term is central to the paper's focus and connects to advancements in surgical technology.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "multi-task learning",
        "canonical": "Multi-task Learning",
        "aliases": [
          "MTL"
        ],
        "category": "broad_technical",
        "rationale": "Multi-task learning is a key approach in the paper, linking to various machine learning applications.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.75
      },
      {
        "surface": "optical flow-based segmentation",
        "canonical": "Optical Flow-based Segmentation",
        "aliases": [
          "optical flow segmentation"
        ],
        "category": "unique_technical",
        "rationale": "This technique is pivotal for label interpolation in the paper, offering a unique approach to video analysis.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.7
      },
      {
        "surface": "surgical instrument segmentation",
        "canonical": "Surgical Instrument Segmentation",
        "aliases": [
          "instrument segmentation"
        ],
        "category": "specific_connectable",
        "rationale": "This task is crucial for understanding surgical scenes and links to computer vision applications.",
        "novelty_score": 0.6,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "visual data",
      "temporal dynamics",
      "key frames"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Robot-assisted surgery",
      "resolved_canonical": "Robot-assisted Surgery",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "multi-task learning",
      "resolved_canonical": "Multi-task Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "optical flow-based segmentation",
      "resolved_canonical": "Optical Flow-based Segmentation",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "surgical instrument segmentation",
      "resolved_canonical": "Surgical Instrument Segmentation",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# Surgical Video Understanding with Label Interpolation

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18802.pdf)
**Category**: cs.CV
**Published**: 2025-09-24
**ArXiv ID**: [2509.18802](https://arxiv.org/abs/2509.18802)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Data-Efficient Learning for Generalizable Surgical Video Understanding_20250922|Data-Efficient Learning for Generalizable Surgical Video Understanding]] (85.8% similar)
- [[2025-09-19/Affordance-Based Disambiguation of Surgical Instructions for Collaborative Robot-Assisted Surgery_20250919|Affordance-Based Disambiguation of Surgical Instructions for Collaborative Robot-Assisted Surgery]] (85.3% similar)
- [[2025-09-24/Towards Application Aligned Synthetic Surgical Image Synthesis_20250924|Towards Application Aligned Synthetic Surgical Image Synthesis]] (83.2% similar)
- [[2025-09-23/VocSegMRI_ Multimodal Learning for Precise Vocal Tract Segmentation in Real-time MRI_20250923|VocSegMRI: Multimodal Learning for Precise Vocal Tract Segmentation in Real-time MRI]] (83.0% similar)
- [[2025-09-23/Efficient 3D Scene Reconstruction and Simulation from Sparse Endoscopic Views_20250923|Efficient 3D Scene Reconstruction and Simulation from Sparse Endoscopic Views]] (82.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Multi-task Learning|Multi-task Learning]]
**ğŸ”— Specific Connectable**: [[keywords/Surgical Instrument Segmentation|Surgical Instrument Segmentation]]
**âš¡ Unique Technical**: [[keywords/Robot-assisted Surgery|Robot-assisted Surgery]], [[keywords/Optical Flow-based Segmentation|Optical Flow-based Segmentation]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18802v1 Announce Type: new 
Abstract: Robot-assisted surgery (RAS) has become a critical paradigm in modern surgery, promoting patient recovery and reducing the burden on surgeons through minimally invasive approaches. To fully realize its potential, however, a precise understanding of the visual data generated during surgical procedures is essential. Previous studies have predominantly focused on single-task approaches, but real surgical scenes involve complex temporal dynamics and diverse instrument interactions that limit comprehensive understanding. Moreover, the effective application of multi-task learning (MTL) requires sufficient pixel-level segmentation data, which are difficult to obtain due to the high cost and expertise required for annotation. In particular, long-term annotations such as phases and steps are available for every frame, whereas short-term annotations such as surgical instrument segmentation and action detection are provided only for key frames, resulting in a significant temporal-spatial imbalance. To address these challenges, we propose a novel framework that combines optical flow-based segmentation label interpolation with multi-task learning. optical flow estimated from annotated key frames is used to propagate labels to adjacent unlabeled frames, thereby enriching sparse spatial supervision and balancing temporal and spatial information for training. This integration improves both the accuracy and efficiency of surgical scene understanding and, in turn, enhances the utility of RAS.

## ğŸ“ ìš”ì•½

ë¡œë´‡ ë³´ì¡° ìˆ˜ìˆ (RAS)ì€ ìµœì†Œ ì¹¨ìŠµì  ì ‘ê·¼ì„ í†µí•´ í™˜ì íšŒë³µì„ ì´‰ì§„í•˜ê³  ì™¸ê³¼ì˜ì‚¬ì˜ ë¶€ë‹´ì„ ì¤„ì´ëŠ” ì¤‘ìš”í•œ í˜„ëŒ€ ìˆ˜ìˆ  íŒ¨ëŸ¬ë‹¤ì„ì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ìˆ˜ìˆ  ì¤‘ ìƒì„±ë˜ëŠ” ì‹œê° ë°ì´í„°ì˜ ì •í™•í•œ ì´í•´ê°€ í•„ìš”í•©ë‹ˆë‹¤. ê¸°ì¡´ ì—°êµ¬ëŠ” ì£¼ë¡œ ë‹¨ì¼ ì‘ì—…ì— ì§‘ì¤‘í–ˆìœ¼ë‚˜, ì‹¤ì œ ìˆ˜ìˆ  ì¥ë©´ì€ ë³µì¡í•œ ì‹œê°„ì  ì—­í•™ê³¼ ë‹¤ì–‘í•œ ê¸°êµ¬ ìƒí˜¸ì‘ìš©ì„ í¬í•¨í•©ë‹ˆë‹¤. ë˜í•œ, ë‹¤ì¤‘ ì‘ì—… í•™ìŠµ(MTL)ì˜ íš¨ê³¼ì ì¸ ì ìš©ì„ ìœ„í•´ì„œëŠ” í”½ì…€ ìˆ˜ì¤€ì˜ ì„¸ë¶„í™” ë°ì´í„°ê°€ í•„ìš”í•˜ì§€ë§Œ, ì´ëŠ” ë†’ì€ ë¹„ìš©ê³¼ ì „ë¬¸ì„± ë•Œë¬¸ì— ì–»ê¸° ì–´ë µìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ê´‘í•™ íë¦„ ê¸°ë°˜ì˜ ì„¸ë¶„í™” ë ˆì´ë¸” ë³´ê°„ê³¼ ë‹¤ì¤‘ ì‘ì—… í•™ìŠµì„ ê²°í•©í•œ ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì£¼ì„ì´ ë‹¬ë¦° ì£¼ìš” í”„ë ˆì„ì—ì„œ ì¶”ì •ëœ ê´‘í•™ íë¦„ì„ ì‚¬ìš©í•˜ì—¬ ë ˆì´ë¸”ì„ ì¸ì ‘í•œ ë¹„ì£¼ì„ í”„ë ˆì„ìœ¼ë¡œ ì „íŒŒí•¨ìœ¼ë¡œì¨, í¬ì†Œí•œ ê³µê°„ì  ê°ë…ì„ í’ë¶€í•˜ê²Œ í•˜ê³  ì‹œê°„ì  ë° ê³µê°„ì  ì •ë³´ë¥¼ ê· í˜• ìˆê²Œ í•©ë‹ˆë‹¤. ì´ í†µí•©ì€ ìˆ˜ìˆ  ì¥ë©´ ì´í•´ì˜ ì •í™•ì„±ê³¼ íš¨ìœ¨ì„±ì„ í–¥ìƒì‹œì¼œ RASì˜ ìœ ìš©ì„±ì„ ë†’ì…ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë¡œë´‡ ë³´ì¡° ìˆ˜ìˆ (RAS)ì€ ìµœì†Œ ì¹¨ìŠµ ì ‘ê·¼ë²•ì„ í†µí•´ í™˜ì íšŒë³µì„ ì´‰ì§„í•˜ê³  ì™¸ê³¼ì˜ì‚¬ì˜ ë¶€ë‹´ì„ ì¤„ì´ëŠ” ì¤‘ìš”í•œ í˜„ëŒ€ ìˆ˜ìˆ  íŒ¨ëŸ¬ë‹¤ì„ì…ë‹ˆë‹¤.
- 2. ê¸°ì¡´ ì—°êµ¬ëŠ” ì£¼ë¡œ ë‹¨ì¼ ì‘ì—… ì ‘ê·¼ë²•ì— ì§‘ì¤‘í–ˆì§€ë§Œ, ì‹¤ì œ ìˆ˜ìˆ  ì¥ë©´ì€ ë³µì¡í•œ ì‹œê°„ì  ì—­í•™ê³¼ ë‹¤ì–‘í•œ ê¸°êµ¬ ìƒí˜¸ì‘ìš©ì„ í¬í•¨í•˜ì—¬ í¬ê´„ì ì¸ ì´í•´ì— í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤.
- 3. ë‹¤ì¤‘ ì‘ì—… í•™ìŠµ(MTL)ì˜ íš¨ê³¼ì ì¸ ì ìš©ì„ ìœ„í•´ì„œëŠ” ì¶©ë¶„í•œ í”½ì…€ ìˆ˜ì¤€ì˜ ë¶„í•  ë°ì´í„°ê°€ í•„ìš”í•˜ì§€ë§Œ, ì´ëŠ” ë†’ì€ ë¹„ìš©ê³¼ ì „ë¬¸ì„± ìš”êµ¬ë¡œ ì¸í•´ ì–»ê¸° ì–´ë µìŠµë‹ˆë‹¤.
- 4. ì œì•ˆëœ í”„ë ˆì„ì›Œí¬ëŠ” ì£¼ì„ëœ ì£¼ìš” í”„ë ˆì„ì—ì„œ ì¶”ì •ëœ ê´‘í•™ íë¦„ì„ ì‚¬ìš©í•˜ì—¬ ë ˆì´ë¸”ì„ ì¸ì ‘í•œ ë¹„ì£¼ì„ í”„ë ˆì„ìœ¼ë¡œ ì „íŒŒí•¨ìœ¼ë¡œì¨ í¬ì†Œí•œ ê³µê°„ì  ê°ë…ì„ í’ë¶€í•˜ê²Œ í•˜ê³  ì‹œê°„ì  ë° ê³µê°„ì  ì •ë³´ë¥¼ ê· í˜• ìˆê²Œ í•©ë‹ˆë‹¤.
- 5. ì´ í†µí•©ì€ ìˆ˜ìˆ  ì¥ë©´ ì´í•´ì˜ ì •í™•ì„±ê³¼ íš¨ìœ¨ì„±ì„ ê°œì„ í•˜ì—¬ RASì˜ ìœ ìš©ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.


---

*Generated on 2025-09-24 16:09:23*