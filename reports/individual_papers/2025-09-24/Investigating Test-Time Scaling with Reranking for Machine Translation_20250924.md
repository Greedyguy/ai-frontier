<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T15:44:00.455328",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Test-Time Scaling",
    "Machine Translation",
    "Neural MT Evaluation Metrics",
    "Compute Budget"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Test-Time Scaling": 0.78,
    "Machine Translation": 0.85,
    "Neural MT Evaluation Metrics": 0.7,
    "Compute Budget": 0.68
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Test-Time Scaling",
        "canonical": "Test-Time Scaling",
        "aliases": [
          "TTS"
        ],
        "category": "unique_technical",
        "rationale": "Test-Time Scaling is a novel approach in the context of machine translation, offering a unique perspective on computational efficiency.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Machine Translation",
        "canonical": "Machine Translation",
        "aliases": [
          "MT"
        ],
        "category": "broad_technical",
        "rationale": "Machine Translation is a core area of study within NLP, providing a strong link to related research in language processing.",
        "novelty_score": 0.4,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Neural MT Evaluation Metrics",
        "canonical": "Neural MT Evaluation Metrics",
        "aliases": [
          "neural machine translation metrics"
        ],
        "category": "specific_connectable",
        "rationale": "These metrics are crucial for assessing translation quality, linking to broader discussions on evaluation in NLP.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      },
      {
        "surface": "Compute Budget",
        "canonical": "Compute Budget",
        "aliases": [
          "computational budget"
        ],
        "category": "specific_connectable",
        "rationale": "Compute Budget is a key factor in model performance and efficiency, relevant to discussions on resource allocation in AI.",
        "novelty_score": 0.5,
        "connectivity_score": 0.65,
        "specificity_score": 0.75,
        "link_intent_score": 0.68
      }
    ],
    "ban_list_suggestions": [
      "scaling",
      "model parameters",
      "language pairs"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Test-Time Scaling",
      "resolved_canonical": "Test-Time Scaling",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Machine Translation",
      "resolved_canonical": "Machine Translation",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Neural MT Evaluation Metrics",
      "resolved_canonical": "Neural MT Evaluation Metrics",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Compute Budget",
      "resolved_canonical": "Compute Budget",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.65,
        "specificity": 0.75,
        "link_intent": 0.68
      }
    }
  ]
}
-->

# Investigating Test-Time Scaling with Reranking for Machine Translation

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19020.pdf)
**Category**: cs.CL
**Published**: 2025-09-24
**ArXiv ID**: [2509.19020](https://arxiv.org/abs/2509.19020)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Mitigating Strategy-Selection Bias in Reasoning for More Effective Test-Time Scaling_20250923|Mitigating Strategy-Selection Bias in Reasoning for More Effective Test-Time Scaling]] (85.9% similar)
- [[2025-09-18/Audio-Based Crowd-Sourced Evaluation of Machine Translation Quality_20250918|Audio-Based Crowd-Sourced Evaluation of Machine Translation Quality]] (83.0% similar)
- [[2025-09-23/LTA-thinker_ Latent Thought-Augmented Training Framework for Large Language Models on Complex Reasoning_20250923|LTA-thinker: Latent Thought-Augmented Training Framework for Large Language Models on Complex Reasoning]] (82.8% similar)
- [[2025-09-23/Transformer-Encoder Trees for Efficient Multilingual Machine Translation and Speech Translation_20250923|Transformer-Encoder Trees for Efficient Multilingual Machine Translation and Speech Translation]] (82.5% similar)
- [[2025-09-23/Scaling, Simplification, and Adaptation_ Lessons from Pretraining on Machine-Translated Text_20250923|Scaling, Simplification, and Adaptation: Lessons from Pretraining on Machine-Translated Text]] (82.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Machine Translation|Machine Translation]]
**ğŸ”— Specific Connectable**: [[keywords/Neural MT Evaluation Metrics|Neural MT Evaluation Metrics]], [[keywords/Compute Budget|Compute Budget]]
**âš¡ Unique Technical**: [[keywords/Test-Time Scaling|Test-Time Scaling]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19020v1 Announce Type: new 
Abstract: Scaling model parameters has become the de facto strategy for improving NLP systems, but it comes with substantial computational costs. Test-Time Scaling (TTS) offers an alternative by allocating more computation at inference: generating multiple candidates and selecting the best. While effective in tasks such as mathematical reasoning, TTS has not been systematically explored for machine translation (MT). In this paper, we present the first systematic study of TTS for MT, investigating a simple but practical best-of-N framework on WMT24 benchmarks. Our experiments cover six high-resource and one low-resource language pairs, five model sizes (3B-72B), and various TTS compute budget (N up to 1024). Our results show that a) For high-resource languages, TTS generally improves translation quality according to multiple neural MT evaluation metrics, and our human evaluation confirms these gains; b) Augmenting smaller models with large $N$ can match or surpass larger models at $N{=}1$ with more compute cost; c) Under fixed compute budgets, larger models are typically more efficient, and TTS can degrade quality due to metric blind spots in low-resource cases.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ê¸°ê³„ ë²ˆì—­(MT)ì—ì„œ í…ŒìŠ¤íŠ¸ ì‹œ ìŠ¤ì¼€ì¼ë§(TTS)ì˜ ì²´ê³„ì ì¸ ì—°êµ¬ë¥¼ ìµœì´ˆë¡œ ìˆ˜í–‰í•˜ì˜€ìŠµë‹ˆë‹¤. TTSëŠ” ì¶”ë¡  ì‹œ ì—¬ëŸ¬ í›„ë³´ë¥¼ ìƒì„±í•˜ê³  ìµœì ì˜ ê²°ê³¼ë¥¼ ì„ íƒí•˜ì—¬ ë²ˆì—­ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¤ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. WMT24 ë²¤ì¹˜ë§ˆí¬ë¥¼ í†µí•´ ê³ ìì› ë° ì €ìì› ì–¸ì–´ ìŒì„ ëŒ€ìƒìœ¼ë¡œ ë‹¤ì–‘í•œ ëª¨ë¸ í¬ê¸°(3B-72B)ì™€ TTS ê³„ì‚° ì˜ˆì‚°(N ìµœëŒ€ 1024)ì„ ì‹¤í—˜í•˜ì˜€ìŠµë‹ˆë‹¤. ì£¼ìš” ë°œê²¬ì‚¬í•­ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤: a) ê³ ìì› ì–¸ì–´ì˜ ê²½ìš°, TTSëŠ” ë²ˆì—­ í’ˆì§ˆì„ ê°œì„ í•˜ë©° ì´ëŠ” ì¸ê°„ í‰ê°€ì—ì„œë„ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤. b) ì‘ì€ ëª¨ë¸ì— í° Nì„ ì ìš©í•˜ë©´ ë” í° ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì´ˆê³¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. c) ê³ ì •ëœ ê³„ì‚° ì˜ˆì‚° í•˜ì—ì„œëŠ” í° ëª¨ë¸ì´ ì¼ë°˜ì ìœ¼ë¡œ ë” íš¨ìœ¨ì ì´ë©°, ì €ìì› ì–¸ì–´ì˜ ê²½ìš° TTSê°€ í’ˆì§ˆì„ ì €í•˜ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. í…ŒìŠ¤íŠ¸ íƒ€ì„ ìŠ¤ì¼€ì¼ë§(TTS)ì€ NLP ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ëŒ€ì•ˆìœ¼ë¡œ, ì¶”ë¡  ì‹œ ë” ë§ì€ ê³„ì‚°ì„ í• ë‹¹í•˜ì—¬ ì—¬ëŸ¬ í›„ë³´ë¥¼ ìƒì„±í•˜ê³  ìµœì ì˜ ê²°ê³¼ë¥¼ ì„ íƒí•˜ëŠ” ë°©ë²•ì´ë‹¤.
- 2. ë³¸ ì—°êµ¬ëŠ” ê¸°ê³„ ë²ˆì—­(MT) ë¶„ì•¼ì—ì„œ TTSì˜ ì²´ê³„ì ì¸ ì²« ì—°êµ¬ë¡œ, WMT24 ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë‹¨ìˆœí•˜ì§€ë§Œ ì‹¤ìš©ì ì¸ best-of-N í”„ë ˆì„ì›Œí¬ë¥¼ ì¡°ì‚¬í•˜ì˜€ë‹¤.
- 3. ì‹¤í—˜ ê²°ê³¼, ê³ ìì› ì–¸ì–´ì˜ ê²½ìš° TTSê°€ ë²ˆì—­ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¤ë©°, ì´ëŠ” ì—¬ëŸ¬ ì‹ ê²½ë§ MT í‰ê°€ ì§€í‘œì™€ ì¸ê°„ í‰ê°€ì—ì„œë„ í™•ì¸ë˜ì—ˆë‹¤.
- 4. ì‘ì€ ëª¨ë¸ì— í° Nì„ ì ìš©í•˜ë©´ ë” ë§ì€ ê³„ì‚° ë¹„ìš©ì„ ë“¤ì—¬ N=1ì˜ í° ëª¨ë¸ê³¼ ë§ë¨¹ê±°ë‚˜ ì´ë¥¼ ëŠ¥ê°€í•  ìˆ˜ ìˆë‹¤.
- 5. ê³ ì •ëœ ê³„ì‚° ì˜ˆì‚° í•˜ì—ì„œëŠ” í° ëª¨ë¸ì´ ì¼ë°˜ì ìœ¼ë¡œ ë” íš¨ìœ¨ì ì´ë©°, ì €ìì› ì–¸ì–´ì˜ ê²½ìš° TTSê°€ í’ˆì§ˆì„ ì €í•˜ì‹œí‚¬ ìˆ˜ ìˆë‹¤.


---

*Generated on 2025-09-24 15:44:00*