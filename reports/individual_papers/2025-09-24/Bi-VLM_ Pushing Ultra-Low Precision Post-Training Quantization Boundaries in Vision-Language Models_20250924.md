<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T16:08:48.875170",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Vision-Language Model",
    "Ultra-Low Precision Quantization",
    "Saliency-Aware Hybrid Quantization",
    "Token Pruning",
    "Gaussian Quantiles"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Vision-Language Model": 0.85,
    "Ultra-Low Precision Quantization": 0.7,
    "Saliency-Aware Hybrid Quantization": 0.75,
    "Token Pruning": 0.68,
    "Gaussian Quantiles": 0.66
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Vision-Language Models",
        "canonical": "Vision-Language Model",
        "aliases": [
          "VLM",
          "Vision-Language"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-Language Models are central to the paper's focus on quantization and efficiency improvements.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.82,
        "link_intent_score": 0.85
      },
      {
        "surface": "Ultra-Low Precision Quantization",
        "canonical": "Ultra-Low Precision Quantization",
        "aliases": [
          "ULP Quantization"
        ],
        "category": "unique_technical",
        "rationale": "This technique is a novel approach discussed in the paper for improving model efficiency.",
        "novelty_score": 0.78,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      },
      {
        "surface": "Saliency-Aware Hybrid Quantization",
        "canonical": "Saliency-Aware Hybrid Quantization",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This specific quantization method is a key contribution of the paper.",
        "novelty_score": 0.82,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.75
      },
      {
        "surface": "Token Pruning",
        "canonical": "Token Pruning",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Token Pruning is a significant technique used in the paper to improve model efficiency.",
        "novelty_score": 0.55,
        "connectivity_score": 0.72,
        "specificity_score": 0.78,
        "link_intent_score": 0.68
      },
      {
        "surface": "Gaussian Quantiles",
        "canonical": "Gaussian Quantiles",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Gaussian Quantiles are used in the paper to separate model weights, which is a novel approach.",
        "novelty_score": 0.65,
        "connectivity_score": 0.58,
        "specificity_score": 0.77,
        "link_intent_score": 0.66
      }
    ],
    "ban_list_suggestions": [
      "model weights",
      "quantization algorithm"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Vision-Language Models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.82,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Ultra-Low Precision Quantization",
      "resolved_canonical": "Ultra-Low Precision Quantization",
      "decision": "linked",
      "scores": {
        "novelty": 0.78,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Saliency-Aware Hybrid Quantization",
      "resolved_canonical": "Saliency-Aware Hybrid Quantization",
      "decision": "linked",
      "scores": {
        "novelty": 0.82,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Token Pruning",
      "resolved_canonical": "Token Pruning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.72,
        "specificity": 0.78,
        "link_intent": 0.68
      }
    },
    {
      "candidate_surface": "Gaussian Quantiles",
      "resolved_canonical": "Gaussian Quantiles",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.58,
        "specificity": 0.77,
        "link_intent": 0.66
      }
    }
  ]
}
-->

# Bi-VLM: Pushing Ultra-Low Precision Post-Training Quantization Boundaries in Vision-Language Models

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18763.pdf)
**Category**: cs.CV
**Published**: 2025-09-24
**ArXiv ID**: [2509.18763](https://arxiv.org/abs/2509.18763)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Eye Gaze Tells You Where to Compute_ Gaze-Driven Efficient VLMs_20250923|Eye Gaze Tells You Where to Compute: Gaze-Driven Efficient VLMs]] (86.8% similar)
- [[2025-09-22/ViSpec_ Accelerating Vision-Language Models with Vision-Aware Speculative Decoding_20250922|ViSpec: Accelerating Vision-Language Models with Vision-Aware Speculative Decoding]] (86.8% similar)
- [[2025-09-23/When Big Models Train Small Ones_ Label-Free Model Parity Alignment for Efficient Visual Question Answering using Small VLMs_20250923|When Big Models Train Small Ones: Label-Free Model Parity Alignment for Efficient Visual Question Answering using Small VLMs]] (86.6% similar)
- [[2025-09-23/SpecVLM_ Fast Speculative Decoding in Vision-Language Models_20250923|SpecVLM: Fast Speculative Decoding in Vision-Language Models]] (86.5% similar)
- [[2025-09-24/SBVR_ Summation of BitVector Representation for Efficient LLM Quantization_20250924|SBVR: Summation of BitVector Representation for Efficient LLM Quantization]] (86.4% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Token Pruning|Token Pruning]]
**âš¡ Unique Technical**: [[keywords/Ultra-Low Precision Quantization|Ultra-Low Precision Quantization]], [[keywords/Saliency-Aware Hybrid Quantization|Saliency-Aware Hybrid Quantization]], [[keywords/Gaussian Quantiles|Gaussian Quantiles]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18763v1 Announce Type: new 
Abstract: We address the critical gap between the computational demands of vision-language models and the possible ultra-low-bit weight precision (bitwidth $\leq2$ bits) we can use for higher efficiency. Our work is motivated by the substantial computational cost and memory requirements of VLMs, which restrict their applicability in hardware-constrained environments. We propose Bi-VLM, which separates model weights non-uniformly based on the Gaussian quantiles. Our formulation groups the model weights into outlier (salient) and multiple inlier (unsalient) subsets, ensuring that each subset contains a proportion of weights corresponding to its quantile in the distribution. We propose a saliency-aware hybrid quantization algorithm and use it to quantize weights by imposing different constraints on the scaler and binary matrices based on the saliency metric and compression objective. We have evaluated our approach on different VLMs. For the language model part of the VLM, our Bi-VLM outperforms the SOTA by 3%-47% on the visual question answering task in terms of four different benchmarks and three different models. For the overall VLM, our Bi-VLM outperforms the SOTA by 4%-45%. We also perform token pruning on the quantized models and observe that there is redundancy of image tokens 90% - 99% in the quantized models. This helps us to further prune the visual tokens to improve efficiency.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë¹„ì „-ì–¸ì–´ ëª¨ë¸(VLM)ì˜ ë†’ì€ ê³„ì‚° ìš”êµ¬ì™€ ì´ˆì €ë¹„íŠ¸ ê°€ì¤‘ì¹˜ ì •ë°€ë„(2ë¹„íŠ¸ ì´í•˜) ì‚¬ì´ì˜ ê°„ê·¹ì„ í•´ê²°í•˜ê³ ì í•©ë‹ˆë‹¤. VLMì˜ ë†’ì€ ê³„ì‚° ë¹„ìš©ê³¼ ë©”ëª¨ë¦¬ ìš”êµ¬ëŠ” í•˜ë“œì›¨ì–´ ì œì•½ í™˜ê²½ì—ì„œì˜ ì ìš©ì„ ì œí•œí•©ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ê°€ìš°ì‹œì•ˆ ë¶„ìœ„ìˆ˜ì— ê¸°ë°˜í•˜ì—¬ ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ë¹„ê· ì¼í•˜ê²Œ ë¶„ë¦¬í•˜ëŠ” Bi-VLMì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ê°€ì¤‘ì¹˜ë¥¼ ì¤‘ìš”í•œ(outlier) ë¶€ë¶„ê³¼ ëœ ì¤‘ìš”í•œ(inlier) ë¶€ë¶„ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ê° ë¶€ë¶„ì´ ë¶„í¬ì˜ ë¶„ìœ„ìˆ˜ì— í•´ë‹¹í•˜ëŠ” ë¹„ìœ¨ì˜ ê°€ì¤‘ì¹˜ë¥¼ í¬í•¨í•˜ë„ë¡ í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì¤‘ìš”ë„ ì¸ì‹ í•˜ì´ë¸Œë¦¬ë“œ ì–‘ìí™” ì•Œê³ ë¦¬ì¦˜ì„ ì œì•ˆí•˜ê³ , ì´ë¥¼ í†µí•´ ì¤‘ìš”ë„ ì§€í‘œì™€ ì••ì¶• ëª©í‘œì— ë”°ë¼ ìŠ¤ì¼€ì¼ëŸ¬ ë° ì´ì§„ í–‰ë ¬ì— ë‹¤ë¥¸ ì œì•½ì„ ë¶€ê³¼í•˜ì—¬ ê°€ì¤‘ì¹˜ë¥¼ ì–‘ìí™”í•©ë‹ˆë‹¤. ì œì•ˆëœ ë°©ë²•ì€ ë‹¤ì–‘í•œ VLMì—ì„œ í‰ê°€ë˜ì—ˆìœ¼ë©°, ì–¸ì–´ ëª¨ë¸ ë¶€ë¶„ì—ì„œ ì‹œê°ì  ì§ˆë¬¸ ì‘ë‹µ ì‘ì—…ì—ì„œ SOTAë¥¼ 3%-47% ì´ˆê³¼í•˜ëŠ” ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ì „ì²´ VLMì—ì„œë„ SOTAë¥¼ 4%-45% ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, ì–‘ìí™”ëœ ëª¨ë¸ì—ì„œ í† í° ê°€ì§€ì¹˜ê¸°ë¥¼ ìˆ˜í–‰í•˜ì—¬ ì´ë¯¸ì§€ í† í°ì˜ 90%-99%ê°€ ì¤‘ë³µë¨ì„ ê´€ì°°í•˜ì˜€ê³ , ì´ë¥¼ í†µí•´ ì‹œê°ì  í† í°ì„ ì¶”ê°€ë¡œ ê°€ì§€ì¹˜ê¸°í•˜ì—¬ íš¨ìœ¨ì„±ì„ ê°œì„ í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Bi-VLMì€ ê°€ìš°ì‹œì•ˆ ë¶„ìœ„ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ë¹„ê· ì¼í•˜ê²Œ ë¶„ë¦¬í•˜ì—¬ íš¨ìœ¨ì„±ì„ ë†’ì…ë‹ˆë‹¤.
- 2. Bi-VLMì€ saliency-aware í•˜ì´ë¸Œë¦¬ë“œ ì–‘ìí™” ì•Œê³ ë¦¬ì¦˜ì„ ì œì•ˆí•˜ì—¬ ê°€ì¤‘ì¹˜ë¥¼ ì–‘ìí™”í•©ë‹ˆë‹¤.
- 3. Bi-VLMì€ VLMì˜ ì–¸ì–´ ëª¨ë¸ ë¶€ë¶„ì—ì„œ SOTA ëŒ€ë¹„ 3%-47% ì„±ëŠ¥ í–¥ìƒì„ ë³´ì˜€ìŠµë‹ˆë‹¤.
- 4. ì „ì²´ VLMì—ì„œ Bi-VLMì€ SOTA ëŒ€ë¹„ 4%-45% ì„±ëŠ¥ í–¥ìƒì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.
- 5. ì–‘ìí™”ëœ ëª¨ë¸ì—ì„œ ì´ë¯¸ì§€ í† í°ì˜ 90%-99%ê°€ ì¤‘ë³µë˜ì–´, ì¶”ê°€ì ì¸ í† í° ê°€ì§€ì¹˜ê¸°ë¥¼ í†µí•´ íš¨ìœ¨ì„±ì„ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 16:08:48*