<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T16:08:48.875170",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Vision-Language Model",
    "Ultra-Low Precision Quantization",
    "Saliency-Aware Hybrid Quantization",
    "Token Pruning",
    "Gaussian Quantiles"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Vision-Language Model": 0.85,
    "Ultra-Low Precision Quantization": 0.7,
    "Saliency-Aware Hybrid Quantization": 0.75,
    "Token Pruning": 0.68,
    "Gaussian Quantiles": 0.66
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Vision-Language Models",
        "canonical": "Vision-Language Model",
        "aliases": [
          "VLM",
          "Vision-Language"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-Language Models are central to the paper's focus on quantization and efficiency improvements.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.82,
        "link_intent_score": 0.85
      },
      {
        "surface": "Ultra-Low Precision Quantization",
        "canonical": "Ultra-Low Precision Quantization",
        "aliases": [
          "ULP Quantization"
        ],
        "category": "unique_technical",
        "rationale": "This technique is a novel approach discussed in the paper for improving model efficiency.",
        "novelty_score": 0.78,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      },
      {
        "surface": "Saliency-Aware Hybrid Quantization",
        "canonical": "Saliency-Aware Hybrid Quantization",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This specific quantization method is a key contribution of the paper.",
        "novelty_score": 0.82,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.75
      },
      {
        "surface": "Token Pruning",
        "canonical": "Token Pruning",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Token Pruning is a significant technique used in the paper to improve model efficiency.",
        "novelty_score": 0.55,
        "connectivity_score": 0.72,
        "specificity_score": 0.78,
        "link_intent_score": 0.68
      },
      {
        "surface": "Gaussian Quantiles",
        "canonical": "Gaussian Quantiles",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Gaussian Quantiles are used in the paper to separate model weights, which is a novel approach.",
        "novelty_score": 0.65,
        "connectivity_score": 0.58,
        "specificity_score": 0.77,
        "link_intent_score": 0.66
      }
    ],
    "ban_list_suggestions": [
      "model weights",
      "quantization algorithm"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Vision-Language Models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.82,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Ultra-Low Precision Quantization",
      "resolved_canonical": "Ultra-Low Precision Quantization",
      "decision": "linked",
      "scores": {
        "novelty": 0.78,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Saliency-Aware Hybrid Quantization",
      "resolved_canonical": "Saliency-Aware Hybrid Quantization",
      "decision": "linked",
      "scores": {
        "novelty": 0.82,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Token Pruning",
      "resolved_canonical": "Token Pruning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.72,
        "specificity": 0.78,
        "link_intent": 0.68
      }
    },
    {
      "candidate_surface": "Gaussian Quantiles",
      "resolved_canonical": "Gaussian Quantiles",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.58,
        "specificity": 0.77,
        "link_intent": 0.66
      }
    }
  ]
}
-->

# Bi-VLM: Pushing Ultra-Low Precision Post-Training Quantization Boundaries in Vision-Language Models

## 📋 메타데이터

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18763.pdf)
**Category**: cs.CV
**Published**: 2025-09-24
**ArXiv ID**: [2509.18763](https://arxiv.org/abs/2509.18763)

## 🔗 유사한 논문
- [[2025-09-23/Eye Gaze Tells You Where to Compute_ Gaze-Driven Efficient VLMs_20250923|Eye Gaze Tells You Where to Compute: Gaze-Driven Efficient VLMs]] (86.8% similar)
- [[2025-09-22/ViSpec_ Accelerating Vision-Language Models with Vision-Aware Speculative Decoding_20250922|ViSpec: Accelerating Vision-Language Models with Vision-Aware Speculative Decoding]] (86.8% similar)
- [[2025-09-23/When Big Models Train Small Ones_ Label-Free Model Parity Alignment for Efficient Visual Question Answering using Small VLMs_20250923|When Big Models Train Small Ones: Label-Free Model Parity Alignment for Efficient Visual Question Answering using Small VLMs]] (86.6% similar)
- [[2025-09-23/SpecVLM_ Fast Speculative Decoding in Vision-Language Models_20250923|SpecVLM: Fast Speculative Decoding in Vision-Language Models]] (86.5% similar)
- [[2025-09-24/SBVR_ Summation of BitVector Representation for Efficient LLM Quantization_20250924|SBVR: Summation of BitVector Representation for Efficient LLM Quantization]] (86.4% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Token Pruning|Token Pruning]]
**⚡ Unique Technical**: [[keywords/Ultra-Low Precision Quantization|Ultra-Low Precision Quantization]], [[keywords/Saliency-Aware Hybrid Quantization|Saliency-Aware Hybrid Quantization]], [[keywords/Gaussian Quantiles|Gaussian Quantiles]]
**🚀 Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.18763v1 Announce Type: new 
Abstract: We address the critical gap between the computational demands of vision-language models and the possible ultra-low-bit weight precision (bitwidth $\leq2$ bits) we can use for higher efficiency. Our work is motivated by the substantial computational cost and memory requirements of VLMs, which restrict their applicability in hardware-constrained environments. We propose Bi-VLM, which separates model weights non-uniformly based on the Gaussian quantiles. Our formulation groups the model weights into outlier (salient) and multiple inlier (unsalient) subsets, ensuring that each subset contains a proportion of weights corresponding to its quantile in the distribution. We propose a saliency-aware hybrid quantization algorithm and use it to quantize weights by imposing different constraints on the scaler and binary matrices based on the saliency metric and compression objective. We have evaluated our approach on different VLMs. For the language model part of the VLM, our Bi-VLM outperforms the SOTA by 3%-47% on the visual question answering task in terms of four different benchmarks and three different models. For the overall VLM, our Bi-VLM outperforms the SOTA by 4%-45%. We also perform token pruning on the quantized models and observe that there is redundancy of image tokens 90% - 99% in the quantized models. This helps us to further prune the visual tokens to improve efficiency.

## 📝 요약

이 논문은 비전-언어 모델(VLM)의 높은 계산 요구와 초저비트 가중치 정밀도(2비트 이하) 사이의 간극을 해결하고자 합니다. VLM의 높은 계산 비용과 메모리 요구는 하드웨어 제약 환경에서의 적용을 제한합니다. 이를 해결하기 위해, 우리는 가우시안 분위수에 기반하여 모델 가중치를 비균일하게 분리하는 Bi-VLM을 제안합니다. 이 방법은 가중치를 중요한(outlier) 부분과 덜 중요한(inlier) 부분으로 나누어 각 부분이 분포의 분위수에 해당하는 비율의 가중치를 포함하도록 합니다. 우리는 중요도 인식 하이브리드 양자화 알고리즘을 제안하고, 이를 통해 중요도 지표와 압축 목표에 따라 스케일러 및 이진 행렬에 다른 제약을 부과하여 가중치를 양자화합니다. 제안된 방법은 다양한 VLM에서 평가되었으며, 언어 모델 부분에서 시각적 질문 응답 작업에서 SOTA를 3%-47% 초과하는 성능을 보였습니다. 전체 VLM에서도 SOTA를 4%-45% 초과했습니다. 또한, 양자화된 모델에서 토큰 가지치기를 수행하여 이미지 토큰의 90%-99%가 중복됨을 관찰하였고, 이를 통해 시각적 토큰을 추가로 가지치기하여 효율성을 개선했습니다.

## 🎯 주요 포인트

- 1. Bi-VLM은 가우시안 분위수를 기반으로 모델 가중치를 비균일하게 분리하여 효율성을 높입니다.
- 2. Bi-VLM은 saliency-aware 하이브리드 양자화 알고리즘을 제안하여 가중치를 양자화합니다.
- 3. Bi-VLM은 VLM의 언어 모델 부분에서 SOTA 대비 3%-47% 성능 향상을 보였습니다.
- 4. 전체 VLM에서 Bi-VLM은 SOTA 대비 4%-45% 성능 향상을 달성했습니다.
- 5. 양자화된 모델에서 이미지 토큰의 90%-99%가 중복되어, 추가적인 토큰 가지치기를 통해 효율성을 개선할 수 있습니다.


---

*Generated on 2025-09-24 16:08:48*