<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T15:27:31.910504",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Federated Learning",
    "Intelligent Selection of Participants",
    "Transformer",
    "Gradient Compression"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Federated Learning": 0.85,
    "Intelligent Selection of Participants": 0.8,
    "Transformer": 0.78,
    "Gradient Compression": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Federated Learning",
        "canonical": "Federated Learning",
        "aliases": [
          "FL"
        ],
        "category": "broad_technical",
        "rationale": "Federated Learning is a central theme of the paper and connects to many related works in decentralized training.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Intelligent Selection of Participants",
        "canonical": "Intelligent Selection of Participants",
        "aliases": [
          "ISP"
        ],
        "category": "unique_technical",
        "rationale": "ISP is a novel mechanism introduced in the paper, offering a unique approach to optimizing client participation in federated learning.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Vision Transformers",
        "canonical": "Transformer",
        "aliases": [
          "Vision Transformer"
        ],
        "category": "broad_technical",
        "rationale": "Vision Transformers are a specific application of Transformers, linking to broader discussions on deep learning models.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.65,
        "link_intent_score": 0.78
      },
      {
        "surface": "Gradient Compression",
        "canonical": "Gradient Compression",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Gradient Compression is a technique to reduce communication costs in federated learning, relevant to the paper's focus.",
        "novelty_score": 0.6,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "communication efficiency",
      "client selection strategies"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Federated Learning",
      "resolved_canonical": "Federated Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Intelligent Selection of Participants",
      "resolved_canonical": "Intelligent Selection of Participants",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Vision Transformers",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.65,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Gradient Compression",
      "resolved_canonical": "Gradient Compression",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Communication-Efficient Federated Learning with Adaptive Number of Participants

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2508.13803.pdf)
**Category**: cs.LG
**Published**: 2025-09-24
**ArXiv ID**: [2508.13803](https://arxiv.org/abs/2508.13803)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Towards Seamless Hierarchical Federated Learning under Intermittent Client Participation_ A Stagewise Decision-Making Methodology_20250923|Towards Seamless Hierarchical Federated Learning under Intermittent Client Participation: A Stagewise Decision-Making Methodology]] (87.3% similar)
- [[2025-09-24/FedFiTS_ Fitness-Selected, Slotted Client Scheduling for Trustworthy Federated Learning in Healthcare AI_20250924|FedFiTS: Fitness-Selected, Slotted Client Scheduling for Trustworthy Federated Learning in Healthcare AI]] (86.9% similar)
- [[2025-09-19/Who to Trust? Aggregating Client Knowledge in Logit-Based Federated Learning_20250919|Who to Trust? Aggregating Client Knowledge in Logit-Based Federated Learning]] (84.5% similar)
- [[2025-09-23/Asynchronous Federated Learning_ A Scalable Approach for Decentralized Machine Learning_20250923|Asynchronous Federated Learning: A Scalable Approach for Decentralized Machine Learning]] (84.4% similar)
- [[2025-09-23/FedEL_ Federated Elastic Learning for Heterogeneous Devices_20250923|FedEL: Federated Elastic Learning for Heterogeneous Devices]] (84.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Federated Learning|Federated Learning]], [[keywords/Transformer|Transformer]]
**ğŸ”— Specific Connectable**: [[keywords/Gradient Compression|Gradient Compression]]
**âš¡ Unique Technical**: [[keywords/Intelligent Selection of Participants|Intelligent Selection of Participants]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2508.13803v2 Announce Type: replace 
Abstract: Rapid scaling of deep learning models has enabled performance gains across domains, yet it introduced several challenges. Federated Learning (FL) has emerged as a promising framework to address these concerns by enabling decentralized training. Nevertheless, communication efficiency remains a key bottleneck in FL, particularly under heterogeneous and dynamic client participation. Existing methods, such as FedAvg and FedProx, or other approaches, including client selection strategies, attempt to mitigate communication costs. However, the problem of choosing the number of clients in a training round remains extremely underexplored. We introduce Intelligent Selection of Participants (ISP), an adaptive mechanism that dynamically determines the optimal number of clients per round to enhance communication efficiency without compromising model accuracy. We validate the effectiveness of ISP across diverse setups, including vision transformers, real-world ECG classification, and training with gradient compression. Our results show consistent communication savings of up to 30\% without losing the final quality. Applying ISP to different real-world ECG classification setups highlighted the selection of the number of clients as a separate task of federated learning.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì—°í•© í•™ìŠµ(FL)ì—ì„œì˜ í†µì‹  íš¨ìœ¨ì„±ì„ ê°œì„ í•˜ê¸° ìœ„í•´ ì œì•ˆëœ ìƒˆë¡œìš´ ë©”ì»¤ë‹ˆì¦˜ì¸ ISP(Intelligent Selection of Participants)ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë°©ë²•ë“¤ì´ í†µì‹  ë¹„ìš©ì„ ì¤„ì´ë ¤ í–ˆì§€ë§Œ, ê° í•™ìŠµ ë¼ìš´ë“œì—ì„œ ì°¸ì—¬í•  í´ë¼ì´ì–¸íŠ¸ ìˆ˜ë¥¼ ê²°ì •í•˜ëŠ” ë¬¸ì œëŠ” ì¶©ë¶„íˆ íƒêµ¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ISPëŠ” ë¼ìš´ë“œë³„ ìµœì ì˜ í´ë¼ì´ì–¸íŠ¸ ìˆ˜ë¥¼ ë™ì ìœ¼ë¡œ ê²°ì •í•˜ì—¬ í†µì‹  íš¨ìœ¨ì„±ì„ ë†’ì´ë©´ì„œë„ ëª¨ë¸ ì •í™•ë„ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤. ë‹¤ì–‘í•œ í™˜ê²½ì—ì„œ ISPì˜ íš¨ê³¼ë¥¼ ê²€ì¦í•œ ê²°ê³¼, ìµœëŒ€ 30%ì˜ í†µì‹  ì ˆê° íš¨ê³¼ë¥¼ ë³´ì˜€ìœ¼ë©°, íŠ¹íˆ ECG ë¶„ë¥˜ì™€ ê°™ì€ ì‹¤ì œ ì‘ìš©ì—ì„œ í´ë¼ì´ì–¸íŠ¸ ìˆ˜ ì„ íƒì´ ì¤‘ìš”í•œ ê³¼ì œë¡œ ë¶€ê°ë˜ì—ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì—°í•© í•™ìŠµ(Federated Learning, FL)ì€ ë¶„ì‚°í˜• í•™ìŠµì„ ê°€ëŠ¥í•˜ê²Œ í•˜ì—¬ ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ ì„±ëŠ¥ í–¥ìƒì„ ì§€ì›í•˜ì§€ë§Œ, í†µì‹  íš¨ìœ¨ì„±ì€ ì—¬ì „íˆ ì£¼ìš” ë³‘ëª© í˜„ìƒìœ¼ë¡œ ë‚¨ì•„ ìˆìŠµë‹ˆë‹¤.
- 2. ê¸°ì¡´ ë°©ë²•ë“¤ì€ í†µì‹  ë¹„ìš©ì„ ì¤„ì´ê¸° ìœ„í•´ ë…¸ë ¥í•˜ê³  ìˆì§€ë§Œ, í•™ìŠµ ë¼ìš´ë“œì—ì„œ í´ë¼ì´ì–¸íŠ¸ ìˆ˜ë¥¼ ì„ íƒí•˜ëŠ” ë¬¸ì œëŠ” ê±°ì˜ íƒêµ¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.
- 3. ISP(Intelligent Selection of Participants)ëŠ” ë¼ìš´ë“œë‹¹ ìµœì ì˜ í´ë¼ì´ì–¸íŠ¸ ìˆ˜ë¥¼ ë™ì ìœ¼ë¡œ ê²°ì •í•˜ì—¬ í†µì‹  íš¨ìœ¨ì„±ì„ í–¥ìƒì‹œí‚¤ëŠ” ì ì‘í˜• ë©”ì»¤ë‹ˆì¦˜ì…ë‹ˆë‹¤.
- 4. ISPëŠ” ë‹¤ì–‘í•œ ì„¤ì •ì—ì„œ ìµœëŒ€ 30%ì˜ í†µì‹  ë¹„ìš© ì ˆê°ì„ ì´ë£¨ë©´ì„œë„ ëª¨ë¸ì˜ ìµœì¢… í’ˆì§ˆì„ ìœ ì§€í•˜ëŠ” ë° ì„±ê³µí–ˆìŠµë‹ˆë‹¤.
- 5. ISPë¥¼ ECG ë¶„ë¥˜ì™€ ê°™ì€ ì‹¤ì œ ì‚¬ë¡€ì— ì ìš©í•œ ê²°ê³¼, í´ë¼ì´ì–¸íŠ¸ ìˆ˜ ì„ íƒì´ ì—°í•© í•™ìŠµì˜ ë³„ë„ ê³¼ì—…ì„ì„ ê°•ì¡°í–ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 15:27:31*