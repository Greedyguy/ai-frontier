<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T15:48:17.878771",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Vision-Language Model",
    "ColorBlindnessEval Benchmark",
    "Ishihara Test",
    "Model Hallucination"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Vision-Language Model": 0.92,
    "ColorBlindnessEval Benchmark": 0.78,
    "Ishihara Test": 0.8,
    "Model Hallucination": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Vision-Language Models",
        "canonical": "Vision-Language Model",
        "aliases": [
          "VLM",
          "Vision-Language"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-Language Models are central to the paper's focus and are a trending topic, facilitating connections to related multimodal research.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.8,
        "link_intent_score": 0.92
      },
      {
        "surface": "ColorBlindnessEval",
        "canonical": "ColorBlindnessEval Benchmark",
        "aliases": [
          "Color Blindness Evaluation"
        ],
        "category": "unique_technical",
        "rationale": "This benchmark is unique to the paper and crucial for evaluating VLMs in specific adversarial scenarios.",
        "novelty_score": 0.85,
        "connectivity_score": 0.6,
        "specificity_score": 0.9,
        "link_intent_score": 0.78
      },
      {
        "surface": "Ishihara color blindness test",
        "canonical": "Ishihara Test",
        "aliases": [
          "Ishihara Plates"
        ],
        "category": "specific_connectable",
        "rationale": "The Ishihara Test is a well-known method for detecting color blindness, relevant for linking to medical and vision research.",
        "novelty_score": 0.5,
        "connectivity_score": 0.75,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "hallucination issues",
        "canonical": "Model Hallucination",
        "aliases": [
          "hallucination",
          "model errors"
        ],
        "category": "specific_connectable",
        "rationale": "Model hallucination is a critical challenge in AI systems, relevant for discussions on model reliability and robustness.",
        "novelty_score": 0.6,
        "connectivity_score": 0.7,
        "specificity_score": 0.78,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "benchmark",
      "dataset",
      "participants"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Vision-Language Models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.8,
        "link_intent": 0.92
      }
    },
    {
      "candidate_surface": "ColorBlindnessEval",
      "resolved_canonical": "ColorBlindnessEval Benchmark",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.6,
        "specificity": 0.9,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Ishihara color blindness test",
      "resolved_canonical": "Ishihara Test",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.75,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "hallucination issues",
      "resolved_canonical": "Model Hallucination",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.7,
        "specificity": 0.78,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# ColorBlindnessEval: Can Vision-Language Models Pass Color Blindness Tests?

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19070.pdf)
**Category**: cs.CL
**Published**: 2025-09-24
**ArXiv ID**: [2509.19070](https://arxiv.org/abs/2509.19070)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Evaluating Fairness in Large Vision-Language Models Across Diverse Demographic Attributes and Prompts_20250923|Evaluating Fairness in Large Vision-Language Models Across Diverse Demographic Attributes and Prompts]] (83.3% similar)
- [[2025-09-23/Benchmarking and Mitigating MCQA Selection Bias of Large Vision-Language Models_20250923|Benchmarking and Mitigating MCQA Selection Bias of Large Vision-Language Models]] (83.2% similar)
- [[2025-09-22/Are Vision-Language Models Safe in the Wild? A Meme-Based Benchmark Study_20250922|Are Vision-Language Models Safe in the Wild? A Meme-Based Benchmark Study]] (82.7% similar)
- [[2025-09-19/QuizRank_ Picking Images by Quizzing VLMs_20250919|QuizRank: Picking Images by Quizzing VLMs]] (82.2% similar)
- [[2025-09-23/Seeing Culture_ A Benchmark for Visual Reasoning and Grounding_20250923|Seeing Culture: A Benchmark for Visual Reasoning and Grounding]] (82.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Ishihara Test|Ishihara Test]], [[keywords/Model Hallucination|Model Hallucination]]
**âš¡ Unique Technical**: [[keywords/ColorBlindnessEval Benchmark|ColorBlindnessEval Benchmark]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19070v1 Announce Type: cross 
Abstract: This paper presents ColorBlindnessEval, a novel benchmark designed to evaluate the robustness of Vision-Language Models (VLMs) in visually adversarial scenarios inspired by the Ishihara color blindness test. Our dataset comprises 500 Ishihara-like images featuring numbers from 0 to 99 with varying color combinations, challenging VLMs to accurately recognize numerical information embedded in complex visual patterns. We assess 9 VLMs using Yes/No and open-ended prompts and compare their performance with human participants. Our experiments reveal limitations in the models' ability to interpret numbers in adversarial contexts, highlighting prevalent hallucination issues. These findings underscore the need to improve the robustness of VLMs in complex visual environments. ColorBlindnessEval serves as a valuable tool for benchmarking and improving the reliability of VLMs in real-world applications where accuracy is critical.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì‹œê°-ì–¸ì–´ ëª¨ë¸(VLM)ì˜ ê°•ê±´ì„±ì„ í‰ê°€í•˜ê¸° ìœ„í•´ Ishihara ìƒ‰ë§¹ í…ŒìŠ¤íŠ¸ì—ì„œ ì˜ê°ì„ ë°›ì€ ColorBlindnessEvalì´ë¼ëŠ” ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ì´ ë°ì´í„°ì…‹ì€ 0ë¶€í„° 99ê¹Œì§€ì˜ ìˆ«ìë¥¼ ë‹¤ì–‘í•œ ìƒ‰ìƒ ì¡°í•©ìœ¼ë¡œ í¬í•¨í•œ 500ê°œì˜ Ishihara ìœ ì‚¬ ì´ë¯¸ì§€ë¥¼ í¬í•¨í•˜ë©°, ë³µì¡í•œ ì‹œê° íŒ¨í„´ ì†ì—ì„œ ìˆ«ìë¥¼ ì •í™•íˆ ì¸ì‹í•˜ë„ë¡ VLMì— ë„ì „í•©ë‹ˆë‹¤. 9ê°œì˜ VLMì„ Yes/No ë° ê°œë°©í˜• ì§ˆë¬¸ìœ¼ë¡œ í‰ê°€í•˜ê³ , ì¸ê°„ ì°¸ê°€ìì™€ì˜ ì„±ëŠ¥ì„ ë¹„êµí•œ ê²°ê³¼, VLMì´ ì ëŒ€ì  ìƒí™©ì—ì„œ ìˆ«ìë¥¼ í•´ì„í•˜ëŠ” ë° í•œê³„ê°€ ìˆìŒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ê²°ê³¼ëŠ” ë³µì¡í•œ ì‹œê° í™˜ê²½ì—ì„œ VLMì˜ ê°•ê±´ì„±ì„ í–¥ìƒì‹œí‚¬ í•„ìš”ì„±ì„ ê°•ì¡°í•˜ë©°, ColorBlindnessEvalì€ ì‹¤ì œ ì‘ìš©ì—ì„œ VLMì˜ ì‹ ë¢°ì„±ì„ ê°œì„ í•˜ëŠ” ë° ìœ ìš©í•œ ë„êµ¬ë¡œ ì‘ìš©í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ColorBlindnessEvalì€ VLMì˜ ì‹œê°ì  ì ëŒ€ì  ìƒí™©ì—ì„œì˜ ê°•ì¸í•¨ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ì…ë‹ˆë‹¤.
- 2. ë°ì´í„°ì…‹ì€ 0ì—ì„œ 99ê¹Œì§€ì˜ ìˆ«ìê°€ ë‹¤ì–‘í•œ ìƒ‰ìƒ ì¡°í•©ìœ¼ë¡œ í¬í•¨ëœ 500ê°œì˜ Ishihara ìœ ì‚¬ ì´ë¯¸ì§€ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.
- 3. ì‹¤í—˜ ê²°ê³¼, VLMì´ ì ëŒ€ì  ë§¥ë½ì—ì„œ ìˆ«ìë¥¼ í•´ì„í•˜ëŠ” ë° í•œê³„ê°€ ìˆìŒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.
- 4. ì—°êµ¬ëŠ” VLMì˜ ë³µì¡í•œ ì‹œê°ì  í™˜ê²½ì—ì„œì˜ ê°•ì¸í•¨ì„ ê°œì„ í•  í•„ìš”ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤.
- 5. ColorBlindnessEvalì€ VLMì˜ ì‹ ë¢°ì„±ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ì¤‘ìš”í•œ ë„êµ¬ë¡œ í™œìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 15:48:17*