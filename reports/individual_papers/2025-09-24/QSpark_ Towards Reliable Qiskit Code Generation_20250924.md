<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T14:37:13.405486",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Qiskit Code Generation",
    "Quantum Circuits",
    "Group Relative Policy Optimization",
    "Odds-Ratio Preference Optimization",
    "Qwen2.5-Coder-32B"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Qiskit Code Generation": 0.78,
    "Quantum Circuits": 0.72,
    "Group Relative Policy Optimization": 0.82,
    "Odds-Ratio Preference Optimization": 0.8,
    "Qwen2.5-Coder-32B": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Qiskit Code Generation",
        "canonical": "Qiskit Code Generation",
        "aliases": [
          "Qiskit Programming",
          "Quantum Circuit Code"
        ],
        "category": "unique_technical",
        "rationale": "This is a specific task within quantum programming that the paper aims to improve, offering unique insights.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Quantum Circuits",
        "canonical": "Quantum Circuits",
        "aliases": [
          "Quantum Circuitry"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's focus, linking quantum programming with error-resilience.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.72
      },
      {
        "surface": "Group Relative Policy Optimization",
        "canonical": "Group Relative Policy Optimization",
        "aliases": [
          "GRPO"
        ],
        "category": "unique_technical",
        "rationale": "A novel reinforcement learning method applied in the study, crucial for understanding the improvements made.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.9,
        "link_intent_score": 0.82
      },
      {
        "surface": "Odds-Ratio Preference Optimization",
        "canonical": "Odds-Ratio Preference Optimization",
        "aliases": [
          "ORPO"
        ],
        "category": "unique_technical",
        "rationale": "Another novel reinforcement learning method used, important for linking to AI optimization techniques.",
        "novelty_score": 0.78,
        "connectivity_score": 0.62,
        "specificity_score": 0.88,
        "link_intent_score": 0.8
      },
      {
        "surface": "Qwen2.5-Coder-32B",
        "canonical": "Qwen2.5-Coder-32B",
        "aliases": [
          "Qwen Model"
        ],
        "category": "unique_technical",
        "rationale": "A specific model fine-tuned in the study, providing a direct link to the paper's experimental setup.",
        "novelty_score": 0.7,
        "connectivity_score": 0.55,
        "specificity_score": 0.92,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "error-resilient",
      "flawed code",
      "benchmark",
      "tasks"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Qiskit Code Generation",
      "resolved_canonical": "Qiskit Code Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Quantum Circuits",
      "resolved_canonical": "Quantum Circuits",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "Group Relative Policy Optimization",
      "resolved_canonical": "Group Relative Policy Optimization",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.9,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Odds-Ratio Preference Optimization",
      "resolved_canonical": "Odds-Ratio Preference Optimization",
      "decision": "linked",
      "scores": {
        "novelty": 0.78,
        "connectivity": 0.62,
        "specificity": 0.88,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Qwen2.5-Coder-32B",
      "resolved_canonical": "Qwen2.5-Coder-32B",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.55,
        "specificity": 0.92,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# QSpark: Towards Reliable Qiskit Code Generation

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2507.12642.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2507.12642](https://arxiv.org/abs/2507.12642)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-24/NGRPO_ Negative-enhanced Group Relative Policy Optimization_20250924|NGRPO: Negative-enhanced Group Relative Policy Optimization]] (86.1% similar)
- [[2025-09-23/GRPO-LEAD_ A Difficulty-Aware Reinforcement Learning Approach for Concise Mathematical Reasoning in Language Models_20250923|GRPO-LEAD: A Difficulty-Aware Reinforcement Learning Approach for Concise Mathematical Reasoning in Language Models]] (82.2% similar)
- [[2025-09-17/Quantum Reinforcement Learning-Guided Diffusion Model for Image Synthesis via Hybrid Quantum-Classical Generative Model Architectures_20250917|Quantum Reinforcement Learning-Guided Diffusion Model for Image Synthesis via Hybrid Quantum-Classical Generative Model Architectures]] (81.7% similar)
- [[2025-09-19/Scalable Multi-Objective Robot Reinforcement Learning through Gradient Conflict Resolution_20250919|Scalable Multi-Objective Robot Reinforcement Learning through Gradient Conflict Resolution]] (81.4% similar)
- [[2025-09-23/GRPOformer_ Advancing Hyperparameter Optimization via Group Relative Policy Optimization_20250923|GRPOformer: Advancing Hyperparameter Optimization via Group Relative Policy Optimization]] (81.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Quantum Circuits|Quantum Circuits]]
**âš¡ Unique Technical**: [[keywords/Qiskit Code Generation|Qiskit Code Generation]], [[keywords/Group Relative Policy Optimization|Group Relative Policy Optimization]], [[keywords/Odds-Ratio Preference Optimization|Odds-Ratio Preference Optimization]], [[keywords/Qwen2.5-Coder-32B|Qwen2.5-Coder-32B]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2507.12642v2 Announce Type: replace-cross 
Abstract: Quantum circuits must be error-resilient, yet LLMs like Granite-20B-Code and StarCoder often output flawed Qiskit code. We fine-tuned the Qwen2.5-Coder-32B model with two RL methods, Group Relative Policy Optimization (GRPO) and Odds-Ratio Preference Optimization (ORPO), using a richly annotated synthetic dataset. On the Qiskit HumanEval benchmark, ORPO reaches 56.29% Pass@1 ($\approx+10$ pp over Granite-8B-QK) and GRPO hits 49%, both beating all general-purpose baselines; on the original HumanEval they score 65.90% and 63.00%. GRPO performs well on basic tasks (44/78) and excels on intermediate ones (41/68), but neither GRPO nor ORPO solves any of the five advanced tasks, highlighting clear gains yet room for progress in AI-assisted quantum programming.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì–‘ì íšŒë¡œì˜ ì˜¤ë¥˜ ë³µì›ë ¥ì„ ë†’ì´ê¸° ìœ„í•´ LLM(ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸)ì´ ìƒì„±í•˜ëŠ” Qiskit ì½”ë“œì˜ ê²°í•¨ì„ ê°œì„ í•˜ëŠ” ì—°êµ¬ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. ì—°êµ¬ì§„ì€ Qwen2.5-Coder-32B ëª¨ë¸ì„ GRPOì™€ ORPOë¼ëŠ” ë‘ ê°€ì§€ ê°•í™” í•™ìŠµ ë°©ë²•ìœ¼ë¡œ ë¯¸ì„¸ ì¡°ì •í–ˆìŠµë‹ˆë‹¤. Qiskit HumanEval ë²¤ì¹˜ë§ˆí¬ì—ì„œ ORPOëŠ” 56.29%ì˜ Pass@1 ì„±ëŠ¥ì„ ê¸°ë¡í•˜ë©° ê¸°ì¡´ ëª¨ë¸ë³´ë‹¤ ì•½ 10%í¬ì¸íŠ¸ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤. GRPOëŠ” 49%ë¥¼ ê¸°ë¡í•˜ë©° ë‘ ë°©ë²• ëª¨ë‘ ì¼ë°˜ì ì¸ ê¸°ì¤€ì„ ëŠ¥ê°€í–ˆìŠµë‹ˆë‹¤. GRPOëŠ” ê¸°ë³¸ ë° ì¤‘ê¸‰ ê³¼ì œì—ì„œ ìš°ìˆ˜í•œ ì„±ê³¼ë¥¼ ë³´ì˜€ìœ¼ë‚˜, ê³ ê¸‰ ê³¼ì œì—ì„œëŠ” ë‘ ë°©ë²• ëª¨ë‘ í•´ê²°í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” AI ê¸°ë°˜ ì–‘ì í”„ë¡œê·¸ë˜ë°ì˜ ë°œì „ ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Qwen2.5-Coder-32B ëª¨ë¸ì€ GRPOì™€ ORPOë¼ëŠ” ë‘ ê°€ì§€ ê°•í™” í•™ìŠµ ë°©ë²•ìœ¼ë¡œ ë¯¸ì„¸ ì¡°ì •ë˜ì—ˆìŠµë‹ˆë‹¤.
- 2. ORPOëŠ” Qiskit HumanEval ë²¤ì¹˜ë§ˆí¬ì—ì„œ 56.29%ì˜ Pass@1 ì„±ëŠ¥ì„ ê¸°ë¡í•˜ë©°, Granite-8B-QKë³´ë‹¤ ì•½ 10%í¬ì¸íŠ¸ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.
- 3. GRPOëŠ” ê¸°ë³¸ ì‘ì—…ì—ì„œ 44/78, ì¤‘ê°„ ì‘ì—…ì—ì„œ 41/68ì˜ ì„±ê³¼ë¥¼ ë³´ì´ë©° ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë°œíœ˜í–ˆìŠµë‹ˆë‹¤.
- 4. GRPOì™€ ORPO ëª¨ë‘ ê³ ê¸‰ ì‘ì—…ì—ì„œëŠ” ì„±ê³¼ë¥¼ ë‚´ì§€ ëª»í–ˆìœ¼ë©°, ì´ëŠ” AI ì§€ì› ì–‘ì í”„ë¡œê·¸ë˜ë°ì—ì„œì˜ ë°œì „ ê°€ëŠ¥ì„±ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.
- 5. ë‘ ë°©ë²• ëª¨ë‘ ì¼ë°˜ì ì¸ ê¸°ì¤€ì„ ì„ ëŠ¥ê°€í–ˆìœ¼ë©°, ì›ë˜ HumanEvalì—ì„œ ê°ê° 65.90%ì™€ 63.00%ì˜ ì„±ê³¼ë¥¼ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 14:37:13*