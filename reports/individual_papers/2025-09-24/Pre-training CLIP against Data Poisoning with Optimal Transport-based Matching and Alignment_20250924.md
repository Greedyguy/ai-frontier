<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T16:07:17.590153",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Vision-Language Model",
    "Optimal Transport",
    "Data Poisoning",
    "Zero-Shot Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Vision-Language Model": 0.85,
    "Optimal Transport": 0.78,
    "Data Poisoning": 0.8,
    "Zero-Shot Learning": 0.82
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "CLIP",
        "canonical": "Vision-Language Model",
        "aliases": [
          "Contrastive Language-Image Pre-training"
        ],
        "category": "evolved_concepts",
        "rationale": "CLIP is a foundational model in vision-language tasks, linking it enhances understanding of multimodal learning.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.8,
        "link_intent_score": 0.85
      },
      {
        "surface": "Optimal Transport",
        "canonical": "Optimal Transport",
        "aliases": [
          "OT"
        ],
        "category": "unique_technical",
        "rationale": "Optimal Transport is a specialized mathematical approach crucial for the proposed framework, enhancing technical depth.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Data Poisoning",
        "canonical": "Data Poisoning",
        "aliases": [
          "Poisoning Attacks"
        ],
        "category": "unique_technical",
        "rationale": "Data poisoning is a critical threat in machine learning, and understanding it is vital for security-focused research.",
        "novelty_score": 0.68,
        "connectivity_score": 0.72,
        "specificity_score": 0.78,
        "link_intent_score": 0.8
      },
      {
        "surface": "Zero-Shot Learning",
        "canonical": "Zero-Shot Learning",
        "aliases": [
          "ZSL"
        ],
        "category": "specific_connectable",
        "rationale": "Zero-shot learning is a key performance metric for CLIP, linking it supports exploration of model capabilities.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.75,
        "link_intent_score": 0.82
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "CLIP",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.8,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Optimal Transport",
      "resolved_canonical": "Optimal Transport",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Data Poisoning",
      "resolved_canonical": "Data Poisoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.72,
        "specificity": 0.78,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Zero-Shot Learning",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.75,
        "link_intent": 0.82
      }
    }
  ]
}
-->

# Pre-training CLIP against Data Poisoning with Optimal Transport-based Matching and Alignment

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18717.pdf)
**Category**: cs.CV
**Published**: 2025-09-24
**ArXiv ID**: [2509.18717](https://arxiv.org/abs/2509.18717)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Neural Antidote_ Class-Wise Prompt Tuning for Purifying Backdoors in CLIP_20250923|Neural Antidote: Class-Wise Prompt Tuning for Purifying Backdoors in CLIP]] (86.0% similar)
- [[2025-09-22/CLIPTTA_ Robust Contrastive Vision-Language Test-Time Adaptation_20250922|CLIPTTA: Robust Contrastive Vision-Language Test-Time Adaptation]] (85.0% similar)
- [[2025-09-23/CLIP-IN_ Enhancing Fine-Grained Visual Understanding in CLIP via Instruction Editing Data and Long Captions_20250923|CLIP-IN: Enhancing Fine-Grained Visual Understanding in CLIP via Instruction Editing Data and Long Captions]] (84.8% similar)
- [[2025-09-23/Test-Time Multimodal Backdoor Detection by Contrastive Prompting_20250923|Test-Time Multimodal Backdoor Detection by Contrastive Prompting]] (84.7% similar)
- [[2025-09-22/RegionMed-CLIP_ A Region-Aware Multimodal Contrastive Learning Pre-trained Model for Medical Image Understanding_20250922|RegionMed-CLIP: A Region-Aware Multimodal Contrastive Learning Pre-trained Model for Medical Image Understanding]] (83.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Zero-Shot Learning|Zero-Shot Learning]]
**âš¡ Unique Technical**: [[keywords/Optimal Transport|Optimal Transport]], [[keywords/Data Poisoning|Data Poisoning]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18717v1 Announce Type: new 
Abstract: Recent studies have shown that Contrastive Language-Image Pre-training (CLIP) models are threatened by targeted data poisoning and backdoor attacks due to massive training image-caption pairs crawled from the Internet. Previous defense methods correct poisoned image-caption pairs by matching a new caption for each image. However, the matching process relies solely on the global representations of images and captions, overlooking fine-grained features of visual and textual features. It may introduce incorrect image-caption pairs and harm the CLIP pre-training. To address their limitations, we propose an Optimal Transport-based framework to reconstruct image-caption pairs, named OTCCLIP. We propose a new optimal transport-based distance measure between fine-grained visual and textual feature sets and re-assign new captions based on the proposed optimal transport distance. Additionally, to further reduce the negative impact of mismatched pairs, we encourage the inter- and intra-modality fine-grained alignment by employing optimal transport-based objective functions. Our experiments demonstrate that OTCCLIP can successfully decrease the attack success rates of poisoning attacks. Also, compared to previous methods, OTCCLIP significantly improves CLIP's zero-shot and linear probing performance trained on poisoned datasets.

## ğŸ“ ìš”ì•½

ìµœê·¼ ì—°êµ¬ì— ë”°ë¥´ë©´, ëŒ€ê·œëª¨ ì´ë¯¸ì§€-ìº¡ì…˜ ìŒì„ í™œìš©í•˜ëŠ” CLIP ëª¨ë¸ì´ ë°ì´í„° ì¤‘ë… ë° ë°±ë„ì–´ ê³µê²©ì— ì·¨ì•½í•˜ë‹¤ëŠ” ë¬¸ì œê°€ ì œê¸°ë˜ì—ˆìŠµë‹ˆë‹¤. ê¸°ì¡´ ë°©ì–´ ë°©ë²•ì€ ì´ë¯¸ì§€ì— ìƒˆë¡œìš´ ìº¡ì…˜ì„ ë§¤ì¹­í•˜ì—¬ ì¤‘ë…ëœ ìŒì„ ìˆ˜ì •í•˜ì§€ë§Œ, ì´ëŠ” ì´ë¯¸ì§€ì™€ ìº¡ì…˜ì˜ ì „ì—­ í‘œí˜„ì—ë§Œ ì˜ì¡´í•˜ì—¬ ì„¸ë¶€ íŠ¹ì§•ì„ ê°„ê³¼í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” OTCCLIPì´ë¼ëŠ” ìµœì  ìˆ˜ì†¡ ê¸°ë°˜ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ì„¸ë¶€ì ì¸ ì‹œê° ë° í…ìŠ¤íŠ¸ íŠ¹ì§• ì„¸íŠ¸ ê°„ì˜ ìµœì  ìˆ˜ì†¡ ê±°ë¦¬ ì¸¡ì •ì„ í†µí•´ ìƒˆë¡œìš´ ìº¡ì…˜ì„ ì¬í• ë‹¹í•©ë‹ˆë‹¤. ë˜í•œ, ìµœì  ìˆ˜ì†¡ ê¸°ë°˜ ëª©í‘œ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë‹¬ë¦¬í‹° ê°„ ë° ë‚´ì—ì„œ ì„¸ë¶€ ì •ë ¬ì„ ì´‰ì§„í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, OTCCLIPì€ ì¤‘ë… ê³µê²©ì˜ ì„±ê³µë¥ ì„ ê°ì†Œì‹œí‚¤ê³ , ì´ì „ ë°©ë²•ì— ë¹„í•´ CLIPì˜ ì œë¡œìƒ· ë° ì„ í˜• íƒìƒ‰ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€ê·œëª¨ ì¸í„°ë„· ì´ë¯¸ì§€-ìº¡ì…˜ ìŒìœ¼ë¡œ ì¸í•´ CLIP ëª¨ë¸ì´ ë°ì´í„° ì¤‘ë… ë° ë°±ë„ì–´ ê³µê²©ì— ì·¨ì•½í•˜ë‹¤ëŠ” ìµœê·¼ ì—°êµ¬ ê²°ê³¼ê°€ ìˆìŠµë‹ˆë‹¤.
- 2. ê¸°ì¡´ ë°©ì–´ ë°©ë²•ì€ ì´ë¯¸ì§€ì— ìƒˆë¡œìš´ ìº¡ì…˜ì„ ë§¤ì¹­í•˜ì—¬ ì¤‘ë…ëœ ì´ë¯¸ì§€-ìº¡ì…˜ ìŒì„ ìˆ˜ì •í•˜ì§€ë§Œ, ì´ëŠ” ì´ë¯¸ì§€ì™€ ìº¡ì…˜ì˜ ì „ì—­ í‘œí˜„ì—ë§Œ ì˜ì¡´í•˜ì—¬ ì„¸ë°€í•œ íŠ¹ì§•ì„ ê°„ê³¼í•©ë‹ˆë‹¤.
- 3. OTCCLIPì€ ìµœì  ìˆ˜ì†¡ ê¸°ë°˜ì˜ ê±°ë¦¬ ì¸¡ì •ì„ í†µí•´ ì„¸ë°€í•œ ì‹œê° ë° í…ìŠ¤íŠ¸ íŠ¹ì§• ì„¸íŠ¸ ê°„ì˜ ìƒˆë¡œìš´ ìº¡ì…˜ì„ ì¬í• ë‹¹í•˜ëŠ” í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.
- 4. OTCCLIPì€ ìµœì  ìˆ˜ì†¡ ê¸°ë°˜ì˜ ëª©í‘œ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë‹¬ë¦¬í‹° ê°„ ë° ëª¨ë‹¬ë¦¬í‹° ë‚´ ì„¸ë°€í•œ ì •ë ¬ì„ ì´‰ì§„í•˜ì—¬ ì˜ëª» ë§¤ì¹­ëœ ìŒì˜ ë¶€ì •ì  ì˜í–¥ì„ ì¤„ì…ë‹ˆë‹¤.
- 5. ì‹¤í—˜ ê²°ê³¼, OTCCLIPì€ ì¤‘ë… ê³µê²©ì˜ ì„±ê³µë¥ ì„ ê°ì†Œì‹œí‚¤ê³ , ì´ì „ ë°©ë²•ì— ë¹„í•´ CLIPì˜ ì œë¡œìƒ· ë° ì„ í˜• íƒìƒ‰ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤.


---

*Generated on 2025-09-24 16:07:17*