<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T15:44:45.675552",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Named Entity Recognition",
    "Transformer",
    "KyrgyzNER Dataset",
    "Multilingual Models"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Named Entity Recognition": 0.85,
    "Transformer": 0.9,
    "KyrgyzNER Dataset": 0.78,
    "Multilingual Models": 0.82
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Named Entity Recognition",
        "canonical": "Named Entity Recognition",
        "aliases": [
          "NER"
        ],
        "category": "broad_technical",
        "rationale": "A fundamental task in Natural Language Processing, crucial for linking language-specific datasets.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "multilingual RoBERTa",
        "canonical": "Transformer",
        "aliases": [
          "mRoBERTa"
        ],
        "category": "broad_technical",
        "rationale": "A specific application of Transformer models, relevant for multilingual NLP tasks.",
        "novelty_score": 0.58,
        "connectivity_score": 0.92,
        "specificity_score": 0.8,
        "link_intent_score": 0.9
      },
      {
        "surface": "KyrgyzNER",
        "canonical": "KyrgyzNER Dataset",
        "aliases": [
          "Kyrgyz NER"
        ],
        "category": "unique_technical",
        "rationale": "A unique dataset for Kyrgyz language, essential for linking language-specific resources.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "multilingual pretrained models",
        "canonical": "Multilingual Models",
        "aliases": [
          "multilingual NLP models"
        ],
        "category": "specific_connectable",
        "rationale": "Highlights the use of models trained on multiple languages, important for cross-lingual NLP research.",
        "novelty_score": 0.5,
        "connectivity_score": 0.87,
        "specificity_score": 0.75,
        "link_intent_score": 0.82
      }
    ],
    "ban_list_suggestions": [
      "dataset",
      "model",
      "language"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Named Entity Recognition",
      "resolved_canonical": "Named Entity Recognition",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "multilingual RoBERTa",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.92,
        "specificity": 0.8,
        "link_intent": 0.9
      }
    },
    {
      "candidate_surface": "KyrgyzNER",
      "resolved_canonical": "KyrgyzNER Dataset",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "multilingual pretrained models",
      "resolved_canonical": "Multilingual Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.87,
        "specificity": 0.75,
        "link_intent": 0.82
      }
    }
  ]
}
-->

# Human-Annotated NER Dataset for the Kyrgyz Language

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19109.pdf)
**Category**: cs.CL
**Published**: 2025-09-24
**ArXiv ID**: [2509.19109](https://arxiv.org/abs/2509.19109)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/DynamicNER_ A Dynamic, Multilingual, and Fine-Grained Dataset for LLM-based Named Entity Recognition_20250922|DynamicNER: A Dynamic, Multilingual, and Fine-Grained Dataset for LLM-based Named Entity Recognition]] (81.1% similar)
- [[2025-09-23/Turk-LettuceDetect_ A Hallucination Detection Models for Turkish RAG Applications_20250923|Turk-LettuceDetect: A Hallucination Detection Models for Turkish RAG Applications]] (79.7% similar)
- [[2025-09-23/KuBERT_ Central Kurdish BERT Model and Its Application for Sentiment Analysis_20250923|KuBERT: Central Kurdish BERT Model and Its Application for Sentiment Analysis]] (79.5% similar)
- [[2025-09-23/SciNLP_ A Domain-Specific Benchmark for Full-Text Scientific Entity and Relation Extraction in NLP_20250923|SciNLP: A Domain-Specific Benchmark for Full-Text Scientific Entity and Relation Extraction in NLP]] (79.0% similar)
- [[2025-09-22/Automatic Lexical Simplification for Turkish_20250922|Automatic Lexical Simplification for Turkish]] (78.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Named Entity Recognition|Named Entity Recognition]], [[keywords/Transformer|Transformer]]
**ğŸ”— Specific Connectable**: [[keywords/Multilingual Models|Multilingual Models]]
**âš¡ Unique Technical**: [[keywords/KyrgyzNER Dataset|KyrgyzNER Dataset]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19109v1 Announce Type: new 
Abstract: We introduce KyrgyzNER, the first manually annotated named entity recognition dataset for the Kyrgyz language. Comprising 1,499 news articles from the 24.KG news portal, the dataset contains 10,900 sentences and 39,075 entity mentions across 27 named entity classes. We show our annotation scheme, discuss the challenges encountered in the annotation process, and present the descriptive statistics. We also evaluate several named entity recognition models, including traditional sequence labeling approaches based on conditional random fields and state-of-the-art multilingual transformer-based models fine-tuned on our dataset. While all models show difficulties with rare entity categories, models such as the multilingual RoBERTa variant pretrained on a large corpus across many languages achieve a promising balance between precision and recall. These findings emphasize both the challenges and opportunities of using multilingual pretrained models for processing languages with limited resources. Although the multilingual RoBERTa model performed best, other multilingual models yielded comparable results. This suggests that future work exploring more granular annotation schemes may offer deeper insights for Kyrgyz language processing pipelines evaluation.

## ğŸ“ ìš”ì•½

KyrgyzNERì€ í‚¤ë¥´ê¸°ìŠ¤ì–´ë¥¼ ìœ„í•œ ìµœì´ˆì˜ ìˆ˜ì‘ì—… ëª…ëª… ê°œì²´ ì¸ì‹ ë°ì´í„°ì…‹ìœ¼ë¡œ, 24.KG ë‰´ìŠ¤ í¬í„¸ì˜ 1,499ê°œ ê¸°ì‚¬ì—ì„œ 10,900ê°œì˜ ë¬¸ì¥ê³¼ 39,075ê°œì˜ ê°œì²´ ì–¸ê¸‰ì„ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ì£¼ì„ ì²´ê³„ë¥¼ ì†Œê°œí•˜ê³ , ì£¼ì„ ê³¼ì •ì—ì„œì˜ ë„ì „ ê³¼ì œë¥¼ ë…¼ì˜í•˜ë©°, ê¸°ìˆ  í†µê³„ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ë˜í•œ, ì¡°ê±´ë¶€ ëœë¤ í•„ë“œ ê¸°ë°˜ì˜ ì „í†µì ì¸ ì‹œí€€ìŠ¤ ë¼ë²¨ë§ ì ‘ê·¼ë²•ê³¼ ìµœì²¨ë‹¨ ë‹¤êµ­ì–´ íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ ëª¨ë¸ì„ í‰ê°€í–ˆìŠµë‹ˆë‹¤. ë“œë¬¸ ê°œì²´ ë²”ì£¼ì—ì„œëŠ” ëª¨ë“  ëª¨ë¸ì´ ì–´ë ¤ì›€ì„ ê²ªì—ˆì§€ë§Œ, ë‹¤êµ­ì–´ RoBERTa ëª¨ë¸ì€ ì •ë°€ë„ì™€ ì¬í˜„ì„± ê°„ì˜ ê· í˜•ì„ ì˜ ìœ ì§€í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ìì›ì´ ì œí•œëœ ì–¸ì–´ ì²˜ë¦¬ì— ë‹¤êµ­ì–´ ì‚¬ì „ í•™ìŠµ ëª¨ë¸ì„ í™œìš©í•˜ëŠ” ê²ƒì˜ ê°€ëŠ¥ì„±ì„ ì‹œì‚¬í•©ë‹ˆë‹¤. ë‹¤êµ­ì–´ RoBERTa ëª¨ë¸ì´ ê°€ì¥ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë‚˜, ë‹¤ë¥¸ ë‹¤êµ­ì–´ ëª¨ë¸ë„ ìœ ì‚¬í•œ ê²°ê³¼ë¥¼ ë³´ì—¬, í–¥í›„ ì—°êµ¬ì—ì„œëŠ” ë” ì„¸ë¶„í™”ëœ ì£¼ì„ ì²´ê³„ë¥¼ íƒêµ¬í•˜ëŠ” ê²ƒì´ í‚¤ë¥´ê¸°ìŠ¤ì–´ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ í‰ê°€ì— ìœ ìš©í•  ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. KyrgyzNERì€ í‚¤ë¥´ê¸°ìŠ¤ì–´ì— ëŒ€í•œ ìµœì´ˆì˜ ìˆ˜ì‘ì—…ìœ¼ë¡œ ì£¼ì„ëœ ê°œì²´ëª… ì¸ì‹ ë°ì´í„°ì…‹ì…ë‹ˆë‹¤.
- 2. ë°ì´í„°ì…‹ì€ 24.KG ë‰´ìŠ¤ í¬í„¸ì˜ 1,499ê°œ ê¸°ì‚¬ì—ì„œ 10,900ê°œì˜ ë¬¸ì¥ê³¼ 39,075ê°œì˜ ê°œì²´ëª…ì„ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.
- 3. ë‹¤ì–‘í•œ ê°œì²´ëª… ì¸ì‹ ëª¨ë¸ì„ í‰ê°€í•œ ê²°ê³¼, ë‹¤êµ­ì–´ RoBERTa ë³€í˜• ëª¨ë¸ì´ ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì—ì„œ ê· í˜• ì¡íŒ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.
- 4. ë“œë¬¸ ê°œì²´ ì¹´í…Œê³ ë¦¬ì—ì„œëŠ” ëª¨ë“  ëª¨ë¸ì´ ì–´ë ¤ì›€ì„ ê²ªì—ˆìœ¼ë‚˜, ë‹¤êµ­ì–´ ì‚¬ì „í•™ìŠµ ëª¨ë¸ì´ ìœ ë§í•œ ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤.
- 5. í–¥í›„ ì—°êµ¬ì—ì„œëŠ” ë” ì„¸ë¶„í™”ëœ ì£¼ì„ ì²´ê³„ë¥¼ íƒêµ¬í•¨ìœ¼ë¡œì¨ í‚¤ë¥´ê¸°ìŠ¤ì–´ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ í‰ê°€ì— ëŒ€í•œ ê¹Šì€ í†µì°°ì„ ì œê³µí•  ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤.


---

*Generated on 2025-09-24 15:44:45*