<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T15:17:13.114727",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Vulnerability Discovery",
    "Code Metrics",
    "Causal Effect"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Vulnerability Discovery": 0.78,
    "Code Metrics": 0.77,
    "Causal Effect": 0.74
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large language models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Large Language Models"
        ],
        "category": "broad_technical",
        "rationale": "Connects to a wide range of discussions on AI and software engineering.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "vulnerability discovery",
        "canonical": "Vulnerability Discovery",
        "aliases": [
          "security vulnerability detection"
        ],
        "category": "unique_technical",
        "rationale": "Central to the paper's focus on improving security through code analysis.",
        "novelty_score": 0.72,
        "connectivity_score": 0.67,
        "specificity_score": 0.82,
        "link_intent_score": 0.78
      },
      {
        "surface": "code metrics",
        "canonical": "Code Metrics",
        "aliases": [
          "software metrics",
          "program metrics"
        ],
        "category": "unique_technical",
        "rationale": "Key to understanding the limitations and capabilities of LLMs in this context.",
        "novelty_score": 0.68,
        "connectivity_score": 0.75,
        "specificity_score": 0.79,
        "link_intent_score": 0.77
      },
      {
        "surface": "causal effect",
        "canonical": "Causal Effect",
        "aliases": [
          "causal relationship"
        ],
        "category": "specific_connectable",
        "rationale": "Highlights the relationship between code metrics and LLM predictions.",
        "novelty_score": 0.55,
        "connectivity_score": 0.72,
        "specificity_score": 0.7,
        "link_intent_score": 0.74
      }
    ],
    "ban_list_suggestions": [
      "software engineering",
      "progress",
      "research"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large language models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "vulnerability discovery",
      "resolved_canonical": "Vulnerability Discovery",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.67,
        "specificity": 0.82,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "code metrics",
      "resolved_canonical": "Code Metrics",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.75,
        "specificity": 0.79,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "causal effect",
      "resolved_canonical": "Causal Effect",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.72,
        "specificity": 0.7,
        "link_intent": 0.74
      }
    }
  ]
}
-->

# LLM-based Vulnerability Discovery through the Lens of Code Metrics

## 📋 메타데이터

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19117.pdf)
**Category**: cs.LG
**Published**: 2025-09-24
**ArXiv ID**: [2509.19117](https://arxiv.org/abs/2509.19117)

## 🔗 유사한 논문
- [[2025-09-23/LLaVul_ A Multimodal LLM for Interpretable Vulnerability Reasoning about Source Code_20250923|LLaVul: A Multimodal LLM for Interpretable Vulnerability Reasoning about Source Code]] (87.8% similar)
- [[2025-09-23/Large Language Models for Cyber Security_ A Systematic Literature Review_20250923|Large Language Models for Cyber Security: A Systematic Literature Review]] (87.5% similar)
- [[2025-09-23/Breaking the Reviewer_ Assessing the Vulnerability of Large Language Models in Automated Peer Review Under Textual Adversarial Attacks_20250923|Breaking the Reviewer: Assessing the Vulnerability of Large Language Models in Automated Peer Review Under Textual Adversarial Attacks]] (85.9% similar)
- [[2025-09-22/Predicting Language Models' Success at Zero-Shot Probabilistic Prediction_20250922|Predicting Language Models' Success at Zero-Shot Probabilistic Prediction]] (85.7% similar)
- [[2025-09-23/Adaptive Distraction_ Probing LLM Contextual Robustness with Automated Tree Search_20250923|Adaptive Distraction: Probing LLM Contextual Robustness with Automated Tree Search]] (85.5% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Causal Effect|Causal Effect]]
**⚡ Unique Technical**: [[keywords/Vulnerability Discovery|Vulnerability Discovery]], [[keywords/Code Metrics|Code Metrics]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.19117v1 Announce Type: cross 
Abstract: Large language models (LLMs) excel in many tasks of software engineering, yet progress in leveraging them for vulnerability discovery has stalled in recent years. To understand this phenomenon, we investigate LLMs through the lens of classic code metrics. Surprisingly, we find that a classifier trained solely on these metrics performs on par with state-of-the-art LLMs for vulnerability discovery. A root-cause analysis reveals a strong correlation and a causal effect between LLMs and code metrics: When the value of a metric is changed, LLM predictions tend to shift by a corresponding magnitude. This dependency suggests that LLMs operate at a similarly shallow level as code metrics, limiting their ability to grasp complex patterns and fully realize their potential in vulnerability discovery. Based on these findings, we derive recommendations on how research should more effectively address this challenge.

## 📝 요약

대형 언어 모델(LLM)은 소프트웨어 공학의 여러 과제에서 뛰어난 성과를 보이지만, 취약점 발견에서는 최근 발전이 정체되었습니다. 본 연구는 LLM을 고전적인 코드 메트릭 관점에서 분석하여, 메트릭만으로 훈련된 분류기가 최첨단 LLM과 유사한 성능을 보임을 발견했습니다. LLM과 코드 메트릭 간의 강한 상관관계와 인과 효과가 드러났으며, 이는 LLM이 복잡한 패턴을 이해하는 데 한계가 있음을 시사합니다. 이러한 결과를 바탕으로 연구가 이 문제를 효과적으로 해결할 수 있는 방안을 제안합니다.

## 🎯 주요 포인트

- 1. 대형 언어 모델(LLM)은 소프트웨어 공학의 여러 작업에서 뛰어난 성과를 보이지만, 취약점 발견 분야에서는 최근 몇 년간 발전이 정체되었다.
- 2. 코드 메트릭을 기반으로 한 분류기가 최첨단 LLM과 유사한 수준으로 취약점을 발견할 수 있음을 발견하였다.
- 3. LLM과 코드 메트릭 사이에는 강한 상관관계와 인과 관계가 있으며, 이는 LLM의 예측이 메트릭 값의 변화에 따라 변동함을 시사한다.
- 4. LLM이 코드 메트릭과 유사한 얕은 수준에서 작동하여 복잡한 패턴을 이해하는 데 한계가 있음을 보여준다.
- 5. 연구가 이 도전을 보다 효과적으로 해결하기 위한 권장 사항을 도출하였다.


---

*Generated on 2025-09-24 15:17:13*