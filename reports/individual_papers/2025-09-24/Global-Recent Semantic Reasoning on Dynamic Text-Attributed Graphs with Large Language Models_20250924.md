<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T15:42:07.436074",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Graph Neural Network",
    "Dynamic Text-Attribute Graph",
    "Dynamic Global-Recent Adaptive Semantic Processing",
    "Temporal Graph Neural Network"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Graph Neural Network": 0.88,
    "Dynamic Text-Attribute Graph": 0.8,
    "Dynamic Global-Recent Adaptive Semantic Processing": 0.82,
    "Temporal Graph Neural Network": 0.84
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are central to the proposed method and connect well with existing research in NLP and machine learning.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Graph Neural Networks",
        "canonical": "Graph Neural Network",
        "aliases": [
          "GNNs"
        ],
        "category": "specific_connectable",
        "rationale": "Graph Neural Networks are crucial for understanding the structural dynamics of DyTAGs and are highly connectable with existing graph-based research.",
        "novelty_score": 0.5,
        "connectivity_score": 0.9,
        "specificity_score": 0.8,
        "link_intent_score": 0.88
      },
      {
        "surface": "Dynamic Text-Attribute Graphs",
        "canonical": "Dynamic Text-Attribute Graph",
        "aliases": [
          "DyTAGs"
        ],
        "category": "unique_technical",
        "rationale": "This is a unique concept introduced in the paper, essential for understanding the specific challenges addressed by the proposed method.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Dynamic Global-Recent Adaptive Semantic Processing",
        "canonical": "Dynamic Global-Recent Adaptive Semantic Processing",
        "aliases": [
          "DyGRASP"
        ],
        "category": "unique_technical",
        "rationale": "DyGRASP is the core method proposed in the paper, representing a novel approach to semantic reasoning on DyTAGs.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.9,
        "link_intent_score": 0.82
      },
      {
        "surface": "Temporal Graph Neural Networks",
        "canonical": "Temporal Graph Neural Network",
        "aliases": [
          "Temporal GNNs"
        ],
        "category": "specific_connectable",
        "rationale": "Temporal GNNs are key to capturing the time-evolving nature of the graphs discussed, linking to temporal dynamics in graph research.",
        "novelty_score": 0.55,
        "connectivity_score": 0.85,
        "specificity_score": 0.78,
        "link_intent_score": 0.84
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance",
      "efficiency issues"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Graph Neural Networks",
      "resolved_canonical": "Graph Neural Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.9,
        "specificity": 0.8,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "Dynamic Text-Attribute Graphs",
      "resolved_canonical": "Dynamic Text-Attribute Graph",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Dynamic Global-Recent Adaptive Semantic Processing",
      "resolved_canonical": "Dynamic Global-Recent Adaptive Semantic Processing",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.9,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Temporal Graph Neural Networks",
      "resolved_canonical": "Temporal Graph Neural Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.85,
        "specificity": 0.78,
        "link_intent": 0.84
      }
    }
  ]
}
-->

# Global-Recent Semantic Reasoning on Dynamic Text-Attributed Graphs with Large Language Models

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18742.pdf)
**Category**: cs.CL
**Published**: 2025-09-24
**ArXiv ID**: [2509.18742](https://arxiv.org/abs/2509.18742)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/GRIL_ Knowledge Graph Retrieval-Integrated Learning with Large Language Models_20250923|GRIL: Knowledge Graph Retrieval-Integrated Learning with Large Language Models]] (83.4% similar)
- [[2025-09-22/Temporal Reasoning with Large Language Models Augmented by Evolving Knowledge Graphs_20250922|Temporal Reasoning with Large Language Models Augmented by Evolving Knowledge Graphs]] (83.0% similar)
- [[2025-09-24/HSGM_ Hierarchical Segment-Graph Memory for Scalable Long-Text Semantics_20250924|HSGM: Hierarchical Segment-Graph Memory for Scalable Long-Text Semantics]] (82.9% similar)
- [[2025-09-23/Full-History Graphs with Edge-Type Decoupled Networks for Temporal Reasoning_20250923|Full-History Graphs with Edge-Type Decoupled Networks for Temporal Reasoning]] (82.5% similar)
- [[2025-09-19/Causal-Counterfactual RAG_ The Integration of Causal-Counterfactual Reasoning into RAG_20250919|Causal-Counterfactual RAG: The Integration of Causal-Counterfactual Reasoning into RAG]] (81.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Graph Neural Network|Graph Neural Network]], [[keywords/Temporal Graph Neural Network|Temporal Graph Neural Network]]
**âš¡ Unique Technical**: [[keywords/Dynamic Text-Attribute Graph|Dynamic Text-Attribute Graph]], [[keywords/Dynamic Global-Recent Adaptive Semantic Processing|Dynamic Global-Recent Adaptive Semantic Processing]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18742v1 Announce Type: new 
Abstract: Dynamic Text-Attribute Graphs (DyTAGs), characterized by time-evolving graph interactions and associated text attributes, are prevalent in real-world applications. Existing methods, such as Graph Neural Networks (GNNs) and Large Language Models (LLMs), mostly focus on static TAGs. Extending these existing methods to DyTAGs is challenging as they largely neglect the recent-global temporal semantics: the recent semantic dependencies among interaction texts and the global semantic evolution of nodes over time. Furthermore, applying LLMs to the abundant and evolving text in DyTAGs faces efficiency issues. To tackle these challenges, we propose Dynamic Global-Recent Adaptive Semantic Processing (DyGRASP), a novel method that leverages LLMs and temporal GNNs to efficiently and effectively reason on DyTAGs. Specifically, we first design a node-centric implicit reasoning method together with a sliding window mechanism to efficiently capture recent temporal semantics. In addition, to capture global semantic dynamics of nodes, we leverage explicit reasoning with tailored prompts and an RNN-like chain structure to infer long-term semantics. Lastly, we intricately integrate the recent and global temporal semantics as well as the dynamic graph structural information using updating and merging layers. Extensive experiments on DyTAG benchmarks demonstrate DyGRASP's superiority, achieving up to 34% improvement in Hit@10 for destination node retrieval task. Besides, DyGRASP exhibits strong generalization across different temporal GNNs and LLMs.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì‹œê°„ì— ë”°ë¼ ë³€í™”í•˜ëŠ” í…ìŠ¤íŠ¸ ì†ì„± ê·¸ë˜í”„(DyTAGs)ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ë°©ë²•ë¡ ì¸ DyGRASPë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ê·¸ë˜í”„ ì‹ ê²½ë§(GNNs)ê³¼ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì€ ì£¼ë¡œ ì •ì  ê·¸ë˜í”„ì— ì´ˆì ì„ ë§ì¶”ê³  ìˆì–´ DyTAGsì˜ ìµœê·¼-ê¸€ë¡œë²Œ ì‹œê°„ì  ì˜ë¯¸ë¥¼ ì œëŒ€ë¡œ ë°˜ì˜í•˜ì§€ ëª»í•©ë‹ˆë‹¤. DyGRASPëŠ” LLMsì™€ ì‹œê°„ì  GNNsë¥¼ í™œìš©í•˜ì—¬ ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤. ë…¸ë“œ ì¤‘ì‹¬ì˜ ì•”ì‹œì  ì¶”ë¡  ë°©ë²•ê³¼ ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´ ìµœê·¼ ì‹œê°„ì  ì˜ë¯¸ë¥¼ í¬ì°©í•˜ê³ , ë§ì¶¤í˜• í”„ë¡¬í”„íŠ¸ì™€ RNN ìœ ì‚¬ êµ¬ì¡°ë¥¼ í†µí•´ ê¸€ë¡œë²Œ ì˜ë¯¸ ë³€í™”ë¥¼ ì¶”ë¡ í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, DyGRASPëŠ” ëª©ì ì§€ ë…¸ë“œ ê²€ìƒ‰ ê³¼ì œì—ì„œ ìµœëŒ€ 34%ì˜ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì˜€ìœ¼ë©°, ë‹¤ì–‘í•œ GNNsì™€ LLMsì—ì„œë„ ê°•ë ¥í•œ ì¼ë°˜í™” ëŠ¥ë ¥ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Dynamic Text-Attribute Graphs (DyTAGs)ëŠ” ì‹œê°„ì— ë”°ë¼ ë³€í™”í•˜ëŠ” ê·¸ë˜í”„ ìƒí˜¸ì‘ìš©ê³¼ ê´€ë ¨ëœ í…ìŠ¤íŠ¸ ì†ì„±ì„ íŠ¹ì§•ìœ¼ë¡œ í•˜ë©°, ê¸°ì¡´ ë°©ë²•ë“¤ì€ ì£¼ë¡œ ì •ì  TAGsì— ì´ˆì ì„ ë§ì¶”ê³  ìˆë‹¤.
- 2. DyTAGsì˜ ìµœê·¼-ê¸€ë¡œë²Œ ì‹œê°„ì  ì˜ë¯¸ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ Dynamic Global-Recent Adaptive Semantic Processing (DyGRASP)ë¼ëŠ” ìƒˆë¡œìš´ ë°©ë²•ì„ ì œì•ˆí•œë‹¤.
- 3. DyGRASPëŠ” LLMsì™€ ì‹œê°„ì  GNNsë¥¼ í™œìš©í•˜ì—¬ DyTAGsì—ì„œ íš¨ìœ¨ì ì´ê³  íš¨ê³¼ì ì¸ ì¶”ë¡ ì„ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤.
- 4. DyGRASPëŠ” ë…¸ë“œ ì¤‘ì‹¬ì˜ ì•”ì‹œì  ì¶”ë¡  ë°©ë²•ê³¼ ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ë©”ì»¤ë‹ˆì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ìµœê·¼ì˜ ì‹œê°„ì  ì˜ë¯¸ë¥¼ í¬ì°©í•œë‹¤.
- 5. DyGRASPëŠ” ë‹¤ì–‘í•œ DyTAG ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìµœëŒ€ 34%ì˜ Hit@10 ê°œì„ ì„ ë‹¬ì„±í•˜ë©°, ë‹¤ì–‘í•œ ì‹œê°„ì  GNNsì™€ LLMsì— ê±¸ì³ ê°•ë ¥í•œ ì¼ë°˜í™” ì„±ëŠ¥ì„ ë³´ì¸ë‹¤.


---

*Generated on 2025-09-24 15:42:07*