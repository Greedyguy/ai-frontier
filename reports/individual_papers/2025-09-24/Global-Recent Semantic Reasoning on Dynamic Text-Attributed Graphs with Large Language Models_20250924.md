<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T15:42:07.436074",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Graph Neural Network",
    "Dynamic Text-Attribute Graph",
    "Dynamic Global-Recent Adaptive Semantic Processing",
    "Temporal Graph Neural Network"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Graph Neural Network": 0.88,
    "Dynamic Text-Attribute Graph": 0.8,
    "Dynamic Global-Recent Adaptive Semantic Processing": 0.82,
    "Temporal Graph Neural Network": 0.84
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are central to the proposed method and connect well with existing research in NLP and machine learning.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Graph Neural Networks",
        "canonical": "Graph Neural Network",
        "aliases": [
          "GNNs"
        ],
        "category": "specific_connectable",
        "rationale": "Graph Neural Networks are crucial for understanding the structural dynamics of DyTAGs and are highly connectable with existing graph-based research.",
        "novelty_score": 0.5,
        "connectivity_score": 0.9,
        "specificity_score": 0.8,
        "link_intent_score": 0.88
      },
      {
        "surface": "Dynamic Text-Attribute Graphs",
        "canonical": "Dynamic Text-Attribute Graph",
        "aliases": [
          "DyTAGs"
        ],
        "category": "unique_technical",
        "rationale": "This is a unique concept introduced in the paper, essential for understanding the specific challenges addressed by the proposed method.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Dynamic Global-Recent Adaptive Semantic Processing",
        "canonical": "Dynamic Global-Recent Adaptive Semantic Processing",
        "aliases": [
          "DyGRASP"
        ],
        "category": "unique_technical",
        "rationale": "DyGRASP is the core method proposed in the paper, representing a novel approach to semantic reasoning on DyTAGs.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.9,
        "link_intent_score": 0.82
      },
      {
        "surface": "Temporal Graph Neural Networks",
        "canonical": "Temporal Graph Neural Network",
        "aliases": [
          "Temporal GNNs"
        ],
        "category": "specific_connectable",
        "rationale": "Temporal GNNs are key to capturing the time-evolving nature of the graphs discussed, linking to temporal dynamics in graph research.",
        "novelty_score": 0.55,
        "connectivity_score": 0.85,
        "specificity_score": 0.78,
        "link_intent_score": 0.84
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance",
      "efficiency issues"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Graph Neural Networks",
      "resolved_canonical": "Graph Neural Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.9,
        "specificity": 0.8,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "Dynamic Text-Attribute Graphs",
      "resolved_canonical": "Dynamic Text-Attribute Graph",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Dynamic Global-Recent Adaptive Semantic Processing",
      "resolved_canonical": "Dynamic Global-Recent Adaptive Semantic Processing",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.9,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Temporal Graph Neural Networks",
      "resolved_canonical": "Temporal Graph Neural Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.85,
        "specificity": 0.78,
        "link_intent": 0.84
      }
    }
  ]
}
-->

# Global-Recent Semantic Reasoning on Dynamic Text-Attributed Graphs with Large Language Models

## 📋 메타데이터

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18742.pdf)
**Category**: cs.CL
**Published**: 2025-09-24
**ArXiv ID**: [2509.18742](https://arxiv.org/abs/2509.18742)

## 🔗 유사한 논문
- [[2025-09-23/GRIL_ Knowledge Graph Retrieval-Integrated Learning with Large Language Models_20250923|GRIL: Knowledge Graph Retrieval-Integrated Learning with Large Language Models]] (83.4% similar)
- [[2025-09-22/Temporal Reasoning with Large Language Models Augmented by Evolving Knowledge Graphs_20250922|Temporal Reasoning with Large Language Models Augmented by Evolving Knowledge Graphs]] (83.0% similar)
- [[2025-09-24/HSGM_ Hierarchical Segment-Graph Memory for Scalable Long-Text Semantics_20250924|HSGM: Hierarchical Segment-Graph Memory for Scalable Long-Text Semantics]] (82.9% similar)
- [[2025-09-23/Full-History Graphs with Edge-Type Decoupled Networks for Temporal Reasoning_20250923|Full-History Graphs with Edge-Type Decoupled Networks for Temporal Reasoning]] (82.5% similar)
- [[2025-09-19/Causal-Counterfactual RAG_ The Integration of Causal-Counterfactual Reasoning into RAG_20250919|Causal-Counterfactual RAG: The Integration of Causal-Counterfactual Reasoning into RAG]] (81.5% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Graph Neural Network|Graph Neural Network]], [[keywords/Temporal Graph Neural Network|Temporal Graph Neural Network]]
**⚡ Unique Technical**: [[keywords/Dynamic Text-Attribute Graph|Dynamic Text-Attribute Graph]], [[keywords/Dynamic Global-Recent Adaptive Semantic Processing|Dynamic Global-Recent Adaptive Semantic Processing]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.18742v1 Announce Type: new 
Abstract: Dynamic Text-Attribute Graphs (DyTAGs), characterized by time-evolving graph interactions and associated text attributes, are prevalent in real-world applications. Existing methods, such as Graph Neural Networks (GNNs) and Large Language Models (LLMs), mostly focus on static TAGs. Extending these existing methods to DyTAGs is challenging as they largely neglect the recent-global temporal semantics: the recent semantic dependencies among interaction texts and the global semantic evolution of nodes over time. Furthermore, applying LLMs to the abundant and evolving text in DyTAGs faces efficiency issues. To tackle these challenges, we propose Dynamic Global-Recent Adaptive Semantic Processing (DyGRASP), a novel method that leverages LLMs and temporal GNNs to efficiently and effectively reason on DyTAGs. Specifically, we first design a node-centric implicit reasoning method together with a sliding window mechanism to efficiently capture recent temporal semantics. In addition, to capture global semantic dynamics of nodes, we leverage explicit reasoning with tailored prompts and an RNN-like chain structure to infer long-term semantics. Lastly, we intricately integrate the recent and global temporal semantics as well as the dynamic graph structural information using updating and merging layers. Extensive experiments on DyTAG benchmarks demonstrate DyGRASP's superiority, achieving up to 34% improvement in Hit@10 for destination node retrieval task. Besides, DyGRASP exhibits strong generalization across different temporal GNNs and LLMs.

## 📝 요약

이 논문은 시간에 따라 변화하는 텍스트 속성 그래프(DyTAGs)를 효율적으로 처리하기 위한 새로운 방법론인 DyGRASP를 제안합니다. 기존의 그래프 신경망(GNNs)과 대형 언어 모델(LLMs)은 주로 정적 그래프에 초점을 맞추고 있어 DyTAGs의 최근-글로벌 시간적 의미를 제대로 반영하지 못합니다. DyGRASP는 LLMs와 시간적 GNNs를 활용하여 이러한 문제를 해결합니다. 노드 중심의 암시적 추론 방법과 슬라이딩 윈도우 메커니즘을 통해 최근 시간적 의미를 포착하고, 맞춤형 프롬프트와 RNN 유사 구조를 통해 글로벌 의미 변화를 추론합니다. 실험 결과, DyGRASP는 목적지 노드 검색 과제에서 최대 34%의 성능 향상을 보였으며, 다양한 GNNs와 LLMs에서도 강력한 일반화 능력을 입증했습니다.

## 🎯 주요 포인트

- 1. Dynamic Text-Attribute Graphs (DyTAGs)는 시간에 따라 변화하는 그래프 상호작용과 관련된 텍스트 속성을 특징으로 하며, 기존 방법들은 주로 정적 TAGs에 초점을 맞추고 있다.
- 2. DyTAGs의 최근-글로벌 시간적 의미를 효과적으로 처리하기 위해 Dynamic Global-Recent Adaptive Semantic Processing (DyGRASP)라는 새로운 방법을 제안한다.
- 3. DyGRASP는 LLMs와 시간적 GNNs를 활용하여 DyTAGs에서 효율적이고 효과적인 추론을 가능하게 한다.
- 4. DyGRASP는 노드 중심의 암시적 추론 방법과 슬라이딩 윈도우 메커니즘을 사용하여 최근의 시간적 의미를 포착한다.
- 5. DyGRASP는 다양한 DyTAG 벤치마크에서 최대 34%의 Hit@10 개선을 달성하며, 다양한 시간적 GNNs와 LLMs에 걸쳐 강력한 일반화 성능을 보인다.


---

*Generated on 2025-09-24 15:42:07*