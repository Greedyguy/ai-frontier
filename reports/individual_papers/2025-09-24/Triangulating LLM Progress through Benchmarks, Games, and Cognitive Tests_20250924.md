<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T15:49:39.690822",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Interactive Games",
    "Cognitive Tests",
    "Causal and Logical Reasoning",
    "Core Executive Functions"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Interactive Games": 0.78,
    "Cognitive Tests": 0.77,
    "Causal and Logical Reasoning": 0.82,
    "Core Executive Functions": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's focus on evaluating language models.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "interactive games",
        "canonical": "Interactive Games",
        "aliases": [
          "Games",
          "Interactive Tests"
        ],
        "category": "unique_technical",
        "rationale": "Highlighted as superior to benchmarks for model discrimination.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "cognitive tests",
        "canonical": "Cognitive Tests",
        "aliases": [
          "Cognitive Assessments"
        ],
        "category": "unique_technical",
        "rationale": "Key to evaluating cognitive abilities of models.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.75,
        "link_intent_score": 0.77
      },
      {
        "surface": "causal and logical reasoning",
        "canonical": "Causal and Logical Reasoning",
        "aliases": [
          "Reasoning Skills"
        ],
        "category": "specific_connectable",
        "rationale": "Correlates with both static and interactive tests, crucial for model evaluation.",
        "novelty_score": 0.55,
        "connectivity_score": 0.8,
        "specificity_score": 0.85,
        "link_intent_score": 0.82
      },
      {
        "surface": "core executive functions",
        "canonical": "Core Executive Functions",
        "aliases": [
          "Executive Functions"
        ],
        "category": "unique_technical",
        "rationale": "Differentiates models in terms of social/emotional skills.",
        "novelty_score": 0.68,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "standard benchmarks",
      "model performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "interactive games",
      "resolved_canonical": "Interactive Games",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "cognitive tests",
      "resolved_canonical": "Cognitive Tests",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.75,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "causal and logical reasoning",
      "resolved_canonical": "Causal and Logical Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.8,
        "specificity": 0.85,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "core executive functions",
      "resolved_canonical": "Core Executive Functions",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Triangulating LLM Progress through Benchmarks, Games, and Cognitive Tests

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2502.14359.pdf)
**Category**: cs.CL
**Published**: 2025-09-24
**ArXiv ID**: [2502.14359](https://arxiv.org/abs/2502.14359)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/LLMsPark_ A Benchmark for Evaluating Large Language Models in Strategic Gaming Contexts_20250923|LLMsPark: A Benchmark for Evaluating Large Language Models in Strategic Gaming Contexts]] (89.2% similar)
- [[2025-09-23/InMind_ Evaluating LLMs in Capturing and Applying Individual Human Reasoning Styles_20250923|InMind: Evaluating LLMs in Capturing and Applying Individual Human Reasoning Styles]] (88.2% similar)
- [[2025-09-23/AIPsychoBench_ Understanding the Psychometric Differences between LLMs and Humans_20250923|AIPsychoBench: Understanding the Psychometric Differences between LLMs and Humans]] (88.0% similar)
- [[2025-09-19/Rationality Check! Benchmarking the Rationality of Large Language Models_20250919|Rationality Check! Benchmarking the Rationality of Large Language Models]] (86.9% similar)
- [[2025-09-22/DivLogicEval_ A Framework for Benchmarking Logical Reasoning Evaluation in Large Language Models_20250922|DivLogicEval: A Framework for Benchmarking Logical Reasoning Evaluation in Large Language Models]] (86.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Causal and Logical Reasoning|Causal and Logical Reasoning]]
**âš¡ Unique Technical**: [[keywords/Interactive Games|Interactive Games]], [[keywords/Cognitive Tests|Cognitive Tests]], [[keywords/Core Executive Functions|Core Executive Functions]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2502.14359v3 Announce Type: replace 
Abstract: We examine three evaluation paradigms: standard benchmarks (e.g., MMLU and BBH), interactive games (e.g., Signalling Games or Taboo), and cognitive tests (e.g., for working memory or theory of mind). First, we investigate which of the former two-benchmarks or games-is most effective at discriminating LLMs of varying quality. Then, inspired by human cognitive assessments, we compile a suite of targeted tests that measure cognitive abilities deemed essential for effective language use, and we investigate their correlation with model performance in benchmarks and games. Our analyses reveal that interactive games are superior to standard benchmarks in discriminating models. Causal and logical reasoning correlate with both static and interactive tests, while differences emerge regarding core executive functions and social/emotional skills, which correlate more with games. We advocate for the development of new interactive benchmarks and targeted cognitive tasks inspired by assessing human abilities but designed specifically for LLMs.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì„¸ ê°€ì§€ í‰ê°€ íŒ¨ëŸ¬ë‹¤ì„ì„ ì¡°ì‚¬í•©ë‹ˆë‹¤: í‘œì¤€ ë²¤ì¹˜ë§ˆí¬, ì¸í„°ë™í‹°ë¸Œ ê²Œì„, ì¸ì§€ í…ŒìŠ¤íŠ¸. ì—°êµ¬ëŠ” ë‹¤ì–‘í•œ í’ˆì§ˆì˜ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ êµ¬ë³„í•˜ëŠ” ë° ìˆì–´ ë²¤ì¹˜ë§ˆí¬ì™€ ê²Œì„ ì¤‘ ì–´ëŠ ê²ƒì´ ë” íš¨ê³¼ì ì¸ì§€ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤. ì¸ê°„ì˜ ì¸ì§€ í‰ê°€ì—ì„œ ì˜ê°ì„ ë°›ì•„, íš¨ê³¼ì ì¸ ì–¸ì–´ ì‚¬ìš©ì— í•„ìˆ˜ì ì¸ ì¸ì§€ ëŠ¥ë ¥ì„ ì¸¡ì •í•˜ëŠ” í…ŒìŠ¤íŠ¸ë¥¼ ê°œë°œí•˜ê³ , ì´ë“¤ì´ ë²¤ì¹˜ë§ˆí¬ ë° ê²Œì„ ì„±ëŠ¥ê³¼ì˜ ìƒê´€ê´€ê³„ë¥¼ ì¡°ì‚¬í•©ë‹ˆë‹¤. ë¶„ì„ ê²°ê³¼, ì¸í„°ë™í‹°ë¸Œ ê²Œì„ì´ í‘œì¤€ ë²¤ì¹˜ë§ˆí¬ë³´ë‹¤ ëª¨ë¸ì„ êµ¬ë³„í•˜ëŠ” ë° ë” ìš°ìˆ˜í•˜ë©°, ì¸ê³¼ ë° ë…¼ë¦¬ì  ì¶”ë¡ ì€ ë‘ í…ŒìŠ¤íŠ¸ ëª¨ë‘ì™€ ìƒê´€ê´€ê³„ê°€ ìˆì§€ë§Œ, í•µì‹¬ ì‹¤í–‰ ê¸°ëŠ¥ ë° ì‚¬íšŒ/ì •ì„œì  ê¸°ìˆ ì€ ê²Œì„ê³¼ ë” ê´€ë ¨ì´ ìˆìŒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ì €ìë“¤ì€ ì¸ê°„ ëŠ¥ë ¥ í‰ê°€ì—ì„œ ì˜ê°ì„ ë°›ì€ ìƒˆë¡œìš´ ì¸í„°ë™í‹°ë¸Œ ë²¤ì¹˜ë§ˆí¬ì™€ ì¸ì§€ ê³¼ì œ ê°œë°œì„ ì œì•ˆí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ìƒí˜¸ì‘ìš© ê²Œì„ì€ í‘œì¤€ ë²¤ì¹˜ë§ˆí¬ë³´ë‹¤ ë‹¤ì–‘í•œ í’ˆì§ˆì˜ LLMì„ êµ¬ë³„í•˜ëŠ” ë° ë” íš¨ê³¼ì ì´ë‹¤.
- 2. ì¸ê³¼ì  ë° ë…¼ë¦¬ì  ì¶”ë¡ ì€ ì •ì  ë° ìƒí˜¸ì‘ìš© í…ŒìŠ¤íŠ¸ ëª¨ë‘ì™€ ìƒê´€ê´€ê³„ê°€ ìˆë‹¤.
- 3. í•µì‹¬ ì‹¤í–‰ ê¸°ëŠ¥ê³¼ ì‚¬íšŒ/ì •ì„œì  ê¸°ìˆ ì€ ê²Œì„ê³¼ ë” ë†’ì€ ìƒê´€ê´€ê³„ë¥¼ ë³´ì¸ë‹¤.
- 4. ì¸ê°„ì˜ ì¸ì§€ í‰ê°€ì—ì„œ ì˜ê°ì„ ë°›ì€ ìƒˆë¡œìš´ ìƒí˜¸ì‘ìš© ë²¤ì¹˜ë§ˆí¬ì™€ LLMì— íŠ¹í™”ëœ ì¸ì§€ ê³¼ì œ ê°œë°œì´ í•„ìš”í•˜ë‹¤.


---

*Generated on 2025-09-24 15:49:39*