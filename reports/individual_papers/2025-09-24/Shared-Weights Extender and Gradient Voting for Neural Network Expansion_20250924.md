<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T14:56:28.554090",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Shared-Weights Extender",
    "Steepest Voting Distributor",
    "Neural Network Expansion",
    "Neuron Inactivity"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Shared-Weights Extender": 0.82,
    "Steepest Voting Distributor": 0.79,
    "Neural Network Expansion": 0.77,
    "Neuron Inactivity": 0.74
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Shared-Weights Extender",
        "canonical": "Shared-Weights Extender",
        "aliases": [
          "SWE"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel method for neural network expansion, enhancing connectivity by preventing neuron inactivity.",
        "novelty_score": 0.85,
        "connectivity_score": 0.78,
        "specificity_score": 0.88,
        "link_intent_score": 0.82
      },
      {
        "surface": "Steepest Voting Distributor",
        "canonical": "Steepest Voting Distributor",
        "aliases": [
          "SVoD"
        ],
        "category": "unique_technical",
        "rationale": "Presents a new gradient-based method for neuron allocation, crucial for linking expansion techniques.",
        "novelty_score": 0.87,
        "connectivity_score": 0.75,
        "specificity_score": 0.86,
        "link_intent_score": 0.79
      },
      {
        "surface": "Neural Network Expansion",
        "canonical": "Neural Network Expansion",
        "aliases": [
          "NN Expansion"
        ],
        "category": "specific_connectable",
        "rationale": "Central to the paper's theme, facilitating connections with existing neural network literature.",
        "novelty_score": 0.58,
        "connectivity_score": 0.83,
        "specificity_score": 0.72,
        "link_intent_score": 0.77
      },
      {
        "surface": "Neuron Inactivity",
        "canonical": "Neuron Inactivity",
        "aliases": [
          "Inactive Neurons"
        ],
        "category": "specific_connectable",
        "rationale": "Addresses a key challenge in neural network training, relevant for linking with optimization strategies.",
        "novelty_score": 0.64,
        "connectivity_score": 0.79,
        "specificity_score": 0.76,
        "link_intent_score": 0.74
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "capacity growth"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Shared-Weights Extender",
      "resolved_canonical": "Shared-Weights Extender",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.78,
        "specificity": 0.88,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Steepest Voting Distributor",
      "resolved_canonical": "Steepest Voting Distributor",
      "decision": "linked",
      "scores": {
        "novelty": 0.87,
        "connectivity": 0.75,
        "specificity": 0.86,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Neural Network Expansion",
      "resolved_canonical": "Neural Network Expansion",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.83,
        "specificity": 0.72,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Neuron Inactivity",
      "resolved_canonical": "Neuron Inactivity",
      "decision": "linked",
      "scores": {
        "novelty": 0.64,
        "connectivity": 0.79,
        "specificity": 0.76,
        "link_intent": 0.74
      }
    }
  ]
}
-->

# Shared-Weights Extender and Gradient Voting for Neural Network Expansion

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18842.pdf)
**Category**: cs.LG
**Published**: 2025-09-24
**ArXiv ID**: [2509.18842](https://arxiv.org/abs/2509.18842)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Bio-Inspired Adaptive Neurons for Dynamic Weighting in Artificial Neural Networks_20250923|Bio-Inspired Adaptive Neurons for Dynamic Weighting in Artificial Neural Networks]] (82.6% similar)
- [[2025-09-23/Dynamical Low-Rank Compression of Neural Networks with Robustness under Adversarial Attacks_20250923|Dynamical Low-Rank Compression of Neural Networks with Robustness under Adversarial Attacks]] (81.9% similar)
- [[2025-09-18/Lightweight and Accurate Multi-View Stereo with Confidence-Aware Diffusion Model_20250918|Lightweight and Accurate Multi-View Stereo with Confidence-Aware Diffusion Model]] (81.4% similar)
- [[2025-09-23/Word2VecGD_ Neural Graph Drawing with Cosine-Stress Optimization_20250923|Word2VecGD: Neural Graph Drawing with Cosine-Stress Optimization]] (81.3% similar)
- [[2025-09-23/Deep Hierarchical Learning with Nested Subspace Networks_20250923|Deep Hierarchical Learning with Nested Subspace Networks]] (81.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Neural Network Expansion|Neural Network Expansion]], [[keywords/Neuron Inactivity|Neuron Inactivity]]
**âš¡ Unique Technical**: [[keywords/Shared-Weights Extender|Shared-Weights Extender]], [[keywords/Steepest Voting Distributor|Steepest Voting Distributor]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18842v1 Announce Type: new 
Abstract: Expanding neural networks during training is a promising way to augment capacity without retraining larger models from scratch. However, newly added neurons often fail to adjust to a trained network and become inactive, providing no contribution to capacity growth. We propose the Shared-Weights Extender (SWE), a novel method explicitly designed to prevent inactivity of new neurons by coupling them with existing ones for smooth integration. In parallel, we introduce the Steepest Voting Distributor (SVoD), a gradient-based method for allocating neurons across layers during deep network expansion. Our extensive benchmarking on four datasets shows that our method can effectively suppress neuron inactivity and achieve better performance compared to other expanding methods and baselines.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ í›ˆë ¨ ì¤‘ ì‹ ê²½ë§ì„ í™•ì¥í•˜ì—¬ ìš©ëŸ‰ì„ ì¦ê°€ì‹œí‚¤ëŠ” ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ìƒˆë¡œìš´ ë‰´ëŸ°ì´ ë¹„í™œì„±í™”ë˜ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ê¸°ì¡´ ë‰´ëŸ°ê³¼ ê²°í•©í•˜ì—¬ ë¶€ë“œëŸ½ê²Œ í†µí•©í•  ìˆ˜ ìˆëŠ” Shared-Weights Extender(SWE) ë°©ë²•ì„ ê°œë°œí–ˆìŠµë‹ˆë‹¤. ë˜í•œ, Steepest Voting Distributor(SVoD)ë¼ëŠ” ê¸°ìš¸ê¸° ê¸°ë°˜ ë°©ë²•ì„ í†µí•´ ì‹¬ì¸µ ë„¤íŠ¸ì›Œí¬ í™•ì¥ ì‹œ ë‰´ëŸ°ì„ ì ì ˆíˆ ë°°ë¶„í•©ë‹ˆë‹¤. ë„¤ ê°€ì§€ ë°ì´í„°ì…‹ì— ëŒ€í•œ ê´‘ë²”ìœ„í•œ ë²¤ì¹˜ë§ˆí‚¹ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì´ ë‰´ëŸ° ë¹„í™œì„±í™”ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì–µì œí•˜ê³  ë‹¤ë¥¸ í™•ì¥ ë°©ë²• ë° ê¸°ì¤€ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. í›ˆë ¨ ì¤‘ ì‹ ê²½ë§ì„ í™•ì¥í•˜ëŠ” ê²ƒì€ ëª¨ë¸ì„ ì²˜ìŒë¶€í„° ë‹¤ì‹œ í›ˆë ¨í•˜ì§€ ì•Šê³  ìš©ëŸ‰ì„ ì¦ê°€ì‹œí‚¤ëŠ” ìœ ë§í•œ ë°©ë²•ì´ë‹¤.
- 2. ìƒˆë¡œ ì¶”ê°€ëœ ë‰´ëŸ°ì´ ë¹„í™œì„±í™”ë˜ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ê¸°ì¡´ ë‰´ëŸ°ê³¼ ê²°í•©í•˜ì—¬ ë§¤ë„ëŸ½ê²Œ í†µí•©í•˜ëŠ” Shared-Weights Extender (SWE) ë°©ë²•ì„ ì œì•ˆí•œë‹¤.
- 3. Steepest Voting Distributor (SVoD)ëŠ” ê¹Šì€ ë„¤íŠ¸ì›Œí¬ í™•ì¥ ì‹œ ë‰´ëŸ°ì„ ë ˆì´ì–´ì— í• ë‹¹í•˜ëŠ” ê¸°ìš¸ê¸° ê¸°ë°˜ ë°©ë²•ì´ë‹¤.
- 4. ë„¤ ê°€ì§€ ë°ì´í„°ì…‹ì— ëŒ€í•œ ê´‘ë²”ìœ„í•œ ë²¤ì¹˜ë§ˆí‚¹ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì´ ë‰´ëŸ° ë¹„í™œì„±í™”ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì–µì œí•˜ê³  ë‹¤ë¥¸ í™•ì¥ ë°©ë²• ë° ê¸°ì¤€ì„ ë³´ë‹¤ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë‹¬ì„±í•¨ì„ ë³´ì—¬ì¤€ë‹¤.


---

*Generated on 2025-09-24 14:56:28*