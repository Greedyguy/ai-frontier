<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T15:02:14.478577",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Text-to-Video Generation",
    "Energy Consumption in AI Models",
    "Scaling Laws in AI",
    "Temporal Coherence in Video Models"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Text-to-Video Generation": 0.82,
    "Energy Consumption in AI Models": 0.79,
    "Scaling Laws in AI": 0.77,
    "Temporal Coherence in Video Models": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "text-to-video generation",
        "canonical": "Text-to-Video Generation",
        "aliases": [
          "T2V generation",
          "text-to-video"
        ],
        "category": "unique_technical",
        "rationale": "This is a distinct and emerging field within generative AI, crucial for linking related research on video synthesis from text.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.85,
        "link_intent_score": 0.82
      },
      {
        "surface": "energy consumption",
        "canonical": "Energy Consumption in AI Models",
        "aliases": [
          "energy demands",
          "power usage"
        ],
        "category": "evolved_concepts",
        "rationale": "Understanding energy consumption is vital for sustainable AI development, linking to broader discussions on AI's environmental impact.",
        "novelty_score": 0.65,
        "connectivity_score": 0.72,
        "specificity_score": 0.78,
        "link_intent_score": 0.79
      },
      {
        "surface": "scaling laws",
        "canonical": "Scaling Laws in AI",
        "aliases": [
          "scaling principles",
          "scaling behaviors"
        ],
        "category": "specific_connectable",
        "rationale": "Scaling laws are fundamental for predicting model performance and resource requirements, connecting to optimization strategies in AI.",
        "novelty_score": 0.6,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.77
      },
      {
        "surface": "temporal coherence",
        "canonical": "Temporal Coherence in Video Models",
        "aliases": [
          "time consistency",
          "temporal consistency"
        ],
        "category": "specific_connectable",
        "rationale": "Temporal coherence is critical for the quality of generated videos, linking to research on video stability and realism.",
        "novelty_score": 0.68,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "compute-bound analytical model",
      "fine-grained experiments"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "text-to-video generation",
      "resolved_canonical": "Text-to-Video Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.85,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "energy consumption",
      "resolved_canonical": "Energy Consumption in AI Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.72,
        "specificity": 0.78,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "scaling laws",
      "resolved_canonical": "Scaling Laws in AI",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "temporal coherence",
      "resolved_canonical": "Temporal Coherence in Video Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# Video Killed the Energy Budget: Characterizing the Latency and Power Regimes of Open Text-to-Video Models

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19222.pdf)
**Category**: cs.LG
**Published**: 2025-09-24
**ArXiv ID**: [2509.19222](https://arxiv.org/abs/2509.19222)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/Identity-Preserving Text-to-Video Generation Guided by Simple yet Effective Spatial-Temporal Decoupled Representations_20250918|Identity-Preserving Text-to-Video Generation Guided by Simple yet Effective Spatial-Temporal Decoupled Representations]] (83.4% similar)
- [[2025-09-23/VidCLearn_ A Continual Learning Approach for Text-to-Video Generation_20250923|VidCLearn: A Continual Learning Approach for Text-to-Video Generation]] (83.0% similar)
- [[2025-09-24/Foresight_ Adaptive Layer Reuse for Accelerated and High-Quality Text-to-Video Generation_20250924|Foresight: Adaptive Layer Reuse for Accelerated and High-Quality Text-to-Video Generation]] (81.6% similar)
- [[2025-09-22/AcT2I_ Evaluating and Improving Action Depiction in Text-to-Image Models_20250922|AcT2I: Evaluating and Improving Action Depiction in Text-to-Image Models]] (81.5% similar)
- [[2025-09-22/BBScoreV2_ Learning Time-Evolution and Latent Alignment from Stochastic Representation_20250922|BBScoreV2: Learning Time-Evolution and Latent Alignment from Stochastic Representation]] (80.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Scaling Laws in AI|Scaling Laws in AI]], [[keywords/Temporal Coherence in Video Models|Temporal Coherence in Video Models]]
**âš¡ Unique Technical**: [[keywords/Text-to-Video Generation|Text-to-Video Generation]]
**ğŸš€ Evolved Concepts**: [[keywords/Energy Consumption in AI Models|Energy Consumption in AI Models]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19222v1 Announce Type: new 
Abstract: Recent advances in text-to-video (T2V) generation have enabled the creation of high-fidelity, temporally coherent clips from natural language prompts. Yet these systems come with significant computational costs, and their energy demands remain poorly understood. In this paper, we present a systematic study of the latency and energy consumption of state-of-the-art open-source T2V models. We first develop a compute-bound analytical model that predicts scaling laws with respect to spatial resolution, temporal length, and denoising steps. We then validate these predictions through fine-grained experiments on WAN2.1-T2V, showing quadratic growth with spatial and temporal dimensions, and linear scaling with the number of denoising steps. Finally, we extend our analysis to six diverse T2V models, comparing their runtime and energy profiles under default settings. Our results provide both a benchmark reference and practical insights for designing and deploying more sustainable generative video systems.

## ğŸ“ ìš”ì•½

ìµœê·¼ í…ìŠ¤íŠ¸-ë¹„ë””ì˜¤(T2V) ìƒì„± ê¸°ìˆ ì˜ ë°œì „ìœ¼ë¡œ ìì—°ì–´ í”„ë¡¬í”„íŠ¸ì—ì„œ ê³ í’ˆì§ˆì˜ ì‹œê°„ì ìœ¼ë¡œ ì¼ê´€ëœ ì˜ìƒì„ ìƒì„±í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ëŸ¬í•œ ì‹œìŠ¤í…œì€ ë†’ì€ ê³„ì‚° ë¹„ìš©ì´ ë“¤ë©°, ì—ë„ˆì§€ ì†Œëª¨ì— ëŒ€í•œ ì´í•´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ìµœì²¨ë‹¨ ì˜¤í”ˆì†ŒìŠ¤ T2V ëª¨ë¸ì˜ ì§€ì—° ì‹œê°„ê³¼ ì—ë„ˆì§€ ì†Œë¹„ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ì—°êµ¬í–ˆìŠµë‹ˆë‹¤. ê³µê°„ í•´ìƒë„, ì‹œê°„ ê¸¸ì´, ë…¸ì´ì¦ˆ ì œê±° ë‹¨ê³„ì— ë”°ë¥¸ ìŠ¤ì¼€ì¼ë§ ë²•ì¹™ì„ ì˜ˆì¸¡í•˜ëŠ” ê³„ì‚° ì¤‘ì‹¬ì˜ ë¶„ì„ ëª¨ë¸ì„ ê°œë°œí•˜ê³ , WAN2.1-T2V ëª¨ë¸ì„ í†µí•´ ì´ë¥¼ ê²€ì¦í–ˆìŠµë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ê³µê°„ ë° ì‹œê°„ ì°¨ì›ì— ë”°ë¼ ì´ì°¨ì ìœ¼ë¡œ ì¦ê°€í•˜ê³ , ë…¸ì´ì¦ˆ ì œê±° ë‹¨ê³„ ìˆ˜ì— ë”°ë¼ ì„ í˜•ì ìœ¼ë¡œ ì¦ê°€í•¨ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, ì—¬ì„¯ ê°€ì§€ ë‹¤ì–‘í•œ T2V ëª¨ë¸ì˜ ì‹¤í–‰ ì‹œê°„ê³¼ ì—ë„ˆì§€ í”„ë¡œí•„ì„ ë¹„êµ ë¶„ì„í•˜ì—¬, ì§€ì† ê°€ëŠ¥í•œ ìƒì„± ë¹„ë””ì˜¤ ì‹œìŠ¤í…œ ì„¤ê³„ë¥¼ ìœ„í•œ ë²¤ì¹˜ë§ˆí¬ì™€ ì‹¤ìš©ì  ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ìµœì‹  í…ìŠ¤íŠ¸-ë¹„ë””ì˜¤ ìƒì„± ê¸°ìˆ ì€ ìì—°ì–´ í”„ë¡¬í”„íŠ¸ë¡œë¶€í„° ê³ í’ˆì§ˆì˜ ì‹œê°„ì ìœ¼ë¡œ ì¼ê´€ëœ í´ë¦½ì„ ìƒì„±í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆë‹¤.
- 2. ë³¸ ì—°êµ¬ëŠ” ìµœì²¨ë‹¨ ì˜¤í”ˆì†ŒìŠ¤ í…ìŠ¤íŠ¸-ë¹„ë””ì˜¤ ëª¨ë¸ì˜ ì§€ì—° ì‹œê°„ê³¼ ì—ë„ˆì§€ ì†Œë¹„ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ì˜€ë‹¤.
- 3. ê³µê°„ í•´ìƒë„, ì‹œê°„ì  ê¸¸ì´, ë…¸ì´ì¦ˆ ì œê±° ë‹¨ê³„ì— ë”°ë¥¸ ìŠ¤ì¼€ì¼ë§ ë²•ì¹™ì„ ì˜ˆì¸¡í•˜ëŠ” ê³„ì‚° ì¤‘ì‹¬ì˜ ë¶„ì„ ëª¨ë¸ì„ ê°œë°œí•˜ì˜€ë‹¤.
- 4. WAN2.1-T2V ëª¨ë¸ì„ í†µí•´ ê³µê°„ ë° ì‹œê°„ì  ì°¨ì›ì— ëŒ€í•œ ì´ì°¨ ì„±ì¥ê³¼ ë…¸ì´ì¦ˆ ì œê±° ë‹¨ê³„ ìˆ˜ì— ëŒ€í•œ ì„ í˜• ìŠ¤ì¼€ì¼ë§ì„ ì‹¤í—˜ì ìœ¼ë¡œ ê²€ì¦í•˜ì˜€ë‹¤.
- 5. ì—¬ì„¯ ê°€ì§€ ë‹¤ì–‘í•œ í…ìŠ¤íŠ¸-ë¹„ë””ì˜¤ ëª¨ë¸ì˜ ì‹¤í–‰ ì‹œê°„ê³¼ ì—ë„ˆì§€ í”„ë¡œí•„ì„ ë¹„êµí•˜ì—¬ ì§€ì† ê°€ëŠ¥í•œ ìƒì„± ë¹„ë””ì˜¤ ì‹œìŠ¤í…œ ì„¤ê³„ì— ì‹¤ìš©ì ì¸ í†µì°°ë ¥ì„ ì œê³µí•˜ì˜€ë‹¤.


---

*Generated on 2025-09-24 15:02:14*