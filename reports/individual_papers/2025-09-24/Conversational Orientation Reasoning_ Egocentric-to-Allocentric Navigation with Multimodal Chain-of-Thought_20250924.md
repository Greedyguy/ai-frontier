<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T13:42:54.906958",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multimodal Chain-of-Thought",
    "Conversational Orientation Reasoning",
    "Egocentric-to-Allocentric Navigation",
    "Multimodal Learning",
    "Chain-of-Thought"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multimodal Chain-of-Thought": 0.92,
    "Conversational Orientation Reasoning": 0.88,
    "Egocentric-to-Allocentric Navigation": 0.86,
    "Multimodal Learning": 0.8,
    "Chain-of-Thought": 0.82
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multimodal chain-of-thought",
        "canonical": "Multimodal Chain-of-Thought",
        "aliases": [
          "MCoT"
        ],
        "category": "unique_technical",
        "rationale": "This concept is central to the paper's methodology, combining multimodal inputs with chain-of-thought reasoning, and is not widely covered in existing vocabularies.",
        "novelty_score": 0.85,
        "connectivity_score": 0.72,
        "specificity_score": 0.88,
        "link_intent_score": 0.92
      },
      {
        "surface": "Conversational Orientation Reasoning",
        "canonical": "Conversational Orientation Reasoning",
        "aliases": [
          "COR"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a new benchmark for spatial reasoning in conversational agents, which is a novel contribution of the paper.",
        "novelty_score": 0.9,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.88
      },
      {
        "surface": "Egocentric-to-Allocentric Navigation",
        "canonical": "Egocentric-to-Allocentric Navigation",
        "aliases": [
          "Egocentric Navigation",
          "Allocentric Navigation"
        ],
        "category": "unique_technical",
        "rationale": "Describes a specific navigation challenge addressed by the paper, linking spatial reasoning with conversational AI.",
        "novelty_score": 0.78,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.86
      },
      {
        "surface": "Multimodal",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal"
        ],
        "category": "specific_connectable",
        "rationale": "The paper's approach integrates multiple data modalities, which is a key aspect of the methodology.",
        "novelty_score": 0.4,
        "connectivity_score": 0.85,
        "specificity_score": 0.6,
        "link_intent_score": 0.8
      },
      {
        "surface": "Chain-of-Thought",
        "canonical": "Chain-of-Thought",
        "aliases": [
          "CoT"
        ],
        "category": "specific_connectable",
        "rationale": "Chain-of-thought reasoning is a significant concept in the paper, linking language and spatial reasoning.",
        "novelty_score": 0.5,
        "connectivity_score": 0.78,
        "specificity_score": 0.7,
        "link_intent_score": 0.82
      }
    ],
    "ban_list_suggestions": [
      "Traditional Chinese",
      "ASR-transcribed",
      "Taiwan-LLM-13B-v2.0-Chat"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multimodal chain-of-thought",
      "resolved_canonical": "Multimodal Chain-of-Thought",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.72,
        "specificity": 0.88,
        "link_intent": 0.92
      }
    },
    {
      "candidate_surface": "Conversational Orientation Reasoning",
      "resolved_canonical": "Conversational Orientation Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.9,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "Egocentric-to-Allocentric Navigation",
      "resolved_canonical": "Egocentric-to-Allocentric Navigation",
      "decision": "linked",
      "scores": {
        "novelty": 0.78,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.86
      }
    },
    {
      "candidate_surface": "Multimodal",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.85,
        "specificity": 0.6,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Chain-of-Thought",
      "resolved_canonical": "Chain-of-Thought",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.78,
        "specificity": 0.7,
        "link_intent": 0.82
      }
    }
  ]
}
-->

# Conversational Orientation Reasoning: Egocentric-to-Allocentric Navigation with Multimodal Chain-of-Thought

## 📋 메타데이터

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18200.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2509.18200](https://arxiv.org/abs/2509.18200)

## 🔗 유사한 논문
- [[2025-09-23/Audio-Reasoner_ Improving Reasoning Capability in Large Audio Language Models_20250923|Audio-Reasoner: Improving Reasoning Capability in Large Audio Language Models]] (83.1% similar)
- [[2025-09-22/Cache-of-Thought_ Master-Apprentice Framework for Cost-Effective Vision Language Model Reasoning_20250922|Cache-of-Thought: Master-Apprentice Framework for Cost-Effective Vision Language Model Reasoning]] (82.8% similar)
- [[2025-09-19/ASCoT_ An Adaptive Self-Correction Chain-of-Thought Method for Late-Stage Fragility in LLMs_20250919|ASCoT: An Adaptive Self-Correction Chain-of-Thought Method for Late-Stage Fragility in LLMs]] (82.8% similar)
- [[2025-09-23/WISE_ Weak-Supervision-Guided Step-by-Step Explanations for Multimodal LLMs in Image Classification_20250923|WISE: Weak-Supervision-Guided Step-by-Step Explanations for Multimodal LLMs in Image Classification]] (82.7% similar)
- [[2025-09-23/AuditoryBench++_ Can Language Models Understand Auditory Knowledge without Hearing?_20250923|AuditoryBench++: Can Language Models Understand Auditory Knowledge without Hearing?]] (82.6% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]], [[keywords/Chain-of-Thought|Chain-of-Thought]]
**⚡ Unique Technical**: [[keywords/Multimodal Chain-of-Thought|Multimodal Chain-of-Thought]], [[keywords/Conversational Orientation Reasoning|Conversational Orientation Reasoning]], [[keywords/Egocentric-to-Allocentric Navigation|Egocentric-to-Allocentric Navigation]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.18200v1 Announce Type: cross 
Abstract: Conversational agents must translate egocentric utterances (e.g., "on my right") into allocentric orientations (N/E/S/W). This challenge is particularly critical in indoor or complex facilities where GPS signals are weak and detailed maps are unavailable. While chain-of-thought (CoT) prompting has advanced reasoning in language and vision tasks, its application to multimodal spatial orientation remains underexplored. We introduce Conversational Orientation Reasoning (COR), a new benchmark designed for Traditional Chinese conversational navigation projected from real-world environments, addressing egocentric-to-allocentric reasoning in non-English and ASR-transcribed scenarios. We propose a multimodal chain-of-thought (MCoT) framework, which integrates ASR-transcribed speech with landmark coordinates through a structured three-step reasoning process: (1) extracting spatial relations, (2) mapping coordinates to absolute directions, and (3) inferring user orientation. A curriculum learning strategy progressively builds these capabilities on Taiwan-LLM-13B-v2.0-Chat, a mid-sized model representative of resource-constrained settings. Experiments show that MCoT achieves 100% orientation accuracy on clean transcripts and 98.1% with ASR transcripts, substantially outperforming unimodal and non-structured baselines. Moreover, MCoT demonstrates robustness under noisy conversational conditions, including ASR recognition errors and multilingual code-switching. The model also maintains high accuracy in cross-domain evaluation and resilience to linguistic variation, domain shift, and referential ambiguity. These findings highlight the potential of structured MCoT spatial reasoning as a path toward interpretable and resource-efficient embodied navigation.

## 📝 요약

이 논문은 실내 환경에서 자아 중심적 발화를 절대적 방향으로 변환하는 대화형 에이전트의 과제를 다룹니다. 이를 위해 새로운 벤치마크인 Conversational Orientation Reasoning (COR)을 소개하며, 이는 비영어권 및 ASR 전사 시나리오에서 자아 중심-절대적 방향 추론을 평가합니다. 제안된 다중 모달 체인 오브 사고(MCoT) 프레임워크는 ASR 전사 음성과 랜드마크 좌표를 통합하여 세 단계로 추론합니다: 공간 관계 추출, 좌표를 절대 방향으로 매핑, 사용자 방향 추론. 이 모델은 Taiwan-LLM-13B-v2.0-Chat을 기반으로 커리큘럼 학습 전략을 통해 개발되었으며, 실험 결과 MCoT는 깨끗한 전사에서 100%, ASR 전사에서 98.1%의 정확도를 달성했습니다. 또한, MCoT는 잡음이 있는 대화 조건에서도 강력한 성능을 보이며, 언어적 변이, 도메인 변화, 참조 모호성에 대한 높은 정확성을 유지합니다. 이러한 결과는 MCoT의 구조화된 공간 추론이 해석 가능하고 자원 효율적인 내비게이션의 가능성을 제시함을 보여줍니다.

## 🎯 주요 포인트

- 1. 대화형 에이전트는 자아 중심 발화를 객관적 방향으로 변환해야 하며, 이는 GPS 신호가 약한 실내 환경에서 특히 중요합니다.
- 2. 새로운 벤치마크인 Conversational Orientation Reasoning (COR)은 비영어권 및 ASR 전사 시나리오에서 자아 중심에서 객관적 방향으로의 추론을 다룹니다.
- 3. MCoT 프레임워크는 ASR 전사된 음성과 랜드마크 좌표를 통합하여 구조화된 3단계 추론 과정을 통해 사용자 방향을 추론합니다.
- 4. MCoT는 깨끗한 전사에서 100%, ASR 전사에서 98.1%의 방향 정확도를 달성하며, 단일 모달 및 비구조적 기준을 능가합니다.
- 5. MCoT는 소음이 있는 대화 조건에서도 강력하며, 다국어 코드 전환 및 언어적 변이에 대한 높은 정확도를 유지합니다.


---

*Generated on 2025-09-24 13:42:54*