<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T13:27:16.867997",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Retrieval Augmented Generation",
    "Large Language Model",
    "Personalized PageRank",
    "Token-Efficient Graph Construction"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Retrieval Augmented Generation": 0.85,
    "Large Language Model": 0.8,
    "Personalized PageRank": 0.78,
    "Token-Efficient Graph Construction": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Graph-Based Retrieval-Augmented Generation",
        "canonical": "Retrieval Augmented Generation",
        "aliases": [
          "RAG"
        ],
        "category": "specific_connectable",
        "rationale": "RAG is a key concept in the paper, linking it to existing retrieval-augmented generation discussions.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.8,
        "link_intent_score": 0.85
      },
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "LLMs are central to the paper's discussion on improving reasoning and accuracy.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Personalized PageRank",
        "canonical": "Personalized PageRank",
        "aliases": [
          "PPR"
        ],
        "category": "unique_technical",
        "rationale": "Personalized PageRank is a novel technique used in the retrieval phase, enhancing graph construction.",
        "novelty_score": 0.65,
        "connectivity_score": 0.75,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Token-Efficient Graph Construction",
        "canonical": "Token-Efficient Graph Construction",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This concept addresses the cost issue in graph-based RAG systems, offering a new perspective.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "method",
      "system",
      "approach"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Graph-Based Retrieval-Augmented Generation",
      "resolved_canonical": "Retrieval Augmented Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.8,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Personalized PageRank",
      "resolved_canonical": "Personalized PageRank",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.75,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Token-Efficient Graph Construction",
      "resolved_canonical": "Token-Efficient Graph Construction",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# TERAG: Token-Efficient Graph-Based Retrieval-Augmented Generation

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18667.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2509.18667](https://arxiv.org/abs/2509.18667)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/GRIL_ Knowledge Graph Retrieval-Integrated Learning with Large Language Models_20250923|GRIL: Knowledge Graph Retrieval-Integrated Learning with Large Language Models]] (88.6% similar)
- [[2025-09-23/Rationale-Guided Retrieval Augmented Generation for Medical Question Answering_20250923|Rationale-Guided Retrieval Augmented Generation for Medical Question Answering]] (86.1% similar)
- [[2025-09-19/GRADA_ Graph-based Reranking against Adversarial Documents Attack_20250919|GRADA: Graph-based Reranking against Adversarial Documents Attack]] (86.1% similar)
- [[2025-09-19/Enhancing Retrieval Augmentation via Adversarial Collaboration_20250919|Enhancing Retrieval Augmentation via Adversarial Collaboration]] (85.9% similar)
- [[2025-09-19/ImpRAG_ Retrieval-Augmented Generation with Implicit Queries_20250919|ImpRAG: Retrieval-Augmented Generation with Implicit Queries]] (85.9% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Retrieval Augmented Generation|Retrieval Augmented Generation]]
**âš¡ Unique Technical**: [[keywords/Personalized PageRank|Personalized PageRank]], [[keywords/Token-Efficient Graph Construction|Token-Efficient Graph Construction]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18667v1 Announce Type: new 
Abstract: Graph-based Retrieval-augmented generation (RAG) has become a widely studied approach for improving the reasoning, accuracy, and factuality of Large Language Models. However, many existing graph-based RAG systems overlook the high cost associated with LLM token usage during graph construction, hindering large-scale adoption. To address this, we propose TERAG, a simple yet effective framework designed to build informative graphs at a significantly lower cost. Inspired by HippoRAG, we incorporate Personalized PageRank (PPR) during the retrieval phase, and we achieve at least 80% of the accuracy of widely used graph-based RAG methods while consuming only 3%-11% of the output tokens.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ì¶”ë¡ , ì •í™•ì„± ë° ì‚¬ì‹¤ì„±ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ê·¸ë˜í”„ ê¸°ë°˜ì˜ ê²€ìƒ‰ ì¦ê°• ìƒì„±(RAG) ì ‘ê·¼ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë§ì€ ê·¸ë˜í”„ ê¸°ë°˜ RAG ì‹œìŠ¤í…œì€ ê·¸ë˜í”„ êµ¬ì¶• ì‹œ ë°œìƒí•˜ëŠ” ë†’ì€ ë¹„ìš© ë¬¸ì œë¥¼ ê°„ê³¼í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ì €ìë“¤ì€ TERAGë¼ëŠ” í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. TERAGëŠ” HippoRAGì—ì„œ ì˜ê°ì„ ë°›ì•„ ê²€ìƒ‰ ë‹¨ê³„ì—ì„œ ê°œì¸í™”ëœ í˜ì´ì§€ë­í¬(PPR)ë¥¼ í™œìš©í•˜ì—¬, ê¸°ì¡´ ë°©ë²•ì˜ 80% ì´ìƒì˜ ì •í™•ì„±ì„ ìœ ì§€í•˜ë©´ì„œë„ ì¶œë ¥ í† í° ì‚¬ìš©ëŸ‰ì„ 3%-11%ë¡œ ì¤„ì´ëŠ” ë° ì„±ê³µí–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ê·¸ë˜í”„ ê¸°ë°˜ ê²€ìƒ‰ ì¦ê°• ìƒì„±(RAG)ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ ì¶”ë¡ , ì •í™•ì„±, ì‚¬ì‹¤ì„±ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ë„ë¦¬ ì—°êµ¬ëœ ì ‘ê·¼ë²•ì´ë‹¤.
- 2. ê¸°ì¡´ì˜ ê·¸ë˜í”„ ê¸°ë°˜ RAG ì‹œìŠ¤í…œì€ ê·¸ë˜í”„ êµ¬ì¶• ì‹œ LLM í† í° ì‚¬ìš©ì˜ ë†’ì€ ë¹„ìš©ì„ ê°„ê³¼í•˜ì—¬ ëŒ€ê·œëª¨ ì±„íƒì„ ì €í•´í•œë‹¤.
- 3. TERAGëŠ” ì •ë³´ì„± ë†’ì€ ê·¸ë˜í”„ë¥¼ ë‚®ì€ ë¹„ìš©ìœ¼ë¡œ êµ¬ì¶•í•˜ê¸° ìœ„í•œ ê°„ë‹¨í•˜ë©´ì„œë„ íš¨ê³¼ì ì¸ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•œë‹¤.
- 4. TERAGëŠ” HippoRAGì—ì„œ ì˜ê°ì„ ë°›ì•„ ê²€ìƒ‰ ë‹¨ê³„ì—ì„œ ê°œì¸í™”ëœ í˜ì´ì§€ë­í¬(PPR)ë¥¼ í†µí•©í•œë‹¤.
- 5. TERAGëŠ” ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ê·¸ë˜í”„ ê¸°ë°˜ RAG ë°©ë²•ì˜ ì •í™•ì„±ì˜ ìµœì†Œ 80%ë¥¼ ë‹¬ì„±í•˜ë©´ì„œ ì¶œë ¥ í† í°ì˜ 3%-11%ë§Œ ì†Œë¹„í•œë‹¤.


---

*Generated on 2025-09-24 13:27:16*