<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T13:48:08.957438",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multimodal Learning",
    "Vision-Language Model",
    "Zero-Shot Learning",
    "Check Fraud Detection"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multimodal Learning": 0.85,
    "Vision-Language Model": 0.84,
    "Zero-Shot Learning": 0.83,
    "Check Fraud Detection": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multimodal Large Language Model",
        "canonical": "Multimodal Learning",
        "aliases": [
          "MLLM"
        ],
        "category": "specific_connectable",
        "rationale": "Multimodal Learning is crucial for integrating vision and language, central to the paper's framework.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.78,
        "link_intent_score": 0.85
      },
      {
        "surface": "Vision Language Model",
        "canonical": "Vision-Language Model",
        "aliases": [
          "VLM"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-Language Models are pivotal for the zero-shot detection capability discussed in the paper.",
        "novelty_score": 0.6,
        "connectivity_score": 0.82,
        "specificity_score": 0.8,
        "link_intent_score": 0.84
      },
      {
        "surface": "Zero-Shot Detection",
        "canonical": "Zero-Shot Learning",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Zero-Shot Learning is a key technique enabling the model's deployment without additional training.",
        "novelty_score": 0.58,
        "connectivity_score": 0.85,
        "specificity_score": 0.77,
        "link_intent_score": 0.83
      },
      {
        "surface": "Check Fraud Detection",
        "canonical": "Check Fraud Detection",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This is a unique application focus of the paper, linking to financial security topics.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "field detection",
      "object detection",
      "dataset"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multimodal Large Language Model",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.78,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Vision Language Model",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.82,
        "specificity": 0.8,
        "link_intent": 0.84
      }
    },
    {
      "candidate_surface": "Zero-Shot Detection",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.85,
        "specificity": 0.77,
        "link_intent": 0.83
      }
    },
    {
      "candidate_surface": "Check Fraud Detection",
      "resolved_canonical": "Check Fraud Detection",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# Check Field Detection Agent (CFD-Agent) using Multimodal Large Language and Vision Language Models

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18405.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2509.18405](https://arxiv.org/abs/2509.18405)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/VLA-Mark_ A cross modal watermark for large vision-language alignment model_20250922|VLA-Mark: A cross modal watermark for large vision-language alignment model]] (82.0% similar)
- [[2025-09-23/Quality Assessment of Tabular Data using Large Language Models and Code Generation_20250923|Quality Assessment of Tabular Data using Large Language Models and Code Generation]] (81.9% similar)
- [[2025-09-23/Advanced Financial Reasoning at Scale_ A Comprehensive Evaluation of Large Language Models on CFA Level III_20250923|Advanced Financial Reasoning at Scale: A Comprehensive Evaluation of Large Language Models on CFA Level III]] (81.6% similar)
- [[2025-09-19/DetectAnyLLM_ Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models_20250919|DetectAnyLLM: Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models]] (81.4% similar)
- [[2025-09-19/Decoupled Proxy Alignment_ Mitigating Language Prior Conflict for Multimodal Alignment in MLLM_20250919|Decoupled Proxy Alignment: Mitigating Language Prior Conflict for Multimodal Alignment in MLLM]] (81.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]], [[keywords/Zero-Shot Learning|Zero-Shot Learning]]
**âš¡ Unique Technical**: [[keywords/Check Fraud Detection|Check Fraud Detection]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18405v1 Announce Type: cross 
Abstract: Checks remain a foundational instrument in the financial ecosystem, facilitating substantial transaction volumes across institutions. However, their continued use also renders them a persistent target for fraud, underscoring the importance of robust check fraud detection mechanisms. At the core of such systems lies the accurate identification and localization of critical fields, such as the signature, magnetic ink character recognition (MICR) line, courtesy amount, legal amount, payee, and payer, which are essential for subsequent verification against reference checks belonging to the same customer. This field-level detection is traditionally dependent on object detection models trained on large, diverse, and meticulously labeled datasets, a resource that is scarce due to proprietary and privacy concerns. In this paper, we introduce a novel, training-free framework for automated check field detection, leveraging the power of a vision language model (VLM) in conjunction with a multimodal large language model (MLLM). Our approach enables zero-shot detection of check components, significantly lowering the barrier to deployment in real-world financial settings. Quantitative evaluation of our model on a hand-curated dataset of 110 checks spanning multiple formats and layouts demonstrates strong performance and generalization capability. Furthermore, this framework can serve as a bootstrap mechanism for generating high-quality labeled datasets, enabling the development of specialized real-time object detection models tailored to institutional needs.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ê¸ˆìœµ ì‹œìŠ¤í…œì—ì„œ ì¤‘ìš”í•œ ìˆ˜ë‹¨ì¸ ìˆ˜í‘œì˜ ì‚¬ê¸° ë°©ì§€ë¥¼ ìœ„í•œ ìƒˆë¡œìš´ ë°©ë²•ë¡ ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì „í†µì ìœ¼ë¡œ ìˆ˜í‘œì˜ ì¤‘ìš”í•œ í•„ë“œë“¤ì„ ì •í™•íˆ ì‹ë³„í•˜ê¸° ìœ„í•´ ëŒ€ê·œëª¨ì˜ ë¼ë²¨ë§ëœ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ëŠ” ê°ì²´ íƒì§€ ëª¨ë¸ì´ í•„ìš”í•˜ì§€ë§Œ, ë°ì´í„° ë¶€ì¡± ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ í›ˆë ¨ì´ í•„ìš” ì—†ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¥¼ ë„ì…í–ˆìŠµë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ë¹„ì „ ì–¸ì–´ ëª¨ë¸(VLM)ê³¼ ë‹¤ì¤‘ ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(MLLM)ì„ í™œìš©í•˜ì—¬ ìˆ˜í‘œ êµ¬ì„± ìš”ì†Œë¥¼ ì œë¡œìƒ·ìœ¼ë¡œ íƒì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 110ê°œì˜ ë‹¤ì–‘í•œ ìˆ˜í‘œ í˜•ì‹ì„ í¬í•¨í•œ ë°ì´í„°ì…‹ì—ì„œì˜ ì‹¤í—˜ ê²°ê³¼, ì´ ë°©ë²•ë¡ ì€ ê°•ë ¥í•œ ì„±ëŠ¥ê³¼ ì¼ë°˜í™” ëŠ¥ë ¥ì„ ë³´ì—¬ì£¼ì—ˆìœ¼ë©°, ê³ í’ˆì§ˆì˜ ë¼ë²¨ë§ ë°ì´í„°ì…‹ ìƒì„±ì—ë„ ê¸°ì—¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ê¸ˆìœµ ìƒíƒœê³„ì—ì„œ ìˆ˜í‘œëŠ” ì—¬ì „íˆ ì¤‘ìš”í•œ ê±°ë˜ ìˆ˜ë‹¨ì´ì§€ë§Œ, ì‚¬ê¸° ìœ„í—˜ì´ ìˆì–´ ê°•ë ¥í•œ ì‚¬ê¸° íƒì§€ ë©”ì»¤ë‹ˆì¦˜ì´ í•„ìš”í•©ë‹ˆë‹¤.
- 2. ìˆ˜í‘œì˜ ì¤‘ìš”í•œ í•„ë“œ(ì„œëª…, MICR ë¼ì¸, ê¸ˆì•¡ ë“±)ë¥¼ ì •í™•íˆ ì‹ë³„í•˜ëŠ” ê²ƒì´ ì‚¬ê¸° íƒì§€ ì‹œìŠ¤í…œì˜ í•µì‹¬ì…ë‹ˆë‹¤.
- 3. ê¸°ì¡´ì˜ í•„ë“œ íƒì§€ëŠ” ëŒ€ê·œëª¨ë¡œ ë¼ë²¨ë§ëœ ë°ì´í„°ì…‹ì— ì˜ì¡´í•˜ì§€ë§Œ, ì´ëŠ” í”„ë¼ì´ë²„ì‹œ ë¬¸ì œë¡œ ì¸í•´ ë¶€ì¡±í•©ë‹ˆë‹¤.
- 4. ë³¸ ë…¼ë¬¸ì€ ë¹„ì „ ì–¸ì–´ ëª¨ë¸(VLM)ê³¼ ë‹¤ì¤‘ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(MLLM)ì„ í™œìš©í•œ ìƒˆë¡œìš´ í›ˆë ¨ ë¶ˆí•„ìš” ìë™ ìˆ˜í‘œ í•„ë“œ íƒì§€ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.
- 5. ì œì•ˆëœ ë°©ë²•ì€ ìˆ˜í‘œ êµ¬ì„± ìš”ì†Œì˜ ì œë¡œìƒ· íƒì§€ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ì—¬ ì‹¤ì œ ê¸ˆìœµ í™˜ê²½ì—ì„œì˜ ì ìš© ì¥ë²½ì„ ë‚®ì¶¥ë‹ˆë‹¤.


---

*Generated on 2025-09-24 13:48:08*