<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T15:54:42.289051",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "False Assumptions",
    "Fact Verification",
    "External Evidence"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "False Assumptions": 0.7,
    "Fact Verification": 0.8,
    "External Evidence": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are central to the paper's approach and are a key concept in many related works.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "false assumptions",
        "canonical": "False Assumptions",
        "aliases": [
          "incorrect assumptions"
        ],
        "category": "unique_technical",
        "rationale": "The concept of false assumptions is unique to the paper's problem statement and critical for understanding the research focus.",
        "novelty_score": 0.7,
        "connectivity_score": 0.5,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      },
      {
        "surface": "fact verification",
        "canonical": "Fact Verification",
        "aliases": [
          "fact-checking"
        ],
        "category": "specific_connectable",
        "rationale": "Fact verification is a specific process discussed in the paper that connects to broader research on information validation.",
        "novelty_score": 0.5,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "external evidence",
        "canonical": "External Evidence",
        "aliases": [
          "retrieved evidence"
        ],
        "category": "specific_connectable",
        "rationale": "Using external evidence is a method to mitigate hallucinations, linking to retrieval-based approaches.",
        "novelty_score": 0.6,
        "connectivity_score": 0.7,
        "specificity_score": 0.65,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "hallucinations",
      "experiments"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "false assumptions",
      "resolved_canonical": "False Assumptions",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.5,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "fact verification",
      "resolved_canonical": "Fact Verification",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "external evidence",
      "resolved_canonical": "External Evidence",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.7,
        "specificity": 0.65,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Identifying and Answering Questions with False Assumptions: An Interpretable Approach

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2508.15139.pdf)
**Category**: cs.CL
**Published**: 2025-09-24
**ArXiv ID**: [2508.15139](https://arxiv.org/abs/2508.15139)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Quantifying Self-Awareness of Knowledge in Large Language Models_20250922|Quantifying Self-Awareness of Knowledge in Large Language Models]] (86.7% similar)
- [[2025-09-22/Do Retrieval Augmented Language Models Know When They Don't Know?_20250922|Do Retrieval Augmented Language Models Know When They Don't Know?]] (85.9% similar)
- [[2025-09-23/No Need for Explanations_ LLMs can implicitly learn from mistakes in-context_20250923|No Need for Explanations: LLMs can implicitly learn from mistakes in-context]] (85.8% similar)
- [[2025-09-24/Unraveling Misinformation Propagation in LLM Reasoning_20250924|Unraveling Misinformation Propagation in LLM Reasoning]] (85.7% similar)
- [[2025-09-23/Question Answering with LLMs and Learning from Answer Sets_20250923|Question Answering with LLMs and Learning from Answer Sets]] (85.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Fact Verification|Fact Verification]], [[keywords/External Evidence|External Evidence]]
**âš¡ Unique Technical**: [[keywords/False Assumptions|False Assumptions]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2508.15139v2 Announce Type: replace 
Abstract: People often ask questions with false assumptions, a type of question that does not have regular answers. Answering such questions requires first identifying the false assumptions. Large Language Models (LLMs) often generate misleading answers to these questions because of hallucinations. In this paper, we focus on identifying and answering questions with false assumptions in several domains. We first investigate whether the problem reduces to fact verification. Then, we present an approach leveraging external evidence to mitigate hallucinations. Experiments with five LLMs demonstrate that (1) incorporating retrieved evidence is beneficial and (2) generating and validating atomic assumptions yields more improvements and provides an interpretable answer by pinpointing the false assumptions.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì˜ëª»ëœ ê°€ì •ì„ í¬í•¨í•œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ê°œì„ í•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ ì´ëŸ¬í•œ ì§ˆë¬¸ì— ëŒ€í•´ ì¢…ì¢… ì˜ëª»ëœ ë‹µë³€ì„ ìƒì„±í•˜ëŠ”ë°, ì´ëŠ” í™˜ê° í˜„ìƒ ë•Œë¬¸ì…ë‹ˆë‹¤. ì—°êµ¬ì§„ì€ ì™¸ë¶€ ì¦ê±°ë¥¼ í™œìš©í•˜ì—¬ í™˜ê°ì„ ì¤„ì´ëŠ” ì ‘ê·¼ë²•ì„ ì œì‹œí•˜ê³ , ë‹¤ì„¯ ê°œì˜ LLMì„ ì‹¤í—˜í•˜ì—¬ ì¦ê±°ë¥¼ í†µí•©í•˜ëŠ” ê²ƒì´ ìœ ìµí•˜ë©°, ì›ìì  ê°€ì •ì„ ìƒì„±í•˜ê³  ê²€ì¦í•˜ëŠ” ê²ƒì´ ë” ë‚˜ì€ í•´ë‹µì„ ì œê³µí•¨ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì˜ëª»ëœ ê°€ì •ì„ ëª…í™•íˆ í•˜ì—¬ í•´ì„ ê°€ëŠ¥í•œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì˜ëª»ëœ ê°€ì •ì„ í¬í•¨í•œ ì§ˆë¬¸ì„ ì‹ë³„í•˜ê³  ë‹µë³€í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤.
- 2. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ í™˜ê°ìœ¼ë¡œ ì¸í•´ ì˜ëª»ëœ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ìˆë‹¤.
- 3. ì™¸ë¶€ ì¦ê±°ë¥¼ í™œìš©í•˜ì—¬ í™˜ê°ì„ ì¤„ì´ëŠ” ì ‘ê·¼ë²•ì„ ì œì‹œí•œë‹¤.
- 4. ì‹¤í—˜ ê²°ê³¼, ê²€ìƒ‰ëœ ì¦ê±°ë¥¼ í†µí•©í•˜ëŠ” ê²ƒì´ ìœ ìµí•˜ë©°, ì›ìì  ê°€ì •ì„ ìƒì„±í•˜ê³  ê²€ì¦í•˜ëŠ” ê²ƒì´ ë” ë‚˜ì€ ê°œì„ ì„ ê°€ì ¸ì˜¨ë‹¤.
- 5. ì˜ëª»ëœ ê°€ì •ì„ ì •í™•íˆ ì§€ì í•¨ìœ¼ë¡œì¨ í•´ì„ ê°€ëŠ¥í•œ ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ìˆë‹¤.


---

*Generated on 2025-09-24 15:54:42*