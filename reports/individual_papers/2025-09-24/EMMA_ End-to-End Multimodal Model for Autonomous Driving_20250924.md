<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T14:25:59.273820",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multimodal Learning",
    "Large Language Model",
    "Motion Planning",
    "3D Object Detection",
    "Road Graph Elements"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multimodal Learning": 0.8,
    "Large Language Model": 0.85,
    "Motion Planning": 0.78,
    "3D Object Detection": 0.77,
    "Road Graph Elements": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multimodal Model",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal",
          "Multimodal Approach"
        ],
        "category": "specific_connectable",
        "rationale": "Multimodal Learning is a key concept in integrating multiple data types, crucial for autonomous driving systems.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Large Language Model",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are foundational to EMMA's architecture, enabling natural language processing capabilities.",
        "novelty_score": 0.4,
        "connectivity_score": 0.92,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Motion Planning",
        "canonical": "Motion Planning",
        "aliases": [
          "Trajectory Planning"
        ],
        "category": "unique_technical",
        "rationale": "Motion Planning is a critical task in autonomous driving, directly addressed by EMMA.",
        "novelty_score": 0.65,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "3D Object Detection",
        "canonical": "3D Object Detection",
        "aliases": [
          "3D Detection",
          "Object Detection"
        ],
        "category": "unique_technical",
        "rationale": "3D Object Detection is essential for understanding the driving environment, a core function of EMMA.",
        "novelty_score": 0.6,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      },
      {
        "surface": "Road Graph Elements",
        "canonical": "Road Graph Elements",
        "aliases": [
          "Road Graphs",
          "Graph Elements"
        ],
        "category": "unique_technical",
        "rationale": "Road Graph Elements are vital for mapping and navigation tasks in autonomous driving.",
        "novelty_score": 0.68,
        "connectivity_score": 0.72,
        "specificity_score": 0.78,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "planner trajectories",
      "perception objects",
      "world knowledge"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multimodal Model",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Large Language Model",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.92,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Motion Planning",
      "resolved_canonical": "Motion Planning",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "3D Object Detection",
      "resolved_canonical": "3D Object Detection",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Road Graph Elements",
      "resolved_canonical": "Road Graph Elements",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.72,
        "specificity": 0.78,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# EMMA: End-to-End Multimodal Model for Autonomous Driving

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2410.23262.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2410.23262](https://arxiv.org/abs/2410.23262)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/VLM-E2E_ Enhancing End-to-End Autonomous Driving with Multimodal Driver Attention Fusion_20250919|VLM-E2E: Enhancing End-to-End Autonomous Driving with Multimodal Driver Attention Fusion]] (84.0% similar)
- [[2025-09-18/Embodied Navigation Foundation Model_20250918|Embodied Navigation Foundation Model]] (83.7% similar)
- [[2025-09-22/Multi-Modal Interpretability for Enhanced Localization in Vision-Language Models_20250922|Multi-Modal Interpretability for Enhanced Localization in Vision-Language Models]] (83.1% similar)
- [[2025-09-17/MAP_ End-to-End Autonomous Driving with Map-Assisted Planning_20250917|MAP: End-to-End Autonomous Driving with Map-Assisted Planning]] (82.1% similar)
- [[2025-09-23/LEO-MINI_ An Efficient Multimodal Large Language Model using Conditional Token Reduction and Mixture of Multi-Modal Experts_20250923|LEO-MINI: An Efficient Multimodal Large Language Model using Conditional Token Reduction and Mixture of Multi-Modal Experts]] (82.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**âš¡ Unique Technical**: [[keywords/Motion Planning|Motion Planning]], [[keywords/3D Object Detection|3D Object Detection]], [[keywords/Road Graph Elements|Road Graph Elements]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2410.23262v3 Announce Type: replace-cross 
Abstract: We introduce EMMA, an End-to-end Multimodal Model for Autonomous driving. Built upon a multi-modal large language model foundation like Gemini, EMMA directly maps raw camera sensor data into various driving-specific outputs, including planner trajectories, perception objects, and road graph elements. EMMA maximizes the utility of world knowledge from the pre-trained large language models, by representing all non-sensor inputs (e.g. navigation instructions and ego vehicle status) and outputs (e.g. trajectories and 3D locations) as natural language text. This approach allows EMMA to jointly process various driving tasks in a unified language space, and generate the outputs for each task using task-specific prompts. Empirically, we demonstrate EMMA's effectiveness by achieving state-of-the-art performance in motion planning on nuScenes as well as competitive results on the Waymo Open Motion Dataset (WOMD). EMMA also yields competitive results for camera-primary 3D object detection on the Waymo Open Dataset (WOD). We show that co-training EMMA with planner trajectories, object detection, and road graph tasks yields improvements across all three domains, highlighting EMMA's potential as a generalist model for autonomous driving applications. We hope that our results will inspire research to further evolve the state of the art in autonomous driving model architectures.

## ğŸ“ ìš”ì•½

EMMAëŠ” ììœ¨ì£¼í–‰ì„ ìœ„í•œ ì¢…ë‹¨ê°„ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ë¡œ, Geminiì™€ ê°™ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ì¹´ë©”ë¼ ì„¼ì„œ ë°ì´í„°ë¥¼ ì£¼í–‰ ê³„íš, ê°ì²´ ì¸ì‹, ë„ë¡œ ê·¸ë˜í”„ ìš”ì†Œ ë“±ìœ¼ë¡œ ì§ì ‘ ë³€í™˜í•©ë‹ˆë‹¤. EMMAëŠ” ì‚¬ì „ í•™ìŠµëœ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ ì„¸ê³„ ì§€ì‹ì„ ìµœëŒ€í•œ í™œìš©í•˜ì—¬ ë¹„ì„¼ì„œ ì…ë ¥ê³¼ ì¶œë ¥ì„ ìì—°ì–´ í…ìŠ¤íŠ¸ë¡œ í‘œí˜„í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë‹¤ì–‘í•œ ì£¼í–‰ ì‘ì—…ì„ í†µí•©ëœ ì–¸ì–´ ê³µê°„ì—ì„œ ì²˜ë¦¬í•˜ê³ , ì‘ì—…ë³„ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•´ ê²°ê³¼ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, EMMAëŠ” nuScenesì—ì„œ ëª¨ì…˜ í”Œë˜ë‹ ë¶„ì•¼ì˜ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë©°, Waymo Open Motion Datasetì—ì„œë„ ê²½ìŸë ¥ ìˆëŠ” ê²°ê³¼ë¥¼ ì–»ì—ˆìŠµë‹ˆë‹¤. ë˜í•œ, Waymo Open Datasetì—ì„œ ì¹´ë©”ë¼ ê¸°ë°˜ 3D ê°ì²´ íƒì§€ì—ì„œë„ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ì£¼í–‰ ê³„íš, ê°ì²´ íƒì§€, ë„ë¡œ ê·¸ë˜í”„ ì‘ì—…ì„ í•¨ê»˜ í•™ìŠµí•¨ìœ¼ë¡œì¨ ëª¨ë“  ì˜ì—­ì—ì„œ ì„±ëŠ¥ì´ í–¥ìƒë˜ì—ˆìœ¼ë©°, ì´ëŠ” EMMAê°€ ììœ¨ì£¼í–‰ ë¶„ì•¼ì˜ ë²”ìš© ëª¨ë¸ë¡œì„œì˜ ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. EMMAëŠ” ë‹¤ì¤‘ ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ì—¬ ì›ì‹œ ì¹´ë©”ë¼ ì„¼ì„œ ë°ì´í„°ë¥¼ ë‹¤ì–‘í•œ ììœ¨ì£¼í–‰ ê´€ë ¨ ì¶œë ¥ìœ¼ë¡œ ì§ì ‘ ë§¤í•‘í•©ë‹ˆë‹¤.
- 2. ëª¨ë“  ë¹„ì„¼ì„œ ì…ë ¥ê³¼ ì¶œë ¥ì„ ìì—°ì–´ í…ìŠ¤íŠ¸ë¡œ í‘œí˜„í•˜ì—¬ ë‹¤ì–‘í•œ ì£¼í–‰ ì‘ì—…ì„ í†µí•©ëœ ì–¸ì–´ ê³µê°„ì—ì„œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
- 3. EMMAëŠ” nuScenesì—ì„œ ëª¨ì…˜ í”Œë˜ë‹ ë¶„ì•¼ì˜ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ê³ , Waymo Open Motion Datasetì—ì„œë„ ê²½ìŸë ¥ ìˆëŠ” ê²°ê³¼ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.
- 4. í”Œë˜ë„ˆ ê¶¤ì , ê°ì²´ íƒì§€, ë„ë¡œ ê·¸ë˜í”„ ì‘ì—…ì„ í•¨ê»˜ í›ˆë ¨í•¨ìœ¼ë¡œì¨ ëª¨ë“  ë¶„ì•¼ì—ì„œ ì„±ëŠ¥ í–¥ìƒì„ ì´ëŒì–´ëƒˆìŠµë‹ˆë‹¤.
- 5. EMMAëŠ” ììœ¨ì£¼í–‰ ì‘ìš© í”„ë¡œê·¸ë¨ì„ ìœ„í•œ ë²”ìš© ëª¨ë¸ë¡œì„œì˜ ì ì¬ë ¥ì„ ë³´ì—¬ì£¼ë©°, ììœ¨ì£¼í–‰ ëª¨ë¸ ì•„í‚¤í…ì²˜ì˜ ë°œì „ì„ ìœ„í•œ ì—°êµ¬ë¥¼ ì´‰ì§„í•˜ê³ ì í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 14:25:59*