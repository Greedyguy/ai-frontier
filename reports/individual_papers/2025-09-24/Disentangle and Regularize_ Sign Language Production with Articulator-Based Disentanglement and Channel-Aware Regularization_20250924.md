<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T15:23:17.068089",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Transformer",
    "Articulator-based Disentanglement",
    "Channel-aware Regularization",
    "Non-autoregressive Transformer"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Transformer": 0.78,
    "Articulator-based Disentanglement": 0.82,
    "Channel-aware Regularization": 0.79,
    "Non-autoregressive Transformer": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Transformer-based sign language production",
        "canonical": "Transformer",
        "aliases": [
          "Transformer-based SLP"
        ],
        "category": "broad_technical",
        "rationale": "Transformers are crucial for understanding the architecture used in the framework, linking to broader technical concepts.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.78
      },
      {
        "surface": "Articulator-based disentanglement",
        "canonical": "Articulator-based Disentanglement",
        "aliases": [
          "Articulator Disentanglement"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel approach specific to the paper's methodology, offering a unique perspective on disentanglement strategies.",
        "novelty_score": 0.72,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.82
      },
      {
        "surface": "Channel-aware regularization",
        "canonical": "Channel-aware Regularization",
        "aliases": [
          "Channel Regularization"
        ],
        "category": "unique_technical",
        "rationale": "This technique is specific to the paper and crucial for understanding the regularization process used in the model.",
        "novelty_score": 0.68,
        "connectivity_score": 0.58,
        "specificity_score": 0.8,
        "link_intent_score": 0.79
      },
      {
        "surface": "Non-autoregressive transformer decoder",
        "canonical": "Non-autoregressive Transformer",
        "aliases": [
          "Non-autoregressive Decoder"
        ],
        "category": "specific_connectable",
        "rationale": "This variant of transformer architecture is significant for understanding the model's decoding process.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "gloss-free",
      "state-of-the-art"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Transformer-based sign language production",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Articulator-based disentanglement",
      "resolved_canonical": "Articulator-based Disentanglement",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Channel-aware regularization",
      "resolved_canonical": "Channel-aware Regularization",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.58,
        "specificity": 0.8,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Non-autoregressive transformer decoder",
      "resolved_canonical": "Non-autoregressive Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Disentangle and Regularize: Sign Language Production with Articulator-Based Disentanglement and Channel-Aware Regularization

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2504.06610.pdf)
**Category**: cs.LG
**Published**: 2025-09-24
**ArXiv ID**: [2504.06610](https://arxiv.org/abs/2504.06610)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Hybrid Autoregressive-Diffusion Model for Real-Time Sign Language Production_20250919|Hybrid Autoregressive-Diffusion Model for Real-Time Sign Language Production]] (88.3% similar)
- [[2025-09-23/Revisiting Speech-Lip Alignment_ A Phoneme-Aware Speech Encoder for Robust Talking Head Synthesis_20250923|Revisiting Speech-Lip Alignment: A Phoneme-Aware Speech Encoder for Robust Talking Head Synthesis]] (82.0% similar)
- [[2025-09-23/Inceptive Transformers_ Enhancing Contextual Representations through Multi-Scale Feature Learning Across Domains and Languages_20250923|Inceptive Transformers: Enhancing Contextual Representations through Multi-Scale Feature Learning Across Domains and Languages]] (81.6% similar)
- [[2025-09-23/DeepInsert_ Early Layer Bypass for Efficient and Performant Multimodal Understanding_20250923|DeepInsert: Early Layer Bypass for Efficient and Performant Multimodal Understanding]] (81.6% similar)
- [[2025-09-17/SSL-SSAW_ Self-Supervised Learning with Sigmoid Self-Attention Weighting for Question-Based Sign Language Translation_20250917|SSL-SSAW: Self-Supervised Learning with Sigmoid Self-Attention Weighting for Question-Based Sign Language Translation]] (81.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Transformer|Transformer]]
**ğŸ”— Specific Connectable**: [[keywords/Non-autoregressive Transformer|Non-autoregressive Transformer]]
**âš¡ Unique Technical**: [[keywords/Articulator-based Disentanglement|Articulator-based Disentanglement]], [[keywords/Channel-aware Regularization|Channel-aware Regularization]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2504.06610v3 Announce Type: replace 
Abstract: In this work, we propose DARSLP, a simple gloss-free, transformer-based sign language production (SLP) framework that directly maps spoken-language text to sign pose sequences. We first train a pose autoencoder that encodes sign poses into a compact latent space using an articulator-based disentanglement strategy, where features corresponding to the face, right hand, left hand, and body are modeled separately to promote structured and interpretable representation learning. Next, a non-autoregressive transformer decoder is trained to predict these latent representations from word-level text embeddings of the input sentence. To guide this process, we apply channel-aware regularization by aligning predicted latent distributions with priors extracted from the ground-truth encodings using a KL divergence loss. The contribution of each channel to the loss is weighted according to its associated articulator region, enabling the model to account for the relative importance of different articulators during training. Our approach does not rely on gloss supervision or pretrained models, and achieves state-of-the-art results on the PHOENIX14T and CSL-Daily datasets.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ì—ì„œëŠ” DARSLPë¼ëŠ” ê°„ë‹¨í•œ ê¸€ë¡œìŠ¤ ì—†ì´ ë™ì‘í•˜ëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ ìˆ˜ì–´ ìƒì„± í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ìŒì„± ì–¸ì–´ í…ìŠ¤íŠ¸ë¥¼ ìˆ˜ì–´ ìì„¸ ì‹œí€€ìŠ¤ë¡œ ì§ì ‘ ë³€í™˜í•©ë‹ˆë‹¤. ë¨¼ì €, ì–¼êµ´, ì˜¤ë¥¸ì†, ì™¼ì†, ëª¸ì„ ê°ê° ëª¨ë¸ë§í•˜ì—¬ êµ¬ì¡°ì ì´ê³  í•´ì„ ê°€ëŠ¥í•œ í‘œí˜„ í•™ìŠµì„ ì´‰ì§„í•˜ëŠ” ìì„¸ ì˜¤í† ì¸ì½”ë”ë¥¼ í›ˆë ¨í•©ë‹ˆë‹¤. ì´í›„, ë¹„ìê¸°íšŒê·€ íŠ¸ëœìŠ¤í¬ë¨¸ ë””ì½”ë”ë¥¼ ì‚¬ìš©í•˜ì—¬ ì…ë ¥ ë¬¸ì¥ì˜ ë‹¨ì–´ ìˆ˜ì¤€ í…ìŠ¤íŠ¸ ì„ë² ë”©ì—ì„œ ì´ëŸ¬í•œ ì ì¬ í‘œí˜„ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤. ì˜ˆì¸¡ëœ ì ì¬ ë¶„í¬ë¥¼ ì‹¤ì œ ì¸ì½”ë”©ì—ì„œ ì¶”ì¶œí•œ ì‚¬ì „ ë¶„í¬ì™€ ì •ë ¬í•˜ê¸° ìœ„í•´ ì±„ë„ ì¸ì‹ ì •ê·œí™”ë¥¼ ì ìš©í•˜ë©°, KL ë°œì‚° ì†ì‹¤ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ê° ì±„ë„ì˜ ì†ì‹¤ ê¸°ì—¬ë„ëŠ” ê´€ë ¨ ê´€ì ˆ ë¶€ìœ„ì— ë”°ë¼ ê°€ì¤‘ì¹˜ê°€ ë¶€ì—¬ë˜ì–´ í›ˆë ¨ ì¤‘ ë‹¤ì–‘í•œ ê´€ì ˆì˜ ìƒëŒ€ì  ì¤‘ìš”ì„±ì„ ê³ ë ¤í•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ê¸€ë¡œìŠ¤ ê°ë…ì´ë‚˜ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì— ì˜ì¡´í•˜ì§€ ì•Šìœ¼ë©°, PHOENIX14T ë° CSL-Daily ë°ì´í„°ì…‹ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. DARSLPëŠ” êµ¬ì–´ í…ìŠ¤íŠ¸ë¥¼ ìˆ˜ì–´ ìì„¸ ì‹œí€€ìŠ¤ë¡œ ì§ì ‘ ë³€í™˜í•˜ëŠ” ê¸€ë¡œìŠ¤ ì—†ëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ ìˆ˜ì–´ ìƒì„± í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.
- 2. í¬ì¦ˆ ì˜¤í† ì¸ì½”ë”ëŠ” ì–¼êµ´, ì˜¤ë¥¸ì†, ì™¼ì†, ëª¸ì˜ íŠ¹ì§•ì„ ë³„ë„ë¡œ ëª¨ë¸ë§í•˜ì—¬ êµ¬ì¡°ì ì´ê³  í•´ì„ ê°€ëŠ¥í•œ í‘œí˜„ í•™ìŠµì„ ì´‰ì§„í•©ë‹ˆë‹¤.
- 3. ë¹„ìê¸°íšŒê·€ íŠ¸ëœìŠ¤í¬ë¨¸ ë””ì½”ë”ëŠ” ì…ë ¥ ë¬¸ì¥ì˜ ë‹¨ì–´ ìˆ˜ì¤€ í…ìŠ¤íŠ¸ ì„ë² ë”©ìœ¼ë¡œë¶€í„° ì ì¬ í‘œí˜„ì„ ì˜ˆì¸¡í•˜ë„ë¡ í›ˆë ¨ë©ë‹ˆë‹¤.
- 4. ì±„ë„ ì¸ì‹ ì •ê·œí™”ë¥¼ í†µí•´ ì˜ˆì¸¡ëœ ì ì¬ ë¶„í¬ë¥¼ ì‹¤ì œ ì¸ì½”ë”©ì—ì„œ ì¶”ì¶œí•œ ì‚¬ì „ ë¶„í¬ì™€ ì •ë ¬í•˜ì—¬ í•™ìŠµì„ ìœ ë„í•©ë‹ˆë‹¤.
- 5. ì´ ì ‘ê·¼ ë°©ì‹ì€ ê¸€ë¡œìŠ¤ ê°ë…ì´ë‚˜ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì— ì˜ì¡´í•˜ì§€ ì•Šìœ¼ë©°, PHOENIX14T ë° CSL-Daily ë°ì´í„°ì…‹ì—ì„œ ìµœì²¨ë‹¨ ê²°ê³¼ë¥¼ ë‹¬ì„±í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 15:23:17*