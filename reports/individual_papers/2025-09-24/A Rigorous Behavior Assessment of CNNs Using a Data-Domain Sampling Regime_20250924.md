<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T15:26:02.683067",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Neural Network",
    "Data-Domain Sampling",
    "Visual Perception in Neural Networks",
    "Domain Shift"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Neural Network": 0.85,
    "Data-Domain Sampling": 0.7,
    "Visual Perception in Neural Networks": 0.77,
    "Domain Shift": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "CNNs",
        "canonical": "Neural Network",
        "aliases": [
          "Convolutional Neural Networks",
          "CNN"
        ],
        "category": "broad_technical",
        "rationale": "CNNs are a fundamental type of neural network used extensively in computer vision tasks.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "data-domain sampling regime",
        "canonical": "Data-Domain Sampling",
        "aliases": [
          "sampling regime"
        ],
        "category": "unique_technical",
        "rationale": "This is a specific technique introduced in the paper for assessing CNN behavior.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      },
      {
        "surface": "graphic perception behaviors",
        "canonical": "Visual Perception in Neural Networks",
        "aliases": [
          "graphic perception",
          "visual perception"
        ],
        "category": "specific_connectable",
        "rationale": "Understanding how neural networks perceive graphics is crucial for linking to computer vision research.",
        "novelty_score": 0.55,
        "connectivity_score": 0.78,
        "specificity_score": 0.72,
        "link_intent_score": 0.77
      },
      {
        "surface": "training-test distribution discrepancies",
        "canonical": "Domain Shift",
        "aliases": [
          "distribution discrepancies",
          "training-test shift"
        ],
        "category": "specific_connectable",
        "rationale": "Domain shift is a key concept in understanding model generalization and robustness.",
        "novelty_score": 0.6,
        "connectivity_score": 0.82,
        "specificity_score": 0.75,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "trials",
      "participants",
      "registration",
      "code"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "CNNs",
      "resolved_canonical": "Neural Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "data-domain sampling regime",
      "resolved_canonical": "Data-Domain Sampling",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "graphic perception behaviors",
      "resolved_canonical": "Visual Perception in Neural Networks",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.78,
        "specificity": 0.72,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "training-test distribution discrepancies",
      "resolved_canonical": "Domain Shift",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.82,
        "specificity": 0.75,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# A Rigorous Behavior Assessment of CNNs Using a Data-Domain Sampling Regime

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2507.03866.pdf)
**Category**: cs.LG
**Published**: 2025-09-24
**ArXiv ID**: [2507.03866](https://arxiv.org/abs/2507.03866)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/R-Net_ A Reliable and Resource-Efficient CNN for Colorectal Cancer Detection with XAI Integration_20250923|R-Net: A Reliable and Resource-Efficient CNN for Colorectal Cancer Detection with XAI Integration]] (82.5% similar)
- [[2025-09-23/A study on Deep Convolutional Neural Networks, transfer learning, and Mnet model for Cervical Cancer Detection_20250923|A study on Deep Convolutional Neural Networks, transfer learning, and Mnet model for Cervical Cancer Detection]] (81.8% similar)
- [[2025-09-22/Training A Neural Network For Partially Occluded Road Sign Identification In The Context Of Autonomous Vehicles_20250922|Training A Neural Network For Partially Occluded Road Sign Identification In The Context Of Autonomous Vehicles]] (81.4% similar)
- [[2025-09-23/Deep Learning Inductive Biases for fMRI Time Series Classification during Resting-state and Movie-watching_20250923|Deep Learning Inductive Biases for fMRI Time Series Classification during Resting-state and Movie-watching]] (81.2% similar)
- [[2025-09-22/Incorporating Visual Cortical Lateral Connection Properties into CNN_ Recurrent Activation and Excitatory-Inhibitory Separation_20250922|Incorporating Visual Cortical Lateral Connection Properties into CNN: Recurrent Activation and Excitatory-Inhibitory Separation]] (80.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Neural Network|Neural Network]]
**ğŸ”— Specific Connectable**: [[keywords/Visual Perception in Neural Networks|Visual Perception in Neural Networks]], [[keywords/Domain Shift|Domain Shift]]
**âš¡ Unique Technical**: [[keywords/Data-Domain Sampling|Data-Domain Sampling]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2507.03866v2 Announce Type: replace 
Abstract: We present a data-domain sampling regime for quantifying CNNs' graphic perception behaviors. This regime lets us evaluate CNNs' ratio estimation ability in bar charts from three perspectives: sensitivity to training-test distribution discrepancies, stability to limited samples, and relative expertise to human observers. After analyzing 16 million trials from 800 CNNs models and 6,825 trials from 113 human participants, we arrived at a simple and actionable conclusion: CNNs can outperform humans and their biases simply depend on the training-test distance. We show evidence of this simple, elegant behavior of the machines when they interpret visualization images. osf.io/gfqc3 provides registration, the code for our sampling regime, and experimental results.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ CNNì˜ ê·¸ë˜í”½ ì¸ì‹ í–‰ë™ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ë°ì´í„° ë„ë©”ì¸ ìƒ˜í”Œë§ ì²´ê³„ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ì´ ì²´ê³„ëŠ” ë°” ì°¨íŠ¸ì—ì„œ CNNì˜ ë¹„ìœ¨ ì¶”ì • ëŠ¥ë ¥ì„ ì„¸ ê°€ì§€ ê´€ì ì—ì„œ í‰ê°€í•©ë‹ˆë‹¤: í›ˆë ¨-í…ŒìŠ¤íŠ¸ ë¶„í¬ ì°¨ì´ì— ëŒ€í•œ ë¯¼ê°ë„, ì œí•œëœ ìƒ˜í”Œì— ëŒ€í•œ ì•ˆì •ì„±, ì¸ê°„ ê´€ì°°ìì— ëŒ€í•œ ìƒëŒ€ì  ì „ë¬¸ì„±. 800ê°œì˜ CNN ëª¨ë¸ê³¼ 113ëª…ì˜ ì¸ê°„ ì°¸ê°€ìì— ëŒ€í•œ ì‹¤í—˜ì„ í†µí•´, CNNì´ ì¸ê°„ì„ ëŠ¥ê°€í•  ìˆ˜ ìˆìœ¼ë©°, ê·¸ í¸í–¥ì€ í›ˆë ¨-í…ŒìŠ¤íŠ¸ ê±°ë¦¬ì˜ ì˜í–¥ì„ ë°›ëŠ”ë‹¤ëŠ” ê²°ë¡ ì„ ë„ì¶œí–ˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” CNNì´ ì‹œê°í™” ì´ë¯¸ì§€ë¥¼ í•´ì„í•  ë•Œì˜ ë‹¨ìˆœí•˜ê³  ìš°ì•„í•œ í–‰ë™ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. CNNì˜ ê·¸ë˜í”½ ì¸ì‹ í–‰ë™ì„ ì •ëŸ‰í™”í•˜ê¸° ìœ„í•œ ë°ì´í„° ë„ë©”ì¸ ìƒ˜í”Œë§ ì²´ê³„ë¥¼ ì œì‹œí–ˆìŠµë‹ˆë‹¤.
- 2. ë°” ì°¨íŠ¸ì—ì„œ CNNì˜ ë¹„ìœ¨ ì¶”ì • ëŠ¥ë ¥ì„ ì„¸ ê°€ì§€ ê´€ì ì—ì„œ í‰ê°€í–ˆìŠµë‹ˆë‹¤: í›ˆë ¨-í…ŒìŠ¤íŠ¸ ë¶„í¬ ë¶ˆì¼ì¹˜ì— ëŒ€í•œ ë¯¼ê°ì„±, ì œí•œëœ ìƒ˜í”Œì— ëŒ€í•œ ì•ˆì •ì„±, ì¸ê°„ ê´€ì°°ìì— ëŒ€í•œ ìƒëŒ€ì  ì „ë¬¸ì„±.
- 3. 800ê°œì˜ CNN ëª¨ë¸ê³¼ 113ëª…ì˜ ì¸ê°„ ì°¸ê°€ìë¡œë¶€í„° ìˆ˜ì§‘í•œ ë°ì´í„°ë¥¼ ë¶„ì„í•œ ê²°ê³¼, CNNì´ ì¸ê°„ì„ ëŠ¥ê°€í•  ìˆ˜ ìˆìœ¼ë©° ê·¸ í¸í–¥ì€ í›ˆë ¨-í…ŒìŠ¤íŠ¸ ê±°ë¦¬ì˜ ì˜í–¥ì„ ë°›ëŠ”ë‹¤ëŠ” ê²°ë¡ ì„ ë„ì¶œí–ˆìŠµë‹ˆë‹¤.
- 4. CNNì´ ì‹œê°í™” ì´ë¯¸ì§€ë¥¼ í•´ì„í•  ë•Œ ë‹¨ìˆœí•˜ê³  ìš°ì•„í•œ í–‰ë™ì„ ë³´ì¸ë‹¤ëŠ” ì¦ê±°ë¥¼ ì œì‹œí–ˆìŠµë‹ˆë‹¤.
- 5. ì—°êµ¬ ë“±ë¡, ìƒ˜í”Œë§ ì²´ê³„ ì½”ë“œ ë° ì‹¤í—˜ ê²°ê³¼ëŠ” osf.io/gfqc3ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 15:26:02*