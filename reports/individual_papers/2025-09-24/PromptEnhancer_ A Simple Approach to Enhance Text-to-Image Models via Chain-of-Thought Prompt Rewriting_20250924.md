<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T16:32:47.037134",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Text-to-Image Diffusion Models",
    "Chain-of-Thought Rewriter",
    "AlignEvaluator",
    "Image-Text Alignment",
    "HunyuanImage 2.1 Model"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Text-to-Image Diffusion Models": 0.78,
    "Chain-of-Thought Rewriter": 0.8,
    "AlignEvaluator": 0.82,
    "Image-Text Alignment": 0.77,
    "HunyuanImage 2.1 Model": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "text-to-image diffusion models",
        "canonical": "Text-to-Image Diffusion Models",
        "aliases": [
          "T2I diffusion models"
        ],
        "category": "specific_connectable",
        "rationale": "This term is central to the paper's focus on enhancing image generation, making it a key concept for linking.",
        "novelty_score": 0.55,
        "connectivity_score": 0.85,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Chain-of-Thought rewriter",
        "canonical": "Chain-of-Thought Rewriter",
        "aliases": [
          "CoT rewriter"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel mechanism for prompt rewriting, which is essential to the paper's contribution.",
        "novelty_score": 0.75,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "AlignEvaluator",
        "canonical": "AlignEvaluator",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "A unique component of the proposed framework, crucial for understanding the feedback mechanism.",
        "novelty_score": 0.8,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.82
      },
      {
        "surface": "image-text alignment",
        "canonical": "Image-Text Alignment",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "A key challenge addressed by the framework, relevant for linking with related works in multimodal learning.",
        "novelty_score": 0.5,
        "connectivity_score": 0.88,
        "specificity_score": 0.78,
        "link_intent_score": 0.77
      },
      {
        "surface": "HunyuanImage 2.1 model",
        "canonical": "HunyuanImage 2.1 Model",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Specific model used for experiments, important for contextualizing results and comparisons.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "prompt",
      "method",
      "framework"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "text-to-image diffusion models",
      "resolved_canonical": "Text-to-Image Diffusion Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.85,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Chain-of-Thought rewriter",
      "resolved_canonical": "Chain-of-Thought Rewriter",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "AlignEvaluator",
      "resolved_canonical": "AlignEvaluator",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "image-text alignment",
      "resolved_canonical": "Image-Text Alignment",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.88,
        "specificity": 0.78,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "HunyuanImage 2.1 model",
      "resolved_canonical": "HunyuanImage 2.1 Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# PromptEnhancer: A Simple Approach to Enhance Text-to-Image Models via Chain-of-Thought Prompt Rewriting

## 📋 메타데이터

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.04545.pdf)
**Category**: cs.CV
**Published**: 2025-09-24
**ArXiv ID**: [2509.04545](https://arxiv.org/abs/2509.04545)

## 🔗 유사한 논문
- [[2025-09-22/AcT2I_ Evaluating and Improving Action Depiction in Text-to-Image Models_20250922|AcT2I: Evaluating and Improving Action Depiction in Text-to-Image Models]] (86.8% similar)
- [[2025-09-23/ComposeMe_ Attribute-Specific Image Prompts for Controllable Human Image Generation_20250923|ComposeMe: Attribute-Specific Image Prompts for Controllable Human Image Generation]] (85.2% similar)
- [[2025-09-18/Iterative Prompt Refinement for Safer Text-to-Image Generation_20250918|Iterative Prompt Refinement for Safer Text-to-Image Generation]] (85.2% similar)
- [[2025-09-24/Understanding-in-Generation_ Reinforcing Generative Capability of Unified Model via Infusing Understanding into Generation_20250924|Understanding-in-Generation: Reinforcing Generative Capability of Unified Model via Infusing Understanding into Generation]] (84.8% similar)
- [[2025-09-22/RespoDiff_ Dual-Module Bottleneck Transformation for Responsible & Faithful T2I Generation_20250922|RespoDiff: Dual-Module Bottleneck Transformation for Responsible & Faithful T2I Generation]] (84.3% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Text-to-Image Diffusion Models|Text-to-Image Diffusion Models]], [[keywords/Image-Text Alignment|Image-Text Alignment]]
**⚡ Unique Technical**: [[keywords/Chain-of-Thought Rewriter|Chain-of-Thought Rewriter]], [[keywords/AlignEvaluator|AlignEvaluator]], [[keywords/HunyuanImage 2.1 Model|HunyuanImage 2.1 Model]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.04545v5 Announce Type: replace 
Abstract: Recent advancements in text-to-image (T2I) diffusion models have demonstrated remarkable capabilities in generating high-fidelity images. However, these models often struggle to faithfully render complex user prompts, particularly in aspects like attribute binding, negation, and compositional relationships. This leads to a significant mismatch between user intent and the generated output. To address this challenge, we introduce PromptEnhancer, a novel and universal prompt rewriting framework that enhances any pretrained T2I model without requiring modifications to its weights. Unlike prior methods that rely on model-specific fine-tuning or implicit reward signals like image-reward scores, our framework decouples the rewriter from the generator. We achieve this by training a Chain-of-Thought (CoT) rewriter through reinforcement learning, guided by a dedicated reward model we term the AlignEvaluator. The AlignEvaluator is trained to provide explicit and fine-grained feedback based on a systematic taxonomy of 24 key points, which are derived from a comprehensive analysis of common T2I failure modes. By optimizing the CoT rewriter to maximize the reward from our AlignEvaluator, our framework learns to generate prompts that are more precisely interpreted by T2I models. Extensive experiments on the HunyuanImage 2.1 model demonstrate that PromptEnhancer significantly improves image-text alignment across a wide range of semantic and compositional challenges. Furthermore, we introduce a new, high-quality human preference benchmark to facilitate future research in this direction.

## 📝 요약

최근 텍스트-이미지 변환(T2I) 확산 모델은 고품질 이미지 생성에서 뛰어난 성능을 보였지만, 복잡한 사용자 프롬프트를 정확히 반영하는 데 어려움을 겪고 있습니다. 이러한 문제를 해결하기 위해, 우리는 PromptEnhancer라는 새로운 프롬프트 재작성 프레임워크를 제안합니다. 이 프레임워크는 사전 학습된 T2I 모델의 가중치를 변경하지 않고도 성능을 향상시킵니다. 기존 방법과 달리, PromptEnhancer는 생성기와 재작성기를 분리하여, 강화 학습을 통해 Chain-of-Thought(CoT) 재작성기를 훈련합니다. AlignEvaluator라는 보상 모델을 통해 24가지 주요 실패 모드에 대한 체계적인 분석을 기반으로 세밀한 피드백을 제공합니다. 이를 통해, T2I 모델이 프롬프트를 더 정확히 해석하도록 최적화합니다. HunyuanImage 2.1 모델을 대상으로 한 실험에서 PromptEnhancer는 이미지-텍스트 정렬을 크게 개선했으며, 향후 연구를 위한 새로운 인간 선호도 벤치마크도 도입했습니다.

## 🎯 주요 포인트

- 1. 최신 텍스트-이미지 변환 확산 모델은 고품질 이미지를 생성할 수 있지만, 복잡한 사용자 프롬프트를 충실히 반영하는 데 어려움을 겪습니다.
- 2. PromptEnhancer는 사전 학습된 T2I 모델의 가중치를 변경하지 않고도 프롬프트를 개선하는 새로운 프레임워크입니다.
- 3. 이 프레임워크는 Chain-of-Thought 재작성기를 강화 학습으로 훈련하여, AlignEvaluator라는 보상 모델을 통해 명시적이고 세밀한 피드백을 제공합니다.
- 4. PromptEnhancer는 HunyuanImage 2.1 모델 실험에서 이미지-텍스트 정렬을 크게 개선하는 것으로 나타났습니다.
- 5. 향후 연구를 지원하기 위해 새로운 고품질 인간 선호 벤치마크를 도입했습니다.


---

*Generated on 2025-09-24 16:32:47*