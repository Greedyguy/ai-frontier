<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T13:24:39.854047",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Chain-of-Thought Reasoning",
    "Model Quantization",
    "Length Controlled Policy Optimization"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.8,
    "Chain-of-Thought Reasoning": 0.78,
    "Model Quantization": 0.72,
    "Length Controlled Policy Optimization": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "reasoning language models",
        "canonical": "Large Language Model",
        "aliases": [
          "reasoning models"
        ],
        "category": "broad_technical",
        "rationale": "Links to existing knowledge on large language models and their reasoning capabilities.",
        "novelty_score": 0.3,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "chain-of-thought sequences",
        "canonical": "Chain-of-Thought Reasoning",
        "aliases": [
          "CoT sequences"
        ],
        "category": "unique_technical",
        "rationale": "Represents a specific reasoning approach that is central to the paper's focus.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "model quantization",
        "canonical": "Model Quantization",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "A key technique discussed for reducing computational demand, relevant to efficiency studies.",
        "novelty_score": 0.55,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.72
      },
      {
        "surface": "length controlled policy optimization",
        "canonical": "Length Controlled Policy Optimization",
        "aliases": [
          "LCPO"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a specific optimization method relevant to the study's methodology.",
        "novelty_score": 0.8,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "compute constraint",
      "safety performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "reasoning language models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "chain-of-thought sequences",
      "resolved_canonical": "Chain-of-Thought Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "model quantization",
      "resolved_canonical": "Model Quantization",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "length controlled policy optimization",
      "resolved_canonical": "Length Controlled Policy Optimization",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Evaluating the Safety and Skill Reasoning of Large Reasoning Models Under Compute Constraints

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18382.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2509.18382](https://arxiv.org/abs/2509.18382)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/Early Stopping Chain-of-thoughts in Large Language Models_20250918|Early Stopping Chain-of-thoughts in Large Language Models]] (87.1% similar)
- [[2025-09-17/Reasoning Efficiently Through Adaptive Chain-of-Thought Compression_ A Self-Optimizing Framework_20250917|Reasoning Efficiently Through Adaptive Chain-of-Thought Compression: A Self-Optimizing Framework]] (86.5% similar)
- [[2025-09-22/ConCISE_ Confidence-guided Compression in Step-by-step Efficient Reasoning_20250922|ConCISE: Confidence-guided Compression in Step-by-step Efficient Reasoning]] (85.9% similar)
- [[2025-09-23/LTA-thinker_ Latent Thought-Augmented Training Framework for Large Language Models on Complex Reasoning_20250923|LTA-thinker: Latent Thought-Augmented Training Framework for Large Language Models on Complex Reasoning]] (85.7% similar)
- [[2025-09-23/Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates_20250923|Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates]] (84.4% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Model Quantization|Model Quantization]]
**âš¡ Unique Technical**: [[keywords/Chain-of-Thought Reasoning|Chain-of-Thought Reasoning]], [[keywords/Length Controlled Policy Optimization|Length Controlled Policy Optimization]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18382v1 Announce Type: new 
Abstract: Test-time compute scaling has demonstrated the ability to improve the performance of reasoning language models by generating longer chain-of-thought (CoT) sequences. However, this increase in performance comes with a significant increase in computational cost. In this work, we investigate two compute constraint strategies: (1) reasoning length constraint and (2) model quantization, as methods to reduce the compute demand of reasoning models and study their impact on their safety performance. Specifically, we explore two approaches to apply compute constraints to reasoning models: (1) fine-tuning reasoning models using a length controlled policy optimization (LCPO) based reinforcement learning method to satisfy a user-defined CoT reasoning length, and (2) applying quantization to maximize the generation of CoT sequences within a user-defined compute constraint. Furthermore, we study the trade-off between the computational efficiency and the safety of the model.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” ì¶”ë¡  ì–¸ì–´ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ê¸´ ì‚¬ê³  ê³¼ì •(Chain-of-Thought, CoT) ì‹œí€€ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” í…ŒìŠ¤íŠ¸ ì‹œì  ê³„ì‚° í™•ì¥ì´ ì„±ëŠ¥ì„ ë†’ì´ì§€ë§Œ, ê³„ì‚° ë¹„ìš©ì´ í¬ê²Œ ì¦ê°€í•˜ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê³ ì í•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ë‘ ê°€ì§€ ê³„ì‚° ì œì•½ ì „ëµì„ ì œì•ˆí•©ë‹ˆë‹¤: (1) ì¶”ë¡  ê¸¸ì´ ì œì•½ê³¼ (2) ëª¨ë¸ ì–‘ìí™”. ì²« ë²ˆì§¸ ë°©ë²•ì€ ê¸¸ì´ ì œì–´ ì •ì±… ìµœì í™”(LCPO) ê¸°ë°˜ ê°•í™” í•™ìŠµì„ í†µí•´ ì‚¬ìš©ì ì •ì˜ CoT ì¶”ë¡  ê¸¸ì´ë¥¼ ë§Œì¡±ì‹œí‚¤ë„ë¡ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ëŠ” ê²ƒì´ê³ , ë‘ ë²ˆì§¸ ë°©ë²•ì€ ì‚¬ìš©ì ì •ì˜ ê³„ì‚° ì œì•½ ë‚´ì—ì„œ CoT ì‹œí€€ìŠ¤ ìƒì„±ì„ ìµœëŒ€í™”í•˜ê¸° ìœ„í•´ ì–‘ìí™”ë¥¼ ì ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì—°êµ¬ëŠ” ê³„ì‚° íš¨ìœ¨ì„±ê³¼ ëª¨ë¸ ì•ˆì „ì„± ê°„ì˜ ê· í˜•ì„ ë¶„ì„í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. í…ŒìŠ¤íŠ¸ ì‹œ ê³„ì‚° í™•ì¥ì€ ë” ê¸´ ì‚¬ê³ ì˜ íë¦„(CoT) ì‹œí€€ìŠ¤ë¥¼ ìƒì„±í•˜ì—¬ ì¶”ë¡  ì–¸ì–´ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- 2. ì„±ëŠ¥ í–¥ìƒì€ ê³„ì‚° ë¹„ìš©ì˜ ì¦ê°€ë¥¼ ë™ë°˜í•˜ë©°, ì´ë¥¼ ì¤„ì´ê¸° ìœ„í•´ ë‘ ê°€ì§€ ê³„ì‚° ì œì•½ ì „ëµì„ ì¡°ì‚¬í•©ë‹ˆë‹¤: ì¶”ë¡  ê¸¸ì´ ì œì•½ê³¼ ëª¨ë¸ ì–‘ìí™”.
- 3. ê¸¸ì´ ì œì–´ ì •ì±… ìµœì í™”(LCPO) ê¸°ë°˜ ê°•í™” í•™ìŠµ ë°©ë²•ì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì •ì˜ CoT ì¶”ë¡  ê¸¸ì´ë¥¼ ë§Œì¡±ì‹œí‚¤ë„ë¡ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•©ë‹ˆë‹¤.
- 4. ì‚¬ìš©ì ì •ì˜ ê³„ì‚° ì œì•½ ë‚´ì—ì„œ CoT ì‹œí€€ìŠ¤ ìƒì„±ì„ ê·¹ëŒ€í™”í•˜ê¸° ìœ„í•´ ì–‘ìí™”ë¥¼ ì ìš©í•©ë‹ˆë‹¤.
- 5. ê³„ì‚° íš¨ìœ¨ì„±ê³¼ ëª¨ë¸ì˜ ì•ˆì „ì„± ê°„ì˜ ê· í˜•ì„ ì—°êµ¬í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 13:24:39*