<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T16:12:21.928516",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Explainable Artificial Intelligence",
    "Saliency Maps",
    "Concept Bottleneck Models",
    "Prototype-based Methods",
    "Hybrid Approaches in xAI"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Explainable Artificial Intelligence": 0.9,
    "Saliency Maps": 0.88,
    "Concept Bottleneck Models": 0.8,
    "Prototype-based Methods": 0.82,
    "Hybrid Approaches in xAI": 0.84
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "xAI",
        "canonical": "Explainable Artificial Intelligence",
        "aliases": [
          "xAI",
          "Explainable AI"
        ],
        "category": "evolved_concepts",
        "rationale": "Explainable Artificial Intelligence is a rapidly evolving field crucial for understanding AI decision-making processes.",
        "novelty_score": 0.75,
        "connectivity_score": 0.85,
        "specificity_score": 0.8,
        "link_intent_score": 0.9
      },
      {
        "surface": "Saliency Maps",
        "canonical": "Saliency Maps",
        "aliases": [
          "Saliency Visualization",
          "Attention Maps"
        ],
        "category": "specific_connectable",
        "rationale": "Saliency Maps are a specific technique in xAI that helps visualize which parts of an image influence AI decisions.",
        "novelty_score": 0.65,
        "connectivity_score": 0.78,
        "specificity_score": 0.82,
        "link_intent_score": 0.88
      },
      {
        "surface": "Concept Bottleneck Models",
        "canonical": "Concept Bottleneck Models",
        "aliases": [
          "CBM",
          "Concept Bottleneck"
        ],
        "category": "unique_technical",
        "rationale": "Concept Bottleneck Models offer a unique approach to interpretability by linking model predictions to human-understandable concepts.",
        "novelty_score": 0.7,
        "connectivity_score": 0.72,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Prototype-based methods",
        "canonical": "Prototype-based Methods",
        "aliases": [
          "Prototype Methods",
          "Prototype Models"
        ],
        "category": "specific_connectable",
        "rationale": "Prototype-based methods provide interpretability by comparing inputs to learned prototypes, enhancing model transparency.",
        "novelty_score": 0.68,
        "connectivity_score": 0.76,
        "specificity_score": 0.79,
        "link_intent_score": 0.82
      },
      {
        "surface": "Hybrid approaches",
        "canonical": "Hybrid Approaches in xAI",
        "aliases": [
          "Hybrid xAI Methods",
          "Mixed xAI Techniques"
        ],
        "category": "unique_technical",
        "rationale": "Hybrid approaches combine multiple xAI techniques to improve interpretability and are a growing area of research.",
        "novelty_score": 0.72,
        "connectivity_score": 0.74,
        "specificity_score": 0.77,
        "link_intent_score": 0.84
      }
    ],
    "ban_list_suggestions": [
      "Deep Learning",
      "Image Analysis"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "xAI",
      "resolved_canonical": "Explainable Artificial Intelligence",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.85,
        "specificity": 0.8,
        "link_intent": 0.9
      }
    },
    {
      "candidate_surface": "Saliency Maps",
      "resolved_canonical": "Saliency Maps",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.78,
        "specificity": 0.82,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "Concept Bottleneck Models",
      "resolved_canonical": "Concept Bottleneck Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.72,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Prototype-based methods",
      "resolved_canonical": "Prototype-based Methods",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.76,
        "specificity": 0.79,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Hybrid approaches",
      "resolved_canonical": "Hybrid Approaches in xAI",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.74,
        "specificity": 0.77,
        "link_intent": 0.84
      }
    }
  ]
}
-->

# xAI-CV: An Overview of Explainable Artificial Intelligence in Computer Vision

## 📋 메타데이터

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18913.pdf)
**Category**: cs.CV
**Published**: 2025-09-24
**ArXiv ID**: [2509.18913](https://arxiv.org/abs/2509.18913)

## 🔗 유사한 논문
- [[2025-09-23/Towards a Transparent and Interpretable AI Model for Medical Image Classifications_20250923|Towards a Transparent and Interpretable AI Model for Medical Image Classifications]] (87.4% similar)
- [[2025-09-23/See What I Mean? CUE_ A Cognitive Model of Understanding Explanations_20250923|See What I Mean? CUE: A Cognitive Model of Understanding Explanations]] (84.6% similar)
- [[2025-09-22/Shedding Light on Depth_ Explainability Assessment in Monocular Depth Estimation_20250922|Shedding Light on Depth: Explainability Assessment in Monocular Depth Estimation]] (84.0% similar)
- [[2025-09-18/From Sea to System_ Exploring User-Centered Explainable AI for Maritime Decision Support_20250918|From Sea to System: Exploring User-Centered Explainable AI for Maritime Decision Support]] (82.2% similar)
- [[2025-09-24/Explainable artificial intelligence (XAI) for scaling_ An application for deducing hydrologic connectivity at watershed scale_20250924|Explainable artificial intelligence (XAI) for scaling: An application for deducing hydrologic connectivity at watershed scale]] (82.1% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Saliency Maps|Saliency Maps]], [[keywords/Prototype-based Methods|Prototype-based Methods]]
**⚡ Unique Technical**: [[keywords/Concept Bottleneck Models|Concept Bottleneck Models]], [[keywords/Hybrid Approaches in xAI|Hybrid Approaches in xAI]]
**🚀 Evolved Concepts**: [[keywords/Explainable Artificial Intelligence|Explainable Artificial Intelligence]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.18913v1 Announce Type: new 
Abstract: Deep learning has become the de facto standard and dominant paradigm in image analysis tasks, achieving state-of-the-art performance. However, this approach often results in "black-box" models, whose decision-making processes are difficult to interpret, raising concerns about reliability in critical applications. To address this challenge and provide human a method to understand how AI model process and make decision, the field of xAI has emerged. This paper surveys four representative approaches in xAI for visual perception tasks: (i) Saliency Maps, (ii) Concept Bottleneck Models (CBM), (iii) Prototype-based methods, and (iv) Hybrid approaches. We analyze their underlying mechanisms, strengths and limitations, as well as evaluation metrics, thereby providing a comprehensive overview to guide future research and applications.

## 📝 요약

이 논문은 이미지 분석 작업에서 딥러닝의 "블랙박스" 문제를 해결하기 위해 등장한 설명 가능한 인공지능(xAI)의 네 가지 대표적 접근법을 조사합니다. 살리언시 맵, 개념 병목 모델(CBM), 프로토타입 기반 방법, 하이브리드 접근법을 다루며, 각 방법의 메커니즘, 장단점, 평가 지표를 분석합니다. 이를 통해 xAI의 미래 연구와 응용을 위한 포괄적인 개요를 제공합니다.

## 🎯 주요 포인트

- 1. 딥러닝은 이미지 분석 작업에서 사실상의 표준이자 지배적인 패러다임이 되었지만, "블랙박스" 모델로 인해 의사 결정 과정을 해석하기 어려운 문제가 있다.
- 2. xAI(설명 가능한 인공지능)는 AI 모델의 처리 및 의사 결정 과정을 이해할 수 있는 방법을 제공하기 위해 등장했다.
- 3. 이 논문은 시각적 인식 작업에서의 xAI의 네 가지 대표적인 접근법인 (i) 주목 지도, (ii) 개념 병목 모델, (iii) 프로토타입 기반 방법, (iv) 하이브리드 접근법을 조사한다.
- 4. 각 접근법의 기본 메커니즘, 강점과 한계, 평가 지표를 분석하여 미래 연구 및 응용을 위한 포괄적인 개요를 제공한다.


---

*Generated on 2025-09-24 16:12:21*