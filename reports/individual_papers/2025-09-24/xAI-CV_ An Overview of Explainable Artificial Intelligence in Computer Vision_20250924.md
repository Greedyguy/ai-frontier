<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T16:12:21.928516",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Explainable Artificial Intelligence",
    "Saliency Maps",
    "Concept Bottleneck Models",
    "Prototype-based Methods",
    "Hybrid Approaches in xAI"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Explainable Artificial Intelligence": 0.9,
    "Saliency Maps": 0.88,
    "Concept Bottleneck Models": 0.8,
    "Prototype-based Methods": 0.82,
    "Hybrid Approaches in xAI": 0.84
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "xAI",
        "canonical": "Explainable Artificial Intelligence",
        "aliases": [
          "xAI",
          "Explainable AI"
        ],
        "category": "evolved_concepts",
        "rationale": "Explainable Artificial Intelligence is a rapidly evolving field crucial for understanding AI decision-making processes.",
        "novelty_score": 0.75,
        "connectivity_score": 0.85,
        "specificity_score": 0.8,
        "link_intent_score": 0.9
      },
      {
        "surface": "Saliency Maps",
        "canonical": "Saliency Maps",
        "aliases": [
          "Saliency Visualization",
          "Attention Maps"
        ],
        "category": "specific_connectable",
        "rationale": "Saliency Maps are a specific technique in xAI that helps visualize which parts of an image influence AI decisions.",
        "novelty_score": 0.65,
        "connectivity_score": 0.78,
        "specificity_score": 0.82,
        "link_intent_score": 0.88
      },
      {
        "surface": "Concept Bottleneck Models",
        "canonical": "Concept Bottleneck Models",
        "aliases": [
          "CBM",
          "Concept Bottleneck"
        ],
        "category": "unique_technical",
        "rationale": "Concept Bottleneck Models offer a unique approach to interpretability by linking model predictions to human-understandable concepts.",
        "novelty_score": 0.7,
        "connectivity_score": 0.72,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Prototype-based methods",
        "canonical": "Prototype-based Methods",
        "aliases": [
          "Prototype Methods",
          "Prototype Models"
        ],
        "category": "specific_connectable",
        "rationale": "Prototype-based methods provide interpretability by comparing inputs to learned prototypes, enhancing model transparency.",
        "novelty_score": 0.68,
        "connectivity_score": 0.76,
        "specificity_score": 0.79,
        "link_intent_score": 0.82
      },
      {
        "surface": "Hybrid approaches",
        "canonical": "Hybrid Approaches in xAI",
        "aliases": [
          "Hybrid xAI Methods",
          "Mixed xAI Techniques"
        ],
        "category": "unique_technical",
        "rationale": "Hybrid approaches combine multiple xAI techniques to improve interpretability and are a growing area of research.",
        "novelty_score": 0.72,
        "connectivity_score": 0.74,
        "specificity_score": 0.77,
        "link_intent_score": 0.84
      }
    ],
    "ban_list_suggestions": [
      "Deep Learning",
      "Image Analysis"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "xAI",
      "resolved_canonical": "Explainable Artificial Intelligence",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.85,
        "specificity": 0.8,
        "link_intent": 0.9
      }
    },
    {
      "candidate_surface": "Saliency Maps",
      "resolved_canonical": "Saliency Maps",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.78,
        "specificity": 0.82,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "Concept Bottleneck Models",
      "resolved_canonical": "Concept Bottleneck Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.72,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Prototype-based methods",
      "resolved_canonical": "Prototype-based Methods",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.76,
        "specificity": 0.79,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Hybrid approaches",
      "resolved_canonical": "Hybrid Approaches in xAI",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.74,
        "specificity": 0.77,
        "link_intent": 0.84
      }
    }
  ]
}
-->

# xAI-CV: An Overview of Explainable Artificial Intelligence in Computer Vision

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18913.pdf)
**Category**: cs.CV
**Published**: 2025-09-24
**ArXiv ID**: [2509.18913](https://arxiv.org/abs/2509.18913)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Towards a Transparent and Interpretable AI Model for Medical Image Classifications_20250923|Towards a Transparent and Interpretable AI Model for Medical Image Classifications]] (87.4% similar)
- [[2025-09-23/See What I Mean? CUE_ A Cognitive Model of Understanding Explanations_20250923|See What I Mean? CUE: A Cognitive Model of Understanding Explanations]] (84.6% similar)
- [[2025-09-22/Shedding Light on Depth_ Explainability Assessment in Monocular Depth Estimation_20250922|Shedding Light on Depth: Explainability Assessment in Monocular Depth Estimation]] (84.0% similar)
- [[2025-09-18/From Sea to System_ Exploring User-Centered Explainable AI for Maritime Decision Support_20250918|From Sea to System: Exploring User-Centered Explainable AI for Maritime Decision Support]] (82.2% similar)
- [[2025-09-24/Explainable artificial intelligence (XAI) for scaling_ An application for deducing hydrologic connectivity at watershed scale_20250924|Explainable artificial intelligence (XAI) for scaling: An application for deducing hydrologic connectivity at watershed scale]] (82.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Saliency Maps|Saliency Maps]], [[keywords/Prototype-based Methods|Prototype-based Methods]]
**âš¡ Unique Technical**: [[keywords/Concept Bottleneck Models|Concept Bottleneck Models]], [[keywords/Hybrid Approaches in xAI|Hybrid Approaches in xAI]]
**ğŸš€ Evolved Concepts**: [[keywords/Explainable Artificial Intelligence|Explainable Artificial Intelligence]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18913v1 Announce Type: new 
Abstract: Deep learning has become the de facto standard and dominant paradigm in image analysis tasks, achieving state-of-the-art performance. However, this approach often results in "black-box" models, whose decision-making processes are difficult to interpret, raising concerns about reliability in critical applications. To address this challenge and provide human a method to understand how AI model process and make decision, the field of xAI has emerged. This paper surveys four representative approaches in xAI for visual perception tasks: (i) Saliency Maps, (ii) Concept Bottleneck Models (CBM), (iii) Prototype-based methods, and (iv) Hybrid approaches. We analyze their underlying mechanisms, strengths and limitations, as well as evaluation metrics, thereby providing a comprehensive overview to guide future research and applications.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì´ë¯¸ì§€ ë¶„ì„ ì‘ì—…ì—ì„œ ë”¥ëŸ¬ë‹ì˜ "ë¸”ë™ë°•ìŠ¤" ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë“±ì¥í•œ ì„¤ëª… ê°€ëŠ¥í•œ ì¸ê³µì§€ëŠ¥(xAI)ì˜ ë„¤ ê°€ì§€ ëŒ€í‘œì  ì ‘ê·¼ë²•ì„ ì¡°ì‚¬í•©ë‹ˆë‹¤. ì‚´ë¦¬ì–¸ì‹œ ë§µ, ê°œë… ë³‘ëª© ëª¨ë¸(CBM), í”„ë¡œí† íƒ€ì… ê¸°ë°˜ ë°©ë²•, í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ë²•ì„ ë‹¤ë£¨ë©°, ê° ë°©ë²•ì˜ ë©”ì»¤ë‹ˆì¦˜, ì¥ë‹¨ì , í‰ê°€ ì§€í‘œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ xAIì˜ ë¯¸ë˜ ì—°êµ¬ì™€ ì‘ìš©ì„ ìœ„í•œ í¬ê´„ì ì¸ ê°œìš”ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë”¥ëŸ¬ë‹ì€ ì´ë¯¸ì§€ ë¶„ì„ ì‘ì—…ì—ì„œ ì‚¬ì‹¤ìƒì˜ í‘œì¤€ì´ì ì§€ë°°ì ì¸ íŒ¨ëŸ¬ë‹¤ì„ì´ ë˜ì—ˆì§€ë§Œ, "ë¸”ë™ë°•ìŠ¤" ëª¨ë¸ë¡œ ì¸í•´ ì˜ì‚¬ ê²°ì • ê³¼ì •ì„ í•´ì„í•˜ê¸° ì–´ë ¤ìš´ ë¬¸ì œê°€ ìˆë‹¤.
- 2. xAI(ì„¤ëª… ê°€ëŠ¥í•œ ì¸ê³µì§€ëŠ¥)ëŠ” AI ëª¨ë¸ì˜ ì²˜ë¦¬ ë° ì˜ì‚¬ ê²°ì • ê³¼ì •ì„ ì´í•´í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ì œê³µí•˜ê¸° ìœ„í•´ ë“±ì¥í–ˆë‹¤.
- 3. ì´ ë…¼ë¬¸ì€ ì‹œê°ì  ì¸ì‹ ì‘ì—…ì—ì„œì˜ xAIì˜ ë„¤ ê°€ì§€ ëŒ€í‘œì ì¸ ì ‘ê·¼ë²•ì¸ (i) ì£¼ëª© ì§€ë„, (ii) ê°œë… ë³‘ëª© ëª¨ë¸, (iii) í”„ë¡œí† íƒ€ì… ê¸°ë°˜ ë°©ë²•, (iv) í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ë²•ì„ ì¡°ì‚¬í•œë‹¤.
- 4. ê° ì ‘ê·¼ë²•ì˜ ê¸°ë³¸ ë©”ì»¤ë‹ˆì¦˜, ê°•ì ê³¼ í•œê³„, í‰ê°€ ì§€í‘œë¥¼ ë¶„ì„í•˜ì—¬ ë¯¸ë˜ ì—°êµ¬ ë° ì‘ìš©ì„ ìœ„í•œ í¬ê´„ì ì¸ ê°œìš”ë¥¼ ì œê³µí•œë‹¤.


---

*Generated on 2025-09-24 16:12:21*