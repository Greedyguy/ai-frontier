<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T14:51:35.785454",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Markov Chain Monte Carlo",
    "Graph Neural Network",
    "Bayesian Optimization",
    "Krylov Subspace Methods"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Markov Chain Monte Carlo": 0.82,
    "Graph Neural Network": 0.79,
    "Bayesian Optimization": 0.78,
    "Krylov Subspace Methods": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Markov Chain Monte Carlo",
        "canonical": "Markov Chain Monte Carlo",
        "aliases": [
          "MCMC"
        ],
        "category": "specific_connectable",
        "rationale": "MCMC is a key technique for matrix inversion and preconditioning, linking it to probabilistic methods in computational mathematics.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "Graph Neural Surrogate",
        "canonical": "Graph Neural Network",
        "aliases": [
          "GNN surrogate"
        ],
        "category": "specific_connectable",
        "rationale": "The use of a graph neural surrogate highlights the application of GNNs in predicting preconditioning speed, connecting it to neural network advancements.",
        "novelty_score": 0.68,
        "connectivity_score": 0.85,
        "specificity_score": 0.81,
        "link_intent_score": 0.79
      },
      {
        "surface": "Bayesian Acquisition Function",
        "canonical": "Bayesian Optimization",
        "aliases": [
          "Bayesian acquisition"
        ],
        "category": "unique_technical",
        "rationale": "This function is crucial for selecting optimal MCMC parameters, linking to Bayesian methods in optimization.",
        "novelty_score": 0.72,
        "connectivity_score": 0.77,
        "specificity_score": 0.83,
        "link_intent_score": 0.78
      },
      {
        "surface": "Krylov Subspace Solvers",
        "canonical": "Krylov Subspace Methods",
        "aliases": [
          "Krylov solvers"
        ],
        "category": "specific_connectable",
        "rationale": "These solvers are fundamental in solving sparse linear systems, connecting to numerical linear algebra techniques.",
        "novelty_score": 0.6,
        "connectivity_score": 0.8,
        "specificity_score": 0.75,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "AI-driven framework",
      "large-scale systems"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Markov Chain Monte Carlo",
      "resolved_canonical": "Markov Chain Monte Carlo",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Graph Neural Surrogate",
      "resolved_canonical": "Graph Neural Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.85,
        "specificity": 0.81,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Bayesian Acquisition Function",
      "resolved_canonical": "Bayesian Optimization",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.77,
        "specificity": 0.83,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Krylov Subspace Solvers",
      "resolved_canonical": "Krylov Subspace Methods",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.8,
        "specificity": 0.75,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Fast Linear Solvers via AI-Tuned Markov Chain Monte Carlo-based Matrix Inversion

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18452.pdf)
**Category**: cs.LG
**Published**: 2025-09-24
**ArXiv ID**: [2509.18452](https://arxiv.org/abs/2509.18452)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/A geometric framework for momentum-based optimizers for low-rank training_20250923|A geometric framework for momentum-based optimizers for low-rank training]] (81.0% similar)
- [[2025-09-17/Physics-based deep kernel learning for parameter estimation in high dimensional PDEs_20250917|Physics-based deep kernel learning for parameter estimation in high dimensional PDEs]] (80.6% similar)
- [[2025-09-23/Machine learning-driven conservative-to-primitive conversion in hybrid piecewise polytropic and tabulated equations of state_20250923|Machine learning-driven conservative-to-primitive conversion in hybrid piecewise polytropic and tabulated equations of state]] (80.1% similar)
- [[2025-09-23/MPIC_ Position-Independent Multimodal Context Caching System for Efficient MLLM Serving_20250923|MPIC: Position-Independent Multimodal Context Caching System for Efficient MLLM Serving]] (79.8% similar)
- [[2025-09-23/MCP_ A Control-Theoretic Orchestration Framework for Synergistic Efficiency and Interpretability in Multimodal Large Language Models_20250923|MCP: A Control-Theoretic Orchestration Framework for Synergistic Efficiency and Interpretability in Multimodal Large Language Models]] (79.4% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Markov Chain Monte Carlo|Markov Chain Monte Carlo]], [[keywords/Graph Neural Network|Graph Neural Network]], [[keywords/Krylov Subspace Methods|Krylov Subspace Methods]]
**âš¡ Unique Technical**: [[keywords/Bayesian Optimization|Bayesian Optimization]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18452v1 Announce Type: new 
Abstract: Large, sparse linear systems are pervasive in modern science and engineering, and Krylov subspace solvers are an established means of solving them. Yet convergence can be slow for ill-conditioned matrices, so practical deployments usually require preconditioners. Markov chain Monte Carlo (MCMC)-based matrix inversion can generate such preconditioners and accelerate Krylov iterations, but its effectiveness depends on parameters whose optima vary across matrices; manual or grid search is costly. We present an AI-driven framework recommending MCMC parameters for a given linear system. A graph neural surrogate predicts preconditioning speed from $A$ and MCMC parameters. A Bayesian acquisition function then chooses the parameter sets most likely to minimise iterations. On a previously unseen ill-conditioned system, the framework achieves better preconditioning with 50\% of the search budget of conventional methods, yielding about a 10\% reduction in iterations to convergence. These results suggest a route for incorporating MCMC-based preconditioners into large-scale systems.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€ê·œëª¨ í¬ì†Œ ì„ í˜• ì‹œìŠ¤í…œì„ í•´ê²°í•˜ê¸° ìœ„í•œ AI ê¸°ë°˜ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. Krylov ë¶€ë¶„ ê³µê°„ í•´ë²•ì€ ì´ëŸ¬í•œ ì‹œìŠ¤í…œì„ í•´ê²°í•˜ëŠ” ë° ë„ë¦¬ ì‚¬ìš©ë˜ì§€ë§Œ, ì¡°ê±´ì´ ë‚˜ìœ í–‰ë ¬ì—ì„œëŠ” ìˆ˜ë ´ì´ ëŠë ¤ì§ˆ ìˆ˜ ìˆì–´ ì „ì²˜ë¦¬ê¸°ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì €ìë“¤ì€ MCMC ê¸°ë°˜ì˜ í–‰ë ¬ ë°˜ì „ì„ í†µí•´ ì „ì²˜ë¦¬ê¸°ë¥¼ ìƒì„±í•˜ê³  Krylov ë°˜ë³µì„ ê°€ì†í™”í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ MCMCì˜ íš¨ê³¼ëŠ” í–‰ë ¬ì— ë”°ë¼ ìµœì ì˜ ë§¤ê°œë³€ìˆ˜ê°€ ë‹¬ë¼ì§€ë¯€ë¡œ, ì´ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì°¾ëŠ” ê²ƒì€ ë¹„ìš©ì´ ë§ì´ ë“­ë‹ˆë‹¤. ì œì•ˆëœ í”„ë ˆì„ì›Œí¬ëŠ” ê·¸ë˜í”„ ì‹ ê²½ë§ì„ í†µí•´ ì „ì²˜ë¦¬ ì†ë„ë¥¼ ì˜ˆì¸¡í•˜ê³ , ë² ì´ì§€ì•ˆ íšë“ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ ë°˜ë³µ íšŸìˆ˜ë¥¼ ìµœì†Œí™”í•  ìˆ˜ ìˆëŠ” ë§¤ê°œë³€ìˆ˜ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ê¸°ì¡´ ë°©ë²• ëŒ€ë¹„ 50% ì ì€ íƒìƒ‰ ë¹„ìš©ìœ¼ë¡œ ì•½ 10%ì˜ ë°˜ë³µ íšŸìˆ˜ ê°ì†Œë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ëŒ€ê·œëª¨ ì‹œìŠ¤í…œì—ì„œ MCMC ê¸°ë°˜ ì „ì²˜ë¦¬ê¸°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í†µí•©í•  ìˆ˜ ìˆëŠ” ê°€ëŠ¥ì„±ì„ ì œì‹œí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• í¬ì†Œ ì„ í˜• ì‹œìŠ¤í…œì—ì„œ Krylov ë¶€ë¶„ ê³µê°„ í•´ë²•ì˜ ìˆ˜ë ´ ì†ë„ë¥¼ ê°œì„ í•˜ê¸° ìœ„í•´ MCMC ê¸°ë°˜ í–‰ë ¬ ì—­í–‰ë ¬ì´ ì‚¬ìš©ë  ìˆ˜ ìˆë‹¤.
- 2. MCMC ê¸°ë°˜ ì „ì²˜ë¦¬ê¸°ì˜ íš¨ê³¼ëŠ” í–‰ë ¬ì— ë”°ë¼ ìµœì ì˜ íŒŒë¼ë¯¸í„°ê°€ ë‹¬ë¼ì§€ë©°, ì´ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì°¾ê±°ë‚˜ ê·¸ë¦¬ë“œ íƒìƒ‰í•˜ëŠ” ê²ƒì€ ë¹„ìš©ì´ ë§ì´ ë“ ë‹¤.
- 3. ì œì•ˆëœ AI ê¸°ë°˜ í”„ë ˆì„ì›Œí¬ëŠ” ì£¼ì–´ì§„ ì„ í˜• ì‹œìŠ¤í…œì— ëŒ€í•´ MCMC íŒŒë¼ë¯¸í„°ë¥¼ ì¶”ì²œí•˜ì—¬, ìˆ˜ë ´ì„ ìœ„í•œ ë°˜ë³µ íšŸìˆ˜ë¥¼ ì¤„ì¸ë‹¤.
- 4. ê·¸ë˜í”„ ì‹ ê²½ë§ ëŒ€ë¦¬ ëª¨ë¸ì´ í–‰ë ¬ $A$ì™€ MCMC íŒŒë¼ë¯¸í„°ë¡œë¶€í„° ì „ì²˜ë¦¬ ì†ë„ë¥¼ ì˜ˆì¸¡í•˜ê³ , ë² ì´ì§€ì•ˆ íšë“ í•¨ìˆ˜ê°€ ë°˜ë³µ íšŸìˆ˜ë¥¼ ìµœì†Œí™”í•  ê°€ëŠ¥ì„±ì´ ë†’ì€ íŒŒë¼ë¯¸í„° ì„¸íŠ¸ë¥¼ ì„ íƒí•œë‹¤.
- 5. ìƒˆë¡œìš´ ì•…ì¡°ê±´ ì‹œìŠ¤í…œì—ì„œ í”„ë ˆì„ì›Œí¬ëŠ” ê¸°ì¡´ ë°©ë²•ì˜ íƒìƒ‰ ì˜ˆì‚°ì˜ 50%ë¡œ ë” ë‚˜ì€ ì „ì²˜ë¦¬ë¥¼ ë‹¬ì„±í•˜ë©°, ì•½ 10%ì˜ ìˆ˜ë ´ ë°˜ë³µ íšŸìˆ˜ ê°ì†Œë¥¼ ì´ëŒì–´ë‚¸ë‹¤.


---

*Generated on 2025-09-24 14:51:35*