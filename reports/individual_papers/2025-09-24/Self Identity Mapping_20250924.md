<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T15:06:05.106211",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Self Identity Mapping",
    "Deep Learning",
    "Few-Shot Learning",
    "Domain Generalization",
    "Semantic Segmentation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Self Identity Mapping": 0.8,
    "Deep Learning": 0.7,
    "Few-Shot Learning": 0.78,
    "Domain Generalization": 0.72,
    "Semantic Segmentation": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Self Identity Mapping",
        "canonical": "Self Identity Mapping",
        "aliases": [
          "SIM"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel regularization framework that can be linked to discussions on model generalization and regularization techniques.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "Deep Learning",
        "canonical": "Deep Learning",
        "aliases": [],
        "category": "broad_technical",
        "rationale": "Provides a foundational context for the proposed regularization framework within the field of deep learning.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.5,
        "link_intent_score": 0.7
      },
      {
        "surface": "Few-Shot Prompt Learning",
        "canonical": "Few-Shot Learning",
        "aliases": [
          "Few-Shot Prompt Learning"
        ],
        "category": "specific_connectable",
        "rationale": "Connects to the trending topic of few-shot learning, emphasizing the method's applicability in this area.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Domain Generalization",
        "canonical": "Domain Generalization",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Highlights the method's effectiveness across different domains, making it relevant for discussions on generalization.",
        "novelty_score": 0.6,
        "connectivity_score": 0.7,
        "specificity_score": 0.75,
        "link_intent_score": 0.72
      },
      {
        "surface": "Semantic Segmentation",
        "canonical": "Semantic Segmentation",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Links to applications in computer vision, showing the method's impact on dense-to-dense tasks.",
        "novelty_score": 0.5,
        "connectivity_score": 0.8,
        "specificity_score": 0.7,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "regularization",
      "method",
      "performance",
      "experiment"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Self Identity Mapping",
      "resolved_canonical": "Self Identity Mapping",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Deep Learning",
      "resolved_canonical": "Deep Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.5,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Few-Shot Prompt Learning",
      "resolved_canonical": "Few-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Domain Generalization",
      "resolved_canonical": "Domain Generalization",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.7,
        "specificity": 0.75,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "Semantic Segmentation",
      "resolved_canonical": "Semantic Segmentation",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.8,
        "specificity": 0.7,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# Self Identity Mapping

## 📋 메타데이터

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18165.pdf)
**Category**: cs.LG
**Published**: 2025-09-24
**ArXiv ID**: [2509.18165](https://arxiv.org/abs/2509.18165)

## 🔗 유사한 논문
- [[2025-09-23/A Novel Metric for Detecting Memorization in Generative Models for Brain MRI Synthesis_20250923|A Novel Metric for Detecting Memorization in Generative Models for Brain MRI Synthesis]] (80.6% similar)
- [[2025-09-22/RespoDiff_ Dual-Module Bottleneck Transformation for Responsible & Faithful T2I Generation_20250922|RespoDiff: Dual-Module Bottleneck Transformation for Responsible & Faithful T2I Generation]] (80.4% similar)
- [[2025-09-23/A non-smooth regularization framework for learning over multitask graphs_20250923|A non-smooth regularization framework for learning over multitask graphs]] (80.4% similar)
- [[2025-09-23/CARINOX_ Inference-time Scaling with Category-Aware Reward-based Initial Noise Optimization and Exploration_20250923|CARINOX: Inference-time Scaling with Category-Aware Reward-based Initial Noise Optimization and Exploration]] (80.1% similar)
- [[2025-09-23/Inceptive Transformers_ Enhancing Contextual Representations through Multi-Scale Feature Learning Across Domains and Languages_20250923|Inceptive Transformers: Enhancing Contextual Representations through Multi-Scale Feature Learning Across Domains and Languages]] (80.1% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Deep Learning|Deep Learning]]
**🔗 Specific Connectable**: [[keywords/Few-Shot Learning|Few-Shot Learning]], [[keywords/Domain Generalization|Domain Generalization]], [[keywords/Semantic Segmentation|Semantic Segmentation]]
**⚡ Unique Technical**: [[keywords/Self Identity Mapping|Self Identity Mapping]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.18165v1 Announce Type: cross 
Abstract: Regularization is essential in deep learning to enhance generalization and mitigate overfitting. However, conventional techniques often rely on heuristics, making them less reliable or effective across diverse settings. We propose Self Identity Mapping (SIM), a simple yet effective, data-intrinsic regularization framework that leverages an inverse mapping mechanism to enhance representation learning. By reconstructing the input from its transformed output, SIM reduces information loss during forward propagation and facilitates smoother gradient flow. To address computational inefficiencies, We instantiate SIM as $ \rho\text{SIM} $ by incorporating patch-level feature sampling and projection-based method to reconstruct latent features, effectively lowering complexity. As a model-agnostic, task-agnostic regularizer, SIM can be seamlessly integrated as a plug-and-play module, making it applicable to different network architectures and tasks.
  We extensively evaluate $\rho\text{SIM}$ across three tasks: image classification, few-shot prompt learning, and domain generalization. Experimental results show consistent improvements over baseline methods, highlighting $\rho\text{SIM}$'s ability to enhance representation learning across various tasks. We also demonstrate that $\rho\text{SIM}$ is orthogonal to existing regularization methods, boosting their effectiveness. Moreover, our results confirm that $\rho\text{SIM}$ effectively preserves semantic information and enhances performance in dense-to-dense tasks, such as semantic segmentation and image translation, as well as in non-visual domains including audio classification and time series anomaly detection. The code is publicly available at https://github.com/XiudingCai/SIM-pytorch.

## 📝 요약

이 논문에서는 딥러닝의 일반화와 과적합 완화를 위해 새로운 정규화 프레임워크인 Self Identity Mapping (SIM)을 제안합니다. SIM은 입력 데이터를 변환된 출력에서 재구성하여 정보 손실을 줄이고, 부드러운 그래디언트 흐름을 촉진합니다. 또한, 패치 수준의 특징 샘플링과 투영 기반 방법을 사용한 $ \rho\text{SIM} $을 통해 계산 복잡성을 낮췄습니다. SIM은 모델과 작업에 구애받지 않는 정규화 기법으로, 다양한 네트워크 아키텍처와 작업에 쉽게 통합될 수 있습니다. 이미지 분류, 소수 샷 프롬프트 학습, 도메인 일반화 등 세 가지 작업에서 실험한 결과, $\rho\text{SIM}$은 기존 방법보다 일관된 성능 향상을 보였습니다. 또한, 기존 정규화 방법과 결합하여 효과를 증대시킬 수 있으며, 시맨틱 정보 보존과 성능 향상에 기여함을 확인했습니다. 코드와 관련 자료는 공개되어 있습니다.

## 🎯 주요 포인트

- 1. Self Identity Mapping (SIM)은 입력을 변환된 출력에서 재구성하여 정보 손실을 줄이고, 부드러운 그래디언트 흐름을 촉진하는 데이터 내재적 정규화 프레임워크입니다.
- 2. SIM은 패치 수준의 특징 샘플링과 투영 기반 방법을 통해 계산 복잡성을 낮추고, 다양한 네트워크 아키텍처와 작업에 쉽게 통합될 수 있는 모델 및 작업 무관 정규화 기법입니다.
- 3. $\rho\text{SIM}$은 이미지 분류, 퓨샷 프롬프트 학습, 도메인 일반화 등 다양한 작업에서 일관된 성능 향상을 보여주며, 기존 정규화 방법과 병행하여 효과를 증대시킬 수 있습니다.
- 4. $\rho\text{SIM}$은 의미 정보를 효과적으로 보존하고, 시맨틱 세그멘테이션 및 이미지 변환과 같은 밀집-대-밀집 작업뿐만 아니라 오디오 분류 및 시계열 이상 탐지와 같은 비시각적 도메인에서도 성능을 향상시킵니다.
- 5. 연구 결과는 $\rho\text{SIM}$이 다양한 작업에서 표현 학습을 향상시키는 능력을 강조하며, 관련 코드는 공개적으로 제공됩니다.


---

*Generated on 2025-09-24 15:06:05*