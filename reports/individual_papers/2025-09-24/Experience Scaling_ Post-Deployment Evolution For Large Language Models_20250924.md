<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T13:28:10.128341",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Experience Scaling",
    "Autonomous Interaction",
    "Collaborative Sharing",
    "Generalization to Unseen Tasks"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Experience Scaling": 0.9,
    "Autonomous Interaction": 0.82,
    "Collaborative Sharing": 0.8,
    "Generalization to Unseen Tasks": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's discussion, linking to a well-established concept in NLP.",
        "novelty_score": 0.2,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Experience Scaling",
        "canonical": "Experience Scaling",
        "aliases": [
          "Post-Deployment Evolution"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel framework for LLM evolution, offering new insights and connections.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.9
      },
      {
        "surface": "Autonomous Interaction",
        "canonical": "Autonomous Interaction",
        "aliases": [
          "Self-Interaction"
        ],
        "category": "unique_technical",
        "rationale": "Describes a key mechanism for LLMs to learn from the environment, enhancing connectivity.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "Collaborative Sharing",
        "canonical": "Collaborative Sharing",
        "aliases": [
          "Knowledge Sharing"
        ],
        "category": "unique_technical",
        "rationale": "Highlights a method for LLMs to exchange learned experiences, fostering networked intelligence.",
        "novelty_score": 0.7,
        "connectivity_score": 0.68,
        "specificity_score": 0.75,
        "link_intent_score": 0.8
      },
      {
        "surface": "Generalization to Unseen Tasks",
        "canonical": "Generalization to Unseen Tasks",
        "aliases": [
          "Task Generalization"
        ],
        "category": "specific_connectable",
        "rationale": "Focuses on LLMs' ability to adapt, a crucial aspect of machine learning research.",
        "novelty_score": 0.65,
        "connectivity_score": 0.75,
        "specificity_score": 0.72,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "saturation",
      "relevance",
      "efficiency"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.2,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Experience Scaling",
      "resolved_canonical": "Experience Scaling",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.9
      }
    },
    {
      "candidate_surface": "Autonomous Interaction",
      "resolved_canonical": "Autonomous Interaction",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Collaborative Sharing",
      "resolved_canonical": "Collaborative Sharing",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.68,
        "specificity": 0.75,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Generalization to Unseen Tasks",
      "resolved_canonical": "Generalization to Unseen Tasks",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.75,
        "specificity": 0.72,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# Experience Scaling: Post-Deployment Evolution For Large Language Models

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18771.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2509.18771](https://arxiv.org/abs/2509.18771)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Modular Machine Learning_ An Indispensable Path towards New-Generation Large Language Models_20250919|Modular Machine Learning: An Indispensable Path towards New-Generation Large Language Models]] (87.2% similar)
- [[2025-09-23/mmExpert_ Integrating Large Language Models for Comprehensive mmWave Data Synthesis and Understanding_20250923|mmExpert: Integrating Large Language Models for Comprehensive mmWave Data Synthesis and Understanding]] (85.5% similar)
- [[2025-09-23/Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates_20250923|Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates]] (85.1% similar)
- [[2025-09-19/Middo_ Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning_20250919|Middo: Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning]] (85.1% similar)
- [[2025-09-17/Simulating a Bias Mitigation Scenario in Large Language Models_20250917|Simulating a Bias Mitigation Scenario in Large Language Models]] (85.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Generalization to Unseen Tasks|Generalization to Unseen Tasks]]
**âš¡ Unique Technical**: [[keywords/Experience Scaling|Experience Scaling]], [[keywords/Autonomous Interaction|Autonomous Interaction]], [[keywords/Collaborative Sharing|Collaborative Sharing]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18771v1 Announce Type: new 
Abstract: Scaling model size, training data, and compute power have driven advances in large language models (LLMs), but these approaches are reaching saturation as human-generated text is exhausted and further gains diminish. We propose experience scaling, a framework for continuous post-deployment evolution for LLMs through autonomous interaction with the environment and collaborative sharing of accumulated experience. The framework captures raw interactions, distills them into compact, reusable knowledge, and periodically refines stored content to preserve relevance and efficiency. We validate the framework in simulated real-world scenarios involving generalization to previously unseen but related tasks, repetitive queries, and over-saturated knowledge stores. Across all settings, experience scaling improves accuracy, sustains performance over time, and maintains gains when applied to novel situations. These results demonstrate that structured post-deployment learning can extend LLM capabilities beyond the limits of static human-generated data, offering a scalable path for continued intelligence progress.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ë°œì „ì„ ìœ„í•´ ê²½í—˜ í™•ì¥ì´ë¼ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ëª¨ë¸ í¬ê¸°, í•™ìŠµ ë°ì´í„°, ê³„ì‚° ëŠ¥ë ¥ í™•ì¥ì€ í•œê³„ì— ë„ë‹¬í–ˆê¸° ë•Œë¬¸ì—, ì´ í”„ë ˆì„ì›Œí¬ëŠ” í™˜ê²½ê³¼ì˜ ììœ¨ì  ìƒí˜¸ì‘ìš© ë° ê²½í—˜ ê³µìœ ë¥¼ í†µí•´ ëª¨ë¸ì„ ì§€ì†ì ìœ¼ë¡œ ë°œì „ì‹œí‚µë‹ˆë‹¤. ì´ ë°©ë²•ë¡ ì€ ì›ì‹œ ìƒí˜¸ì‘ìš©ì„ ì••ì¶•ëœ ì§€ì‹ìœ¼ë¡œ ì •ì œí•˜ê³ , ì €ì¥ëœ ë‚´ìš©ì„ ì£¼ê¸°ì ìœ¼ë¡œ ê°±ì‹ í•˜ì—¬ ê´€ë ¨ì„±ê³¼ íš¨ìœ¨ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤. ì‹œë®¬ë ˆì´ì…˜ëœ í˜„ì‹¤ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ê²€ì¦í•œ ê²°ê³¼, ê²½í—˜ í™•ì¥ì€ ì •í™•ì„±ì„ ë†’ì´ê³ , ìƒˆë¡œìš´ ìƒí™©ì—ì„œë„ ì„±ëŠ¥ì„ ìœ ì§€í•˜ë©°, LLMì˜ ëŠ¥ë ¥ì„ ì¸ê°„ ìƒì„± ë°ì´í„°ì˜ í•œê³„ë¥¼ ë„˜ì–´ í™•ì¥í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ë°œì „ì€ ëª¨ë¸ í¬ê¸°, í•™ìŠµ ë°ì´í„°, ê³„ì‚° ëŠ¥ë ¥ì˜ í™•ëŒ€ë¡œ ì´ë£¨ì–´ì¡Œìœ¼ë‚˜, ì¸ê°„ì´ ìƒì„±í•œ í…ìŠ¤íŠ¸ì˜ í•œê³„ë¡œ ì¸í•´ ì´ëŸ¬í•œ ì ‘ê·¼ë²•ì€ í¬í™” ìƒíƒœì— ì´ë¥´ê³  ìˆë‹¤.
- 2. ê²½í—˜ í™•ì¥ í”„ë ˆì„ì›Œí¬ëŠ” LLMì´ í™˜ê²½ê³¼ì˜ ììœ¨ì ì¸ ìƒí˜¸ì‘ìš©ì„ í†µí•´ ì§€ì†ì ìœ¼ë¡œ ë°œì „í•˜ê³ , ì¶•ì ëœ ê²½í—˜ì„ í˜‘ë ¥ì ìœ¼ë¡œ ê³µìœ í•  ìˆ˜ ìˆë„ë¡ í•œë‹¤.
- 3. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ì›ì‹œ ìƒí˜¸ì‘ìš©ì„ í¬ì°©í•˜ì—¬ ì´ë¥¼ ê°„ê²°í•˜ê³  ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ì§€ì‹ìœ¼ë¡œ ì •ì œí•˜ê³ , ì €ì¥ëœ ì½˜í…ì¸ ë¥¼ ì£¼ê¸°ì ìœ¼ë¡œ ê°œì„ í•˜ì—¬ ê´€ë ¨ì„±ê³¼ íš¨ìœ¨ì„±ì„ ìœ ì§€í•œë‹¤.
- 4. ì‹œë®¬ë ˆì´ì…˜ëœ ì‹¤ì œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ê²½í—˜ í™•ì¥ì€ ì •í™•ì„±ì„ í–¥ìƒì‹œí‚¤ê³ , ì‹œê°„ì´ ì§€ë‚˜ë„ ì„±ëŠ¥ì„ ìœ ì§€í•˜ë©°, ìƒˆë¡œìš´ ìƒí™©ì—ì„œë„ ì„±ê³¼ë¥¼ ìœ ì§€í•˜ëŠ” ê²ƒìœ¼ë¡œ ê²€ì¦ë˜ì—ˆë‹¤.
- 5. êµ¬ì¡°í™”ëœ ë°°í¬ í›„ í•™ìŠµì€ ì •ì  ì¸ê°„ ìƒì„± ë°ì´í„°ì˜ í•œê³„ë¥¼ ë„˜ì–´ LLMì˜ ëŠ¥ë ¥ì„ í™•ì¥í•  ìˆ˜ ìˆìœ¼ë©°, ì§€ì†ì ì¸ ì§€ëŠ¥ ë°œì „ì„ ìœ„í•œ í™•ì¥ ê°€ëŠ¥í•œ ê²½ë¡œë¥¼ ì œê³µí•œë‹¤.


---

*Generated on 2025-09-24 13:28:10*