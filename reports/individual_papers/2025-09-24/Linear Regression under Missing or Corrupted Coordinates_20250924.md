<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T15:18:38.949551",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Linear Regression",
    "Gaussian Covariates",
    "Adversarial Missingness",
    "Information-Theoretic Lower Bounds"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Linear Regression": 0.8,
    "Gaussian Covariates": 0.75,
    "Adversarial Missingness": 0.78,
    "Information-Theoretic Lower Bounds": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Linear Regression",
        "canonical": "Linear Regression",
        "aliases": [
          "Linear Model",
          "Linear Predictor"
        ],
        "category": "broad_technical",
        "rationale": "A fundamental statistical method widely used in machine learning and data analysis, facilitating connections to various regression techniques.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.8
      },
      {
        "surface": "Gaussian Covariates",
        "canonical": "Gaussian Covariates",
        "aliases": [
          "Gaussian Features",
          "Normal Covariates"
        ],
        "category": "unique_technical",
        "rationale": "Describes a specific type of input data distribution critical for understanding the statistical properties of the model.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      },
      {
        "surface": "Adversarial Missingness",
        "canonical": "Adversarial Missingness",
        "aliases": [
          "Adversarial Data Deletion",
          "Adversarial Erasure"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel concept of data missingness due to adversarial actions, relevant for robust statistical modeling.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Information-Theoretic Lower Bounds",
        "canonical": "Information-Theoretic Lower Bounds",
        "aliases": [
          "IT Lower Bounds",
          "Information Bounds"
        ],
        "category": "specific_connectable",
        "rationale": "Provides a theoretical framework for understanding the limits of estimation error, linking to broader topics in information theory.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Linear Regression",
      "resolved_canonical": "Linear Regression",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Gaussian Covariates",
      "resolved_canonical": "Gaussian Covariates",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Adversarial Missingness",
      "resolved_canonical": "Adversarial Missingness",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Information-Theoretic Lower Bounds",
      "resolved_canonical": "Information-Theoretic Lower Bounds",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Linear Regression under Missing or Corrupted Coordinates

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19242.pdf)
**Category**: cs.LG
**Published**: 2025-09-24
**ArXiv ID**: [2509.19242](https://arxiv.org/abs/2509.19242)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/Data coarse graining can improve model performance_20250918|Data coarse graining can improve model performance]] (81.7% similar)
- [[2025-09-17/On the Rate of Gaussian Approximation for Linear Regression Problems_20250917|On the Rate of Gaussian Approximation for Linear Regression Problems]] (80.9% similar)
- [[2025-09-22/Accelerated Gradient Methods with Biased Gradient Estimates_ Risk Sensitivity, High-Probability Guarantees, and Large Deviation Bounds_20250922|Accelerated Gradient Methods with Biased Gradient Estimates: Risk Sensitivity, High-Probability Guarantees, and Large Deviation Bounds]] (80.4% similar)
- [[2025-09-19/Moment- and Power-Spectrum-Based Gaussianity Regularization for Text-to-Image Models_20250919|Moment- and Power-Spectrum-Based Gaussianity Regularization for Text-to-Image Models]] (80.2% similar)
- [[2025-09-24/Stability and Generalization of Adversarial Diffusion Training_20250924|Stability and Generalization of Adversarial Diffusion Training]] (79.9% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Linear Regression|Linear Regression]]
**ğŸ”— Specific Connectable**: [[keywords/Information-Theoretic Lower Bounds|Information-Theoretic Lower Bounds]]
**âš¡ Unique Technical**: [[keywords/Gaussian Covariates|Gaussian Covariates]], [[keywords/Adversarial Missingness|Adversarial Missingness]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19242v1 Announce Type: cross 
Abstract: We study multivariate linear regression under Gaussian covariates in two settings, where data may be erased or corrupted by an adversary under a coordinate-wise budget. In the incomplete data setting, an adversary may inspect the dataset and delete entries in up to an $\eta$-fraction of samples per coordinate; a strong form of the Missing Not At Random model. In the corrupted data setting, the adversary instead replaces values arbitrarily, and the corruption locations are unknown to the learner. Despite substantial work on missing data, linear regression under such adversarial missingness remains poorly understood, even information-theoretically. Unlike the clean setting, where estimation error vanishes with more samples, here the optimal error remains a positive function of the problem parameters. Our main contribution is to characterize this error up to constant factors across essentially the entire parameter range. Specifically, we establish novel information-theoretic lower bounds on the achievable error that match the error of (computationally efficient) algorithms. A key implication is that, perhaps surprisingly, the optimal error in the missing data setting matches that in the corruption setting-so knowing the corruption locations offers no general advantage.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ê°€ìš°ì‹œì•ˆ ê³µë³€ëŸ‰ í•˜ì—ì„œ ë‹¤ë³€ëŸ‰ ì„ í˜• íšŒê·€ë¥¼ ì—°êµ¬í•˜ë©°, ë°ì´í„°ê°€ ì¢Œí‘œë³„ ì˜ˆì‚°ì— ë”°ë¼ ì‚­ì œë˜ê±°ë‚˜ ì†ìƒë  ìˆ˜ ìˆëŠ” ë‘ ê°€ì§€ ìƒí™©ì„ ë‹¤ë£¹ë‹ˆë‹¤. ì²« ë²ˆì§¸ëŠ” ë°ì´í„°ê°€ ì„ì˜ë¡œ ì‚­ì œë  ìˆ˜ ìˆëŠ” ë¶ˆì™„ì „ ë°ì´í„° ìƒí™©ì´ë©°, ë‘ ë²ˆì§¸ëŠ” ë°ì´í„°ê°€ ì„ì˜ë¡œ ë³€ê²½ë  ìˆ˜ ìˆëŠ” ì†ìƒ ë°ì´í„° ìƒí™©ì…ë‹ˆë‹¤. ì£¼ìš” ê¸°ì—¬ëŠ” ì´ëŸ¬í•œ ì ëŒ€ì  ê²°ì¸¡ ìƒí™©ì—ì„œì˜ ìµœì  ì˜¤ë¥˜ë¥¼ ë¬¸ì œ ë§¤ê°œë³€ìˆ˜ì˜ í•¨ìˆ˜ë¡œ íŠ¹ì„±í™”í•œ ê²ƒì…ë‹ˆë‹¤. íŠ¹íˆ, ì •ë³´ ì´ë¡ ì  í•˜í•œì„ ì„¤ì •í•˜ì—¬, ì•Œê³ ë¦¬ì¦˜ì˜ ì˜¤ë¥˜ì™€ ì¼ì¹˜í•˜ëŠ” ìµœì  ì˜¤ë¥˜ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ì¤‘ìš”í•œ ë°œê²¬ì€ ê²°ì¸¡ ë°ì´í„°ì™€ ì†ìƒ ë°ì´í„° ìƒí™©ì—ì„œì˜ ìµœì  ì˜¤ë¥˜ê°€ ì¼ì¹˜í•œë‹¤ëŠ” ì ìœ¼ë¡œ, ì†ìƒ ìœ„ì¹˜ë¥¼ ì•„ëŠ” ê²ƒì´ ì¼ë°˜ì ì¸ ì´ì ì„ ì œê³µí•˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ê°€ìš°ì‹œì•ˆ ê³µë³€ëŸ‰ í•˜ì—ì„œ ë‹¤ë³€ëŸ‰ ì„ í˜• íšŒê·€ë¥¼ ì—°êµ¬í•˜ë©°, ë°ì´í„°ê°€ ì‚­ì œë˜ê±°ë‚˜ ì ëŒ€ì ìœ¼ë¡œ ì†ìƒë  ìˆ˜ ìˆëŠ” ë‘ ê°€ì§€ ì„¤ì •ì„ ë‹¤ë£¹ë‹ˆë‹¤.
- 2. ë¶ˆì™„ì „ ë°ì´í„° ì„¤ì •ì—ì„œëŠ” ì ëŒ€ìê°€ ê° ì¢Œí‘œë‹¹ ìƒ˜í”Œì˜ $\eta$-ë¹„ìœ¨ê¹Œì§€ ë°ì´í„°ë¥¼ ì‚­ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- 3. ì†ìƒëœ ë°ì´í„° ì„¤ì •ì—ì„œëŠ” ì ëŒ€ìê°€ ì„ì˜ë¡œ ê°’ì„ ëŒ€ì²´í•˜ë©°, ì†ìƒ ìœ„ì¹˜ëŠ” í•™ìŠµìê°€ ì•Œ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
- 4. ì •ë³´ ì´ë¡ ì ìœ¼ë¡œ ë‹¬ì„± ê°€ëŠ¥í•œ ì˜¤ë¥˜ì— ëŒ€í•œ ìƒˆë¡œìš´ í•˜í•œì„ ì œì‹œí•˜ë©°, ì´ëŠ” íš¨ìœ¨ì ì¸ ì•Œê³ ë¦¬ì¦˜ì˜ ì˜¤ë¥˜ì™€ ì¼ì¹˜í•©ë‹ˆë‹¤.
- 5. ì†ì‹¤ ë°ì´í„° ì„¤ì •ì—ì„œ ìµœì ì˜ ì˜¤ë¥˜ê°€ ì†ìƒ ë°ì´í„° ì„¤ì •ê³¼ ì¼ì¹˜í•˜ì—¬, ì†ìƒ ìœ„ì¹˜ë¥¼ ì•„ëŠ” ê²ƒì´ ì¼ë°˜ì ìœ¼ë¡œ ì´ì ì„ ì œê³µí•˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ì ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.


---

*Generated on 2025-09-24 15:18:38*