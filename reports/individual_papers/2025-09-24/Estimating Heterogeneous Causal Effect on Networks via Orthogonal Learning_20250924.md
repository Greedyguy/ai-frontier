<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T15:10:23.595068",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Graph Neural Network",
    "Attention Mechanism",
    "Neyman Orthogonalization",
    "Spillover Effects"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Graph Neural Network": 0.88,
    "Attention Mechanism": 0.82,
    "Neyman Orthogonalization": 0.79,
    "Spillover Effects": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Graph Neural Networks",
        "canonical": "Graph Neural Network",
        "aliases": [
          "GNN"
        ],
        "category": "specific_connectable",
        "rationale": "Graph Neural Networks are central to the method proposed in the paper, offering strong connectivity with existing research on network topology.",
        "novelty_score": 0.45,
        "connectivity_score": 0.92,
        "specificity_score": 0.85,
        "link_intent_score": 0.88
      },
      {
        "surface": "Attention-based Interference Model",
        "canonical": "Attention Mechanism",
        "aliases": [
          "Attention Model"
        ],
        "category": "specific_connectable",
        "rationale": "The attention-based interference model is a novel application of attention mechanisms, linking to broader research on attention in neural networks.",
        "novelty_score": 0.58,
        "connectivity_score": 0.87,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "Neyman Orthogonalization",
        "canonical": "Neyman Orthogonalization",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Neyman Orthogonalization is a unique statistical technique used to ensure robustness in causal effect estimation, providing a novel link to statistical methods.",
        "novelty_score": 0.72,
        "connectivity_score": 0.65,
        "specificity_score": 0.83,
        "link_intent_score": 0.79
      },
      {
        "surface": "Spillover Effects",
        "canonical": "Spillover Effects",
        "aliases": [
          "Indirect Effects"
        ],
        "category": "specific_connectable",
        "rationale": "Understanding spillover effects is crucial for causal inference in networks, connecting to various fields like epidemiology and economics.",
        "novelty_score": 0.55,
        "connectivity_score": 0.78,
        "specificity_score": 0.81,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "causal effects",
      "networks",
      "interference"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Graph Neural Networks",
      "resolved_canonical": "Graph Neural Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.92,
        "specificity": 0.85,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "Attention-based Interference Model",
      "resolved_canonical": "Attention Mechanism",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.87,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Neyman Orthogonalization",
      "resolved_canonical": "Neyman Orthogonalization",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.65,
        "specificity": 0.83,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Spillover Effects",
      "resolved_canonical": "Spillover Effects",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.78,
        "specificity": 0.81,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# Estimating Heterogeneous Causal Effect on Networks via Orthogonal Learning

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18484.pdf)
**Category**: cs.LG
**Published**: 2025-09-24
**ArXiv ID**: [2509.18484](https://arxiv.org/abs/2509.18484)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Entropic Causal Inference_ Graph Identifiability_20250923|Entropic Causal Inference: Graph Identifiability]] (82.0% similar)
- [[2025-09-22/Interpretable Network-assisted Random Forest+_20250922|Interpretable Network-assisted Random Forest+]] (81.4% similar)
- [[2025-09-22/Decomposing Interventional Causality into Synergistic, Redundant, and Unique Components_20250922|Decomposing Interventional Causality into Synergistic, Redundant, and Unique Components]] (81.2% similar)
- [[2025-09-22/Adversarial generalization of unfolding (model-based) networks_20250922|Adversarial generalization of unfolding (model-based) networks]] (80.4% similar)
- [[2025-09-22/Neural Networks for Learnable and Scalable Influence Estimation of Instruction Fine-Tuning Data_20250922|Neural Networks for Learnable and Scalable Influence Estimation of Instruction Fine-Tuning Data]] (79.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Graph Neural Network|Graph Neural Network]], [[keywords/Attention Mechanism|Attention Mechanism]], [[keywords/Spillover Effects|Spillover Effects]]
**âš¡ Unique Technical**: [[keywords/Neyman Orthogonalization|Neyman Orthogonalization]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18484v1 Announce Type: cross 
Abstract: Estimating causal effects on networks is important for both scientific research and practical applications. Unlike traditional settings that assume the Stable Unit Treatment Value Assumption (SUTVA), interference allows an intervention/treatment on one unit to affect the outcomes of others. Understanding both direct and spillover effects is critical in fields such as epidemiology, political science, and economics. Causal inference on networks faces two main challenges. First, causal effects are typically heterogeneous, varying with unit features and local network structure. Second, connected units often exhibit dependence due to network homophily, creating confounding between structural correlations and causal effects. In this paper, we propose a two-stage method to estimate heterogeneous direct and spillover effects on networks. The first stage uses graph neural networks to estimate nuisance components that depend on the complex network topology. In the second stage, we adjust for network confounding using these estimates and infer causal effects through a novel attention-based interference model. Our approach balances expressiveness and interpretability, enabling downstream tasks such as identifying influential neighborhoods and recovering the sign of spillover effects. We integrate the two stages using Neyman orthogonalization and cross-fitting, which ensures that errors from nuisance estimation contribute only at higher order. As a result, our causal effect estimates are robust to bias and misspecification in modeling causal effects under network dependencies.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë„¤íŠ¸ì›Œí¬ ìƒì—ì„œì˜ ì¸ê³¼ íš¨ê³¼ ì¶”ì •ì„ ë‹¤ë£¨ë©°, ì „í†µì ì¸ SUTVA ê°€ì • ëŒ€ì‹  ê°„ì„­ì„ ê³ ë ¤í•©ë‹ˆë‹¤. ì´ëŠ” ì—­í•™, ì •ì¹˜í•™, ê²½ì œí•™ ë“±ì—ì„œ ì§ì ‘ ë° íŒŒê¸‰ íš¨ê³¼ë¥¼ ì´í•´í•˜ëŠ” ë° ì¤‘ìš”í•©ë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ ì¸ê³¼ ì¶”ë¡ ì˜ ì£¼ìš” ë„ì „ì€ ì´ì§ˆì ì¸ ì¸ê³¼ íš¨ê³¼ì™€ ë„¤íŠ¸ì›Œí¬ ë™ì§ˆì„±ìœ¼ë¡œ ì¸í•œ ì˜ì¡´ì„±ì…ë‹ˆë‹¤. ì €ìë“¤ì€ ë‘ ë‹¨ê³„ ë°©ë²•ë¡ ì„ ì œì•ˆí•˜ì—¬, ì²« ë²ˆì§¸ ë‹¨ê³„ì—ì„œ ê·¸ë˜í”„ ì‹ ê²½ë§ì„ ì‚¬ìš©í•´ ë³µì¡í•œ ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°ì— ì˜ì¡´í•˜ëŠ” ì„±ë¶„ì„ ì¶”ì •í•˜ê³ , ë‘ ë²ˆì§¸ ë‹¨ê³„ì—ì„œ ë„¤íŠ¸ì›Œí¬ í˜¼ë€ì„ ì¡°ì •í•˜ì—¬ ì¸ê³¼ íš¨ê³¼ë¥¼ ì¶”ë¡ í•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ í‘œí˜„ë ¥ê³¼ í•´ì„ ê°€ëŠ¥ì„±ì„ ê· í˜• ìˆê²Œ ìœ ì§€í•˜ë©°, ì˜í–¥ë ¥ ìˆëŠ” ì´ì›ƒ ì‹ë³„ ë° íŒŒê¸‰ íš¨ê³¼ì˜ ë¶€í˜¸ ë³µêµ¬ ë“±ì˜ ì‘ì—…ì„ ì§€ì›í•©ë‹ˆë‹¤. Neyman ì§êµí™”ì™€ êµì°¨ ì í•©ì„ í†µí•´ ì¶”ì • ì˜¤ë¥˜ë¥¼ ìµœì†Œí™”í•˜ì—¬ ë„¤íŠ¸ì›Œí¬ ì˜ì¡´ì„± í•˜ì—ì„œë„ í¸í–¥ì— ê°•í•œ ì¸ê³¼ íš¨ê³¼ ì¶”ì •ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë„¤íŠ¸ì›Œí¬ì—ì„œì˜ ì¸ê³¼ íš¨ê³¼ ì¶”ì •ì€ ê³¼í•™ ì—°êµ¬ì™€ ì‹¤ìš©ì  ì‘ìš© ëª¨ë‘ì—ì„œ ì¤‘ìš”í•˜ë‹¤.
- 2. ë„¤íŠ¸ì›Œí¬ì—ì„œì˜ ì¸ê³¼ ì¶”ë¡ ì€ ë‹¨ìœ„ì˜ íŠ¹ì„±ê³¼ ì§€ì—­ ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°ì— ë”°ë¼ ì´ì§ˆì ì¸ ì¸ê³¼ íš¨ê³¼ë¥¼ ë³´ì´ëŠ” ê²ƒì´ ì£¼ìš” ë„ì „ ê³¼ì œ ì¤‘ í•˜ë‚˜ì´ë‹¤.
- 3. ì œì•ˆëœ ë°©ë²•ì€ ê·¸ë˜í”„ ì‹ ê²½ë§ì„ ì‚¬ìš©í•˜ì—¬ ë³µì¡í•œ ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°ì— ì˜ì¡´í•˜ëŠ” ë¶ˆí•„ìš”í•œ ìš”ì†Œë¥¼ ì¶”ì •í•˜ê³ , ì£¼ì˜ ê¸°ë°˜ ê°„ì„­ ëª¨ë¸ì„ í†µí•´ ì¸ê³¼ íš¨ê³¼ë¥¼ ì¶”ë¡ í•œë‹¤.
- 4. ë„¤íŠ¸ì›Œí¬ ìƒì˜ ì¸ê³¼ íš¨ê³¼ ì¶”ì •ì—ì„œ í¸í–¥ê³¼ ì˜ëª»ëœ ëª…ì„¸ì— ê°•ê±´í•œ ê²°ê³¼ë¥¼ ì œê³µí•˜ê¸° ìœ„í•´ Neyman ì§êµí™”ì™€ êµì°¨ ì í•©ì„ í†µí•©í•˜ì˜€ë‹¤.
- 5. ì œì•ˆëœ ì ‘ê·¼ë²•ì€ í‘œí˜„ë ¥ê³¼ í•´ì„ ê°€ëŠ¥ì„±ì„ ê· í˜• ìˆê²Œ ìœ ì§€í•˜ì—¬, ì˜í–¥ë ¥ ìˆëŠ” ì´ì›ƒ ì‹ë³„ ë° ìŠ¤í•„ì˜¤ë²„ íš¨ê³¼ì˜ ë¶€í˜¸ ë³µêµ¬ì™€ ê°™ì€ í›„ì† ì‘ì—…ì„ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤.


---

*Generated on 2025-09-24 15:10:23*