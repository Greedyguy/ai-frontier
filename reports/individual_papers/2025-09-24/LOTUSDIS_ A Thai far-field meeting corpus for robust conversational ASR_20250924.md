<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T15:41:55.545371",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Far-Field Automatic Speech Recognition",
    "Whisper Model",
    "Distance-Diverse Training Data",
    "Zero-Shot and Fine-Tuning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Far-Field Automatic Speech Recognition": 0.78,
    "Whisper Model": 0.82,
    "Distance-Diverse Training Data": 0.77,
    "Zero-Shot and Fine-Tuning": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "far-field conversational ASR",
        "canonical": "Far-Field Automatic Speech Recognition",
        "aliases": [
          "far-field ASR",
          "conversational ASR"
        ],
        "category": "unique_technical",
        "rationale": "This term is central to the paper's focus on improving ASR systems for distant speech, which is a niche area in ASR research.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.82,
        "link_intent_score": 0.78
      },
      {
        "surface": "Whisper variants",
        "canonical": "Whisper Model",
        "aliases": [
          "Whisper",
          "Whisper ASR"
        ],
        "category": "specific_connectable",
        "rationale": "The Whisper model is a specific ASR model evaluated in the study, relevant for linking to discussions on ASR model performance.",
        "novelty_score": 0.58,
        "connectivity_score": 0.79,
        "specificity_score": 0.76,
        "link_intent_score": 0.82
      },
      {
        "surface": "distance-diverse training data",
        "canonical": "Distance-Diverse Training Data",
        "aliases": [
          "distance-varied data",
          "distance diversity"
        ],
        "category": "unique_technical",
        "rationale": "This concept is pivotal for improving ASR robustness, highlighting the importance of varied data in training models.",
        "novelty_score": 0.68,
        "connectivity_score": 0.65,
        "specificity_score": 0.71,
        "link_intent_score": 0.77
      },
      {
        "surface": "zero-shot and fine-tuned conditions",
        "canonical": "Zero-Shot and Fine-Tuning",
        "aliases": [
          "zero-shot learning",
          "fine-tuning"
        ],
        "category": "specific_connectable",
        "rationale": "These learning paradigms are crucial for understanding the performance benchmarks discussed in the paper.",
        "novelty_score": 0.55,
        "connectivity_score": 0.83,
        "specificity_score": 0.69,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "microphone types",
      "train, dev, test splits",
      "baseline system"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "far-field conversational ASR",
      "resolved_canonical": "Far-Field Automatic Speech Recognition",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.82,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Whisper variants",
      "resolved_canonical": "Whisper Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.79,
        "specificity": 0.76,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "distance-diverse training data",
      "resolved_canonical": "Distance-Diverse Training Data",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.65,
        "specificity": 0.71,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "zero-shot and fine-tuned conditions",
      "resolved_canonical": "Zero-Shot and Fine-Tuning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.83,
        "specificity": 0.69,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# LOTUSDIS: A Thai far-field meeting corpus for robust conversational ASR

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18722.pdf)
**Category**: cs.CL
**Published**: 2025-09-24
**ArXiv ID**: [2509.18722](https://arxiv.org/abs/2509.18722)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-24/SloPalSpeech_ A 2,8000-Hour Slovak Speech Corpus from Parliamentary Data_20250924|SloPalSpeech: A 2,8000-Hour Slovak Speech Corpus from Parliamentary Data]] (84.1% similar)
- [[2025-09-22/AS-ASR_ A Lightweight Framework for Aphasia-Specific Automatic Speech Recognition_20250922|AS-ASR: A Lightweight Framework for Aphasia-Specific Automatic Speech Recognition]] (80.6% similar)
- [[2025-09-23/Audio-Conditioned Diffusion LLMs for ASR and Deliberation Processing_20250923|Audio-Conditioned Diffusion LLMs for ASR and Deliberation Processing]] (79.8% similar)
- [[2025-09-22/LESS_ Large Language Model Enhanced Semi-Supervised Learning for Speech Foundational Models Using in-the-wild Data_20250922|LESS: Large Language Model Enhanced Semi-Supervised Learning for Speech Foundational Models Using in-the-wild Data]] (79.8% similar)
- [[2025-09-23/WenetSpeech-Chuan_ A Large-Scale Sichuanese Corpus with Rich Annotation for Dialectal Speech Processing_20250923|WenetSpeech-Chuan: A Large-Scale Sichuanese Corpus with Rich Annotation for Dialectal Speech Processing]] (79.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Whisper Model|Whisper Model]], [[keywords/Zero-Shot and Fine-Tuning|Zero-Shot and Fine-Tuning]]
**âš¡ Unique Technical**: [[keywords/Far-Field Automatic Speech Recognition|Far-Field Automatic Speech Recognition]], [[keywords/Distance-Diverse Training Data|Distance-Diverse Training Data]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18722v1 Announce Type: new 
Abstract: We present LOTUSDIS, a publicly available Thai meeting corpus designed to advance far-field conversational ASR. The dataset comprises 114 hours of spontaneous, unscripted dialogue collected in 15-20 minute sessions with three participants, where overlapping speech is frequent and natural. Speech was recorded simultaneously by nine independent single-channel devices spanning six microphone types at distances from 0.12 m to 10 m, preserving the authentic effects of reverberation, noise, and device coloration without relying on microphone arrays. We provide standard train, dev, test splits and release a reproducible baseline system. We benchmarked several Whisper variants under zero-shot and fine-tuned conditions. Off-the-shelf models showed strong degradation with distance, confirming a mismatch between pre-training data and Thai far-field speech. Fine-tuning on LOTUSDIS dramatically improved robustness: a Thai Whisper baseline reduced overall WER from 64.3 to 38.3 and far-field WER from 81.6 to 49.5, with especially large gains on the most distant microphones. These results underscore the importance of distance-diverse training data for robust ASR. The corpus is available under CC-BY-SA 4.0. We also release training and evaluation scripts as a baseline system to promote reproducible research in this field.

## ğŸ“ ìš”ì•½

LOTUSDISëŠ” ì›ê±°ë¦¬ ëŒ€í™”í˜• ìŒì„± ì¸ì‹(ASR)ì„ ë°œì „ì‹œí‚¤ê¸° ìœ„í•´ ê°œë°œëœ ê³µê°œ íƒœêµ­ì–´ íšŒì˜ ì½”í¼ìŠ¤ë¡œ, 114ì‹œê°„ì˜ ìë°œì  ëŒ€í™”ë¥¼ í¬í•¨í•©ë‹ˆë‹¤. ì´ ë°ì´í„°ëŠ” 0.12mì—ì„œ 10m ê±°ë¦¬ì˜ ë‹¤ì–‘í•œ ë§ˆì´í¬ë¡œ ìˆ˜ì§‘ë˜ì–´ ìì—°ìŠ¤ëŸ¬ìš´ ë°˜í–¥ê³¼ ì¡ìŒì„ ë³´ì¡´í•©ë‹ˆë‹¤. ê¸°ë³¸ í•™ìŠµ, ê°œë°œ, í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¥¼ ì œê³µí•˜ë©°, ì¬í˜„ ê°€ëŠ¥í•œ ê¸°ì¤€ ì‹œìŠ¤í…œì„ ê³µê°œí–ˆìŠµë‹ˆë‹¤. ì‚¬ì „ í•™ìŠµ ëª¨ë¸ì€ ê±°ë¦¬ ì¦ê°€ì— ë”°ë¼ ì„±ëŠ¥ì´ ì €í•˜ë˜ì—ˆìœ¼ë‚˜, LOTUSDISë¡œ ë¯¸ì„¸ ì¡°ì •í•œ ê²°ê³¼, WERì´ í¬ê²Œ ê°œì„ ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ê±°ë¦¬ ë‹¤ì–‘ì„±ì„ ê³ ë ¤í•œ í›ˆë ¨ ë°ì´í„°ì˜ ì¤‘ìš”ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤. ë°ì´í„°ëŠ” CC-BY-SA 4.0 ë¼ì´ì„ ìŠ¤ë¡œ ì œê³µë©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. LOTUSDISëŠ” íƒœêµ­ì–´ ì›ê±°ë¦¬ ëŒ€í™”í˜• ASRì„ ë°œì „ì‹œí‚¤ê¸° ìœ„í•´ ì„¤ê³„ëœ ê³µê°œëœ íƒœêµ­ íšŒì˜ ì½”í¼ìŠ¤ì…ë‹ˆë‹¤.
- 2. ë°ì´í„°ì…‹ì€ 114ì‹œê°„ì˜ ìë°œì ì´ê³  ëŒ€ë³¸ ì—†ëŠ” ëŒ€í™”ë¥¼ í¬í•¨í•˜ë©°, 3ëª…ì˜ ì°¸ê°€ìê°€ 15-20ë¶„ ì„¸ì…˜ ë™ì•ˆ ëŒ€í™”í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤.
- 3. 0.12mì—ì„œ 10m ê±°ë¦¬ì˜ 6ê°€ì§€ ë§ˆì´í¬ ìœ í˜•ì„ ì‚¬ìš©í•˜ëŠ” 9ê°œì˜ ë…ë¦½ì ì¸ ë‹¨ì¼ ì±„ë„ ì¥ì¹˜ë¡œ ë™ì‹œì— ë…¹ìŒí•˜ì—¬, ë°˜í–¥, ì†ŒìŒ ë° ì¥ì¹˜ ìƒ‰ì±„ì˜ íš¨ê³¼ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ë³´ì¡´í–ˆìŠµë‹ˆë‹¤.
- 4. LOTUSDISë¡œ ë¯¸ì„¸ ì¡°ì •í•œ ê²°ê³¼, íƒœêµ­ì–´ Whisper ëª¨ë¸ì˜ WERì´ ì „ë°˜ì ìœ¼ë¡œ 64.3ì—ì„œ 38.3ìœ¼ë¡œ, ì›ê±°ë¦¬ WERì´ 81.6ì—ì„œ 49.5ë¡œ í¬ê²Œ ê°œì„ ë˜ì—ˆìŠµë‹ˆë‹¤.
- 5. ì´ ì—°êµ¬ëŠ” ë‹¤ì–‘í•œ ê±°ë¦¬ì˜ í›ˆë ¨ ë°ì´í„°ê°€ ê°•ë ¥í•œ ASRì„ ìœ„í•´ ì¤‘ìš”í•˜ë‹¤ëŠ” ê²ƒì„ ê°•ì¡°í•˜ë©°, ì½”í¼ìŠ¤ëŠ” CC-BY-SA 4.0 ë¼ì´ì„ ìŠ¤ë¡œ ì œê³µë©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 15:41:55*