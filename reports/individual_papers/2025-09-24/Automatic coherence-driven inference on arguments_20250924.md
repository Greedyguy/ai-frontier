<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T13:52:24.011668",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Coherence-Driven Inference",
    "Combinatorial Optimization",
    "Neurosymbolic Architecture"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Coherence-Driven Inference": 0.78,
    "Combinatorial Optimization": 0.77,
    "Neurosymbolic Architecture": 0.74
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are central to the paper's proposed solution and are a key technology in NLP.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "coherence-driven inference",
        "canonical": "Coherence-Driven Inference",
        "aliases": [
          "CDI"
        ],
        "category": "unique_technical",
        "rationale": "Coherence-driven inference is a novel concept introduced in the paper, crucial for understanding its unique approach.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "combinatorial optimization",
        "canonical": "Combinatorial Optimization",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Combinatorial optimization is a specific method used in the paper, linking it to mathematical and computational techniques.",
        "novelty_score": 0.55,
        "connectivity_score": 0.7,
        "specificity_score": 0.72,
        "link_intent_score": 0.77
      },
      {
        "surface": "neurosymbolic architecture",
        "canonical": "Neurosymbolic Architecture",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "The neurosymbolic architecture is a unique feature of the proposed system, combining neural and symbolic methods.",
        "novelty_score": 0.68,
        "connectivity_score": 0.6,
        "specificity_score": 0.78,
        "link_intent_score": 0.74
      }
    ],
    "ban_list_suggestions": [
      "inconsistencies",
      "law",
      "administration",
      "jurisprudence"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "coherence-driven inference",
      "resolved_canonical": "Coherence-Driven Inference",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "combinatorial optimization",
      "resolved_canonical": "Combinatorial Optimization",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.7,
        "specificity": 0.72,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "neurosymbolic architecture",
      "resolved_canonical": "Neurosymbolic Architecture",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.6,
        "specificity": 0.78,
        "link_intent": 0.74
      }
    }
  ]
}
-->

# Automatic coherence-driven inference on arguments

## 📋 메타데이터

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18523.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2509.18523](https://arxiv.org/abs/2509.18523)

## 🔗 유사한 논문
- [[2025-09-24/Coherence-driven inference for cybersecurity_20250924|Coherence-driven inference for cybersecurity]] (86.5% similar)
- [[2025-09-23/Roundtable Policy_ Improving Scientific Reasoning and Narratives through Confidence-Weighted Consensus of LLMs_20250923|Roundtable Policy: Improving Scientific Reasoning and Narratives through Confidence-Weighted Consensus of LLMs]] (84.8% similar)
- [[2025-09-23/Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates_20250923|Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates]] (84.5% similar)
- [[2025-09-23/Does Reasoning Introduce Bias? A Study of Social Bias Evaluation and Mitigation in LLM Reasoning_20250923|Does Reasoning Introduce Bias? A Study of Social Bias Evaluation and Mitigation in LLM Reasoning]] (83.6% similar)
- [[2025-09-23/Question Answering with LLMs and Learning from Answer Sets_20250923|Question Answering with LLMs and Learning from Answer Sets]] (83.1% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Combinatorial Optimization|Combinatorial Optimization]]
**⚡ Unique Technical**: [[keywords/Coherence-Driven Inference|Coherence-Driven Inference]], [[keywords/Neurosymbolic Architecture|Neurosymbolic Architecture]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.18523v1 Announce Type: cross 
Abstract: Inconsistencies are ubiquitous in law, administration, and jurisprudence. Though a cure is too much to hope for, we propose a technological remedy. Large language models (LLMs) can accurately extract propositions from arguments and compile them into natural data structures that enable coherence-driven inference (CDI) via combinatorial optimization. This neurosymbolic architecture naturally separates concerns and enables meaningful judgments about the coherence of arguments that can inform legislative and policy analysis and legal reasoning.

## 📝 요약

이 논문은 법, 행정, 사법 분야에서 흔히 발생하는 불일치 문제를 해결하기 위한 기술적 방안을 제안합니다. 주요 기여는 대형 언어 모델(LLM)을 활용하여 논증에서 명제를 정확히 추출하고 이를 자연스러운 데이터 구조로 컴파일하는 것입니다. 이 구조는 조합 최적화를 통해 일관성 기반 추론(CDI)을 가능하게 합니다. 제안된 신경-기호적 아키텍처는 문제를 자연스럽게 분리하여 논증의 일관성에 대한 의미 있는 판단을 가능하게 하며, 이는 입법 및 정책 분석과 법적 추론에 유용할 수 있습니다.

## 🎯 주요 포인트

- 1. 법, 행정, 법학에서 불일치는 흔히 발생하는 문제입니다.
- 2. 대형 언어 모델(LLM)은 주장에서 명제를 정확하게 추출하고 이를 자연스러운 데이터 구조로 컴파일할 수 있습니다.
- 3. 이러한 데이터 구조는 결합 최적화를 통해 일관성 기반 추론(CDI)을 가능하게 합니다.
- 4. 신경 기호적 아키텍처는 문제를 자연스럽게 분리하고, 입법 및 정책 분석과 법적 추론에 유용한 판단을 내릴 수 있게 합니다.


---

*Generated on 2025-09-24 13:52:24*