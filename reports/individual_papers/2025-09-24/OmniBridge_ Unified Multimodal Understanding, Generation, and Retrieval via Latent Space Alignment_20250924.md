<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T14:58:44.960579",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "OmniBridge",
    "Multimodal Learning",
    "Vision-Language Model",
    "Latent Space Alignment",
    "Semantic-Guided Diffusion Training"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "OmniBridge": 0.8,
    "Multimodal Learning": 0.88,
    "Vision-Language Model": 0.85,
    "Latent Space Alignment": 0.82,
    "Semantic-Guided Diffusion Training": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "OmniBridge",
        "canonical": "OmniBridge",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "OmniBridge is the central framework discussed in the paper, offering a unique approach to multimodal tasks.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "multimodal large language models",
        "canonical": "Multimodal Learning",
        "aliases": [
          "multimodal LLMs"
        ],
        "category": "specific_connectable",
        "rationale": "Multimodal Learning connects various modalities, which is a core aspect of the paper's framework.",
        "novelty_score": 0.7,
        "connectivity_score": 0.85,
        "specificity_score": 0.8,
        "link_intent_score": 0.88
      },
      {
        "surface": "vision-language understanding",
        "canonical": "Vision-Language Model",
        "aliases": [
          "vision-language tasks"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-Language Models are integral to the paper's approach, bridging vision and language tasks.",
        "novelty_score": 0.65,
        "connectivity_score": 0.78,
        "specificity_score": 0.82,
        "link_intent_score": 0.85
      },
      {
        "surface": "latent space alignment",
        "canonical": "Latent Space Alignment",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Latent Space Alignment is a novel technique proposed in the paper for unifying multimodal tasks.",
        "novelty_score": 0.8,
        "connectivity_score": 0.7,
        "specificity_score": 0.88,
        "link_intent_score": 0.82
      },
      {
        "surface": "semantic-guided diffusion training",
        "canonical": "Semantic-Guided Diffusion Training",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This training strategy is a unique contribution of the paper, enhancing cross-modal alignment.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "OmniBridge",
      "resolved_canonical": "OmniBridge",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "multimodal large language models",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.85,
        "specificity": 0.8,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "vision-language understanding",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.78,
        "specificity": 0.82,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "latent space alignment",
      "resolved_canonical": "Latent Space Alignment",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.7,
        "specificity": 0.88,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "semantic-guided diffusion training",
      "resolved_canonical": "Semantic-Guided Diffusion Training",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# OmniBridge: Unified Multimodal Understanding, Generation, and Retrieval via Latent Space Alignment

## 📋 메타데이터

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19018.pdf)
**Category**: cs.LG
**Published**: 2025-09-24
**ArXiv ID**: [2509.19018](https://arxiv.org/abs/2509.19018)

## 🔗 유사한 논문
- [[2025-09-24/Linguistic Neuron Overlap Patterns to Facilitate Cross-lingual Transfer on Low-resource Languages_20250924|Linguistic Neuron Overlap Patterns to Facilitate Cross-lingual Transfer on Low-resource Languages]] (87.0% similar)
- [[2025-09-24/OptMerge_ Unifying Multimodal LLM Capabilities and Modalities via Model Merging_20250924|OptMerge: Unifying Multimodal LLM Capabilities and Modalities via Model Merging]] (85.8% similar)
- [[2025-09-23/Open Vision Reasoner_ Transferring Linguistic Cognitive Behavior for Visual Reasoning_20250923|Open Vision Reasoner: Transferring Linguistic Cognitive Behavior for Visual Reasoning]] (85.0% similar)
- [[2025-09-22/Exploring Polyglot Harmony_ On Multilingual Data Allocation for Large Language Models Pretraining_20250922|Exploring Polyglot Harmony: On Multilingual Data Allocation for Large Language Models Pretraining]] (84.7% similar)
- [[2025-09-19/Decoupled Proxy Alignment_ Mitigating Language Prior Conflict for Multimodal Alignment in MLLM_20250919|Decoupled Proxy Alignment: Mitigating Language Prior Conflict for Multimodal Alignment in MLLM]] (84.5% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**⚡ Unique Technical**: [[keywords/OmniBridge|OmniBridge]], [[keywords/Latent Space Alignment|Latent Space Alignment]], [[keywords/Semantic-Guided Diffusion Training|Semantic-Guided Diffusion Training]]
**🚀 Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.19018v1 Announce Type: new 
Abstract: Recent advances in multimodal large language models (LLMs) have led to significant progress in understanding, generation, and retrieval tasks. However, current solutions often treat these tasks in isolation or require training LLMs from scratch, resulting in high computational costs and limited generalization across modalities. In this work, we present OmniBridge, a unified and modular multimodal framework that supports vision-language understanding, generation, and retrieval within a unified architecture. OmniBridge adopts a language-centric design that reuses pretrained LLMs and introduces a lightweight bidirectional latent alignment module. To address the challenge of task interference, we propose a two-stage decoupled training strategy: supervised fine-tuning and latent space alignment for aligning LLM behavior with multimodal reasoning, and semantic-guided diffusion training to align cross-modal latent spaces via learnable query embeddings. Extensive experiments across a wide range of benchmarks demonstrate that OmniBridge achieves competitive or state-of-the-art performance in all three tasks. Moreover, our results highlight the effectiveness of latent space alignment for unifying multimodal modeling under a shared representation space. Code and models are released at https://github.com/xiao-xt/OmniBridge.

## 📝 요약

최근 멀티모달 대형 언어 모델(LLM)의 발전은 이해, 생성, 검색 작업에서 큰 진전을 이루었습니다. 그러나 기존 솔루션은 이러한 작업을 개별적으로 처리하거나 LLM을 처음부터 훈련해야 하므로 높은 계산 비용과 제한된 일반화 문제가 있습니다. 본 연구에서는 OmniBridge라는 통합 모듈형 멀티모달 프레임워크를 제안하여 비전-언어 이해, 생성, 검색을 하나의 아키텍처 내에서 지원합니다. OmniBridge는 사전 훈련된 LLM을 재사용하고 경량의 양방향 잠재 정렬 모듈을 도입하는 언어 중심 설계를 채택합니다. 작업 간섭 문제를 해결하기 위해 두 단계로 분리된 훈련 전략을 제안하며, 이는 감독된 미세 조정과 잠재 공간 정렬을 통해 LLM의 멀티모달 추론을 조정하고, 학습 가능한 쿼리 임베딩을 통한 의미 기반 확산 훈련으로 교차 모달 잠재 공간을 정렬합니다. 다양한 벤치마크 실험에서 OmniBridge는 모든 작업에서 경쟁력 있는 또는 최첨단 성능을 달성했으며, 잠재 공간 정렬의 효과를 강조했습니다. 코드와 모델은 https://github.com/xiao-xt/OmniBridge에서 공개됩니다.

## 🎯 주요 포인트

- 1. OmniBridge는 비전-언어 이해, 생성, 검색을 통합된 아키텍처 내에서 지원하는 통합 모듈형 멀티모달 프레임워크입니다.
- 2. 이 프레임워크는 사전 학습된 대형 언어 모델(LLM)을 재사용하고 경량의 양방향 잠재 정렬 모듈을 도입합니다.
- 3. 작업 간섭 문제를 해결하기 위해 두 단계로 분리된 훈련 전략을 제안하며, 이는 감독된 미세 조정과 잠재 공간 정렬을 포함합니다.
- 4. 광범위한 벤치마크 실험에서 OmniBridge는 모든 작업에서 경쟁력 있는 또는 최첨단 성능을 달성했습니다.
- 5. 잠재 공간 정렬의 효과는 공유 표현 공간에서 멀티모달 모델링을 통합하는 데 중요한 역할을 합니다.


---

*Generated on 2025-09-24 14:58:44*