<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T14:58:44.960579",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "OmniBridge",
    "Multimodal Learning",
    "Vision-Language Model",
    "Latent Space Alignment",
    "Semantic-Guided Diffusion Training"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "OmniBridge": 0.8,
    "Multimodal Learning": 0.88,
    "Vision-Language Model": 0.85,
    "Latent Space Alignment": 0.82,
    "Semantic-Guided Diffusion Training": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "OmniBridge",
        "canonical": "OmniBridge",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "OmniBridge is the central framework discussed in the paper, offering a unique approach to multimodal tasks.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "multimodal large language models",
        "canonical": "Multimodal Learning",
        "aliases": [
          "multimodal LLMs"
        ],
        "category": "specific_connectable",
        "rationale": "Multimodal Learning connects various modalities, which is a core aspect of the paper's framework.",
        "novelty_score": 0.7,
        "connectivity_score": 0.85,
        "specificity_score": 0.8,
        "link_intent_score": 0.88
      },
      {
        "surface": "vision-language understanding",
        "canonical": "Vision-Language Model",
        "aliases": [
          "vision-language tasks"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-Language Models are integral to the paper's approach, bridging vision and language tasks.",
        "novelty_score": 0.65,
        "connectivity_score": 0.78,
        "specificity_score": 0.82,
        "link_intent_score": 0.85
      },
      {
        "surface": "latent space alignment",
        "canonical": "Latent Space Alignment",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Latent Space Alignment is a novel technique proposed in the paper for unifying multimodal tasks.",
        "novelty_score": 0.8,
        "connectivity_score": 0.7,
        "specificity_score": 0.88,
        "link_intent_score": 0.82
      },
      {
        "surface": "semantic-guided diffusion training",
        "canonical": "Semantic-Guided Diffusion Training",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This training strategy is a unique contribution of the paper, enhancing cross-modal alignment.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "OmniBridge",
      "resolved_canonical": "OmniBridge",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "multimodal large language models",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.85,
        "specificity": 0.8,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "vision-language understanding",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.78,
        "specificity": 0.82,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "latent space alignment",
      "resolved_canonical": "Latent Space Alignment",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.7,
        "specificity": 0.88,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "semantic-guided diffusion training",
      "resolved_canonical": "Semantic-Guided Diffusion Training",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# OmniBridge: Unified Multimodal Understanding, Generation, and Retrieval via Latent Space Alignment

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19018.pdf)
**Category**: cs.LG
**Published**: 2025-09-24
**ArXiv ID**: [2509.19018](https://arxiv.org/abs/2509.19018)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-24/Linguistic Neuron Overlap Patterns to Facilitate Cross-lingual Transfer on Low-resource Languages_20250924|Linguistic Neuron Overlap Patterns to Facilitate Cross-lingual Transfer on Low-resource Languages]] (87.0% similar)
- [[2025-09-24/OptMerge_ Unifying Multimodal LLM Capabilities and Modalities via Model Merging_20250924|OptMerge: Unifying Multimodal LLM Capabilities and Modalities via Model Merging]] (85.8% similar)
- [[2025-09-23/Open Vision Reasoner_ Transferring Linguistic Cognitive Behavior for Visual Reasoning_20250923|Open Vision Reasoner: Transferring Linguistic Cognitive Behavior for Visual Reasoning]] (85.0% similar)
- [[2025-09-22/Exploring Polyglot Harmony_ On Multilingual Data Allocation for Large Language Models Pretraining_20250922|Exploring Polyglot Harmony: On Multilingual Data Allocation for Large Language Models Pretraining]] (84.7% similar)
- [[2025-09-19/Decoupled Proxy Alignment_ Mitigating Language Prior Conflict for Multimodal Alignment in MLLM_20250919|Decoupled Proxy Alignment: Mitigating Language Prior Conflict for Multimodal Alignment in MLLM]] (84.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**âš¡ Unique Technical**: [[keywords/OmniBridge|OmniBridge]], [[keywords/Latent Space Alignment|Latent Space Alignment]], [[keywords/Semantic-Guided Diffusion Training|Semantic-Guided Diffusion Training]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19018v1 Announce Type: new 
Abstract: Recent advances in multimodal large language models (LLMs) have led to significant progress in understanding, generation, and retrieval tasks. However, current solutions often treat these tasks in isolation or require training LLMs from scratch, resulting in high computational costs and limited generalization across modalities. In this work, we present OmniBridge, a unified and modular multimodal framework that supports vision-language understanding, generation, and retrieval within a unified architecture. OmniBridge adopts a language-centric design that reuses pretrained LLMs and introduces a lightweight bidirectional latent alignment module. To address the challenge of task interference, we propose a two-stage decoupled training strategy: supervised fine-tuning and latent space alignment for aligning LLM behavior with multimodal reasoning, and semantic-guided diffusion training to align cross-modal latent spaces via learnable query embeddings. Extensive experiments across a wide range of benchmarks demonstrate that OmniBridge achieves competitive or state-of-the-art performance in all three tasks. Moreover, our results highlight the effectiveness of latent space alignment for unifying multimodal modeling under a shared representation space. Code and models are released at https://github.com/xiao-xt/OmniBridge.

## ğŸ“ ìš”ì•½

ìµœê·¼ ë©€í‹°ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ë°œì „ì€ ì´í•´, ìƒì„±, ê²€ìƒ‰ ì‘ì—…ì—ì„œ í° ì§„ì „ì„ ì´ë£¨ì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê¸°ì¡´ ì†”ë£¨ì…˜ì€ ì´ëŸ¬í•œ ì‘ì—…ì„ ê°œë³„ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ê±°ë‚˜ LLMì„ ì²˜ìŒë¶€í„° í›ˆë ¨í•´ì•¼ í•˜ë¯€ë¡œ ë†’ì€ ê³„ì‚° ë¹„ìš©ê³¼ ì œí•œëœ ì¼ë°˜í™” ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” OmniBridgeë¼ëŠ” í†µí•© ëª¨ë“ˆí˜• ë©€í‹°ëª¨ë‹¬ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•˜ì—¬ ë¹„ì „-ì–¸ì–´ ì´í•´, ìƒì„±, ê²€ìƒ‰ì„ í•˜ë‚˜ì˜ ì•„í‚¤í…ì²˜ ë‚´ì—ì„œ ì§€ì›í•©ë‹ˆë‹¤. OmniBridgeëŠ” ì‚¬ì „ í›ˆë ¨ëœ LLMì„ ì¬ì‚¬ìš©í•˜ê³  ê²½ëŸ‰ì˜ ì–‘ë°©í–¥ ì ì¬ ì •ë ¬ ëª¨ë“ˆì„ ë„ì…í•˜ëŠ” ì–¸ì–´ ì¤‘ì‹¬ ì„¤ê³„ë¥¼ ì±„íƒí•©ë‹ˆë‹¤. ì‘ì—… ê°„ì„­ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë‘ ë‹¨ê³„ë¡œ ë¶„ë¦¬ëœ í›ˆë ¨ ì „ëµì„ ì œì•ˆí•˜ë©°, ì´ëŠ” ê°ë…ëœ ë¯¸ì„¸ ì¡°ì •ê³¼ ì ì¬ ê³µê°„ ì •ë ¬ì„ í†µí•´ LLMì˜ ë©€í‹°ëª¨ë‹¬ ì¶”ë¡ ì„ ì¡°ì •í•˜ê³ , í•™ìŠµ ê°€ëŠ¥í•œ ì¿¼ë¦¬ ì„ë² ë”©ì„ í†µí•œ ì˜ë¯¸ ê¸°ë°˜ í™•ì‚° í›ˆë ¨ìœ¼ë¡œ êµì°¨ ëª¨ë‹¬ ì ì¬ ê³µê°„ì„ ì •ë ¬í•©ë‹ˆë‹¤. ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ ì‹¤í—˜ì—ì„œ OmniBridgeëŠ” ëª¨ë“  ì‘ì—…ì—ì„œ ê²½ìŸë ¥ ìˆëŠ” ë˜ëŠ” ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìœ¼ë©°, ì ì¬ ê³µê°„ ì •ë ¬ì˜ íš¨ê³¼ë¥¼ ê°•ì¡°í–ˆìŠµë‹ˆë‹¤. ì½”ë“œì™€ ëª¨ë¸ì€ https://github.com/xiao-xt/OmniBridgeì—ì„œ ê³µê°œë©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. OmniBridgeëŠ” ë¹„ì „-ì–¸ì–´ ì´í•´, ìƒì„±, ê²€ìƒ‰ì„ í†µí•©ëœ ì•„í‚¤í…ì²˜ ë‚´ì—ì„œ ì§€ì›í•˜ëŠ” í†µí•© ëª¨ë“ˆí˜• ë©€í‹°ëª¨ë‹¬ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.
- 2. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ì‚¬ì „ í•™ìŠµëœ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ ì¬ì‚¬ìš©í•˜ê³  ê²½ëŸ‰ì˜ ì–‘ë°©í–¥ ì ì¬ ì •ë ¬ ëª¨ë“ˆì„ ë„ì…í•©ë‹ˆë‹¤.
- 3. ì‘ì—… ê°„ì„­ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë‘ ë‹¨ê³„ë¡œ ë¶„ë¦¬ëœ í›ˆë ¨ ì „ëµì„ ì œì•ˆí•˜ë©°, ì´ëŠ” ê°ë…ëœ ë¯¸ì„¸ ì¡°ì •ê³¼ ì ì¬ ê³µê°„ ì •ë ¬ì„ í¬í•¨í•©ë‹ˆë‹¤.
- 4. ê´‘ë²”ìœ„í•œ ë²¤ì¹˜ë§ˆí¬ ì‹¤í—˜ì—ì„œ OmniBridgeëŠ” ëª¨ë“  ì‘ì—…ì—ì„œ ê²½ìŸë ¥ ìˆëŠ” ë˜ëŠ” ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.
- 5. ì ì¬ ê³µê°„ ì •ë ¬ì˜ íš¨ê³¼ëŠ” ê³µìœ  í‘œí˜„ ê³µê°„ì—ì„œ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ë§ì„ í†µí•©í•˜ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 14:58:44*