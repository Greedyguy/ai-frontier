<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T14:02:43.430786",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Self-supervised Learning",
    "Medical Image Representation Learning",
    "Discrete Self-Supervision",
    "Multi-scale Vector Quantization",
    "Representation Transfer"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Self-supervised Learning": 0.85,
    "Medical Image Representation Learning": 0.78,
    "Discrete Self-Supervision": 0.8,
    "Multi-scale Vector Quantization": 0.75,
    "Representation Transfer": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Self-supervised learning",
        "canonical": "Self-supervised Learning",
        "aliases": [
          "SSL"
        ],
        "category": "specific_connectable",
        "rationale": "A core concept in the paper, linking it to existing literature on self-supervised methods in medical imaging.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Medical image representation learning",
        "canonical": "Medical Image Representation Learning",
        "aliases": [
          "Medical Imaging SSL"
        ],
        "category": "unique_technical",
        "rationale": "Describes the specific application of SSL in medical imaging, a unique focus of the paper.",
        "novelty_score": 0.65,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Discrete Self-Supervision",
        "canonical": "Discrete Self-Supervision",
        "aliases": [
          "DiSSECT"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel method for structuring medical image representations, central to the paper's contribution.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Multi-scale vector quantization",
        "canonical": "Multi-scale Vector Quantization",
        "aliases": [
          "MSVQ"
        ],
        "category": "unique_technical",
        "rationale": "A technical approach used in the paper to improve model performance, relevant for linking to quantization techniques.",
        "novelty_score": 0.68,
        "connectivity_score": 0.65,
        "specificity_score": 0.78,
        "link_intent_score": 0.75
      },
      {
        "surface": "Representation transfer",
        "canonical": "Representation Transfer",
        "aliases": [
          "Transfer Learning"
        ],
        "category": "broad_technical",
        "rationale": "A fundamental concept in machine learning, relevant for understanding the paper's approach to improving generalizability.",
        "novelty_score": 0.4,
        "connectivity_score": 0.85,
        "specificity_score": 0.6,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "experiment"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Self-supervised learning",
      "resolved_canonical": "Self-supervised Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Medical image representation learning",
      "resolved_canonical": "Medical Image Representation Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Discrete Self-Supervision",
      "resolved_canonical": "Discrete Self-Supervision",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Multi-scale vector quantization",
      "resolved_canonical": "Multi-scale Vector Quantization",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.65,
        "specificity": 0.78,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Representation transfer",
      "resolved_canonical": "Representation Transfer",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.85,
        "specificity": 0.6,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# DiSSECT: Structuring Transfer-Ready Medical Image Representations through Discrete Self-Supervision

## 📋 메타데이터

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18765.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2509.18765](https://arxiv.org/abs/2509.18765)

## 🔗 유사한 논문
- [[2025-09-23/Enhancing Semantic Segmentation with Continual Self-Supervised Pre-training_20250923|Enhancing Semantic Segmentation with Continual Self-Supervised Pre-training]] (84.6% similar)
- [[2025-09-23/An Efficient Dual-Line Decoder Network with Multi-Scale Convolutional Attention for Multi-organ Segmentation_20250923|An Efficient Dual-Line Decoder Network with Multi-Scale Convolutional Attention for Multi-organ Segmentation]] (83.8% similar)
- [[2025-09-23/SAM-DCE_ Addressing Token Uniformity and Semantic Over-Smoothing in Medical Segmentation_20250923|SAM-DCE: Addressing Token Uniformity and Semantic Over-Smoothing in Medical Segmentation]] (83.1% similar)
- [[2025-09-22/SuPreME_ A Supervised Pre-training Framework for Multimodal ECG Representation Learning_20250922|SuPreME: A Supervised Pre-training Framework for Multimodal ECG Representation Learning]] (82.9% similar)
- [[2025-09-23/Ambiguous Medical Image Segmentation Using Diffusion Schr\"{o}dinger Bridge_20250923|Ambiguous Medical Image Segmentation Using Diffusion Schr\"{o}dinger Bridge]] (82.9% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Representation Transfer|Representation Transfer]]
**🔗 Specific Connectable**: [[keywords/Self-supervised Learning|Self-supervised Learning]]
**⚡ Unique Technical**: [[keywords/Medical Image Representation Learning|Medical Image Representation Learning]], [[keywords/Discrete Self-Supervision|Discrete Self-Supervision]], [[keywords/Multi-scale Vector Quantization|Multi-scale Vector Quantization]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.18765v1 Announce Type: cross 
Abstract: Self-supervised learning (SSL) has emerged as a powerful paradigm for medical image representation learning, particularly in settings with limited labeled data. However, existing SSL methods often rely on complex architectures, anatomy-specific priors, or heavily tuned augmentations, which limit their scalability and generalizability. More critically, these models are prone to shortcut learning, especially in modalities like chest X-rays, where anatomical similarity is high and pathology is subtle. In this work, we introduce DiSSECT -- Discrete Self-Supervision for Efficient Clinical Transferable Representations, a framework that integrates multi-scale vector quantization into the SSL pipeline to impose a discrete representational bottleneck. This constrains the model to learn repeatable, structure-aware features while suppressing view-specific or low-utility patterns, improving representation transfer across tasks and domains. DiSSECT achieves strong performance on both classification and segmentation tasks, requiring minimal or no fine-tuning, and shows particularly high label efficiency in low-label regimes. We validate DiSSECT across multiple public medical imaging datasets, demonstrating its robustness and generalizability compared to existing state-of-the-art approaches.

## 📝 요약

이 논문은 의료 영상 표현 학습에서 자기 지도 학습(SSL)의 한계를 극복하기 위해 DiSSECT라는 새로운 프레임워크를 제안합니다. 기존 SSL 방법은 복잡한 구조와 특정 해부학적 사전 지식에 의존하여 확장성과 일반화에 한계가 있었습니다. DiSSECT는 다중 스케일 벡터 양자화를 통해 모델이 구조 인식 기능을 학습하도록 하여, 작업 및 도메인 간 표현 전이를 개선합니다. 이 방법은 최소한의 미세 조정으로도 높은 성능을 보이며, 특히 적은 레이블 환경에서 효율적입니다. 여러 공공 의료 영상 데이터셋에서 DiSSECT의 강력한 성능과 일반화를 입증했습니다.

## 🎯 주요 포인트

- 1. 자기 지도 학습(SSL)은 제한된 라벨 데이터 환경에서 의료 이미지 표현 학습에 강력한 패러다임으로 부상하고 있다.
- 2. 기존 SSL 방법은 복잡한 아키텍처, 해부학적 사전 지식, 또는 조정된 증강에 의존하여 확장성과 일반화 가능성이 제한된다.
- 3. DiSSECT는 다중 스케일 벡터 양자화를 SSL 파이프라인에 통합하여 모델이 구조 인식 기능을 학습하도록 유도한다.
- 4. DiSSECT는 분류 및 세분화 작업에서 강력한 성능을 발휘하며, 최소한의 미세 조정만으로도 높은 라벨 효율성을 보인다.
- 5. 여러 공공 의료 이미지 데이터셋에서 DiSSECT의 강력함과 일반화 가능성을 검증하였다.


---

*Generated on 2025-09-24 14:02:43*