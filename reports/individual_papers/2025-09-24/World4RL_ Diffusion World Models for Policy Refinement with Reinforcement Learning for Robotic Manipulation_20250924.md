<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T14:10:00.672586",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Reinforcement Learning",
    "Diffusion Models",
    "Robotic Manipulation",
    "World Models"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Reinforcement Learning": 0.85,
    "Diffusion Models": 0.79,
    "Robotic Manipulation": 0.82,
    "World Models": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Reinforcement Learning",
        "canonical": "Reinforcement Learning",
        "aliases": [
          "RL"
        ],
        "category": "broad_technical",
        "rationale": "Reinforcement Learning is a foundational concept in the paper, facilitating connections to policy refinement and robotic manipulation.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Diffusion Models",
        "canonical": "Diffusion Models",
        "aliases": [
          "Diffusion-based Models"
        ],
        "category": "unique_technical",
        "rationale": "The use of diffusion models is central to the proposed framework, offering a novel approach to world modeling in robotics.",
        "novelty_score": 0.78,
        "connectivity_score": 0.72,
        "specificity_score": 0.82,
        "link_intent_score": 0.79
      },
      {
        "surface": "Robotic Manipulation",
        "canonical": "Robotic Manipulation",
        "aliases": [
          "Robot Manipulation"
        ],
        "category": "specific_connectable",
        "rationale": "Robotic manipulation is a key application area discussed, linking to both policy refinement and simulation.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.8,
        "link_intent_score": 0.82
      },
      {
        "surface": "World Models",
        "canonical": "World Models",
        "aliases": [
          "World Model"
        ],
        "category": "specific_connectable",
        "rationale": "World models are integral to the framework, enabling policy refinement in simulated environments.",
        "novelty_score": 0.55,
        "connectivity_score": 0.78,
        "specificity_score": 0.75,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "imitation learning",
      "expert data",
      "real-world interactions"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Reinforcement Learning",
      "resolved_canonical": "Reinforcement Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Diffusion Models",
      "resolved_canonical": "Diffusion Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.78,
        "connectivity": 0.72,
        "specificity": 0.82,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Robotic Manipulation",
      "resolved_canonical": "Robotic Manipulation",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.8,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "World Models",
      "resolved_canonical": "World Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.78,
        "specificity": 0.75,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# World4RL: Diffusion World Models for Policy Refinement with Reinforcement Learning for Robotic Manipulation

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19080.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2509.19080](https://arxiv.org/abs/2509.19080)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Latent Policy Steering with Embodiment-Agnostic Pretrained World Models_20250923|Latent Policy Steering with Embodiment-Agnostic Pretrained World Models]] (85.8% similar)
- [[2025-09-23/Prepare Before You Act_ Learning From Humans to Rearrange Initial States_20250923|Prepare Before You Act: Learning From Humans to Rearrange Initial States]] (83.6% similar)
- [[2025-09-24/Generalizable Domain Adaptation for Sim-and-Real Policy Co-Training_20250924|Generalizable Domain Adaptation for Sim-and-Real Policy Co-Training]] (83.6% similar)
- [[2025-09-23/Sample-Efficient Reinforcement Learning with Symmetry-Guided Demonstrations for Robotic Manipulation_20250923|Sample-Efficient Reinforcement Learning with Symmetry-Guided Demonstrations for Robotic Manipulation]] (83.4% similar)
- [[2025-09-18/PRISM-DP_ Spatial Pose-based Observations for Diffusion-Policies via Segmentation, Mesh Generation, and Pose Tracking_20250918|PRISM-DP: Spatial Pose-based Observations for Diffusion-Policies via Segmentation, Mesh Generation, and Pose Tracking]] (83.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Reinforcement Learning|Reinforcement Learning]]
**ğŸ”— Specific Connectable**: [[keywords/Robotic Manipulation|Robotic Manipulation]], [[keywords/World Models|World Models]]
**âš¡ Unique Technical**: [[keywords/Diffusion Models|Diffusion Models]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19080v1 Announce Type: cross 
Abstract: Robotic manipulation policies are commonly initialized through imitation learning, but their performance is limited by the scarcity and narrow coverage of expert data. Reinforcement learning can refine polices to alleviate this limitation, yet real-robot training is costly and unsafe, while training in simulators suffers from the sim-to-real gap. Recent advances in generative models have demonstrated remarkable capabilities in real-world simulation, with diffusion models in particular excelling at generation. This raises the question of how diffusion model-based world models can be combined to enhance pre-trained policies in robotic manipulation. In this work, we propose World4RL, a framework that employs diffusion-based world models as high-fidelity simulators to refine pre-trained policies entirely in imagined environments for robotic manipulation. Unlike prior works that primarily employ world models for planning, our framework enables direct end-to-end policy optimization. World4RL is designed around two principles: pre-training a diffusion world model that captures diverse dynamics on multi-task datasets and refining policies entirely within a frozen world model to avoid online real-world interactions. We further design a two-hot action encoding scheme tailored for robotic manipulation and adopt diffusion backbones to improve modeling fidelity. Extensive simulation and real-world experiments demonstrate that World4RL provides high-fidelity environment modeling and enables consistent policy refinement, yielding significantly higher success rates compared to imitation learning and other baselines. More visualization results are available at https://world4rl.github.io/.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë¡œë´‡ ì¡°ì‘ ì •ì±…ì„ ê°œì„ í•˜ê¸° ìœ„í•´ ì œì•ˆëœ World4RLì´ë¼ëŠ” í”„ë ˆì„ì›Œí¬ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ëª¨ë°© í•™ìŠµê³¼ ê°•í™” í•™ìŠµì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´, World4RLì€ í™•ì‚° ëª¨ë¸ ê¸°ë°˜ì˜ ì„¸ê³„ ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ê³ í’ˆì§ˆ ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ì‚¬ì „ í•™ìŠµëœ ì •ì±…ì„ ìƒìƒëœ í™˜ê²½ ë‚´ì—ì„œ ìµœì í™”í•˜ë©°, ì‹¤ì œ í™˜ê²½ê³¼ì˜ ìƒí˜¸ì‘ìš© ì—†ì´ ì •ì±…ì„ ê°œì„ í•©ë‹ˆë‹¤. ë‘ ê°€ì§€ ì£¼ìš” ì›ì¹™ì€ ë‹¤ì–‘í•œ ë™ì  ë°ì´í„°ë¥¼ í¬ê´„í•˜ëŠ” í™•ì‚° ì„¸ê³„ ëª¨ë¸ì˜ ì‚¬ì „ í•™ìŠµê³¼ ê³ ì •ëœ ì„¸ê³„ ëª¨ë¸ ë‚´ì—ì„œì˜ ì •ì±… ìµœì í™”ì…ë‹ˆë‹¤. ë˜í•œ, ë¡œë´‡ ì¡°ì‘ì— íŠ¹í™”ëœ ì´ì¤‘-í•« ì•¡ì…˜ ì¸ì½”ë”© ë°©ì‹ì„ ì„¤ê³„í–ˆìŠµë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, World4RLì€ ë†’ì€ ì„±ê³µë¥ ì„ ë³´ì´ë©° ê¸°ì¡´ì˜ ëª¨ë°© í•™ìŠµ ë° ë‹¤ë¥¸ ê¸°ì¤€ë³´ë‹¤ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. World4RLì€ í™•ì‚° ê¸°ë°˜ ì„¸ê³„ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë¡œë´‡ ì¡°ì‘ì„ ìœ„í•œ ì‚¬ì „ í•™ìŠµëœ ì •ì±…ì„ ìƒìƒëœ í™˜ê²½ì—ì„œ ì •ì œí•˜ëŠ” í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.
- 2. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ê³„íšì— ì£¼ë¡œ ì‚¬ìš©ë˜ë˜ ê¸°ì¡´ì˜ ì„¸ê³„ ëª¨ë¸ê³¼ ë‹¬ë¦¬, ì§ì ‘ì ì¸ ì¢…ë‹¨ ê°„ ì •ì±… ìµœì í™”ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
- 3. World4RLì€ ë‹¤ì–‘í•œ ë™ì  íŠ¹ì„±ì„ í¬ì°©í•˜ëŠ” ë‹¤ì¤‘ ì‘ì—… ë°ì´í„°ì…‹ì—ì„œ í™•ì‚° ì„¸ê³„ ëª¨ë¸ì„ ì‚¬ì „ í•™ìŠµí•˜ê³ , ì˜¨ë¼ì¸ í˜„ì‹¤ ì„¸ê³„ ìƒí˜¸ì‘ìš©ì„ í”¼í•˜ê¸° ìœ„í•´ ê³ ì •ëœ ì„¸ê³„ ëª¨ë¸ ë‚´ì—ì„œ ì •ì±…ì„ ì •ì œí•©ë‹ˆë‹¤.
- 4. ë¡œë´‡ ì¡°ì‘ì— ë§ì¶˜ íˆ¬-í•« ì•¡ì…˜ ì¸ì½”ë”© ë°©ì‹ì„ ì„¤ê³„í•˜ê³ , í™•ì‚° ë°±ë³¸ì„ ì±„íƒí•˜ì—¬ ëª¨ë¸ë§ ì •í™•ë„ë¥¼ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
- 5. ê´‘ë²”ìœ„í•œ ì‹œë®¬ë ˆì´ì…˜ ë° ì‹¤ì œ ì‹¤í—˜ì„ í†µí•´ World4RLì´ ë†’ì€ ì •í™•ë„ì˜ í™˜ê²½ ëª¨ë¸ë§ì„ ì œê³µí•˜ê³ , ì¼ê´€ëœ ì •ì±… ì •ì œë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ì—¬ ëª¨ë°© í•™ìŠµ ë° ê¸°íƒ€ ê¸°ì¤€ë³´ë‹¤ í›¨ì”¬ ë†’ì€ ì„±ê³µë¥ ì„ ë‹¬ì„±í•¨ì„ ì…ì¦í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 14:10:00*