<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T14:49:09.306759",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Federated Graph Learning",
    "Gradient Pruning",
    "Graph Neural Network",
    "Domain Skew"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Federated Graph Learning": 0.78,
    "Gradient Pruning": 0.77,
    "Graph Neural Network": 0.85,
    "Domain Skew": 0.74
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Federated Graph Learning",
        "canonical": "Federated Graph Learning",
        "aliases": [
          "FGL"
        ],
        "category": "unique_technical",
        "rationale": "Federated Graph Learning is a specific technique that addresses domain skew in federated learning, making it a unique and relevant concept for linking.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Gradient Pruning",
        "canonical": "Gradient Pruning",
        "aliases": [
          "Pruning"
        ],
        "category": "unique_technical",
        "rationale": "Gradient Pruning is a technique used to improve model efficiency, which is central to the paper's methodology.",
        "novelty_score": 0.67,
        "connectivity_score": 0.72,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      },
      {
        "surface": "Graph Neural Network",
        "canonical": "Graph Neural Network",
        "aliases": [
          "GNN"
        ],
        "category": "specific_connectable",
        "rationale": "Graph Neural Networks are a core component of the discussed federated learning framework, providing strong connectivity to related research.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.88,
        "link_intent_score": 0.85
      },
      {
        "surface": "Domain Skew",
        "canonical": "Domain Skew",
        "aliases": [
          "Domain Shift"
        ],
        "category": "unique_technical",
        "rationale": "Domain Skew is a critical challenge addressed in the paper, relevant for understanding the context of federated learning.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.78,
        "link_intent_score": 0.74
      }
    ],
    "ban_list_suggestions": [
      "method",
      "aggregation",
      "convergence"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Federated Graph Learning",
      "resolved_canonical": "Federated Graph Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Gradient Pruning",
      "resolved_canonical": "Gradient Pruning",
      "decision": "linked",
      "scores": {
        "novelty": 0.67,
        "connectivity": 0.72,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Graph Neural Network",
      "resolved_canonical": "Graph Neural Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.88,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Domain Skew",
      "resolved_canonical": "Domain Skew",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.78,
        "link_intent": 0.74
      }
    }
  ]
}
-->

# FedIA: A Plug-and-Play Importance-Aware Gradient Pruning Aggregation Method for Domain-Robust Federated Graph Learning on Node Classification

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18171.pdf)
**Category**: cs.LG
**Published**: 2025-09-24
**ArXiv ID**: [2509.18171](https://arxiv.org/abs/2509.18171)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-17/FedSSG_ Expectation-Gated and History-Aware Drift Alignment for Federated Learning_20250917|FedSSG: Expectation-Gated and History-Aware Drift Alignment for Federated Learning]] (85.0% similar)
- [[2025-09-24/FedFusion_ Federated Learning with Diversity- and Cluster-Aware Encoders for Robust Adaptation under Label Scarcity_20250924|FedFusion: Federated Learning with Diversity- and Cluster-Aware Encoders for Robust Adaptation under Label Scarcity]] (84.8% similar)
- [[2025-09-24/FedFiTS_ Fitness-Selected, Slotted Client Scheduling for Trustworthy Federated Learning in Healthcare AI_20250924|FedFiTS: Fitness-Selected, Slotted Client Scheduling for Trustworthy Federated Learning in Healthcare AI]] (83.6% similar)
- [[2025-09-19/FedAVOT_ Exact Distribution Alignment in Federated Learning via Masked Optimal Transport_20250919|FedAVOT: Exact Distribution Alignment in Federated Learning via Masked Optimal Transport]] (83.3% similar)
- [[2025-09-19/Who to Trust? Aggregating Client Knowledge in Logit-Based Federated Learning_20250919|Who to Trust? Aggregating Client Knowledge in Logit-Based Federated Learning]] (83.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Graph Neural Network|Graph Neural Network]]
**âš¡ Unique Technical**: [[keywords/Federated Graph Learning|Federated Graph Learning]], [[keywords/Gradient Pruning|Gradient Pruning]], [[keywords/Domain Skew|Domain Skew]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18171v1 Announce Type: new 
Abstract: Federated Graph Learning (FGL) under domain skew -- as observed on platforms such as \emph{Twitch Gamers} and multilingual \emph{Wikipedia} networks -- drives client models toward incompatible representations, rendering naive aggregation both unstable and ineffective. We find that the culprit is not the weighting scheme but the \emph{noisy gradient signal}: empirical analysis of baseline methods suggests that a vast majority of gradient dimensions can be dominated by domain-specific variance. We therefore shift focus from "aggregation-first" to a \emph{projection-first} strategy that denoises client updates \emph{before} they are combined. The proposed FedIA framework realises this \underline{I}mportance-\underline{A}ware idea through a two-stage, plug-and-play pipeline: (i) a server-side top-$\rho$ mask keeps only the most informative about 5% of coordinates, and (ii) a lightweight influence-regularised momentum weight suppresses outlier clients. FedIA adds \emph{no extra uplink traffic and only negligible server memory}, making it readily deployable. On both homogeneous (Twitch Gamers) and heterogeneous (Wikipedia) graphs, it yields smoother, more stable convergence and higher final accuracy than nine strong baselines. A convergence sketch further shows that dynamic projection maintains the optimal $\mathcal{O}(\sigma^{2}/\sqrt{T})$ rate.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë„ë©”ì¸ ë¶ˆê· í˜•ì´ ìˆëŠ” í™˜ê²½ì—ì„œì˜ ì—°í•© ê·¸ë˜í”„ í•™ìŠµ(FGL)ì„ ë‹¤ë£¹ë‹ˆë‹¤. ê¸°ì¡´ ë°©ë²•ì˜ ë¬¸ì œëŠ” ê°€ì¤‘ì¹˜ê°€ ì•„ë‹Œ, ë„ë©”ì¸ íŠ¹ì´ì  ë³€ë™ì„±ì— ì˜í•´ ì§€ë°°ë˜ëŠ” ë…¸ì´ì¦ˆê°€ ë§ì€ ê·¸ë˜ë””ì–¸íŠ¸ ì‹ í˜¸ë¼ëŠ” ì ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, í´ë¼ì´ì–¸íŠ¸ ì—…ë°ì´íŠ¸ë¥¼ ê²°í•©í•˜ê¸° ì „ì— ë…¸ì´ì¦ˆë¥¼ ì œê±°í•˜ëŠ” 'í”„ë¡œì ì…˜ ìš°ì„ ' ì „ëµì„ ì œì•ˆí•©ë‹ˆë‹¤. ì œì•ˆëœ FedIA í”„ë ˆì„ì›Œí¬ëŠ” ë‘ ë‹¨ê³„ë¡œ êµ¬ì„±ë˜ë©°, ì„œë²„ ì¸¡ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ 5%ì˜ ì¢Œí‘œë§Œ ìœ ì§€í•˜ëŠ” ë§ˆìŠ¤í¬ì™€, ì´ìƒì¹˜ í´ë¼ì´ì–¸íŠ¸ë¥¼ ì–µì œí•˜ëŠ” ê°€ë²¼ìš´ ì˜í–¥-ì •ê·œí™” ëª¨ë©˜í…€ ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. FedIAëŠ” ì¶”ê°€ì ì¸ ì—…ë§í¬ íŠ¸ë˜í”½ ì—†ì´ë„ ì•ˆì •ì ì´ê³  ë†’ì€ ì •í™•ë„ë¥¼ ë‹¬ì„±í•˜ë©°, ìˆ˜ë ´ ì†ë„ë„ ìµœì ì˜ $\mathcal{O}(\sigma^{2}/\sqrt{T})$ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë„ë©”ì¸ í¸í–¥ì´ ìˆëŠ” ì—°í•© ê·¸ë˜í”„ í•™ìŠµ(FGL)ì—ì„œëŠ” í´ë¼ì´ì–¸íŠ¸ ëª¨ë¸ ê°„ì˜ í‘œí˜„ ë¶ˆì¼ì¹˜ê°€ ë°œìƒí•˜ì—¬ ë‹¨ìˆœí•œ ì§‘ê³„ê°€ ë¶ˆì•ˆì •í•˜ê³  ë¹„íš¨ìœ¨ì ì´ë‹¤.
- 2. ë¬¸ì œì˜ ì›ì¸ì€ ê°€ì¤‘ì¹˜ ì²´ê³„ê°€ ì•„ë‹ˆë¼ ë„ë©”ì¸ íŠ¹ì´ì  ë¶„ì‚°ì— ì˜í•´ ì§€ë°°ë˜ëŠ” \emph{ë…¸ì´ì¦ˆê°€ ë§ì€ ê·¸ë˜ë””ì–¸íŠ¸ ì‹ í˜¸}ì´ë‹¤.
- 3. FedIA í”„ë ˆì„ì›Œí¬ëŠ” í´ë¼ì´ì–¸íŠ¸ ì—…ë°ì´íŠ¸ë¥¼ ê²°í•©í•˜ê¸° ì „ì— ë…¸ì´ì¦ˆë¥¼ ì œê±°í•˜ëŠ” \emph{íˆ¬ì˜ ìš°ì„ } ì „ëµì„ ì±„íƒí•œë‹¤.
- 4. FedIAëŠ” ì„œë²„ ì¸¡ì—ì„œ ê°€ì¥ ì •ë³´ê°€ ë§ì€ ì•½ 5%ì˜ ì¢Œí‘œë§Œ ìœ ì§€í•˜ëŠ” ìƒìœ„-$\rho$ ë§ˆìŠ¤í¬ì™€ ì´ìƒì¹˜ í´ë¼ì´ì–¸íŠ¸ë¥¼ ì–µì œí•˜ëŠ” ê²½ëŸ‰ì˜ ì˜í–¥-ì •ê·œí™” ëª¨ë©˜í…€ ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•œë‹¤.
- 5. FedIAëŠ” ì¶”ê°€ì ì¸ ì—…ë§í¬ íŠ¸ë˜í”½ ì—†ì´ ë°°í¬ ê°€ëŠ¥í•˜ë©°, ë™ì  íˆ¬ì˜ì„ í†µí•´ ìµœì ì˜ ìˆ˜ë ´ ì†ë„ë¥¼ ìœ ì§€í•œë‹¤.


---

*Generated on 2025-09-24 14:49:09*