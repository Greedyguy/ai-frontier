<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T13:36:00.546387",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Transformer",
    "Scientific Method",
    "Path Integration",
    "Explainability"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Transformer": 0.85,
    "Scientific Method": 0.7,
    "Path Integration": 0.72,
    "Explainability": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "transformer-based machine learning",
        "canonical": "Transformer",
        "aliases": [
          "transformer",
          "transformer model"
        ],
        "category": "broad_technical",
        "rationale": "Transformers are a foundational technology in machine learning, connecting to various applications and methods.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "scientific method",
        "canonical": "Scientific Method",
        "aliases": [
          "scientific approach",
          "scientific process"
        ],
        "category": "unique_technical",
        "rationale": "The scientific method is a distinct approach to knowledge acquisition, contrasting with machine learning.",
        "novelty_score": 0.65,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      },
      {
        "surface": "path-integration techniques",
        "canonical": "Path Integration",
        "aliases": [
          "path integration method",
          "path integral"
        ],
        "category": "specific_connectable",
        "rationale": "Path integration is a mathematical technique that can be linked to transformer operations.",
        "novelty_score": 0.6,
        "connectivity_score": 0.75,
        "specificity_score": 0.78,
        "link_intent_score": 0.72
      },
      {
        "surface": "explainability",
        "canonical": "Explainability",
        "aliases": [
          "model interpretability",
          "interpretability"
        ],
        "category": "evolved_concepts",
        "rationale": "Explainability is crucial for understanding machine learning models and their decision-making processes.",
        "novelty_score": 0.55,
        "connectivity_score": 0.8,
        "specificity_score": 0.75,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "random-like character",
      "physical problem",
      "general comments"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "transformer-based machine learning",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "scientific method",
      "resolved_canonical": "Scientific Method",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "path-integration techniques",
      "resolved_canonical": "Path Integration",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.75,
        "specificity": 0.78,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "explainability",
      "resolved_canonical": "Explainability",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.8,
        "specificity": 0.75,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# Two ways to knowledge?

## 📋 메타데이터

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18131.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2509.18131](https://arxiv.org/abs/2509.18131)

## 🔗 유사한 논문
- [[2025-09-22/Hierarchical Self-Attention_ Generalizing Neural Attention Mechanics to Multi-Scale Problems_20250922|Hierarchical Self-Attention: Generalizing Neural Attention Mechanics to Multi-Scale Problems]] (81.2% similar)
- [[2025-09-23/Measure-to-measure interpolation using Transformers_20250923|Measure-to-measure interpolation using Transformers]] (81.0% similar)
- [[2025-09-23/Scaling Efficient LLMs_20250923|Scaling Efficient LLMs]] (79.2% similar)
- [[2025-09-22/RMT-KD_ Random Matrix Theoretic Causal Knowledge Distillation_20250922|RMT-KD: Random Matrix Theoretic Causal Knowledge Distillation]] (78.3% similar)
- [[2025-09-22/Negotiated Representations to Prevent Overfitting in Machine Learning Applications_20250922|Negotiated Representations to Prevent Overfitting in Machine Learning Applications]] (78.1% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Transformer|Transformer]]
**🔗 Specific Connectable**: [[keywords/Path Integration|Path Integration]]
**⚡ Unique Technical**: [[keywords/Scientific Method|Scientific Method]]
**🚀 Evolved Concepts**: [[keywords/Explainability|Explainability]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.18131v1 Announce Type: cross 
Abstract: It is shown that the weight matrices of transformer-based machine learning applications to the solution of two representative physical applications show a random-like character which bears no directly recognizable link to the physical and mathematical structure of the physical problem under study. This suggests that machine learning and the scientific method may represent two distinct and potentially complementary paths to knowledge, even though a strict notion of explainability in terms of direct correspondence between network parameters and physical structures may remain out of reach. It is also observed that drawing a parallel between transformer operation and (generalized) path-integration techniques may account for the random-like nature of the weights, but still does not resolve the tension with explainability. We conclude with some general comments on the hazards of gleaning knowledge without the benefit of Insight.

## 📝 요약

이 논문은 트랜스포머 기반 머신러닝이 두 가지 물리적 문제를 해결하는 과정에서 생성하는 가중치 행렬이 무작위적 특성을 보이며, 이는 문제의 물리적 및 수학적 구조와 직접적인 연관성이 없음을 보여줍니다. 이는 머신러닝과 과학적 방법이 서로 다른 지식 획득 경로를 제공할 수 있음을 시사합니다. 또한, 트랜스포머의 작동을 경로 적분 기법과 비교해 볼 수 있지만, 이는 설명 가능성 문제를 해결하지 못합니다. 마지막으로, 통찰 없이 지식을 얻는 것의 위험성에 대한 일반적인 논평을 제시합니다.

## 🎯 주요 포인트

- 1. 트랜스포머 기반 기계 학습의 가중치 행렬은 물리적 문제의 구조와 직접적으로 연결되지 않는 무작위적 특성을 보인다.
- 2. 기계 학습과 과학적 방법은 지식 획득의 두 가지 상이하고 잠재적으로 상호 보완적인 경로를 나타낼 수 있다.
- 3. 트랜스포머의 작동과 경로 적분 기법 간의 유사성은 가중치의 무작위적 특성을 설명할 수 있지만, 설명 가능성 문제는 여전히 해결되지 않는다.
- 4. 통찰 없이 지식을 얻는 것의 위험성에 대한 일반적인 논평이 제시된다.


---

*Generated on 2025-09-24 13:36:00*