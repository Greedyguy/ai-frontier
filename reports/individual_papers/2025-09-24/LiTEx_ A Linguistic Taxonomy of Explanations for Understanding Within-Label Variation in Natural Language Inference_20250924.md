<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T15:52:47.226776",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Natural Language Processing",
    "Human Label Variation",
    "Within-Label Variation",
    "Linguistic Taxonomy",
    "Explanation Generation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Natural Language Processing": 0.85,
    "Human Label Variation": 0.8,
    "Within-Label Variation": 0.75,
    "Linguistic Taxonomy": 0.78,
    "Explanation Generation": 0.82
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Natural Language Inference",
        "canonical": "Natural Language Processing",
        "aliases": [
          "NLI"
        ],
        "category": "broad_technical",
        "rationale": "Natural Language Inference is a key task within Natural Language Processing, providing a strong link to existing NLP concepts.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Human Label Variation",
        "canonical": "Human Label Variation",
        "aliases": [
          "HLV"
        ],
        "category": "unique_technical",
        "rationale": "This concept highlights the variability in human annotation, which is crucial for understanding model performance and human reasoning.",
        "novelty_score": 0.72,
        "connectivity_score": 0.7,
        "specificity_score": 0.78,
        "link_intent_score": 0.8
      },
      {
        "surface": "Within-Label Variation",
        "canonical": "Within-Label Variation",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This term addresses a specific challenge in NLI that is not widely covered, offering a unique angle for research exploration.",
        "novelty_score": 0.68,
        "connectivity_score": 0.65,
        "specificity_score": 0.82,
        "link_intent_score": 0.75
      },
      {
        "surface": "Linguistic Taxonomy",
        "canonical": "Linguistic Taxonomy",
        "aliases": [
          "LiTEx"
        ],
        "category": "unique_technical",
        "rationale": "LiTEx provides a structured approach to categorizing explanations, enhancing understanding of linguistic reasoning.",
        "novelty_score": 0.7,
        "connectivity_score": 0.72,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Explanation Generation",
        "canonical": "Explanation Generation",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "This concept is pivotal for bridging the gap between human and model explanations, linking to broader AI explainability efforts.",
        "novelty_score": 0.55,
        "connectivity_score": 0.84,
        "specificity_score": 0.7,
        "link_intent_score": 0.82
      }
    ],
    "ban_list_suggestions": [
      "taxonomy",
      "dataset",
      "annotate"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Natural Language Inference",
      "resolved_canonical": "Natural Language Processing",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Human Label Variation",
      "resolved_canonical": "Human Label Variation",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.7,
        "specificity": 0.78,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Within-Label Variation",
      "resolved_canonical": "Within-Label Variation",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.65,
        "specificity": 0.82,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Linguistic Taxonomy",
      "resolved_canonical": "Linguistic Taxonomy",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.72,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Explanation Generation",
      "resolved_canonical": "Explanation Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.84,
        "specificity": 0.7,
        "link_intent": 0.82
      }
    }
  ]
}
-->

# LiTEx: A Linguistic Taxonomy of Explanations for Understanding Within-Label Variation in Natural Language Inference

## 📋 메타데이터

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2505.22848.pdf)
**Category**: cs.CL
**Published**: 2025-09-24
**ArXiv ID**: [2505.22848](https://arxiv.org/abs/2505.22848)

## 🔗 유사한 논문
- [[2025-09-24/From latent factors to language_ a user study on LLM-generated explanations for an inherently interpretable matrix-based recommender system_20250924|From latent factors to language: a user study on LLM-generated explanations for an inherently interpretable matrix-based recommender system]] (82.8% similar)
- [[2025-09-24/Can LLMs Explain Themselves Counterfactually?_20250924|Can LLMs Explain Themselves Counterfactually?]] (81.6% similar)
- [[2025-09-24/Extractive Fact Decomposition for Interpretable Natural Language Inference in one Forward Pass_20250924|Extractive Fact Decomposition for Interpretable Natural Language Inference in one Forward Pass]] (81.3% similar)
- [[2025-09-23/Learning to vary_ Teaching LMs to reproduce human linguistic variability in next-word prediction_20250923|Learning to vary: Teaching LMs to reproduce human linguistic variability in next-word prediction]] (81.0% similar)
- [[2025-09-19/SMARTER_ A Data-efficient Framework to Improve Toxicity Detection with Explanation via Self-augmenting Large Language Models_20250919|SMARTER: A Data-efficient Framework to Improve Toxicity Detection with Explanation via Self-augmenting Large Language Models]] (80.5% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Natural Language Processing|Natural Language Processing]]
**🔗 Specific Connectable**: [[keywords/Explanation Generation|Explanation Generation]]
**⚡ Unique Technical**: [[keywords/Human Label Variation|Human Label Variation]], [[keywords/Within-Label Variation|Within-Label Variation]], [[keywords/Linguistic Taxonomy|Linguistic Taxonomy]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2505.22848v3 Announce Type: replace 
Abstract: There is increasing evidence of Human Label Variation (HLV) in Natural Language Inference (NLI), where annotators assign different labels to the same premise-hypothesis pair. However, within-label variation--cases where annotators agree on the same label but provide divergent reasoning--poses an additional and mostly overlooked challenge. Several NLI datasets contain highlighted words in the NLI item as explanations, but the same spans on the NLI item can be highlighted for different reasons, as evidenced by free-text explanations, which offer a window into annotators' reasoning. To systematically understand this problem and gain insight into the rationales behind NLI labels, we introduce LITEX, a linguistically-informed taxonomy for categorizing free-text explanations. Using this taxonomy, we annotate a subset of the e-SNLI dataset, validate the taxonomy's reliability, and analyze how it aligns with NLI labels, highlights, and explanations. We further assess the taxonomy's usefulness in explanation generation, demonstrating that conditioning generation on LITEX yields explanations that are linguistically closer to human explanations than those generated using only labels or highlights. Our approach thus not only captures within-label variation but also shows how taxonomy-guided generation for reasoning can bridge the gap between human and model explanations more effectively than existing strategies.

## 📝 요약

이 논문은 자연어 추론(NLI)에서 인간 레이블 변이(HLV)와 레이블 내 변이 문제를 다룹니다. 레이블 내 변이는 동일한 레이블에 대해 주어진 이유가 다를 때 발생합니다. 이를 해결하기 위해 저자들은 자유 텍스트 설명을 분류하는 언어학적 분류 체계인 LITEX를 제안했습니다. e-SNLI 데이터셋의 일부를 이 체계로 주석하고, 체계의 신뢰성을 검증했으며, NLI 레이블 및 설명과의 정렬을 분석했습니다. 또한, LITEX를 기반으로 설명을 생성할 때 인간의 설명과 더 유사한 결과를 얻을 수 있음을 보여주었습니다. 이 접근법은 레이블 내 변이를 포착하고, 모델과 인간 설명 간의 격차를 효과적으로 줄이는 데 기여합니다.

## 🎯 주요 포인트

- 1. 자연어 추론(NLI)에서 동일한 전제-가설 쌍에 대해 주석자들이 다른 레이블을 할당하는 인간 레이블 변동(HLV)이 증가하고 있다.
- 2. 동일한 레이블에 대해 주석자들이 합의하지만 서로 다른 이유를 제공하는 '레이블 내 변동'이 추가적인 도전 과제로 부각되고 있다.
- 3. LITEX라는 언어학적으로 정보가 풍부한 분류 체계를 도입하여 자유 텍스트 설명을 분류하고, 이를 통해 NLI 레이블의 근거를 체계적으로 이해하고자 한다.
- 4. LITEX를 사용한 설명 생성은 레이블이나 강조 표시만을 사용한 생성보다 인간 설명에 더 가깝게 접근할 수 있음을 보여준다.
- 5. 제안된 접근 방식은 레이블 내 변동을 포착할 뿐만 아니라, 인간과 모델 설명 간의 격차를 효과적으로 줄일 수 있음을 입증한다.


---

*Generated on 2025-09-24 15:52:47*