<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T15:43:41.424753",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "End-to-End Speech Translation",
    "Dynamic Time Warping",
    "Modality Gap",
    "Speech and Text Embeddings",
    "Low Resource Settings"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "End-to-End Speech Translation": 0.78,
    "Dynamic Time Warping": 0.79,
    "Modality Gap": 0.75,
    "Speech and Text Embeddings": 0.8,
    "Low Resource Settings": 0.74
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "End-to-End Speech Translation",
        "canonical": "End-to-End Speech Translation",
        "aliases": [
          "E2E-ST"
        ],
        "category": "unique_technical",
        "rationale": "This is the primary focus of the paper and represents a distinct technical domain.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Dynamic Time Warping",
        "canonical": "Dynamic Time Warping",
        "aliases": [
          "DTW"
        ],
        "category": "specific_connectable",
        "rationale": "DTW is a key technique used in the paper for aligning speech and text embeddings.",
        "novelty_score": 0.68,
        "connectivity_score": 0.72,
        "specificity_score": 0.8,
        "link_intent_score": 0.79
      },
      {
        "surface": "Modality Gap",
        "canonical": "Modality Gap",
        "aliases": [
          "Bridging Modality Gap"
        ],
        "category": "unique_technical",
        "rationale": "The concept of a modality gap is central to the paper's contribution in improving translation accuracy.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.82,
        "link_intent_score": 0.75
      },
      {
        "surface": "Speech and Text Embeddings",
        "canonical": "Speech and Text Embeddings",
        "aliases": [
          "Speech-Text Embeddings"
        ],
        "category": "specific_connectable",
        "rationale": "These embeddings are crucial for understanding the alignment process discussed in the paper.",
        "novelty_score": 0.65,
        "connectivity_score": 0.78,
        "specificity_score": 0.77,
        "link_intent_score": 0.8
      },
      {
        "surface": "Low Resource Settings",
        "canonical": "Low Resource Settings",
        "aliases": [
          "Low-Resource Languages"
        ],
        "category": "specific_connectable",
        "rationale": "The paper highlights improvements in translation for low-resource languages, a significant application area.",
        "novelty_score": 0.6,
        "connectivity_score": 0.7,
        "specificity_score": 0.75,
        "link_intent_score": 0.74
      }
    ],
    "ban_list_suggestions": [
      "alignment tool",
      "nearest-neighbor similarity search"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "End-to-End Speech Translation",
      "resolved_canonical": "End-to-End Speech Translation",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Dynamic Time Warping",
      "resolved_canonical": "Dynamic Time Warping",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.72,
        "specificity": 0.8,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Modality Gap",
      "resolved_canonical": "Modality Gap",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.82,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Speech and Text Embeddings",
      "resolved_canonical": "Speech and Text Embeddings",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.78,
        "specificity": 0.77,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Low Resource Settings",
      "resolved_canonical": "Low Resource Settings",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.7,
        "specificity": 0.75,
        "link_intent": 0.74
      }
    }
  ]
}
-->

# DTW-Align: Bridging the Modality Gap in End-to-End Speech Translation with Dynamic Time Warping Alignment

## 📋 메타데이터

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18987.pdf)
**Category**: cs.CL
**Published**: 2025-09-24
**ArXiv ID**: [2509.18987](https://arxiv.org/abs/2509.18987)

## 🔗 유사한 논문
- [[2025-09-23/Transformer-Encoder Trees for Efficient Multilingual Machine Translation and Speech Translation_20250923|Transformer-Encoder Trees for Efficient Multilingual Machine Translation and Speech Translation]] (82.7% similar)
- [[2025-09-23/TMD-TTS_ A Unified Tibetan Multi-Dialect Text-to-Speech Synthesis for \"U-Tsang, Amdo and Kham Speech Dataset Generation_20250923|TMD-TTS: A Unified Tibetan Multi-Dialect Text-to-Speech Synthesis for \"U-Tsang, Amdo and Kham Speech Dataset Generation]] (81.3% similar)
- [[2025-09-23/Revisiting Speech-Lip Alignment_ A Phoneme-Aware Speech Encoder for Robust Talking Head Synthesis_20250923|Revisiting Speech-Lip Alignment: A Phoneme-Aware Speech Encoder for Robust Talking Head Synthesis]] (80.2% similar)
- [[2025-09-22/Frustratingly Easy Data Augmentation for Low-Resource ASR_20250922|Frustratingly Easy Data Augmentation for Low-Resource ASR]] (80.2% similar)
- [[2025-09-23/Bridging Past and Future_ Distribution-Aware Alignment for Time Series Forecasting_20250923|Bridging Past and Future: Distribution-Aware Alignment for Time Series Forecasting]] (80.2% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Dynamic Time Warping|Dynamic Time Warping]], [[keywords/Speech and Text Embeddings|Speech and Text Embeddings]], [[keywords/Low Resource Settings|Low Resource Settings]]
**⚡ Unique Technical**: [[keywords/End-to-End Speech Translation|End-to-End Speech Translation]], [[keywords/Modality Gap|Modality Gap]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.18987v1 Announce Type: new 
Abstract: End-to-End Speech Translation (E2E-ST) is the task of translating source speech directly into target text bypassing the intermediate transcription step. The representation discrepancy between the speech and text modalities has motivated research on what is known as bridging the modality gap. State-of-the-art methods addressed this by aligning speech and text representations on the word or token level. Unfortunately, this requires an alignment tool that is not available for all languages. Although this issue has been addressed by aligning speech and text embeddings using nearest-neighbor similarity search, it does not lead to accurate alignments. In this work, we adapt Dynamic Time Warping (DTW) for aligning speech and text embeddings during training. Our experiments demonstrate the effectiveness of our method in bridging the modality gap in E2E-ST. Compared to previous work, our method produces more accurate alignments and achieves comparable E2E-ST results while being significantly faster. Furthermore, our method outperforms previous work in low resource settings on 5 out of 6 language directions.

## 📝 요약

이 논문은 음성-텍스트 간의 표현 차이를 해결하기 위해 Dynamic Time Warping(DTW)을 활용하여 음성과 텍스트 임베딩을 정렬하는 방법을 제안합니다. 기존 방법들은 단어 또는 토큰 수준에서 정렬을 시도했으나, 모든 언어에 적용 가능한 정렬 도구가 부족한 문제가 있었습니다. 제안된 방법은 훈련 과정에서 DTW를 사용하여 더 정확한 정렬을 제공하며, 특히 자원이 적은 환경에서 6개 언어 중 5개에서 기존 방법보다 우수한 성능을 보였습니다. 또한, 제안된 방법은 이전 연구 대비 더 빠르게 실행됩니다.

## 🎯 주요 포인트

- 1. E2E-ST는 중간 전사 단계 없이 음성을 직접 텍스트로 번역하는 작업이다.
- 2. 음성과 텍스트 간의 표현 차이를 줄이기 위해 Dynamic Time Warping(DTW)을 사용하여 음성과 텍스트 임베딩을 정렬하는 방법을 제안했다.
- 3. 제안된 방법은 기존 방법보다 더 정확한 정렬을 제공하며, E2E-ST 결과에서도 유사한 성능을 보이면서도 속도가 빠르다.
- 4. 제안된 방법은 특히 자원이 적은 환경에서 6개 언어 방향 중 5개에서 기존 방법보다 우수한 성능을 보였다.


---

*Generated on 2025-09-24 15:43:41*