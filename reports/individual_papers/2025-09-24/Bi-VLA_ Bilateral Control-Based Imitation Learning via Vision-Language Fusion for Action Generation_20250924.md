<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T15:14:30.337565",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Bilateral Control-Based Imitation Learning",
    "Vision-Language Model",
    "SigLIP",
    "FiLM-based Fusion",
    "Natural Language Processing"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Bilateral Control-Based Imitation Learning": 0.8,
    "Vision-Language Model": 0.85,
    "SigLIP": 0.75,
    "FiLM-based Fusion": 0.78,
    "Natural Language Processing": 0.82
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Bilateral Control-Based Imitation Learning",
        "canonical": "Bilateral Control-Based Imitation Learning",
        "aliases": [
          "Bi-VLA"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel framework that extends existing bilateral control methods, making it a unique technical concept.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "Vision-Language Fusion",
        "canonical": "Vision-Language Model",
        "aliases": [
          "Vision-Language Fusion"
        ],
        "category": "evolved_concepts",
        "rationale": "Combining vision and language is a trending concept that enhances model versatility.",
        "novelty_score": 0.7,
        "connectivity_score": 0.88,
        "specificity_score": 0.78,
        "link_intent_score": 0.85
      },
      {
        "surface": "SigLIP",
        "canonical": "SigLIP",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "SigLIP is a specific technique mentioned for fusion, representing a unique technical element.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.75
      },
      {
        "surface": "FiLM-based Fusion",
        "canonical": "FiLM-based Fusion",
        "aliases": [
          "FiLM"
        ],
        "category": "unique_technical",
        "rationale": "FiLM is a specific method for feature fusion, crucial for understanding the paper's methodology.",
        "novelty_score": 0.75,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Natural Language Instructions",
        "canonical": "Natural Language Processing",
        "aliases": [
          "Language Instructions"
        ],
        "category": "broad_technical",
        "rationale": "Incorporating language instructions is key to the paper's approach, linking it to broader NLP concepts.",
        "novelty_score": 0.6,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.82
      }
    ],
    "ban_list_suggestions": [
      "task-specific models",
      "task success rates"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Bilateral Control-Based Imitation Learning",
      "resolved_canonical": "Bilateral Control-Based Imitation Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Vision-Language Fusion",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.88,
        "specificity": 0.78,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "SigLIP",
      "resolved_canonical": "SigLIP",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "FiLM-based Fusion",
      "resolved_canonical": "FiLM-based Fusion",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Natural Language Instructions",
      "resolved_canonical": "Natural Language Processing",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.82
      }
    }
  ]
}
-->

# Bi-VLA: Bilateral Control-Based Imitation Learning via Vision-Language Fusion for Action Generation

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18865.pdf)
**Category**: cs.LG
**Published**: 2025-09-24
**ArXiv ID**: [2509.18865](https://arxiv.org/abs/2509.18865)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/CollabVLA_ Self-Reflective Vision-Language-Action Model Dreaming Together with Human_20250919|CollabVLA: Self-Reflective Vision-Language-Action Model Dreaming Together with Human]] (87.5% similar)
- [[2025-09-24/VLA-LPAF_ Lightweight Perspective-Adaptive Fusion for Vision-Language-Action to Enable More Unconstrained Robotic Manipulation_20250924|VLA-LPAF: Lightweight Perspective-Adaptive Fusion for Vision-Language-Action to Enable More Unconstrained Robotic Manipulation]] (87.4% similar)
- [[2025-09-24/Pure Vision Language Action (VLA) Models_ A Comprehensive Survey_20250924|Pure Vision Language Action (VLA) Models: A Comprehensive Survey]] (86.8% similar)
- [[2025-09-22/A Vision-Language-Action-Critic Model for Robotic Real-World Reinforcement Learning_20250922|A Vision-Language-Action-Critic Model for Robotic Real-World Reinforcement Learning]] (86.0% similar)
- [[2025-09-19/ForceVLA_ Enhancing VLA Models with a Force-aware MoE for Contact-rich Manipulation_20250919|ForceVLA: Enhancing VLA Models with a Force-aware MoE for Contact-rich Manipulation]] (86.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Natural Language Processing|Natural Language Processing]]
**âš¡ Unique Technical**: [[keywords/Bilateral Control-Based Imitation Learning|Bilateral Control-Based Imitation Learning]], [[keywords/SigLIP|SigLIP]], [[keywords/FiLM-based Fusion|FiLM-based Fusion]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18865v1 Announce Type: cross 
Abstract: We propose Bilateral Control-Based Imitation Learning via Vision-Language Fusion for Action Generation (Bi-VLA), a novel framework that extends bilateral control-based imitation learning to handle more than one task within a single model. Conventional bilateral control methods exploit joint angle, velocity, torque, and vision for precise manipulation but require task-specific models, limiting their generality. Bi-VLA overcomes this limitation by utilizing robot joint angle, velocity, and torque data from leader-follower bilateral control with visual features and natural language instructions through SigLIP and FiLM-based fusion. We validated Bi-VLA on two task types: one requiring supplementary language cues and another distinguishable solely by vision. Real-robot experiments showed that Bi-VLA successfully interprets vision-language combinations and improves task success rates compared to conventional bilateral control-based imitation learning. Our Bi-VLA addresses the single-task limitation of prior bilateral approaches and provides empirical evidence that combining vision and language significantly enhances versatility. Experimental results validate the effectiveness of Bi-VLA in real-world tasks. For additional material, please visit the website: https://mertcookimg.github.io/bi-vla/

## ğŸ“ ìš”ì•½

Bi-VLAëŠ” ì‹œê°-ì–¸ì–´ ìœµí•©ì„ í†µí•œ í–‰ë™ ìƒì„± ëª¨ë°© í•™ìŠµ í”„ë ˆì„ì›Œí¬ë¡œ, ê¸°ì¡´ì˜ ì–‘ë°©í–¥ ì œì–´ ê¸°ë°˜ ëª¨ë°© í•™ìŠµì˜ ë‹¨ì¼ ì‘ì—… í•œê³„ë¥¼ ê·¹ë³µí•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ë¡œë´‡ ê´€ì ˆ ê°ë„, ì†ë„, í† í¬ ë°ì´í„°ë¥¼ ì‹œê°ì  íŠ¹ì§•ê³¼ ìì—°ì–´ ì§€ì‹œì™€ ìœµí•©í•˜ì—¬ ë‹¤ì–‘í•œ ì‘ì—…ì„ í•˜ë‚˜ì˜ ëª¨ë¸ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. SigLIP ë° FiLM ê¸°ë°˜ ìœµí•©ì„ í™œìš©í•˜ì—¬, ì–¸ì–´ì  ë‹¨ì„œê°€ í•„ìš”í•œ ì‘ì—…ê³¼ ì‹œê°ì ìœ¼ë¡œ êµ¬ë³„ ê°€ëŠ¥í•œ ì‘ì—…ì—ì„œ Bi-VLAì˜ ì„±ëŠ¥ì„ ê²€ì¦í–ˆìŠµë‹ˆë‹¤. ì‹¤ì œ ë¡œë´‡ ì‹¤í—˜ ê²°ê³¼, Bi-VLAëŠ” ì‹œê°-ì–¸ì–´ ì¡°í•©ì„ ì„±ê³µì ìœ¼ë¡œ í•´ì„í•˜ë©°, ê¸°ì¡´ ë°©ë²•ë³´ë‹¤ ì‘ì—… ì„±ê³µë¥ ì„ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ Bi-VLAëŠ” ë‹¤ì¤‘ ì‘ì—… ì²˜ë¦¬ì˜ ìœ ì—°ì„±ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Bi-VLAëŠ” ì–‘ë°©í–¥ ì œì–´ ê¸°ë°˜ ëª¨ë°© í•™ìŠµì„ í™•ì¥í•˜ì—¬ ë‹¨ì¼ ëª¨ë¸ë¡œ ì—¬ëŸ¬ ì‘ì—…ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.
- 2. ê¸°ì¡´ ì–‘ë°©í–¥ ì œì–´ ë°©ë²•ì€ ì‘ì—…ë³„ ëª¨ë¸ì´ í•„ìš”í•˜ì—¬ ì¼ë°˜ì„±ì´ ì œí•œë˜ì§€ë§Œ, Bi-VLAëŠ” ì‹œê°ì  íŠ¹ì§•ê³¼ ìì—°ì–´ ì§€ì‹œë¥¼ ìœµí•©í•˜ì—¬ ì´ í•œê³„ë¥¼ ê·¹ë³µí•©ë‹ˆë‹¤.
- 3. Bi-VLAëŠ” ì‹œê° ë° ì–¸ì–´ ê²°í•©ì„ ì„±ê³µì ìœ¼ë¡œ í•´ì„í•˜ê³ , ê¸°ì¡´ ì–‘ë°©í–¥ ì œì–´ ê¸°ë°˜ ëª¨ë°© í•™ìŠµì— ë¹„í•´ ì‘ì—… ì„±ê³µë¥ ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
- 4. ì‹¤í—˜ ê²°ê³¼, Bi-VLAëŠ” ì‹¤ì œ ì‘ì—…ì—ì„œ íš¨ê³¼ì ì„ì„ ì…ì¦í•˜ë©°, ì‹œê°ê³¼ ì–¸ì–´ì˜ ê²°í•©ì´ ë‹¤ì¬ë‹¤ëŠ¥ì„±ì„ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤.


---

*Generated on 2025-09-24 15:14:30*