<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T13:52:57.142061",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Cycle-Consistency in Question Answering",
    "Large Language Model",
    "Flan-T5 Model",
    "Reasoning Benchmarks"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Cycle-Consistency in Question Answering": 0.8,
    "Large Language Model": 0.85,
    "Flan-T5 Model": 0.75,
    "Reasoning Benchmarks": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Cycle-Consistency in Question Answering",
        "canonical": "Cycle-Consistency in Question Answering",
        "aliases": [
          "CCQA"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel reasoning method specifically proposed in the paper, making it a unique concept for linking.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are a central topic in the paper and connect to a broad range of related research.",
        "novelty_score": 0.2,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Flan-T5 model",
        "canonical": "Flan-T5 Model",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "The Flan-T5 model is specifically mentioned as a tool used in the research, providing a unique connection point.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      },
      {
        "surface": "Mathematical and Commonsense Reasoning Benchmarks",
        "canonical": "Reasoning Benchmarks",
        "aliases": [
          "Mathematical Reasoning",
          "Commonsense Reasoning"
        ],
        "category": "specific_connectable",
        "rationale": "These benchmarks are critical for evaluating the proposed method and connect to broader research on reasoning.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.65,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "inference-time reasoning",
      "state-of-the-art methods",
      "solution"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Cycle-Consistency in Question Answering",
      "resolved_canonical": "Cycle-Consistency in Question Answering",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.2,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Flan-T5 model",
      "resolved_canonical": "Flan-T5 Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Mathematical and Commonsense Reasoning Benchmarks",
      "resolved_canonical": "Reasoning Benchmarks",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.65,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# CCQA: Generating Question from Solution Can Improve Inference-Time Reasoning in SLMs

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18536.pdf)
**Category**: cs.AI
**Published**: 2025-09-24
**ArXiv ID**: [2509.18536](https://arxiv.org/abs/2509.18536)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/FLARE_ Faithful Logic-Aided Reasoning and Exploration_20250922|FLARE: Faithful Logic-Aided Reasoning and Exploration]] (85.6% similar)
- [[2025-09-23/Step Guided Reasoning_ Improving Mathematical Reasoning using Guidance Generation and Step Reasoning_20250923|Step Guided Reasoning: Improving Mathematical Reasoning using Guidance Generation and Step Reasoning]] (85.6% similar)
- [[2025-09-23/Large Language Models Meet Knowledge Graphs for Question Answering_ Synthesis and Opportunities_20250923|Large Language Models Meet Knowledge Graphs for Question Answering: Synthesis and Opportunities]] (84.4% similar)
- [[2025-09-23/Question Answering with LLMs and Learning from Answer Sets_20250923|Question Answering with LLMs and Learning from Answer Sets]] (83.8% similar)
- [[2025-09-22/Quantifying Self-Awareness of Knowledge in Large Language Models_20250922|Quantifying Self-Awareness of Knowledge in Large Language Models]] (83.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Reasoning Benchmarks|Reasoning Benchmarks]]
**âš¡ Unique Technical**: [[keywords/Cycle-Consistency in Question Answering|Cycle-Consistency in Question Answering]], [[keywords/Flan-T5 Model|Flan-T5 Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18536v1 Announce Type: cross 
Abstract: Recently, inference-time reasoning strategies have further improved the accuracy of large language models (LLMs), but their effectiveness on smaller models remains unclear. Based on the observation that conventional approaches often fail to improve performance in this context, we propose \textbf{C}ycle-\textbf{C}onsistency in \textbf{Q}uestion \textbf{A}nswering (CCQA), a novel reasoning method that can be effectively applied to SLMs. Inspired by cycle consistency, CCQA generates a question from each reasoning path and answer, evaluates each by its similarity to the original question, and then selects the candidate solution with the highest similarity score as the final response. Since conventional SLMs struggle to generate accurate questions from their own reasoning paths and answers, we employ a lightweight Flan-T5 model specialized for question generation to support this process efficiently. From the experimental results, it is verified that CCQA consistently outperforms existing state-of-the-art (SOTA) methods across eight models on mathematical and commonsense reasoning benchmarks. Furthermore, our method establishes a new practical baseline for efficient reasoning in SLMs. Source code can be found at https://github.com/scai-research/ccqa_official.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì†Œí˜• ì–¸ì–´ ëª¨ë¸(SLM)ì—ì„œ ì¶”ë¡  ì •í™•ë„ë¥¼ ë†’ì´ê¸° ìœ„í•œ ìƒˆë¡œìš´ ë°©ë²•ë¡ ì¸ CCQA(Cycle-Consistency in Question Answering)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. CCQAëŠ” ê° ì¶”ë¡  ê²½ë¡œì™€ ë‹µë³€ì—ì„œ ì§ˆë¬¸ì„ ìƒì„±í•˜ê³ , ì´ë¥¼ ì›ë˜ ì§ˆë¬¸ê³¼ì˜ ìœ ì‚¬ì„±ì„ í‰ê°€í•˜ì—¬ ê°€ì¥ ë†’ì€ ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ ê°€ì§„ í›„ë³´ë¥¼ ìµœì¢… ë‹µë³€ìœ¼ë¡œ ì„ íƒí•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤. ê¸°ì¡´ SLMì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´, ì§ˆë¬¸ ìƒì„±ì— íŠ¹í™”ëœ ê²½ëŸ‰ Flan-T5 ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, CCQAëŠ” ìˆ˜í•™ ë° ìƒì‹ ì¶”ë¡  ë²¤ì¹˜ë§ˆí¬ì—ì„œ ê¸°ì¡´ ìµœì²¨ë‹¨(SOTA) ë°©ë²•ë“¤ì„ ëŠ¥ê°€í•˜ë©°, SLMì˜ íš¨ìœ¨ì ì¸ ì¶”ë¡ ì„ ìœ„í•œ ìƒˆë¡œìš´ ì‹¤ìš©ì  ê¸°ì¤€ì„ ì œì‹œí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. CCQAëŠ” ì†Œí˜• ì–¸ì–´ ëª¨ë¸(SLM)ì— íš¨ê³¼ì ìœ¼ë¡œ ì ìš©í•  ìˆ˜ ìˆëŠ” ìƒˆë¡œìš´ ì¶”ë¡  ë°©ë²•ì…ë‹ˆë‹¤.
- 2. CCQAëŠ” ê° ì¶”ë¡  ê²½ë¡œì™€ ë‹µë³€ì—ì„œ ì§ˆë¬¸ì„ ìƒì„±í•˜ê³ , ì´ë¥¼ ì›ë˜ ì§ˆë¬¸ê³¼ì˜ ìœ ì‚¬ì„±ìœ¼ë¡œ í‰ê°€í•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ì„ íƒí•©ë‹ˆë‹¤.
- 3. ê²½ëŸ‰í™”ëœ Flan-T5 ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ SLMì˜ ì§ˆë¬¸ ìƒì„± ê³¼ì •ì„ ì§€ì›í•©ë‹ˆë‹¤.
- 4. CCQAëŠ” ìˆ˜í•™ ë° ìƒì‹ ì¶”ë¡  ë²¤ì¹˜ë§ˆí¬ì—ì„œ ê¸°ì¡´ ìµœì²¨ë‹¨(SOTA) ë°©ë²•ì„ ëŠ¥ê°€í•˜ëŠ” ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.
- 5. ì´ ë°©ë²•ì€ SLMì˜ íš¨ìœ¨ì ì¸ ì¶”ë¡ ì„ ìœ„í•œ ìƒˆë¡œìš´ ì‹¤ìš©ì  ê¸°ì¤€ì„ ì œì‹œí•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 13:52:57*