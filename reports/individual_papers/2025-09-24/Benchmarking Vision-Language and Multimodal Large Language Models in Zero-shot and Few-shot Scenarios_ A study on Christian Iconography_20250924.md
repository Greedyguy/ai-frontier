<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T16:10:04.060983",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multimodal Learning",
    "Vision-Language Model",
    "Christian Iconography",
    "Zero-Shot Learning",
    "Few-Shot Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multimodal Learning": 0.85,
    "Vision-Language Model": 0.87,
    "Christian Iconography": 0.78,
    "Zero-Shot Learning": 0.8,
    "Few-Shot Learning": 0.82
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multimodal Large Language Models",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal LLMs"
        ],
        "category": "specific_connectable",
        "rationale": "Multimodal Learning is a key concept in linking language and vision tasks, relevant to the study's focus on multimodal models.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.78,
        "link_intent_score": 0.85
      },
      {
        "surface": "Vision Language Models",
        "canonical": "Vision-Language Model",
        "aliases": [
          "VLMs"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-Language Models represent an evolved concept crucial for understanding the integration of visual and textual data.",
        "novelty_score": 0.5,
        "connectivity_score": 0.9,
        "specificity_score": 0.8,
        "link_intent_score": 0.87
      },
      {
        "surface": "Christian Iconography",
        "canonical": "Christian Iconography",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Christian Iconography is a unique technical domain that the study specifically addresses, providing a niche context for linking.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Zero-shot",
        "canonical": "Zero-Shot Learning",
        "aliases": [
          "Zero-shot"
        ],
        "category": "specific_connectable",
        "rationale": "Zero-Shot Learning is a specific connectable concept relevant to the study's evaluation of model performance without prior examples.",
        "novelty_score": 0.45,
        "connectivity_score": 0.82,
        "specificity_score": 0.72,
        "link_intent_score": 0.8
      },
      {
        "surface": "Few-shot",
        "canonical": "Few-Shot Learning",
        "aliases": [
          "Few-shot"
        ],
        "category": "specific_connectable",
        "rationale": "Few-Shot Learning is crucial for understanding the study's approach to enhancing model performance with minimal examples.",
        "novelty_score": 0.48,
        "connectivity_score": 0.85,
        "specificity_score": 0.75,
        "link_intent_score": 0.82
      }
    ],
    "ban_list_suggestions": [
      "performance",
      "method",
      "experiment"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multimodal Large Language Models",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.78,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Vision Language Models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.9,
        "specificity": 0.8,
        "link_intent": 0.87
      }
    },
    {
      "candidate_surface": "Christian Iconography",
      "resolved_canonical": "Christian Iconography",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Zero-shot",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.82,
        "specificity": 0.72,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Few-shot",
      "resolved_canonical": "Few-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.48,
        "connectivity": 0.85,
        "specificity": 0.75,
        "link_intent": 0.82
      }
    }
  ]
}
-->

# Benchmarking Vision-Language and Multimodal Large Language Models in Zero-shot and Few-shot Scenarios: A study on Christian Iconography

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18839.pdf)
**Category**: cs.CV
**Published**: 2025-09-24
**ArXiv ID**: [2509.18839](https://arxiv.org/abs/2509.18839)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/LLMs Can Compensate for Deficiencies in Visual Representations_20250922|LLMs Can Compensate for Deficiencies in Visual Representations]] (83.8% similar)
- [[2025-09-22/It Depends_ Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge_20250922|It Depends: Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge]] (83.7% similar)
- [[2025-09-22/Predicting Language Models' Success at Zero-Shot Probabilistic Prediction_20250922|Predicting Language Models' Success at Zero-Shot Probabilistic Prediction]] (83.6% similar)
- [[2025-09-24/Large Language Models Do Multi-Label Classification Differently_20250924|Large Language Models Do Multi-Label Classification Differently]] (83.3% similar)
- [[2025-09-23/Can LLMs Reason Over Non-Text Modalities in a Training-Free Manner? A Case Study with In-Context Representation Learning_20250923|Can LLMs Reason Over Non-Text Modalities in a Training-Free Manner? A Case Study with In-Context Representation Learning]] (83.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]], [[keywords/Zero-Shot Learning|Zero-Shot Learning]], [[keywords/Few-Shot Learning|Few-Shot Learning]]
**âš¡ Unique Technical**: [[keywords/Christian Iconography|Christian Iconography]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.18839v1 Announce Type: new 
Abstract: This study evaluates the capabilities of Multimodal Large Language Models (LLMs) and Vision Language Models (VLMs) in the task of single-label classification of Christian Iconography. The goal was to assess whether general-purpose VLMs (CLIP and SigLIP) and LLMs, such as GPT-4o and Gemini 2.5, can interpret the Iconography, typically addressed by supervised classifiers, and evaluate their performance. Two research questions guided the analysis: (RQ1) How do multimodal LLMs perform on image classification of Christian saints? And (RQ2), how does performance vary when enriching input with contextual information or few-shot exemplars? We conducted a benchmarking study using three datasets supporting Iconclass natively: ArtDL, ICONCLASS, and Wikidata, filtered to include the top 10 most frequent classes. Models were tested under three conditions: (1) classification using class labels, (2) classification with Iconclass descriptions, and (3) few-shot learning with five exemplars. Results were compared against ResNet50 baselines fine-tuned on the same datasets. The findings show that Gemini-2.5 Pro and GPT-4o outperformed the ResNet50 baselines. Accuracy dropped significantly on the Wikidata dataset, where Siglip reached the highest accuracy score, suggesting model sensitivity to image size and metadata alignment. Enriching prompts with class descriptions generally improved zero-shot performance, while few-shot learning produced lower results, with only occasional and minimal increments in accuracy. We conclude that general-purpose multimodal LLMs are capable of classification in visually complex cultural heritage domains. These results support the application of LLMs as metadata curation tools in digital humanities workflows, suggesting future research on prompt optimization and the expansion of the study to other classification strategies and models.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” ê¸°ë…êµ ë„ìƒí•™ì˜ ë‹¨ì¼ ë ˆì´ë¸” ë¶„ë¥˜ì—ì„œ ë‹¤ì¤‘ ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ê³¼ ë¹„ì „ ì–¸ì–´ ëª¨ë¸(VLMs)ì˜ ëŠ¥ë ¥ì„ í‰ê°€í–ˆìŠµë‹ˆë‹¤. CLIP, SigLIP, GPT-4o, Gemini 2.5ì™€ ê°™ì€ ì¼ë°˜ ëª©ì ì˜ VLMsì™€ LLMsê°€ ë„ìƒí•™ì„ í•´ì„í•  ìˆ˜ ìˆëŠ”ì§€ë¥¼ ì¡°ì‚¬í•˜ê³  ê·¸ ì„±ëŠ¥ì„ í‰ê°€í–ˆìŠµë‹ˆë‹¤. ì—°êµ¬ëŠ” ë‘ ê°€ì§€ ì§ˆë¬¸ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì§„í–‰ë˜ì—ˆìŠµë‹ˆë‹¤: (1) ë‹¤ì¤‘ ëª¨ë‹¬ LLMsê°€ ê¸°ë…êµ ì„±ì¸ì˜ ì´ë¯¸ì§€ ë¶„ë¥˜ì—ì„œ ì–´ë–»ê²Œ ìˆ˜í–‰ë˜ëŠ”ê°€? (2) ë§¥ë½ ì •ë³´ë‚˜ ì˜ˆì‹œë¥¼ ì¶”ê°€í•˜ë©´ ì„±ëŠ¥ì´ ì–´ë–»ê²Œ ë³€í•˜ëŠ”ê°€? ArtDL, ICONCLASS, Wikidata ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ ì„¸ ê°€ì§€ ì¡°ê±´ì—ì„œ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í–ˆìŠµë‹ˆë‹¤. ê²°ê³¼ì ìœ¼ë¡œ Gemini-2.5 Proì™€ GPT-4oê°€ ResNet50 ê¸°ì¤€ì„ ì´ˆê³¼í–ˆìœ¼ë©°, SigLIPì€ Wikidataì—ì„œ ê°€ì¥ ë†’ì€ ì •í™•ë„ë¥¼ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤. í´ë˜ìŠ¤ ì„¤ëª…ì„ ì¶”ê°€í•˜ë©´ ì„±ëŠ¥ì´ í–¥ìƒë˜ì—ˆìœ¼ë‚˜, ì˜ˆì‹œë¥¼ ì¶”ê°€í•œ í•™ìŠµì—ì„œëŠ” ì„±ëŠ¥ ì¦ê°€ê°€ ë¯¸ë¯¸í–ˆìŠµë‹ˆë‹¤. ì—°êµ¬ëŠ” ì¼ë°˜ ëª©ì ì˜ ë‹¤ì¤‘ ëª¨ë‹¬ LLMsê°€ ë³µì¡í•œ ë¬¸í™”ìœ ì‚° ë¶„ì•¼ì—ì„œ ë¶„ë¥˜ê°€ ê°€ëŠ¥í•¨ì„ ë³´ì—¬ì£¼ë©°, ë””ì§€í„¸ ì¸ë¬¸í•™ì—ì„œ ë©”íƒ€ë°ì´í„° ê´€ë¦¬ ë„êµ¬ë¡œì„œì˜ ê°€ëŠ¥ì„±ì„ ì œì‹œí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì´ ì—°êµ¬ëŠ” ê¸°ë…êµ ë„ìƒí•™ì˜ ë‹¨ì¼ ë ˆì´ë¸” ë¶„ë¥˜ ì‘ì—…ì—ì„œ ë©€í‹°ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ê³¼ ë¹„ì „ ì–¸ì–´ ëª¨ë¸(VLMs)ì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.
- 2. Gemini-2.5 Proì™€ GPT-4oëŠ” ResNet50 ê¸°ë°˜ ëª¨ë¸ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.
- 3. SigLIP ëª¨ë¸ì€ Wikidata ë°ì´í„°ì…‹ì—ì„œ ê°€ì¥ ë†’ì€ ì •í™•ë„ë¥¼ ê¸°ë¡í–ˆìœ¼ë©°, ì´ëŠ” ì´ë¯¸ì§€ í¬ê¸°ì™€ ë©”íƒ€ë°ì´í„° ì •ë ¬ì— ëŒ€í•œ ëª¨ë¸ì˜ ë¯¼ê°ì„±ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.
- 4. í´ë˜ìŠ¤ ì„¤ëª…ì„ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ëŠ” ì œë¡œìƒ· ì„±ëŠ¥ì„ ê°œì„ í–ˆì§€ë§Œ, ëª‡ ìƒ· í•™ìŠµì€ ì •í™•ë„ ì¦ê°€ê°€ ë¯¸ë¯¸í–ˆìŠµë‹ˆë‹¤.
- 5. ì¼ë°˜ ëª©ì ì˜ ë©€í‹°ëª¨ë‹¬ LLMsëŠ” ì‹œê°ì ìœ¼ë¡œ ë³µì¡í•œ ë¬¸í™”ìœ ì‚° ë¶„ì•¼ì—ì„œ ë¶„ë¥˜ê°€ ê°€ëŠ¥í•˜ë©°, ë””ì§€í„¸ ì¸ë¬¸í•™ ì›Œí¬í”Œë¡œìš°ì—ì„œ ë©”íƒ€ë°ì´í„° íë ˆì´ì…˜ ë„êµ¬ë¡œ í™œìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-24 16:10:04*