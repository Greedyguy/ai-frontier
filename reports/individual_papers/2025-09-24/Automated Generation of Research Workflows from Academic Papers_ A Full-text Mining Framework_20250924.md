<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T15:55:32.802214",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Natural Language Processing",
    "Positive-Unlabeled Learning",
    "SciBERT",
    "Flan-T5",
    "Few-Shot Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Natural Language Processing": 0.85,
    "Positive-Unlabeled Learning": 0.7,
    "SciBERT": 0.78,
    "Flan-T5": 0.75,
    "Few-Shot Learning": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Natural Language Processing",
        "canonical": "Natural Language Processing",
        "aliases": [
          "NLP"
        ],
        "category": "broad_technical",
        "rationale": "This is a key domain for the case study and connects to a broad range of related research topics.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Positive-Unlabeled Learning",
        "canonical": "Positive-Unlabeled Learning",
        "aliases": [
          "PU Learning"
        ],
        "category": "unique_technical",
        "rationale": "This technique is pivotal in identifying workflow-descriptive paragraphs, making it a unique technical element.",
        "novelty_score": 0.65,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      },
      {
        "surface": "SciBERT",
        "canonical": "SciBERT",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "SciBERT is a specialized model for scientific text, crucial for the text mining framework discussed.",
        "novelty_score": 0.5,
        "connectivity_score": 0.75,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Flan-T5",
        "canonical": "Flan-T5",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Flan-T5 is used for generating workflow phrases, linking it to advanced NLP techniques.",
        "novelty_score": 0.55,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      },
      {
        "surface": "Few-Shot Learning",
        "canonical": "Few-Shot Learning",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Few-Shot Learning is employed for classification, highlighting its relevance in modern AI applications.",
        "novelty_score": 0.4,
        "connectivity_score": 0.85,
        "specificity_score": 0.75,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "research workflows",
      "data preparation",
      "data processing",
      "data analysis"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Natural Language Processing",
      "resolved_canonical": "Natural Language Processing",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Positive-Unlabeled Learning",
      "resolved_canonical": "Positive-Unlabeled Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "SciBERT",
      "resolved_canonical": "SciBERT",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.75,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Flan-T5",
      "resolved_canonical": "Flan-T5",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Few-Shot Learning",
      "resolved_canonical": "Few-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.85,
        "specificity": 0.75,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# Automated Generation of Research Workflows from Academic Papers: A Full-text Mining Framework

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.12955.pdf)
**Category**: cs.CL
**Published**: 2025-09-24
**ArXiv ID**: [2509.12955](https://arxiv.org/abs/2509.12955)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/(P)rior(D)yna(F)low_ A Priori Dynamic Workflow Construction via Multi-Agent Collaboration_20250919|(P)rior(D)yna(F)low: A Priori Dynamic Workflow Construction via Multi-Agent Collaboration]] (84.6% similar)
- [[2025-09-23/WebResearcher_ Unleashing unbounded reasoning capability in Long-Horizon Agents_20250923|WebResearcher: Unleashing unbounded reasoning capability in Long-Horizon Agents]] (82.7% similar)
- [[2025-09-18/ComfyGPT_ A Self-Optimizing Multi-Agent System for Comprehensive ComfyUI Workflow Generation_20250918|ComfyGPT: A Self-Optimizing Multi-Agent System for Comprehensive ComfyUI Workflow Generation]] (82.7% similar)
- [[2025-09-18/$Agent^2$_ An Agent-Generates-Agent Framework for Reinforcement Learning Automation_20250918|$Agent^2$: An Agent-Generates-Agent Framework for Reinforcement Learning Automation]] (82.4% similar)
- [[2025-09-23/BAGELS_ Benchmarking the Automated Generation and Extraction of Limitations from Scholarly Text_20250923|BAGELS: Benchmarking the Automated Generation and Extraction of Limitations from Scholarly Text]] (82.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Natural Language Processing|Natural Language Processing]]
**ğŸ”— Specific Connectable**: [[keywords/SciBERT|SciBERT]], [[keywords/Flan-T5|Flan-T5]], [[keywords/Few-Shot Learning|Few-Shot Learning]]
**âš¡ Unique Technical**: [[keywords/Positive-Unlabeled Learning|Positive-Unlabeled Learning]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.12955v2 Announce Type: replace 
Abstract: The automated generation of research workflows is essential for improving the reproducibility of research and accelerating the paradigm of "AI for Science". However, existing methods typically extract merely fragmented procedural components and thus fail to capture complete research workflows. To address this gap, we propose an end-to-end framework that generates comprehensive, structured research workflows by mining full-text academic papers. As a case study in the Natural Language Processing (NLP) domain, our paragraph-centric approach first employs Positive-Unlabeled (PU) Learning with SciBERT to identify workflow-descriptive paragraphs, achieving an F1-score of 0.9772. Subsequently, we utilize Flan-T5 with prompt learning to generate workflow phrases from these paragraphs, yielding ROUGE-1, ROUGE-2, and ROUGE-L scores of 0.4543, 0.2877, and 0.4427, respectively. These phrases are then systematically categorized into data preparation, data processing, and data analysis stages using ChatGPT with few-shot learning, achieving a classification precision of 0.958. By mapping categorized phrases to their document locations in the documents, we finally generate readable visual flowcharts of the entire research workflows. This approach facilitates the analysis of workflows derived from an NLP corpus and reveals key methodological shifts over the past two decades, including the increasing emphasis on data analysis and the transition from feature engineering to ablation studies. Our work offers a validated technical framework for automated workflow generation, along with a novel, process-oriented perspective for the empirical investigation of evolving scientific paradigms. Source code and data are available at: https://github.com/ZH-heng/research_workflow.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì—°êµ¬ ì¬í˜„ì„±ì„ ë†’ì´ê³  "ê³¼í•™ì„ ìœ„í•œ AI" íŒ¨ëŸ¬ë‹¤ì„ì„ ê°€ì†í™”í•˜ê¸° ìœ„í•´ ìë™í™”ëœ ì—°êµ¬ ì›Œí¬í”Œë¡œìš° ìƒì„± í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ ë°©ë²•ë“¤ì´ ë‹¨í¸ì ì¸ ì ˆì°¨ë§Œ ì¶”ì¶œí•˜ëŠ” í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´, ë³¸ ì—°êµ¬ëŠ” í•™ìˆ  ë…¼ë¬¸ì˜ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ í¬ê´„ì ì´ê³  êµ¬ì¡°í™”ëœ ì—°êµ¬ ì›Œí¬í”Œë¡œìš°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ìì—°ì–´ ì²˜ë¦¬(NLP) ë¶„ì•¼ë¥¼ ì‚¬ë¡€ë¡œ, SciBERTë¥¼ í™œìš©í•œ Positive-Unlabeled í•™ìŠµì„ í†µí•´ ì›Œí¬í”Œë¡œìš°ë¥¼ ì„¤ëª…í•˜ëŠ” ë¬¸ë‹¨ì„ ì‹ë³„í•˜ê³ , Flan-T5ì™€ í”„ë¡¬í”„íŠ¸ í•™ìŠµì„ í†µí•´ ì›Œí¬í”Œë¡œìš° êµ¬ë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤. ìƒì„±ëœ êµ¬ë¬¸ì€ ChatGPTë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ì¤€ë¹„, ì²˜ë¦¬, ë¶„ì„ ë‹¨ê³„ë¡œ ë¶„ë¥˜ë˜ë©°, ë¬¸ì„œ ë‚´ ìœ„ì¹˜ì™€ ë§¤í•‘ë˜ì–´ ì‹œê°ì  íë¦„ë„ë¡œ í‘œí˜„ë©ë‹ˆë‹¤. ì´ ì ‘ê·¼ë²•ì€ ì§€ë‚œ 20ë…„ê°„ì˜ ë°©ë²•ë¡ ì  ë³€í™”ë¥¼ ë¶„ì„í•˜ëŠ” ë° ê¸°ì—¬í•˜ë©°, ìë™í™”ëœ ì›Œí¬í”Œë¡œìš° ìƒì„±ì— ëŒ€í•œ ê¸°ìˆ ì  í‹€ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì—°êµ¬ ì¬í˜„ì„±ì„ ê°œì„ í•˜ê³  "AI for Science" íŒ¨ëŸ¬ë‹¤ì„ì„ ê°€ì†í™”í•˜ê¸° ìœ„í•´ ìë™í™”ëœ ì—°êµ¬ ì›Œí¬í”Œë¡œìš° ìƒì„±ì´ ì¤‘ìš”í•©ë‹ˆë‹¤.
- 2. ë³¸ ì—°êµ¬ëŠ” í•™ìˆ  ë…¼ë¬¸ì˜ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ í¬ê´„ì ì´ê³  êµ¬ì¡°í™”ëœ ì—°êµ¬ ì›Œí¬í”Œë¡œìš°ë¥¼ ìƒì„±í•˜ëŠ” ì¢…ë‹¨ ê°„ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.
- 3. ìì—°ì–´ ì²˜ë¦¬(NLP) ë¶„ì•¼ì—ì„œ SciBERTë¥¼ í™œìš©í•œ Positive-Unlabeled(PU) í•™ìŠµì„ í†µí•´ ì›Œí¬í”Œë¡œìš°ë¥¼ ì„¤ëª…í•˜ëŠ” ë¬¸ë‹¨ì„ ì‹ë³„í•˜ì—¬ F1-score 0.9772ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.
- 4. Flan-T5ì™€ í”„ë¡¬í”„íŠ¸ í•™ìŠµì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ë‹¨ì—ì„œ ì›Œí¬í”Œë¡œìš° êµ¬ë¬¸ì„ ìƒì„±í•˜ê³ , ì´ë¥¼ ë°ì´í„° ì¤€ë¹„, ì²˜ë¦¬, ë¶„ì„ ë‹¨ê³„ë¡œ ì²´ê³„ì ìœ¼ë¡œ ë¶„ë¥˜í•˜ì—¬ ë¶„ë¥˜ ì •ë°€ë„ 0.958ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.
- 5. ë³¸ ì—°êµ¬ëŠ” ìë™í™”ëœ ì›Œí¬í”Œë¡œìš° ìƒì„±ì— ëŒ€í•œ ê¸°ìˆ ì  í”„ë ˆì„ì›Œí¬ë¥¼ ì œê³µí•˜ë©°, ê³¼í•™ì  íŒ¨ëŸ¬ë‹¤ì„ì˜ ë³€í™”ì— ëŒ€í•œ ìƒˆë¡œìš´ ê´€ì ì„ ì œì‹œí•©ë‹ˆë‹¤.


---

*Generated on 2025-09-24 15:55:32*