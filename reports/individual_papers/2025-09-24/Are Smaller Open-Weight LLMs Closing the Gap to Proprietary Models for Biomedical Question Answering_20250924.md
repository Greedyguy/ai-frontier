<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-24T15:14:13.601101",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Biomedical Question Answering",
    "Open-weight Model",
    "Ensemble Learning",
    "Few-Shot Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Biomedical Question Answering": 0.8,
    "Open-weight Model": 0.78,
    "Ensemble Learning": 0.77,
    "Few-Shot Learning": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Large Language Models"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's focus on comparing model types for biomedical question answering.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Biomedical Question Answering",
        "canonical": "Biomedical Question Answering",
        "aliases": [
          "BioQA"
        ],
        "category": "unique_technical",
        "rationale": "Specific domain application of LLMs discussed in the paper.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Open-weight Models",
        "canonical": "Open-weight Model",
        "aliases": [
          "Open-weight LLMs"
        ],
        "category": "unique_technical",
        "rationale": "Highlights the focus on open-source alternatives to proprietary models.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Ensemble Approaches",
        "canonical": "Ensemble Learning",
        "aliases": [
          "Ensemble Methods"
        ],
        "category": "specific_connectable",
        "rationale": "Describes a method used to enhance model performance in the study.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.65,
        "link_intent_score": 0.77
      },
      {
        "surface": "In-context Learning",
        "canonical": "Few-Shot Learning",
        "aliases": [
          "In-context Learning"
        ],
        "category": "specific_connectable",
        "rationale": "Relevant technique for improving model performance with minimal data.",
        "novelty_score": 0.6,
        "connectivity_score": 0.8,
        "specificity_score": 0.7,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "Task 13B Phase B",
      "BioASQ challenge",
      "DeepSeek-V3"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Biomedical Question Answering",
      "resolved_canonical": "Biomedical Question Answering",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Open-weight Models",
      "resolved_canonical": "Open-weight Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Ensemble Approaches",
      "resolved_canonical": "Ensemble Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.65,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "In-context Learning",
      "resolved_canonical": "Few-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.8,
        "specificity": 0.7,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Are Smaller Open-Weight LLMs Closing the Gap to Proprietary Models for Biomedical Question Answering?

## 📋 메타데이터

**Links**: [[daily_digest_20250924|20250924]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.18843.pdf)
**Category**: cs.LG
**Published**: 2025-09-24
**ArXiv ID**: [2509.18843](https://arxiv.org/abs/2509.18843)

## 🔗 유사한 논문
- [[2025-09-22/Evaluating the Limitations of Local LLMs in Solving Complex Programming Challenges_20250922|Evaluating the Limitations of Local LLMs in Solving Complex Programming Challenges]] (85.1% similar)
- [[2025-09-22/It Depends_ Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge_20250922|It Depends: Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge]] (84.1% similar)
- [[2025-09-23/When Big Models Train Small Ones_ Label-Free Model Parity Alignment for Efficient Visual Question Answering using Small VLMs_20250923|When Big Models Train Small Ones: Label-Free Model Parity Alignment for Efficient Visual Question Answering using Small VLMs]] (84.0% similar)
- [[2025-09-23/Beyond Prompting_ An Efficient Embedding Framework for Open-Domain Question Answering_20250923|Beyond Prompting: An Efficient Embedding Framework for Open-Domain Question Answering]] (83.8% similar)
- [[2025-09-23/LLaSA_ A Sensor-Aware LLM for Natural Language Reasoning of Human Activity from IMU Data_20250923|LLaSA: A Sensor-Aware LLM for Natural Language Reasoning of Human Activity from IMU Data]] (83.0% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Ensemble Learning|Ensemble Learning]], [[keywords/Few-Shot Learning|Few-Shot Learning]]
**⚡ Unique Technical**: [[keywords/Biomedical Question Answering|Biomedical Question Answering]], [[keywords/Open-weight Model|Open-weight Model]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.18843v1 Announce Type: cross 
Abstract: Open-weight versions of large language models (LLMs) are rapidly advancing, with state-of-the-art models like DeepSeek-V3 now performing comparably to proprietary LLMs. This progression raises the question of whether small open-weight LLMs are capable of effectively replacing larger closed-source models. We are particularly interested in the context of biomedical question-answering, a domain we explored by participating in Task 13B Phase B of the BioASQ challenge. In this work, we compare several open-weight models against top-performing systems such as GPT-4o, GPT-4.1, Claude 3.5 Sonnet, and Claude 3.7 Sonnet. To enhance question answering capabilities, we use various techniques including retrieving the most relevant snippets based on embedding distance, in-context learning, and structured outputs. For certain submissions, we utilize ensemble approaches to leverage the diverse outputs generated by different models for exact-answer questions. Our results demonstrate that open-weight LLMs are comparable to proprietary ones. In some instances, open-weight LLMs even surpassed their closed counterparts, particularly when ensembling strategies were applied. All code is publicly available at https://github.com/evidenceprime/BioASQ-13b.

## 📝 요약

이 논문은 대형 언어 모델(LLM)의 공개 가중치 버전이 빠르게 발전하고 있으며, 특히 DeepSeek-V3와 같은 최신 모델이 독점 LLM과 유사한 성능을 보이고 있음을 다룹니다. 연구는 바이오메디컬 질문-응답 분야에서 소형 공개 가중치 LLM이 대형 폐쇄형 모델을 효과적으로 대체할 수 있는지를 탐구합니다. BioASQ 챌린지의 Task 13B Phase B에 참여하여 여러 공개 가중치 모델을 GPT-4o, GPT-4.1, Claude 3.5 Sonnet, Claude 3.7 Sonnet 등과 비교했습니다. 질문 응답 능력을 향상시키기 위해 임베딩 거리 기반의 관련 스니펫 검색, 맥락 내 학습, 구조화된 출력 등 다양한 기법을 사용했으며, 일부 제출에서는 다양한 모델의 출력을 활용한 앙상블 접근법을 적용했습니다. 결과적으로, 공개 가중치 LLM은 독점 모델과 비교할 만한 성능을 보였으며, 특히 앙상블 전략을 적용했을 때는 폐쇄형 모델을 능가하기도 했습니다. 모든 코드는 공개되어 있습니다.

## 🎯 주요 포인트

- 1. 최신 오픈 가중치 대형 언어 모델(LLM)들이 DeepSeek-V3와 같은 모델을 통해 독점 LLM과 유사한 성능을 보이고 있다.
- 2. 소형 오픈 가중치 LLM이 대형 폐쇄형 모델을 효과적으로 대체할 수 있는지에 대한 의문이 제기되고 있다.
- 3. 바이오메디컬 질문-응답 분야에서 오픈 가중치 모델과 GPT-4o, Claude 3.5 Sonnet 등과 같은 상위 성능 시스템을 비교하였다.
- 4. 질문 응답 능력을 향상시키기 위해 임베딩 거리 기반의 관련 스니펫 검색, 맥락 내 학습, 구조화된 출력 등의 기법을 사용하였다.
- 5. 오픈 가중치 LLM이 독점 모델과 비교할 만한 성능을 보이며, 일부 경우에는 앙상블 전략을 통해 더 나은 성능을 발휘하였다.


---

*Generated on 2025-09-24 15:14:13*