# FOVAL: Calibration-Free and Subject-Invariant Fixation Depth Estimation Across Diverse Eye-Tracking Datasets

**Korean Title:** FOVAL: ë‹¤ì–‘í•œ ì‹œì„  ì¶”ì  ë°ì´í„°ì…‹ì—ì„œ ë³´ì •ì´ í•„ìš” ì—†ê³  í”¼í—˜ìì— ë¬´ê´€í•œ ê³ ì • ê¹Šì´ ì¶”ì •

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Calibration-Free Fixation Depth Estimation

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/ForceVLA_ Enhancing VLA Models with a Force-aware MoE for Contact-rich Manipulation_20250919|ForceVLA Enhancing VLA Models with a Force-aware MoE for Contact-rich Manipulation]] (82.5% similar)
- [[2025-09-22/ORCA_ Agentic Reasoning For Hallucination and Adversarial Robustness in Vision-Language Models_20250922|ORCA Agentic Reasoning For Hallucination and Adversarial Robustness in Vision-Language Models]] (81.2% similar)
- [[2025-09-19/Depth AnyEvent_ A Cross-Modal Distillation Paradigm for Event-Based Monocular Depth Estimation_20250919|Depth AnyEvent A Cross-Modal Distillation Paradigm for Event-Based Monocular Depth Estimation]] (81.1% similar)
- [[2025-09-18/Lost in Translation Vocabulary Alignment for Source-Free Domain Adaptation in Open-Vocabulary Semantic Segmentation_20250918|Lost in Translation Vocabulary Alignment for Source-Free Domain Adaptation in Open-Vocabulary Semantic Segmentation]] (80.9% similar)
- [[2025-09-22/Saccadic Vision for Fine-Grained Visual Classification_20250922|Saccadic Vision for Fine-Grained Visual Classification]] (80.9% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2408.03591v2 Announce Type: replace-cross 
Abstract: Accurate fixation depth estimation is essential for applications in extended reality (XR), robotics, and human-computer interaction. However, current methods heavily depend on user-specific calibration, which limits their scalability and usability. We introduce FOVAL, a robust calibration-free approach that combines spatiotemporal sequence modelling via Long Short-Term Memory (LSTM) networks with subject-invariant feature engineering and normalisation. Compared to Transformers, Temporal Convolutional Networks (TCNs), and CNNs, FOVAL achieves superior performance, particularly in scenarios with limited and noisy gaze data. Evaluations across three benchmark datasets using Leave-One-Out Cross-Validation (LOOCV) and cross-dataset validation show a mean absolute error (MAE) of 9.1 cm and strong generalisation without calibration. We further analyse inter-subject variability and domain shifts, providing insight into model robustness and adaptation. FOVAL's scalability and accuracy make it highly suitable for real-world deployment.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2408.03591v2 ë°œí‘œ ìœ í˜•: êµì°¨ ëŒ€ì²´  
ì´ˆë¡: ì •í™•í•œ ê³ ì • ê¹Šì´ ì¶”ì •ì€ í™•ì¥ í˜„ì‹¤(XR), ë¡œë´‡ ê³µí•™, ì¸ê°„-ì»´í“¨í„° ìƒí˜¸ì‘ìš© ë¶„ì•¼ì—ì„œ í•„ìˆ˜ì ì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ í˜„ì¬ì˜ ë°©ë²•ë“¤ì€ ì‚¬ìš©ìë³„ ë³´ì •ì— í¬ê²Œ ì˜ì¡´í•˜ì—¬ í™•ì¥ì„±ê³¼ ì‚¬ìš©ì„±ì„ ì œí•œí•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” FOVALì„ ì†Œê°œí•©ë‹ˆë‹¤. ì´ëŠ” Long Short-Term Memory (LSTM) ë„¤íŠ¸ì›Œí¬ë¥¼ í†µí•œ ì‹œê³µê°„ ì‹œí€€ìŠ¤ ëª¨ë¸ë§ê³¼ ì£¼ì²´ ë¶ˆë³€ íŠ¹ì§• ê³µí•™ ë° ì •ê·œí™”ë¥¼ ê²°í•©í•œ ê²¬ê³ í•œ ë³´ì • ì—†ëŠ” ì ‘ê·¼ ë°©ì‹ì…ë‹ˆë‹¤. Transformer, Temporal Convolutional Networks (TCNs), CNNsì™€ ë¹„êµí•˜ì—¬, FOVALì€ íŠ¹íˆ ì œí•œì ì´ê³  ì¡ìŒì´ ë§ì€ ì‹œì„  ë°ì´í„° ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë°œíœ˜í•©ë‹ˆë‹¤. Leave-One-Out Cross-Validation (LOOCV) ë° êµì°¨ ë°ì´í„°ì…‹ ê²€ì¦ì„ ì‚¬ìš©í•œ ì„¸ ê°€ì§€ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ í‰ê°€ì—ì„œ í‰ê·  ì ˆëŒ€ ì˜¤ì°¨(MAE) 9.1 cmì™€ ë³´ì • ì—†ëŠ” ê°•ë ¥í•œ ì¼ë°˜í™”ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ë˜í•œ ì£¼ì²´ ê°„ ë³€ë™ì„±ê³¼ ë„ë©”ì¸ ë³€í™”ë¥¼ ë¶„ì„í•˜ì—¬ ëª¨ë¸ì˜ ê²¬ê³ ì„±ê³¼ ì ì‘ì— ëŒ€í•œ í†µì°°ë ¥ì„ ì œê³µí•©ë‹ˆë‹¤. FOVALì˜ í™•ì¥ì„±ê³¼ ì •í™•ì„±ì€ ì‹¤ì œ í™˜ê²½ì—ì„œì˜ ë°°í¬ì— ë§¤ìš° ì í•©í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ XR, ë¡œë´‡ê³µí•™, ì¸ê°„-ì»´í“¨í„° ìƒí˜¸ì‘ìš©ì—ì„œ ì¤‘ìš”í•œ ê³ ì • ê¹Šì´ ì¶”ì •ì„ ìœ„í•œ ìƒˆë¡œìš´ ë°©ë²•ë¡ ì¸ FOVALì„ ì†Œê°œí•©ë‹ˆë‹¤. FOVALì€ ì‚¬ìš©ìë³„ ë³´ì • ì—†ì´ LSTM ë„¤íŠ¸ì›Œí¬ë¥¼ í™œìš©í•œ ì‹œê³µê°„ ì‹œí€€ìŠ¤ ëª¨ë¸ë§ê³¼ ì£¼ì œ ë¶ˆë³€ì  íŠ¹ì§• ê³µí•™ ë° ì •ê·œí™”ë¥¼ ê²°í•©í•˜ì—¬ ê¸°ì¡´ ë°©ë²•ì˜ í•œê³„ë¥¼ ê·¹ë³µí•©ë‹ˆë‹¤. FOVALì€ ì œí•œì ì´ê³  ì¡ìŒì´ ë§ì€ ì‹œì„  ë°ì´í„° ìƒí™©ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì´ë©°, ì„¸ ê°€ì§€ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì—ì„œ Leave-One-Out êµì°¨ ê²€ì¦ê³¼ êµì°¨ ë°ì´í„°ì…‹ ê²€ì¦ì„ í†µí•´ í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ 9.1 cmë¥¼ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, ì£¼ì œ ê°„ ë³€ë™ì„±ê³¼ ë„ë©”ì¸ ë³€í™”ì— ëŒ€í•œ ë¶„ì„ì„ í†µí•´ ëª¨ë¸ì˜ ê²¬ê³ ì„±ê³¼ ì ì‘ë ¥ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤. FOVALì€ ë³´ì • ì—†ì´ë„ ë†’ì€ ì •í™•ë„ì™€ í™•ì¥ì„±ì„ ì œê³µí•˜ì—¬ ì‹¤ì œ ì‘ìš©ì— ì í•©í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. FOVALì€ ì‚¬ìš©ìë³„ ë³´ì • ì—†ì´ë„ ì •í™•í•œ ê³ ì • ê¹Šì´ ì¶”ì •ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ê°•ë ¥í•œ ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤.

- 2. LSTM ë„¤íŠ¸ì›Œí¬ë¥¼ í™œìš©í•œ ì‹œê³µê°„ ì‹œí€€ìŠ¤ ëª¨ë¸ë§ê³¼ ì£¼ì œ ë¶ˆë³€ì  íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§ ë° ì •ê·œí™”ë¥¼ ê²°í•©í•˜ì—¬ ë†’ì€ ì„±ëŠ¥ì„ ë‹¬ì„±í•©ë‹ˆë‹¤.

- 3. FOVALì€ ì œí•œì ì´ê³  ì¡ìŒì´ ë§ì€ ì‹œì„  ë°ì´í„° ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ íŠ¹íˆ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì´ë©°, ê¸°ì¡´ì˜ Transformer, TCN, CNNë³´ë‹¤ ìš°ìˆ˜í•©ë‹ˆë‹¤.

- 4. ì„¸ ê°€ì§€ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì—ì„œ LOOCVì™€ êµì°¨ ë°ì´í„°ì…‹ ê²€ì¦ì„ í†µí•´ í‰ê·  ì ˆëŒ€ ì˜¤ì°¨(MAE) 9.1 cmë¥¼ ê¸°ë¡í•˜ë©°, ë³´ì • ì—†ì´ë„ ê°•ë ¥í•œ ì¼ë°˜í™” ëŠ¥ë ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

- 5. FOVALì˜ í™•ì¥ì„±ê³¼ ì •í™•ì„±ì€ ì‹¤ì œ í™˜ê²½ì—ì„œì˜ í™œìš©ì— ë§¤ìš° ì í•©í•©ë‹ˆë‹¤.

---

*Generated on 2025-09-22 14:37:12*