# LLM Cache Bandit Revisited: Addressing Query Heterogeneity for Cost-Effective LLM Inference

**Korean Title:** LLM ìºì‹œ ë°´ë”§ ì¬ê²€í† : ë¹„ìš© íš¨ìœ¨ì ì¸ LLM ì¶”ë¡ ì„ ìœ„í•œ ì¿¼ë¦¬ ì´ì§ˆì„± í•´ê²°

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[reports/digests/daily_digest_20250922|2025-09-22]] [[keywords/evolved/Query Heterogeneity|Query Heterogeneity]] [[keywords/specific/Knapsack Problem|Knapsack Problem]] [[keywords/broad/LLM|LLM]] [[keywords/broad/Cache Management|Cache Management]] [[keywords/unique/LLM Cache Bandit|LLM Cache Bandit]] [[categories/cs.CL|cs.CL]] [[2025-09-22/Robustifying Learning-Augmented Caching Efficiently without Compromising 1-Consistency_20250922|Robustifying Learning-Augmented Caching Efficiently without Compromising 1-Consistency]] (82.5% similar) [[2025-09-22/KVCompose_ Efficient Structured KV Cache Compression with Composite Tokens_20250922|KVCompose: Efficient Structured KV Cache Compression with Composite Tokens]] (82.2% similar) [[2025-09-22/Cache-of-Thought_ Master-Apprentice Framework for Cost-Effective Vision Language Model Reasoning_20250922|Cache-of-Thought: Master-Apprentice Framework for Cost-Effective Vision Language Model Reasoning]] (81.4% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Query Heterogeneity
**ğŸ”— Specific Connectable**: Knapsack Problem
**ğŸ”¬ Broad Technical**: LLM, Cache Management
**â­ Unique Technical**: LLM Cache Bandit
## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Robustifying Learning-Augmented Caching Efficiently without Compromising 1-Consistency_20250922|Robustifying Learning-Augmented Caching Efficiently without Compromising 1-Consistency]] (82.5% similar)
- [[2025-09-22/KVCompose_ Efficient Structured KV Cache Compression with Composite Tokens_20250922|KVCompose Efficient Structured KV Cache Compression with Composite Tokens]] (82.2% similar)
- [[2025-09-22/Cache-of-Thought_ Master-Apprentice Framework for Cost-Effective Vision Language Model Reasoning_20250922|Cache-of-Thought Master-Apprentice Framework for Cost-Effective Vision Language Model Reasoning]] (81.4% similar)
- [[2025-09-18/Stochastic Bilevel Optimization with Heavy-Tailed Noise_20250918|Stochastic Bilevel Optimization with Heavy-Tailed Noise]] (79.6% similar)
- [[2025-09-22/CARD_ A Cache-Assisted Parallel Speculative Decoding Framework via Query-and-Correct Paradigm for Accelerating LLM Inference_20250922|CARD A Cache-Assisted Parallel Speculative Decoding Framework via Query-and-Correct Paradigm for Accelerating LLM Inference]] (79.5% similar)


**ArXiv ID**: [2509.15515](https://arxiv.org/abs/2509.15515)
**Published**: 2025-09-22
**Category**: cs.CL
**PDF**: [Download](https://arxiv.org/pdf/2509.15515.pdf)


**ArXiv ID**: [2509.15515](https://arxiv.org/abs/2509.15515)
**Published**: 2025-09-22
**Category**: cs.CL
**PDF**: [Download](https://arxiv.org/pdf/2509.15515.pdf)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Query Heterogeneity
**ğŸ”— Specific Connectable**: Knapsack Problem
**â­ Unique Technical**: LLM Cache Bandit
**ğŸ”¬ Broad Technical**: LLM, Cache Management

## ğŸ·ï¸ ì¶”ì¶œëœ í‚¤ì›Œë“œ



`LLM` â€¢ 

`Cache Management` â€¢ 

`Knapsack Problem` â€¢ 

`LLM Cache Bandit` â€¢ 

`Query Heterogeneity`



## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸

Similar papers will be displayed here based on embedding similarity.

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15515v1 Announce Type: new 
Abstract: This paper revisits the LLM cache bandit problem, with a special focus on addressing the query heterogeneity for cost-effective LLM inference. Previous works often assume uniform query sizes. Heterogeneous query sizes introduce a combinatorial structure for cache selection, making the cache replacement process more computationally and statistically challenging. We treat optimal cache selection as a knapsack problem and employ an accumulation-based strategy to effectively balance computational overhead and cache updates. In theoretical analysis, we prove that the regret of our algorithm achieves an $O(\sqrt{MNT})$ bound, improving the coefficient of $\sqrt{MN}$ compared to the $O(MN\sqrt{T})$ result in Berkeley, where $N$ is the total number of queries and $M$ is the cache size. Additionally, we also provide a problem-dependent bound, which was absent in previous works. The experiment rely on real-world data show that our algorithm reduces the total cost by approximately 12\%.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15515v1 ë°œí‘œ ìœ í˜•: ìƒˆë¡œìš´ ë…¼ë¬¸  
ì´ˆë¡: ë³¸ ë…¼ë¬¸ì€ ë¹„ìš© íš¨ìœ¨ì ì¸ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM) ì¶”ë¡ ì„ ìœ„í•´ ì¿¼ë¦¬ ì´ì§ˆì„±ì„ í•´ê²°í•˜ëŠ” ë° ì¤‘ì ì„ ë‘ê³  LLM ìºì‹œ ë°´ë”§ ë¬¸ì œë¥¼ ì¬ê²€í† í•©ë‹ˆë‹¤. ì´ì „ ì—°êµ¬ë“¤ì€ ì¢…ì¢… ê· ì¼í•œ ì¿¼ë¦¬ í¬ê¸°ë¥¼ ê°€ì •í•©ë‹ˆë‹¤. ì´ì§ˆì ì¸ ì¿¼ë¦¬ í¬ê¸°ëŠ” ìºì‹œ ì„ íƒì— ì¡°í•©ì  êµ¬ì¡°ë¥¼ ë„ì…í•˜ì—¬ ìºì‹œ êµì²´ ê³¼ì •ì„ ë” ë³µì¡í•˜ê³  í†µê³„ì ìœ¼ë¡œ ë„ì „ì ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ìµœì ì˜ ìºì‹œ ì„ íƒì„ ë°°ë‚­ ë¬¸ì œë¡œ ê°„ì£¼í•˜ê³ , ê³„ì‚° ì˜¤ë²„í—¤ë“œì™€ ìºì‹œ ì—…ë°ì´íŠ¸ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ê· í˜• ì¡ê¸° ìœ„í•´ ì¶•ì  ê¸°ë°˜ ì „ëµì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ë¡ ì  ë¶„ì„ì—ì„œ, ìš°ë¦¬ëŠ” ìš°ë¦¬ì˜ ì•Œê³ ë¦¬ì¦˜ì˜ í›„íšŒê°€ $O(\sqrt{MNT})$ ê²½ê³„ë¥¼ ë‹¬ì„±í•¨ì„ ì¦ëª…í•˜ë©°, ì´ëŠ” ë²„í´ë¦¬ì˜ $O(MN\sqrt{T})$ ê²°ê³¼ì— ë¹„í•´ $\sqrt{MN}$ ê³„ìˆ˜ë¥¼ ê°œì„ í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œ $N$ì€ ì´ ì¿¼ë¦¬ ìˆ˜ì´ê³  $M$ì€ ìºì‹œ í¬ê¸°ì…ë‹ˆë‹¤. ì¶”ê°€ì ìœ¼ë¡œ, ì´ì „ ì—°êµ¬ì—ì„œ ê²°ì—¬ë˜ì—ˆë˜ ë¬¸ì œ ì˜ì¡´ì  ê²½ê³„ë„ ì œê³µí•©ë‹ˆë‹¤. ì‹¤ì œ ë°ì´í„°ì— ê¸°ë°˜í•œ ì‹¤í—˜ì€ ìš°ë¦¬ì˜ ì•Œê³ ë¦¬ì¦˜ì´ ì´ ë¹„ìš©ì„ ì•½ 12% ê°ì†Œì‹œí‚´ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ LLM ìºì‹œ ë°´ë”§ ë¬¸ì œë¥¼ ì¬ê²€í† í•˜ë©°, íŠ¹íˆ ë¹„ìš© íš¨ìœ¨ì ì¸ LLM ì¶”ë¡ ì„ ìœ„í•œ ì¿¼ë¦¬ ì´ì§ˆì„± ë¬¸ì œë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. ê¸°ì¡´ ì—°êµ¬ëŠ” ì£¼ë¡œ ê· ì¼í•œ ì¿¼ë¦¬ í¬ê¸°ë¥¼ ê°€ì •í–ˆìœ¼ë‚˜, ì´ì§ˆì ì¸ ì¿¼ë¦¬ í¬ê¸°ëŠ” ìºì‹œ ì„ íƒì˜ ì¡°í•©ì  êµ¬ì¡°ë¥¼ ë„ì…í•˜ì—¬ ìºì‹œ êµì²´ ê³¼ì •ì„ ë” ë³µì¡í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤. ë³¸ ì—°êµ¬ëŠ” ìµœì ì˜ ìºì‹œ ì„ íƒì„ ë°°ë‚­ ë¬¸ì œë¡œ ê°„ì£¼í•˜ê³ , ëˆ„ì  ê¸°ë°˜ ì „ëµì„ ì‚¬ìš©í•˜ì—¬ ê³„ì‚° ì˜¤ë²„í—¤ë“œì™€ ìºì‹œ ì—…ë°ì´íŠ¸ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ê· í˜• ì¡ìŠµë‹ˆë‹¤. ì´ë¡ ì  ë¶„ì„ì—ì„œ, ì œì•ˆëœ ì•Œê³ ë¦¬ì¦˜ì˜ í›„íšŒê°€ $O(\sqrt{MNT})$ ê²½ê³„ë¥¼ ë‹¬ì„±í•¨ì„ ì¦ëª…í•˜ë©°, ì´ëŠ” Berkeleyì˜ $O(MN\sqrt{T})$ ê²°ê³¼ì— ë¹„í•´ $\sqrt{MN}$ ê³„ìˆ˜ë¥¼ ê°œì„ í•©ë‹ˆë‹¤. ë˜í•œ, ì´ì „ ì—°êµ¬ì— ì—†ë˜ ë¬¸ì œ ì¢…ì†ì ì¸ ê²½ê³„ë„ ì œê³µí•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ì•Œê³ ë¦¬ì¦˜ì€ ì´ ë¹„ìš©ì„ ì•½ 12% ì ˆê°í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸


- 1. ë³¸ ë…¼ë¬¸ì€ LLM ìºì‹œ ë°´ë”§ ë¬¸ì œë¥¼ ì¬ê²€í† í•˜ë©°, ë¹„ìš© íš¨ìœ¨ì ì¸ LLM ì¶”ë¡ ì„ ìœ„í•œ ì¿¼ë¦¬ ì´ì§ˆì„± ë¬¸ì œë¥¼ ì¤‘ì ì ìœ¼ë¡œ ë‹¤ë£¹ë‹ˆë‹¤.

- 2. ì´ì§ˆì ì¸ ì¿¼ë¦¬ í¬ê¸°ëŠ” ìºì‹œ ì„ íƒì— ì¡°í•©ì  êµ¬ì¡°ë¥¼ ë„ì…í•˜ì—¬ ìºì‹œ êµì²´ ê³¼ì •ì„ ë” ë³µì¡í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤.

- 3. ìµœì ì˜ ìºì‹œ ì„ íƒì„ ë°°ë‚­ ë¬¸ì œë¡œ ê°„ì£¼í•˜ê³ , ê³„ì‚° ì˜¤ë²„í—¤ë“œì™€ ìºì‹œ ì—…ë°ì´íŠ¸ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ê· í˜• ì¡ê¸° ìœ„í•œ ëˆ„ì  ê¸°ë°˜ ì „ëµì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

- 4. ì´ë¡ ì  ë¶„ì„ì—ì„œ ìš°ë¦¬ì˜ ì•Œê³ ë¦¬ì¦˜ì´ $O(\sqrt{MNT})$ì˜ í›„íšŒë¥¼ ë‹¬ì„±í•¨ì„ ì¦ëª…í•˜ë©°, ì´ëŠ” Berkeleyì˜ $O(MN\sqrt{T})$ ê²°ê³¼ì™€ ë¹„êµí•˜ì—¬ $\sqrt{MN}$ì˜ ê³„ìˆ˜ë¥¼ ê°œì„ í•©ë‹ˆë‹¤.

- 5. ì‹¤ì œ ë°ì´í„°ì— ê¸°ë°˜í•œ ì‹¤í—˜ ê²°ê³¼, ìš°ë¦¬ì˜ ì•Œê³ ë¦¬ì¦˜ì€ ì´ ë¹„ìš©ì„ ì•½ 12% ì ˆê°í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-22 16:22:18*