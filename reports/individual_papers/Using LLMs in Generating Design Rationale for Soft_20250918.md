
# Using LLMs in Generating Design Rationale for Software Architecture Decisions

**Korean Title:** ì†Œí”„íŠ¸ì›¨ì–´ ì•„í‚¤í…ì²˜ ê²°ì •ì— ëŒ€í•œ ì„¤ê³„ ê·¼ê±° ìƒì„±ì— LLM ì‚¬ìš©í•˜ê¸°

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-18|2025-09-18]] [[keywords/evolved/Multi-agent RAG|Multi-agent RAG]] [[keywords/broad/Large Language Models|Large Language Models]] [[keywords/broad/Design Rationale|Design Rationale]] [[keywords/specific/Stack Overflow|Stack Overflow]] [[keywords/unique/Chain of Thought (CoT|Chain of Thought (CoT]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Text Comprehension
**ğŸ”¬ Broad Technical**: Large Language Models, Design Rationale
**ğŸ”— Specific Connectable**: Stack Overflow
**â­ Unique Technical**: Chain of Thought (CoT

**ArXiv ID**: [2504.20781](https://arxiv.org/abs/2504.20781)
**Published**: 2025-09-18
**Category**: cs.AI
**PDF**: [Download](https://arxiv.org/pdf/2504.20781.pdf)


## ğŸ·ï¸ ì¶”ì¶œëœ í‚¤ì›Œë“œ



`Large Language Models` â€¢ 

`Design Rationale` â€¢ 

`Stack Overflow` â€¢ 

`Chain of Thought (CoT` â€¢ 

`LLM-based Agents`



## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2504.20781v2 Announce Type: replace-cross 
Abstract: Design Rationale (DR) for software architecture decisions refers to the reasoning underlying architectural choices, which provides valuable insights into the different phases of the architecting process throughout software development. However, in practice, DR is often inadequately documented due to a lack of motivation and effort from developers. With the recent advancements in Large Language Models (LLMs), their capabilities in text comprehension, reasoning, and generation may enable the generation and recovery of DR for architecture decisions. In this study, we evaluated the performance of LLMs in generating DR for architecture decisions. First, we collected 50 Stack Overflow (SO) posts, 25 GitHub issues, and 25 GitHub discussions related to architecture decisions to construct a dataset of 100 architecture-related problems. Then, we selected five LLMs to generate DR for the architecture decisions with three prompting strategies, including zero-shot, chain of thought (CoT), and LLM-based agents. With the DR provided by human experts as ground truth, the Precision of LLM-generated DR with the three prompting strategies ranges from 0.267 to 0.278, Recall from 0.627 to 0.715, and F1-score from 0.351 to 0.389. Additionally, 64.45% to 69.42% of the arguments of DR not mentioned by human experts are also helpful, 4.12% to 4.87% of the arguments have uncertain correctness, and 1.59% to 3.24% of the arguments are potentially misleading. To further understand the trustworthiness and applicability of LLM-generated DR in practice, we conducted semi-structured interviews with six practitioners. Based on the experimental and interview results, we discussed the pros and cons of the three prompting strategies, the strengths and limitations of LLM-generated DR, and the implications for the practical use of LLM-generated DR.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2504.20781v2 ë°œí‘œ ìœ í˜•: replace-cross
ìš”ì•½: ì†Œí”„íŠ¸ì›¨ì–´ ì•„í‚¤í…ì²˜ ê²°ì •ì— ëŒ€í•œ ë””ìì¸ ê·¼ê±° (DR)ëŠ” ì•„í‚¤í…ì²˜ ì„ íƒì— ëŒ€í•œ ì¶”ë¡ ì„ ì˜ë¯¸í•˜ë©°, ì´ëŠ” ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ ê³¼ì • ì „ì²´ì—ì„œ ì•„í‚¤í…ì²˜í™” í”„ë¡œì„¸ìŠ¤ì˜ ë‹¤ì–‘í•œ ë‹¨ê³„ì— ëŒ€í•œ ìœ ìš©í•œ í†µì°°ë ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì‹¤ì œë¡œëŠ” DRì´ ê°œë°œìë“¤ì˜ ë™ê¸° ë¶€ì—¬ì™€ ë…¸ë ¥ ë¶€ì¡±ìœ¼ë¡œ ì¸í•´ ë¶€ì ì ˆí•˜ê²Œ ë¬¸ì„œí™”ë˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. ìµœê·¼ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ (LLM)ì˜ ë°œì „ìœ¼ë¡œ ì¸í•´ í…ìŠ¤íŠ¸ ì´í•´, ì¶”ë¡  ë° ìƒì„± ëŠ¥ë ¥ì´ í–¥ìƒë˜ì–´ ì•„í‚¤í…ì²˜ ê²°ì •ì— ëŒ€í•œ DRì˜ ìƒì„± ë° ë³µêµ¬ê°€ ê°€ëŠ¥í•´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” LLMì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ì—¬ ì•„í‚¤í…ì²˜ ê²°ì •ì— ëŒ€í•œ DRì„ ìƒì„±í•˜ëŠ” ëŠ¥ë ¥ì„ ì¡°ì‚¬í–ˆìŠµë‹ˆë‹¤. ë¨¼ì €, ì•„í‚¤í…ì²˜ ê´€ë ¨ ë¬¸ì œ 100ê°œì˜ ë°ì´í„°ì…‹ì„ êµ¬ì¶•í•˜ê¸° ìœ„í•´ 50ê°œì˜ Stack Overflow (SO) ê²Œì‹œë¬¼, 25ê°œì˜ GitHub ì´ìŠˆ ë° 25ê°œì˜ GitHub í† ë¡ ì„ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ, ì„¸ ê°€ì§€ í”„ë¡¬í”„íŒ… ì „ëµì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ì„¯ ê°€ì§€ LLMì„ ì„ íƒí•˜ì—¬ ì•„í‚¤í…ì²˜ ê²°ì •ì— ëŒ€í•œ DRì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤. ì´ë•Œ ì‚¬ìš©ëœ í”„ë¡¬í”„íŒ… ì „ëµì€ zero-shot, chain of thought (CoT), LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤. ì¸ê°„ ì „ë¬¸ê°€ê°€ ì œê³µí•œ DRì„ ê¸°ì¤€ìœ¼ë¡œ, ì„¸ ê°€ì§€ í”„ë¡¬í”„íŒ… ì „ëµì„ ì‚¬ìš©í•˜ì—¬ ìƒì„±ëœ LLMì˜ DRì˜ ì •ë°€ë„ëŠ” 0.267ì—ì„œ 0.278, ì¬í˜„ìœ¨ì€ 0.627ì—ì„œ 0.715, F1 ì ìˆ˜ëŠ” 0.351ì—ì„œ 0.389ë¡œ ë²”ìœ„ê°€ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ì¸ê°„ ì „ë¬¸ê°€ê°€ ì–¸ê¸‰í•˜ì§€ ì•Šì€ DRì˜ ì£¼ì¥ ì¤‘ 64.45%ì—ì„œ 69.42%ëŠ” ë„ì›€ì´ ë˜ë©°, 4.12%ì—ì„œ 4.87%ëŠ” ë¶ˆí™•ì‹¤í•œ ì •í™•ì„±ì„ ê°€ì§€ê³  ìˆê³ , 1.59%ì—ì„œ 3.24%ëŠ” ì ì¬ì ìœ¼ë¡œ ì˜¤ë„í•˜ëŠ” ì£¼ì¥ì…ë‹ˆë‹¤. LLMì´ ìƒì„±í•œ DRì˜ ì‹ ë¢°ì„±ê³¼ ì ìš© ê°€ëŠ¥ì„±ì„ ë” ì˜ ì´í•´í•˜ê¸° ìœ„í•´ ìš°ë¦¬ëŠ” 6ëª…ì˜ ì‹¤ë¬´ìì™€ ë°˜êµ¬ì¡°í™”ëœ ì¸í„°ë·°ë¥¼ ì‹¤ì‹œí–ˆìŠµë‹ˆë‹¤. ì‹¤í—˜ ë° ì¸í„°ë·° ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì„¸ ê°€ì§€ í”„ë¡¬í”„íŒ… ì „ëµì˜ ì¥ë‹¨ì , LLMì´ ìƒì„±í•œ DRì˜ ê°•ì ê³¼ í•œê³„, ê·¸ë¦¬ê³  LLMì´ ìƒì„±í•œ DRì˜ ì‹¤ì œ ì‚¬ìš©ì— ëŒ€í•œ í•¨ì˜ì— ëŒ€í•´ ë…¼ì˜í–ˆìŠµë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ë³¸ ì—°êµ¬ëŠ” ì†Œí”„íŠ¸ì›¨ì–´ ì•„í‚¤í…ì²˜ ê²°ì •ì— ëŒ€í•œ ì„¤ê³„ ê·¼ê±° (DR)ê°€ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ ê³¼ì • ì „ë°˜ì— ê±¸ì³ ì•„í‚¤í…ì²˜ ì„ íƒì— ëŒ€í•œ ì´ìœ ë¥¼ ì œê³µí•¨ìœ¼ë¡œì¨ ê°€ì¹˜ ìˆëŠ” í†µì°°ì„ ì œê³µí•œë‹¤. ê·¸ëŸ¬ë‚˜ ì‹¤ì œë¡œ DRì€ ê°œë°œìë“¤ì˜ ë™ê¸° ë¶€ì¡±ê³¼ ë…¸ë ¥ ë¶€ì¡±ìœ¼ë¡œ ì¸í•´ ë¶€ì ì ˆí•˜ê²Œ ë¬¸ì„œí™”ë˜ëŠ” ê²½ìš°ê°€ ë§ë‹¤. ìµœê·¼ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ (LLMs)ì˜ ë°œì „ìœ¼ë¡œ ì¸í•´ í…ìŠ¤íŠ¸ ì´í•´, ì¶”ë¡  ë° ìƒì„± ëŠ¥ë ¥ì´ í–¥ìƒë˜ì–´ ì•„í‚¤í…ì²˜ ê²°ì •ì— ëŒ€í•œ DRì˜ ìƒì„± ë° ë³µêµ¬ê°€ ê°€ëŠ¥í•´ì¡Œë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” LLMsì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê³  100ê°œì˜ ì•„í‚¤í…ì²˜ ê´€ë ¨ ë¬¸ì œ ë°ì´í„° ì„¸íŠ¸ë¥¼ êµ¬ì¶•í•˜ì—¬ ì•„í‚¤í…ì²˜ ê²°ì •ì— ëŒ€í•œ DRì„ ìƒì„±í•˜ëŠ” ë‹¤ì–‘í•œ ì „ëµì„ ê²€í† í•˜ì˜€ë‹¤. ì‹¤í—˜ ë° ì¸í„°ë·° ê²°ê³¼ë¥¼ í† ëŒ€ë¡œ LLMsê°€ ìƒì„±í•œ DRì˜ ì‹ ë¢°ì„±ê³¼ ì ìš© ê°€ëŠ¥ì„±ì„ ë…¼ì˜í•˜ì˜€ë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸


- 1. ì†Œí”„íŠ¸ì›¨ì–´ ì•„í‚¤í…ì²˜ ê²°ì •ì— ëŒ€í•œ ì„¤ê³„ ê·¼ê±°ëŠ” ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ ê³¼ì •ì˜ ë‹¤ì–‘í•œ ë‹¨ê³„ì— ëŒ€í•œ ìœ ìš©í•œ í†µì°°ì„ ì œê³µí•œë‹¤.

- 2. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì€ í…ìŠ¤íŠ¸ ì´í•´, ì¶”ë¡  ë° ìƒì„± ëŠ¥ë ¥ì„ í†µí•´ ì•„í‚¤í…ì²˜ ê²°ì •ì— ëŒ€í•œ ì„¤ê³„ ê·¼ê±°ë¥¼ ìƒì„±í•˜ê³  ë³µêµ¬í•  ìˆ˜ ìˆë‹¤.

- 3. LLMsë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒì„±ëœ ì„¤ê³„ ê·¼ê±°ì˜ ì •ë°€ë„ëŠ” 0.267ì—ì„œ 0.278ë¡œ ë‚˜íƒ€ë‚¬ìœ¼ë©°, ë¦¬ì½œì€ 0.627ì—ì„œ 0.715ë¡œ ë‚˜íƒ€ë‚¬ë‹¤.


---

*Generated on 2025-09-18 16:33:00*