
# Language models' activations linearly encode training-order recency

**Korean Title:** ì–¸ì–´ ëª¨ë¸ì˜ í™œì„±í™”ëŠ” í›ˆë ¨ ìˆœì„œì˜ ìµœì‹ ì„±ì„ ì„ í˜•ì ìœ¼ë¡œ ë¶€í˜¸í™”í•©ë‹ˆë‹¤.

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-18|2025-09-18]] [[keywords/evolved/Temporal signal|Temporal signal]] [[keywords/broad/Language models|Language models]] [[keywords/broad/Training-order recency|Training-order recency]] [[keywords/specific/Linear probes|Linear probes]] [[keywords/unique/Llama-3.2-1B|Llama-3.2-1B]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Sequential fine-tuning
**ğŸ”¬ Broad Technical**: Language models, Training-order recency
**ğŸ”— Specific Connectable**: Linear probes
**â­ Unique Technical**: Llama-3.2-1B

**ArXiv ID**: [2509.14223](https://arxiv.org/abs/2509.14223)
**Published**: 2025-09-18
**Category**: cs.AI
**PDF**: [Download](https://arxiv.org/pdf/2509.14223.pdf)


## ğŸ·ï¸ ì¶”ì¶œëœ í‚¤ì›Œë“œ



`Language models` â€¢ 

`Training-order recency` â€¢ 

`Linear probes` â€¢ 

`Llama-3.2-1B` â€¢ 

`Temporal signal`



## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.14223v1 Announce Type: cross 
Abstract: We show that language models' activations linearly encode when information was learned during training. Our setup involves creating a model with a known training order by sequentially fine-tuning Llama-3.2-1B on six disjoint but otherwise similar datasets about named entities. We find that the average activations of test samples for the six training datasets encode the training order: when projected into a 2D subspace, these centroids are arranged exactly in the order of training and lie on a straight line. Further, we show that linear probes can accurately (~90%) distinguish "early" vs. "late" entities, generalizing to entities unseen during the probes' own training. The model can also be fine-tuned to explicitly report an unseen entity's training stage (~80% accuracy). Interestingly, this temporal signal does not seem attributable to simple differences in activation magnitudes, losses, or model confidence. Our paper demonstrates that models are capable of differentiating information by its acquisition time, and carries significant implications for how they might manage conflicting data and respond to knowledge modifications.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.14223v1 ë°œí‘œ ìœ í˜•: êµì°¨
ìš”ì•½: ìš°ë¦¬ëŠ” ì–¸ì–´ ëª¨ë¸ì˜ í™œì„±í™”ê°€ í›ˆë ¨ ì¤‘ì— ì •ë³´ê°€ ì–¸ì œ ë°°ì›Œì¡ŒëŠ”ì§€ë¥¼ ì„ í˜•ì ìœ¼ë¡œ ì¸ì½”ë”©í•œë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì„¤ì •ì€ ëª…ëª…ëœ ì—”í‹°í‹°ì— ê´€í•œ ì—¬ì„¯ ê°€ì§€ ê²¹ì¹˜ì§€ ì•ŠëŠ” ê·¸ëŸ¬ë‚˜ ê·¸ ì™¸ ìœ ì‚¬í•œ ë°ì´í„°ì…‹ì—ì„œ ìˆœì°¨ì ìœ¼ë¡œ Llama-3.2-1Bë¥¼ íŒŒì¸íŠœë‹í•˜ì—¬ ì•Œë ¤ì§„ í›ˆë ¨ ìˆœì„œë¥¼ ê°€ì§„ ëª¨ë¸ì„ ë§Œë“œëŠ” ê²ƒì„ í¬í•¨í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì—¬ì„¯ ê°€ì§€ í›ˆë ¨ ë°ì´í„°ì…‹ì˜ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œë“¤ì˜ í‰ê·  í™œì„±í™”ê°€ í›ˆë ¨ ìˆœì„œë¥¼ ì¸ì½”ë”©í•œë‹¤ëŠ” ê²ƒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤: 2D ë¶€ë¶„ ê³µê°„ìœ¼ë¡œ íˆ¬ì˜ë  ë•Œ, ì´ëŸ¬í•œ ì¤‘ì‹¬ì ì€ í›ˆë ¨ ìˆœì„œëŒ€ë¡œ ì •í™•íˆ ë°°ì—´ë˜ì–´ ìˆê³  ì§ì„ ìƒì— ìœ„ì¹˜í•©ë‹ˆë‹¤. ë” ë‚˜ì•„ê°€, ìš°ë¦¬ëŠ” ì„ í˜• í”„ë¡œë¸Œê°€ "ì´ë¥¸" vs. "ëŠ¦ì€" ì—”í‹°í‹°ë¥¼ ì •í™•í•˜ê²Œ(~90%) êµ¬ë³„í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì£¼ë©°, í”„ë¡œë¸Œ ìì²´ì˜ í›ˆë ¨ ì¤‘ì— ë³´ì§€ ëª»í•œ ì—”í‹°í‹°ì— ëŒ€í•´ ì¼ë°˜í™”ë©ë‹ˆë‹¤. ëª¨ë¸ì€ ë˜í•œ ë³´ê³ ë˜ì§€ ì•Šì€ ì—”í‹°í‹°ì˜ í›ˆë ¨ ë‹¨ê³„ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ë³´ê³ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤(~80% ì •í™•ë„). í¥ë¯¸ë¡œìš´ ì ì€, ì´ ì‹œê°„ ì‹ í˜¸ê°€ í™œì„±í™” í¬ê¸°, ì†ì‹¤ ë˜ëŠ” ëª¨ë¸ ì‹ ë¢°ë„ì˜ ê°„ë‹¨í•œ ì°¨ì´ë¡œ ì„¤ëª…ë˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. ìš°ë¦¬ì˜ ë…¼ë¬¸ì€ ëª¨ë¸ì´ íšë“ ì‹œê°„ì— ë”°ë¼ ì •ë³´ë¥¼ êµ¬ë³„í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ë³´ì—¬ì£¼ë©°, ëª¨ìˆœë˜ëŠ” ë°ì´í„°ë¥¼ ì–´ë–»ê²Œ ì²˜ë¦¬í•˜ê³  ì§€ì‹ ìˆ˜ì •ì— ëŒ€ì‘í• ì§€ì— ëŒ€í•œ ì¤‘ìš”í•œ í•¨ì˜ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” ì–¸ì–´ ëª¨ë¸ì˜ í™œì„±í™”ê°€ í›ˆë ¨ ì¤‘ ì–¸ì œ ì •ë³´ë¥¼ ë°°ì› ëŠ”ì§€ ì„ í˜•ì ìœ¼ë¡œ ì¸ì½”ë”©ëœë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì‹¤í—˜ì—ì„œëŠ” Llama-3.2-1Bë¥¼ ìˆœì°¨ì ìœ¼ë¡œ fine-tuningí•˜ì—¬ ì•Œë ¤ì§„ í›ˆë ¨ ìˆœì„œë¥¼ ê°€ì§„ ëª¨ë¸ì„ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ ìƒ˜í”Œì˜ í‰ê·  í™œì„±í™”ëŠ” í›ˆë ¨ ìˆœì„œë¥¼ ì¸ì½”ë”©í•˜ë©°, 2D ë¶€ë¶„ ê³µê°„ìœ¼ë¡œ íˆ¬ì˜í•˜ë©´ í›ˆë ¨ ìˆœì„œëŒ€ë¡œ ì •ë ¬ë˜ê³  ì§ì„ ìƒì— ìœ„ì¹˜í•©ë‹ˆë‹¤. ë˜í•œ ì„ í˜• í”„ë¡œë¸Œë¥¼ ì‚¬ìš©í•˜ì—¬ "ì¼ì°" vs. "ëŠ¦ê²Œ" í•™ìŠµëœ ì—”í‹°í‹°ë¥¼ ì •í™•í•˜ê²Œ (~90%) êµ¬ë³„í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŸ¬í•œ ì‹œê°„ ì‹ í˜¸ëŠ” ê°„ë‹¨í•œ í™œì„±í™” í¬ê¸°, ì†ì‹¤ ë˜ëŠ” ëª¨ë¸ ì‹ ë¢°ë„ì˜ ì°¨ì´ë¡œ ì„¤ëª…ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ëª¨ë¸ì´ ì •ë³´ë¥¼ ìŠµë“í•œ ì‹œê°„ì— ë”°ë¼ êµ¬ë¶„í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì£¼ë©°, ëª¨ìˆœë˜ëŠ” ë°ì´í„°ë¥¼ ì–´ë–»ê²Œ ì²˜ë¦¬í•˜ê³  ì§€ì‹ ìˆ˜ì •ì— ëŒ€ì‘í• ì§€ì— ëŒ€í•œ ì¤‘ìš”í•œ í•¨ì˜ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸


- ì–¸ì–´ ëª¨ë¸ì˜ í™œì„±í™”ëŠ” í›ˆë ¨ ì¤‘ì— ì–¸ì œ ì •ë³´ê°€ í•™ìŠµë˜ì—ˆëŠ”ì§€ ì„ í˜•ì ìœ¼ë¡œ ì¸ì½”ë”©ë¨ì„ ë³´ì—¬ì¤Œ

- ì„ í˜• í”„ë¡œë¸ŒëŠ” "ì¼ì°" ëŒ€ "ëŠ¦ê²Œ" ì—”í‹°í‹°ë¥¼ ì •í™•í•˜ê²Œ (~90%) êµ¬ë³„í•  ìˆ˜ ìˆìŒ

- ëª¨ë¸ì€ ë³´ê³ ë˜ì§€ ì•Šì€ ì—”í‹°í‹°ì˜ í›ˆë ¨ ë‹¨ê³„ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ë³´ê³ í•  ìˆ˜ ìˆìŒ (~80% ì •í™•ë„)


---

*Generated on 2025-09-18 16:26:09*