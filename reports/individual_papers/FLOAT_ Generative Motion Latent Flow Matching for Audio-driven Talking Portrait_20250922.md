# FLOAT: Generative Motion Latent Flow Matching for Audio-driven Talking Portrait

**Korean Title:** FLOAT: 오디오 기반의 대화형 초상화를 위한 생성적 모션 잠재 흐름 매칭

## 📋 메타데이터

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Flow Matching Generative Model

## 🔗 유사한 논문
- [[2025-09-18/Real-Time Streaming Mel Vocoding with Generative Flow Matching_20250918|Real-Time Streaming Mel Vocoding with Generative Flow Matching]] (82.3% similar)
- [[2025-09-19/Hybrid Autoregressive-Diffusion Model for Real-Time Sign Language Production_20250919|Hybrid Autoregressive-Diffusion Model for Real-Time Sign Language Production]] (82.1% similar)
- [[2025-09-17/RFM-Editing_ Rectified Flow Matching for Text-guided Audio Editing_20250917|RFM-Editing Rectified Flow Matching for Text-guided Audio Editing]] (81.1% similar)
- [[2025-09-22/Compose Yourself_ Average-Velocity Flow Matching for One-Step Speech Enhancement_20250922|Compose Yourself Average-Velocity Flow Matching for One-Step Speech Enhancement]] (81.1% similar)
- [[2025-09-19/MeanFlowSE_ one-step generative speech enhancement via conditional mean flow_20250919|MeanFlowSE one-step generative speech enhancement via conditional mean flow]] (81.0% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2412.01064v5 Announce Type: replace-cross 
Abstract: With the rapid advancement of diffusion-based generative models, portrait image animation has achieved remarkable results. However, it still faces challenges in temporally consistent video generation and fast sampling due to its iterative sampling nature. This paper presents FLOAT, an audio-driven talking portrait video generation method based on flow matching generative model. Instead of a pixel-based latent space, we take advantage of a learned orthogonal motion latent space, enabling efficient generation and editing of temporally consistent motion. To achieve this, we introduce a transformer-based vector field predictor with an effective frame-wise conditioning mechanism. Additionally, our method supports speech-driven emotion enhancement, enabling a natural incorporation of expressive motions. Extensive experiments demonstrate that our method outperforms state-of-the-art audio-driven talking portrait methods in terms of visual quality, motion fidelity, and efficiency.

## 🔍 Abstract (한글 번역)

arXiv:2412.01064v5 발표 유형: 교차 교체  
초록: 확산 기반 생성 모델의 급속한 발전으로 인해 초상화 이미지 애니메이션은 놀라운 성과를 거두었습니다. 그러나 반복적인 샘플링 특성으로 인해 시간적으로 일관된 비디오 생성과 빠른 샘플링에 여전히 도전 과제를 안고 있습니다. 본 논문에서는 흐름 매칭 생성 모델을 기반으로 한 오디오 구동 대화형 초상화 비디오 생성 방법인 FLOAT를 제시합니다. 픽셀 기반 잠재 공간 대신 학습된 직교 운동 잠재 공간을 활용하여 시간적으로 일관된 운동의 효율적인 생성 및 편집을 가능하게 합니다. 이를 달성하기 위해 효과적인 프레임 단위 조건 메커니즘을 갖춘 트랜스포머 기반 벡터 필드 예측기를 도입합니다. 또한, 본 방법은 음성 구동 감정 향상을 지원하여 표현력이 풍부한 동작을 자연스럽게 통합할 수 있습니다. 광범위한 실험을 통해 본 방법이 시각적 품질, 동작 충실도 및 효율성 측면에서 최첨단 오디오 구동 대화형 초상화 방법을 능가함을 입증합니다.

## 📝 요약

이 논문은 음성 기반의 인물 영상 생성 방법인 FLOAT를 제안합니다. 이는 흐름 매칭 생성 모델을 사용하여, 픽셀 기반이 아닌 학습된 직교 모션 잠재 공간을 활용함으로써 시간적으로 일관된 모션을 효율적으로 생성하고 편집할 수 있습니다. 또한, 트랜스포머 기반 벡터 필드 예측기와 효과적인 프레임별 조건부 메커니즘을 도입하여 구현됩니다. 이 방법은 음성에 기반한 감정 표현 강화도 지원하여 자연스러운 표현 동작을 포함할 수 있습니다. 실험 결과, FLOAT는 시각적 품질, 모션 충실도, 효율성 면에서 기존의 음성 기반 인물 영상 생성 방법들을 능가하는 성능을 보였습니다.

## 🎯 주요 포인트

- 1. FLOAT는 흐름 매칭 생성 모델을 기반으로 한 오디오 기반의 말하는 초상화 비디오 생성 방법을 제안합니다.

- 2. 학습된 직교 모션 잠재 공간을 활용하여 시간적으로 일관된 모션의 효율적인 생성 및 편집을 가능하게 합니다.

- 3. 트랜스포머 기반 벡터 필드 예측기와 효과적인 프레임별 조건부 메커니즘을 도입합니다.

- 4. 감정 강화를 지원하여 자연스러운 표현 모션을 통합할 수 있습니다.

- 5. 실험 결과, FLOAT는 시각적 품질, 모션 충실도 및 효율성 측면에서 최첨단 오디오 기반 말하는 초상화 방법을 능가합니다.

---

*Generated on 2025-09-22 14:40:42*