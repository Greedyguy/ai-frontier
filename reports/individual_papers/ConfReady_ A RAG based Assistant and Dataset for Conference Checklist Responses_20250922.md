# ConfReady: A RAG based Assistant and Dataset for Conference Checklist Responses

**Korean Title:** ConfReady: 학회 체크리스트 응답을 위한 RAG 기반 보조 도구 및 데이터셋

## 📋 메타데이터

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: Conference Checklist Evaluation

## 🔗 유사한 논문
- [[2025-09-19/Engineering RAG Systems for Real-World Applications_ Design, Development, and Evaluation_20250919|Engineering RAG Systems for Real-World Applications Design, Development, and Evaluation]] (82.0% similar)
- [[2025-09-19/Enhancing Retrieval Augmentation via Adversarial Collaboration_20250919|Enhancing Retrieval Augmentation via Adversarial Collaboration]] (79.8% similar)
- [[2025-09-19/AIP_ Subverting Retrieval-Augmented Generation via Adversarial Instructional Prompt_20250919|AIP Subverting Retrieval-Augmented Generation via Adversarial Instructional Prompt]] (79.7% similar)
- [[2025-09-22/CCrepairBench_ A High-Fidelity Benchmark and Reinforcement Learning Framework for C++ Compilation Repair_20250922|CCrepairBench A High-Fidelity Benchmark and Reinforcement Learning Framework for C++ Compilation Repair]] (78.6% similar)
- [[2025-09-18/TAI Scan Tool_ A RAG-Based Tool With Minimalistic Input for Trustworthy AI Self-Assessment_20250918|TAI Scan Tool A RAG-Based Tool With Minimalistic Input for Trustworthy AI Self-Assessment]] (78.6% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2408.04675v2 Announce Type: replace-cross 
Abstract: The ARR Responsible NLP Research checklist website states that the "checklist is designed to encourage best practices for responsible research, addressing issues of research ethics, societal impact and reproducibility." Answering the questions is an opportunity for authors to reflect on their work and make sure any shared scientific assets follow best practices. Ideally, considering a checklist before submission can favorably impact the writing of a research paper. However, previous research has shown that self-reported checklist responses don't always accurately represent papers. In this work, we introduce ConfReady, a retrieval-augmented generation (RAG) application that can be used to empower authors to reflect on their work and assist authors with conference checklists. To evaluate checklist assistants, we curate a dataset of 1,975 ACL checklist responses, analyze problems in human answers, and benchmark RAG and Large Language Model (LM) based systems on an evaluation subset. Our code is released under the AGPL-3.0 license on GitHub, with documentation covering the user interface and PyPI package.

## 🔍 Abstract (한글 번역)

arXiv:2408.04675v2 발표 유형: 교차 교체  
초록: ARR 책임 있는 NLP 연구 체크리스트 웹사이트는 "체크리스트는 연구 윤리, 사회적 영향 및 재현 가능성 문제를 다루며 책임 있는 연구를 위한 모범 사례를 장려하기 위해 설계되었습니다."라고 명시하고 있습니다. 질문에 답하는 것은 저자들이 자신의 작업을 성찰하고 공유된 과학적 자산이 모범 사례를 따르는지 확인할 수 있는 기회를 제공합니다. 이상적으로는 제출 전에 체크리스트를 고려하는 것이 연구 논문의 작성에 긍정적인 영향을 미칠 수 있습니다. 그러나 이전 연구에 따르면 자기 보고된 체크리스트 응답이 항상 논문을 정확하게 대표하지는 않는 것으로 나타났습니다. 이 연구에서는 저자들이 자신의 작업을 성찰하고 학회 체크리스트를 지원할 수 있도록 돕는 검색 증강 생성(RAG) 애플리케이션인 ConfReady를 소개합니다. 체크리스트 보조 도구를 평가하기 위해, 우리는 1,975개의 ACL 체크리스트 응답 데이터셋을 큐레이션하고, 인간의 응답에서 문제를 분석하며, 평가 하위 집합에서 RAG 및 대형 언어 모델(LM) 기반 시스템을 벤치마킹합니다. 우리의 코드는 사용자 인터페이스 및 PyPI 패키지를 다루는 문서와 함께 GitHub에서 AGPL-3.0 라이선스로 공개됩니다.

## 📝 요약

이 논문은 연구 윤리, 사회적 영향 및 재현 가능성을 다루는 책임 있는 연구를 장려하기 위한 ARR 책임 있는 NLP 연구 체크리스트의 중요성을 강조합니다. 저자들이 자신의 연구를 성찰하고 최선의 관행을 따르도록 돕기 위해 ConfReady라는 RAG 애플리케이션을 소개합니다. 이를 평가하기 위해 1,975개의 ACL 체크리스트 응답을 분석하고, RAG 및 대형 언어 모델 기반 시스템을 벤치마킹했습니다. 연구의 코드는 AGPL-3.0 라이선스로 GitHub에 공개되었습니다.

## 🎯 주요 포인트

- 1. 연구 윤리, 사회적 영향, 재현 가능성 문제를 다루기 위한 책임 있는 연구 체크리스트의 중요성을 강조합니다.

- 2. ConfReady라는 RAG 애플리케이션을 소개하여 저자들이 연구를 반성하고 학회 체크리스트를 작성하는 데 도움을 줍니다.

- 3. 1,975개의 ACL 체크리스트 응답 데이터를 수집하여 인간의 응답 문제를 분석하고, RAG 및 대형 언어 모델 기반 시스템을 평가합니다.

- 4. AGPL-3.0 라이선스 하에 GitHub에 코드를 공개하며, 사용자 인터페이스 및 PyPI 패키지에 대한 문서를 제공합니다.

---

*Generated on 2025-09-22 14:37:29*