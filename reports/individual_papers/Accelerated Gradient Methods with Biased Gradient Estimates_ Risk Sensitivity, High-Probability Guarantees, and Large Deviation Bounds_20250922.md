# Accelerated Gradient Methods with Biased Gradient Estimates: Risk Sensitivity, High-Probability Guarantees, and Large Deviation Bounds

**Korean Title:** í¸í–¥ëœ ê·¸ë˜ë””ì–¸íŠ¸ ì¶”ì •ì¹˜ë¥¼ ì‚¬ìš©í•˜ëŠ” ê°€ì† ê·¸ë˜ë””ì–¸íŠ¸ ë°©ë²•: ìœ„í—˜ ë¯¼ê°ì„±, ë†’ì€ í™•ë¥  ë³´ì¥, ë° í° í¸ì°¨ ê²½ê³„

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[reports/digests/daily_digest_20250922|2025-09-22]] [[keywords/evolved/Non Asymptotic Large Deviation Bounds|Non Asymptotic Large Deviation Bounds]] [[keywords/specific/Generalized Momentum Methods|Generalized Momentum Methods]] [[keywords/broad/Robust Control Theory|Robust Control Theory]] [[keywords/unique/Risk Sensitive Index|Risk Sensitive Index]] [[categories/cs.LG|cs.LG]] [[2025-09-18/Stochastic Bilevel Optimization with Heavy-Tailed Noise_20250918|Stochastic Bilevel Optimization with Heavy-Tailed Noise]] (83.3% similar) [[2025-09-22/Policy Gradient Optimzation for Bayesian-Risk MDPs with General Convex Losses_20250922|Policy Gradient Optimzation for Bayesian-Risk MDPs with General Convex Losses]] (83.0% similar) [[2025-09-22/Training More Robust Classification Model via Discriminative Loss and Gaussian Noise Injection_20250922|Training More Robust Classification Model via Discriminative Loss and Gaussian Noise Injection]] (81.7% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Non Asymptotic Large Deviation Bounds
**ğŸ”— Specific Connectable**: Generalized Momentum Methods
**ğŸ”¬ Broad Technical**: Robust Control Theory
**â­ Unique Technical**: Risk Sensitive Index
## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/Stochastic Bilevel Optimization with Heavy-Tailed Noise_20250918|Stochastic Bilevel Optimization with Heavy-Tailed Noise]] (83.3% similar)
- [[2025-09-22/Policy Gradient Optimzation for Bayesian-Risk MDPs with General Convex Losses_20250922|Policy Gradient Optimzation for Bayesian-Risk MDPs with General Convex Losses]] (83.0% similar)
- [[2025-09-22/Training More Robust Classification Model via Discriminative Loss and Gaussian Noise Injection_20250922|Training More Robust Classification Model via Discriminative Loss and Gaussian Noise Injection]] (81.7% similar)
- [[2025-09-18/Probabilistic and nonlinear compressive sensing_20250918|Probabilistic and nonlinear compressive sensing]] (81.5% similar)
- [[2025-09-18/Bellman Optimality of Average-Reward Robust Markov Decision Processes with a Constant Gain_20250918|Bellman Optimality of Average-Reward Robust Markov Decision Processes with a Constant Gain]] (81.1% similar)


**ArXiv ID**: [2509.13628](https://arxiv.org/abs/2509.13628)
**Published**: 2025-09-22
**Category**: cs.LG
**PDF**: [Download](https://arxiv.org/pdf/2509.13628.pdf)


**ArXiv ID**: [2509.13628](https://arxiv.org/abs/2509.13628)
**Published**: 2025-09-22
**Category**: cs.LG
**PDF**: [Download](https://arxiv.org/pdf/2509.13628.pdf)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Non Asymptotic Guarantees
**ğŸ”— Specific Connectable**: Generalized Momentum Methods
**â­ Unique Technical**: Risk Sensitive Index
**ğŸ”¬ Broad Technical**: Robust Control Theory

## ğŸ·ï¸ ì¶”ì¶œëœ í‚¤ì›Œë“œ



`Robust Control Theory` â€¢ 

`Generalized Momentum Methods` â€¢ 

`Risk Sensitive Index` â€¢ 

`Non Asymptotic Large Deviation Bounds`



## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸

Similar papers will be displayed here based on embedding similarity.

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.13628v2 Announce Type: replace-cross 
Abstract: We study trade-offs between convergence rate and robustness to gradient errors in the context of first-order methods. Our focus is on generalized momentum methods (GMMs)--a broad class that includes Nesterov's accelerated gradient, heavy-ball, and gradient descent methods--for minimizing smooth strongly convex objectives. We allow stochastic gradient errors that may be adversarial and biased, and quantify robustness of these methods to gradient errors via the risk-sensitive index (RSI) from robust control theory. For quadratic objectives with i.i.d. Gaussian noise, we give closed form expressions for RSI in terms of solutions to 2x2 matrix Riccati equations, revealing a Pareto frontier between RSI and convergence rate over the choice of step-size and momentum parameters. We then prove a large-deviation principle for time-averaged suboptimality in the large iteration limit and show that the rate function is, up to a scaling, the convex conjugate of the RSI function. We further show that the rate function and RSI are linked to the $H_\infty$-norm--a measure of robustness to the worst-case deterministic gradient errors--so that stronger worst-case robustness (smaller $H_\infty$-norm) leads to sharper decay of the tail probabilities for the average suboptimality. Beyond quadratics, under potentially biased sub-Gaussian gradient errors, we derive non-asymptotic bounds on a finite-time analogue of the RSI, yielding finite-time high-probability guarantees and non-asymptotic large-deviation bounds for the averaged iterates. In the case of smooth strongly convex functions, we also observe an analogous trade-off between RSI and convergence-rate bounds. To our knowledge, these are the first non-asymptotic guarantees for GMMs with biased gradients and the first risk-sensitive analysis of GMMs. Finally, we provide numerical experiments on a robust regression problem to illustrate our results.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.13628v2 ë°œí‘œ ìœ í˜•: êµì°¨ êµì²´  
ì´ˆë¡: ìš°ë¦¬ëŠ” 1ì°¨ ë°©ë²•ì˜ ë§¥ë½ì—ì„œ ìˆ˜ë ´ ì†ë„ì™€ ê¸°ìš¸ê¸° ì˜¤ë¥˜ì— ëŒ€í•œ ê°•ê±´ì„± ì‚¬ì´ì˜ ì ˆì¶©ì ì„ ì—°êµ¬í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì´ˆì ì€ ë§¤ë„ëŸ½ê³  ê°•í•˜ê²Œ ë³¼ë¡í•œ ëª©ì ì„ ìµœì†Œí™”í•˜ê¸° ìœ„í•œ Nesterovì˜ ê°€ì† ê¸°ìš¸ê¸°, ì¤‘ë ¥êµ¬, ê¸°ìš¸ê¸° í•˜ê°• ë°©ë²•ì„ í¬í•¨í•˜ëŠ” ê´‘ë²”ìœ„í•œ í´ë˜ìŠ¤ì¸ ì¼ë°˜í™”ëœ ëª¨ë©˜í…€ ë°©ë²•(GMMs)ì— ìˆìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì ëŒ€ì ì´ê³  í¸í–¥ëœ í™•ë¥ ì  ê¸°ìš¸ê¸° ì˜¤ë¥˜ë¥¼ í—ˆìš©í•˜ë©°, ê°•ê±´ ì œì–´ ì´ë¡ ì˜ ìœ„í—˜ ë¯¼ê° ì§€ìˆ˜(RSI)ë¥¼ í†µí•´ ì´ëŸ¬í•œ ë°©ë²•ì˜ ê¸°ìš¸ê¸° ì˜¤ë¥˜ì— ëŒ€í•œ ê°•ê±´ì„±ì„ ì •ëŸ‰í™”í•©ë‹ˆë‹¤. ë…ë¦½ì ìœ¼ë¡œ ë™ì¼í•˜ê²Œ ë¶„í¬ëœ(i.i.d.) ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆê°€ ìˆëŠ” ì´ì°¨ ëª©ì ì— ëŒ€í•´, 2x2 í–‰ë ¬ ë¦¬ì¹´í‹° ë°©ì •ì‹ì˜ í•´ë¥¼ í†µí•´ RSIì— ëŒ€í•œ ë‹«íŒ í˜•ì‹ í‘œí˜„ì„ ì œê³µí•˜ì—¬ ìŠ¤í… í¬ê¸°ì™€ ëª¨ë©˜í…€ ë§¤ê°œë³€ìˆ˜ ì„ íƒì— ë”°ë¥¸ RSIì™€ ìˆ˜ë ´ ì†ë„ ê°„ì˜ íŒŒë ˆí†  ì „ì„ ì„ ë“œëŸ¬ëƒ…ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ, í° ë°˜ë³µ í•œê³„ì—ì„œ ì‹œê°„ í‰ê·  ë¹„ìµœì ì„±ì— ëŒ€í•œ í° í¸ì°¨ ì›ë¦¬ë¥¼ ì¦ëª…í•˜ê³ , ì†ë„ í•¨ìˆ˜ê°€ ìŠ¤ì¼€ì¼ë§ì— ë”°ë¼ RSI í•¨ìˆ˜ì˜ ë³¼ë¡ ì¼¤ë ˆì„ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë˜í•œ, ì†ë„ í•¨ìˆ˜ì™€ RSIê°€ ìµœì•…ì˜ ê²°ì •ë¡ ì  ê¸°ìš¸ê¸° ì˜¤ë¥˜ì— ëŒ€í•œ ê°•ê±´ì„±ì˜ ì²™ë„ì¸ $H_\infty$-ë…¸ë¦„ê³¼ ì—°ê²°ë˜ì–´ ìˆìŒì„ ë³´ì—¬ì£¼ì–´, ë” ê°•í•œ ìµœì•…ì˜ ê²½ìš° ê°•ê±´ì„±(ë” ì‘ì€ $H_\infty$-ë…¸ë¦„)ì´ í‰ê·  ë¹„ìµœì ì„±ì˜ ê¼¬ë¦¬ í™•ë¥ ì˜ ë” ë‚ ì¹´ë¡œìš´ ê°ì†Œë¡œ ì´ì–´ì§ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. í¸í–¥ëœ ì„œë¸Œ ê°€ìš°ì‹œì•ˆ ê¸°ìš¸ê¸° ì˜¤ë¥˜ê°€ ìˆì„ ìˆ˜ ìˆëŠ” ê²½ìš°, ìš°ë¦¬ëŠ” RSIì˜ ìœ í•œ ì‹œê°„ ìœ ì‚¬ì²´ì— ëŒ€í•œ ë¹„ëŒ€ì¹­ì  ê²½ê³„ë¥¼ ë„ì¶œí•˜ì—¬ ìœ í•œ ì‹œê°„ ë†’ì€ í™•ë¥  ë³´ì¥ê³¼ í‰ê·  ë°˜ë³µì— ëŒ€í•œ ë¹„ëŒ€ì¹­ì  í° í¸ì°¨ ê²½ê³„ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ë§¤ë„ëŸ½ê³  ê°•í•˜ê²Œ ë³¼ë¡í•œ í•¨ìˆ˜ì˜ ê²½ìš°, ìš°ë¦¬ëŠ” ë˜í•œ RSIì™€ ìˆ˜ë ´ ì†ë„ ê²½ê³„ ì‚¬ì´ì˜ ìœ ì‚¬í•œ ì ˆì¶©ì ì„ ê´€ì°°í•©ë‹ˆë‹¤. ìš°ë¦¬ê°€ ì•„ëŠ” í•œ, ì´ê²ƒë“¤ì€ í¸í–¥ëœ ê¸°ìš¸ê¸°ë¥¼ ê°€ì§„ GMMsì— ëŒ€í•œ ìµœì´ˆì˜ ë¹„ëŒ€ì¹­ì  ë³´ì¥ì´ë©°, GMMsì— ëŒ€í•œ ìµœì´ˆì˜ ìœ„í—˜ ë¯¼ê° ë¶„ì„ì…ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ, ìš°ë¦¬ì˜ ê²°ê³¼ë¥¼ ì„¤ëª…í•˜ê¸° ìœ„í•´ ê°•ê±´ íšŒê·€ ë¬¸ì œì— ëŒ€í•œ ìˆ˜ì¹˜ ì‹¤í—˜ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ 1ì°¨ ë°©ë²•ë¡ ì—ì„œ ìˆ˜ë ´ ì†ë„ì™€ ê·¸ë˜ë””ì–¸íŠ¸ ì˜¤ë¥˜ì— ëŒ€í•œ ê°•ê±´ì„± ì‚¬ì´ì˜ ìƒì¶© ê´€ê³„ë¥¼ ì—°êµ¬í•©ë‹ˆë‹¤. ì¼ë°˜í™”ëœ ëª¨ë©˜í…€ ë°©ë²•(GMMs)ì„ ì¤‘ì‹¬ìœ¼ë¡œ, ë§¤ë„ëŸ½ê³  ê°•í•˜ê²Œ ë³¼ë¡í•œ ëª©í‘œë¥¼ ìµœì†Œí™”í•˜ëŠ” ê³¼ì •ì—ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ì ëŒ€ì ì´ê³  í¸í–¥ëœ í™•ë¥ ì  ê·¸ë˜ë””ì–¸íŠ¸ ì˜¤ë¥˜ì— ëŒ€í•œ ê°•ê±´ì„±ì„ ë¶„ì„í•©ë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ì´ì°¨ ëª©í‘œì™€ ë…ë¦½ ë™ì¼ ë¶„í¬ ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆë¥¼ ê³ ë ¤í•˜ì—¬, 2x2 ë¦¬ì¹´í‹° ë°©ì •ì‹ì˜ í•´ë¥¼ í†µí•´ ìœ„í—˜ ë¯¼ê° ì§€ìˆ˜(RSI)ì™€ ìˆ˜ë ´ ì†ë„ ê°„ì˜ íŒŒë ˆí†  ê²½ê³„ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ë˜í•œ, ì‹œê°„ í‰ê·  ë¶€ìµœì ì„±ì— ëŒ€í•œ ëŒ€í¸ì°¨ ì›ë¦¬ë¥¼ ì¦ëª…í•˜ê³ , RSI í•¨ìˆ˜ì˜ ë³¼ë¡ ì¼¤ë ˆì™€ ê´€ë ¨ëœ ë¹„ìœ¨ í•¨ìˆ˜ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ë” ë‚˜ì•„ê°€, ìµœì•…ì˜ ê²°ì •ë¡ ì  ê·¸ë˜ë””ì–¸íŠ¸ ì˜¤ë¥˜ì— ëŒ€í•œ ê°•ê±´ì„± ì²™ë„ì¸ $H_\infty$-ë…¸ë¦„ê³¼ì˜ ì—°ê´€ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë¹„ì´ì°¨ì  ê²½ìš°ì—ë„ í¸í–¥ëœ ì„œë¸Œê°€ìš°ì‹œì•ˆ ê·¸ë˜ë””ì–¸íŠ¸ ì˜¤ë¥˜ í•˜ì—ì„œ ë¹„ëŒ€ì¹­ì  ê²½ê³„ì™€ ë†’ì€ í™•ë¥  ë³´ì¥ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ëŠ” GMMsì˜ í¸í–¥ëœ ê·¸ë˜ë””ì–¸íŠ¸ì— ëŒ€í•œ ìµœì´ˆì˜ ë¹„ëŒ€ì¹­ì  ë³´ì¥ê³¼ ìœ„í—˜ ë¯¼ê° ë¶„ì„ì…ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ, ê°•ê±´í•œ íšŒê·€ ë¬¸ì œë¥¼ í†µí•´ ê²°ê³¼ë¥¼ ì‹¤í—˜ì ìœ¼ë¡œ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸


- 1. ì¼ë°˜í™”ëœ ëª¨ë©˜í…€ ë°©ë²•(GMMs)ì€ ë§¤ë„ëŸ½ê³  ê°•í•˜ê²Œ ë³¼ë¡í•œ ëª©ì ì„ ìµœì†Œí™”í•˜ëŠ” ë° ì‚¬ìš©ë˜ë©°, ì´ ë°©ë²•ë“¤ì€ í™•ë¥ ì  ê·¸ë˜ë””ì–¸íŠ¸ ì˜¤ë¥˜ì— ëŒ€í•œ ê°•ê±´ì„±ì„ ìœ„í—˜ ë¯¼ê° ì§€ìˆ˜(RSI)ë¡œ ì •ëŸ‰í™”í•©ë‹ˆë‹¤.

- 2. ì´ ë…¼ë¬¸ì€ i.i.d. ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆë¥¼ ê°€ì§„ ì´ì°¨ ëª©ì  í•¨ìˆ˜ì— ëŒ€í•´ RSIì™€ ìˆ˜ë ´ ì†ë„ ê°„ì˜ íŒŒë ˆí†  ê²½ê³„ë¥¼ ë“œëŸ¬ë‚´ë©°, ì´ëŠ” ìŠ¤í… í¬ê¸°ì™€ ëª¨ë©˜í…€ ë§¤ê°œë³€ìˆ˜ ì„ íƒì— ë”°ë¼ ë‹¬ë¼ì§‘ë‹ˆë‹¤.

- 3. ì‹œê°„ í‰ê·  ë¹„ìµœì ì„±ì— ëŒ€í•œ í° í¸ì°¨ ì›ë¦¬ë¥¼ ì¦ëª…í•˜ê³ , ë¹„ìœ¨ í•¨ìˆ˜ê°€ RSI í•¨ìˆ˜ì˜ ë³¼ë¡ ì¼¤ë ˆì„ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

- 4. ìµœì•…ì˜ ê²°ì •ë¡ ì  ê·¸ë˜ë””ì–¸íŠ¸ ì˜¤ë¥˜ì— ëŒ€í•œ ê°•ê±´ì„±ì„ ì¸¡ì •í•˜ëŠ” $H_\infty$-ë…¸ë¦„ê³¼ RSI ë° ë¹„ìœ¨ í•¨ìˆ˜ ê°„ì˜ ì—°ê²°ì„ ë°í˜€ë‚´ì–´, ê°•í•œ ìµœì•…ì˜ ê²½ìš° ê°•ê±´ì„±ì´ í‰ê·  ë¹„ìµœì ì„±ì˜ ê¼¬ë¦¬ í™•ë¥ ì˜ ê¸‰ê²©í•œ ê°ì†Œë¡œ ì´ì–´ì§ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

- 5. í¸í–¥ëœ ê·¸ë˜ë””ì–¸íŠ¸ ì˜¤ë¥˜ê°€ ìˆëŠ” GMMsì— ëŒ€í•œ ë¹„ë¹„ëŒ€ì¹­ì  ë³´ì¥ê³¼ ìœ„í—˜ ë¯¼ê° ë¶„ì„ì„ ì œê³µí•˜ëŠ” ìµœì´ˆì˜ ì—°êµ¬ì…ë‹ˆë‹¤.


---

*Generated on 2025-09-22 16:18:17*