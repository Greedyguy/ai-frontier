# Personalized Language Models via Privacy-Preserving Evolutionary Model Merging

**Korean Title:** ê°œì¸í™”ëœ ì–¸ì–´ ëª¨ë¸: í”„ë¼ì´ë²„ì‹œ ë³´í˜¸ ì§„í™”ì  ëª¨ë¸ ë³‘í•©ì„ í†µí•œ ì ‘ê·¼

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[reports/digests/daily_digest_20250922|2025-09-22]] [[keywords/evolved/Privacy-Utility Trade-off|Privacy-Utility Trade-off]] [[keywords/specific/Evolutionary Algorithms|Evolutionary Algorithms]] [[keywords/broad/Language Models|Language Models]] [[keywords/broad/Privacy Preservation|Privacy Preservation]] [[keywords/unique/PriME|PriME]] [[categories/cs.CL|cs.CL]] [[2025-09-19/Communication-Efficient and Privacy-Adaptable Mechanism for Federated Learning_20250919|Communication-Efficient and Privacy-Adaptable Mechanism for Federated Learning]] (83.3% similar) [[2025-09-22/DP-GTR_ Differentially Private Prompt Protection via Group Text Rewriting_20250922|DP-GTR: Differentially Private Prompt Protection via Group Text Rewriting]] (82.6% similar) [[2025-09-17/ParaAegis_ Parallel Protection for Flexible Privacy-preserved Federated Learning_20250917|ParaAegis: Parallel Protection for Flexible Privacy-preserved Federated Learning]] (81.7% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Privacy-Utility Trade-off
**ğŸ”— Specific Connectable**: Evolutionary Algorithms
**ğŸ”¬ Broad Technical**: Language Models, Privacy Preservation
**â­ Unique Technical**: PriME
## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Communication-Efficient and Privacy-Adaptable Mechanism for Federated Learning_20250919|Communication-Efficient and Privacy-Adaptable Mechanism for Federated Learning]] (83.3% similar)
- [[2025-09-22/DP-GTR_ Differentially Private Prompt Protection via Group Text Rewriting_20250922|DP-GTR Differentially Private Prompt Protection via Group Text Rewriting]] (82.6% similar)
- [[2025-09-17/ParaAegis_ Parallel Protection for Flexible Privacy-preserved Federated Learning_20250917|ParaAegis Parallel Protection for Flexible Privacy-preserved Federated Learning]] (81.7% similar)
- [[2025-09-19/Learning in Context_ Personalizing Educational Content with Large Language Models to Enhance Student Learning_20250919|Learning in Context Personalizing Educational Content with Large Language Models to Enhance Student Learning]] (81.7% similar)
- [[2025-09-19/The Sum Leaks More Than Its Parts_ Compositional Privacy Risks and Mitigations in Multi-Agent Collaboration_20250919|The Sum Leaks More Than Its Parts Compositional Privacy Risks and Mitigations in Multi-Agent Collaboration]] (81.7% similar)


**ArXiv ID**: [2503.18008](https://arxiv.org/abs/2503.18008)
**Published**: 2025-09-22
**Category**: cs.CL
**PDF**: [Download](https://arxiv.org/pdf/2503.18008.pdf)


**ArXiv ID**: [2503.18008](https://arxiv.org/abs/2503.18008)
**Published**: 2025-09-22
**Category**: cs.CL
**PDF**: [Download](https://arxiv.org/pdf/2503.18008.pdf)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Privacy Utility Trade off
**ğŸ”— Specific Connectable**: Privacy Preserving Algorithms
**â­ Unique Technical**: PriME
**ğŸ”¬ Broad Technical**: Natural Language Processing

## ğŸ·ï¸ ì¶”ì¶œëœ í‚¤ì›Œë“œ



`Language Models` â€¢ 

`Privacy Preservation` â€¢ 

`Evolutionary Algorithms` â€¢ 

`PriME` â€¢ 

`Privacy-Utility Trade-off`



## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸

Similar papers will be displayed here based on embedding similarity.

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2503.18008v2 Announce Type: replace 
Abstract: Personalization in language models aims to tailor model behavior to individual users or user groups. Prompt-based methods incorporate user preferences into queries, while training-based methods encode them into model parameters. Model merging has also been explored for personalization under limited data. However, existing methods often fail to directly optimize task-specific utility and lack explicit mechanisms for privacy preservation. To address the limitations, we propose Privacy-Preserving Model Merging via Evolutionary Algorithms (PriME), a novel personalization approach that employs gradient-free methods to directly optimize utility while reducing privacy risks. By integrating privacy preservation into the optimization objective, PriME creates personalized modules that effectively capture target user preferences while minimizing privacy risks for data-sharing users. Experiments on the LaMP benchmark show that PriME consistently outperforms a range of baselines, achieving up to a 45% improvement in task performance. Further analysis demonstrates that PriME achieves a superior privacy-utility trade-off compared to a prior state-of-the-art, with enhanced robustness to membership inference attacks and greater utility in capturing user preferences.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2503.18008v2 ë°œí‘œ ìœ í˜•: êµì²´  
ì´ˆë¡: ì–¸ì–´ ëª¨ë¸ì˜ ê°œì¸í™”ëŠ” ê°œë³„ ì‚¬ìš©ì ë˜ëŠ” ì‚¬ìš©ì ê·¸ë£¹ì— ë§ì¶° ëª¨ë¸ì˜ ë™ì‘ì„ ì¡°ì •í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ë°©ë²•ì€ ì‚¬ìš©ì ì„ í˜¸ë„ë¥¼ ì¿¼ë¦¬ì— í†µí•©í•˜ëŠ” ë°˜ë©´, í•™ìŠµ ê¸°ë°˜ ë°©ë²•ì€ ì´ë¥¼ ëª¨ë¸ ë§¤ê°œë³€ìˆ˜ì— ì¸ì½”ë”©í•©ë‹ˆë‹¤. ì œí•œëœ ë°ì´í„° í•˜ì—ì„œ ê°œì¸í™”ë¥¼ ìœ„í•œ ëª¨ë¸ ë³‘í•©ë„ íƒêµ¬ë˜ì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê¸°ì¡´ ë°©ë²•ë“¤ì€ ì¢…ì¢… ê³¼ì œë³„ íš¨ìš©ì„ ì§ì ‘ ìµœì í™”í•˜ì§€ ëª»í•˜ê³ , í”„ë¼ì´ë²„ì‹œ ë³´í˜¸ë¥¼ ìœ„í•œ ëª…ì‹œì ì¸ ë©”ì»¤ë‹ˆì¦˜ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ í•œê³„ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ì§„í™” ì•Œê³ ë¦¬ì¦˜ì„ í†µí•œ í”„ë¼ì´ë²„ì‹œ ë³´í˜¸ ëª¨ë¸ ë³‘í•©(PriME)ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ëŠ” íš¨ìš©ì„ ì§ì ‘ ìµœì í™”í•˜ë©´ì„œ í”„ë¼ì´ë²„ì‹œ ìœ„í—˜ì„ ì¤„ì´ëŠ” ìƒˆë¡œìš´ ê°œì¸í™” ì ‘ê·¼ ë°©ì‹ì…ë‹ˆë‹¤. ìµœì í™” ëª©í‘œì— í”„ë¼ì´ë²„ì‹œ ë³´í˜¸ë¥¼ í†µí•©í•¨ìœ¼ë¡œì¨, PriMEëŠ” ë°ì´í„° ê³µìœ  ì‚¬ìš©ìì— ëŒ€í•œ í”„ë¼ì´ë²„ì‹œ ìœ„í—˜ì„ ìµœì†Œí™”í•˜ë©´ì„œ ëª©í‘œ ì‚¬ìš©ì ì„ í˜¸ë„ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í¬ì°©í•˜ëŠ” ê°œì¸í™” ëª¨ë“ˆì„ ìƒì„±í•©ë‹ˆë‹¤. LaMP ë²¤ì¹˜ë§ˆí¬ ì‹¤í—˜ì—ì„œ PriMEëŠ” ë‹¤ì–‘í•œ ê¸°ì¤€ì„ ì¼ê´€ë˜ê²Œ ëŠ¥ê°€í•˜ë©°, ê³¼ì œ ì„±ëŠ¥ì—ì„œ ìµœëŒ€ 45%ì˜ í–¥ìƒì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. ì¶”ê°€ ë¶„ì„ì„ í†µí•´ PriMEê°€ ì´ì „ ìµœì²¨ë‹¨ ë°©ë²•ì— ë¹„í•´ ìš°ìˆ˜í•œ í”„ë¼ì´ë²„ì‹œ-íš¨ìš© ê· í˜•ì„ ë‹¬ì„±í•˜ë©°, ë©¤ë²„ì‹­ ì¶”ë¡  ê³µê²©ì— ëŒ€í•œ í–¥ìƒëœ ê°•ê±´ì„±ê³¼ ì‚¬ìš©ì ì„ í˜¸ë„ë¥¼ í¬ì°©í•˜ëŠ” ë° ìˆì–´ ë” í° íš¨ìš©ì„ ì œê³µí•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ê°œì¸í™”ëœ ì–¸ì–´ ëª¨ë¸ì„ ìœ„í•œ ìƒˆë¡œìš´ ì ‘ê·¼ë²•ì¸ PriMEë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ ë°©ë²•ë“¤ì´ íŠ¹ì • ì‘ì—…ì˜ ìœ ìš©ì„±ì„ ìµœì í™”í•˜ì§€ ëª»í•˜ê³  í”„ë¼ì´ë²„ì‹œ ë³´í˜¸ ë©”ì»¤ë‹ˆì¦˜ì´ ë¶€ì¡±í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, PriMEëŠ” ì§„í™” ì•Œê³ ë¦¬ì¦˜ì„ í™œìš©í•˜ì—¬ í”„ë¼ì´ë²„ì‹œ ìœ„í—˜ì„ ì¤„ì´ë©´ì„œ ìœ ìš©ì„±ì„ ì§ì ‘ ìµœì í™”í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, PriMEëŠ” LaMP ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìµœëŒ€ 45%ì˜ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì˜€ìœ¼ë©°, í”„ë¼ì´ë²„ì‹œ-ìœ ìš©ì„± ê°„ì˜ ê· í˜•ì„ ì˜ ìœ ì§€í•˜ê³  ì‚¬ìš©ì ì„ í˜¸ë„ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ë°˜ì˜í•˜ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸


- 1. ê°œì¸í™”ëœ ì–¸ì–´ ëª¨ë¸ì€ ì‚¬ìš©ì ë§ì¶¤í˜• í–‰ë™ì„ ëª©í‘œë¡œ í•˜ë©°, PriMEëŠ” ì§„í™” ì•Œê³ ë¦¬ì¦˜ì„ í†µí•´ ì´ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.

- 2. PriMEëŠ” í”„ë¼ì´ë²„ì‹œ ìœ„í—˜ì„ ì¤„ì´ë©´ì„œ ìœ í‹¸ë¦¬í‹°ë¥¼ ì§ì ‘ ìµœì í™”í•˜ëŠ” ìƒˆë¡œìš´ ê°œì¸í™” ì ‘ê·¼ë²•ì…ë‹ˆë‹¤.

- 3. PriMEëŠ” LaMP ë²¤ì¹˜ë§ˆí¬ ì‹¤í—˜ì—ì„œ ìµœëŒ€ 45%ì˜ ì„±ëŠ¥ í–¥ìƒì„ ë‹¬ì„±í•˜ë©°, ë‹¤ì–‘í•œ ê¸°ì¤€ì„ ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.

- 4. PriMEëŠ” ì´ì „ ìµœì²¨ë‹¨ ë°©ë²•ë³´ë‹¤ í”„ë¼ì´ë²„ì‹œ-ìœ í‹¸ë¦¬í‹° ê· í˜•ì´ ë›°ì–´ë‚˜ë©°, ë©¤ë²„ì‹­ ì¶”ë¡  ê³µê²©ì— ëŒ€í•œ ê°•ê±´ì„±ì´ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤.

- 5. PriMEëŠ” ë°ì´í„° ê³µìœ  ì‚¬ìš©ìì— ëŒ€í•œ í”„ë¼ì´ë²„ì‹œ ìœ„í—˜ì„ ìµœì†Œí™”í•˜ë©´ì„œ ëª©í‘œ ì‚¬ìš©ì ì„ í˜¸ë„ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í¬ì°©í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-22 16:36:22*