# Personalized Language Models via Privacy-Preserving Evolutionary Model Merging

**Korean Title:** 개인화된 언어 모델: 프라이버시 보호 진화적 모델 병합을 통한 접근

## 📋 메타데이터

## 📋 메타데이터

**Links**: [[reports/digests/daily_digest_20250922|2025-09-22]] [[keywords/evolved/Privacy-Utility Trade-off|Privacy-Utility Trade-off]] [[keywords/specific/Evolutionary Algorithms|Evolutionary Algorithms]] [[keywords/broad/Language Models|Language Models]] [[keywords/broad/Privacy Preservation|Privacy Preservation]] [[keywords/unique/PriME|PriME]] [[categories/cs.CL|cs.CL]] [[2025-09-19/Communication-Efficient and Privacy-Adaptable Mechanism for Federated Learning_20250919|Communication-Efficient and Privacy-Adaptable Mechanism for Federated Learning]] (83.3% similar) [[2025-09-22/DP-GTR_ Differentially Private Prompt Protection via Group Text Rewriting_20250922|DP-GTR: Differentially Private Prompt Protection via Group Text Rewriting]] (82.6% similar) [[2025-09-17/ParaAegis_ Parallel Protection for Flexible Privacy-preserved Federated Learning_20250917|ParaAegis: Parallel Protection for Flexible Privacy-preserved Federated Learning]] (81.7% similar)

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Privacy-Utility Trade-off
**🔗 Specific Connectable**: Evolutionary Algorithms
**🔬 Broad Technical**: Language Models, Privacy Preservation
**⭐ Unique Technical**: PriME
## 🔗 유사한 논문
- [[2025-09-19/Communication-Efficient and Privacy-Adaptable Mechanism for Federated Learning_20250919|Communication-Efficient and Privacy-Adaptable Mechanism for Federated Learning]] (83.3% similar)
- [[2025-09-22/DP-GTR_ Differentially Private Prompt Protection via Group Text Rewriting_20250922|DP-GTR Differentially Private Prompt Protection via Group Text Rewriting]] (82.6% similar)
- [[2025-09-17/ParaAegis_ Parallel Protection for Flexible Privacy-preserved Federated Learning_20250917|ParaAegis Parallel Protection for Flexible Privacy-preserved Federated Learning]] (81.7% similar)
- [[2025-09-19/Learning in Context_ Personalizing Educational Content with Large Language Models to Enhance Student Learning_20250919|Learning in Context Personalizing Educational Content with Large Language Models to Enhance Student Learning]] (81.7% similar)
- [[2025-09-19/The Sum Leaks More Than Its Parts_ Compositional Privacy Risks and Mitigations in Multi-Agent Collaboration_20250919|The Sum Leaks More Than Its Parts Compositional Privacy Risks and Mitigations in Multi-Agent Collaboration]] (81.7% similar)


**ArXiv ID**: [2503.18008](https://arxiv.org/abs/2503.18008)
**Published**: 2025-09-22
**Category**: cs.CL
**PDF**: [Download](https://arxiv.org/pdf/2503.18008.pdf)


**ArXiv ID**: [2503.18008](https://arxiv.org/abs/2503.18008)
**Published**: 2025-09-22
**Category**: cs.CL
**PDF**: [Download](https://arxiv.org/pdf/2503.18008.pdf)

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Privacy Utility Trade off
**🔗 Specific Connectable**: Privacy Preserving Algorithms
**⭐ Unique Technical**: PriME
**🔬 Broad Technical**: Natural Language Processing

## 🏷️ 추출된 키워드



`Language Models` • 

`Privacy Preservation` • 

`Evolutionary Algorithms` • 

`PriME` • 

`Privacy-Utility Trade-off`



## 🔗 유사한 논문

Similar papers will be displayed here based on embedding similarity.

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2503.18008v2 Announce Type: replace 
Abstract: Personalization in language models aims to tailor model behavior to individual users or user groups. Prompt-based methods incorporate user preferences into queries, while training-based methods encode them into model parameters. Model merging has also been explored for personalization under limited data. However, existing methods often fail to directly optimize task-specific utility and lack explicit mechanisms for privacy preservation. To address the limitations, we propose Privacy-Preserving Model Merging via Evolutionary Algorithms (PriME), a novel personalization approach that employs gradient-free methods to directly optimize utility while reducing privacy risks. By integrating privacy preservation into the optimization objective, PriME creates personalized modules that effectively capture target user preferences while minimizing privacy risks for data-sharing users. Experiments on the LaMP benchmark show that PriME consistently outperforms a range of baselines, achieving up to a 45% improvement in task performance. Further analysis demonstrates that PriME achieves a superior privacy-utility trade-off compared to a prior state-of-the-art, with enhanced robustness to membership inference attacks and greater utility in capturing user preferences.

## 🔍 Abstract (한글 번역)

arXiv:2503.18008v2 발표 유형: 교체  
초록: 언어 모델의 개인화는 개별 사용자 또는 사용자 그룹에 맞춰 모델의 동작을 조정하는 것을 목표로 합니다. 프롬프트 기반 방법은 사용자 선호도를 쿼리에 통합하는 반면, 학습 기반 방법은 이를 모델 매개변수에 인코딩합니다. 제한된 데이터 하에서 개인화를 위한 모델 병합도 탐구되었습니다. 그러나 기존 방법들은 종종 과제별 효용을 직접 최적화하지 못하고, 프라이버시 보호를 위한 명시적인 메커니즘이 부족합니다. 이러한 한계를 해결하기 위해, 우리는 진화 알고리즘을 통한 프라이버시 보호 모델 병합(PriME)을 제안합니다. 이는 효용을 직접 최적화하면서 프라이버시 위험을 줄이는 새로운 개인화 접근 방식입니다. 최적화 목표에 프라이버시 보호를 통합함으로써, PriME는 데이터 공유 사용자에 대한 프라이버시 위험을 최소화하면서 목표 사용자 선호도를 효과적으로 포착하는 개인화 모듈을 생성합니다. LaMP 벤치마크 실험에서 PriME는 다양한 기준을 일관되게 능가하며, 과제 성능에서 최대 45%의 향상을 달성했습니다. 추가 분석을 통해 PriME가 이전 최첨단 방법에 비해 우수한 프라이버시-효용 균형을 달성하며, 멤버십 추론 공격에 대한 향상된 강건성과 사용자 선호도를 포착하는 데 있어 더 큰 효용을 제공함을 보여줍니다.

## 📝 요약

이 논문은 개인화된 언어 모델을 위한 새로운 접근법인 PriME를 제안합니다. 기존 방법들이 특정 작업의 유용성을 최적화하지 못하고 프라이버시 보호 메커니즘이 부족한 문제를 해결하기 위해, PriME는 진화 알고리즘을 활용하여 프라이버시 위험을 줄이면서 유용성을 직접 최적화합니다. 실험 결과, PriME는 LaMP 벤치마크에서 최대 45%의 성능 향상을 보였으며, 프라이버시-유용성 간의 균형을 잘 유지하고 사용자 선호도를 효과적으로 반영하는 것으로 나타났습니다.

## 🎯 주요 포인트


- 1. 개인화된 언어 모델은 사용자 맞춤형 행동을 목표로 하며, PriME는 진화 알고리즘을 통해 이를 구현합니다.

- 2. PriME는 프라이버시 위험을 줄이면서 유틸리티를 직접 최적화하는 새로운 개인화 접근법입니다.

- 3. PriME는 LaMP 벤치마크 실험에서 최대 45%의 성능 향상을 달성하며, 다양한 기준선보다 우수한 성능을 보입니다.

- 4. PriME는 이전 최첨단 방법보다 프라이버시-유틸리티 균형이 뛰어나며, 멤버십 추론 공격에 대한 강건성이 향상되었습니다.

- 5. PriME는 데이터 공유 사용자에 대한 프라이버시 위험을 최소화하면서 목표 사용자 선호도를 효과적으로 포착합니다.


---

*Generated on 2025-09-22 16:36:22*