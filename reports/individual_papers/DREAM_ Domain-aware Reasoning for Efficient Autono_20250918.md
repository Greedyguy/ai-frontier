
# DREAM: Domain-aware Reasoning for Efficient Autonomous Underwater Monitoring

**Korean Title:** 한국어 번역:
DREAM: 효율적인 자율 잠수함 모니터링을 위한 도메인 인식 추론

## 📋 메타데이터

**Links**: [[daily/2025-09-18|2025-09-18]] [[keywords/evolved/Environment-aware decisions|Environment-aware decisions]] [[keywords/broad/Autonomous Underwater Monitoring|Autonomous Underwater Monitoring]] [[keywords/broad/Vision Language Model|Vision Language Model]] [[keywords/specific/Long-term monitoring systems|Long-term monitoring systems]] [[keywords/unique/DREAM|DREAM]] [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Environment-aware decisions
**🔬 Broad Technical**: Autonomous Underwater Monitoring, Vision Language Model
**🔗 Specific Connectable**: Long-term monitoring systems
**⭐ Unique Technical**: DREAM

**ArXiv ID**: [2509.13666](https://arxiv.org/abs/2509.13666)
**Published**: 2025-09-18
**Category**: cs.AI
**PDF**: [Download](https://arxiv.org/pdf/2509.13666.pdf)


## 🏷️ 추출된 키워드



`Autonomous Underwater Monitoring` • 

`Vision Language Model` • 

`Long-term monitoring systems` • 

`DREAM` • 

`Environment-aware decisions`



## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.13666v1 Announce Type: cross 
Abstract: The ocean is warming and acidifying, increasing the risk of mass mortality events for temperature-sensitive shellfish such as oysters. This motivates the development of long-term monitoring systems. However, human labor is costly and long-duration underwater work is highly hazardous, thus favoring robotic solutions as a safer and more efficient option. To enable underwater robots to make real-time, environment-aware decisions without human intervention, we must equip them with an intelligent "brain." This highlights the need for persistent,wide-area, and low-cost benthic monitoring. To this end, we present DREAM, a Vision Language Model (VLM)-guided autonomy framework for long-term underwater exploration and habitat monitoring. The results show that our framework is highly efficient in finding and exploring target objects (e.g., oysters, shipwrecks) without prior location information. In the oyster-monitoring task, our framework takes 31.5% less time than the previous baseline with the same amount of oysters. Compared to the vanilla VLM, it uses 23% fewer steps while covering 8.88% more oysters. In shipwreck scenes, our framework successfully explores and maps the wreck without collisions, requiring 27.5% fewer steps than the vanilla model and achieving 100% coverage, while the vanilla model achieves 60.23% average coverage in our shipwreck environments.

## 🔍 Abstract (한글 번역)

arXiv:2509.13666v1 발표 유형: 교차
요약: 해양은 온난화되고 산성화되며, 조개류와 같은 온도에 민감한 조개류에 대한 대규모 사멸 사건의 위험을 증가시킵니다. 이는 장기간 모니터링 시스템의 개발을 촉발시킵니다. 그러나 인간 노동은 비용이 많이 들고 장기간 수중 작업은 매우 위험하기 때문에, 로봇 솔루션이 더 안전하고 효율적인 옵션으로 선호됩니다. 인간 개입 없이 수중 로봇이 실시간으로 환경을 인식하고 결정을 내릴 수 있도록 하려면, 그들에게 지능적인 "뇌"를 장착해야 합니다. 이는 지속적이고 넓은 영역, 저비용의 해저 모니터링의 필요성을 강조합니다. 이를 위해 우리는 장기간 수중 탐사 및 서식지 모니터링을 위한 Vision Language Model (VLM)-guided 자율 프레임워크인 DREAM을 제시합니다. 결과는 우리의 프레임워크가 사전 위치 정보 없이도 대상 물체(예: 조개, 난파선)를 찾고 탐색하는 데 매우 효율적임을 보여줍니다. 조개 모니터링 작업에서 우리의 프레임워크는 이전 베이스라인과 동일한 양의 조개를 처리하는 데 31.5% 더 적은 시간이 걸립니다. 바닐라 VLM과 비교했을 때, 23% 더 적은 단계를 사용하면서 8.88% 더 많은 조개를 처리합니다. 난파선 장면에서는 우리의 프레임워크가 충돌 없이 난파선을 탐색하고 매핑하는 데 바닐라 모델보다 27.5% 더 적은 단계가 필요하며 100%의 커버리지를 달성합니다. 한편 바닐라 모델은 우리의 난파선 환경에서 평균 60.23%의 커버리지를 달성합니다.

## 📝 요약

해양은 온난화와 산성화로 인해 조개류와 같은 온도 민감한 해산물의 대규모 사멸 사건 위험이 증가하고 있다. 이에 장기간 모니터링 시스템의 개발이 필요한데, 인력은 비용이 많이 들고 장기간 수중 작업은 매우 위험하므로 로봇 솔루션이 안전하고 효율적인 선택지로 부상하고 있다. 이를 위해 우리는 DREAM이라는 비전 언어 모델(VLM)로 안내되는 자율성 프레임워크를 제시하여 장기간 수중 탐사 및 서식지 모니터링을 위한 지속적이고 넓은 영역의 저비용 해저 모니터링이 필요함을 강조한다. 결과는 우리의 프레임워크가 목표물(예: 굴, 난파선)을 사전 위치 정보 없이 찾고 탐사하는 데 매우 효율적임을 보여준다.

## 🎯 주요 포인트


- 1. 조개류와 같은 온도 민감한 해산물의 대규모 사멸 사건 위험 증가로 장기 모니터링 시스템의 필요성 증가

- 2. DREAM은 장기 수중 탐사 및 서식지 모니터링을 위한 지능적인 "뇌"를 장착한 비전 언어 모델 (VLM)로 안내되는 자율 프레임워크 제시

- 3. DREAM 프레임워크는 이전 기준선과 비교하여 조개 모니터링 작업에서 시간을 31.5% 절약하고, 배낭 모델과 비교하여 23% 더 적은 단계를 사용하며 8.88% 더 많은 조개를 커버함.


---

*Generated on 2025-09-18 16:21:15*