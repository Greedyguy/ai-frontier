# SETrLUSI: Stochastic Ensemble Multi-Source Transfer Learning Using Statistical Invariant

**Korean Title:** SETrLUSI: í†µê³„ì  ë¶ˆë³€ëŸ‰ì„ ì‚¬ìš©í•˜ëŠ” í™•ë¥ ì  ì•™ìƒë¸” ë‹¤ì¤‘ ì†ŒìŠ¤ ì „ì´ í•™ìŠµ

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.LG|cs.LG]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Multi-source Transfer Learning

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Select to Know_ An Internal-External Knowledge Self-Selection Framework for Domain-Specific Question Answering_20250919|Select to Know An Internal-External Knowledge Self-Selection Framework for Domain-Specific Question Answering]] (80.6% similar)
- [[2025-09-22/TISDiSS_ A Training-Time and Inference-Time Scalable Framework for Discriminative Source Separation_20250922|TISDiSS A Training-Time and Inference-Time Scalable Framework for Discriminative Source Separation]] (80.5% similar)
- [[2025-09-22/Efficient Long-Tail Learning in Latent Space by sampling Synthetic Data_20250922|Efficient Long-Tail Learning in Latent Space by sampling Synthetic Data]] (79.7% similar)
- [[2025-09-19/CodeLSI_ Leveraging Foundation Models for Automated Code Generation with Low-Rank Optimization and Domain-Specific Instruction Tuning_20250919|CodeLSI Leveraging Foundation Models for Automated Code Generation with Low-Rank Optimization and Domain-Specific Instruction Tuning]] (79.6% similar)
- [[2025-09-19/Superpose Task-specific Features for Model Merging_20250919|Superpose Task-specific Features for Model Merging]] (79.0% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15593v1 Announce Type: cross 
Abstract: In transfer learning, a source domain often carries diverse knowledge, and different domains usually emphasize different types of knowledge. Different from handling only a single type of knowledge from all domains in traditional transfer learning methods, we introduce an ensemble learning framework with a weak mode of convergence in the form of Statistical Invariant (SI) for multi-source transfer learning, formulated as Stochastic Ensemble Multi-Source Transfer Learning Using Statistical Invariant (SETrLUSI). The proposed SI extracts and integrates various types of knowledge from both source and target domains, which not only effectively utilizes diverse knowledge but also accelerates the convergence process. Further, SETrLUSI incorporates stochastic SI selection, proportional source domain sampling, and target domain bootstrapping, which improves training efficiency while enhancing model stability. Experiments show that SETrLUSI has good convergence and outperforms related methods with a lower time cost.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15593v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ì „ì´ í•™ìŠµì—ì„œ ì†ŒìŠ¤ ë„ë©”ì¸ì€ ì¢…ì¢… ë‹¤ì–‘í•œ ì§€ì‹ì„ í¬í•¨í•˜ê³  ìˆìœ¼ë©°, ì„œë¡œ ë‹¤ë¥¸ ë„ë©”ì¸ì€ ë³´í†µ ì„œë¡œ ë‹¤ë¥¸ ìœ í˜•ì˜ ì§€ì‹ì„ ê°•ì¡°í•©ë‹ˆë‹¤. ì „í†µì ì¸ ì „ì´ í•™ìŠµ ë°©ë²•ì—ì„œ ëª¨ë“  ë„ë©”ì¸ìœ¼ë¡œë¶€í„° ë‹¨ì¼ ìœ í˜•ì˜ ì§€ì‹ë§Œì„ ë‹¤ë£¨ëŠ” ê²ƒê³¼ ë‹¬ë¦¬, ìš°ë¦¬ëŠ” ë‹¤ì¤‘ ì†ŒìŠ¤ ì „ì´ í•™ìŠµì„ ìœ„í•œ í†µê³„ì  ë¶ˆë³€ì„±(SI)ì˜ í˜•íƒœë¡œ ì•½í•œ ìˆ˜ë ´ ëª¨ë“œë¥¼ ê°€ì§„ ì•™ìƒë¸” í•™ìŠµ í”„ë ˆì„ì›Œí¬ë¥¼ ë„ì…í•©ë‹ˆë‹¤. ì´ëŠ” í†µê³„ì  ë¶ˆë³€ì„±ì„ ì‚¬ìš©í•˜ëŠ” í™•ë¥ ì  ì•™ìƒë¸” ë‹¤ì¤‘ ì†ŒìŠ¤ ì „ì´ í•™ìŠµ(SETrLUSI)ìœ¼ë¡œ ê³µì‹í™”ë©ë‹ˆë‹¤. ì œì•ˆëœ SIëŠ” ì†ŒìŠ¤ ë° íƒ€ê²Ÿ ë„ë©”ì¸ ëª¨ë‘ì—ì„œ ë‹¤ì–‘í•œ ìœ í˜•ì˜ ì§€ì‹ì„ ì¶”ì¶œí•˜ê³  í†µí•©í•˜ì—¬, ë‹¤ì–‘í•œ ì§€ì‹ì„ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•  ë¿ë§Œ ì•„ë‹ˆë¼ ìˆ˜ë ´ ê³¼ì •ì„ ê°€ì†í™”í•©ë‹ˆë‹¤. ë˜í•œ, SETrLUSIëŠ” í™•ë¥ ì  SI ì„ íƒ, ë¹„ë¡€ ì†ŒìŠ¤ ë„ë©”ì¸ ìƒ˜í”Œë§, íƒ€ê²Ÿ ë„ë©”ì¸ ë¶€íŠ¸ìŠ¤íŠ¸ë˜í•‘ì„ í¬í•¨í•˜ì—¬, ëª¨ë¸ì˜ ì•ˆì •ì„±ì„ í–¥ìƒì‹œí‚¤ë©´ì„œ í›ˆë ¨ íš¨ìœ¨ì„±ì„ ê°œì„ í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, SETrLUSIëŠ” ì¢‹ì€ ìˆ˜ë ´ì„±ì„ ë³´ì´ë©°, ê´€ë ¨ ë°©ë²•ë“¤ì— ë¹„í•´ ë‚®ì€ ì‹œê°„ ë¹„ìš©ìœ¼ë¡œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë°œíœ˜í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì „ì´ í•™ìŠµì—ì„œ ë‹¤ì–‘í•œ ì§€ì‹ì„ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•˜ê¸° ìœ„í•´ ë‹¤ì¤‘ ì†ŒìŠ¤ ì „ì´ í•™ìŠµì„ ìœ„í•œ í†µê³„ì  ë¶ˆë³€(SI) ê¸°ë°˜ì˜ ì•™ìƒë¸” í•™ìŠµ í”„ë ˆì„ì›Œí¬(SETrLUSI)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì œì•ˆëœ ë°©ë²•ì€ ì†ŒìŠ¤ì™€ íƒ€ê²Ÿ ë„ë©”ì¸ì—ì„œ ë‹¤ì–‘í•œ ì§€ì‹ì„ ì¶”ì¶œí•˜ê³  í†µí•©í•˜ì—¬ ìˆ˜ë ´ ê³¼ì •ì„ ê°€ì†í™”í•©ë‹ˆë‹¤. ë˜í•œ, í™•ë¥ ì  SI ì„ íƒ, ë¹„ë¡€ì  ì†ŒìŠ¤ ë„ë©”ì¸ ìƒ˜í”Œë§, íƒ€ê²Ÿ ë„ë©”ì¸ ë¶€íŠ¸ìŠ¤íŠ¸ë˜í•‘ì„ í†µí•´ ëª¨ë¸ì˜ ì•ˆì •ì„±ì„ ë†’ì´ê³  í›ˆë ¨ íš¨ìœ¨ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, SETrLUSIëŠ” ìš°ìˆ˜í•œ ìˆ˜ë ´ì„±ì„ ë³´ì´ë©° ê´€ë ¨ ë°©ë²•ë“¤ë³´ë‹¤ ë‚®ì€ ì‹œê°„ ë¹„ìš©ìœ¼ë¡œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. SETrLUSIëŠ” í†µê³„ì  ë¶ˆë³€ì„±(SI)ì„ í™œìš©í•˜ì—¬ ë‹¤ì–‘í•œ ì¶œì²˜ì™€ ëª©í‘œ ë„ë©”ì¸ì—ì„œ ì§€ì‹ì„ ì¶”ì¶œí•˜ê³  í†µí•©í•©ë‹ˆë‹¤.

- 2. ì œì•ˆëœ í”„ë ˆì„ì›Œí¬ëŠ” ë‹¤ì–‘í•œ ì§€ì‹ì„ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•˜ë©´ì„œ ìˆ˜ë ´ ê³¼ì •ì„ ê°€ì†í™”í•©ë‹ˆë‹¤.

- 3. SETrLUSIëŠ” í™•ë¥ ì  SI ì„ íƒ, ë¹„ë¡€ì  ì¶œì²˜ ë„ë©”ì¸ ìƒ˜í”Œë§, ëª©í‘œ ë„ë©”ì¸ ë¶€íŠ¸ìŠ¤íŠ¸ë˜í•‘ì„ í¬í•¨í•˜ì—¬ í›ˆë ¨ íš¨ìœ¨ì„±ì„ ê°œì„ í•˜ê³  ëª¨ë¸ ì•ˆì •ì„±ì„ ê°•í™”í•©ë‹ˆë‹¤.

- 4. ì‹¤í—˜ ê²°ê³¼, SETrLUSIëŠ” ì¢‹ì€ ìˆ˜ë ´ì„±ì„ ë³´ì´ë©°, ê´€ë ¨ ë°©ë²•ë“¤ë³´ë‹¤ ë‚®ì€ ì‹œê°„ ë¹„ìš©ìœ¼ë¡œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë°œíœ˜í•©ë‹ˆë‹¤.

---

*Generated on 2025-09-22 15:39:58*