
# Generative Image Coding with Diffusion Prior

**Korean Title:** 확산 사전을 이용한 생성 이미지 코딩

## 📋 메타데이터

**Links**: [[daily/2025-09-18|2025-09-18]] [[keywords/evolved/Efficient Adaptation|Efficient Adaptation]] [[keywords/broad/Generative Coding|Generative Coding]] [[keywords/broad/Diffusion Prior|Diffusion Prior]] [[keywords/specific/Pre-optimized Encoder|Pre-optimized Encoder]] [[keywords/unique/Distribution Renormalization|Distribution Renormalization]] [[categories/cs.CV|cs.CV]]

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Efficient Adaptation
**🔬 Broad Technical**: Generative Coding, Diffusion Priors
**🔗 Specific Connectable**: Pre-optimized Encoder
**⭐ Unique Technical**: Distribution Renormalization

**ArXiv ID**: [2509.13768](https://arxiv.org/abs/2509.13768)
**Published**: 2025-09-18
**Category**: cs.CV
**PDF**: [Download](https://arxiv.org/pdf/2509.13768.pdf)


## 🏷️ 추출된 키워드



`Generative Coding` • 

`Diffusion Prior` • 

`Pre-optimized Encoder` • 

`Distribution Renormalization` • 

`Efficient Adaptation`



## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.13768v1 Announce Type: new 
Abstract: As generative technologies advance, visual content has evolved into a complex mix of natural and AI-generated images, driving the need for more efficient coding techniques that prioritize perceptual quality. Traditional codecs and learned methods struggle to maintain subjective quality at high compression ratios, while existing generative approaches face challenges in visual fidelity and generalization. To this end, we propose a novel generative coding framework leveraging diffusion priors to enhance compression performance at low bitrates. Our approach employs a pre-optimized encoder to generate generalized compressed-domain representations, integrated with the pretrained model's internal features via a lightweight adapter and an attentive fusion module. This framework effectively leverages existing pretrained diffusion models and enables efficient adaptation to different pretrained models for new requirements with minimal retraining costs. We also introduce a distribution renormalization method to further enhance reconstruction fidelity. Extensive experiments show that our method (1) outperforms existing methods in visual fidelity across low bitrates, (2) improves compression performance by up to 79% over H.266/VVC, and (3) offers an efficient solution for AI-generated content while being adaptable to broader content types.

## 🔍 Abstract (한글 번역)

arXiv:2509.13768v1 발표 유형: 새로운
요약: 생성 기술이 발전함에 따라 시각적 콘텐츠는 자연 및 AI 생성 이미지의 복합적인 혼합물로 진화하고 있으며, 이는 지각적 품질을 우선시하는 더 효율적인 코딩 기술의 필요성을 증가시키고 있습니다. 전통적인 코덱 및 학습된 방법은 고 압축 비율에서 주관적 품질을 유지하기 어렵지만, 기존의 생성 접근 방식은 시각적 충실성과 일반화에 도전을 겪고 있습니다. 이에 우리는 낮은 비트율에서 압축 성능을 향상시키기 위해 확산 사전을 활용한 새로운 생성 코딩 프레임워크를 제안합니다. 우리의 접근 방식은 사전 최적화된 인코더를 사용하여 일반화된 압축 도메인 표현을 생성하고, 가벼운 어댑터와 주의 집중 모듈을 통해 사전 학습된 모델의 내부 기능과 통합합니다. 이 프레임워크는 효과적으로 기존의 사전 학습된 확산 모델을 활용하고, 최소한의 재학습 비용으로 새로운 요구 사항에 대한 다양한 사전 학습된 모델에 효율적으로 적응할 수 있습니다. 또한 재구성 충실성을 더 향상시키기 위한 분포 재정규화 방법을 소개합니다. 광범위한 실험 결과는 우리의 방법이 (1) 낮은 비트율에서 시각적 충실성에서 기존 방법을 능가하고, (2) H.266/VVC 대비 최대 79%의 압축 성능을 향상시키며, (3) AI 생성 콘텐츠에 효율적인 솔루션을 제공하면서 더 넓은 콘텐츠 유형에 적응할 수 있다는 것을 보여줍니다.

## 📝 요약

최근 생성 기술의 발전으로 시각 콘텐츠는 자연 및 AI 생성 이미지의 복합물이 되어가고 있어, 주관적 품질을 우선시하는 효율적인 코딩 기술이 필요하다. 기존 코덱 및 학습된 방법은 고압축 비율에서 주관적 품질을 유지하는 데 어려움을 겪고, 기존 생성 방법은 시각적 충실성과 일반화에 어려움을 겪고 있다. 이에 우리는 낮은 비트율에서 압축 성능을 향상시키기 위해 확산 사전을 활용하는 새로운 생성 코딩 프레임워크를 제안한다. 우리의 방법은 사전 최적화된 인코더를 사용하여 일반화된 압축 도메인 표현을 생성하고, 가벼운 어댑터와 주의 집중 모듈을 통해 사전 학습 모델의 내부 특징을 효과적으로 통합한다. 우리의 방법은 시각적 충실성에서 기존 방법을 능가하고, H.266/VVC 대비 최대 79%의 압축 성능 향상을 보여주며, AI 생성 콘텐츠에 효율적인 솔루션을 제공하면서 보다 넓은 콘텐츠 유형에 대해 적응 가능하다.

## 🎯 주요 포인트


- 시각 콘텐츠의 복잡성 증가로 더 효율적인 코딩 기술 필요

- 확산 사전을 활용한 새로운 생성 코딩 프레임워크 제안

- 저 비트율에서 시각적 충실성 향상 및 압축 성능 개선을 보여줌


---

*Generated on 2025-09-18 17:01:26*