
# Semi-MoE: Mixture-of-Experts meets Semi-Supervised Histopathology Segmentation

**Korean Title:** Semi-MoE: ì „ë¬¸ê°€ í˜¼í•© ëª¨ë¸ì´ ë°˜ì§€ë„ í•™ìŠµì„ ë§Œë‚˜ëŠ” Semi-Supervised ì¡°ì§ë³‘ë¦¬í•™ ë¶„í• 

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-18|2025-09-18]] [[keywords/evolved/Multi-Gating Pseudo-labeling|Multi-Gating Pseudo-labeling]] [[keywords/broad/Semi-supervised learning|Semi-supervised learning]] [[keywords/broad/Histopathology image segmentation|Histopathology image segmentation]] [[keywords/specific/Multi-task learning|Multi-task learning]] [[keywords/unique/Semi-MoE|Semi-MoE]] [[categories/cs.CV|cs.CV]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Multi-Gating Pseudo-labeling
**ğŸ”¬ Broad Technical**: Semi-supervised learning, Histopathology image segmentation
**ğŸ”— Specific Connectable**: Multi-task learning
**â­ Unique Technical**: Semi-MoE

**ArXiv ID**: [2509.13834](https://arxiv.org/abs/2509.13834)
**Published**: 2025-09-18
**Category**: cs.CV
**PDF**: [Download](https://arxiv.org/pdf/2509.13834.pdf)


## ğŸ·ï¸ ì¶”ì¶œëœ í‚¤ì›Œë“œ



`Semi-supervised learning` â€¢ 

`Histopathology image segmentation` â€¢ 

`Multi-task learning` â€¢ 

`Semi-MoE` â€¢ 

`Multi-Gating Pseudo-labeling`



## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.13834v1 Announce Type: new 
Abstract: Semi-supervised learning has been employed to alleviate the need for extensive labeled data for histopathology image segmentation, but existing methods struggle with noisy pseudo-labels due to ambiguous gland boundaries and morphological misclassification. This paper introduces Semi-MOE, to the best of our knowledge, the first multi-task Mixture-of-Experts framework for semi-supervised histopathology image segmentation. Our approach leverages three specialized expert networks: A main segmentation expert, a signed distance field regression expert, and a boundary prediction expert, each dedicated to capturing distinct morphological features. Subsequently, the Multi-Gating Pseudo-labeling module dynamically aggregates expert features, enabling a robust fuse-and-refine pseudo-labeling mechanism. Furthermore, to eliminate manual tuning while dynamically balancing multiple learning objectives, we propose an Adaptive Multi-Objective Loss. Extensive experiments on GlaS and CRAG benchmarks show that our method outperforms state-of-the-art approaches in low-label settings, highlighting the potential of MoE-based architectures in advancing semi-supervised segmentation. Our code is available at https://github.com/vnlvi2k3/Semi-MoE.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.13834v1 ë°œí‘œ ìœ í˜•: ìƒˆë¡œìš´
ìš”ì•½: ë°˜ì§€ë„ í•™ìŠµì€ ì¡°ì§ë³‘ë¦¬í•™ ì´ë¯¸ì§€ ë¶„í• ì„ ìœ„í•œ ê´‘ë²”ìœ„í•œ ë ˆì´ë¸” ë°ì´í„°ì˜ í•„ìš”ì„±ì„ ì™„í™”í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë˜ì–´ ì™”ì§€ë§Œ, ê¸°ì¡´ ë°©ë²•ë“¤ì€ ëª¨í˜¸í•œ ì„ ìƒ˜ê³¼ í˜•íƒœí•™ì  ì˜¤ë¶„ë¥˜ë¡œ ì¸í•œ ì¡ìŒì´ ìˆëŠ” ê°€ì§œ ë ˆì´ë¸”ë¡œ ê³ ë¯¼í•©ë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ìš°ë¦¬ì˜ ì§€ì‹ìœ¼ë¡œëŠ” ë°˜ì§€ë„ ì¡°ì§ë³‘ë¦¬í•™ ì´ë¯¸ì§€ ë¶„í• ì„ ìœ„í•œ ìµœì´ˆì˜ ë‹¤ì¤‘ ì‘ì—… ì „ë¬¸ê°€ ëª¨ë¸ì¸ Semi-MOEë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ì €í¬ ë°©ë²•ì€ ì„¸ ê°€ì§€ ì „ë¬¸ê°€ ë„¤íŠ¸ì›Œí¬ë¥¼ í™œìš©í•©ë‹ˆë‹¤: ì£¼ìš” ë¶„í•  ì „ë¬¸ê°€, ë¶€í˜¸í™”ëœ ê±°ë¦¬ í•„ë“œ íšŒê·€ ì „ë¬¸ê°€ ë° ê²½ê³„ ì˜ˆì¸¡ ì „ë¬¸ê°€ë¡œ, ê°ê°ì´ ë‹¤ë¥¸ í˜•íƒœí•™ì  íŠ¹ì§•ì„ ìº¡ì²˜í•˜ê¸° ìœ„í•´ ì „ìš©ë©ë‹ˆë‹¤. ì´í›„ Multi-Gating Pseudo-labeling ëª¨ë“ˆì€ ì „ë¬¸ê°€ íŠ¹ì§•ì„ ë™ì ìœ¼ë¡œ ì§‘ê³„í•˜ì—¬ ê²¬ê³ í•œ ìœµí•© ë° ì •ì œ ê°€ì§œ ë ˆì´ë¸” ë©”ì»¤ë‹ˆì¦˜ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ë” ë‚˜ì•„ê°€, ë‹¤ì¤‘ í•™ìŠµ ëª©í‘œë¥¼ ë™ì ìœ¼ë¡œ ê· í˜•ì„ ë§ì¶”ë©´ì„œ ìˆ˜ë™ ì¡°ì •ì„ ì œê±°í•˜ê¸° ìœ„í•´ ìš°ë¦¬ëŠ” ì ì‘í˜• ë‹¤ì¤‘ ëª©ì  ì†ì‹¤ì„ ì œì•ˆí•©ë‹ˆë‹¤. GlaS ë° CRAG ë²¤ì¹˜ë§ˆí¬ì—ì„œì˜ ê´‘ë²”ìœ„í•œ ì‹¤í—˜ ê²°ê³¼ëŠ” ì €í¬ ë°©ë²•ì´ ì €ë ˆì´ë¸” ì„¤ì •ì—ì„œ ìµœì²¨ë‹¨ ì ‘ê·¼ ë°©ì‹ì„ ëŠ¥ê°€í•¨ì„ ë³´ì—¬ì£¼ë©°, ë°˜ì§€ë„ ë¶„í• ì„ ë°œì „ì‹œí‚¤ëŠ” MoE ê¸°ë°˜ ì•„í‚¤í…ì²˜ì˜ ì ì¬ë ¥ì„ ê°•ì¡°í•©ë‹ˆë‹¤. ì €í¬ ì½”ë“œëŠ” https://github.com/vnlvi2k3/Semi-MoEì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì¡°ì§í•™ ì´ë¯¸ì§€ ë¶„í• ì„ ìœ„í•œ ë°˜ì§€ë„ í•™ìŠµì„ ê°œì„ í•˜ê¸° ìœ„í•´ Semi-MOEë¥¼ ì œì•ˆí•œë‹¤. ì´ëŠ” ë‹¤ì¤‘ ì „ë¬¸ê°€(Mixture-of-Experts) í”„ë ˆì„ì›Œí¬ë¡œ, ì£¼ìš” ë¶„í•  ì „ë¬¸ê°€, ë¶€í˜¸ ê±°ë¦¬ í•„ë“œ íšŒê·€ ì „ë¬¸ê°€, ê²½ê³„ ì˜ˆì¸¡ ì „ë¬¸ê°€ë¥¼ í™œìš©í•˜ì—¬ ê°ê° ë‹¤ë¥¸ í˜•íƒœí•™ì  íŠ¹ì§•ì„ ìº¡ì²˜í•œë‹¤. ë˜í•œ, Multi-Gating Pseudo-labeling ëª¨ë“ˆì„ í†µí•´ ì „ë¬¸ê°€ íŠ¹ì§•ì„ ë™ì ìœ¼ë¡œ ì§‘ê³„í•˜ì—¬ ê²¬ê³ í•œ ê°€ì§œ ë¼ë²¨ë§ ë©”ì»¤ë‹ˆì¦˜ì„ êµ¬í˜„í•œë‹¤. ë˜í•œ, ë‹¤ì¤‘ í•™ìŠµ ëª©í‘œë¥¼ ë™ì ìœ¼ë¡œ ê· í˜•ì¡ê¸° ìœ„í•´ ì ì‘í˜• ë‹¤ì¤‘ ëª©ì  ì†ì‹¤ì„ ì œì•ˆí•œë‹¤. GlaS ë° CRAG ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìˆ˜í–‰ëœ ì‹¤í—˜ ê²°ê³¼, ì €ë ˆì´ë¸” í™˜ê²½ì—ì„œ ìµœì‹  ê¸°ìˆ  ì ‘ê·¼ë²•ì„ ëŠ¥ê°€í•¨ì„ ë³´ì—¬ì£¼ë©°, MoE ê¸°ë°˜ ì•„í‚¤í…ì²˜ì˜ ì ì¬ë ¥ì„ ê°•ì¡°í•œë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸


- 1. ë³¸ ë…¼ë¬¸ì€ ë°˜ì§€ë„ í•™ìŠµì„ ì‚¬ìš©í•˜ì—¬ ì¡°ì§ë³‘ë¦¬ ì´ë¯¸ì§€ ë¶„í• ì— ìˆì–´ ë…¸ì´ì¦ˆê°€ ìˆëŠ” ê°€ì§œ ë¼ë²¨ì„ ì²˜ë¦¬í•˜ëŠ” Semi-MOEë¥¼ ì†Œê°œí•œë‹¤.

- 2. Semi-MOEëŠ” ì„¸ ê°€ì§€ ì „ë¬¸í™”ëœ ì „ë¬¸ ë„¤íŠ¸ì›Œí¬ë¥¼ í™œìš©í•˜ì—¬ ê°ê° ë‹¤ë¥¸ í˜•íƒœí•™ì  íŠ¹ì§•ì„ ìº¡ì²˜í•˜ëŠ”ë° ì „ë…í•œë‹¤.

- 3. Multi-Gating Pseudo-labeling ëª¨ë“ˆì€ ì „ë¬¸ íŠ¹ì§•ì„ ë™ì ìœ¼ë¡œ ì§‘ê³„í•˜ì—¬ ê²¬ê³ í•œ ê°€ì§œ ë¼ë²¨ë§ ë©”ì»¤ë‹ˆì¦˜ì„ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤.


---

*Generated on 2025-09-18 17:02:15*