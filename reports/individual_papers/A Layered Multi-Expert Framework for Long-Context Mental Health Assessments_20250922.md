# A Layered Multi-Expert Framework for Long-Context Mental Health Assessments

**Korean Title:** ì¥ê¸° ë¬¸ë§¥ ì •ì‹  ê±´ê°• í‰ê°€ë¥¼ ìœ„í•œ ê³„ì¸µí˜• ë‹¤ì¤‘ ì „ë¬¸ê°€ í”„ë ˆì„ì›Œí¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Layered Multi-Expert Framework

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Beyond Spurious Signals_ Debiasing Multimodal Large Language Models via Counterfactual Inference and Adaptive Expert Routing_20250922|Beyond Spurious Signals Debiasing Multimodal Large Language Models via Counterfactual Inference and Adaptive Expert Routing]] (84.9% similar)
- [[2025-09-22/Diagnostics of cognitive failures in multi-agent expert systems using dynamic evaluation protocols and subsequent mutation of the processing context_20250922|Diagnostics of cognitive failures in multi-agent expert systems using dynamic evaluation protocols and subsequent mutation of the processing context]] (83.4% similar)
- [[2025-09-17/DSCC-HS_ A Dynamic Self-Reinforcing Framework for Hallucination Suppression in Large Language Models_20250917|DSCC-HS A Dynamic Self-Reinforcing Framework for Hallucination Suppression in Large Language Models]] (83.2% similar)
- [[2025-09-19/Large Multi-modal Models Can Interpret Features in Large Multi-modal Models_20250919|Large Multi-modal Models Can Interpret Features in Large Multi-modal Models]] (83.1% similar)
- [[2025-09-19/A Multi-To-One Interview Paradigm for Efficient MLLM Evaluation_20250919|A Multi-To-One Interview Paradigm for Efficient MLLM Evaluation]] (83.1% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2501.13951v3 Announce Type: replace-cross 
Abstract: Long-form mental health assessments pose unique challenges for large language models (LLMs), which often exhibit hallucinations or inconsistent reasoning when handling extended, domain-specific contexts. We introduce Stacked Multi-Model Reasoning (SMMR), a layered framework that leverages multiple LLMs and specialized smaller models as coequal 'experts'. Early layers isolate short, discrete subtasks, while later layers integrate and refine these partial outputs through more advanced long-context models. We evaluate SMMR on the DAIC-WOZ depression-screening dataset and 48 curated case studies with psychiatric diagnoses, demonstrating consistent improvements over single-model baselines in terms of accuracy, F1-score, and PHQ-8 error reduction. By harnessing diverse 'second opinions', SMMR mitigates hallucinations, captures subtle clinical nuances, and enhances reliability in high-stakes mental health assessments. Our findings underscore the value of multi-expert frameworks for more trustworthy AI-driven screening.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2501.13951v3 ë°œí‘œ ìœ í˜•: êµì°¨ ëŒ€ì²´  
ì´ˆë¡: ì¥ë¬¸ì˜ ì •ì‹  ê±´ê°• í‰ê°€ì—ì„œëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì´ ë…íŠ¹í•œ ë„ì „ì— ì§ë©´í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ëª¨ë¸ì€ ì¢…ì¢… í™•ì¥ëœ ë„ë©”ì¸ íŠ¹í™” ë¬¸ë§¥ì„ ì²˜ë¦¬í•  ë•Œ í™˜ê°ì´ë‚˜ ì¼ê´€ì„± ì—†ëŠ” ì¶”ë¡ ì„ ë³´ì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì—¬ëŸ¬ LLMê³¼ íŠ¹í™”ëœ ì†Œí˜• ëª¨ë¸ì„ ë™ë“±í•œ 'ì „ë¬¸ê°€'ë¡œ í™œìš©í•˜ëŠ” ê³„ì¸µì  í”„ë ˆì„ì›Œí¬ì¸ Stacked Multi-Model Reasoning (SMMR)ì„ ì†Œê°œí•©ë‹ˆë‹¤. ì´ˆê¸° ê³„ì¸µì—ì„œëŠ” ì§§ê³  ê°œë³„ì ì¸ í•˜ìœ„ ì‘ì—…ì„ ë¶„ë¦¬í•˜ê³ , ì´í›„ ê³„ì¸µì—ì„œëŠ” ì´ëŸ¬í•œ ë¶€ë¶„ ì¶œë ¥ì„ ë” ë°œì „ëœ ì¥ë¬¸ë§¥ ëª¨ë¸ì„ í†µí•´ í†µí•©í•˜ê³  ì •ì œí•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” DAIC-WOZ ìš°ìš¸ì¦ ì„ ë³„ ë°ì´í„°ì…‹ê³¼ ì •ì‹ ê³¼ ì§„ë‹¨ì´ í¬í•¨ëœ 48ê°œì˜ íë ˆì´ì…˜ëœ ì‚¬ë¡€ ì—°êµ¬ì—ì„œ SMMRì„ í‰ê°€í•˜ì—¬, ì •í™•ë„, F1 ì ìˆ˜ ë° PHQ-8 ì˜¤ë¥˜ ê°ì†Œ ì¸¡ë©´ì—ì„œ ë‹¨ì¼ ëª¨ë¸ ê¸°ì¤€ì„ ì„ ì¼ê´€ë˜ê²Œ ê°œì„ í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë‹¤ì–‘í•œ 'ì œ2ì˜ ì˜ê²¬'ì„ í™œìš©í•¨ìœ¼ë¡œì¨, SMMRì€ í™˜ê°ì„ ì™„í™”í•˜ê³  ë¯¸ë¬˜í•œ ì„ìƒì  ë‰˜ì•™ìŠ¤ë¥¼ í¬ì°©í•˜ë©°, ê³ ìœ„í—˜ ì •ì‹  ê±´ê°• í‰ê°€ì—ì„œì˜ ì‹ ë¢°ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ìš°ë¦¬ì˜ ì—°êµ¬ ê²°ê³¼ëŠ” ë³´ë‹¤ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” AI ê¸°ë°˜ ì„ ë³„ì„ ìœ„í•œ ë‹¤ì¤‘ ì „ë¬¸ê°€ í”„ë ˆì„ì›Œí¬ì˜ ê°€ì¹˜ë¥¼ ê°•ì¡°í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì¥ë¬¸ì˜ ì •ì‹  ê±´ê°• í‰ê°€ì—ì„œ ë°œìƒí•˜ëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ Stacked Multi-Model Reasoning(SMMR)ì´ë¼ëŠ” í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. SMMRì€ ì—¬ëŸ¬ LLMê³¼ ì „ë¬¸í™”ëœ ì†Œí˜• ëª¨ë¸ì„ 'ì „ë¬¸ê°€'ë¡œ í™œìš©í•˜ì—¬ ì´ˆê¸° ë‹¨ê³„ì—ì„œ ì§§ê³  ê°œë³„ì ì¸ í•˜ìœ„ ì‘ì—…ì„ ë¶„ë¦¬í•˜ê³ , ì´í›„ ë‹¨ê³„ì—ì„œ ì´ë¥¼ í†µí•© ë° ê°œì„ í•©ë‹ˆë‹¤. DAIC-WOZ ìš°ìš¸ì¦ ìŠ¤í¬ë¦¬ë‹ ë°ì´í„°ì…‹ê³¼ 48ê°œì˜ ì •ì‹ ê³¼ ì§„ë‹¨ ì‚¬ë¡€ ì—°êµ¬ë¥¼ í†µí•´ SMMRì´ ë‹¨ì¼ ëª¨ë¸ ê¸°ë°˜ë³´ë‹¤ ì •í™•ë„, F1-ì ìˆ˜, PHQ-8 ì˜¤ë¥˜ ê°ì†Œì—ì„œ ì¼ê´€ëœ ê°œì„ ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë‹¤ì–‘í•œ 'ì œ2ì˜ ì˜ê²¬'ì„ í™œìš©í•˜ì—¬ í™˜ê°ì„ ì¤„ì´ê³ , ì„ìƒì  ë¯¸ë¬˜í•¨ì„ í¬ì°©í•˜ë©°, ì‹ ë¢°ì„±ì„ ë†’ì…ë‹ˆë‹¤. ì—°êµ¬ ê²°ê³¼ëŠ” ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” AI ê¸°ë°˜ ìŠ¤í¬ë¦¬ë‹ì„ ìœ„í•œ ë‹¤ì¤‘ ì „ë¬¸ê°€ í”„ë ˆì„ì›Œí¬ì˜ ê°€ì¹˜ë¥¼ ê°•ì¡°í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Stacked Multi-Model Reasoning (SMMR)ì€ ì—¬ëŸ¬ LLMê³¼ ì „ë¬¸í™”ëœ ì†Œí˜• ëª¨ë¸ì„ ë™ë“±í•œ 'ì „ë¬¸ê°€'ë¡œ í™œìš©í•˜ëŠ” ê³„ì¸µì  í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.

- 2. SMMRì€ ì´ˆê¸° ê³„ì¸µì—ì„œ ì§§ê³  ê°œë³„ì ì¸ í•˜ìœ„ ì‘ì—…ì„ ë¶„ë¦¬í•˜ê³ , ì´í›„ ê³„ì¸µì—ì„œ ì´ë¥¼ í†µí•© ë° ì •ì œí•˜ì—¬ ê¸´ ë¬¸ë§¥ì„ ì²˜ë¦¬í•˜ëŠ” ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

- 3. DAIC-WOZ ìš°ìš¸ì¦ ìŠ¤í¬ë¦¬ë‹ ë°ì´í„°ì…‹ê³¼ 48ê°œì˜ ì •ì‹ ê³¼ ì§„ë‹¨ ì‚¬ë¡€ ì—°êµ¬ì—ì„œ SMMRì€ ë‹¨ì¼ ëª¨ë¸ ê¸°ì¤€ë³´ë‹¤ ì •í™•ë„, F1-ì ìˆ˜, PHQ-8 ì˜¤ë¥˜ ê°ì†Œ ì¸¡ë©´ì—ì„œ ì¼ê´€ëœ ê°œì„ ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

- 4. ë‹¤ì–‘í•œ 'ë‘ ë²ˆì§¸ ì˜ê²¬'ì„ í™œìš©í•˜ì—¬ SMMRì€ í™˜ê°ì„ ì¤„ì´ê³ , ë¯¸ì„¸í•œ ì„ìƒì  ë‰˜ì•™ìŠ¤ë¥¼ í¬ì°©í•˜ë©°, ê³ ìœ„í—˜ ì •ì‹  ê±´ê°• í‰ê°€ì—ì„œ ì‹ ë¢°ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

- 5. ì—°êµ¬ ê²°ê³¼ëŠ” ë‹¤ì¤‘ ì „ë¬¸ê°€ í”„ë ˆì„ì›Œí¬ê°€ AI ê¸°ë°˜ ìŠ¤í¬ë¦¬ë‹ì˜ ì‹ ë¢°ì„±ì„ ë†’ì´ëŠ” ë° ê°€ì¹˜ê°€ ìˆìŒì„ ê°•ì¡°í•©ë‹ˆë‹¤.

---

*Generated on 2025-09-22 14:41:26*