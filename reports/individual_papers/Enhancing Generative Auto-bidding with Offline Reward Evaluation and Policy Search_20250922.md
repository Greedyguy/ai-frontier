# Enhancing Generative Auto-bidding with Offline Reward Evaluation and Policy Search

**Korean Title:** ìƒì„±ì  ìë™ ì…ì°°ì˜ í–¥ìƒì„ ìœ„í•œ ì˜¤í”„ë¼ì¸ ë³´ìƒ í‰ê°€ ë° ì •ì±… íƒìƒ‰

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Generative Planning with Policy Optimization

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/JU-NLP at Touch'e_ Covert Advertisement in Conversational AI-Generation and Detection Strategies_20250919|JU-NLP at Touch'e Covert Advertisement in Conversational AI-Generation and Detection Strategies]] (83.2% similar)
- [[2025-09-19/Optimal Type-Dependent Liquid Welfare Guarantees for Autobidding Agents with Budgets_20250919|Optimal Type-Dependent Liquid Welfare Guarantees for Autobidding Agents with Budgets]] (82.3% similar)
- [[2025-09-18/TGPO_ Tree-Guided Preference Optimization for Robust Web Agent Reinforcement Learning_20250918|TGPO Tree-Guided Preference Optimization for Robust Web Agent Reinforcement Learning]] (81.5% similar)
- [[2025-09-17/TGPO_ Tree-Guided Preference Optimization for Robust Web Agent Reinforcement Learning_20250917|TGPO Tree-Guided Preference Optimization for Robust Web Agent Reinforcement Learning]] (81.4% similar)
- [[2025-09-19/Multi-Fidelity Hybrid Reinforcement Learning via Information Gain Maximization_20250919|Multi-Fidelity Hybrid Reinforcement Learning via Information Gain Maximization]] (80.7% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15927v1 Announce Type: cross 
Abstract: Auto-bidding is an essential tool for advertisers to enhance their advertising performance. Recent progress has shown that AI-Generated Bidding (AIGB), which formulates the auto-bidding as a trajectory generation task and trains a conditional diffusion-based planner on offline data, achieves superior and stable performance compared to typical offline reinforcement learning (RL)-based auto-bidding methods. However, existing AIGB methods still encounter a performance bottleneck due to their neglect of fine-grained generation quality evaluation and inability to explore beyond static datasets. To address this, we propose AIGB-Pearl (\emph{Planning with EvAluator via RL}), a novel method that integrates generative planning and policy optimization. The key to AIGB-Pearl is to construct a non-bootstrapped \emph{trajectory evaluator} to assign rewards and guide policy search, enabling the planner to optimize its generation quality iteratively through interaction. Furthermore, to enhance trajectory evaluator accuracy in offline settings, we incorporate three key techniques: (i) a Large Language Model (LLM)-based architecture for better representational capacity, (ii) hybrid point-wise and pair-wise losses for better score learning, and (iii) adaptive integration of expert feedback for better generalization ability. Extensive experiments on both simulated and real-world advertising systems demonstrate the state-of-the-art performance of our approach.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15927v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ìë™ ì…ì°°ì€ ê´‘ê³ ì£¼ê°€ ê´‘ê³  ì„±ê³¼ë¥¼ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ í•„ìˆ˜ ë„êµ¬ì…ë‹ˆë‹¤. ìµœê·¼ì˜ ë°œì „ì€ AI ìƒì„± ì…ì°°(AIGB)ì´ ìë™ ì…ì°°ì„ ê¶¤ì  ìƒì„± ì‘ì—…ìœ¼ë¡œ ê³µì‹í™”í•˜ê³  ì˜¤í”„ë¼ì¸ ë°ì´í„°ì—ì„œ ì¡°ê±´ë¶€ í™•ì‚° ê¸°ë°˜ ê³„íšìë¥¼ í›ˆë ¨í•˜ì—¬ ì „í˜•ì ì¸ ì˜¤í”„ë¼ì¸ ê°•í™” í•™ìŠµ(RL) ê¸°ë°˜ ìë™ ì…ì°° ë°©ë²•ì— ë¹„í•´ ìš°ìˆ˜í•˜ê³  ì•ˆì •ì ì¸ ì„±ëŠ¥ì„ ë‹¬ì„±í•œë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê¸°ì¡´ì˜ AIGB ë°©ë²•ì€ ì„¸ë°€í•œ ìƒì„± í’ˆì§ˆ í‰ê°€ë¥¼ ë¬´ì‹œí•˜ê³  ì •ì  ë°ì´í„°ì…‹ì„ ë„˜ì–´ íƒìƒ‰í•  ìˆ˜ ì—†ê¸° ë•Œë¬¸ì— ì—¬ì „íˆ ì„±ëŠ¥ ë³‘ëª© í˜„ìƒì„ ê²ªê³  ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ìš°ë¦¬ëŠ” ìƒì„± ê³„íšê³¼ ì •ì±… ìµœì í™”ë¥¼ í†µí•©í•œ ìƒˆë¡œìš´ ë°©ë²•ì¸ AIGB-Pearl(\emph{Planning with EvAluator via RL})ì„ ì œì•ˆí•©ë‹ˆë‹¤. AIGB-Pearlì˜ í•µì‹¬ì€ ë¹„ë¶€íŠ¸ìŠ¤íŠ¸ë© \emph{ê¶¤ì  í‰ê°€ì}ë¥¼ êµ¬ì„±í•˜ì—¬ ë³´ìƒì„ í• ë‹¹í•˜ê³  ì •ì±… íƒìƒ‰ì„ ì•ˆë‚´í•¨ìœ¼ë¡œì¨ ê³„íšìê°€ ìƒí˜¸ì‘ìš©ì„ í†µí•´ ìƒì„± í’ˆì§ˆì„ ë°˜ë³µì ìœ¼ë¡œ ìµœì í™”í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ë”ìš±ì´, ì˜¤í”„ë¼ì¸ í™˜ê²½ì—ì„œ ê¶¤ì  í‰ê°€ìì˜ ì •í™•ì„±ì„ ë†’ì´ê¸° ìœ„í•´ ìš°ë¦¬ëŠ” ì„¸ ê°€ì§€ ì£¼ìš” ê¸°ìˆ ì„ í†µí•©í•©ë‹ˆë‹¤: (i) ë” ë‚˜ì€ í‘œí˜„ ëŠ¥ë ¥ì„ ìœ„í•œ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM) ê¸°ë°˜ ì•„í‚¤í…ì²˜, (ii) ë” ë‚˜ì€ ì ìˆ˜ í•™ìŠµì„ ìœ„í•œ í•˜ì´ë¸Œë¦¬ë“œ ì  ë‹¨ìœ„ ë° ìŒ ë‹¨ìœ„ ì†ì‹¤, (iii) ë” ë‚˜ì€ ì¼ë°˜í™” ëŠ¥ë ¥ì„ ìœ„í•œ ì „ë¬¸ê°€ í”¼ë“œë°±ì˜ ì ì‘ì  í†µí•©. ì‹œë®¬ë ˆì´ì…˜ ë° ì‹¤ì œ ê´‘ê³  ì‹œìŠ¤í…œ ëª¨ë‘ì—ì„œì˜ ê´‘ë²”ìœ„í•œ ì‹¤í—˜ì€ ìš°ë¦¬ ì ‘ê·¼ ë°©ì‹ì˜ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ê´‘ê³  ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ìë™ ì…ì°° ë„êµ¬ì¸ AI-ìƒì„± ì…ì°°(AIGB)ì˜ ì„±ëŠ¥ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ AIGB-Pearlì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ AIGBëŠ” ì£¼ë¡œ ì˜¤í”„ë¼ì¸ ê°•í™” í•™ìŠµ ê¸°ë°˜ìœ¼ë¡œ ì‘ë™í•˜ì§€ë§Œ, ì„¸ë°€í•œ ìƒì„± í’ˆì§ˆ í‰ê°€ì™€ ì •ì  ë°ì´í„°ì…‹ì„ ë„˜ì–´ì„  íƒìƒ‰ì— í•œê³„ê°€ ìˆì—ˆìŠµë‹ˆë‹¤. AIGB-Pearlì€ ìƒì„± ê³„íšê³¼ ì •ì±… ìµœì í™”ë¥¼ í†µí•©í•˜ì—¬ ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤. íŠ¹íˆ, ë¹„ë¶€íŠ¸ìŠ¤íŠ¸ë© ë°©ì‹ì˜ ê²½ë¡œ í‰ê°€ìë¥¼ ë„ì…í•˜ì—¬ ë³´ìƒì„ í• ë‹¹í•˜ê³  ì •ì±… íƒìƒ‰ì„ ì•ˆë‚´í•¨ìœ¼ë¡œì¨ ìƒì„± í’ˆì§ˆì„ ë°˜ë³µì ìœ¼ë¡œ ìµœì í™”í•©ë‹ˆë‹¤. ë˜í•œ, ì˜¤í”„ë¼ì¸ í™˜ê²½ì—ì„œì˜ ì •í™•ì„±ì„ ë†’ì´ê¸° ìœ„í•´ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM) ê¸°ë°˜ ì•„í‚¤í…ì²˜, í˜¼í•© ì†ì‹¤ í•¨ìˆ˜, ì „ë¬¸ê°€ í”¼ë“œë°±ì˜ ì ì‘ì  í†µí•©ì„ í™œìš©í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì´ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë³´ì„ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. AIGB-Pearlì€ ìƒì„±ì  ê³„íšê³¼ ì •ì±… ìµœì í™”ë¥¼ í†µí•©í•˜ì—¬ ê´‘ê³  ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ìƒˆë¡œìš´ ë°©ë²•ì…ë‹ˆë‹¤.

- 2. ë¹„ë¶€íŠ¸ìŠ¤íŠ¸ë© ë°©ì‹ì˜ ê²½ë¡œ í‰ê°€ìë¥¼ êµ¬ì¶•í•˜ì—¬ ë³´ìƒì„ í• ë‹¹í•˜ê³  ì •ì±… íƒìƒ‰ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.

- 3. ì˜¤í”„ë¼ì¸ í™˜ê²½ì—ì„œ ê²½ë¡œ í‰ê°€ìì˜ ì •í™•ì„±ì„ ë†’ì´ê¸° ìœ„í•´ LLM ê¸°ë°˜ ì•„í‚¤í…ì²˜, í˜¼í•© ì†ì‹¤, ì „ë¬¸ê°€ í”¼ë“œë°±ì˜ ì ì‘ì  í†µí•©ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

- 4. ì‹œë®¬ë ˆì´ì…˜ ë° ì‹¤ì œ ê´‘ê³  ì‹œìŠ¤í…œ ì‹¤í—˜ì—ì„œ AIGB-Pearlì˜ ìµœì²¨ë‹¨ ì„±ëŠ¥ì´ ì…ì¦ë˜ì—ˆìŠµë‹ˆë‹¤.

---

*Generated on 2025-09-22 14:17:23*