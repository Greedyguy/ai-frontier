# Optimizing Product Deduplication in E-Commerce with Multimodal Embeddings

**Korean Title:** ì „ì ìƒê±°ë˜ì—ì„œ ë‹¤ì¤‘ ëª¨ë‹¬ ì„ë² ë”©ì„ í™œìš©í•œ ì œí’ˆ ì¤‘ë³µ ì œê±° ìµœì í™”

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[reports/digests/daily_digest_20250922|2025-09-22]] [[keywords/specific/Multimodal Embeddings|Multimodal Embeddings]] [[keywords/specific/Dimensionality Reduction|Dimensionality Reduction]] [[keywords/broad/Natural Language Processing|Natural Language Processing]] [[keywords/broad/Computer Vision|Computer Vision]] [[keywords/unique/MaskedAutoEncoders|MaskedAutoEncoders]] [[categories/cs.LG|cs.LG]] [[2025-09-18/RoboEye_ Enhancing 2D Robotic Object Identification with Selective 3D Geometric Keypoint Matching_20250918|RoboEye: Enhancing 2D Robotic Object Identification with Selective 3D Geometric Keypoint Matching]] (82.1% similar) [[2025-09-19/PRISM_ Product Retrieval In Shopping Carts using Hybrid Matching_20250919|PRISM: Product Retrieval In Shopping Carts using Hybrid Matching]] (82.0% similar) [[2025-09-22/Efficient Extractive Text Summarization for Online News Articles Using Machine Learning_20250922|Efficient Extractive Text Summarization for Online News Articles Using Machine Learning]] (79.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: Multimodal Embeddings, Dimensionality Reduction
**ğŸ”¬ Broad Technical**: Natural Language Processing, Computer Vision
**â­ Unique Technical**: MaskedAutoEncoders
## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/RoboEye_ Enhancing 2D Robotic Object Identification with Selective 3D Geometric Keypoint Matching_20250918|RoboEye Enhancing 2D Robotic Object Identification with Selective 3D Geometric Keypoint Matching]] (82.1% similar)
- [[2025-09-19/PRISM_ Product Retrieval In Shopping Carts using Hybrid Matching_20250919|PRISM Product Retrieval In Shopping Carts using Hybrid Matching]] (82.0% similar)
- [[2025-09-22/Efficient Extractive Text Summarization for Online News Articles Using Machine Learning_20250922|Efficient Extractive Text Summarization for Online News Articles Using Machine Learning]] (79.3% similar)
- [[2025-09-19/What's the Best Way to Retrieve Slides A Comparative Study of Multimodal, Caption-Based, and Hybrid Retrieval Techniques_20250919|What's the Best Way to Retrieve Slides A Comparative Study of Multimodal, Caption-Based, and Hybrid Retrieval Techniques]] (79.2% similar)
- [[2025-09-22/Relevance to Utility_ Process-Supervised Rewrite for RAG_20250922|Relevance to Utility Process-Supervised Rewrite for RAG]] (79.1% similar)


**ArXiv ID**: [2509.15858](https://arxiv.org/abs/2509.15858)
**Published**: 2025-09-22
**Category**: cs.LG
**PDF**: [Download](https://arxiv.org/pdf/2509.15858.pdf)


**ArXiv ID**: [2509.15858](https://arxiv.org/abs/2509.15858)
**Published**: 2025-09-22
**Category**: cs.LG
**PDF**: [Download](https://arxiv.org/pdf/2509.15858.pdf)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: Multimodal Embeddings, Dimensionality Reduction
**â­ Unique Technical**: MaskedAutoEncoders
**ğŸ”¬ Broad Technical**: Natural Language Processing, Computer Vision

## ğŸ·ï¸ ì¶”ì¶œëœ í‚¤ì›Œë“œ



`Natural Language Processing` â€¢ 

`Computer Vision` â€¢ 

`Multimodal Embeddings` â€¢ 

`Dimensionality Reduction` â€¢ 

`MaskedAutoEncoders`



## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸

Similar papers will be displayed here based on embedding similarity.

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15858v1 Announce Type: cross 
Abstract: In large scale e-commerce marketplaces, duplicate product listings frequently cause consumer confusion and operational inefficiencies, degrading trust on the platform and increasing costs. Traditional keyword-based search methodologies falter in accurately identifying duplicates due to their reliance on exact textual matches, neglecting semantic similarities inherent in product titles. To address these challenges, we introduce a scalable, multimodal product deduplication designed specifically for the e-commerce domain. Our approach employs a domain-specific text model grounded in BERT architecture in conjunction with MaskedAutoEncoders for image representations. Both of these architectures are augmented with dimensionality reduction techniques to produce compact 128-dimensional embeddings without significant information loss. Complementing this, we also developed a novel decider model that leverages both text and image vectors. By integrating these feature extraction mechanisms with Milvus, an optimized vector database, our system can facilitate efficient and high-precision similarity searches across extensive product catalogs exceeding 200 million items with just 100GB of system RAM consumption. Empirical evaluations demonstrate that our matching system achieves a macro-average F1 score of 0.90, outperforming third-party solutions which attain an F1 score of 0.83. Our findings show the potential of combining domain-specific adaptations with state-of-the-art machine learning techniques to mitigate duplicate listings in large-scale e-commerce environments.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15858v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ëŒ€ê·œëª¨ ì „ììƒê±°ë˜ ë§ˆì¼“í”Œë ˆì´ìŠ¤ì—ì„œëŠ” ì¤‘ë³µëœ ìƒí’ˆ ëª©ë¡ì´ ì†Œë¹„ìì—ê²Œ í˜¼ë€ì„ ì£¼ê³  ìš´ì˜ìƒì˜ ë¹„íš¨ìœ¨ì„±ì„ ì´ˆë˜í•˜ì—¬ í”Œë«í¼ì— ëŒ€í•œ ì‹ ë¢°ë¥¼ ì €í•˜ì‹œí‚´ê³¼ ë™ì‹œì— ë¹„ìš©ì„ ì¦ê°€ì‹œí‚µë‹ˆë‹¤. ì „í†µì ì¸ í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ ë°©ë²•ë¡ ì€ ì •í™•í•œ í…ìŠ¤íŠ¸ ì¼ì¹˜ì— ì˜ì¡´í•˜ì—¬ ì œí’ˆ ì œëª©ì— ë‚´ì¬ëœ ì˜ë¯¸ì  ìœ ì‚¬ì„±ì„ ê°„ê³¼í•¨ìœ¼ë¡œì¨ ì¤‘ë³µì„ ì •í™•í•˜ê²Œ ì‹ë³„í•˜ëŠ” ë° ì‹¤íŒ¨í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ì „ììƒê±°ë˜ ë„ë©”ì¸ì— íŠ¹í™”ëœ í™•ì¥ ê°€ëŠ¥í•œ ë©€í‹°ëª¨ë‹¬ ì œí’ˆ ì¤‘ë³µ ì œê±° ë°©ë²•ì„ ì†Œê°œí•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì ‘ê·¼ ë°©ì‹ì€ BERT ì•„í‚¤í…ì²˜ì— ê¸°ë°˜í•œ ë„ë©”ì¸ íŠ¹í™” í…ìŠ¤íŠ¸ ëª¨ë¸ê³¼ ì´ë¯¸ì§€ í‘œí˜„ì„ ìœ„í•œ MaskedAutoEncodersë¥¼ ê²°í•©í•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ ë‘ ì•„í‚¤í…ì²˜ ëª¨ë‘ ì°¨ì› ì¶•ì†Œ ê¸°ë²•ìœ¼ë¡œ ë³´ê°•ë˜ì–´ ì •ë³´ ì†ì‹¤ ì—†ì´ 128ì°¨ì›ì˜ ì»´íŒ©íŠ¸í•œ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤. ì´ë¥¼ ë³´ì™„í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ ë²¡í„°ë¥¼ ëª¨ë‘ í™œìš©í•˜ëŠ” ìƒˆë¡œìš´ ê²°ì • ëª¨ë¸ë„ ê°œë°œí–ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ íŠ¹ì§• ì¶”ì¶œ ë©”ì»¤ë‹ˆì¦˜ì„ ìµœì í™”ëœ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì¸ Milvusì™€ í†µí•©í•¨ìœ¼ë¡œì¨, ìš°ë¦¬ì˜ ì‹œìŠ¤í…œì€ 2ì–µ ê°œ ì´ìƒì˜ ìƒí’ˆ ì¹´íƒˆë¡œê·¸ì— ëŒ€í•´ 100GBì˜ ì‹œìŠ¤í…œ RAMë§Œìœ¼ë¡œë„ íš¨ìœ¨ì ì´ê³  ë†’ì€ ì •ë°€ë„ì˜ ìœ ì‚¬ì„± ê²€ìƒ‰ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹¤ì¦ì  í‰ê°€ ê²°ê³¼, ìš°ë¦¬ì˜ ë§¤ì¹­ ì‹œìŠ¤í…œì€ ë§¤í¬ë¡œ í‰ê·  F1 ì ìˆ˜ 0.90ì„ ë‹¬ì„±í•˜ì—¬ F1 ì ìˆ˜ 0.83ì„ ê¸°ë¡í•œ íƒ€ì‚¬ ì†”ë£¨ì…˜ì„ ëŠ¥ê°€í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì—°êµ¬ ê²°ê³¼ëŠ” ëŒ€ê·œëª¨ ì „ììƒê±°ë˜ í™˜ê²½ì—ì„œ ì¤‘ë³µ ëª©ë¡ì„ ì™„í™”í•˜ê¸° ìœ„í•´ ë„ë©”ì¸ íŠ¹í™” ì ì‘ê³¼ ìµœì²¨ë‹¨ ê¸°ê³„ í•™ìŠµ ê¸°ë²•ì„ ê²°í•©í•  ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€ê·œëª¨ ì „ììƒê±°ë˜ í”Œë«í¼ì—ì„œ ì¤‘ë³µ ìƒí’ˆ ëª©ë¡ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ í™•ì¥ ê°€ëŠ¥í•œ ë©€í‹°ëª¨ë‹¬ ì¤‘ë³µ ì œê±° ì‹œìŠ¤í…œì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ ë°©ë²•ì€ ì •í™•í•œ í…ìŠ¤íŠ¸ ì¼ì¹˜ì— ì˜ì¡´í•˜ì—¬ ì¤‘ë³µ ì‹ë³„ì— í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ BERT ê¸°ë°˜ì˜ ë„ë©”ì¸ íŠ¹í™” í…ìŠ¤íŠ¸ ëª¨ë¸ê³¼ ì´ë¯¸ì§€ í‘œí˜„ì„ ìœ„í•œ MaskedAutoEncodersë¥¼ ì‚¬ìš©í•˜ì—¬ 128ì°¨ì› ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œì€ Milvus ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì™€ ê²°í•©í•˜ì—¬ 2ì–µ ê°œ ì´ìƒì˜ ìƒí’ˆ ëª©ë¡ì—ì„œ íš¨ìœ¨ì ì´ê³  ì •ë°€í•œ ìœ ì‚¬ì„± ê²€ìƒ‰ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ë©°, 100GBì˜ RAMë§Œìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ì‹œìŠ¤í…œì€ F1 ì ìˆ˜ 0.90ì„ ê¸°ë¡í•˜ë©°, ê¸°ì¡´ ì†”ë£¨ì…˜ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ë„ë©”ì¸ íŠ¹í™” ì ì‘ê³¼ ìµœì‹  ê¸°ê³„ í•™ìŠµ ê¸°ë²•ì˜ ê²°í•©ì´ ëŒ€ê·œëª¨ ì „ììƒê±°ë˜ í™˜ê²½ì—ì„œ ì¤‘ë³µ ëª©ë¡ ë¬¸ì œë¥¼ ì™„í™”í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸


- 1. ëŒ€ê·œëª¨ ì „ììƒê±°ë˜ ì‹œì¥ì—ì„œ ì¤‘ë³µ ìƒí’ˆ ë“±ë¡ì€ ì†Œë¹„ì í˜¼ë€ê³¼ ìš´ì˜ ë¹„íš¨ìœ¨ì„±ì„ ì´ˆë˜í•˜ë©°, í”Œë«í¼ ì‹ ë¢°ë„ë¥¼ ì €í•˜ì‹œí‚¨ë‹¤.

- 2. ê¸°ì¡´ì˜ í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ ë°©ë²•ì€ ì •í™•í•œ í…ìŠ¤íŠ¸ ì¼ì¹˜ì— ì˜ì¡´í•˜ì—¬ ì¤‘ë³µ ìƒí’ˆ ì‹ë³„ì— í•œê³„ë¥¼ ë³´ì¸ë‹¤.

- 3. ë³¸ ì—°êµ¬ëŠ” BERT ì•„í‚¤í…ì²˜ ê¸°ë°˜ì˜ í…ìŠ¤íŠ¸ ëª¨ë¸ê³¼ MaskedAutoEncodersë¥¼ í™œìš©í•œ ì´ë¯¸ì§€ í‘œí˜„ì„ ê²°í•©í•œ í™•ì¥ ê°€ëŠ¥í•œ ë‹¤ì¤‘ ëª¨ë‹¬ ìƒí’ˆ ì¤‘ë³µ ì œê±° ë°©ë²•ì„ ì œì•ˆí•œë‹¤.

- 4. ì œì•ˆëœ ì‹œìŠ¤í…œì€ 200ë°±ë§Œ ê°œ ì´ìƒì˜ ìƒí’ˆ ëª©ë¡ì—ì„œ íš¨ìœ¨ì ì´ê³  ë†’ì€ ì •ë°€ë„ì˜ ìœ ì‚¬ì„± ê²€ìƒ‰ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ë©°, 100GBì˜ ì‹œìŠ¤í…œ RAMë§Œì„ ì†Œë¹„í•œë‹¤.

- 5. ì œì•ˆëœ ë§¤ì¹­ ì‹œìŠ¤í…œì€ ë§¤í¬ë¡œ í‰ê·  F1 ì ìˆ˜ 0.90ì„ ë‹¬ì„±í•˜ì—¬, F1 ì ìˆ˜ 0.83ì„ ê¸°ë¡í•œ íƒ€ì‚¬ ì†”ë£¨ì…˜ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤.


---

*Generated on 2025-09-22 15:43:33*