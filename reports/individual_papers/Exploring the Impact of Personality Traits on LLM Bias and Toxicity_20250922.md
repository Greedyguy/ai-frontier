# Exploring the Impact of Personality Traits on LLM Bias and Toxicity

**Korean Title:** μ„±κ²© νΉμ„±μ΄ λ€ν• μ–Έμ–΄ λ¨λΈμ νΈν–¥μ„±κ³Ό μ ν•΄μ„±μ— λ―ΈμΉλ” μν–¥ νƒκµ¬

## π“‹ λ©”νƒ€λ°μ΄ν„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## π·οΈ μΉ΄ν…κ³ λ¦¬ν™”λ ν‚¤μ›λ“
**π€ Evolved Concepts**: Personality-based Text Generation

## π”— μ μ‚¬ν• λ…Όλ¬Έ
- [[2025-09-18/Do LLMs Align Human Values Regarding Social Biases Judging and Explaining Social Biases with LLMs_20250918|Do LLMs Align Human Values Regarding Social Biases Judging and Explaining Social Biases with LLMs]] (86.5% similar)
- [[2025-09-17/Simulating a Bias Mitigation Scenario in Large Language Models_20250917|Simulating a Bias Mitigation Scenario in Large Language Models]] (86.4% similar)
- [[2025-09-19/Adding LLMs to the psycholinguistic norming toolbox_ A practical guide to getting the most out of human ratings_20250919|Adding LLMs to the psycholinguistic norming toolbox A practical guide to getting the most out of human ratings]] (85.3% similar)
- [[2025-09-18/Catch Me If You Can Not Yet_ LLMs Still Struggle to Imitate the Implicit Writing Styles of Everyday Authors_20250918|Catch Me If You Can Not Yet LLMs Still Struggle to Imitate the Implicit Writing Styles of Everyday Authors]] (84.1% similar)
- [[2025-09-18/How Does Cognitive Bias Affect Large Language Models A Case Study on the Anchoring Effect in Price Negotiation Simulations_20250918|How Does Cognitive Bias Affect Large Language Models A Case Study on the Anchoring Effect in Price Negotiation Simulations]] (83.9% similar)

## π“‹ μ €μ μ •λ³΄

**Authors:** 

## π“„ Abstract (μ›λ¬Έ)

arXiv:2502.12566v3 Announce Type: replace 
Abstract: With the different roles that AI is expected to play in human life, imbuing large language models (LLMs) with different personalities has attracted increasing research interests. While the "personification" enhances human experiences of interactivity and adaptability of LLMs, it gives rise to critical concerns about content safety, particularly regarding bias, sentiment and toxicity of LLM generation. This study explores how assigning different personality traits to LLMs affects the toxicity and biases of their outputs. Leveraging the widely accepted HEXACO personality framework developed in social psychology, we design experimentally sound prompts to test three LLMs' performance on three toxic and bias benchmarks. The findings demonstrate the sensitivity of all three models to HEXACO personality traits and, more importantly, a consistent variation in the biases, negative sentiment and toxicity of their output. In particular, adjusting the levels of several personality traits can effectively reduce bias and toxicity in model performance, similar to humans' correlations between personality traits and toxic behaviors. The findings highlight the additional need to examine content safety besides the efficiency of training or fine-tuning methods for LLM personification. They also suggest a potential for the adjustment of personalities to be a simple and low-cost method to conduct controlled text generation.

## π” Abstract (ν•κΈ€ λ²μ—­)

arXiv:2502.12566v3 λ°ν‘ μ ν•: κµμ²΄  
μ΄λ΅: μΈκ³µμ§€λ¥(AI)μ΄ μΈκ°„ μƒν™μ—μ„ λ‹¤μ–‘ν• μ—­ν• μ„ μν–‰ν•  κ²ƒμΌλ΅ κΈ°λ€λ¨μ— λ”°λΌ λ€ν• μ–Έμ–΄ λ¨λΈ(LLM)μ— λ‹¤μ–‘ν• μ„±κ²©μ„ λ¶€μ—¬ν•λ” κ²ƒμ΄ μ μ  λ” λ§μ€ μ—°κµ¬ κ΄€μ‹¬μ„ λκ³  μμµλ‹λ‹¤. "μΈκ²©ν™”"λ” LLMμ μƒνΈμ‘μ©μ„±κ³Ό μ μ‘μ„±μ„ ν–¥μƒμ‹ν‚¤μ§€λ§, LLM μƒμ„±μ νΈν–¥, κ°μ • λ° μ ν•΄μ„±μ— λ€ν• λ‚΄μ© μ•μ „μ„±μ— λ€ν• μ¤‘μ”ν• μ°λ ¤λ¥Ό λ¶λ¬μΌμΌν‚µλ‹λ‹¤. λ³Έ μ—°κµ¬λ” LLMμ— λ‹¤λ¥Έ μ„±κ²© νΉμ„±μ„ λ¶€μ—¬ν•λ” κ²ƒμ΄ κ·Έλ“¤μ μ¶λ ¥λ¬Όμ μ ν•΄μ„±κ³Ό νΈν–¥μ— μ–΄λ–»κ² μν–¥μ„ λ―ΈμΉλ”μ§€λ¥Ό νƒκµ¬ν•©λ‹λ‹¤. μ‚¬ν μ‹¬λ¦¬ν•™μ—μ„ κ°λ°λ λ„λ¦¬ μΈμ •λ°›λ” HEXACO μ„±κ²© ν”„λ μ„μ›ν¬λ¥Ό ν™μ©ν•μ—¬, μ„Έ κ°€μ§€ μ ν•΄μ„±κ³Ό νΈν–¥ κΈ°μ¤€μ— λ€ν• μ„Έ κ°€μ§€ LLMμ μ„±λ¥μ„ μ‹¤ν—μ μΌλ΅ κ²€μ¦ν•κΈ° μ„ν• ν”„λ΅¬ν”„νΈλ¥Ό μ„¤κ³„ν•©λ‹λ‹¤. μ—°κµ¬ κ²°κ³Όλ” μ„Έ λ¨λΈ λ¨λ‘ HEXACO μ„±κ²© νΉμ„±μ— λ―Όκ°ν•λ©°, λ” μ¤‘μ”ν•κ²λ” μ¶λ ¥λ¬Όμ νΈν–¥, λ¶€μ •μ  κ°μ • λ° μ ν•΄μ„±μ— μΌκ΄€λ λ³€ν™”λ¥Ό λ³΄μΈλ‹¤λ” κ²ƒμ„ λ³΄μ—¬μ¤λ‹λ‹¤. νΉν, μ—¬λ¬ μ„±κ²© νΉμ„±μ μμ¤€μ„ μ΅°μ •ν•λ©΄ λ¨λΈ μ„±λ¥μ νΈν–¥κ³Ό μ ν•΄μ„±μ„ ν¨κ³Όμ μΌλ΅ μ¤„μΌ μ μμΌλ©°, μ΄λ” μΈκ°„μ μ„±κ²© νΉμ„±κ³Ό μ ν•΄ ν–‰λ™ κ°„μ μƒκ΄€κ΄€κ³„μ™€ μ μ‚¬ν•©λ‹λ‹¤. μ—°κµ¬ κ²°κ³Όλ” LLM μΈκ²©ν™”λ¥Ό μ„ν• ν›λ ¨ λλ” λ―Έμ„Έ μ΅°μ • λ°©λ²•μ ν¨μ¨μ„± μ™Έμ—λ„ λ‚΄μ© μ•μ „μ„±μ„ μ¶”κ°€λ΅ κ²€ν† ν•  ν•„μ”μ„±μ„ κ°•μ΅°ν•©λ‹λ‹¤. λν•, μ„±κ²© μ΅°μ •μ΄ ν†µμ λ ν…μ¤νΈ μƒμ„±μ„ μν–‰ν•λ” κ°„λ‹¨ν•κ³  μ €λΉ„μ©μ λ°©λ²•μ΄ λ  μ μλ” μ μ¬λ ¥μ„ μ‹μ‚¬ν•©λ‹λ‹¤.

## π“ μ”μ•½

μ΄ μ—°κµ¬λ” λ€ν• μ–Έμ–΄ λ¨λΈ(LLM)μ— λ‹¤μ–‘ν• μ„±κ²©μ„ λ¶€μ—¬ν•λ” κ²ƒμ΄ λ¨λΈμ νΈν–¥μ„±κ³Ό λ…μ„±μ— μ–΄λ–¤ μν–¥μ„ λ―ΈμΉλ”μ§€λ¥Ό νƒκµ¬ν•©λ‹λ‹¤. μ‚¬νμ‹¬λ¦¬ν•™μ HEXACO μ„±κ²© λ¨λΈμ„ ν™μ©ν•μ—¬ μ„Έ κ°€μ§€ LLMμ„ λ€μƒμΌλ΅ μ‹¤ν—μ„ μ„¤κ³„ν•κ³ , λ…μ„±κ³Ό νΈν–¥μ„± λ²¤μΉλ§ν¬λ¥Ό ν†µν•΄ μ„±λ¥μ„ ν‰κ°€ν–μµλ‹λ‹¤. μ—°κµ¬ κ²°κ³Ό, λ¨λ“  λ¨λΈμ΄ HEXACO μ„±κ²© νΉμ„±μ— λ―Όκ°ν•κ² λ°μ‘ν•λ©°, μ„±κ²© μ΅°μ •μ΄ λ¨λΈμ νΈν–¥μ„±κ³Ό λ…μ„±μ„ μ¤„μ΄λ” λ° ν¨κ³Όμ μ„μ„ ν™•μΈν–μµλ‹λ‹¤. μ΄λ” LLMμ μ„±κ²© μ΅°μ •μ΄ μ•μ „ν• μ½ν…μΈ  μƒμ„±μ„ μ„ν• κ°„λ‹¨ν•κ³  λΉ„μ© ν¨μ¨μ μΈ λ°©λ²•μ΄ λ  μ μμμ„ μ‹μ‚¬ν•©λ‹λ‹¤.

## π― μ£Όμ” ν¬μΈνΈ

- 1. λ€ν• μ–Έμ–΄ λ¨λΈ(LLM)μ— λ‹¤μ–‘ν• μ„±κ²©μ„ λ¶€μ—¬ν•λ” μ—°κµ¬κ°€ μ¦κ°€ν•κ³  μμΌλ©°, μ΄λ” μƒνΈμ‘μ©μ„±κ³Ό μ μ‘μ„±μ„ λ†’μ΄μ§€λ§ νΈν–¥, κ°μ • λ° μ ν•΄μ„±μ— λ€ν• μ°λ ¤λ¥Ό λ¶λ¬μΌμΌν‚¨λ‹¤.

- 2. μ΄ μ—°κµ¬λ” HEXACO μ„±κ²© ν”„λ μ„μ›ν¬λ¥Ό ν™μ©ν•μ—¬ LLMμ μ„±κ²© νΉμ„±μ΄ μ¶λ ¥λ¬Όμ μ ν•΄μ„±κ³Ό νΈν–¥μ— λ―ΈμΉλ” μν–¥μ„ μ‹¤ν—μ μΌλ΅ μ΅°μ‚¬ν•μ€λ‹¤.

- 3. μ‹¤ν— κ²°κ³Ό, μ„Έ κ°€μ§€ LLM λ¨λ‘ HEXACO μ„±κ²© νΉμ„±μ— λ―Όκ°ν•κ² λ°μ‘ν•λ©°, νΈν–¥, λ¶€μ •μ  κ°μ • λ° μ ν•΄μ„±μ— μΌκ΄€λ λ³€ν™”λ¥Ό λ³΄μ€λ‹¤.

- 4. νΉμ • μ„±κ²© νΉμ„±μ μμ¤€μ„ μ΅°μ •ν•λ©΄ λ¨λΈμ νΈν–¥μ„±κ³Ό μ ν•΄μ„±μ„ ν¨κ³Όμ μΌλ΅ μ¤„μΌ μ μμΌλ©°, μ΄λ” μΈκ°„μ μ„±κ²© νΉμ„±κ³Ό μ ν•΄ ν–‰λ™ κ°„μ μƒκ΄€κ΄€κ³„μ™€ μ μ‚¬ν•λ‹¤.

- 5. μ—°κµ¬ κ²°κ³Όλ” LLMμ μ„±κ²©ν™”μ—μ„ ν›λ ¨ ν¨μ¨μ„± μ™Έμ—λ„ μ½ν…μΈ  μ•μ „μ„±μ„ μ¶”κ°€λ΅ κ²€ν† ν•  ν•„μ”μ„±μ„ κ°•μ΅°ν•λ©°, μ„±κ²© μ΅°μ •μ΄ ν†µμ λ ν…μ¤νΈ μƒμ„±μ„ μ„ν• κ°„λ‹¨ν•κ³  μ €λΉ„μ©μ λ°©λ²•μ΄ λ  μ μμμ„ μ‹μ‚¬ν•λ‹¤.

---

*Generated on 2025-09-22 14:30:18*