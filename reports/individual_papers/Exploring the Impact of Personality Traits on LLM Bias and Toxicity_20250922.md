# Exploring the Impact of Personality Traits on LLM Bias and Toxicity

**Korean Title:** 성격 특성이 대형 언어 모델의 편향성과 유해성에 미치는 영향 탐구

## 📋 메타데이터

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Personality-based Text Generation

## 🔗 유사한 논문
- [[2025-09-18/Do LLMs Align Human Values Regarding Social Biases Judging and Explaining Social Biases with LLMs_20250918|Do LLMs Align Human Values Regarding Social Biases Judging and Explaining Social Biases with LLMs]] (86.5% similar)
- [[2025-09-17/Simulating a Bias Mitigation Scenario in Large Language Models_20250917|Simulating a Bias Mitigation Scenario in Large Language Models]] (86.4% similar)
- [[2025-09-19/Adding LLMs to the psycholinguistic norming toolbox_ A practical guide to getting the most out of human ratings_20250919|Adding LLMs to the psycholinguistic norming toolbox A practical guide to getting the most out of human ratings]] (85.3% similar)
- [[2025-09-18/Catch Me If You Can Not Yet_ LLMs Still Struggle to Imitate the Implicit Writing Styles of Everyday Authors_20250918|Catch Me If You Can Not Yet LLMs Still Struggle to Imitate the Implicit Writing Styles of Everyday Authors]] (84.1% similar)
- [[2025-09-18/How Does Cognitive Bias Affect Large Language Models A Case Study on the Anchoring Effect in Price Negotiation Simulations_20250918|How Does Cognitive Bias Affect Large Language Models A Case Study on the Anchoring Effect in Price Negotiation Simulations]] (83.9% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2502.12566v3 Announce Type: replace 
Abstract: With the different roles that AI is expected to play in human life, imbuing large language models (LLMs) with different personalities has attracted increasing research interests. While the "personification" enhances human experiences of interactivity and adaptability of LLMs, it gives rise to critical concerns about content safety, particularly regarding bias, sentiment and toxicity of LLM generation. This study explores how assigning different personality traits to LLMs affects the toxicity and biases of their outputs. Leveraging the widely accepted HEXACO personality framework developed in social psychology, we design experimentally sound prompts to test three LLMs' performance on three toxic and bias benchmarks. The findings demonstrate the sensitivity of all three models to HEXACO personality traits and, more importantly, a consistent variation in the biases, negative sentiment and toxicity of their output. In particular, adjusting the levels of several personality traits can effectively reduce bias and toxicity in model performance, similar to humans' correlations between personality traits and toxic behaviors. The findings highlight the additional need to examine content safety besides the efficiency of training or fine-tuning methods for LLM personification. They also suggest a potential for the adjustment of personalities to be a simple and low-cost method to conduct controlled text generation.

## 🔍 Abstract (한글 번역)

arXiv:2502.12566v3 발표 유형: 교체  
초록: 인공지능(AI)이 인간 생활에서 다양한 역할을 수행할 것으로 기대됨에 따라 대형 언어 모델(LLM)에 다양한 성격을 부여하는 것이 점점 더 많은 연구 관심을 끌고 있습니다. "인격화"는 LLM의 상호작용성과 적응성을 향상시키지만, LLM 생성의 편향, 감정 및 유해성에 대한 내용 안전성에 대한 중요한 우려를 불러일으킵니다. 본 연구는 LLM에 다른 성격 특성을 부여하는 것이 그들의 출력물의 유해성과 편향에 어떻게 영향을 미치는지를 탐구합니다. 사회 심리학에서 개발된 널리 인정받는 HEXACO 성격 프레임워크를 활용하여, 세 가지 유해성과 편향 기준에 대한 세 가지 LLM의 성능을 실험적으로 검증하기 위한 프롬프트를 설계합니다. 연구 결과는 세 모델 모두 HEXACO 성격 특성에 민감하며, 더 중요하게는 출력물의 편향, 부정적 감정 및 유해성에 일관된 변화를 보인다는 것을 보여줍니다. 특히, 여러 성격 특성의 수준을 조정하면 모델 성능의 편향과 유해성을 효과적으로 줄일 수 있으며, 이는 인간의 성격 특성과 유해 행동 간의 상관관계와 유사합니다. 연구 결과는 LLM 인격화를 위한 훈련 또는 미세 조정 방법의 효율성 외에도 내용 안전성을 추가로 검토할 필요성을 강조합니다. 또한, 성격 조정이 통제된 텍스트 생성을 수행하는 간단하고 저비용의 방법이 될 수 있는 잠재력을 시사합니다.

## 📝 요약

이 연구는 대형 언어 모델(LLM)에 다양한 성격을 부여하는 것이 모델의 편향성과 독성에 어떤 영향을 미치는지를 탐구합니다. 사회심리학의 HEXACO 성격 모델을 활용하여 세 가지 LLM을 대상으로 실험을 설계하고, 독성과 편향성 벤치마크를 통해 성능을 평가했습니다. 연구 결과, 모든 모델이 HEXACO 성격 특성에 민감하게 반응하며, 성격 조정이 모델의 편향성과 독성을 줄이는 데 효과적임을 확인했습니다. 이는 LLM의 성격 조정이 안전한 콘텐츠 생성을 위한 간단하고 비용 효율적인 방법이 될 수 있음을 시사합니다.

## 🎯 주요 포인트

- 1. 대형 언어 모델(LLM)에 다양한 성격을 부여하는 연구가 증가하고 있으며, 이는 상호작용성과 적응성을 높이지만 편향, 감정 및 유해성에 대한 우려를 불러일으킨다.

- 2. 이 연구는 HEXACO 성격 프레임워크를 활용하여 LLM의 성격 특성이 출력물의 유해성과 편향에 미치는 영향을 실험적으로 조사하였다.

- 3. 실험 결과, 세 가지 LLM 모두 HEXACO 성격 특성에 민감하게 반응하며, 편향, 부정적 감정 및 유해성에 일관된 변화를 보였다.

- 4. 특정 성격 특성의 수준을 조정하면 모델의 편향성과 유해성을 효과적으로 줄일 수 있으며, 이는 인간의 성격 특성과 유해 행동 간의 상관관계와 유사하다.

- 5. 연구 결과는 LLM의 성격화에서 훈련 효율성 외에도 콘텐츠 안전성을 추가로 검토할 필요성을 강조하며, 성격 조정이 통제된 텍스트 생성을 위한 간단하고 저비용의 방법이 될 수 있음을 시사한다.

---

*Generated on 2025-09-22 14:30:18*