# Video2Roleplay: A Multimodal Dataset and Framework for Video-Guided Role-playing Agents

**Korean Title:** Video2Roleplay: 비디오 안내 역할 수행 에이전트를 위한 다중 모달 데이터셋 및 프레임워크

## 📋 메타데이터

## 📋 메타데이터

**Links**: [[reports/digests/daily_digest_20250922|2025-09-22]] [[keywords/evolved/Dynamic Role Profiles|Dynamic Role Profiles]] [[keywords/specific/Multimodal Dataset|Multimodal Dataset]] [[keywords/broad/Computer Vision|Computer Vision]] [[keywords/broad/Natural Language Processing|Natural Language Processing]] [[keywords/unique/Role-playing-Video60k|Role-playing-Video60k]] [[categories/cs.CL|cs.CL]] [[2025-09-18/When Avatars Have Personality_ Effects on Engagement and Communication in Immersive Medical Training_20250918|When Avatars Have Personality: Effects on Engagement and Communication in Immersive Medical Training]] (81.1% similar) [[2025-09-19/Ask-to-Clarify_ Resolving Instruction Ambiguity through Multi-turn Dialogue_20250919|Ask-to-Clarify: Resolving Instruction Ambiguity through Multi-turn Dialogue]] (81.1% similar) [[2025-09-22/Hierarchical Reinforcement Learning with Low-Level MPC for Multi-Agent Control_20250922|Hierarchical Reinforcement Learning with Low-Level MPC for Multi-Agent Control]] (80.4% similar)

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Dynamic Role Profiles
**🔗 Specific Connectable**: Multimodal Dataset
**🔬 Broad Technical**: Computer Vision, Natural Language Processing
**⭐ Unique Technical**: Role-playing-Video60k
## 🔗 유사한 논문
- [[2025-09-18/When Avatars Have Personality_ Effects on Engagement and Communication in Immersive Medical Training_20250918|When Avatars Have Personality Effects on Engagement and Communication in Immersive Medical Training]] (81.1% similar)
- [[2025-09-19/Ask-to-Clarify_ Resolving Instruction Ambiguity through Multi-turn Dialogue_20250919|Ask-to-Clarify Resolving Instruction Ambiguity through Multi-turn Dialogue]] (81.1% similar)
- [[2025-09-22/Hierarchical Reinforcement Learning with Low-Level MPC for Multi-Agent Control_20250922|Hierarchical Reinforcement Learning with Low-Level MPC for Multi-Agent Control]] (80.4% similar)
- [[2025-09-18/$Agent^2$_ An Agent-Generates-Agent Framework for Reinforcement Learning Automation_20250918|$Agent^2$ An Agent-Generates-Agent Framework for Reinforcement Learning Automation]] (79.8% similar)
- [[2025-09-22/ChronoForge-RL_ Chronological Forging through Reinforcement Learning for Enhanced Video Understanding_20250922|ChronoForge-RL Chronological Forging through Reinforcement Learning for Enhanced Video Understanding]] (79.8% similar)


**ArXiv ID**: [2509.15233](https://arxiv.org/abs/2509.15233)
**Published**: 2025-09-22
**Category**: cs.CL
**PDF**: [Download](https://arxiv.org/pdf/2509.15233.pdf)


**ArXiv ID**: [2509.15233](https://arxiv.org/abs/2509.15233)
**Published**: 2025-09-22
**Category**: cs.CL
**PDF**: [Download](https://arxiv.org/pdf/2509.15233.pdf)

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Dynamic Role Profiles
**🔗 Specific Connectable**: Adaptive Temporal Sampling
**⭐ Unique Technical**: Role-playing-Video60k
**🔬 Broad Technical**: Multimodal Dataset, Role-playing Agents

## 🏷️ 추출된 키워드



`Computer Vision` • 

`Natural Language Processing` • 

`Multimodal Dataset` • 

`Role-playing-Video60k` • 

`Dynamic Role Profiles`



## 🔗 유사한 논문

Similar papers will be displayed here based on embedding similarity.

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.15233v1 Announce Type: cross 
Abstract: Role-playing agents (RPAs) have attracted growing interest for their ability to simulate immersive and interactive characters. However, existing approaches primarily focus on static role profiles, overlooking the dynamic perceptual abilities inherent to humans. To bridge this gap, we introduce the concept of dynamic role profiles by incorporating video modality into RPAs. To support this, we construct Role-playing-Video60k, a large-scale, high-quality dataset comprising 60k videos and 700k corresponding dialogues. Based on this dataset, we develop a comprehensive RPA framework that combines adaptive temporal sampling with both dynamic and static role profile representations. Specifically, the dynamic profile is created by adaptively sampling video frames and feeding them to the LLM in temporal order, while the static profile consists of (1) character dialogues from training videos during fine-tuning, and (2) a summary context from the input video during inference. This joint integration enables RPAs to generate greater responses. Furthermore, we propose a robust evaluation method covering eight metrics. Experimental results demonstrate the effectiveness of our framework, highlighting the importance of dynamic role profiles in developing RPAs.

## 🔍 Abstract (한글 번역)

arXiv:2509.15233v1 발표 유형: 교차  
초록: 역할 수행 에이전트(RPAs)는 몰입적이고 상호작용적인 캐릭터를 시뮬레이션하는 능력으로 인해 점점 더 많은 관심을 받고 있습니다. 그러나 기존 접근 방식은 주로 정적인 역할 프로필에 초점을 맞추고 있어 인간의 고유한 동적 지각 능력을 간과하고 있습니다. 이러한 격차를 해소하기 위해, 우리는 비디오 모달리티를 RPAs에 통합하여 동적 역할 프로필의 개념을 도입합니다. 이를 지원하기 위해, 우리는 60,000개의 비디오와 700,000개의 대응하는 대화를 포함하는 대규모 고품질 데이터셋인 Role-playing-Video60k를 구축합니다. 이 데이터셋을 기반으로, 우리는 동적 및 정적 역할 프로필 표현을 모두 포함하는 적응형 시간 샘플링을 결합한 포괄적인 RPA 프레임워크를 개발합니다. 구체적으로, 동적 프로필은 비디오 프레임을 적응적으로 샘플링하여 시간 순서에 따라 LLM에 입력함으로써 생성되며, 정적 프로필은 (1) 미세 조정 중 훈련 비디오에서의 캐릭터 대화와 (2) 추론 중 입력 비디오에서의 요약 컨텍스트로 구성됩니다. 이러한 통합은 RPAs가 더 나은 응답을 생성할 수 있게 합니다. 또한, 우리는 8가지 메트릭을 포괄하는 강력한 평가 방법을 제안합니다. 실험 결과는 우리의 프레임워크의 효과를 입증하며, RPAs 개발에서 동적 역할 프로필의 중요성을 강조합니다.

## 📝 요약

이 논문은 동적 역할 프로필을 도입하여 몰입형 상호작용 캐릭터를 시뮬레이션하는 역할 수행 에이전트(RPAs)의 발전을 제안합니다. 이를 위해 60,000개의 비디오와 700,000개의 대화를 포함한 대규모 데이터셋인 Role-playing-Video60k를 구축하였습니다. 제안된 RPA 프레임워크는 적응적 시간 샘플링을 통해 동적 및 정적 역할 프로필을 결합합니다. 동적 프로필은 비디오 프레임을 시간 순서대로 샘플링하여 생성되며, 정적 프로필은 훈련 비디오의 캐릭터 대화와 입력 비디오의 요약 컨텍스트로 구성됩니다. 이 통합 접근법은 RPAs의 응답성을 향상시킵니다. 실험 결과, 동적 역할 프로필의 중요성을 강조하며 제안된 프레임워크의 효과를 입증합니다.

## 🎯 주요 포인트


- 1. 기존의 역할 수행 에이전트(RPAs)는 정적 역할 프로필에 중점을 두고 있어 인간의 동적 지각 능력을 간과하고 있다.

- 2. 동적 역할 프로필 개념을 도입하여 비디오 모달리티를 RPAs에 통합함으로써 이러한 격차를 해소하고자 한다.

- 3. Role-playing-Video60k라는 대규모 데이터셋을 구축하여 60,000개의 비디오와 700,000개의 대화를 포함하였다.

- 4. 적응형 시간 샘플링을 통해 동적 및 정적 역할 프로필을 결합한 포괄적인 RPA 프레임워크를 개발하였다.

- 5. 실험 결과, 동적 역할 프로필이 RPAs 개발에 있어 중요한 역할을 하며, 제안된 프레임워크의 효과성을 입증하였다.


---

*Generated on 2025-09-22 16:30:31*