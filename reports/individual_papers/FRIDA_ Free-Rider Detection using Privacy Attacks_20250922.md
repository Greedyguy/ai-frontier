# FRIDA: Free-Rider Detection using Privacy Attacks

**Korean Title:** FRIDA: 프라이버시 공격을 이용한 무임승차자 탐지

## 📋 메타데이터

## 📋 메타데이터

**Links**: [[reports/digests/daily_digest_20250922|2025-09-22]] [[keywords/specific/Membership Inference Attacks|Membership Inference Attacks]] [[keywords/specific/Property Inference Attacks|Property Inference Attacks]] [[keywords/broad/Federated Learning|Federated Learning]] [[keywords/unique/FRIDA|FRIDA]] [[categories/cs.LG|cs.LG]] [[2025-09-17/ParaAegis_ Parallel Protection for Flexible Privacy-preserved Federated Learning_20250917|ParaAegis: Parallel Protection for Flexible Privacy-preserved Federated Learning]] (82.6% similar) [[2025-09-19/Communication-Efficient and Privacy-Adaptable Mechanism for Federated Learning_20250919|Communication-Efficient and Privacy-Adaptable Mechanism for Federated Learning]] (82.5% similar) [[2025-09-17/Differential Privacy in Federated Learning_ Mitigating Inference Attacks with Randomized Response_20250917|Differential Privacy in Federated Learning: Mitigating Inference Attacks with Randomized Response]] (82.0% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: Membership Inference Attacks, Property Inference Attacks
**🔬 Broad Technical**: Federated Learning
**⭐ Unique Technical**: FRIDA
## 🔗 유사한 논문
- [[2025-09-17/ParaAegis_ Parallel Protection for Flexible Privacy-preserved Federated Learning_20250917|ParaAegis Parallel Protection for Flexible Privacy-preserved Federated Learning]] (82.6% similar)
- [[2025-09-19/Communication-Efficient and Privacy-Adaptable Mechanism for Federated Learning_20250919|Communication-Efficient and Privacy-Adaptable Mechanism for Federated Learning]] (82.5% similar)
- [[2025-09-17/Differential Privacy in Federated Learning_ Mitigating Inference Attacks with Randomized Response_20250917|Differential Privacy in Federated Learning Mitigating Inference Attacks with Randomized Response]] (82.0% similar)
- [[2025-09-22/Negotiated Representations to Prevent Overfitting in Machine Learning Applications_20250922|Negotiated Representations to Prevent Overfitting in Machine Learning Applications]] (81.1% similar)
- [[2025-09-19/Who to Trust Aggregating Client Knowledge in Logit-Based Federated Learning_20250919|Who to Trust Aggregating Client Knowledge in Logit-Based Federated Learning]] (80.3% similar)


**ArXiv ID**: [2410.05020](https://arxiv.org/abs/2410.05020)
**Published**: 2025-09-22
**Category**: cs.LG
**PDF**: [Download](https://arxiv.org/pdf/2410.05020.pdf)


**ArXiv ID**: [2410.05020](https://arxiv.org/abs/2410.05020)
**Published**: 2025-09-22
**Category**: cs.LG
**PDF**: [Download](https://arxiv.org/pdf/2410.05020.pdf)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: Membership Inference Attacks, Property Inference Attacks
**⭐ Unique Technical**: FRIDA
**🔬 Broad Technical**: Federated Learning

## 🏷️ 추출된 키워드



`Federated Learning` • 

`Membership Inference Attacks` • 

`Property Inference Attacks` • 

`FRIDA`



## 🔗 유사한 논문

Similar papers will be displayed here based on embedding similarity.

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2410.05020v2 Announce Type: replace 
Abstract: Federated learning is increasingly popular as it enables multiple parties with limited datasets and resources to train a machine learning model collaboratively. However, similar to other collaborative systems, federated learning is vulnerable to free-riders - participants who benefit from the global model without contributing. Free-riders compromise the integrity of the learning process and slow down the convergence of the global model, resulting in increased costs for honest participants. To address this challenge, we propose FRIDA: free-rider detection using privacy attacks. Instead of focusing on implicit effects of free-riding, FRIDA utilizes membership and property inference attacks to directly infer evidence of genuine client training. Our extensive evaluation demonstrates that FRIDA is effective across a wide range of scenarios.

## 🔍 Abstract (한글 번역)

arXiv:2410.05020v2 발표 유형: 교체  
초록: 연합 학습은 제한된 데이터셋과 자원을 가진 여러 당사자가 협력하여 기계 학습 모델을 훈련할 수 있게 해주어 점점 인기를 끌고 있습니다. 그러나 다른 협력 시스템과 마찬가지로 연합 학습은 글로벌 모델의 혜택을 누리면서 기여하지 않는 참여자인 무임승차자에게 취약합니다. 무임승차자는 학습 과정의 무결성을 훼손하고 글로벌 모델의 수렴 속도를 늦추어 정직한 참여자에게 비용을 증가시킵니다. 이 문제를 해결하기 위해, 우리는 FRIDA: 프라이버시 공격을 이용한 무임승차자 탐지를 제안합니다. 무임승차의 암묵적 효과에 집중하는 대신, FRIDA는 멤버십 및 속성 추론 공격을 활용하여 진정한 클라이언트 훈련의 증거를 직접적으로 추론합니다. 우리의 광범위한 평가 결과, FRIDA는 다양한 시나리오에서 효과적임을 보여줍니다.

## 📝 요약

이 논문은 연합 학습에서 발생하는 무임승차 문제를 해결하기 위해 FRIDA라는 새로운 접근법을 제안합니다. 연합 학습은 여러 참여자가 협력하여 모델을 훈련하는 방식이지만, 무임승차자는 기여 없이 혜택만 누려 학습 과정의 무결성을 해치고 비용을 증가시킵니다. FRIDA는 무임승차의 간접적 효과 대신, 프라이버시 공격을 활용하여 실제 클라이언트의 훈련 여부를 직접 추론합니다. 다양한 시나리오에서 FRIDA의 효과를 입증한 평가 결과를 제시합니다.

## 🎯 주요 포인트


- 1. 연합 학습은 여러 참가자가 제한된 데이터셋과 자원을 활용하여 협력적으로 기계 학습 모델을 훈련할 수 있게 해줍니다.

- 2. 연합 학습은 기여 없이 글로벌 모델의 혜택만 누리는 프리라이더 문제에 취약합니다.

- 3. 프리라이더는 학습 과정의 무결성을 훼손하고 글로벌 모델의 수렴을 지연시켜 정직한 참가자들에게 비용을 증가시킵니다.

- 4. FRIDA는 프라이버시 공격을 이용하여 프리라이더를 탐지하는 방법으로, 진정한 클라이언트 훈련의 증거를 추론합니다.

- 5. FRIDA는 다양한 시나리오에서 효과적임이 광범위한 평가를 통해 입증되었습니다.


---

*Generated on 2025-09-22 15:51:25*