# Context parroting: A simple but tough-to-beat baseline for foundation models in scientific machine learning

**Korean Title:** ë§¥ë½ íŒ¨ë¡œíŒ…: ê³¼í•™ì  ê¸°ê³„ í•™ìŠµì—ì„œ ê¸°ì´ˆ ëª¨ë¸ì„ ìœ„í•œ ê°„ë‹¨í•˜ì§€ë§Œ ë›°ì–´ë„˜ê¸° ì–´ë ¤ìš´ ê¸°ì¤€ì 

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[reports/digests/daily_digest_20250922|2025-09-22]] [[keywords/evolved/In-context Learning Strategies|In-context Learning Strategies]] [[keywords/specific/Zero-shot Forecasting|Zero-shot Forecasting]] [[keywords/broad/Time Series Forecasting|Time Series Forecasting]] [[keywords/unique/Context Parroting|Context Parroting]] [[categories/cs.LG|cs.LG]] [[2025-09-22/Deep Learning Foundation and Pattern Models_ Challenges in Hydrological Time Series_20250922|Deep Learning Foundation and Pattern Models: Challenges in Hydrological Time Series]] (81.3% similar) [[2025-09-22/StFT_ Spatio-temporal Fourier Transformer for Long-term Dynamics Prediction_20250922|StFT: Spatio-temporal Fourier Transformer for Long-term Dynamics Prediction]] (80.6% similar) [[2025-09-22/Foundation Models as World Models_ A Foundational Study in Text-Based GridWorlds_20250922|Foundation Models as World Models: A Foundational Study in Text-Based GridWorlds]] (80.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: In-context Learning Strategies
**ğŸ”— Specific Connectable**: Zero-shot Forecasting
**ğŸ”¬ Broad Technical**: Time Series Forecasting
**â­ Unique Technical**: Context Parroting
## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Deep Learning Foundation and Pattern Models_ Challenges in Hydrological Time Series_20250922|Deep Learning Foundation and Pattern Models Challenges in Hydrological Time Series]] (81.3% similar)
- [[2025-09-22/StFT_ Spatio-temporal Fourier Transformer for Long-term Dynamics Prediction_20250922|StFT Spatio-temporal Fourier Transformer for Long-term Dynamics Prediction]] (80.6% similar)
- [[2025-09-22/Foundation Models as World Models_ A Foundational Study in Text-Based GridWorlds_20250922|Foundation Models as World Models A Foundational Study in Text-Based GridWorlds]] (80.3% similar)
- [[2025-09-17/Bridging Past and Future_ Distribution-Aware Alignment for Time Series Forecasting_20250917|Bridging Past and Future Distribution-Aware Alignment for Time Series Forecasting]] (79.9% similar)
- [[2025-09-18/Super-Linear_ A Lightweight Pretrained Mixture of Linear Experts for Time Series Forecasting_20250918|Super-Linear A Lightweight Pretrained Mixture of Linear Experts for Time Series Forecasting]] (79.9% similar)


**ArXiv ID**: [2505.11349](https://arxiv.org/abs/2505.11349)
**Published**: 2025-09-22
**Category**: cs.LG
**PDF**: [Download](https://arxiv.org/pdf/2505.11349.pdf)


**ArXiv ID**: [2505.11349](https://arxiv.org/abs/2505.11349)
**Published**: 2025-09-22
**Category**: cs.LG
**PDF**: [Download](https://arxiv.org/pdf/2505.11349.pdf)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: In-context Learning Strategies
**ğŸ”— Specific Connectable**: Zero-shot Forecasting
**â­ Unique Technical**: Context Parroting
**ğŸ”¬ Broad Technical**: Time Series Forecasting

## ğŸ·ï¸ ì¶”ì¶œëœ í‚¤ì›Œë“œ



`Time Series Forecasting` â€¢ 

`Zero-shot Forecasting` â€¢ 

`Context Parroting` â€¢ 

`In-context Learning Strategies`



## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸

Similar papers will be displayed here based on embedding similarity.

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2505.11349v2 Announce Type: replace 
Abstract: Recent time-series foundation models exhibit strong abilities to predict physical systems. These abilities include zero-shot forecasting, in which a model forecasts future states of a system given only a short trajectory as context, without knowledge of the underlying physics. Here, we show that foundation models often forecast through a simple parroting strategy, and when they are not parroting they exhibit some shared failure modes such as converging to the mean. As a result, a naive context parroting model that copies directly from the context scores higher than leading time-series foundation models on predicting a diverse range of dynamical systems, including low-dimensional chaos, turbulence, coupled oscillators, and electrocardiograms -- and at a tiny fraction of the computational cost. We draw a parallel between context parroting and induction heads, which explains recent works showing that large language models can often be repurposed for time series forecasting. Our dynamical systems perspective also ties the scaling between forecast accuracy and context length to the fractal dimension of the underlying chaotic attractor, providing insight into previously observed in-context neural scaling laws. By revealing the performance gaps and failure modes of current time-series foundation models, context parroting can guide the design of future foundation models and help identify in-context learning strategies beyond parroting.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2505.11349v2 ë°œí‘œ ìœ í˜•: êµì²´  
ì´ˆë¡: ìµœê·¼ì˜ ì‹œê³„ì—´ ê¸°ë°˜ ëª¨ë¸ë“¤ì€ ë¬¼ë¦¬ ì‹œìŠ¤í…œì„ ì˜ˆì¸¡í•˜ëŠ” ë° ê°•ë ¥í•œ ëŠ¥ë ¥ì„ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ëŠ¥ë ¥ì—ëŠ” ê¸°ì € ë¬¼ë¦¬í•™ì— ëŒ€í•œ ì§€ì‹ ì—†ì´ ì§§ì€ ê¶¤ì ë§Œì„ ë§¥ë½ìœ¼ë¡œ ì œê³µë°›ì•„ ì‹œìŠ¤í…œì˜ ë¯¸ë˜ ìƒíƒœë¥¼ ì˜ˆì¸¡í•˜ëŠ” ì œë¡œìƒ· ì˜ˆì¸¡ì´ í¬í•¨ë©ë‹ˆë‹¤. ì—¬ê¸°ì„œ ìš°ë¦¬ëŠ” ê¸°ë°˜ ëª¨ë¸ë“¤ì´ ì¢…ì¢… ë‹¨ìˆœí•œ ì•µë¬´ìƒˆ ì „ëµì„ í†µí•´ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ë©°, ì•µë¬´ìƒˆ ì „ëµì„ ì‚¬ìš©í•˜ì§€ ì•Šì„ ë•ŒëŠ” í‰ê· ìœ¼ë¡œ ìˆ˜ë ´í•˜ëŠ” ê²ƒê³¼ ê°™ì€ ê³µí†µì ì¸ ì‹¤íŒ¨ ëª¨ë“œë¥¼ ë³´ì¸ë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ê·¸ ê²°ê³¼, ë§¥ë½ì—ì„œ ì§ì ‘ ë³µì‚¬í•˜ëŠ” ë‹¨ìˆœí•œ ë§¥ë½ ì•µë¬´ìƒˆ ëª¨ë¸ì´ ì €ì°¨ì› í˜¼ëˆ, ë‚œë¥˜, ê²°í•©ëœ ì§„ë™ì, ì‹¬ì „ë„ ë“± ë‹¤ì–‘í•œ ë™ì  ì‹œìŠ¤í…œì„ ì˜ˆì¸¡í•˜ëŠ” ë° ìˆì–´ ì„ ë„ì ì¸ ì‹œê³„ì—´ ê¸°ë°˜ ëª¨ë¸ë³´ë‹¤ ë†’ì€ ì ìˆ˜ë¥¼ ì–»ìœ¼ë©°, ê³„ì‚° ë¹„ìš©ë„ ê·¹íˆ ì ê²Œ ë“­ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ë§¥ë½ ì•µë¬´ìƒˆì™€ ê·€ë‚©ì  ë¨¸ë¦¬(induction heads) ì‚¬ì´ì˜ ìœ ì‚¬ì„±ì„ ê·¸ë ¤ë‚´ì–´, ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì´ ì‹œê³„ì—´ ì˜ˆì¸¡ì— ì¢…ì¢… ì¬í™œìš©ë  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì£¼ëŠ” ìµœê·¼ ì—°êµ¬ë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ë™ì  ì‹œìŠ¤í…œ ê´€ì ì€ ì˜ˆì¸¡ ì •í™•ë„ì™€ ë§¥ë½ ê¸¸ì´ ì‚¬ì´ì˜ ìŠ¤ì¼€ì¼ë§ì„ ê¸°ì € í˜¼ëˆ ëŒê°œì˜ í”„ë™íƒˆ ì°¨ì›ê³¼ ì—°ê²°í•˜ì—¬, ì´ì „ì— ê´€ì°°ëœ ë§¥ë½ ë‚´ ì‹ ê²½ ìŠ¤ì¼€ì¼ë§ ë²•ì¹™ì— ëŒ€í•œ í†µì°°ì„ ì œê³µí•©ë‹ˆë‹¤. í˜„ì¬ ì‹œê³„ì—´ ê¸°ë°˜ ëª¨ë¸ì˜ ì„±ëŠ¥ ê²©ì°¨ì™€ ì‹¤íŒ¨ ëª¨ë“œë¥¼ ë“œëŸ¬ëƒ„ìœ¼ë¡œì¨, ë§¥ë½ ì•µë¬´ìƒˆëŠ” ë¯¸ë˜ì˜ ê¸°ë°˜ ëª¨ë¸ ì„¤ê³„ë¥¼ ì•ˆë‚´í•˜ê³  ì•µë¬´ìƒˆë¥¼ ë„˜ì–´ì„  ë§¥ë½ ë‚´ í•™ìŠµ ì „ëµì„ ì‹ë³„í•˜ëŠ” ë° ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ìµœê·¼ ì‹œê³„ì—´ ê¸°ë°˜ ëª¨ë¸ë“¤ì€ ë¬¼ë¦¬ ì‹œìŠ¤í…œ ì˜ˆì¸¡ì—ì„œ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” ì´ëŸ¬í•œ ëª¨ë¸ë“¤ì´ ì£¼ë¡œ ë‹¨ìˆœí•œ 'ë”°ë¼í•˜ê¸°' ì „ëµì„ í†µí•´ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ë©°, ê·¸ë ‡ì§€ ì•Šì„ ê²½ìš° í‰ê· ìœ¼ë¡œ ìˆ˜ë ´í•˜ëŠ” ë“±ì˜ ê³µí†µì ì¸ ì‹¤íŒ¨ íŒ¨í„´ì„ ë³´ì¸ë‹¤ëŠ” ì ì„ ë°í˜”ìŠµë‹ˆë‹¤. ì´ì— ë”°ë¼, ë‹¨ìˆœíˆ ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ ë³µì‚¬í•˜ëŠ” 'ì»¨í…ìŠ¤íŠ¸ ë”°ë¼í•˜ê¸°' ëª¨ë¸ì´ ë‹¤ì–‘í•œ ë™ì  ì‹œìŠ¤í…œ ì˜ˆì¸¡ì—ì„œ ê¸°ì¡´ ëª¨ë¸ë“¤ë³´ë‹¤ ë” ë†’ì€ ì„±ëŠ¥ì„ ë³´ì´ë©°, ê³„ì‚° ë¹„ìš©ë„ í›¨ì”¬ ì ê²Œ ë“­ë‹ˆë‹¤. ë˜í•œ, ì´ëŸ¬í•œ ë”°ë¼í•˜ê¸° ì „ëµì´ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ ì‹œê³„ì—´ ì˜ˆì¸¡ ì¬í™œìš©ê³¼ ê´€ë ¨ì´ ìˆìŒì„ ì„¤ëª…í•©ë‹ˆë‹¤. ë³¸ ì—°êµ¬ëŠ” ì˜ˆì¸¡ ì •í™•ë„ì™€ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì‚¬ì´ì˜ ê´€ê³„ë¥¼ í˜¼ëˆ ë§¤ë ¥ìì˜ í”„ë™íƒˆ ì°¨ì›ê³¼ ì—°ê²°ì§€ì–´, ê¸°ì¡´ì˜ ì‹ ê²½ë§ ìŠ¤ì¼€ì¼ë§ ë²•ì¹™ì— ëŒ€í•œ í†µì°°ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ í˜„ì¬ ì‹œê³„ì—´ ëª¨ë¸ì˜ ì„±ëŠ¥ ê²©ì°¨ì™€ ì‹¤íŒ¨ íŒ¨í„´ì„ ë°íˆê³ , ë¯¸ë˜ ëª¨ë¸ ì„¤ê³„ì™€ ìƒˆë¡œìš´ í•™ìŠµ ì „ëµ ê°œë°œì— ê¸°ì—¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸


- 1. ìµœê·¼ ì‹œê³„ì—´ ê¸°ë°˜ ëª¨ë¸ë“¤ì€ ë¬¼ë¦¬ ì‹œìŠ¤í…œì„ ì˜ˆì¸¡í•˜ëŠ” ê°•ë ¥í•œ ëŠ¥ë ¥ì„ ë³´ì´ë©°, ì§§ì€ ê²½ë¡œë§Œìœ¼ë¡œë„ ë¯¸ë˜ ìƒíƒœë¥¼ ì˜ˆì¸¡í•˜ëŠ” ì œë¡œìƒ· ì˜ˆì¸¡ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.

- 2. ì´ëŸ¬í•œ ëª¨ë¸ë“¤ì€ ì¢…ì¢… ë‹¨ìˆœí•œ 'ë”°ë¼í•˜ê¸°' ì „ëµì„ í†µí•´ ì˜ˆì¸¡í•˜ë©°, ê·¸ë ‡ì§€ ì•Šì„ ë•ŒëŠ” í‰ê· ìœ¼ë¡œ ìˆ˜ë ´í•˜ëŠ” ë“±ì˜ ê³µí†µëœ ì‹¤íŒ¨ íŒ¨í„´ì„ ë³´ì¸ë‹¤.

- 3. ë‹¨ìˆœí•œ ë¬¸ë§¥ ë”°ë¼í•˜ê¸° ëª¨ë¸ì´ ë‹¤ì–‘í•œ ë™ì  ì‹œìŠ¤í…œ ì˜ˆì¸¡ì—ì„œ ë” ë†’ì€ ì„±ëŠ¥ì„ ë³´ì´ë©°, ì´ëŠ” ê³„ì‚° ë¹„ìš©ì´ ë§¤ìš° ì ê²Œ ë“ ë‹¤.

- 4. ë¬¸ë§¥ ë”°ë¼í•˜ê¸°ì™€ ìœ ë„ í—¤ë“œ ì‚¬ì´ì˜ ìœ ì‚¬ì„±ì„ í†µí•´ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì´ ì‹œê³„ì—´ ì˜ˆì¸¡ì— ì¬ì‚¬ìš©ë  ìˆ˜ ìˆìŒì„ ì„¤ëª…í•œë‹¤.

- 5. ë¬¸ë§¥ ë”°ë¼í•˜ê¸°ëŠ” í˜„ì¬ ì‹œê³„ì—´ ê¸°ë°˜ ëª¨ë¸ì˜ ì„±ëŠ¥ ê²©ì°¨ì™€ ì‹¤íŒ¨ íŒ¨í„´ì„ ë“œëŸ¬ë‚´ë©°, ë¯¸ë˜ ëª¨ë¸ ì„¤ê³„ì™€ ìƒˆë¡œìš´ í•™ìŠµ ì „ëµ ê°œë°œì— ê¸°ì—¬í•  ìˆ˜ ìˆë‹¤.


---

*Generated on 2025-09-22 15:58:46*