# AI for Scientific Discovery is a Social Problem

**Korean Title:** 과학적 발견을 위한 인공지능은 사회적 문제이다.

## 📋 메타데이터

## 📋 메타데이터

**Links**: [[reports/digests/daily_digest_20250922|2025-09-22]] [[keywords/evolved/Collective Social Project|Collective Social Project]] [[keywords/specific/Cross-disciplinary Education|Cross-disciplinary Education]] [[keywords/broad/Artificial Intelligence|Artificial Intelligence]] [[categories/cs.LG|cs.LG]] [[2025-09-22/Algorithmic Fairness_ Not a Purely Technical but Socio-Technical Property_20250922|Algorithmic Fairness: Not a Purely Technical but Socio-Technical Property]] (84.2% similar) [[2025-09-22/Who is Responsible When AI Fails Mapping Causes, Entities, and Consequences of AI Privacy and Ethical Incidents_20250922|Who is Responsible When AI Fails? Mapping Causes, Entities, and Consequences of AI Privacy and Ethical Incidents]] (82.1% similar) [[2025-09-22/Towards deployment-centric multimodal AI beyond vision and language_20250922|Towards deployment-centric multimodal AI beyond vision and language]] (80.9% similar)

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Collective Social Project
**🔗 Specific Connectable**: Cross-disciplinary Education
**🔬 Broad Technical**: Artificial Intelligence
## 🔗 유사한 논문
- [[2025-09-22/Algorithmic Fairness_ Not a Purely Technical but Socio-Technical Property_20250922|Algorithmic Fairness Not a Purely Technical but Socio-Technical Property]] (84.2% similar)
- [[2025-09-22/Who is Responsible When AI Fails Mapping Causes, Entities, and Consequences of AI Privacy and Ethical Incidents_20250922|Who is Responsible When AI Fails Mapping Causes, Entities, and Consequences of AI Privacy and Ethical Incidents]] (82.1% similar)
- [[2025-09-22/Towards deployment-centric multimodal AI beyond vision and language_20250922|Towards deployment-centric multimodal AI beyond vision and language]] (80.9% similar)
- [[2025-09-22/The Great AI Witch Hunt_ Reviewers Perception and (Mis)Conception of Generative AI in Research Writing_20250922|The Great AI Witch Hunt Reviewers Perception and (Mis)Conception of Generative AI in Research Writing]] (80.5% similar)
- [[2025-09-18/Position_ AI Safety Must Embrace an Antifragile Perspective_20250918|Position AI Safety Must Embrace an Antifragile Perspective]] (79.1% similar)


**ArXiv ID**: [2509.06580](https://arxiv.org/abs/2509.06580)
**Published**: 2025-09-22
**Category**: cs.LG
**PDF**: [Download](https://arxiv.org/pdf/2509.06580.pdf)


**ArXiv ID**: [2509.06580](https://arxiv.org/abs/2509.06580)
**Published**: 2025-09-22
**Category**: cs.LG
**PDF**: [Download](https://arxiv.org/pdf/2509.06580.pdf)

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Collective Social Project
**🔗 Specific Connectable**: Cross-disciplinary Education
**🔬 Broad Technical**: Artificial Intelligence

## 🏷️ 추출된 키워드



`Artificial Intelligence` • 

`Machine Learning` • 

`Cross-disciplinary Education` • 

`Collective Social Project`



## 🔗 유사한 논문

Similar papers will be displayed here based on embedding similarity.

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.06580v2 Announce Type: replace 
Abstract: Artificial intelligence promises to accelerate scientific discovery, yet its benefits remain unevenly distributed. While technical obstacles such as scarce data, fragmented standards, and unequal access to computation are significant, we argue that the primary barriers are social and institutional. Narratives that defer progress to speculative "AI scientists," the undervaluing of data and infrastructure contributions, misaligned incentives, and gaps between domain experts and machine learning researchers all constrain impact. We highlight four interconnected challenges: community dysfunction, research priorities misaligned with upstream needs, data fragmentation, and infrastructure inequities. We argue that their roots lie in cultural and organizational practices. Addressing them requires not only technical innovation but also intentional community-building, cross-disciplinary education, shared benchmarks, and accessible infrastructure. We call for reframing AI for science as a collective social project, where sustainable collaboration and equitable participation are treated as prerequisites for technical progress.

## 🔍 Abstract (한글 번역)

arXiv:2509.06580v2 발표 유형: 교체  
초록: 인공지능은 과학적 발견을 가속화할 가능성을 가지고 있지만, 그 혜택은 여전히 고르게 분배되지 않고 있습니다. 드문 데이터, 분절된 표준, 불균등한 계산 접근과 같은 기술적 장애물도 중요하지만, 우리는 주요 장벽이 사회적 및 제도적이라고 주장합니다. 진보를 가상의 "AI 과학자"에게 미루는 서사, 데이터 및 인프라 기여의 저평가, 잘못된 인센티브, 도메인 전문가와 기계 학습 연구자 간의 격차가 모두 영향을 제한합니다. 우리는 네 가지 상호 연결된 도전 과제를 강조합니다: 커뮤니티의 기능 장애, 상류 요구와 맞지 않는 연구 우선순위, 데이터 분열, 인프라 불평등. 우리는 그 근본이 문화적 및 조직적 관행에 있다고 주장합니다. 이를 해결하기 위해서는 기술 혁신뿐만 아니라 의도적인 커뮤니티 구축, 학제 간 교육, 공유 벤치마크, 접근 가능한 인프라가 필요합니다. 우리는 과학을 위한 AI를 지속 가능한 협력과 공정한 참여가 기술적 진보의 전제 조건으로 간주되는 집단적 사회 프로젝트로 재구성할 것을 촉구합니다.

## 📝 요약

이 논문은 인공지능(AI)이 과학적 발견을 가속화할 수 있는 잠재력을 가지고 있지만, 그 혜택이 고르게 분배되지 않는다고 주장합니다. 기술적 장애물도 있지만, 주요 장벽은 사회적 및 제도적 요인에 있다고 지적합니다. AI 과학자에 대한 과도한 기대, 데이터와 인프라 기여의 저평가, 잘못된 인센티브, 도메인 전문가와 기계 학습 연구자 간의 격차가 문제의 핵심입니다. 저자들은 커뮤니티의 기능 장애, 연구 우선순위의 불일치, 데이터 분열, 인프라 불평등 등 네 가지 도전 과제를 강조하며, 이를 해결하기 위해 기술 혁신뿐만 아니라 공동체 구축, 학제 간 교육, 공유 벤치마크, 접근 가능한 인프라가 필요하다고 주장합니다. AI를 과학을 위한 사회적 프로젝트로 재구성하여 지속 가능한 협력과 공정한 참여가 기술 발전의 전제 조건이 되어야 한다고 제안합니다.

## 🎯 주요 포인트


- 1. 인공지능의 과학적 발견 가속화 가능성에도 불구하고, 그 혜택은 고르게 분배되지 않고 있다.

- 2. 주요 장벽은 기술적 문제보다 사회적 및 제도적 문제에 있으며, AI 과학자에 대한 기대, 데이터 및 인프라 기여의 저평가, 잘못된 인센티브 등이 영향을 미친다.

- 3. 커뮤니티의 기능 장애, 연구 우선순위의 불일치, 데이터 분열, 인프라 불평등이라는 네 가지 상호 연결된 도전 과제가 있다.

- 4. 이러한 문제의 근본 원인은 문화적 및 조직적 관행에 있으며, 이를 해결하기 위해서는 기술 혁신뿐만 아니라 공동체 구축, 학제 간 교육, 공유 벤치마크, 접근 가능한 인프라가 필요하다.

- 5. 과학을 위한 AI를 지속 가능한 협력과 공정한 참여를 기술 발전의 전제조건으로 삼는 집단적 사회 프로젝트로 재구성할 필요가 있다.


---

*Generated on 2025-09-22 16:02:49*