# Evaluating Multimodal Large Language Models on Spoken Sarcasm Understanding

**Korean Title:** êµ¬ì–´ì  ë°˜ì–´ë²• ì´í•´ì— ëŒ€í•œ ë‹¤ì¤‘ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ í‰ê°€

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[reports/digests/daily_digest_20250922|2025-09-22]] [[keywords/evolved/Cross-lingual Sarcasm Understanding|Cross-lingual Sarcasm Understanding]] [[keywords/specific/Few-shot Learning|Few-shot Learning]] [[keywords/specific/Collaborative Gating Fusion|Collaborative Gating Fusion]] [[keywords/broad/Multimodal Large Language Models|Multimodal Large Language Models]] [[keywords/broad/Natural Language Understanding|Natural Language Understanding]] [[categories/cs.CL|cs.CL]] [[2025-09-22/Predicting Language Models' Success at Zero-Shot Probabilistic Prediction_20250922|Predicting Language Models' Success at Zero-Shot Probabilistic Prediction]] (84.7% similar) [[2025-09-19/Large Multi-modal Models Can Interpret Features in Large Multi-modal Models_20250919|Large Multi-modal Models Can Interpret Features in Large Multi-modal Models]] (84.3% similar) [[2025-09-22/Exploring Fine-Tuning of Large Audio Language Models for Spoken Language Understanding under Limited Speech data_20250922|Exploring Fine-Tuning of Large Audio Language Models for Spoken Language Understanding under Limited Speech data]] (84.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: Zero-shot Learning, Few-shot Learning
**ğŸ”¬ Broad Technical**: Multimodal Large Language Models, Natural Language Understanding
**â­ Unique Technical**: Collaborative Gating Fusion Module
## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Predicting Language Models' Success at Zero-Shot Probabilistic Prediction_20250922|Predicting Language Models' Success at Zero-Shot Probabilistic Prediction]] (84.7% similar)
- [[2025-09-19/Large Multi-modal Models Can Interpret Features in Large Multi-modal Models_20250919|Large Multi-modal Models Can Interpret Features in Large Multi-modal Models]] (84.3% similar)
- [[2025-09-22/Exploring Fine-Tuning of Large Audio Language Models for Spoken Language Understanding under Limited Speech data_20250922|Exploring Fine-Tuning of Large Audio Language Models for Spoken Language Understanding under Limited Speech data]] (84.2% similar)
- [[2025-09-19/Decoupled Proxy Alignment_ Mitigating Language Prior Conflict for Multimodal Alignment in MLLM_20250919|Decoupled Proxy Alignment Mitigating Language Prior Conflict for Multimodal Alignment in MLLM]] (84.1% similar)
- [[2025-09-22/Beyond Spurious Signals_ Debiasing Multimodal Large Language Models via Counterfactual Inference and Adaptive Expert Routing_20250922|Beyond Spurious Signals Debiasing Multimodal Large Language Models via Counterfactual Inference and Adaptive Expert Routing]] (83.8% similar)


**ArXiv ID**: [2509.15476](https://arxiv.org/abs/2509.15476)
**Published**: 2025-09-22
**Category**: cs.CL
**PDF**: [Download](https://arxiv.org/pdf/2509.15476.pdf)


**ArXiv ID**: [2509.15476](https://arxiv.org/abs/2509.15476)
**Published**: 2025-09-22
**Category**: cs.CL
**PDF**: [Download](https://arxiv.org/pdf/2509.15476.pdf)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Cross-lingual Sarcasm Understanding
**ğŸ”— Specific Connectable**: Few-shot Learning, Collaborative Gating Fusion
**ğŸ”¬ Broad Technical**: Multimodal Large Language Models, Natural Language Understanding

## ğŸ·ï¸ ì¶”ì¶œëœ í‚¤ì›Œë“œ



`Multimodal Large Language Models` â€¢ 

`Natural Language Understanding` â€¢ 

`Zero-shot Learning` â€¢ 

`Few-shot Learning` â€¢ 

`Collaborative Gating Fusion Module`



## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸

Similar papers will be displayed here based on embedding similarity.

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15476v1 Announce Type: new 
Abstract: Sarcasm detection remains a challenge in natural language understanding, as sarcastic intent often relies on subtle cross-modal cues spanning text, speech, and vision. While prior work has primarily focused on textual or visual-textual sarcasm, comprehensive audio-visual-textual sarcasm understanding remains underexplored. In this paper, we systematically evaluate large language models (LLMs) and multimodal LLMs for sarcasm detection on English (MUStARD++) and Chinese (MCSD 1.0) in zero-shot, few-shot, and LoRA fine-tuning settings. In addition to direct classification, we explore models as feature encoders, integrating their representations through a collaborative gating fusion module. Experimental results show that audio-based models achieve the strongest unimodal performance, while text-audio and audio-vision combinations outperform unimodal and trimodal models. Furthermore, MLLMs such as Qwen-Omni show competitive zero-shot and fine-tuned performance. Our findings highlight the potential of MLLMs for cross-lingual, audio-visual-textual sarcasm understanding.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15476v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: í’ì ê°ì§€(sarcasm detection)ëŠ” ìì—°ì–´ ì´í•´ì—ì„œ ì—¬ì „íˆ ë„ì „ ê³¼ì œë¡œ ë‚¨ì•„ ìˆìœ¼ë©°, í’ìì  ì˜ë„ëŠ” ì¢…ì¢… í…ìŠ¤íŠ¸, ìŒì„± ë° ì‹œê°ì„ ì•„ìš°ë¥´ëŠ” ë¯¸ë¬˜í•œ êµì°¨ ëª¨ë‹¬ ë‹¨ì„œì— ì˜ì¡´í•©ë‹ˆë‹¤. ì´ì „ ì—°êµ¬ëŠ” ì£¼ë¡œ í…ìŠ¤íŠ¸ ë˜ëŠ” ì‹œê°-í…ìŠ¤íŠ¸ í’ìì— ì´ˆì ì„ ë§ì¶°ì™”ìœ¼ë‚˜, í¬ê´„ì ì¸ ì˜¤ë””ì˜¤-ë¹„ì£¼ì–¼-í…ìŠ¤íŠ¸ í’ì ì´í•´ëŠ” ì—¬ì „íˆ ì¶©ë¶„íˆ íƒêµ¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì˜ì–´(MUStARD++)ì™€ ì¤‘êµ­ì–´(MCSD 1.0)ì— ëŒ€í•´ ì œë¡œìƒ·, ëª‡ìƒ·, LoRA ë¯¸ì„¸ ì¡°ì • ì„¤ì •ì—ì„œ í’ì ê°ì§€ë¥¼ ìœ„í•œ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ê³¼ ë‹¤ì¤‘ ëª¨ë‹¬ LLMì„ ì²´ê³„ì ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤. ì§ì ‘ ë¶„ë¥˜ ì™¸ì—ë„, ìš°ë¦¬ëŠ” ëª¨ë¸ì„ íŠ¹ì§• ì¸ì½”ë”ë¡œ í™œìš©í•˜ì—¬ í˜‘ë ¥ì  ê²Œì´íŒ… ìœµí•© ëª¨ë“ˆì„ í†µí•´ ê·¸ë“¤ì˜ í‘œí˜„ì„ í†µí•©í•˜ëŠ” ë°©ë²•ì„ íƒêµ¬í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼ì— ë”°ë¥´ë©´, ì˜¤ë””ì˜¤ ê¸°ë°˜ ëª¨ë¸ì´ ê°€ì¥ ê°•ë ¥í•œ ë‹¨ì¼ ëª¨ë‹¬ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ë©°, í…ìŠ¤íŠ¸-ì˜¤ë””ì˜¤ ë° ì˜¤ë””ì˜¤-ë¹„ì „ ì¡°í•©ì´ ë‹¨ì¼ ëª¨ë‹¬ ë° ì‚¼ì¤‘ ëª¨ë‹¬ ëª¨ë¸ì„ ëŠ¥ê°€í•©ë‹ˆë‹¤. ë˜í•œ, Qwen-Omniì™€ ê°™ì€ MLLMì€ ê²½ìŸë ¥ ìˆëŠ” ì œë¡œìƒ· ë° ë¯¸ì„¸ ì¡°ì • ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì—°êµ¬ ê²°ê³¼ëŠ” MLLMì´ êµì°¨ ì–¸ì–´, ì˜¤ë””ì˜¤-ë¹„ì£¼ì–¼-í…ìŠ¤íŠ¸ í’ì ì´í•´ì— ì ì¬ë ¥ì´ ìˆìŒì„ ê°•ì¡°í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ìì—°ì–´ ì´í•´ì—ì„œì˜ í’ì ê°ì§€ ë¬¸ì œë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. ê¸°ì¡´ ì—°êµ¬ëŠ” ì£¼ë¡œ í…ìŠ¤íŠ¸ë‚˜ ì‹œê°-í…ìŠ¤íŠ¸ í’ìì— ì§‘ì¤‘í–ˆì§€ë§Œ, ì´ ë…¼ë¬¸ì€ ì˜¤ë””ì˜¤-ë¹„ì£¼ì–¼-í…ìŠ¤íŠ¸ í’ì ì´í•´ë¥¼ í¬ê´„ì ìœ¼ë¡œ íƒêµ¬í•©ë‹ˆë‹¤. ì˜ì–´(MUStARD++)ì™€ ì¤‘êµ­ì–´(MCSD 1.0) ë°ì´í„°ì…‹ì—ì„œ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ê³¼ ë©€í‹°ëª¨ë‹¬ LLMì„ ì‚¬ìš©í•˜ì—¬ ì œë¡œìƒ·, í“¨ìƒ·, LoRA ë¯¸ì„¸ ì¡°ì • ì„¤ì •ì—ì„œ í’ì ê°ì§€ë¥¼ í‰ê°€í–ˆìŠµë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì˜¤ë””ì˜¤ ê¸°ë°˜ ëª¨ë¸ì´ ê°€ì¥ ê°•ë ¥í•œ ë‹¨ì¼ ëª¨ë‹¬ ì„±ëŠ¥ì„ ë³´ì˜€ê³ , í…ìŠ¤íŠ¸-ì˜¤ë””ì˜¤ ë° ì˜¤ë””ì˜¤-ë¹„ì „ ì¡°í•©ì´ ë‹¨ì¼ ë° ì‚¼ì¤‘ ëª¨ë‹¬ ëª¨ë¸ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë‚˜íƒ€ëƒˆìŠµë‹ˆë‹¤. ë˜í•œ, Qwen-Omniì™€ ê°™ì€ MLLMì€ ê²½ìŸë ¥ ìˆëŠ” ì œë¡œìƒ· ë° ë¯¸ì„¸ ì¡°ì • ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” MLLMì˜ ë‹¤êµ­ì–´ ì˜¤ë””ì˜¤-ë¹„ì£¼ì–¼-í…ìŠ¤íŠ¸ í’ì ì´í•´ ê°€ëŠ¥ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸


- 1. í’ì ê°ì§€ì—ì„œ ìŒì„± ê¸°ë°˜ ëª¨ë¸ì´ ê°€ì¥ ê°•ë ¥í•œ ë‹¨ì¼ ëª¨ë‹¬ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤.

- 2. í…ìŠ¤íŠ¸-ì˜¤ë””ì˜¤ ë° ì˜¤ë””ì˜¤-ë¹„ì „ ì¡°í•©ì´ ë‹¨ì¼ ëª¨ë‹¬ ë° ì‚¼ì¤‘ ëª¨ë‹¬ ëª¨ë¸ë³´ë‹¤ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë°œíœ˜í•œë‹¤.

- 3. Qwen-Omniì™€ ê°™ì€ ë‹¤ì¤‘ ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(MLLMs)ì´ ì œë¡œìƒ· ë° ë¯¸ì„¸ ì¡°ì • ì„±ëŠ¥ì—ì„œ ê²½ìŸë ¥ì„ ë³´ì¸ë‹¤.

- 4. MLLMsëŠ” êµì°¨ ì–¸ì–´, ì˜¤ë””ì˜¤-ë¹„ì£¼ì–¼-í…ìŠ¤íŠ¸ í’ì ì´í•´ì— ì ì¬ë ¥ì„ ê°€ì§€ê³  ìˆë‹¤.

- 5. í˜‘ë ¥ ê²Œì´íŒ… ìœµí•© ëª¨ë“ˆì„ í†µí•´ ëª¨ë¸ì˜ í‘œí˜„ì„ í†µí•©í•˜ì—¬ í’ì ê°ì§€ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¨ë‹¤.


---

*Generated on 2025-09-22 16:21:32*