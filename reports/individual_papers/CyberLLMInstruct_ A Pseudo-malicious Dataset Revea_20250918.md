
# CyberLLMInstruct: A Pseudo-malicious Dataset Revealing Safety-performance Trade-offs in Cyber Security LLM Fine-tuning

**Korean Title:** ì‚¬ì´ë²„ LLMInstruct: ì‚¬ì´ë²„ ë³´ì•ˆ LLM íŒŒì¸ íŠœë‹ì—ì„œ ì•ˆì „ì„±-ì„±ëŠ¥ íŠ¸ë ˆì´ë“œ ì˜¤í”„ë¥¼ ë“œëŸ¬ë‚´ëŠ” ê°€ì§œ ì•…ì„± ë°ì´í„°ì…‹.

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-18|2025-09-18]] [[keywords/evolved/Safety-performance Trade-offs|Safety-performance Trade-offs]] [[keywords/broad/Large Language Models|Large Language Models]] [[keywords/broad/Cyber Security|Cyber Security]] [[keywords/specific/Fine-tuning|Fine-tuning]] [[keywords/unique/CyberLLMInstruct|CyberLLMInstruct]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Safety-performance Trade-offs
**ğŸ”¬ Broad Technical**: Large Language Models, Cyber Security
**ğŸ”— Specific Connectable**: Fine-tuning
**â­ Unique Technical**: CyberLLMInstruct

**ArXiv ID**: [2503.09334](https://arxiv.org/abs/2503.09334)
**Published**: 2025-09-18
**Category**: cs.AI
**PDF**: [Download](https://arxiv.org/pdf/2503.09334.pdf)


## ğŸ·ï¸ ì¶”ì¶œëœ í‚¤ì›Œë“œ



`Large Language Models` â€¢ 

`Fine-tuning` â€¢ 

`Malware Analysis` â€¢ 

`CyberLLMInstruct` â€¢ 

`Safety-performance Trade-offs`



## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2503.09334v3 Announce Type: replace-cross 
Abstract: The integration of large language models (LLMs) into cyber security applications presents both opportunities and critical safety risks. We introduce CyberLLMInstruct, a dataset of 54,928 pseudo-malicious instruction-response pairs spanning cyber security tasks including malware analysis, phishing simulations, and zero-day vulnerabilities. Our comprehensive evaluation using seven open-source LLMs reveals a critical trade-off: while fine-tuning improves cyber security task performance (achieving up to 92.50% accuracy on CyberMetric), it severely compromises safety resilience across all tested models and attack vectors (e.g., Llama 3.1 8B's security score against prompt injection drops from 0.95 to 0.15). The dataset incorporates diverse sources including CTF challenges, academic papers, industry reports, and CVE databases to ensure comprehensive coverage of cyber security domains. Our findings highlight the unique challenges of securing LLMs in adversarial domains and establish the critical need for developing fine-tuning methodologies that balance performance gains with safety preservation in security-sensitive domains.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2503.09334v3 ë°œí‘œ ìœ í˜•: replace-cross
ìš”ì•½: ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ (LLMs)ì„ ì‚¬ì´ë²„ ë³´ì•ˆ ì‘ìš© í”„ë¡œê·¸ë¨ì— í†µí•©í•˜ëŠ” ê²ƒì€ ê¸°íšŒì™€ ì¤‘ìš”í•œ ì•ˆì „ ìœ„í—˜ì„ ë™ì‹œì— ì œì‹œí•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì‚¬ì´ë²„ ë³´ì•ˆ ì‘ì—…ì„ í¬í•¨í•œ 54,928ê°œì˜ ê°€ì§œ ì•…ì„± ëª…ë ¹-ì‘ë‹µ ìŒìœ¼ë¡œ ì´ë£¨ì–´ì§„ CyberLLMInstruct ë°ì´í„°ì…‹ì„ ì†Œê°œí•©ë‹ˆë‹¤. ì´ ë°ì´í„°ì…‹ì€ ì•…ì„± ì½”ë“œ ë¶„ì„, í”¼ì‹± ì‹œë®¬ë ˆì´ì…˜, ê·¸ë¦¬ê³  ì œë¡œë°ì´ ì·¨ì•½ì ì„ í¬í•¨í•œ ì‚¬ì´ë²„ ë³´ì•ˆ ì‘ì—…ì„ ë‹¤ë£¹ë‹ˆë‹¤. ì¼ê³± ê°œì˜ ì˜¤í”ˆ ì†ŒìŠ¤ LLMì„ ì‚¬ìš©í•œ í¬ê´„ì ì¸ í‰ê°€ ê²°ê³¼, ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” íŒŒì¸íŠœë‹ì€ ì‚¬ì´ë²„ ë³´ì•ˆ ì‘ì—… ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ì§€ë§Œ (CyberMetricì—ì„œ ìµœëŒ€ 92.50%ì˜ ì •í™•ë„ ë‹¬ì„±), ëª¨ë“  í…ŒìŠ¤íŠ¸ëœ ëª¨ë¸ê³¼ ê³µê²© ë²¡í„° (ì˜ˆ: Llama 3.1 8Bì˜ í”„ë¡¬í”„íŠ¸ ì‚½ì…ì— ëŒ€í•œ ë³´ì•ˆ ì ìˆ˜ê°€ 0.95ì—ì„œ 0.15ë¡œ í•˜ë½)ì— ëŒ€í•œ ì•ˆì „ì„± ë‚´ì„±ì„ ì‹¬ê°í•˜ê²Œ ì €í•´í•©ë‹ˆë‹¤. ì´ ë°ì´í„°ì…‹ì€ CTF ì±Œë¦°ì§€, í•™ìˆ  ë…¼ë¬¸, ì‚°ì—… ë³´ê³ ì„œ, ê·¸ë¦¬ê³  CVE ë°ì´í„°ë² ì´ìŠ¤ë¥¼ í¬í•¨í•œ ë‹¤ì–‘í•œ ì¶œì²˜ë¥¼ í†µí•©í•˜ì—¬ ì‚¬ì´ë²„ ë³´ì•ˆ ë„ë©”ì¸ì˜ í¬ê´„ì ì¸ ì»¤ë²„ë¦¬ì§€ë¥¼ ë³´ì¥í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì—°êµ¬ ê²°ê³¼ëŠ” ì ëŒ€ì  ë„ë©”ì¸ì—ì„œ LLMì˜ ë³´ì•ˆì„ í™•ë³´í•˜ëŠ” ë…íŠ¹í•œ ë„ì „ ê³¼ì œë¥¼ ê°•ì¡°í•˜ë©°, ë³´ì•ˆ ë¯¼ê°í•œ ë„ë©”ì¸ì—ì„œ ì„±ëŠ¥ í–¥ìƒê³¼ ì•ˆì „ ë³´ì¡´ì„ ê· í˜•ìˆê²Œ ì œê³µí•˜ëŠ” íŒŒì¸íŠœë‹ ë°©ë²•ë¡ ì˜ ì¤‘ìš”ì„±ì„ í™•ë¦½í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ë³¸ ì—°êµ¬ëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(Large Language Models, LLMs)ì„ ì‚¬ì´ë²„ ë³´ì•ˆ ì‘ìš© í”„ë¡œê·¸ë¨ì— í†µí•©í•˜ëŠ” ê²ƒì´ ê¸°íšŒì™€ ì¤‘ìš”í•œ ì•ˆì „ ìœ„í—˜ì„ ë™ì‹œì— ì œê³µí•œë‹¤ëŠ” ê²ƒì„ ì†Œê°œí•œë‹¤. ìš°ë¦¬ëŠ” ì‚¬ì´ë²„ ë³´ì•ˆ ì‘ì—…ì„ í¬í•¨í•œ 54,928ê°œì˜ ê°€ì§œ ì•…ì„± ëª…ë ¹-ì‘ë‹µ ìŒìœ¼ë¡œ ì´ë£¨ì–´ì§„ CyberLLMInstruct ë°ì´í„°ì…‹ì„ ì†Œê°œí•œë‹¤. ìš°ë¦¬ì˜ í¬ê´„ì ì¸ í‰ê°€ëŠ” 7ê°œì˜ ì˜¤í”ˆ ì†ŒìŠ¤ LLMsë¥¼ ì‚¬ìš©í•˜ì—¬ ì¤‘ìš”í•œ íŠ¸ë ˆì´ë“œ ì˜¤í”„ë¥¼ ë³´ì—¬ì¤€ë‹¤: íŒŒì¸íŠœë‹ì€ ì‚¬ì´ë²„ ë³´ì•ˆ ì‘ì—… ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ì§€ë§Œ(ì˜ˆ: CyberMetricì—ì„œ ìµœëŒ€ 92.50%ì˜ ì •í™•ë„ ë‹¬ì„±), ëª¨ë“  í…ŒìŠ¤íŠ¸ëœ ëª¨ë¸ê³¼ ê³µê²© ë²¡í„°(ì˜ˆ: Llama 3.1 8Bì˜ í”„ë¡¬í”„íŠ¸ ì‚½ì…ì— ëŒ€í•œ ë³´ì•ˆ ì ìˆ˜ê°€ 0.95ì—ì„œ 0.15ë¡œ í•˜ë½)ì— ê±¸ì³ ì•ˆì „ì„± ë‚´ì„±ì„ ì‹¬ê°í•˜ê²Œ ì €í•´í•œë‹¤. ì´ ë°ì´í„°ì…‹ì€ CTF ë„ì „, í•™ìˆ  ë…¼ë¬¸, ì‚°ì—… ë³´ê³ ì„œ ë° CVE ë°ì´í„°ë² ì´ìŠ¤ì™€ ê°™ì€ ë‹¤ì–‘í•œ ì†ŒìŠ¤ë¥¼ í†µí•©í•˜ì—¬ ì‚¬ì´ë²„ ë³´ì•ˆ ë„ë©”ì¸ì˜ í¬ê´„ì ì¸ ì»¤ë²„ë¦¬ì§€ë¥¼ ë³´ì¥í•œë‹¤. ìš°ë¦¬ì˜ ì—°êµ¬ ê²°ê³¼ëŠ” ì ëŒ€ì  ë„ë©”ì¸ì—ì„œ LLMsë¥¼ ì•ˆì „í•˜ê²Œ ë³´í˜¸í•˜ëŠ” ë™ì‹œì— ì„±ëŠ¥ í–¥ìƒì„ ê· í˜•ìˆê²Œ ìœ ì§€í•˜ëŠ” íŒŒì¸íŠœë‹ ë°©ë²•ë¡ ì˜ ì¤‘ìš”ì„±ì„ ê°•ì¡°í•œë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸


- ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ ì‚¬ì´ë²„ ë³´ì•ˆ ì‘ìš© í”„ë¡œê·¸ë¨ì— í†µí•©í•˜ëŠ” ê²ƒì€ ê¸°íšŒì™€ ì¤‘ìš”í•œ ì•ˆì „ ìœ„í—˜ì„ ì œì‹œí•œë‹¤.

- CyberLLMInstructëŠ” ì•…ì„± ëª…ë ¹-ì‘ë‹µ ìŒì„ í¬í•¨í•œ ì‚¬ì´ë²„ ë³´ì•ˆ ì‘ì—…ì„ ìœ„í•œ ë°ì´í„° ì„¸íŠ¸ë¥¼ ì†Œê°œí•œë‹¤.

- ì„¸ë¶„í™”ëŠ” ì‚¬ì´ë²„ ë³´ì•ˆ ì‘ì—… ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ì§€ë§Œ ëª¨ë“  í…ŒìŠ¤íŠ¸ëœ ëª¨ë¸ê³¼ ê³µê²© ë²¡í„°ì—ì„œ ì•ˆì „ì„± ì €í•­ë ¥ì„ ì‹¬ê°í•˜ê²Œ ì €í•´í•œë‹¤.


---

*Generated on 2025-09-18 16:31:33*