
# CyberLLMInstruct: A Pseudo-malicious Dataset Revealing Safety-performance Trade-offs in Cyber Security LLM Fine-tuning

**Korean Title:** 사이버 LLMInstruct: 사이버 보안 LLM 파인 튜닝에서 안전성-성능 트레이드 오프를 드러내는 가짜 악성 데이터셋.

## 📋 메타데이터

**Links**: [[daily/2025-09-18|2025-09-18]] [[keywords/evolved/Safety-performance Trade-offs|Safety-performance Trade-offs]] [[keywords/broad/Large Language Models|Large Language Models]] [[keywords/broad/Cyber Security|Cyber Security]] [[keywords/specific/Fine-tuning|Fine-tuning]] [[keywords/unique/CyberLLMInstruct|CyberLLMInstruct]] [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Safety-performance Trade-offs
**🔬 Broad Technical**: Large Language Models, Cyber Security
**🔗 Specific Connectable**: Fine-tuning
**⭐ Unique Technical**: CyberLLMInstruct

**ArXiv ID**: [2503.09334](https://arxiv.org/abs/2503.09334)
**Published**: 2025-09-18
**Category**: cs.AI
**PDF**: [Download](https://arxiv.org/pdf/2503.09334.pdf)


## 🏷️ 추출된 키워드



`Large Language Models` • 

`Fine-tuning` • 

`Malware Analysis` • 

`CyberLLMInstruct` • 

`Safety-performance Trade-offs`



## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2503.09334v3 Announce Type: replace-cross 
Abstract: The integration of large language models (LLMs) into cyber security applications presents both opportunities and critical safety risks. We introduce CyberLLMInstruct, a dataset of 54,928 pseudo-malicious instruction-response pairs spanning cyber security tasks including malware analysis, phishing simulations, and zero-day vulnerabilities. Our comprehensive evaluation using seven open-source LLMs reveals a critical trade-off: while fine-tuning improves cyber security task performance (achieving up to 92.50% accuracy on CyberMetric), it severely compromises safety resilience across all tested models and attack vectors (e.g., Llama 3.1 8B's security score against prompt injection drops from 0.95 to 0.15). The dataset incorporates diverse sources including CTF challenges, academic papers, industry reports, and CVE databases to ensure comprehensive coverage of cyber security domains. Our findings highlight the unique challenges of securing LLMs in adversarial domains and establish the critical need for developing fine-tuning methodologies that balance performance gains with safety preservation in security-sensitive domains.

## 🔍 Abstract (한글 번역)

arXiv:2503.09334v3 발표 유형: replace-cross
요약: 대규모 언어 모델 (LLMs)을 사이버 보안 응용 프로그램에 통합하는 것은 기회와 중요한 안전 위험을 동시에 제시합니다. 우리는 사이버 보안 작업을 포함한 54,928개의 가짜 악성 명령-응답 쌍으로 이루어진 CyberLLMInstruct 데이터셋을 소개합니다. 이 데이터셋은 악성 코드 분석, 피싱 시뮬레이션, 그리고 제로데이 취약점을 포함한 사이버 보안 작업을 다룹니다. 일곱 개의 오픈 소스 LLM을 사용한 포괄적인 평가 결과, 성능을 향상시키는 파인튜닝은 사이버 보안 작업 성능을 향상시키지만 (CyberMetric에서 최대 92.50%의 정확도 달성), 모든 테스트된 모델과 공격 벡터 (예: Llama 3.1 8B의 프롬프트 삽입에 대한 보안 점수가 0.95에서 0.15로 하락)에 대한 안전성 내성을 심각하게 저해합니다. 이 데이터셋은 CTF 챌린지, 학술 논문, 산업 보고서, 그리고 CVE 데이터베이스를 포함한 다양한 출처를 통합하여 사이버 보안 도메인의 포괄적인 커버리지를 보장합니다. 우리의 연구 결과는 적대적 도메인에서 LLM의 보안을 확보하는 독특한 도전 과제를 강조하며, 보안 민감한 도메인에서 성능 향상과 안전 보존을 균형있게 제공하는 파인튜닝 방법론의 중요성을 확립합니다.

## 📝 요약

본 연구는 대형 언어 모델(Large Language Models, LLMs)을 사이버 보안 응용 프로그램에 통합하는 것이 기회와 중요한 안전 위험을 동시에 제공한다는 것을 소개한다. 우리는 사이버 보안 작업을 포함한 54,928개의 가짜 악성 명령-응답 쌍으로 이루어진 CyberLLMInstruct 데이터셋을 소개한다. 우리의 포괄적인 평가는 7개의 오픈 소스 LLMs를 사용하여 중요한 트레이드 오프를 보여준다: 파인튜닝은 사이버 보안 작업 성능을 향상시키지만(예: CyberMetric에서 최대 92.50%의 정확도 달성), 모든 테스트된 모델과 공격 벡터(예: Llama 3.1 8B의 프롬프트 삽입에 대한 보안 점수가 0.95에서 0.15로 하락)에 걸쳐 안전성 내성을 심각하게 저해한다. 이 데이터셋은 CTF 도전, 학술 논문, 산업 보고서 및 CVE 데이터베이스와 같은 다양한 소스를 통합하여 사이버 보안 도메인의 포괄적인 커버리지를 보장한다. 우리의 연구 결과는 적대적 도메인에서 LLMs를 안전하게 보호하는 동시에 성능 향상을 균형있게 유지하는 파인튜닝 방법론의 중요성을 강조한다.

## 🎯 주요 포인트


- 대규모 언어 모델을 사이버 보안 응용 프로그램에 통합하는 것은 기회와 중요한 안전 위험을 제시한다.

- CyberLLMInstruct는 악성 명령-응답 쌍을 포함한 사이버 보안 작업을 위한 데이터 세트를 소개한다.

- 세분화는 사이버 보안 작업 성능을 향상시키지만 모든 테스트된 모델과 공격 벡터에서 안전성 저항력을 심각하게 저해한다.


---

*Generated on 2025-09-18 16:31:33*