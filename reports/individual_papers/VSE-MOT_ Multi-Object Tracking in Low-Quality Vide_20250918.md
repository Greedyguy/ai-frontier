
# VSE-MOT: Multi-Object Tracking in Low-Quality Video Scenes Guided by Visual Semantic Enhancement

**Korean Title:** VSE-MOT: 시각적 의미 향상에 의해 안내되는 저품질 비디오 장면에서의 다중 객체 추적

## 📋 메타데이터

**Links**: [[daily/2025-09-18|2025-09-18]] [[keywords/evolved/Visual Semantic Enhancement|Visual Semantic Enhancement]] [[keywords/broad/Multi-Object Tracking|Multi-Object Tracking]] [[keywords/broad/Vision-Language Models|Vision-Language Models]] [[keywords/specific/Tri-branch Architecture|Tri-branch Architecture]] [[keywords/unique/VSE-MOT|VSE-MOT]] [[categories/cs.CV|cs.CV]]

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Visual Semantic Enhancement
**🔬 Broad Technical**: Multi-Object Tracking, Vision-Language Models
**🔗 Specific Connectable**: Tri-branch Architecture
**⭐ Unique Technical**: VSE-MOT

**ArXiv ID**: [2509.14060](https://arxiv.org/abs/2509.14060)
**Published**: 2025-09-18
**Category**: cs.CV
**PDF**: [Download](https://arxiv.org/pdf/2509.14060.pdf)


## 🏷️ 추출된 키워드



`Multi-Object Tracking` • 

`Vision-Language Model` • 

`Tri-branch Architecture` • 

`Visual Semantic Enhancement-guided Multi-Object Tracking framework (VSE-MOT` • 

`Visual Semantic Fusion Module (VSFM`



## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.14060v1 Announce Type: new 
Abstract: Current multi-object tracking (MOT) algorithms typically overlook issues inherent in low-quality videos, leading to significant degradation in tracking performance when confronted with real-world image deterioration. Therefore, advancing the application of MOT algorithms in real-world low-quality video scenarios represents a critical and meaningful endeavor. To address the challenges posed by low-quality scenarios, inspired by vision-language models, this paper proposes a Visual Semantic Enhancement-guided Multi-Object Tracking framework (VSE-MOT). Specifically, we first design a tri-branch architecture that leverages a vision-language model to extract global visual semantic information from images and fuse it with query vectors. Subsequently, to further enhance the utilization of visual semantic information, we introduce the Multi-Object Tracking Adapter (MOT-Adapter) and the Visual Semantic Fusion Module (VSFM). The MOT-Adapter adapts the extracted global visual semantic information to suit multi-object tracking tasks, while the VSFM improves the efficacy of feature fusion. Through extensive experiments, we validate the effectiveness and superiority of the proposed method in real-world low-quality video scenarios. Its tracking performance metrics outperform those of existing methods by approximately 8% to 20%, while maintaining robust performance in conventional scenarios.

## 🔍 Abstract (한글 번역)

arXiv:2509.14060v1 발표 유형: 새로운
요약: 현재의 다중 객체 추적 (MOT) 알고리즘은 일반적으로 저품질 비디오에 내재된 문제를 간과하여, 실제 이미지의 저하에 직면했을 때 추적 성능이 크게 저하되는 문제가 발생합니다. 따라서 MOT 알고리즘의 응용을 실제 세계의 저품질 비디오 시나리오에서 발전시키는 것은 중요하고 의미 있는 노력입니다. 저품질 시나리오에서 제기되는 문제에 대응하기 위해, 이 논문은 시각-언어 모델에서 영감을 받아 Visual Semantic Enhancement-guided Multi-Object Tracking 프레임워크 (VSE-MOT)를 제안합니다. 구체적으로, 우리는 먼저 비전-언어 모델을 활용하여 이미지에서 전역 시각 의미 정보를 추출하고 이를 쿼리 벡터와 융합하는 tri-branch 아키텍처를 설계합니다. 이후, 시각 의미 정보의 활용을 더욱 향상시키기 위해 Multi-Object Tracking Adapter (MOT-Adapter)와 Visual Semantic Fusion Module (VSFM)을 소개합니다. MOT-Adapter는 추출된 전역 시각 의미 정보를 다중 객체 추적 작업에 맞게 조정하고, VSFM은 특징 융합의 효과를 향상시킵니다. 다양한 실험을 통해, 우리는 제안된 방법의 효과성과 우수성을 실제 세계의 저품질 비디오 시나리오에서 검증합니다. 해당 추적 성능 지표는 기존 방법들보다 약 8%에서 20% 정도 우수하며, 전통적인 시나리오에서 견고한 성능을 유지합니다.

## 📝 요약

본 논문은 저화질 비디오에서 발생하는 문제를 해결하기 위해 시각-언어 모델에 영감을 받아 Visual Semantic Enhancement-guided Multi-Object Tracking(VSE-MOT) 프레임워크를 제안한다. VSE-MOT는 시각-언어 모델을 활용하여 전역 시각 의미 정보를 추출하고 쿼리 벡터와 융합하는 tri-branch 아키텍처를 설계한다. 또한, Multi-Object Tracking Adapter(MOT-Adapter)와 Visual Semantic Fusion Module(VSFM)을 도입하여 시각 의미 정보의 활용성을 향상시킨다. 실험 결과, VSE-MOT은 기존 방법들보다 약 8%에서 20%의 성능 향상을 보여주며 전통적인 시나리오에서도 강력한 성능을 유지한다.

## 🎯 주요 포인트


- 1. 저품질 비디오에서의 다중 객체 추적 알고리즘의 성능 저하 문제를 해결하기 위해 Visual Semantic Enhancement-guided Multi-Object Tracking framework (VSE-MOT) 제안

- 2. Vision-language 모델을 활용하여 전역 시각 의미 정보를 추출하고 쿼리 벡터와 융합하는 tri-branch 아키텍처 설계

- 3. Multi-Object Tracking Adapter (MOT-Adapter) 및 Visual Semantic Fusion Module (VSFM) 도입으로 시각 의미 정보 활용성 향상 및 특징 융합 효과 향상

- 4. 제안된 방법은 저품질 비디오 시나리오에서 기존 방법보다 약 8% ~ 20% 우수한 추적 성능을 보여주며 전통적인 시나리오에서도 견고한 성능 유지.


---

*Generated on 2025-09-18 17:02:58*