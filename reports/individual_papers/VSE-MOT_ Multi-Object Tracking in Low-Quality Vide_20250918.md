
# VSE-MOT: Multi-Object Tracking in Low-Quality Video Scenes Guided by Visual Semantic Enhancement

**Korean Title:** VSE-MOT: ì‹œê°ì  ì˜ë¯¸ í–¥ìƒì— ì˜í•´ ì•ˆë‚´ë˜ëŠ” ì €í’ˆì§ˆ ë¹„ë””ì˜¤ ì¥ë©´ì—ì„œì˜ ë‹¤ì¤‘ ê°ì²´ ì¶”ì 

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-18|2025-09-18]] [[keywords/evolved/Visual Semantic Enhancement|Visual Semantic Enhancement]] [[keywords/broad/Multi-Object Tracking|Multi-Object Tracking]] [[keywords/broad/Vision-Language Models|Vision-Language Models]] [[keywords/specific/Tri-branch Architecture|Tri-branch Architecture]] [[keywords/unique/VSE-MOT|VSE-MOT]] [[categories/cs.CV|cs.CV]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Visual Semantic Enhancement
**ğŸ”¬ Broad Technical**: Multi-Object Tracking, Vision-Language Models
**ğŸ”— Specific Connectable**: Tri-branch Architecture
**â­ Unique Technical**: VSE-MOT

**ArXiv ID**: [2509.14060](https://arxiv.org/abs/2509.14060)
**Published**: 2025-09-18
**Category**: cs.CV
**PDF**: [Download](https://arxiv.org/pdf/2509.14060.pdf)


## ğŸ·ï¸ ì¶”ì¶œëœ í‚¤ì›Œë“œ



`Multi-Object Tracking` â€¢ 

`Vision-Language Model` â€¢ 

`Tri-branch Architecture` â€¢ 

`Visual Semantic Enhancement-guided Multi-Object Tracking framework (VSE-MOT` â€¢ 

`Visual Semantic Fusion Module (VSFM`



## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.14060v1 Announce Type: new 
Abstract: Current multi-object tracking (MOT) algorithms typically overlook issues inherent in low-quality videos, leading to significant degradation in tracking performance when confronted with real-world image deterioration. Therefore, advancing the application of MOT algorithms in real-world low-quality video scenarios represents a critical and meaningful endeavor. To address the challenges posed by low-quality scenarios, inspired by vision-language models, this paper proposes a Visual Semantic Enhancement-guided Multi-Object Tracking framework (VSE-MOT). Specifically, we first design a tri-branch architecture that leverages a vision-language model to extract global visual semantic information from images and fuse it with query vectors. Subsequently, to further enhance the utilization of visual semantic information, we introduce the Multi-Object Tracking Adapter (MOT-Adapter) and the Visual Semantic Fusion Module (VSFM). The MOT-Adapter adapts the extracted global visual semantic information to suit multi-object tracking tasks, while the VSFM improves the efficacy of feature fusion. Through extensive experiments, we validate the effectiveness and superiority of the proposed method in real-world low-quality video scenarios. Its tracking performance metrics outperform those of existing methods by approximately 8% to 20%, while maintaining robust performance in conventional scenarios.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.14060v1 ë°œí‘œ ìœ í˜•: ìƒˆë¡œìš´
ìš”ì•½: í˜„ì¬ì˜ ë‹¤ì¤‘ ê°ì²´ ì¶”ì  (MOT) ì•Œê³ ë¦¬ì¦˜ì€ ì¼ë°˜ì ìœ¼ë¡œ ì €í’ˆì§ˆ ë¹„ë””ì˜¤ì— ë‚´ì¬ëœ ë¬¸ì œë¥¼ ê°„ê³¼í•˜ì—¬, ì‹¤ì œ ì´ë¯¸ì§€ì˜ ì €í•˜ì— ì§ë©´í–ˆì„ ë•Œ ì¶”ì  ì„±ëŠ¥ì´ í¬ê²Œ ì €í•˜ë˜ëŠ” ë¬¸ì œê°€ ë°œìƒí•©ë‹ˆë‹¤. ë”°ë¼ì„œ MOT ì•Œê³ ë¦¬ì¦˜ì˜ ì‘ìš©ì„ ì‹¤ì œ ì„¸ê³„ì˜ ì €í’ˆì§ˆ ë¹„ë””ì˜¤ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ë°œì „ì‹œí‚¤ëŠ” ê²ƒì€ ì¤‘ìš”í•˜ê³  ì˜ë¯¸ ìˆëŠ” ë…¸ë ¥ì…ë‹ˆë‹¤. ì €í’ˆì§ˆ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì œê¸°ë˜ëŠ” ë¬¸ì œì— ëŒ€ì‘í•˜ê¸° ìœ„í•´, ì´ ë…¼ë¬¸ì€ ì‹œê°-ì–¸ì–´ ëª¨ë¸ì—ì„œ ì˜ê°ì„ ë°›ì•„ Visual Semantic Enhancement-guided Multi-Object Tracking í”„ë ˆì„ì›Œí¬ (VSE-MOT)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. êµ¬ì²´ì ìœ¼ë¡œ, ìš°ë¦¬ëŠ” ë¨¼ì € ë¹„ì „-ì–¸ì–´ ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ì´ë¯¸ì§€ì—ì„œ ì „ì—­ ì‹œê° ì˜ë¯¸ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³  ì´ë¥¼ ì¿¼ë¦¬ ë²¡í„°ì™€ ìœµí•©í•˜ëŠ” tri-branch ì•„í‚¤í…ì²˜ë¥¼ ì„¤ê³„í•©ë‹ˆë‹¤. ì´í›„, ì‹œê° ì˜ë¯¸ ì •ë³´ì˜ í™œìš©ì„ ë”ìš± í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ Multi-Object Tracking Adapter (MOT-Adapter)ì™€ Visual Semantic Fusion Module (VSFM)ì„ ì†Œê°œí•©ë‹ˆë‹¤. MOT-AdapterëŠ” ì¶”ì¶œëœ ì „ì—­ ì‹œê° ì˜ë¯¸ ì •ë³´ë¥¼ ë‹¤ì¤‘ ê°ì²´ ì¶”ì  ì‘ì—…ì— ë§ê²Œ ì¡°ì •í•˜ê³ , VSFMì€ íŠ¹ì§• ìœµí•©ì˜ íš¨ê³¼ë¥¼ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ë‹¤ì–‘í•œ ì‹¤í—˜ì„ í†µí•´, ìš°ë¦¬ëŠ” ì œì•ˆëœ ë°©ë²•ì˜ íš¨ê³¼ì„±ê³¼ ìš°ìˆ˜ì„±ì„ ì‹¤ì œ ì„¸ê³„ì˜ ì €í’ˆì§ˆ ë¹„ë””ì˜¤ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ê²€ì¦í•©ë‹ˆë‹¤. í•´ë‹¹ ì¶”ì  ì„±ëŠ¥ ì§€í‘œëŠ” ê¸°ì¡´ ë°©ë²•ë“¤ë³´ë‹¤ ì•½ 8%ì—ì„œ 20% ì •ë„ ìš°ìˆ˜í•˜ë©°, ì „í†µì ì¸ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ê²¬ê³ í•œ ì„±ëŠ¥ì„ ìœ ì§€í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ë³¸ ë…¼ë¬¸ì€ ì €í™”ì§ˆ ë¹„ë””ì˜¤ì—ì„œ ë°œìƒí•˜ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì‹œê°-ì–¸ì–´ ëª¨ë¸ì— ì˜ê°ì„ ë°›ì•„ Visual Semantic Enhancement-guided Multi-Object Tracking(VSE-MOT) í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•œë‹¤. VSE-MOTëŠ” ì‹œê°-ì–¸ì–´ ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ì „ì—­ ì‹œê° ì˜ë¯¸ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³  ì¿¼ë¦¬ ë²¡í„°ì™€ ìœµí•©í•˜ëŠ” tri-branch ì•„í‚¤í…ì²˜ë¥¼ ì„¤ê³„í•œë‹¤. ë˜í•œ, Multi-Object Tracking Adapter(MOT-Adapter)ì™€ Visual Semantic Fusion Module(VSFM)ì„ ë„ì…í•˜ì—¬ ì‹œê° ì˜ë¯¸ ì •ë³´ì˜ í™œìš©ì„±ì„ í–¥ìƒì‹œí‚¨ë‹¤. ì‹¤í—˜ ê²°ê³¼, VSE-MOTì€ ê¸°ì¡´ ë°©ë²•ë“¤ë³´ë‹¤ ì•½ 8%ì—ì„œ 20%ì˜ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì—¬ì£¼ë©° ì „í†µì ì¸ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œë„ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ìœ ì§€í•œë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸


- 1. ì €í’ˆì§ˆ ë¹„ë””ì˜¤ì—ì„œì˜ ë‹¤ì¤‘ ê°ì²´ ì¶”ì  ì•Œê³ ë¦¬ì¦˜ì˜ ì„±ëŠ¥ ì €í•˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ Visual Semantic Enhancement-guided Multi-Object Tracking framework (VSE-MOT) ì œì•ˆ

- 2. Vision-language ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ì „ì—­ ì‹œê° ì˜ë¯¸ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³  ì¿¼ë¦¬ ë²¡í„°ì™€ ìœµí•©í•˜ëŠ” tri-branch ì•„í‚¤í…ì²˜ ì„¤ê³„

- 3. Multi-Object Tracking Adapter (MOT-Adapter) ë° Visual Semantic Fusion Module (VSFM) ë„ì…ìœ¼ë¡œ ì‹œê° ì˜ë¯¸ ì •ë³´ í™œìš©ì„± í–¥ìƒ ë° íŠ¹ì§• ìœµí•© íš¨ê³¼ í–¥ìƒ

- 4. ì œì•ˆëœ ë°©ë²•ì€ ì €í’ˆì§ˆ ë¹„ë””ì˜¤ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ê¸°ì¡´ ë°©ë²•ë³´ë‹¤ ì•½ 8% ~ 20% ìš°ìˆ˜í•œ ì¶”ì  ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ë©° ì „í†µì ì¸ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œë„ ê²¬ê³ í•œ ì„±ëŠ¥ ìœ ì§€.


---

*Generated on 2025-09-18 17:02:58*