# Do Retrieval Augmented Language Models Know When They Don't Know?

**Korean Title:** íšŒìˆ˜ ì¦ê°• ì–¸ì–´ ëª¨ë¸ì€ ìì‹ ì´ ëª¨ë¥´ëŠ” ê²ƒì„ ì•Œê³  ìˆëŠ”ê°€?

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: In-context Fine-tuning

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Search and Refine During Think_ Facilitating Knowledge Refinement for Improved Retrieval-Augmented Reasoning_20250922|Search and Refine During Think Facilitating Knowledge Refinement for Improved Retrieval-Augmented Reasoning]] (84.4% similar)
- [[2025-09-18/KBM_ Delineating Knowledge Boundary for Adaptive Retrieval in Large Language Models_20250918|KBM Delineating Knowledge Boundary for Adaptive Retrieval in Large Language Models]] (83.9% similar)
- [[2025-09-17/DSCC-HS_ A Dynamic Self-Reinforcing Framework for Hallucination Suppression in Large Language Models_20250917|DSCC-HS A Dynamic Self-Reinforcing Framework for Hallucination Suppression in Large Language Models]] (83.8% similar)
- [[2025-09-22/Efficient Real-time Refinement of Language Model Text Generation_20250922|Efficient Real-time Refinement of Language Model Text Generation]] (83.6% similar)
- [[2025-09-22/Knowledge-Driven Hallucination in Large Language Models_ An Empirical Study on Process Modeling_20250922|Knowledge-Driven Hallucination in Large Language Models An Empirical Study on Process Modeling]] (83.4% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.01476v2 Announce Type: replace-cross 
Abstract: Existing Large Language Models (LLMs) occasionally generate plausible yet factually incorrect responses, known as hallucinations. Researchers are primarily using two approaches to mitigate hallucinations, namely Retrieval Augmented Language Models (RALMs) and refusal post-training. However, current research predominantly emphasizes their individual effectiveness while overlooking the evaluation of the refusal capability of RALMs. In this study, we ask the fundamental question: Do RALMs know when they don't know? Specifically, we ask three questions. First, are RALMs well-calibrated regarding different internal and external knowledge states? We examine the influence of various factors. Contrary to expectations, we find that LLMs exhibit significant \textbf{over-refusal} behavior. Then, how does refusal post-training affect the over-refusal issue? We investigate the Refusal-aware Instruction Tuning and In-Context Fine-tuning methods. Our results show that the over-refusal problem is mitigated by In-context fine-tuning. but magnified by R-tuning. However, we also find that the refusal ability may conflict with the quality of the answer. Finally, we develop a simple yet effective refusal method for refusal post-trained models to improve their overall answer quality in terms of refusal and correct answers. Our study provides a more comprehensive understanding of the influence of important factors on RALM systems.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.01476v2 ë°œí‘œ ìœ í˜•: êµì°¨ ëŒ€ì²´  
ì´ˆë¡: ê¸°ì¡´ì˜ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì€ ë•Œë•Œë¡œ ê·¸ëŸ´ë“¯í•˜ì§€ë§Œ ì‚¬ì‹¤ê³¼ ë‹¤ë¥¸ ì‘ë‹µì„ ìƒì„±í•˜ëŠ”ë°, ì´ë¥¼ í™˜ê°(hallucinations)ì´ë¼ê³  í•©ë‹ˆë‹¤. ì—°êµ¬ìë“¤ì€ ì£¼ë¡œ í™˜ê°ì„ ì¤„ì´ê¸° ìœ„í•´ ê²€ìƒ‰ ì¦ê°• ì–¸ì–´ ëª¨ë¸(RALMs)ê³¼ ê±°ë¶€ í›„ í›ˆë ¨ì´ë¼ëŠ” ë‘ ê°€ì§€ ì ‘ê·¼ ë°©ì‹ì„ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ í˜„ì¬ ì—°êµ¬ëŠ” ì£¼ë¡œ ì´ë“¤ì˜ ê°œë³„ì ì¸ íš¨ê³¼ì— ì¤‘ì ì„ ë‘ê³  ìˆìœ¼ë©°, RALMsì˜ ê±°ë¶€ ëŠ¥ë ¥ í‰ê°€ë¥¼ ê°„ê³¼í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” ê·¼ë³¸ì ì¸ ì§ˆë¬¸ì„ ì œê¸°í•©ë‹ˆë‹¤: RALMsëŠ” ìì‹ ì´ ëª¨ë¥¼ ë•Œë¥¼ ì•Œê³  ìˆëŠ”ê°€? êµ¬ì²´ì ìœ¼ë¡œ, ìš°ë¦¬ëŠ” ì„¸ ê°€ì§€ ì§ˆë¬¸ì„ ì œê¸°í•©ë‹ˆë‹¤. ì²«ì§¸, RALMsëŠ” ë‹¤ì–‘í•œ ë‚´ë¶€ ë° ì™¸ë¶€ ì§€ì‹ ìƒíƒœì— ëŒ€í•´ ì˜ ì¡°ì •ë˜ì–´ ìˆëŠ”ê°€? ìš°ë¦¬ëŠ” ë‹¤ì–‘í•œ ìš”ì¸ì˜ ì˜í–¥ì„ ì¡°ì‚¬í•©ë‹ˆë‹¤. ê¸°ëŒ€ì™€ ë‹¬ë¦¬, LLMsëŠ” ìƒë‹¹í•œ \textbf{ê³¼ì‰ ê±°ë¶€} í–‰ë™ì„ ë³´ì¸ë‹¤ëŠ” ê²ƒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ê·¸ë ‡ë‹¤ë©´, ê±°ë¶€ í›„ í›ˆë ¨ì€ ê³¼ì‰ ê±°ë¶€ ë¬¸ì œì— ì–´ë–»ê²Œ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ê°€? ìš°ë¦¬ëŠ” ê±°ë¶€ ì¸ì‹ ì§€ì‹œ ì¡°ì •(Refusal-aware Instruction Tuning)ê³¼ ë§¥ë½ ë‚´ ë¯¸ì„¸ ì¡°ì •(In-Context Fine-tuning) ë°©ë²•ì„ ì¡°ì‚¬í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ê²°ê³¼ëŠ” ë§¥ë½ ë‚´ ë¯¸ì„¸ ì¡°ì •ì´ ê³¼ì‰ ê±°ë¶€ ë¬¸ì œë¥¼ ì™„í™”í•˜ì§€ë§Œ, R-ì¡°ì •(R-tuning)ì— ì˜í•´ í™•ëŒ€ëœë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ìš°ë¦¬ëŠ” ë˜í•œ ê±°ë¶€ ëŠ¥ë ¥ì´ ì‘ë‹µì˜ ì§ˆê³¼ ì¶©ëŒí•  ìˆ˜ ìˆìŒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ, ìš°ë¦¬ëŠ” ê±°ë¶€ í›„ í›ˆë ¨ëœ ëª¨ë¸ì˜ ì „ë°˜ì ì¸ ì‘ë‹µ í’ˆì§ˆì„ ê±°ë¶€ì™€ ì˜¬ë°”ë¥¸ ì‘ë‹µ ì¸¡ë©´ì—ì„œ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ê°„ë‹¨í•˜ì§€ë§Œ íš¨ê³¼ì ì¸ ê±°ë¶€ ë°©ë²•ì„ ê°œë°œí–ˆìŠµë‹ˆë‹¤. ìš°ë¦¬ì˜ ì—°êµ¬ëŠ” RALM ì‹œìŠ¤í…œì— ì¤‘ìš”í•œ ìš”ì¸ë“¤ì´ ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë³´ë‹¤ í¬ê´„ì ìœ¼ë¡œ ì´í•´í•˜ëŠ” ë° ê¸°ì—¬í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ í™˜ê° ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ë°©ë²•ìœ¼ë¡œ ê²€ìƒ‰ ì¦ê°• ì–¸ì–´ ëª¨ë¸(RALM)ê³¼ ê±°ë¶€ í›„ í›ˆë ¨ì„ íƒêµ¬í•©ë‹ˆë‹¤. ì—°êµ¬ëŠ” RALMì˜ ê±°ë¶€ ëŠ¥ë ¥ì„ í‰ê°€í•˜ëŠ” ë° ì¤‘ì ì„ ë‘ê³ , RALMì´ ê³¼ë„í•œ ê±°ë¶€ í–‰ë™ì„ ë³´ì¸ë‹¤ëŠ” ê²ƒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ê±°ë¶€ í›„ í›ˆë ¨ì´ ì´ëŸ¬í•œ ê³¼ë„í•œ ê±°ë¶€ ë¬¸ì œì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•œ ê²°ê³¼, ë¬¸ë§¥ ë‚´ ë¯¸ì„¸ ì¡°ì •ì€ ë¬¸ì œë¥¼ ì™„í™”í•˜ì§€ë§Œ R-íŠœë‹ì€ ë¬¸ì œë¥¼ ì•…í™”ì‹œí‚µë‹ˆë‹¤. ë˜í•œ, ê±°ë¶€ ëŠ¥ë ¥ê³¼ ë‹µë³€ì˜ ì§ˆì´ ìƒì¶©í•  ìˆ˜ ìˆìŒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ìµœì¢…ì ìœ¼ë¡œ, ê±°ë¶€ í›„ í›ˆë ¨ëœ ëª¨ë¸ì˜ ë‹µë³€ í’ˆì§ˆì„ ê°œì„ í•˜ê¸° ìœ„í•œ ê°„ë‹¨í•˜ê³  íš¨ê³¼ì ì¸ ê±°ë¶€ ë°©ë²•ì„ ê°œë°œí–ˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” RALM ì‹œìŠ¤í…œì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ì¤‘ìš”í•œ ìš”ì¸ë“¤ì— ëŒ€í•œ í¬ê´„ì ì¸ ì´í•´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ ë•Œë•Œë¡œ ì‚¬ì‹¤ê³¼ ë‹¤ë¥¸ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í™˜ê° ë¬¸ì œë¥¼ ê²ªëŠ”ë‹¤.

- 2. í™˜ê° ë¬¸ì œë¥¼ ì™„í™”í•˜ê¸° ìœ„í•´ ì£¼ë¡œ ê²€ìƒ‰ ë³´ê°• ì–¸ì–´ ëª¨ë¸(RALM)ê³¼ ê±°ë¶€ í›„ í›ˆë ¨ ë°©ë²•ì´ ì‚¬ìš©ëœë‹¤.

- 3. ì—°êµ¬ ê²°ê³¼, RALMì€ ê³¼ë„í•œ ê±°ë¶€(over-refusal) í–‰ë™ì„ ë³´ì´ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ë‹¤.

- 4. In-context ë¯¸ì„¸ ì¡°ì •ì€ ê³¼ë„í•œ ê±°ë¶€ ë¬¸ì œë¥¼ ì™„í™”í•˜ì§€ë§Œ, R-tuningì€ ì´ë¥¼ ì•…í™”ì‹œí‚¨ë‹¤.

- 5. ê±°ë¶€ í›„ í›ˆë ¨ëœ ëª¨ë¸ì˜ ì „ë°˜ì ì¸ ì‘ë‹µ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ê°„ë‹¨í•˜ë©´ì„œë„ íš¨ê³¼ì ì¸ ê±°ë¶€ ë°©ë²•ì„ ê°œë°œí•˜ì˜€ë‹¤.

---

*Generated on 2025-09-22 15:01:07*