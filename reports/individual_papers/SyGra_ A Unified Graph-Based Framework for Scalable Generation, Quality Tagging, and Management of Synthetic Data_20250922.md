# SyGra: A Unified Graph-Based Framework for Scalable Generation, Quality Tagging, and Management of Synthetic Data

**Korean Title:** SyGra: í•©ì„± ë°ì´í„°ì˜ í™•ì¥ ê°€ëŠ¥í•œ ìƒì„±, í’ˆì§ˆ íƒœê¹… ë° ê´€ë¦¬ì— ëŒ€í•œ í†µí•© ê·¸ë˜í”„ ê¸°ë°˜ í”„ë ˆì„ì›Œí¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: Supervised Fine Tuning, Direct Preference Optimization

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Middo_ Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning_20250919|Middo Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning]] (85.6% similar)
- [[2025-09-17/Synthetic Data Generation for Screen Time and App Usage_20250917|Synthetic Data Generation for Screen Time and App Usage]] (83.9% similar)
- [[2025-09-22/LiteLong_ Resource-Efficient Long-Context Data Synthesis for LLMs_20250922|LiteLong Resource-Efficient Long-Context Data Synthesis for LLMs]] (83.1% similar)
- [[2025-09-19/Enhancing Logical Reasoning in Language Models via Symbolically-Guided Monte Carlo Process Supervision_20250919|Enhancing Logical Reasoning in Language Models via Symbolically-Guided Monte Carlo Process Supervision]] (82.6% similar)
- [[2025-09-19/Controlling Language Difficulty in Dialogues with Linguistic Features_20250919|Controlling Language Difficulty in Dialogues with Linguistic Features]] (82.5% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2508.15432v2 Announce Type: replace 
Abstract: The advancement of large language models (LLMs) is critically dependent on the availability of high-quality datasets for Supervised Fine-Tuning (SFT), alignment tasks like Direct Preference Optimization (DPO), etc. In this work, we present a comprehensive synthetic data generation framework that facilitates scalable, configurable, and high-fidelity generation of synthetic data tailored for these training paradigms. Our approach employs a modular and configuration-based pipeline capable of modeling complex dialogue flows with minimal manual intervention. This framework uses a dual-stage quality tagging mechanism, combining heuristic rules and LLM-based evaluations, to automatically filter and score data extracted from OASST-formatted conversations, ensuring the curation of high-quality dialogue samples. The resulting datasets are structured under a flexible schema supporting both SFT and DPO use cases, enabling seamless integration into diverse training workflows. Together, these innovations offer a robust solution for generating and managing synthetic conversational data at scale, significantly reducing the overhead of data preparation in LLM training pipelines.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2508.15432v2 ë°œí‘œ ìœ í˜•: êµì²´  
ì´ˆë¡: ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ë°œì „ì€ ê°ë…ëœ ë¯¸ì„¸ ì¡°ì •(SFT), ì§ì ‘ ì„ í˜¸ ìµœì í™”(DPO)ì™€ ê°™ì€ ì •ë ¬ ì‘ì—…ì„ ìœ„í•œ ê³ í’ˆì§ˆ ë°ì´í„°ì…‹ì˜ ê°€ìš©ì„±ì— í¬ê²Œ ì˜ì¡´í•©ë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” ì´ëŸ¬í•œ í›ˆë ¨ íŒ¨ëŸ¬ë‹¤ì„ì— ë§ì¶˜ í•©ì„± ë°ì´í„°ë¥¼ í™•ì¥ ê°€ëŠ¥í•˜ê³  êµ¬ì„± ê°€ëŠ¥í•˜ë©° ê³ ì¶©ì‹¤ë„ë¡œ ìƒì„±í•  ìˆ˜ ìˆëŠ” í¬ê´„ì ì¸ í•©ì„± ë°ì´í„° ìƒì„± í”„ë ˆì„ì›Œí¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì ‘ê·¼ ë°©ì‹ì€ ìµœì†Œí•œì˜ ìˆ˜ì‘ì—… ê°œì…ìœ¼ë¡œ ë³µì¡í•œ ëŒ€í™” íë¦„ì„ ëª¨ë¸ë§í•  ìˆ˜ ìˆëŠ” ëª¨ë“ˆì‹ ë° êµ¬ì„± ê¸°ë°˜ íŒŒì´í”„ë¼ì¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” íœ´ë¦¬ìŠ¤í‹± ê·œì¹™ê³¼ LLM ê¸°ë°˜ í‰ê°€ë¥¼ ê²°í•©í•œ ì´ì¤‘ ë‹¨ê³„ í’ˆì§ˆ íƒœê·¸ ë©”ì»¤ë‹ˆì¦˜ì„ ì‚¬ìš©í•˜ì—¬ OASST í˜•ì‹ì˜ ëŒ€í™”ì—ì„œ ì¶”ì¶œí•œ ë°ì´í„°ë¥¼ ìë™ìœ¼ë¡œ í•„í„°ë§í•˜ê³  ì ìˆ˜ë¥¼ ë§¤ê²¨ ê³ í’ˆì§ˆ ëŒ€í™” ìƒ˜í”Œì„ ì„ ë³„í•©ë‹ˆë‹¤. ê²°ê³¼ ë°ì´í„°ì…‹ì€ SFTì™€ DPO ì‚¬ìš© ì‚¬ë¡€ ëª¨ë‘ë¥¼ ì§€ì›í•˜ëŠ” ìœ ì—°í•œ ìŠ¤í‚¤ë§ˆë¡œ êµ¬ì¡°í™”ë˜ì–´ ë‹¤ì–‘í•œ í›ˆë ¨ ì›Œí¬í”Œë¡œì— ì›í™œí•˜ê²Œ í†µí•©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ í˜ì‹ ë“¤ì€ ëŒ€ê·œëª¨ í•©ì„± ëŒ€í™” ë°ì´í„°ë¥¼ ìƒì„±í•˜ê³  ê´€ë¦¬í•˜ëŠ” ê°•ë ¥í•œ ì†”ë£¨ì…˜ì„ ì œê³µí•˜ì—¬ LLM í›ˆë ¨ íŒŒì´í”„ë¼ì¸ì˜ ë°ì´í„° ì¤€ë¹„ì— ëŒ€í•œ ë¶€ë‹´ì„ í¬ê²Œ ì¤„ì—¬ì¤ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ë°œì „ì„ ìœ„í•œ ê³ í’ˆì§ˆ ë°ì´í„°ì…‹ ìƒì„± í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ëŒ€í™” íë¦„ì„ ëª¨ë¸ë§í•˜ëŠ” ëª¨ë“ˆí˜• íŒŒì´í”„ë¼ì¸ì„ í†µí•´ ìµœì†Œí•œì˜ ìˆ˜ì‘ì—…ìœ¼ë¡œ ëŒ€ê·œëª¨ í•©ì„± ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ë˜í•œ, ì´ì¤‘ ë‹¨ê³„ì˜ í’ˆì§ˆ íƒœê¹… ë©”ì»¤ë‹ˆì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ëŒ€í™” ë°ì´í„°ë¥¼ ìë™ìœ¼ë¡œ í•„í„°ë§í•˜ê³  í‰ê°€í•©ë‹ˆë‹¤. ìƒì„±ëœ ë°ì´í„°ì…‹ì€ SFTì™€ DPOì— ëª¨ë‘ í™œìš© ê°€ëŠ¥í•˜ë©°, ë‹¤ì–‘í•œ í›ˆë ¨ ì›Œí¬í”Œë¡œìš°ì— ì‰½ê²Œ í†µí•©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¡œì¨ LLM í›ˆë ¨ì—ì„œ ë°ì´í„° ì¤€ë¹„ì˜ ë¶€ë‹´ì„ í¬ê²Œ ì¤„ì…ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ë°œì „ì€ ê³ í’ˆì§ˆ ë°ì´í„°ì…‹ì˜ ê°€ìš©ì„±ì— í¬ê²Œ ì˜ì¡´í•˜ë©°, ì´ë¥¼ ìœ„í•œ ì¢…í•©ì ì¸ í•©ì„± ë°ì´í„° ìƒì„± í”„ë ˆì„ì›Œí¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.

- 2. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ìµœì†Œí•œì˜ ìˆ˜ì‘ì—… ê°œì…ìœ¼ë¡œ ë³µì¡í•œ ëŒ€í™” íë¦„ì„ ëª¨ë¸ë§í•  ìˆ˜ ìˆëŠ” ëª¨ë“ˆì‹ ë° êµ¬ì„± ê¸°ë°˜ íŒŒì´í”„ë¼ì¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

- 3. ì´ì¤‘ ë‹¨ê³„ í’ˆì§ˆ íƒœê·¸ ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´ OASST í˜•ì‹ì˜ ëŒ€í™”ì—ì„œ ì¶”ì¶œëœ ë°ì´í„°ë¥¼ ìë™ìœ¼ë¡œ í•„í„°ë§í•˜ê³  í‰ê°€í•˜ì—¬ ê³ í’ˆì§ˆ ëŒ€í™” ìƒ˜í”Œì„ ì„ ë³„í•©ë‹ˆë‹¤.

- 4. ìƒì„±ëœ ë°ì´í„°ì…‹ì€ SFT ë° DPO ì‚¬ìš© ì‚¬ë¡€ë¥¼ ì§€ì›í•˜ëŠ” ìœ ì—°í•œ ìŠ¤í‚¤ë§ˆë¡œ êµ¬ì¡°í™”ë˜ì–´ ë‹¤ì–‘í•œ í›ˆë ¨ ì›Œí¬í”Œë¡œìš°ì— ì›í™œí•˜ê²Œ í†µí•©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- 5. ì´ í˜ì‹ ì€ ëŒ€ê·œëª¨ í•©ì„± ëŒ€í™” ë°ì´í„°ë¥¼ ìƒì„± ë° ê´€ë¦¬í•˜ëŠ” ê°•ë ¥í•œ ì†”ë£¨ì…˜ì„ ì œê³µí•˜ì—¬ LLM í›ˆë ¨ íŒŒì´í”„ë¼ì¸ì˜ ë°ì´í„° ì¤€ë¹„ ë¶€ë‹´ì„ í¬ê²Œ ì¤„ì…ë‹ˆë‹¤.

---

*Generated on 2025-09-22 14:33:09*