# Adaptive Self-improvement LLM Agentic System for ML Library Development

**Korean Title:** 적응형 자기개선 LLM 에이전틱 시스템을 통한 기계 학습 라이브러리 개발

## 📋 메타데이터

## 📋 메타데이터

**Links**: [[reports/digests/daily_digest_20250922|2025-09-22]] [[keywords/specific/Architecture Specific Programming Languages|Architecture Specific Programming Languages]] [[keywords/broad/Large Language Models|Large Language Models]] [[keywords/broad/Machine Learning Libraries|Machine Learning Libraries]] [[keywords/unique/Adaptive Self-improvement Agentic System|Adaptive Self-improvement Agentic System]] [[categories/cs.CL|cs.CL]] [[2025-09-19/An LLM-based multi-agent framework for agile effort estimation_20250919|An LLM-based multi-agent framework for agile effort estimation]] (83.9% similar) [[2025-09-19/Modular Machine Learning_ An Indispensable Path towards New-Generation Large Language Models_20250919|Modular Machine Learning: An Indispensable Path towards New-Generation Large Language Models]] (83.9% similar) [[2025-09-18/An LLM Agentic Approach for Legal-Critical Software_ A Case Study for Tax Prep Software_20250918|An LLM Agentic Approach for Legal-Critical Software: A Case Study for Tax Prep Software]] (83.7% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: Architecture Specific Programming Languages
**🔬 Broad Technical**: Large Language Models, Machine Learning Libraries
**⭐ Unique Technical**: Adaptive Self-improvement Agentic System
## 🔗 유사한 논문
- [[2025-09-19/An LLM-based multi-agent framework for agile effort estimation_20250919|An LLM-based multi-agent framework for agile effort estimation]] (83.9% similar)
- [[2025-09-19/Modular Machine Learning_ An Indispensable Path towards New-Generation Large Language Models_20250919|Modular Machine Learning An Indispensable Path towards New-Generation Large Language Models]] (83.9% similar)
- [[2025-09-18/An LLM Agentic Approach for Legal-Critical Software_ A Case Study for Tax Prep Software_20250918|An LLM Agentic Approach for Legal-Critical Software A Case Study for Tax Prep Software]] (83.7% similar)
- [[2025-09-22/Evaluating the Limitations of Local LLMs in Solving Complex Programming Challenges_20250922|Evaluating the Limitations of Local LLMs in Solving Complex Programming Challenges]] (83.4% similar)
- [[2025-09-18/LLM-I_ LLMs are Naturally Interleaved Multimodal Creators_20250918|LLM-I LLMs are Naturally Interleaved Multimodal Creators]] (83.3% similar)


**ArXiv ID**: [2502.02534](https://arxiv.org/abs/2502.02534)
**Published**: 2025-09-22
**Category**: cs.CL
**PDF**: [Download](https://arxiv.org/pdf/2502.02534.pdf)


**ArXiv ID**: [2502.02534](https://arxiv.org/abs/2502.02534)
**Published**: 2025-09-22
**Category**: cs.CL
**PDF**: [Download](https://arxiv.org/pdf/2502.02534.pdf)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: Architecture Specific Programming Languages
**⭐ Unique Technical**: Adaptive Self-improvement Agentic System
**🔬 Broad Technical**: Large Language Models, Machine Learning Libraries

## 🏷️ 추출된 키워드



`Large Language Models` • 

`Machine Learning Libraries` • 

`Architecture Specific Programming Languages` • 

`Adaptive Self-improvement Agentic System`



## 🔗 유사한 논문

Similar papers will be displayed here based on embedding similarity.

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2502.02534v2 Announce Type: replace 
Abstract: ML libraries, often written in architecture-specific programming languages (ASPLs) that target domain-specific architectures, are key to efficient ML systems. However, writing these high-performance ML libraries is challenging because it requires expert knowledge of ML algorithms and the ASPL. Large language models (LLMs), on the other hand, have shown general coding capabilities. However, challenges remain when using LLMs for generating ML libraries using ASPLs because 1) this task is complicated even for experienced human programmers and 2) there are limited code examples because of the esoteric and evolving nature of ASPLs. Therefore, LLMs need complex reasoning with limited data in order to complete this task. To address these challenges, we introduce an adaptive self-improvement agentic system. In order to evaluate the effectiveness of our system, we construct a benchmark of a typical ML library and generate ASPL code with both open and closed-source LLMs on this benchmark. Our results show improvements of up to $3.9\times$ over a baseline single LLM.

## 🔍 Abstract (한글 번역)

arXiv:2502.02534v2 발표 유형: 교체  
초록: ML 라이브러리는 종종 도메인 특화 아키텍처를 목표로 하는 아키텍처 특화 프로그래밍 언어(ASPL)로 작성되며, 이는 효율적인 ML 시스템의 핵심입니다. 그러나 이러한 고성능 ML 라이브러리를 작성하는 것은 ML 알고리즘과 ASPL에 대한 전문가 지식이 필요하기 때문에 어렵습니다. 반면에 대형 언어 모델(LLM)은 일반적인 코딩 능력을 보여주었습니다. 그러나 ASPL을 사용하여 ML 라이브러리를 생성할 때 LLM을 사용하는 데는 여전히 어려움이 있습니다. 이는 1) 이 작업이 경험이 많은 인간 프로그래머에게도 복잡하고 2) ASPL의 난해하고 진화하는 특성 때문에 코드 예제가 제한적이기 때문입니다. 따라서 LLM은 제한된 데이터로 복잡한 추론을 수행해야 이 작업을 완료할 수 있습니다. 이러한 문제를 해결하기 위해 우리는 적응형 자기 개선 에이전트 시스템을 도입합니다. 시스템의 효과를 평가하기 위해, 우리는 전형적인 ML 라이브러리의 벤치마크를 구성하고 이 벤치마크에서 개방형 및 폐쇄형 소스 LLM을 사용하여 ASPL 코드를 생성합니다. 우리의 결과는 단일 LLM을 기준으로 최대 $3.9\times$의 개선을 보여줍니다.

## 📝 요약

이 논문은 도메인 특화 아키텍처를 목표로 하는 아키텍처 특화 프로그래밍 언어(ASPL)로 작성된 고성능 머신러닝(ML) 라이브러리의 개발을 다룹니다. 이러한 라이브러리를 작성하는 것은 ML 알고리즘과 ASPL에 대한 전문 지식이 필요하여 어렵습니다. 대형 언어 모델(LLM)은 일반적인 코딩 능력을 보유하고 있지만, ASPL을 사용한 ML 라이브러리 생성에는 여전히 도전 과제가 있습니다. 이를 해결하기 위해 적응형 자기 개선 에이전트 시스템을 제안하였으며, 이를 평가하기 위해 ML 라이브러리 벤치마크를 구축하고 다양한 LLM을 사용하여 ASPL 코드를 생성했습니다. 그 결과, 단일 LLM 대비 최대 3.9배의 성능 향상을 보였습니다.

## 🎯 주요 포인트


- 1. ML 라이브러리는 특정 아키텍처를 목표로 하는 프로그래밍 언어로 작성되어 효율적인 ML 시스템에 필수적이다.

- 2. 고성능 ML 라이브러리를 작성하는 것은 ML 알고리즘과 ASPL에 대한 전문 지식이 필요하여 어렵다.

- 3. 대형 언어 모델(LLM)은 일반적인 코딩 능력을 보이지만, ASPL을 사용한 ML 라이브러리 생성에는 여전히 도전 과제가 존재한다.

- 4. 이러한 문제를 해결하기 위해 적응형 자기 개선 에이전트 시스템을 도입하였다.

- 5. 시스템의 효과를 평가하기 위해 ML 라이브러리 벤치마크를 구성하고, LLM을 사용하여 ASPL 코드를 생성한 결과, 최대 3.9배의 성능 향상을 보였다.


---

*Generated on 2025-09-22 16:33:32*