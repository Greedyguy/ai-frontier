# Distribution-Aligned Decoding for Efficient LLM Task Adaptation

**Korean Title:** ë¶„í¬ ì •ë ¬ ë””ì½”ë”©ì„ í†µí•œ íš¨ìœ¨ì ì¸ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ ê³¼ì œ ì ì‘

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: Kullback Leibler Divergence

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/Singular Value Few-shot Adaptation of Vision-Language Models_20250918|Singular Value Few-shot Adaptation of Vision-Language Models]] (84.0% similar)
- [[2025-09-22/On Optimal Steering to Achieve Exact Fairness_20250922|On Optimal Steering to Achieve Exact Fairness]] (83.5% similar)
- [[2025-09-18/Mind the Gap_ Data Rewriting for Stable Off-Policy Supervised Fine-Tuning_20250918|Mind the Gap Data Rewriting for Stable Off-Policy Supervised Fine-Tuning]] (83.2% similar)
- [[2025-09-19/Delta Knowledge Distillation for Large Language Models_20250919|Delta Knowledge Distillation for Large Language Models]] (83.1% similar)
- [[2025-09-19/ReCoVeR the Target Language_ Language Steering without Sacrificing Task Performance_20250919|ReCoVeR the Target Language Language Steering without Sacrificing Task Performance]] (82.8% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15888v1 Announce Type: cross 
Abstract: Adapting billion-parameter language models to a downstream task is still costly, even with parameter-efficient fine-tuning (PEFT). We re-cast task adaptation as output-distribution alignment: the objective is to steer the output distribution toward the task distribution directly during decoding rather than indirectly through weight updates. Building on this view, we introduce Steering Vector Decoding (SVD), a lightweight, PEFT-compatible, and theoretically grounded method. We start with a short warm-start fine-tune and extract a task-aware steering vector from the Kullback-Leibler (KL) divergence gradient between the output distribution of the warm-started and pre-trained models. This steering vector is then used to guide the decoding process to steer the model's output distribution towards the task distribution. We theoretically prove that SVD is first-order equivalent to the gradient step of full fine-tuning and derive a globally optimal solution for the strength of the steering vector. Across three tasks and nine benchmarks, SVD paired with four standard PEFT methods improves multiple-choice accuracy by up to 5 points and open-ended truthfulness by 2 points, with similar gains (1-2 points) on commonsense datasets without adding trainable parameters beyond the PEFT adapter. SVD thus offers a lightweight, theoretically grounded path to stronger task adaptation for large language models.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15888v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ìˆ˜ì‹­ì–µ ê°œì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ê°€ì§„ ì–¸ì–´ ëª¨ë¸ì„ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—…ì— ì ì‘ì‹œí‚¤ëŠ” ê²ƒì€ ì—¬ì „íˆ ë¹„ìš©ì´ ë§ì´ ë“¤ë©°, ë§¤ê°œë³€ìˆ˜ íš¨ìœ¨ì ì¸ ë¯¸ì„¸ ì¡°ì •(PEFT)ì„ ì‚¬ìš©í•˜ë”ë¼ë„ ë§ˆì°¬ê°€ì§€ì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì‘ì—… ì ì‘ì„ ì¶œë ¥ ë¶„í¬ ì •ë ¬ë¡œ ì¬êµ¬ì„±í•©ë‹ˆë‹¤: ëª©í‘œëŠ” ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ë¥¼ í†µí•´ ê°„ì ‘ì ìœ¼ë¡œê°€ ì•„ë‹ˆë¼ ë””ì½”ë”© ì¤‘ì— ì§ì ‘ì ìœ¼ë¡œ ì¶œë ¥ ë¶„í¬ë¥¼ ì‘ì—… ë¶„í¬ë¡œ ì¡°ì •í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ ê´€ì ì„ ë°”íƒ•ìœ¼ë¡œ, ìš°ë¦¬ëŠ” Steering Vector Decoding (SVD)ë¼ëŠ” ê²½ëŸ‰ì˜, PEFT í˜¸í™˜ ê°€ëŠ¥í•˜ë©° ì´ë¡ ì ìœ¼ë¡œ ê·¼ê±° ìˆëŠ” ë°©ë²•ì„ ì†Œê°œí•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì§§ì€ ì›Œë°ì—… ë¯¸ì„¸ ì¡°ì •ìœ¼ë¡œ ì‹œì‘í•˜ì—¬ ì›Œë°ì—…ëœ ëª¨ë¸ê³¼ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì˜ ì¶œë ¥ ë¶„í¬ ì‚¬ì´ì˜ Kullback-Leibler (KL) ë°œì‚°ì˜ ê¸°ìš¸ê¸°ì—ì„œ ì‘ì—… ì¸ì‹ ì¡°ì • ë²¡í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ ì´ ì¡°ì • ë²¡í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë””ì½”ë”© ê³¼ì •ì„ ì•ˆë‚´í•˜ì—¬ ëª¨ë¸ì˜ ì¶œë ¥ ë¶„í¬ë¥¼ ì‘ì—… ë¶„í¬ë¡œ ì¡°ì •í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” SVDê°€ ì „ì²´ ë¯¸ì„¸ ì¡°ì •ì˜ ê¸°ìš¸ê¸° ë‹¨ê³„ì™€ 1ì°¨ ë™ë“±í•¨ì„ ì´ë¡ ì ìœ¼ë¡œ ì¦ëª…í•˜ê³ , ì¡°ì • ë²¡í„°ì˜ ê°•ë„ì— ëŒ€í•œ ì „ì—­ ìµœì  ì†”ë£¨ì…˜ì„ ë„ì¶œí•©ë‹ˆë‹¤. ì„¸ ê°€ì§€ ì‘ì—…ê³¼ ì•„í™‰ ê°€ì§€ ë²¤ì¹˜ë§ˆí¬ì— ê±¸ì³, SVDëŠ” ë„¤ ê°€ì§€ í‘œì¤€ PEFT ë°©ë²•ê³¼ ê²°í•©í•˜ì—¬ ì„ íƒí˜• ë¬¸ì œì˜ ì •í™•ì„±ì„ ìµœëŒ€ 5ì , ê°œë°©í˜• ì§„ì‹¤ì„±ì„ 2ì ê¹Œì§€ í–¥ìƒì‹œí‚¤ë©°, PEFT ì–´ëŒ‘í„° ì™¸ì— í•™ìŠµ ê°€ëŠ¥í•œ ë§¤ê°œë³€ìˆ˜ë¥¼ ì¶”ê°€í•˜ì§€ ì•Šê³ ë„ ìƒì‹ ë°ì´í„°ì…‹ì—ì„œ ìœ ì‚¬í•œ í–¥ìƒ(1-2ì )ì„ ë³´ì…ë‹ˆë‹¤. ë”°ë¼ì„œ SVDëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ ë” ê°•ë ¥í•œ ì‘ì—… ì ì‘ì„ ìœ„í•œ ê²½ëŸ‰ì˜, ì´ë¡ ì ìœ¼ë¡œ ê·¼ê±° ìˆëŠ” ê²½ë¡œë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—… ì ì‘ì„ ìœ„í•œ ìƒˆë¡œìš´ ë°©ë²•ë¡ ì¸ Steering Vector Decoding (SVD)ì„ ì œì•ˆí•©ë‹ˆë‹¤. SVDëŠ” ì¶œë ¥ ë¶„í¬ë¥¼ ì‘ì—… ë¶„í¬ì— ì§ì ‘ ë§ì¶”ëŠ” ë°©ì‹ìœ¼ë¡œ, íŒŒë¼ë¯¸í„° íš¨ìœ¨ì  ë¯¸ì„¸ ì¡°ì •(PEFT)ê³¼ í˜¸í™˜ë©ë‹ˆë‹¤. ì´ˆê¸° ë¯¸ì„¸ ì¡°ì • í›„ Kullback-Leibler ë°œì‚°ì˜ ê¸°ìš¸ê¸°ë¥¼ ì´ìš©í•´ ì‘ì—… ì¸ì‹ ì¡°ì • ë²¡í„°ë¥¼ ì¶”ì¶œí•˜ê³ , ì´ë¥¼ í†µí•´ ëª¨ë¸ì˜ ì¶œë ¥ ë¶„í¬ë¥¼ ì‘ì—… ë¶„í¬ë¡œ ìœ ë„í•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ì „ì²´ ë¯¸ì„¸ ì¡°ì •ì˜ ê¸°ìš¸ê¸° ë‹¨ê³„ì™€ 1ì°¨ì ìœ¼ë¡œ ë™ë“±í•˜ë©°, ì¡°ì • ë²¡í„°ì˜ ìµœì  ê°•ë„ë¥¼ ì´ë¡ ì ìœ¼ë¡œ ë„ì¶œí•©ë‹ˆë‹¤. ì„¸ ê°€ì§€ ì‘ì—…ê³¼ ì•„í™‰ ê°œì˜ ë²¤ì¹˜ë§ˆí¬ì—ì„œ SVDëŠ” PEFT ë°©ë²•ê³¼ ê²°í•©í•˜ì—¬ ì„ íƒí˜• ì •í™•ë„ë¥¼ ìµœëŒ€ 5ì , ê°œë°©í˜• ì§„ì‹¤ì„±ì„ 2ì  í–¥ìƒì‹œì¼°ìœ¼ë©°, ì¶”ê°€ í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ì—†ì´ ìƒì‹ ë°ì´í„°ì…‹ì—ì„œë„ 1-2ì ì˜ ìœ ì‚¬í•œ í–¥ìƒì„ ë³´ì˜€ìŠµë‹ˆë‹¤. SVDëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ì‘ì—… ì ì‘ì„ ê°•í™”í•˜ëŠ” ê²½ëŸ‰ì˜ ì´ë¡ ì  ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. SVD(Steering Vector Decoding)ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ì¶œë ¥ ë¶„í¬ë¥¼ ì§ì ‘ ì¡°ì •í•˜ì—¬ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—…ì— ì ì‘ì‹œí‚¤ëŠ” ê²½ëŸ‰í™”ëœ ë°©ë²•ì…ë‹ˆë‹¤.

- 2. SVDëŠ” Kullback-Leibler(KL) ë°œì‚°ì˜ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ í™œìš©í•˜ì—¬ ì‘ì—… ì¸ì‹ ì¡°ì • ë²¡í„°ë¥¼ ì¶”ì¶œí•˜ê³ , ì´ë¥¼ í†µí•´ ëª¨ë¸ì˜ ì¶œë ¥ ë¶„í¬ë¥¼ ì‘ì—… ë¶„í¬ë¡œ ìœ ë„í•©ë‹ˆë‹¤.

- 3. SVDëŠ” ì „ì²´ ë¯¸ì„¸ ì¡°ì •ì˜ ê·¸ë˜ë””ì–¸íŠ¸ ë‹¨ê³„ì™€ 1ì°¨ì ìœ¼ë¡œ ë™ë“±í•˜ë©°, ì¡°ì • ë²¡í„°ì˜ ìµœì  ê°•ë„ë¥¼ ì´ë¡ ì ìœ¼ë¡œ ë„ì¶œí•©ë‹ˆë‹¤.

- 4. SVDëŠ” ì„¸ ê°€ì§€ ì‘ì—…ê³¼ ì•„í™‰ ê°œì˜ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë‹¤ì¤‘ ì„ íƒ ì •í™•ë„ë¥¼ ìµœëŒ€ 5ì , ê°œë°©í˜• ì§„ì‹¤ì„±ì„ 2ì  í–¥ìƒì‹œí‚µë‹ˆë‹¤.

- 5. SVDëŠ” ì¶”ê°€ í•™ìŠµ ê°€ëŠ¥í•œ ë§¤ê°œë³€ìˆ˜ë¥¼ ë„ì…í•˜ì§€ ì•Šê³ ë„ PEFT ì–´ëŒ‘í„°ì™€ í•¨ê»˜ ì‚¬ìš©í•˜ì—¬ ìƒì‹ ë°ì´í„°ì…‹ì—ì„œ 1-2ì ì˜ ìœ ì‚¬í•œ ì„±ëŠ¥ í–¥ìƒì„ ì œê³µí•©ë‹ˆë‹¤.

---

*Generated on 2025-09-22 14:15:24*