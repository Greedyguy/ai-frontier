
# Privacy-Aware In-Context Learning for Large Language Models

**Korean Title:** ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ ìœ„í•œ ê°œì¸ì •ë³´ ë³´í˜¸ ì¸-ì»¨í…ìŠ¤íŠ¸ í•™ìŠµ

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-18|2025-09-18]] [[keywords/evolved/Privacy-Preserving Text Generation|Privacy-Preserving Text Generation]] [[keywords/broad/Large Language Models|Large Language Models]] [[keywords/broad/Differential Privacy|Differential Privacy]] [[keywords/specific/In-context Learning|In-context Learning]] [[keywords/unique/Privacy-Aware In-Context Learning|Privacy-Aware In-Context Learning]] [[categories/cs.LG|cs.LG]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Privacy-Preserving Text Generation
**ğŸ”¬ Broad Technical**: Large Language Models, Differential Privacy
**ğŸ”— Specific Connectable**: In-context Learning
**â­ Unique Technical**: Private Prediction Framework

**ArXiv ID**: [2509.13625](https://arxiv.org/abs/2509.13625)
**Published**: 2025-09-18
**Category**: cs.LG
**PDF**: [Download](https://arxiv.org/pdf/2509.13625.pdf)


## ğŸ·ï¸ ì¶”ì¶œëœ í‚¤ì›Œë“œ



`Large Language Models` â€¢ 

`Differential Privacy` â€¢ 

`In-context Learning` â€¢ 

`Private Prediction Framework` â€¢ 

`Privacy-Preserving Text Generation`



## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.13625v1 Announce Type: new 
Abstract: Large language models (LLMs) have significantly transformed natural language understanding and generation, but they raise privacy concerns due to potential exposure of sensitive information. Studies have highlighted the risk of information leakage, where adversaries can extract sensitive information embedded in the prompts. In this work, we introduce a novel private prediction framework for generating high-quality synthetic text with strong privacy guarantees. Our approach leverages the Differential Privacy (DP) framework to ensure worst-case theoretical bounds on information leakage without requiring any fine-tuning of the underlying models.The proposed method performs inference on private records and aggregates the resulting per-token output distributions. This enables the generation of longer and coherent synthetic text while maintaining privacy guarantees. Additionally, we propose a simple blending operation that combines private and public inference to further enhance utility. Empirical evaluations demonstrate that our approach outperforms previous state-of-the-art methods on in-context-learning (ICL) tasks, making it a promising direction for privacy-preserving text generation while maintaining high utility.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.13625v1 ë°œí‘œ ìœ í˜•: ìƒˆë¡œìš´
ìš”ì•½: ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLMs)ì€ ìì—°ì–´ ì´í•´ì™€ ìƒì„±ì„ í˜„ê²©í•˜ê²Œ ë³€í™”ì‹œì¼°ì§€ë§Œ, ë¯¼ê°í•œ ì •ë³´ ë…¸ì¶œ ê°€ëŠ¥ì„±ìœ¼ë¡œ ì¸í•´ ê°œì¸ì •ë³´ ë³´í˜¸ ìš°ë ¤ê°€ ì œê¸°ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì—°êµ¬ë“¤ì€ ì ëŒ€ìê°€ í”„ë¡¬í”„íŠ¸ì— ë‚´ì¥ëœ ë¯¼ê°í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ìˆëŠ” ì •ë³´ ëˆ„ì¶œ ìœ„í—˜ì„ ê°•ì¡°í•´ì™”ìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” ê°•ë ¥í•œ ê°œì¸ ì •ë³´ ë³´í˜¸ ë³´ì¥ì„ ê°€ì§„ ê³ í’ˆì§ˆ í•©ì„± í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ê°œì¸ ì˜ˆì¸¡ í”„ë ˆì„ì›Œí¬ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì ‘ê·¼ ë°©ì‹ì€ Differential Privacy (DP) í”„ë ˆì„ì›Œí¬ë¥¼ í™œìš©í•˜ì—¬ ê¸°ë³¸ ëª¨ë¸ì˜ ì„¸ë°€í•œ ì¡°ì • ì—†ì´ ì •ë³´ ëˆ„ì¶œì— ëŒ€í•œ ìµœì•…ì˜ ê²½ìš° ì´ë¡ ì  í•œê³„ë¥¼ ë³´ì¥í•©ë‹ˆë‹¤. ì œì•ˆëœ ë°©ë²•ì€ ê°œì¸ ë ˆì½”ë“œì—ì„œ ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ì ì¸ í† í°ë³„ ì¶œë ¥ ë¶„í¬ë¥¼ ì§‘ê³„í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ê°œì¸ ì •ë³´ ë³´í˜¸ë¥¼ ìœ ì§€í•˜ë©´ì„œ ë” ê¸´ ì¼ê´€ëœ í•©ì„± í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ìš°ë¦¬ëŠ” ê°œì¸ ë° ê³µê°œ ì¶”ë¡ ì„ ê²°í•©í•˜ëŠ” ê°„ë‹¨í•œ í˜¼í•© ì‘ì—…ì„ ì œì•ˆí•˜ì—¬ ìœ í‹¸ë¦¬í‹°ë¥¼ ë”ìš± í–¥ìƒì‹œí‚µë‹ˆë‹¤. ê²½í—˜ì  í‰ê°€ ê²°ê³¼, ìš°ë¦¬ì˜ ì ‘ê·¼ ë°©ì‹ì´ ì»¨í…ìŠ¤íŠ¸ ë‚´ í•™ìŠµ(ICL) ì‘ì—…ì—ì„œ ì´ì „ ìµœì²¨ë‹¨ ë°©ë²•ì„ ëŠ¥ê°€í•¨ì„ ë³´ì—¬ì£¼ë©°, ë†’ì€ ìœ í‹¸ë¦¬í‹°ë¥¼ ìœ ì§€í•˜ë©´ì„œ ê°œì¸ ì •ë³´ ë³´í˜¸ í…ìŠ¤íŠ¸ ìƒì„±ì— ëŒ€í•œ ìœ ë§í•œ ë°©í–¥ì„ì„ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì´ ìì—°ì–´ ì´í•´ ë° ìƒì„±ì„ í˜ì‹ ì ìœ¼ë¡œ ë³€í™”ì‹œì¼°ì§€ë§Œ, ë¯¼ê°í•œ ì •ë³´ ë…¸ì¶œë¡œ ì¸í•œ ê°œì¸ì •ë³´ ë³´ì•ˆ ìš°ë ¤ë¥¼ ì œê¸°í•˜ê³  ìˆë‹¤. ì •ë³´ ëˆ„ì¶œ ìœ„í—˜ì„ ê°•ì¡°í•œ ì—°êµ¬ë“¤ì´ ìˆìœ¼ë©°, ì´ì— ëŒ€ì‘í•˜ê¸° ìœ„í•´ ê°•ë ¥í•œ ê°œì¸ì •ë³´ ë³´í˜¸ë¥¼ ì œê³µí•˜ëŠ” ìƒˆë¡œìš´ í”„ë¼ì´ë²„ì‹œ ì˜ˆì¸¡ í”„ë ˆì„ì›Œí¬ë¥¼ ì†Œê°œí•œë‹¤. ì œì•ˆëœ ë°©ë²•ì€ Differential Privacy (DP) í”„ë ˆì„ì›Œí¬ë¥¼ í™œìš©í•˜ì—¬ ì •ë³´ ëˆ„ì¶œì— ëŒ€í•œ ìµœì•…ì˜ ê²½ìš° ì´ë¡ ì  í•œê³„ë¥¼ ë³´ì¥í•˜ë©°, ê¸°ì¡´ ëª¨ë¸ì˜ ì„¸ë°€í•œ ì¡°ì • ì—†ì´ ê³ í’ˆì§ˆì˜ í•©ì„± í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•œë‹¤. ì œì•ˆëœ ë°©ë²•ì€ ê°œì¸ ë ˆì½”ë“œì—ì„œ ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ì ìœ¼ë¡œ í† í° ë‹¨ìœ„ì˜ ì¶œë ¥ ë¶„í¬ë¥¼ ì§‘ê³„í•œë‹¤. ì´ë¥¼ í†µí•´ ê°œì¸ì •ë³´ ë³´í˜¸ë¥¼ ìœ ì§€í•˜ë©´ì„œ ë” ê¸´ ë° ì¼ê´€ëœ í•©ì„± í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ìˆë‹¤. ë˜í•œ, ê°œì¸ ë° ê³µê°œ ì¶”ë¡ ì„ ê²°í•©í•˜ëŠ” ê°„ë‹¨í•œ ë¸”ë Œë”© ì‘ì—…ì„ ì œì•ˆí•˜ì—¬ ìœ í‹¸ë¦¬í‹°ë¥¼ ë”ìš± í–¥ìƒì‹œí‚¨ë‹¤. ê²½í—˜ì  í‰ê°€ ê²°ê³¼, ì´ ë°©ë²•ì€ ì´ì „ ìµœì²¨ë‹¨ ë°©ë²•ë“¤ì„ ëŠ¥ê°€í•˜ì—¬ ê³ ìœ ìš©ë„ í•™ìŠµ(ICL) ì‘ì—…ì—ì„œ ìš°ìˆ˜í•œ ì„±ê³¼ë¥¼ ë³´ì—¬ì£¼ì–´ ê°œì¸ì •ë³´ ë³´í˜¸ë¥¼ ìœ ì§€í•˜ë©´ì„œ ë†’ì€ ìœ í‹¸ë¦¬í‹°ë¥¼ ì œê³µí•˜ëŠ” í…ìŠ¤íŠ¸ ìƒì„±ì˜ ìœ ë§í•œ ë°©í–¥ì„ì„ ì…ì¦í•˜ì˜€ë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸


- ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì€ ìì—°ì–´ ì´í•´ ë° ìƒì„±ì„ í˜ì‹ ì ìœ¼ë¡œ ë³€í™”ì‹œì¼°ì§€ë§Œ ë¯¼ê°í•œ ì •ë³´ ë…¸ì¶œë¡œ ì¸í•œ ê°œì¸ì •ë³´ ë³´í˜¸ ìš°ë ¤ê°€ ìˆìŒ

- ì œì•ˆëœ í”„ë ˆì„ì›Œí¬ëŠ” ë¯¼ê°í•œ ì •ë³´ ë…¸ì¶œì— ëŒ€í•œ ê°•ë ¥í•œ ê°œì¸ì •ë³´ ë³´í˜¸ë¥¼ ì œê³µí•˜ë©´ì„œ ê³ í’ˆì§ˆì˜ í•©ì„± í…ìŠ¤íŠ¸ë¥¼ ìƒì„±

- Differential Privacy (DP) í”„ë ˆì„ì›Œí¬ë¥¼ í™œìš©í•˜ì—¬ ì •ë³´ ë…¸ì¶œì— ëŒ€í•œ ì´ë¡ ì  í•œê³„ë¥¼ ë³´ì¥í•˜ë©° ê°œì¸ì •ë³´ ë³´í˜¸

- ì œì•ˆëœ ë°©ë²•ì€ ê°œì¸ ë ˆì½”ë“œì—ì„œ ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ í† í° ë‹¨ìœ„ë¡œ ì§‘ê³„í•˜ì—¬ ê°œì¸ ì •ë³´ ë³´í˜¸ë¥¼ ìœ ì§€í•˜ë©´ì„œ ê¸´ í•©ì„± í…ìŠ¤íŠ¸ ìƒì„± ê°€ëŠ¥

- ê°œì¸ ë° ê³µê°œ ì¶”ë¡ ì„ ê²°í•©í•˜ëŠ” ê°„ë‹¨í•œ ë¸”ë Œë”© ì‘ì—…ì„ ì œì•ˆí•˜ì—¬ ìœ í‹¸ë¦¬í‹°ë¥¼ ë”ìš± í–¥ìƒì‹œí‚´


---

*Generated on 2025-09-18 16:37:11*