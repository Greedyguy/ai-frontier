# Fairness-in-the-Workflow: How Machine Learning Practitioners at Big Tech Companies Approach Fairness in Recommender Systems

**Korean Title:** 워크플로우에서의 공정성: 대형 기술 기업의 머신러닝 실무자들이 추천 시스템에서 공정성을 접근하는 방법

## 📋 메타데이터

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Dynamic Fairness Considerations

## 🔗 유사한 논문
- [[2025-09-19/Let's Grow an Unbiased Community_ Guiding the Fairness of Graphs via New Links_20250919|Let's Grow an Unbiased Community Guiding the Fairness of Graphs via New Links]] (78.3% similar)
- [[2025-09-22/Dynamic Policy Fusion for User Alignment Without Re-Interaction_20250922|Dynamic Policy Fusion for User Alignment Without Re-Interaction]] (77.3% similar)
- [[2025-09-22/On Optimal Steering to Achieve Exact Fairness_20250922|On Optimal Steering to Achieve Exact Fairness]] (77.0% similar)
- [[2025-09-19/CausalPre_ Scalable and Effective Data Pre-processing for Causal Fairness_20250919|CausalPre Scalable and Effective Data Pre-processing for Causal Fairness]] (76.7% similar)
- [[2025-09-22/Who is Responsible When AI Fails Mapping Causes, Entities, and Consequences of AI Privacy and Ethical Incidents_20250922|Who is Responsible When AI Fails Mapping Causes, Entities, and Consequences of AI Privacy and Ethical Incidents]] (76.7% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2505.19441v2 Announce Type: replace-cross 
Abstract: Recommender systems (RS), which are widely deployed across high-stakes domains, are susceptible to biases that can cause large-scale societal impacts. Researchers have proposed methods to measure and mitigate such biases -- but translating academic theory into practice is inherently challenging. RS practitioners must balance the competing interests of diverse stakeholders, including providers and users, and operate in dynamic environments. Through a semi-structured interview study (N=11), we map the RS practitioner workflow within large technology companies, focusing on how technical teams consider fairness internally and in collaboration with other (legal, data, and fairness) teams. We identify key challenges to incorporating fairness into existing RS workflows: defining fairness in RS contexts, particularly when navigating multi-stakeholder and dynamic fairness considerations. We also identify key organization-wide challenges: making time for fairness work and facilitating cross-team communication. Finally, we offer actionable recommendations for the RS community, including HCI researchers and practitioners.

## 🔍 Abstract (한글 번역)

arXiv:2505.19441v2 발표 유형: 교차 교체  
초록: 추천 시스템(RS)은 고위험 분야에서 널리 사용되며, 대규모 사회적 영향을 초래할 수 있는 편향에 취약합니다. 연구자들은 이러한 편향을 측정하고 완화하기 위한 방법을 제안했지만, 학문적 이론을 실제로 전환하는 것은 본질적으로 도전적입니다. RS 실무자들은 제공자와 사용자 등 다양한 이해관계자의 상충되는 이익을 균형 있게 조정하고, 역동적인 환경에서 운영해야 합니다. 반구조화된 인터뷰 연구(N=11)를 통해 대형 기술 회사 내 RS 실무자의 워크플로를 매핑하고, 기술 팀이 내부적으로 및 다른 팀(법률, 데이터, 공정성)과 협력하여 공정성을 고려하는 방식을 중점적으로 다룹니다. 기존 RS 워크플로에 공정성을 통합하는 데 있어 주요 과제를 식별합니다: 특히 다중 이해관계자 및 역동적인 공정성 고려사항을 탐색할 때 RS 맥락에서 공정성을 정의하는 것. 또한 조직 전반의 주요 과제를 식별합니다: 공정성 작업에 시간을 할애하고 팀 간 의사소통을 촉진하는 것. 마지막으로, HCI 연구자 및 실무자를 포함한 RS 커뮤니티를 위한 실행 가능한 권장 사항을 제시합니다.

## 📝 요약

이 논문은 추천 시스템(RS)의 공정성 문제를 다루며, 대규모 기술 기업 내 RS 실무자들의 워크플로우를 분석합니다. 연구진은 반구조화된 인터뷰(N=11)를 통해 RS 팀이 공정성을 어떻게 고려하는지 조사했습니다. 주요 발견사항으로는 RS에서 공정성을 정의하는 어려움, 다중 이해관계자 및 동적 환경에서의 공정성 고려, 그리고 조직 내 공정성 작업을 위한 시간 확보와 팀 간 소통의 어려움이 있습니다. 연구는 RS 커뮤니티를 위한 실질적인 권고사항을 제시하며, HCI 연구자와 실무자들에게도 유용한 통찰을 제공합니다.

## 🎯 주요 포인트

- 1. 추천 시스템(RS)은 사회적 영향을 미칠 수 있는 편향에 취약하며, 이를 측정하고 완화하기 위한 방법이 제안되고 있다.

- 2. 대형 기술 기업 내 RS 실무자 워크플로우를 조사한 결과, 공정성을 기존 RS 워크플로우에 통합하는 데 있어 정의 및 다중 이해관계자와의 협력에서 어려움이 발견되었다.

- 3. 조직 전반에서 공정성 작업을 위한 시간 확보와 팀 간 커뮤니케이션 촉진이 주요 과제로 확인되었다.

- 4. RS 커뮤니티, 특히 HCI 연구자 및 실무자를 위한 실행 가능한 권장 사항이 제시되었다.

---

*Generated on 2025-09-22 14:50:53*