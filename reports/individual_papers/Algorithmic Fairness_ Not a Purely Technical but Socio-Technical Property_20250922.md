# Algorithmic Fairness: Not a Purely Technical but Socio-Technical Property

**Korean Title:** 알고리즘 공정성: 순수한 기술적 속성이 아닌 사회-기술적 속성

## 📋 메타데이터

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Socio-Technical Fairness

## 🔗 유사한 논문
- [[2025-09-17/APFEx_ Adaptive Pareto Front Explorer for Intersectional Fairness_20250917|APFEx Adaptive Pareto Front Explorer for Intersectional Fairness]] (83.1% similar)
- [[2025-09-22/Fairness-in-the-Workflow_ How Machine Learning Practitioners at Big Tech Companies Approach Fairness in Recommender Systems_20250922|Fairness-in-the-Workflow How Machine Learning Practitioners at Big Tech Companies Approach Fairness in Recommender Systems]] (82.9% similar)
- [[2025-09-22/Who is Responsible When AI Fails Mapping Causes, Entities, and Consequences of AI Privacy and Ethical Incidents_20250922|Who is Responsible When AI Fails Mapping Causes, Entities, and Consequences of AI Privacy and Ethical Incidents]] (82.3% similar)
- [[2025-09-22/The Great AI Witch Hunt_ Reviewers Perception and (Mis)Conception of Generative AI in Research Writing_20250922|The Great AI Witch Hunt Reviewers Perception and (Mis)Conception of Generative AI in Research Writing]] (81.2% similar)
- [[2025-09-19/CausalPre_ Scalable and Effective Data Pre-processing for Causal Fairness_20250919|CausalPre Scalable and Effective Data Pre-processing for Causal Fairness]] (81.1% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2506.12556v2 Announce Type: replace-cross 
Abstract: The rapid trend of deploying artificial intelligence (AI) and machine learning (ML) systems in socially consequential domains has raised growing concerns about their trustworthiness, including potential discriminatory behaviours. Research in algorithmic fairness has generated a proliferation of mathematical definitions and metrics, yet persistent misconceptions and limitations -- both within and beyond the fairness community -- limit their effectiveness, such as an unreached consensus on its understanding, prevailing measures primarily tailored to binary group settings, and superficial handling for intersectional contexts. Here we critically remark on these misconceptions and argue that fairness cannot be reduced to purely technical constraints on models; we also examine the limitations of existing fairness measures through conceptual analysis and empirical illustrations, showing their limited applicability in the face of complex real-world scenarios, challenging prevailing views on the incompatibility between accuracy and fairness as well as that among fairness measures themselves, and outlining three worth-considering principles in the design of fairness measures. We believe these findings will help bridge the gap between technical formalisation and social realities and meet the challenges of real-world AI/ML deployment.

## 🔍 Abstract (한글 번역)

arXiv:2506.12556v2 발표 유형: 교차 교체  
초록: 인공지능(AI) 및 기계 학습(ML) 시스템이 사회적으로 중요한 분야에 빠르게 배치되는 추세는 신뢰성, 특히 잠재적인 차별적 행동에 대한 우려를 증가시키고 있습니다. 알고리즘 공정성 연구는 수많은 수학적 정의와 지표를 생성했지만, 공정성 커뮤니티 내외에서의 지속적인 오해와 한계는 그 효과를 제한하고 있습니다. 예를 들어, 공정성에 대한 이해에 대한 합의가 이루어지지 않았고, 주로 이진 그룹 설정에 맞춰진 기존의 측정 방법, 그리고 교차성 맥락에 대한 피상적인 처리가 있습니다. 여기서 우리는 이러한 오해를 비판적으로 지적하고, 공정성이 모델에 대한 순수한 기술적 제약으로 축소될 수 없음을 주장합니다. 또한 개념적 분석과 실증적 예시를 통해 기존 공정성 측정의 한계를 검토하며, 복잡한 실제 시나리오에서의 제한된 적용 가능성을 보여주고, 정확성과 공정성 간의 불일치 및 공정성 측정 간의 불일치에 대한 기존의 견해에 도전하며, 공정성 측정 설계에서 고려할 가치가 있는 세 가지 원칙을 제시합니다. 우리는 이러한 발견이 기술적 형식화와 사회적 현실 사이의 격차를 좁히고, 실제 AI/ML 배포의 도전에 대응하는 데 도움이 될 것이라고 믿습니다.

## 📝 요약

이 논문은 인공지능(AI) 및 기계 학습(ML) 시스템의 신뢰성 문제, 특히 차별적 행동에 대한 우려를 다룹니다. 알고리즘 공정성 연구에서 다양한 수학적 정의와 지표가 제시되었지만, 이들의 효과성은 제한적입니다. 이는 공정성에 대한 합의 부족, 이진 그룹 설정에 맞춰진 지표, 교차적 맥락에서의 피상적 처리 등으로 인해 발생합니다. 저자들은 공정성이 단순히 모델의 기술적 제약으로 축소될 수 없음을 주장하며, 기존 공정성 지표의 한계를 개념적 분석과 실증적 예시를 통해 설명합니다. 또한, 정확성과 공정성 간의 불일치 및 공정성 지표 간의 불일치에 대한 기존 관점을 도전하며, 공정성 지표 설계 시 고려해야 할 세 가지 원칙을 제시합니다. 이러한 발견은 기술적 형식화와 사회적 현실 간의 격차를 줄이고, 실제 AI/ML 배포의 도전에 대응하는 데 기여할 것입니다.

## 🎯 주요 포인트

- 1. 인공지능 및 기계 학습 시스템의 신뢰성에 대한 우려가 증가하고 있으며, 특히 차별적 행동 가능성에 대한 연구가 필요합니다.

- 2. 알고리즘 공정성 연구에서 수많은 수학적 정의와 지표가 생성되었으나, 이들의 효과성은 오해와 한계로 인해 제한되고 있습니다.

- 3. 공정성은 단순히 모델에 대한 기술적 제약으로 축소될 수 없으며, 기존 공정성 지표의 한계를 개념적 분석과 실증적 예시를 통해 검토합니다.

- 4. 정확성과 공정성 간의 불일치, 그리고 공정성 지표들 간의 불일치에 대한 기존 관점을 도전하며, 공정성 지표 설계에 고려해야 할 세 가지 원칙을 제시합니다.

- 5. 이 연구 결과는 기술적 형식화와 사회적 현실 간의 격차를 줄이고, 실제 AI/ML 배포의 도전에 대응하는 데 기여할 것입니다.

---

*Generated on 2025-09-22 14:55:08*