
# Is GPT-4o mini Blinded by its Own Safety Filters? Exposing the Multimodal-to-Unimodal Bottleneck in Hate Speech Detection

**Korean Title:** GPT-4o miniëŠ” ìì²´ ì•ˆì „ í•„í„°ì— ì˜í•´ ëˆˆì´ ë©€ì—ˆëŠ”ê°€? í˜ì˜¤ ë°œì–¸ íƒì§€ì—ì„œì˜ ë©€í‹°ëª¨ë‹¬-ìœ ë‹ˆëª¨ë‹¬ ë³‘ëª©í˜„ìƒ ë…¸ì¶œ

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-18|2025-09-18]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Unimodal Bottleneck

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[Multimodal Hate Detection Using Dual-Stream Graph Neural Networks]] (82.7% similar)
- [[Humor in Pixels Benchmarking Large Multimodal Models Understanding of Online Comics]] (81.4% similar)
- [[Language Models Identify Ambiguities and Exploit Loopholes]] (81.2% similar)
- [[Understanding and Mitigating Overrefusal in LLMs from an Unveiling Perspective of Safety Decision Boundary]] (80.9% similar)
- [[CyberLLMInstruct A Pseudo-malicious Dataset Revealing Safety-performance Trade-offs in Cyber Security LLM Fine-tuning]] (80.5% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.13608v1 Announce Type: new 
Abstract: As Large Multimodal Models (LMMs) become integral to daily digital life, understanding their safety architectures is a critical problem for AI Alignment. This paper presents a systematic analysis of OpenAI's GPT-4o mini, a globally deployed model, on the difficult task of multimodal hate speech detection. Using the Hateful Memes Challenge dataset, we conduct a multi-phase investigation on 500 samples to probe the model's reasoning and failure modes. Our central finding is the experimental identification of a "Unimodal Bottleneck," an architectural flaw where the model's advanced multimodal reasoning is systematically preempted by context-blind safety filters. A quantitative validation of 144 content policy refusals reveals that these overrides are triggered in equal measure by unimodal visual 50% and textual 50% content. We further demonstrate that this safety system is brittle, blocking not only high-risk imagery but also benign, common meme formats, leading to predictable false positives. These findings expose a fundamental tension between capability and safety in state-of-the-art LMMs, highlighting the need for more integrated, context-aware alignment strategies to ensure AI systems can be deployed both safely and effectively.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.13608v1 ê³µê³  ìœ í˜•: ì‹ ê·œ
ì´ˆë¡: ëŒ€ê·œëª¨ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸(LMMs)ì´ ì¼ìƒì ì¸ ë””ì§€í„¸ ìƒí™œì˜ í•µì‹¬ ìš”ì†Œê°€ ë˜ë©´ì„œ, ì´ë“¤ì˜ ì•ˆì „ ì•„í‚¤í…ì²˜ë¥¼ ì´í•´í•˜ëŠ” ê²ƒì€ AI ì •ë ¬(AI Alignment)ì˜ ì¤‘ìš”í•œ ë¬¸ì œê°€ ë˜ì—ˆë‹¤. ë³¸ ë…¼ë¬¸ì€ ì „ ì„¸ê³„ì ìœ¼ë¡œ ë°°í¬ëœ ëª¨ë¸ì¸ OpenAIì˜ GPT-4o miniì— ëŒ€í•´ ë©€í‹°ëª¨ë‹¬ í˜ì˜¤ ë°œì–¸ íƒì§€ë¼ëŠ” ì–´ë ¤ìš´ ê³¼ì œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì²´ê³„ì  ë¶„ì„ì„ ì œì‹œí•œë‹¤. Hateful Memes Challenge ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ 500ê°œì˜ ìƒ˜í”Œì— ëŒ€í•œ ë‹¤ë‹¨ê³„ ì¡°ì‚¬ë¥¼ ìˆ˜í–‰í•˜ì—¬ ëª¨ë¸ì˜ ì¶”ë¡  ê³¼ì •ê³¼ ì‹¤íŒ¨ ëª¨ë“œë¥¼ íƒêµ¬í•˜ì˜€ë‹¤. ìš°ë¦¬ì˜ í•µì‹¬ ë°œê²¬ì€ "ìœ ë‹ˆëª¨ë‹¬ ë³‘ëª©(Unimodal Bottleneck)"ì˜ ì‹¤í—˜ì  ì‹ë³„ë¡œ, ì´ëŠ” ëª¨ë¸ì˜ ê³ ê¸‰ ë©€í‹°ëª¨ë‹¬ ì¶”ë¡ ì´ ë§¥ë½ì„ ê³ ë ¤í•˜ì§€ ì•ŠëŠ” ì•ˆì „ í•„í„°ì— ì˜í•´ ì²´ê³„ì ìœ¼ë¡œ ì„ ì ë˜ëŠ” ì•„í‚¤í…ì²˜ ê²°í•¨ì´ë‹¤. 144ê°œì˜ ì½˜í…ì¸  ì •ì±… ê±°ë¶€ ì‚¬ë¡€ì— ëŒ€í•œ ì •ëŸ‰ì  ê²€ì¦ ê²°ê³¼, ì´ëŸ¬í•œ ìš°ì„ ì  ê°œì…ì´ ìœ ë‹ˆëª¨ë‹¬ ì‹œê°ì  ì½˜í…ì¸  50%ì™€ í…ìŠ¤íŠ¸ ì½˜í…ì¸  50%ì— ì˜í•´ ë™ë“±í•œ ë¹„ìœ¨ë¡œ ì´‰ë°œë¨ì„ í™•ì¸í•˜ì˜€ë‹¤. ë˜í•œ ì´ ì•ˆì „ ì‹œìŠ¤í…œì´ ì·¨ì•½í•˜ì—¬ ê³ ìœ„í—˜ ì´ë¯¸ì§€ë¿ë§Œ ì•„ë‹ˆë¼ ë¬´í•´í•˜ê³  ì¼ë°˜ì ì¸ ë°ˆ í˜•ì‹ë„ ì°¨ë‹¨í•¨ìœ¼ë¡œì¨ ì˜ˆì¸¡ ê°€ëŠ¥í•œ ê±°ì§“ ì–‘ì„±(false positives)ì„ ì•¼ê¸°í•¨ì„ ì‹¤ì¦í•˜ì˜€ë‹¤. ì´ëŸ¬í•œ ë°œê²¬ë“¤ì€ ìµœì²¨ë‹¨ LMMsì—ì„œ ì—­ëŸ‰ê³¼ ì•ˆì „ì„± ê°„ì˜ ê·¼ë³¸ì ì¸ ê¸´ì¥ê´€ê³„ë¥¼ ë“œëŸ¬ë‚´ë©°, AI ì‹œìŠ¤í…œì´ ì•ˆì „í•˜ë©´ì„œë„ íš¨ê³¼ì ìœ¼ë¡œ ë°°í¬ë  ìˆ˜ ìˆë„ë¡ ë³´ë‹¤ í†µí•©ì ì´ê³  ë§¥ë½ì„ ì¸ì‹í•˜ëŠ” ì •ë ¬ ì „ëµì˜ í•„ìš”ì„±ì„ ê°•ì¡°í•œë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ OpenAIì˜ GPT-4o mini ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ì¤‘ ëª¨ë“œ í˜ì˜¤ ë°œì–¸ ê°ì§€ ë¬¸ì œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤. ì—°êµ¬ëŠ” Hateful Memes Challenge ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬ ëª¨ë¸ì˜ ì¶”ë¡  ë° ì‹¤íŒ¨ ëª¨ë“œë¥¼ ì¡°ì‚¬í•˜ì˜€ìœ¼ë©°, ì£¼ìš” ë°œê²¬ì€ "ë‹¨ì¼ ëª¨ë“œ ë³‘ëª©í˜„ìƒ"ì´ë¼ëŠ” êµ¬ì¡°ì  ê²°í•¨ì„ ì‹¤í—˜ì ìœ¼ë¡œ í™•ì¸í•œ ê²ƒì…ë‹ˆë‹¤. ì´ ê²°í•¨ì€ ëª¨ë¸ì˜ ê³ ê¸‰ ë‹¤ì¤‘ ëª¨ë“œ ì¶”ë¡ ì´ ë§¥ë½ì„ ê³ ë ¤í•˜ì§€ ì•ŠëŠ” ì•ˆì „ í•„í„°ì— ì˜í•´ ë°©í•´ë°›ëŠ” í˜„ìƒì„ ë§í•©ë‹ˆë‹¤. 144ê°œì˜ ì½˜í…ì¸  ì •ì±… ê±°ë¶€ ì‚¬ë¡€ë¥¼ ë¶„ì„í•œ ê²°ê³¼, ì‹œê°ì  ì½˜í…ì¸ ì™€ í…ìŠ¤íŠ¸ ì½˜í…ì¸ ê°€ ê°ê° 50%ì”© ì´ í•„í„°ì— ì˜í•´ ì°¨ë‹¨ëœë‹¤ëŠ” ê²ƒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, ì´ ì•ˆì „ ì‹œìŠ¤í…œì´ ê³ ìœ„í—˜ ì´ë¯¸ì§€ë§Œì´ ì•„ë‹ˆë¼ ì¼ë°˜ì ì¸ ë°ˆ í˜•ì‹ë„ ì°¨ë‹¨í•˜ì—¬ ì˜ˆì¸¡ ê°€ëŠ¥í•œ ì˜¤íƒì„ ë°œìƒì‹œí‚¨ë‹¤ëŠ” ì ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŸ¬í•œ ê²°ê³¼ëŠ” ìµœì‹  ë‹¤ì¤‘ ëª¨ë“œ ëª¨ë¸ì—ì„œ ëŠ¥ë ¥ê³¼ ì•ˆì „ì„± ê°„ì˜ ê·¼ë³¸ì ì¸ ê¸´ì¥ì„ ë“œëŸ¬ë‚´ë©°, ë³´ë‹¤ í†µí•©ì ì´ê³  ë§¥ë½ì„ ê³ ë ¤í•œ ì •ë ¬ ì „ëµì˜ í•„ìš”ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€ê·œëª¨ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸(LMM)ì˜ ì•ˆì „ì„± êµ¬ì¡° ì´í•´ëŠ” AI ì •ë ¬ì—ì„œ ì¤‘ìš”í•œ ë¬¸ì œë¡œ ë¶€ê°ë˜ê³  ìˆë‹¤.

- 2. OpenAIì˜ GPT-4o mini ëª¨ë¸ì„ ëŒ€ìƒìœ¼ë¡œ ë©€í‹°ëª¨ë‹¬ í˜ì˜¤ ë°œì–¸ íƒì§€ ì‘ì—…ì„ ë¶„ì„í•œ ê²°ê³¼, "ë‹¨ì¼ ëª¨ë‹¬ ë³‘ëª© í˜„ìƒ"ì´ë¼ëŠ” êµ¬ì¡°ì  ê²°í•¨ì´ ë°œê²¬ë˜ì—ˆë‹¤.

- 3. ëª¨ë¸ì˜ ì•ˆì „ í•„í„°ê°€ ë§¥ë½ì„ ê³ ë ¤í•˜ì§€ ì•Šê³  ì‘ë™í•˜ì—¬ ê³ ê¸‰ ë©€í‹°ëª¨ë‹¬ ì¶”ë¡ ì„ ë°©í•´í•˜ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ë‹¤.

- 4. ì•ˆì „ ì‹œìŠ¤í…œì´ ê³ ìœ„í—˜ ì´ë¯¸ì§€ë§Œì´ ì•„ë‹ˆë¼ ì¼ë°˜ì ì¸ ë°ˆ í˜•ì‹ë„ ì°¨ë‹¨í•˜ì—¬ ì˜¤íƒì„ ìœ ë°œí•˜ëŠ” ì·¨ì•½ì„±ì„ ë³´ì˜€ë‹¤.

- 5. LMMì˜ ëŠ¥ë ¥ê³¼ ì•ˆì „ì„± ê°„ì˜ ê·¼ë³¸ì ì¸ ê¸´ì¥ì„ ë“œëŸ¬ë‚´ë©°, ë§¥ë½ì„ ê³ ë ¤í•œ í†µí•©ì ì¸ ì •ë ¬ ì „ëµì˜ í•„ìš”ì„±ì„ ê°•ì¡°í–ˆë‹¤.

---

*Generated on 2025-09-19 11:14:23*