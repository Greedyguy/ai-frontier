
# Humor in Pixels: Benchmarking Large Multimodal Models Understanding of Online Comics

**Korean Title:** 픽셀 속의 유머: 온라인 만화에 대한 대규모 멀티모달 모델의 이해 벤치마킹

## 📋 메타데이터

**Links**: [[daily/2025-09-18|2025-09-18]] [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Multimodal Humor Understanding

## 🔗 유사한 논문
- [[Forget What You Know about LLMs Evaluations -- LLMs are Like a Chameleon]] (81.7% similar)
- [[Is GPT-4o mini Blinded by its Own Safety Filters_ Exposing the Multimodal-to-Unimodal Bottleneck in Hate Speech Detection_20250918|Is GPT-4o mini Blinded by its Own Safety Filters Exposing the Multimodal-to-Unimodal Bottleneck in Hate Speech Detection]] (81.4% similar)
- [[Visible Yet Unreadable A Systematic Blind Spot of Vision Language Models Across Writing Systems]] (80.4% similar)
- [[xGen-MM (BLIP-3) A Family of Open Large Multimodal Models]] (80.1% similar)
- [[LLM-I LLMs are Naturally Interleaved Multimodal Creators]] (80.1% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.12248v2 Announce Type: replace-cross 
Abstract: Understanding humor is a core aspect of social intelligence, yet it remains a significant challenge for Large Multimodal Models (LMMs). We introduce PixelHumor, a benchmark dataset of 2,800 annotated multi-panel comics designed to evaluate LMMs' ability to interpret multimodal humor and recognize narrative sequences. Experiments with state-of-the-art LMMs reveal substantial gaps: for instance, top models achieve only 61% accuracy in panel sequencing, far below human performance. This underscores critical limitations in current models' integration of visual and textual cues for coherent narrative and humor understanding. By providing a rigorous framework for evaluating multimodal contextual and narrative reasoning, PixelHumor aims to drive the development of LMMs that better engage in natural, socially aware interactions.

## 🔍 Abstract (한글 번역)

arXiv:2509.12248v2 공고 유형: 교차 대체
초록: 유머를 이해하는 것은 사회적 지능의 핵심 요소이지만, 대규모 다중모달 모델(LMMs)에게는 여전히 중대한 도전과제로 남아있다. 우리는 LMMs의 다중모달 유머 해석 및 내러티브 시퀀스 인식 능력을 평가하기 위해 설계된 2,800개의 주석이 달린 다중 패널 만화로 구성된 벤치마크 데이터셋인 PixelHumor를 소개한다. 최신 LMMs를 대상으로 한 실험 결과 상당한 격차가 드러났다: 예를 들어, 최고 성능 모델들도 패널 시퀀싱에서 61%의 정확도만을 달성하여 인간 성능을 크게 하회했다. 이는 일관성 있는 내러티브와 유머 이해를 위한 시각적 및 텍스트 단서의 통합에서 현재 모델들이 가진 중대한 한계를 부각시킨다. 다중모달 맥락적 및 내러티브 추론을 평가하기 위한 엄격한 프레임워크를 제공함으로써, PixelHumor는 자연스럽고 사회적으로 인식하는 상호작용에 더 잘 참여할 수 있는 LMMs의 개발을 촉진하는 것을 목표로 한다.

## 📝 요약

PixelHumor는 멀티패널 만화 2,800개로 구성된 벤치마크 데이터셋으로, 대형 멀티모달 모델(LMMs)이 멀티모달 유머를 해석하고 서사적 순서를 인식하는 능력을 평가합니다. 최신 LMMs 실험 결과, 패널 순서 배열 정확도가 61%에 불과하여 인간 성능에 크게 못 미쳤습니다. 이는 현재 모델들이 시각 및 텍스트 단서를 통합하여 서사와 유머를 이해하는 데 한계가 있음을 보여줍니다. PixelHumor는 멀티모달 맥락 및 서사 추론을 평가하는 엄격한 틀을 제공하여, 자연스럽고 사회적으로 인식 있는 상호작용을 가능하게 하는 LMMs 개발을 촉진하고자 합니다.

## 🎯 주요 포인트

- 1. PixelHumor는 2,800개의 주석이 달린 멀티 패널 만화로 구성된 벤치마크 데이터셋으로, 멀티모달 유머 해석 및 서사 시퀀스 인식을 평가하기 위해 설계되었습니다.

- 2. 최첨단 대형 멀티모달 모델(LMMs) 실험 결과, 패널 시퀀싱에서 최고 모델이 61%의 정확도를 기록하며 인간 성능에 크게 미치지 못하는 것으로 나타났습니다.

- 3. 현재 모델들이 시각적 및 텍스트적 단서를 통합하여 일관된 서사와 유머를 이해하는 데 있어 중요한 한계가 있음을 강조합니다.

- 4. PixelHumor는 멀티모달 맥락 및 서사적 추론을 평가하기 위한 엄격한 프레임워크를 제공하여, 자연스럽고 사회적으로 인식 가능한 상호작용을 더 잘 수행하는 LMMs 개발을 촉진하는 것을 목표로 합니다.

---

*Generated on 2025-09-19 11:13:03*