# Not All Degradations Are Equal: A Targeted Feature Denoising Framework for Generalizable Image Super-Resolution

**Korean Title:** ëª¨ë“  ì—´í™”ê°€ ë™ì¼í•˜ì§€ëŠ” ì•Šë‹¤: ì¼ë°˜í™” ê°€ëŠ¥í•œ ì´ë¯¸ì§€ ì´ˆí•´ìƒë„ë¥¼ ìœ„í•œ ëª©í‘œ ì§€í–¥ì  íŠ¹ì§• ì¡ìŒ ì œê±° í”„ë ˆì„ì›Œí¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-18|2025-09-18]] [[authors/Hongjun Wang|Hongjun Wang]] [[authors/Jiyuan Chen|Jiyuan Chen]] [[authors/Zhengwei Yin|Zhengwei Yin]] [[authors/Xuan Song|Xuan Song]] [[authors/Yinqiang Zheng|Yinqiang Zheng]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Generalizable Image Super-Resolution

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[End4_ End-to-end Denoising Diffusion for Diffusion-Based Inpainting Detection_20250919|End4 End-to-end Denoising Diffusion for Diffusion-Based Inpainting Detection]] (80.7% similar)
- [[HPGN_ Hybrid Priors-Guided Network for Compressed Low-Light Image Enhancement_20250919|HPGN Hybrid Priors-Guided Network for Compressed Low-Light Image Enhancement]] (79.9% similar)
- [[Low-rank surrogate modeling and stochastic zero-order optimization for training of neural networks with black-box layers_20250918|Low-rank surrogate modeling and stochastic zero-order optimization for training of neural networks with black-box layers]] (78.7% similar)
- [[Sea-ing Through Scattered Rays_ Revisiting the Image Formation Model for Realistic Underwater Image Generation_20250918|Sea-ing Through Scattered Rays Revisiting the Image Formation Model for Realistic Underwater Image Generation]] (78.4% similar)
- [[Lightweight Gradient-Aware Upscaling of 3D Gaussian Splatting Images_20250918|Lightweight Gradient-Aware Upscaling of 3D Gaussian Splatting Images]] (78.1% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** Hongjun Wang, Jiyuan Chen, Zhengwei Yin, Xuan Song, Yinqiang Zheng

## ğŸ“„ Abstract (ì›ë¬¸)

Generalizable Image Super-Resolution aims to enhance model generalization
capabilities under unknown degradations. To achieve this goal, the models are
expected to focus only on image content-related features instead of overfitting
degradations. Recently, numerous approaches such as Dropout and Feature
Alignment have been proposed to suppress models' natural tendency to overfit
degradations and yield promising results. Nevertheless, these works have
assumed that models overfit to all degradation types (e.g., blur, noise, JPEG),
while through careful investigations in this paper, we discover that models
predominantly overfit to noise, largely attributable to its distinct
degradation pattern compared to other degradation types. In this paper, we
propose a targeted feature denoising framework, comprising noise detection and
denoising modules. Our approach presents a general solution that can be
seamlessly integrated with existing super-resolution models without requiring
architectural modifications. Our framework demonstrates superior performance
compared to previous regularization-based methods across five traditional
benchmarks and datasets, encompassing both synthetic and real-world scenarios.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

ì¼ë°˜í™” ê°€ëŠ¥í•œ ì´ë¯¸ì§€ ì´ˆí•´ìƒë„(Generalizable Image Super-Resolution)ëŠ” ì•Œë ¤ì§€ì§€ ì•Šì€ ì—´í™”(degradation) ìƒí™©ì—ì„œë„ ëª¨ë¸ì˜ ì¼ë°˜í™” ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤. ì´ë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•´, ëª¨ë¸ì€ ì—´í™”ì— ê³¼ì í•©ë˜ëŠ” ëŒ€ì‹  ì´ë¯¸ì§€ ë‚´ìš©ê³¼ ê´€ë ¨ëœ íŠ¹ì§•ì—ë§Œ ì§‘ì¤‘í•´ì•¼ í•©ë‹ˆë‹¤. ìµœê·¼ì—ëŠ” ë“œë¡­ì•„ì›ƒ(Dropout)ê³¼ íŠ¹ì§• ì •ë ¬(Feature Alignment)ê³¼ ê°™ì€ ì—¬ëŸ¬ ì ‘ê·¼ë²•ì´ ëª¨ë¸ì˜ ì—´í™”ì— ëŒ€í•œ ìì—°ìŠ¤ëŸ¬ìš´ ê³¼ì í•© ê²½í–¥ì„ ì–µì œí•˜ê³  ìœ ë§í•œ ê²°ê³¼ë¥¼ ë„ì¶œí•˜ê¸° ìœ„í•´ ì œì•ˆë˜ì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ëŸ¬í•œ ì—°êµ¬ë“¤ì€ ëª¨ë¸ì´ ëª¨ë“  ì—´í™” ìœ í˜•(ì˜ˆ: ë¸”ëŸ¬, ë…¸ì´ì¦ˆ, JPEG)ì— ê³¼ì í•©ëœë‹¤ê³  ê°€ì •í•´ì™”ìŠµë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì‹ ì¤‘í•œ ì¡°ì‚¬ë¥¼ í†µí•´ ëª¨ë¸ì´ ì£¼ë¡œ ë…¸ì´ì¦ˆì— ê³¼ì í•©ëœë‹¤ëŠ” ê²ƒì„ ë°œê²¬í•˜ì˜€ìœ¼ë©°, ì´ëŠ” ë‹¤ë¥¸ ì—´í™” ìœ í˜•ê³¼ ë¹„êµí–ˆì„ ë•Œ ë…¸ì´ì¦ˆì˜ ë…íŠ¹í•œ ì—´í™” íŒ¨í„´ì— í¬ê²Œ ê¸°ì¸í•©ë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ë…¸ì´ì¦ˆ íƒì§€ ë° ì œê±° ëª¨ë“ˆë¡œ êµ¬ì„±ëœ íƒ€ê²Ÿí™”ëœ íŠ¹ì§• ì œê±° í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì ‘ê·¼ë²•ì€ ê¸°ì¡´ì˜ ì´ˆí•´ìƒë„ ëª¨ë¸ì— ì•„í‚¤í…ì²˜ ìˆ˜ì • ì—†ì´ ì›í™œí•˜ê²Œ í†µí•©ë  ìˆ˜ ìˆëŠ” ì¼ë°˜ì ì¸ ì†”ë£¨ì…˜ì„ ì œì‹œí•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ í”„ë ˆì„ì›Œí¬ëŠ” ê¸°ì¡´ì˜ ì •ê·œí™” ê¸°ë°˜ ë°©ë²•ë“¤ê³¼ ë¹„êµí•˜ì—¬ ë‹¤ì„¯ ê°€ì§€ ì „í†µì ì¸ ë²¤ì¹˜ë§ˆí¬ì™€ ë°ì´í„°ì…‹, ì¦‰ í•©ì„± ë° ì‹¤ì œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì´ë¯¸ì§€ ì´ˆí•´ìƒë„ ëª¨ë¸ì˜ ì¼ë°˜í™” ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´, ëª¨ë¸ì´ ë…¸ì´ì¦ˆì— ì£¼ë¡œ ê³¼ì í•©ëœë‹¤ëŠ” ì‚¬ì‹¤ì„ ë°œê²¬í•˜ê³  ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ë°©ë²•ë¡ ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë“œë¡­ì•„ì›ƒ ë° í”¼ì²˜ ì •ë ¬ ë°©ë²•ì€ ëª¨ë“  ìœ í˜•ì˜ ì—´í™”ì— ê³¼ì í•©ëœë‹¤ê³  ê°€ì •í–ˆìœ¼ë‚˜, ë³¸ ì—°êµ¬ëŠ” ë…¸ì´ì¦ˆê°€ ë‹¤ë¥¸ ì—´í™” ìœ í˜•ê³¼ ë‹¤ë¥¸ íŒ¨í„´ì„ ë³´ì„ì„ ë°í˜€ëƒˆìŠµë‹ˆë‹¤. ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ë…¸ì´ì¦ˆ íƒì§€ ë° ì œê±° ëª¨ë“ˆë¡œ êµ¬ì„±ëœ í”¼ì²˜ ë””ë…¸ì´ì§• í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•˜ë©°, ì´ëŠ” ê¸°ì¡´ ëª¨ë¸ì— êµ¬ì¡°ì  ë³€ê²½ ì—†ì´ í†µí•© ê°€ëŠ¥í•©ë‹ˆë‹¤. ì œì•ˆëœ ë°©ë²•ì€ ê¸°ì¡´ì˜ ì •ê·œí™” ê¸°ë°˜ ë°©ë²•ë“¤ë³´ë‹¤ 5ê°œì˜ ì „í†µì ì¸ ë²¤ì¹˜ë§ˆí¬ ë° ë°ì´í„°ì…‹ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì¼ë°˜í™” ê°€ëŠ¥í•œ ì´ë¯¸ì§€ ì´ˆí•´ìƒë„ëŠ” ë¯¸ì§€ì˜ ì—´í™” ìƒí™©ì—ì„œ ëª¨ë¸ì˜ ì¼ë°˜í™” ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

- 2. ìµœê·¼ ë“œë¡­ì•„ì›ƒê³¼ íŠ¹ì§• ì •ë ¬ê³¼ ê°™ì€ ì ‘ê·¼ë²•ì´ ëª¨ë¸ì˜ ì—´í™” ê³¼ì í•©ì„ ì–µì œí•˜ëŠ” ë° ì‚¬ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤.

- 3. ë³¸ ì—°êµ¬ì—ì„œëŠ” ëª¨ë¸ì´ ì£¼ë¡œ ë…¸ì´ì¦ˆì— ê³¼ì í•©ëœë‹¤ëŠ” ì‚¬ì‹¤ì„ ë°œê²¬í•˜ê³ , ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë…¸ì´ì¦ˆ íƒì§€ ë° ì œê±° ëª¨ë“ˆë¡œ êµ¬ì„±ëœ ëª©í‘œ ì§€í–¥ì  íŠ¹ì§• ì œê±° í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.

- 4. ì œì•ˆëœ í”„ë ˆì„ì›Œí¬ëŠ” ê¸°ì¡´ ì´ˆí•´ìƒë„ ëª¨ë¸ì— êµ¬ì¡°ì  ë³€ê²½ ì—†ì´ í†µí•©ë  ìˆ˜ ìˆëŠ” ì¼ë°˜ì ì¸ ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.

- 5. ìš°ë¦¬ì˜ í”„ë ˆì„ì›Œí¬ëŠ” ë‹¤ì„¯ ê°€ì§€ ì „í†µì ì¸ ë²¤ì¹˜ë§ˆí¬ì™€ ë°ì´í„°ì…‹ì—ì„œ ì´ì „ì˜ ì •ê·œí™” ê¸°ë°˜ ë°©ë²•ë“¤ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

---

*Generated on 2025-09-20 02:48:22*