# Mitigating Intra-Speaker Variability in Diarization with Style-Controllable Speech Augmentation

**Korean Title:** í™”ì ë‚´ ë³€ë™ì„±ì„ ì™„í™”í•˜ê¸° ìœ„í•œ ìŠ¤íƒ€ì¼ ì œì–´ ê°€ëŠ¥í•œ ìŒì„± ì¦ê°•ì„ í†µí•œ ë‹¤ì´ì–´ë¦¬ì œì´ì…˜ ê°œì„ 

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-18|2025-09-18]] [[authors/Miseul Kim|Miseul Kim]] [[authors/Soo Jin Park|Soo Jin Park]] [[authors/Kyungguen Byun|Kyungguen Byun]] [[authors/Hyeon-Kyeong Shin|Hyeon-Kyeong Shin]] [[authors/Sunkuk Moon|Sunkuk Moon]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Intra-speaker Variability Mitigation

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[Hybrid Autoregressive-Diffusion Model for Real-Time Sign Language Production_20250919|Hybrid Autoregressive-Diffusion Model for Real-Time Sign Language Production]] (79.5% similar)
- [[Towards Human-like Multimodal Conversational Agent by Generating Engaging Speech_20250919|Towards Human-like Multimodal Conversational Agent by Generating Engaging Speech]] (78.8% similar)
- [[Diffusion-Based Unsupervised Audio-Visual Speech Separation in Noisy Environments with Noise Prior_20250919|Diffusion-Based Unsupervised Audio-Visual Speech Separation in Noisy Environments with Noise Prior]] (78.5% similar)
- [[Mitigating data replication in text-to-audio generative diffusion models through anti-memorization guidance_20250919|Mitigating data replication in text-to-audio generative diffusion models through anti-memorization guidance]] (78.1% similar)
- [[SpeechOp_ Inference-Time Task Composition for Generative Speech Processing_20250919|SpeechOp Inference-Time Task Composition for Generative Speech Processing]] (77.1% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** Miseul Kim, Soo Jin Park, Kyungguen Byun, Hyeon-Kyeong Shin, Sunkuk Moon, Shuhua Zhang, Erik Visser

## ğŸ“„ Abstract (ì›ë¬¸)

Speaker diarization systems often struggle with high intrinsic intra-speaker
variability, such as shifts in emotion, health, or content. This can cause
segments from the same speaker to be misclassified as different individuals,
for example, when one raises their voice or speaks faster during conversation.
To address this, we propose a style-controllable speech generation model that
augments speech across diverse styles while preserving the target speaker's
identity. The proposed system starts with diarized segments from a conventional
diarizer. For each diarized segment, it generates augmented speech samples
enriched with phonetic and stylistic diversity. And then, speaker embeddings
from both the original and generated audio are blended to enhance the system's
robustness in grouping segments with high intrinsic intra-speaker variability.
We validate our approach on a simulated emotional speech dataset and the
truncated AMI dataset, demonstrating significant improvements, with error rate
reductions of 49% and 35% on each dataset, respectively.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

í™”ì ë¶„í•  ì‹œìŠ¤í…œì€ ê°ì •, ê±´ê°•, ë˜ëŠ” ë‚´ìš©ì˜ ë³€í™”ì™€ ê°™ì€ ë†’ì€ ë‚´ì¬ì  í™”ì ë‚´ ë³€ë™ì„±ìœ¼ë¡œ ì¸í•´ ì¢…ì¢… ì–´ë ¤ì›€ì„ ê²ªìŠµë‹ˆë‹¤. ì´ëŠ” ë™ì¼í•œ í™”ìì˜ ì„¸ê·¸ë¨¼íŠ¸ê°€ ì„œë¡œ ë‹¤ë¥¸ ê°œì²´ë¡œ ì˜ëª» ë¶„ë¥˜ë˜ëŠ” ì›ì¸ì´ ë  ìˆ˜ ìˆìœ¼ë©°, ì˜ˆë¥¼ ë“¤ì–´ ëŒ€í™” ì¤‘ì— ëª©ì†Œë¦¬ë¥¼ ë†’ì´ê±°ë‚˜ ë” ë¹ ë¥´ê²Œ ë§í•  ë•Œ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ëŒ€ìƒ í™”ìì˜ ì •ì²´ì„±ì„ ìœ ì§€í•˜ë©´ì„œ ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ë¡œ ìŒì„±ì„ ì¦ê°•í•˜ëŠ” ìŠ¤íƒ€ì¼ ì œì–´ ê°€ëŠ¥í•œ ìŒì„± ìƒì„± ëª¨ë¸ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì œì•ˆëœ ì‹œìŠ¤í…œì€ ê¸°ì¡´ì˜ í™”ì ë¶„í• ê¸°ì˜ ë¶„í• ëœ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ì‹œì‘í•©ë‹ˆë‹¤. ê° ë¶„í• ëœ ì„¸ê·¸ë¨¼íŠ¸ì— ëŒ€í•´, ìŒìš´ì  ë° ìŠ¤íƒ€ì¼ì  ë‹¤ì–‘ì„±ì´ í’ë¶€í•œ ì¦ê°• ìŒì„± ìƒ˜í”Œì„ ìƒì„±í•©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ, ì›ë³¸ ë° ìƒì„±ëœ ì˜¤ë””ì˜¤ì—ì„œ í™”ì ì„ë² ë”©ì„ í˜¼í•©í•˜ì—¬ ë†’ì€ ë‚´ì¬ì  í™”ì ë‚´ ë³€ë™ì„±ì„ ê°€ì§„ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ê·¸ë£¹í™”í•˜ëŠ” ì‹œìŠ¤í…œì˜ ê²¬ê³ ì„±ì„ ê°•í™”í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ëª¨ì˜ ê°ì • ìŒì„± ë°ì´í„°ì…‹ê³¼ ì¶•ì•½ëœ AMI ë°ì´í„°ì…‹ì—ì„œ ìš°ë¦¬ì˜ ì ‘ê·¼ ë°©ì‹ì„ ê²€ì¦í•˜ì˜€ìœ¼ë©°, ê°ê°ì˜ ë°ì´í„°ì…‹ì—ì„œ ì˜¤ë¥˜ìœ¨ì´ 49%ì™€ 35% ê°ì†Œí•˜ëŠ” ìœ ì˜ë¯¸í•œ ê°œì„ ì„ ì…ì¦í•˜ì˜€ìŠµë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ê°ì •, ê±´ê°•, ë‚´ìš© ë³€í™” ë“±ìœ¼ë¡œ ì¸í•œ í™”ìì˜ ë‚´ì¬ì  ë³€ë™ì„± ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ìŠ¤íƒ€ì¼ ì œì–´ ê°€ëŠ¥í•œ ìŒì„± ìƒì„± ëª¨ë¸ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ í™”ì ë¶„í•  ì‹œìŠ¤í…œì—ì„œ ì–»ì€ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ì˜ ìŒì„±ì„ ìƒì„±í•˜ì—¬ í™”ìì˜ ì •ì²´ì„±ì„ ìœ ì§€í•˜ë©´ì„œë„ ìŒì„±ì˜ ë‹¤ì–‘ì„±ì„ ì¦ëŒ€ì‹œí‚µë‹ˆë‹¤. ì›ë³¸ ë° ìƒì„±ëœ ìŒì„±ì—ì„œ ì¶”ì¶œí•œ í™”ì ì„ë² ë”©ì„ ê²°í•©í•˜ì—¬ ì‹œìŠ¤í…œì˜ ê°•ê±´ì„±ì„ ë†’ì…ë‹ˆë‹¤. ì œì•ˆëœ ë°©ë²•ì€ ëª¨ì˜ ê°ì • ìŒì„± ë°ì´í„°ì…‹ê³¼ AMI ë°ì´í„°ì…‹ì—ì„œ ê°ê° 49%ì™€ 35%ì˜ ì˜¤ë¥˜ìœ¨ ê°ì†Œë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. í™”ì ë¶„í•  ì‹œìŠ¤í…œì€ ê°ì •, ê±´ê°•, ë‚´ìš© ë³€í™” ë“±ìœ¼ë¡œ ì¸í•œ í™”ì ë‚´ ë³€ë™ì„± ë•Œë¬¸ì— ë™ì¼ í™”ìì˜ ë°œí™”ê°€ ë‹¤ë¥¸ ì‚¬ëŒì˜ ê²ƒìœ¼ë¡œ ì˜ëª» ë¶„ë¥˜ë  ìˆ˜ ìˆë‹¤.

- 2. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ëª©í‘œ í™”ìì˜ ì •ì²´ì„±ì„ ìœ ì§€í•˜ë©´ì„œ ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ë¡œ ìŒì„±ì„ ì¦ê°•í•˜ëŠ” ìŠ¤íƒ€ì¼ ì œì–´ ê°€ëŠ¥í•œ ìŒì„± ìƒì„± ëª¨ë¸ì„ ì œì•ˆí•œë‹¤.

- 3. ì œì•ˆëœ ì‹œìŠ¤í…œì€ ê¸°ì¡´ì˜ í™”ì ë¶„í•  ì‹œìŠ¤í…œì—ì„œ ì‹œì‘í•˜ì—¬, ê° ë¶„í• ëœ ì„¸ê·¸ë¨¼íŠ¸ì— ëŒ€í•´ ìŒìš´ ë° ìŠ¤íƒ€ì¼ ë‹¤ì–‘ì„±ì´ í’ë¶€í•œ ì¦ê°• ìŒì„± ìƒ˜í”Œì„ ìƒì„±í•œë‹¤.

- 4. ì›ë³¸ ë° ìƒì„±ëœ ì˜¤ë””ì˜¤ì—ì„œ í™”ì ì„ë² ë”©ì„ í˜¼í•©í•˜ì—¬ í™”ì ë‚´ ë³€ë™ì„±ì´ í° ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ê·¸ë£¹í™”í•˜ëŠ” ì‹œìŠ¤í…œì˜ ê°•ê±´ì„±ì„ í–¥ìƒì‹œí‚¨ë‹¤.

- 5. ì œì•ˆëœ ì ‘ê·¼ë²•ì€ ê°ì •ì  ìŒì„± ë°ì´í„°ì…‹ê³¼ AMI ë°ì´í„°ì…‹ì—ì„œ ê°ê° 49%ì™€ 35%ì˜ ì˜¤ë¥˜ìœ¨ ê°ì†Œë¥¼ ë³´ì—¬ì£¼ë©° ìœ ì˜ë¯¸í•œ ê°œì„ ì„ ì…ì¦í•œë‹¤.

---

*Generated on 2025-09-20 05:48:10*