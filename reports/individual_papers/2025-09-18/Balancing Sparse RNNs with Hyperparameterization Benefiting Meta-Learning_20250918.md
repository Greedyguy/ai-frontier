---
keywords:
  - Meta-Learning
  - Neural Networks
  - Hidden Proportion Metric
category: cs.AI
publish_date: 2025-09-18
arxiv_id:
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 22:37:50.877577",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Meta-Learning",
    "Neural Networks",
    "Hidden Proportion Metric"
  ],
  "rejected_keywords": [
    "Optimization"
  ],
  "similarity_scores": {
    "Meta-Learning": 0.8,
    "Neural Networks": 0.78,
    "Hidden Proportion Metric": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->

# Balancing Sparse RNNs with Hyperparameterization Benefiting Meta-Learning

**Korean Title:** í¬ì†Œ RNNì˜ ê· í˜• ì¡°ì •: ë©”íƒ€ í•™ìŠµì— ìœ ìµí•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°í™”

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[digests/daily_digest_20250918|2025-09-18]]     [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸŒ Broad Technical**: [[keywords/Neural Networks|sparse Recurrent Neural Networks]]
**ğŸ”— Specific Connectable**: [[keywords/Meta-Learning|meta-learning]]
**âš¡ Unique Technical**: [[keywords/Hidden Proportion Metric|hidden proportion]]

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[Online reinforcement learning via sparse Gaussian mixture model Q-functions_20250919|Online reinforcement learning via sparse Gaussian mixture model Q-functions]] (79.4% similar)
- [[Low-rank surrogate modeling and stochastic zero-order optimization for training of neural networks with black-box layers_20250918|Low-rank surrogate modeling and stochastic zero-order optimization for training of neural networks with black-box layers]] (78.9% similar)
- [[HAM_ Hierarchical Adapter Merging for Scalable Continual Learning_20250918|HAM Hierarchical Adapter Merging for Scalable Continual Learning]] (78.1% similar)
- [[A Universal Banach--Bregman Framework for Stochastic Iterations_ Unifying Stochastic Mirror Descent, Learning and LLM Training_20250917|A Universal Banach--Bregman Framework for Stochastic Iterations Unifying Stochastic Mirror Descent, Learning and LLM Training]] (78.0% similar)
- [[Probabilistic and nonlinear compressive sensing_20250918|Probabilistic and nonlinear compressive sensing]] (77.9% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** Quincy Hershey, Randy Paffenroth

## ğŸ“„ Abstract (ì›ë¬¸)

This paper develops alternative hyperparameters for specifying sparse
Recurrent Neural Networks (RNNs). These hyperparameters allow for varying
sparsity within the trainable weight matrices of the model while improving
overall performance. This architecture enables the definition of a novel
metric, hidden proportion, which seeks to balance the distribution of unknowns
within the model and provides significant explanatory power of model
performance. Together, the use of the varied sparsity RNN architecture combined
with the hidden proportion metric generates significant performance gains while
improving performance expectations on an a priori basis. This combined approach
provides a path forward towards generalized meta-learning applications and
model optimization based on intrinsic characteristics of the data set,
including input and output dimensions.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

ì´ ë…¼ë¬¸ì€ í¬ì†Œ ìˆœí™˜ ì‹ ê²½ë§(RNN)ì„ ì§€ì •í•˜ê¸° ìœ„í•œ ëŒ€ì²´ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ê°œë°œí•©ë‹ˆë‹¤. ì´ëŸ¬í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ëŠ” ëª¨ë¸ì˜ í•™ìŠµ ê°€ëŠ¥í•œ ê°€ì¤‘ì¹˜ í–‰ë ¬ ë‚´ì—ì„œ í¬ì†Œì„±ì„ ë‹¤ì–‘í•˜ê²Œ ì¡°ì •í•  ìˆ˜ ìˆê²Œ í•˜ë©°, ì „ë°˜ì ì¸ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì´ ì•„í‚¤í…ì²˜ëŠ” ëª¨ë¸ ë‚´ ë¯¸ì§€ìˆ˜ì˜ ë¶„í¬ë¥¼ ê· í˜• ìˆê²Œ ì¡°ì •í•˜ê³  ëª¨ë¸ ì„±ëŠ¥ì— ëŒ€í•œ ì¤‘ìš”í•œ ì„¤ëª…ë ¥ì„ ì œê³µí•˜ëŠ” ìƒˆë¡œìš´ ì§€í‘œì¸ 'ì€ë‹‰ ë¹„ìœ¨(hidden proportion)'ì„ ì •ì˜í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤. ë‹¤ì–‘í•œ í¬ì†Œì„± RNN ì•„í‚¤í…ì²˜ì™€ ì€ë‹‰ ë¹„ìœ¨ ì§€í‘œì˜ ê²°í•© ì‚¬ìš©ì€ ì„±ëŠ¥ ê¸°ëŒ€ì¹˜ë¥¼ ì‚¬ì „ì— ê°œì„ í•˜ë©´ì„œë„ ìƒë‹¹í•œ ì„±ëŠ¥ í–¥ìƒì„ ê°€ì ¸ì˜µë‹ˆë‹¤. ì´ëŸ¬í•œ ê²°í•© ì ‘ê·¼ë²•ì€ ì…ë ¥ ë° ì¶œë ¥ ì°¨ì›ì„ í¬í•¨í•œ ë°ì´í„° ì„¸íŠ¸ì˜ ë‚´ì¬ì  íŠ¹ì„±ì— ê¸°ë°˜í•œ ì¼ë°˜í™”ëœ ë©”íƒ€ í•™ìŠµ ì‘ìš© ë° ëª¨ë¸ ìµœì í™”ë¥¼ í–¥í•œ ì§„ë¡œë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ í¬ì†Œì„± ê°€ì¤‘ì¹˜ë¥¼ ê°€ì§„ ìˆœí™˜ ì‹ ê²½ë§(RNN)ì„ ìœ„í•œ ìƒˆë¡œìš´ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ê°œë°œí–ˆìŠµë‹ˆë‹¤. ì´ í•˜ì´í¼íŒŒë¼ë¯¸í„°ëŠ” ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ í–‰ë ¬ ë‚´ í¬ì†Œì„±ì„ ì¡°ì ˆí•˜ì—¬ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ë˜í•œ, 'ìˆ¨ê²¨ì§„ ë¹„ìœ¨'ì´ë¼ëŠ” ìƒˆë¡œìš´ ì§€í‘œë¥¼ ë„ì…í•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ì„ ì„¤ëª…í•˜ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì ‘ê·¼ ë°©ì‹ì€ ë‹¤ì–‘í•œ í¬ì†Œì„± RNN ì•„í‚¤í…ì²˜ì™€ ìˆ¨ê²¨ì§„ ë¹„ìœ¨ ì§€í‘œë¥¼ ê²°í•©í•˜ì—¬ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚¤ê³ , ë°ì´í„° ì„¸íŠ¸ì˜ ë³¸ì§ˆì  íŠ¹ì„±ì— ê¸°ë°˜í•œ ëª¨ë¸ ìµœì í™” ë° ë©”íƒ€ í•™ìŠµ ì‘ìš©ì— ê¸°ì—¬í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì´ ë…¼ë¬¸ì€ í¬ì†Œì„±ì„ ì¡°ì ˆí•  ìˆ˜ ìˆëŠ” ëŒ€ì²´ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ í†µí•´ í¬ì†Œ ìˆœí™˜ ì‹ ê²½ë§(RNN)ì„ ê°œë°œí•©ë‹ˆë‹¤.

- 2. ìƒˆë¡œìš´ ë©”íŠ¸ë¦­ì¸ 'hidden proportion'ì„ ì •ì˜í•˜ì—¬ ëª¨ë¸ ë‚´ ë¯¸ì§€ìˆ˜ì˜ ë¶„í¬ë¥¼ ê· í˜• ìˆê²Œ ì¡°ì ˆí•˜ê³  ì„±ëŠ¥ ì„¤ëª…ë ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

- 3. ë‹¤ì–‘í•œ í¬ì†Œì„± RNN ì•„í‚¤í…ì²˜ì™€ hidden proportion ë©”íŠ¸ë¦­ì˜ ê²°í•©ì€ ì„±ëŠ¥ ê¸°ëŒ€ì¹˜ë¥¼ ì‚¬ì „ì— ê°œì„ í•˜ë©´ì„œ ì„±ëŠ¥ í–¥ìƒì„ ì´ëŒì–´ëƒ…ë‹ˆë‹¤.

- 4. ì´ ì ‘ê·¼ë²•ì€ ë°ì´í„° ì„¸íŠ¸ì˜ ë‚´ì¬ì  íŠ¹ì„±ì— ê¸°ë°˜í•œ ì¼ë°˜í™”ëœ ë©”íƒ€ í•™ìŠµ ì‘ìš© ë° ëª¨ë¸ ìµœì í™”ì˜ ê°€ëŠ¥ì„±ì„ ì œì‹œí•©ë‹ˆë‹¤.

---

*Generated on 2025-09-20 01:06:19*