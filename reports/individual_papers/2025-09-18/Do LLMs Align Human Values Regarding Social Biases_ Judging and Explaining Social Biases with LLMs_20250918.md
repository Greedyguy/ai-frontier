---
keywords:
  - Large Language Models
  - Human Values
  - Social Biases
category: cs.AI
publish_date: 2025-09-18
arxiv_id: 2509.13869
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 22:32:13.848709",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Models",
    "Human Values",
    "Social Biases"
  ],
  "rejected_keywords": [
    "Model Families"
  ],
  "similarity_scores": {
    "Large Language Models": 0.8,
    "Human Values": 0.78,
    "Social Biases": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->


# Do LLMs Align Human Values Regarding Social Biases? Judging and Explaining Social Biases with LLMs

**Korean Title:** LLMμ΄ μ‚¬νμ  νΈκ²¬μ— λ€ν• μΈκ°„ κ°€μΉλ¥Ό μΌμΉμ‹ν‚¤λ”κ°€? LLMμ„ μ‚¬μ©ν•μ—¬ μ‚¬νμ  νΈκ²¬μ„ νλ‹¨ν•κ³  μ„¤λ…ν•κΈ°

## π“‹ λ©”νƒ€λ°μ΄ν„°

**Links**: [[digests/daily_digest_20250918|2025-09-18]]   [[categories/cs.AI|cs.AI]]

## π·οΈ μΉ΄ν…κ³ λ¦¬ν™”λ ν‚¤μ›λ“
**β΅ Unique Technical**: [[keywords/Human Values|Human Values]], [[keywords/Social Biases|Social Biases]]
**π€ Evolved Concepts**: [[keywords/Large Language Models|Large Language Models]]

## π”— μ μ‚¬ν• λ…Όλ¬Έ
- [[How_Does_Cognitive_Bias_Affect_Large_Language_Models_A_Case_Study_on_the_Anchoring_Effect_in_Price_Negotiation_Simulations_20250918|How Does Cognitive Bias Affect Large Language Models? A Case Study on the Anchoring Effect in Price Negotiation Simulations]] (85.3% similar)
- [[A Comprehensive Survey on the Trustworthiness of Large Language Models in Healthcare]] (84.7% similar)
- [[Forget What You Know about LLMs Evaluations -- LLMs are Like a Chameleon]] (83.8% similar)
- [[Language Models Identify Ambiguities and Exploit Loopholes]] (83.2% similar)
- [[Emergent_Social_Dynamics_of_LLM_Agents_in_the_El_Farol_Bar_Problem_20250918|Emergent Social Dynamics of LLM Agents in the El Farol Bar Problem]] (82.6% similar)

## π“‹ μ €μ μ •λ³΄

**Authors:** 

## π“„ Abstract (μ›λ¬Έ)

arXiv:2509.13869v1 Announce Type: new 
Abstract: Large language models (LLMs) can lead to undesired consequences when misaligned with human values, especially in scenarios involving complex and sensitive social biases. Previous studies have revealed the misalignment of LLMs with human values using expert-designed or agent-based emulated bias scenarios. However, it remains unclear whether the alignment of LLMs with human values differs across different types of scenarios (e.g., scenarios containing negative vs. non-negative questions). In this study, we investigate the alignment of LLMs with human values regarding social biases (HVSB) in different types of bias scenarios. Through extensive analysis of 12 LLMs from four model families and four datasets, we demonstrate that LLMs with large model parameter scales do not necessarily have lower misalignment rate and attack success rate. Moreover, LLMs show a certain degree of alignment preference for specific types of scenarios and the LLMs from the same model family tend to have higher judgment consistency. In addition, we study the understanding capacity of LLMs with their explanations of HVSB. We find no significant differences in the understanding of HVSB across LLMs. We also find LLMs prefer their own generated explanations. Additionally, we endow smaller language models (LMs) with the ability to explain HVSB. The generation results show that the explanations generated by the fine-tuned smaller LMs are more readable, but have a relatively lower model agreeability.

## π” Abstract (ν•κΈ€ λ²μ—­)

arXiv:2509.13869v1 λ°ν‘ μ ν•: μƒλ΅μ΄
μ”μ•½: λ€ν• μ–Έμ–΄ λ¨λΈ (LLMs)μ€ μΈκ°„μ κ°€μΉμ™€ μΌμΉν•μ§€ μ•μ„ λ• νΉν λ³µμ΅ν•κ³  λ―Όκ°ν• μ‚¬νμ  νΈν–¥μ΄ ν¬ν•¨λ μ‹λ‚λ¦¬μ¤μ—μ„ μ›μΉ μ•λ” κ²°κ³Όλ΅ μ΄μ–΄μ§ μ μμµλ‹λ‹¤. μ΄μ „ μ—°κµ¬μ—μ„λ” μ „λ¬Έκ°€κ°€ μ„¤κ³„ν• λλ” μ—μ΄μ „νΈ κΈ°λ°μ ν‰λ‚΄ λ‚΄λ” νΈν–¥ μ‹λ‚λ¦¬μ¤λ¥Ό μ‚¬μ©ν•μ—¬ LLMsμ μΈκ°„μ κ°€μΉμ™€μ λ¶μΌμΉλ¥Ό λ°ν€λƒμµλ‹λ‹¤. κ·Έλ¬λ‚ LLMsμ μΈκ°„μ κ°€μΉμ™€μ μΌμΉ μ—¬λ¶€κ°€ λ‹¤λ¥Έ μ ν•μ μ‹λ‚λ¦¬μ¤(μ: λ¶€μ •μ μΈ vs. λΉ„λ¶€μ •μ μΈ μ§λ¬Έμ΄ ν¬ν•¨λ μ‹λ‚λ¦¬μ¤) κ°„μ— λ‹¤λ¥Έμ§€ μ—¬μ „ν λ¶λ¶„λ…ν•©λ‹λ‹¤. λ³Έ μ—°κµ¬μ—μ„λ” λ‹¤μ–‘ν• μ ν•μ νΈν–¥ μ‹λ‚λ¦¬μ¤μ—μ„ LLMsμ μΈκ°„μ κ°€μΉμ™€μ μΌμΉλ¥Ό μ΅°μ‚¬ν•©λ‹λ‹¤. λ„¤ κ°€μ§€ λ¨λΈ ν¨λ°€λ¦¬μ™€ λ„¤ κ°€μ§€ λ°μ΄ν„°μ…‹μ—μ„ 12κ°μ LLMsλ¥Ό μ² μ €ν λ¶„μ„ν•μ—¬ λ€ν• λ¨λΈ λ§¤κ° λ³€μ κ·λ¨λ¥Ό κ°€μ§„ LLMsκ°€ μΌμΉμ¨κ³Ό κ³µκ²© μ„±κ³µλ¥ μ΄ λ‚®λ‹¤λ” κ²ƒμ„ μ…μ¦ν•©λ‹λ‹¤. λν•, νΉμ • μ ν•μ μ‹λ‚λ¦¬μ¤μ— λ€ν•΄ LLMsκ°€ μΌμ •ν• μ •λ ¬ μ„ νΈλ„λ¥Ό λ³΄μ΄λ©°, λ™μΌν• λ¨λΈ ν¨λ°€λ¦¬μ LLMsλ” λ” λ†’μ€ νλ‹¨ μΌκ΄€μ„±μ„ κ°€μ§‘λ‹λ‹¤. λν•, LLMsμ HVSB μ„¤λ…λ ¥μ„ μ—°κµ¬ν•©λ‹λ‹¤. LLMs κ°„ HVSB μ΄ν•΄μ—λ” μ μλ―Έν• μ°¨μ΄κ°€ μ—†μμ„ λ°κ²¬ν•©λ‹λ‹¤. λν•, LLMsλ” μμ²΄ μƒμ„±λ μ„¤λ…μ„ μ„ νΈν•λ” κ²ƒμΌλ΅ λ‚νƒ€λƒ…λ‹λ‹¤. μ¶”κ°€λ΅, μ°λ¦¬λ” λ” μ‘μ€ μ–Έμ–΄ λ¨λΈ (LMs)μ—κ² HVSBλ¥Ό μ„¤λ…ν•  μ μλ” λ¥λ ¥μ„ λ¶€μ—¬ν•©λ‹λ‹¤. μƒμ„± κ²°κ³Όλ” μ„Έλ°€ν•κ² μ΅°μ •λ λ” μ‘μ€ LMsκ°€ μƒμ„±ν• μ„¤λ…μ΄ λ” μ½κΈ° μ‰½μ§€λ§, μƒλ€μ μΌλ΅ λ‚®μ€ λ¨λΈ ν•©μμ„±μ„ κ°€μ§€κ³  μμμ„ λ³΄μ—¬μ¤λ‹λ‹¤.

## π“ μ”μ•½

μ΄ μ—°κµ¬λ” λ€ν• μ–Έμ–΄ λ¨λΈ(LLMs)μ΄ μΈκ°„ κ°€μΉμ™€ μΌμΉν•μ§€ μ•μ„ λ• λ³µμ΅ν•κ³  λ―Όκ°ν• μ‚¬νμ  νΈν–¥μ΄ ν¬ν•¨λ μ‹λ‚λ¦¬μ¤μ—μ„ μ›μΉ μ•λ” κ²°κ³Όλ¥Ό μ΄λν•  μ μλ‹¤λ” λ¬Έμ λ¥Ό λ‹¤λ£¬λ‹¤. μ΄μ „ μ—°κµ¬λ“¤μ€ μ „λ¬Έκ°€κ°€ μ„¤κ³„ν• λλ” μ—μ΄μ „νΈ κΈ°λ°μ νΈν–¥ μ‹λ‚λ¦¬μ¤λ¥Ό μ‚¬μ©ν•μ—¬ LLMsμ μΈκ°„ κ°€μΉμ™€μ λ¶μΌμΉλ¥Ό λ°ν€λƒλ‹¤. κ·Έλ¬λ‚ λ‹¤μ–‘ν• μ ν•μ μ‹λ‚λ¦¬μ¤(μ: λ¶€μ •μ  vs. λΉ„λ¶€μ •μ  μ§λ¬Έμ΄ ν¬ν•¨λ μ‹λ‚λ¦¬μ¤)μ—μ„ LLMsμ μΈκ°„ κ°€μΉμ™€μ μΌμΉ μ—¬λ¶€κ°€ λ‹¤λ¥Έμ§€ μ—¬λ¶€λ” μ—¬μ „ν λ¶λ¶„λ…ν•λ‹¤. λ³Έ μ—°κµ¬μ—μ„λ” λ‹¤μ–‘ν• μ ν•μ νΈν–¥ μ‹λ‚λ¦¬μ¤μ—μ„ LLMsμ μΈκ°„ κ°€μΉμ™€μ μΌμΉλ¥Ό μ΅°μ‚¬ν•λ‹¤. 4κ°€μ§€ λ¨λΈ ν¨λ°€λ¦¬μ™€ 4κ°€μ§€ λ°μ΄ν„°μ…‹μ—μ„ 12κ°μ LLMsλ¥Ό μ² μ €ν λ¶„μ„ν• κ²°κ³Ό, λ€κ·λ¨ λ¨λΈ νλΌλ―Έν„° μ¤μΌ€μΌμ„ κ°€μ§„ LLMsκ°€ μΌμΉμ¨κ³Ό κ³µκ²© μ„±κ³µλ¥ μ΄ λ‚®λ‹¤λ” κ²ƒμ„ λ³΄μ—¬μ¤€λ‹¤. λν•, LLMsλ” νΉμ • μ ν•μ μ‹λ‚λ¦¬μ¤μ— λ€ν•΄ μΌμ •ν• μ •λ ¬ μ„ νΈλ„λ¥Ό λ³΄μ΄λ©°, λ™μΌν• λ¨λΈ ν¨λ°€λ¦¬μ LLMsλ” λ” λ†’μ€ νλ‹¨ μΌκ΄€μ„±μ„ κ°€μ§„ κ²½ν–¥μ΄ μλ‹¤. λν•, LLMsμ HVSB μ΄ν•΄ λ¥λ ¥μ„ μ—°κµ¬ν•λ‹¤. LLMs κ°„ HVSBμ μ΄ν•΄μ—λ” μ μλ―Έν• μ°¨μ΄κ°€ μ—†μμ„ λ°κ²¬ν•λ©°, LLMsλ” μμ²΄ μƒμ„±λ μ„¤λ…μ„ μ„ νΈν•λ” κ²½ν–¥μ΄ μλ‹¤. λ”λ¶μ–΄, μ‘μ€ μ–Έμ–΄ λ¨λΈ(LMs)μ— HVSBλ¥Ό μ„¤λ…ν•  μ μλ” λ¥λ ¥μ„ λ¶€μ—¬ν•λ‹¤. μƒμ„± κ²°κ³Όλ” λ―Έμ„Έ μ΅°μ •λ μ‘μ€ LMsκ°€ λ” μ½κΈ° μ‰½μ§€λ§ μƒλ€μ μΌλ΅ λ‚®μ€ λ¨λΈ ν•©μμ„±μ„ κ°€μ§„ μ„¤λ…μ„ μƒμ„±ν•λ‹¤.

## π― μ£Όμ” ν¬μΈνΈ

- λ€ν• μ–Έμ–΄ λ¨λΈμ€ μ‚¬νμ  νΈν–¥κ³Όμ μΌμΉλ¥Ό μ΅°μ‚¬ν•λ” λ° μ‚¬μ©λ  μ μμ

- λ€ν• λ¨λΈ νλΌλ―Έν„° κ·λ¨κ°€ λ†’μ„μλ΅ μ‚¬νμ  νΈν–¥κ³Όμ λ¶μΌμΉμ¨μ΄ λ‚®μ§€ μ•μ„ μ μμ

- λ™μΌν• λ¨λΈ ν¨λ°€λ¦¬μ λ€ν• μ–Έμ–΄ λ¨λΈμ€ νλ‹¨ μΌκ΄€μ„±μ΄ λ†’μ„ μ μμ

---

*Generated on 2025-09-18 16:51:10*