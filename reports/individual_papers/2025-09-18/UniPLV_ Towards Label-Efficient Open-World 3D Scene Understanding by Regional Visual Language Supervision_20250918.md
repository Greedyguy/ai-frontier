---
keywords:
  - Multi-Modal Learning
  - 3D Scene Understanding
  - Vision-Point Matching
category: cs.AI
publish_date: 2025-09-18
arxiv_id: 2412.18131
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 22:02:22.424503",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multi-Modal Learning",
    "3D Scene Understanding",
    "Vision-Point Matching"
  ],
  "rejected_keywords": [
    "Open-World",
    "Semantic Segmentation"
  ],
  "similarity_scores": {
    "Multi-Modal Learning": 0.8,
    "3D Scene Understanding": 0.78,
    "Vision-Point Matching": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->


# UniPLV: Towards Label-Efficient Open-World 3D Scene Understanding by Regional Visual Language Supervision

**Korean Title:** UniPLV: ì§€ì—­ ì‹œê° ì–¸ì–´ ê°ë…ì— ì˜í•œ ë ˆì´ë¸” íš¨ìœ¨ì ì¸ ì˜¤í”ˆ ì›”ë“œ 3D ì¥ë©´ ì´í•´ë¡œ í–¥í•˜ë©°

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[digests/daily_digest_20250918|2025-09-18]]   [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Multi-Modal Learning|Multimodal Alignment]]
**âš¡ Unique Technical**: [[keywords/3D Scene Understanding|3D Scene Understanding]], [[keywords/Vision-Point Matching|Vision-Point Matching]]

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[Search-TTA: A Multimodal Test-Time Adaptation Framework for Visual Search in the Wild]] (79.7% similar)
- [[Uni-cot_Towards_Unified_Chain-of-Thought_Reasoning_Across_Text_and_Vision_20250918|Uni-cot: Towards Unified Chain-of-Thought Reasoning Across Text and Vision]] (79.7% similar)
- [[GeoAware-VLA_Implicit_Geometry_Aware_Vision-Language-Action_Model_20250918|GeoAware-VLA: Implicit Geometry Aware Vision-Language-Action Model]] (79.3% similar)
- [[LLM-I_LLMs_are_Naturally_Interleaved_Multimodal_Creators_20250918|LLM-I: LLMs are Naturally Interleaved Multimodal Creators]] (79.1% similar)
- [[SAIL-VL2_Technical_Report_20250918|SAIL-VL2 Technical Report]] (79.1% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2412.18131v2 Announce Type: replace 
Abstract: Open-world 3D scene understanding is a critical challenge that involves recognizing and distinguishing diverse objects and categories from 3D data, such as point clouds, without relying on manual annotations. Traditional methods struggle with this open-world task, especially due to the limitations of constructing extensive point cloud-text pairs and handling multimodal data effectively. In response to these challenges, we present UniPLV, a robust framework that unifies point clouds, images, and text within a single learning paradigm for comprehensive 3D scene understanding. UniPLV leverages images as a bridge to co-embed 3D points with pre-aligned images and text in a shared feature space, eliminating the need for labor-intensive point cloud-text pair crafting. Our framework achieves precise multimodal alignment through two innovative strategies: (i) Logit and feature distillation modules between images and point clouds to enhance feature coherence; (ii) A vision-point matching module that implicitly corrects 3D semantic predictions affected by projection inaccuracies from points to pixels. To further boost performance, we implement four task-specific losses alongside a two-stage training strategy. Extensive experiments demonstrate that UniPLV significantly surpasses state-of-the-art methods, with average improvements of 15.6% and 14.8% in semantic segmentation for Base-Annotated and Annotation-Free tasks, respectively. These results underscore UniPLV's efficacy in pushing the boundaries of open-world 3D scene understanding. We will release the code to support future research and development.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2412.18131v2 ë°œí‘œ ìœ í˜•: ëŒ€ì²´
ìš”ì•½: ì˜¤í”ˆ ì›”ë“œ 3D ì¥ë©´ ì´í•´ëŠ” í¬ì¸íŠ¸ í´ë¼ìš°ë“œì™€ ê°™ì€ 3D ë°ì´í„°ì—ì„œ ë‹¤ì–‘í•œ ê°ì²´ì™€ ë²”ì£¼ë¥¼ ì¸ì‹í•˜ê³  êµ¬ë³„í•˜ëŠ” ì¤‘ìš”í•œ ê³¼ì œì´ë©° ìˆ˜ë™ ì£¼ì„ì— ì˜ì¡´í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì „í†µì ì¸ ë°©ë²•ì€ íŠ¹íˆ ê´‘ë²”ìœ„í•œ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ-í…ìŠ¤íŠ¸ ìŒì„ êµ¬ì„±í•˜ê³  ë‹¤ì¤‘ ëª¨ë‹¬ ë°ì´í„°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” ì œí•œìœ¼ë¡œ ì¸í•´ì´ ì˜¤í”ˆ ì›”ë“œ ì‘ì—…ì— ì–´ë ¤ì›€ì„ ê²ªìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë„ì „ì— ëŒ€ì‘í•˜ì—¬ ìš°ë¦¬ëŠ” í¬ê´„ì ì¸ 3D ì¥ë©´ ì´í•´ë¥¼ ìœ„í•´ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ, ì´ë¯¸ì§€ ë° í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ í•™ìŠµ íŒ¨ëŸ¬ë‹¤ì„ì—ì„œ í†µí•©í•˜ëŠ” ê°•ë ¥í•œ í”„ë ˆì„ì›Œí¬ ì¸ UniPLVë¥¼ ì œì‹œí•©ë‹ˆë‹¤. UniPLVëŠ” ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ 3D í¬ì¸íŠ¸ë¥¼ ì‚¬ì „ ì •ë ¬ëœ ì´ë¯¸ì§€ ë° í…ìŠ¤íŠ¸ì™€ í•¨ê»˜ ê³µìœ ëœ íŠ¹ì§• ê³µê°„ì— ë™ì‹œì— ì„ë² ë“œí•˜ëŠ” ë‹¤ë¦¬ë¡œ í™œìš©í•˜ì—¬ ë…¸ë™ ì§‘ì•½ì ì¸ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ-í…ìŠ¤íŠ¸ ìŒ ì‘ì—…ì„ ì—†ì• ì¤ë‹ˆë‹¤. ìš°ë¦¬ì˜ í”„ë ˆì„ì›Œí¬ëŠ” ë‘ ê°€ì§€ í˜ì‹ ì ì¸ ì „ëµì„ í†µí•´ ì •í™•í•œ ë‹¤ì¤‘ ëª¨ë‹¬ ì •ë ¬ì„ ë‹¬ì„±í•©ë‹ˆë‹¤: (i) ì´ë¯¸ì§€ì™€ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ì‚¬ì´ì˜ ë¡œì§“ ë° íŠ¹ì§• ì¦ë¥˜ ëª¨ë“ˆì„ í†µí•´ íŠ¹ì§• ì¼ê´€ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤; (ii) í¬ì¸íŠ¸ì—ì„œ í”½ì…€ë¡œì˜ íˆ¬ì˜ ì˜¤ì°¨ì— ì˜í–¥ì„ ë°›ëŠ” 3D ì˜ë¯¸ë¡ ì  ì˜ˆì¸¡ì„ ì•”ë¬µì ìœ¼ë¡œ ìˆ˜ì •í•˜ëŠ” ë¹„ì „-í¬ì¸íŠ¸ ë§¤ì¹­ ëª¨ë“ˆ. ì„±ëŠ¥ì„ ë” í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ìš°ë¦¬ëŠ” ë‘ ë‹¨ê³„ í•™ìŠµ ì „ëµê³¼ í•¨ê»˜ ë„¤ ê°€ì§€ ì‘ì—…ë³„ ì†ì‹¤ì„ êµ¬í˜„í•©ë‹ˆë‹¤. ê´‘ë²”ìœ„í•œ ì‹¤í—˜ ê²°ê³¼ UniPLVê°€ ìµœì‹  ê¸°ìˆ  ë°©ë²•ì„ í¬ê²Œ ëŠ¥ê°€í•˜ë©° Base-Annotated ë° Annotation-Free ì‘ì—…ì— ëŒ€í•´ ê°ê° 15.6% ë° 14.8%ì˜ í‰ê·  í–¥ìƒì„ ë‹¬ì„±í•œë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŸ¬í•œ ê²°ê³¼ëŠ” UniPLVê°€ ì˜¤í”ˆ ì›”ë“œ 3D ì¥ë©´ ì´í•´ì˜ ê²½ê³„ë¥¼ ë„“íˆëŠ” ë° íš¨ê³¼ì ì„ì„ ê°•ì¡°í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ë¯¸ë˜ ì—°êµ¬ ë° ê°œë°œì„ ì§€ì›í•˜ê¸° ìœ„í•´ ì½”ë“œë¥¼ ê³µê°œí•  ê²ƒì…ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ë³¸ ì—°êµ¬ëŠ” ì˜¤í”ˆ ì›”ë“œ 3D ì¥ë©´ ì´í•´ë¥¼ ìœ„í•œ UniPLV í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•œë‹¤. UniPLVëŠ” ì´ë¯¸ì§€ë¥¼ í†µí•´ 3D í¬ì¸íŠ¸ì™€ ì‚¬ì „ ì •ë ¬ëœ ì´ë¯¸ì§€ ë° í…ìŠ¤íŠ¸ë¥¼ ê³µìœ ëœ íŠ¹ì§• ê³µê°„ì— í•¨ê»˜ ì„ë² ë”©í•˜ì—¬ labor-intensiveí•œ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ-í…ìŠ¤íŠ¸ í˜ì–´ ì‘ì—…ì„ ì—†ì• ê³  ì •í™•í•œ ë©€í‹°ëª¨ë‹¬ ì •ë ¬ì„ ë‹¬ì„±í•œë‹¤. ì´ë¥¼ ìœ„í•´ ì´ë¯¸ì§€ì™€ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ê°„ì˜ Logit ë° í”¼ì²˜ ë””ìŠ¤í‹¸ë ˆì´ì…˜ ëª¨ë“ˆ, ê·¸ë¦¬ê³  ë¹„ì „-í¬ì¸íŠ¸ ë§¤ì¹­ ëª¨ë“ˆì„ í†µí•´ ì„¸ë¶„í™”ëœ íŠ¹ì§•ì„ í–¥ìƒì‹œí‚¤ê³  3D ì‹œë§¨í‹± ì˜ˆì¸¡ì„ ë³´ì •í•œë‹¤. ì‹¤í—˜ ê²°ê³¼ëŠ” UniPLVê°€ ì˜¤í”ˆ ì›”ë“œ 3D ì¥ë©´ ì´í•´ ë¶„ì•¼ì—ì„œ ìµœì²¨ë‹¨ ë°©ë²•ë“¤ì„ í¬ê²Œ ëŠ¥ê°€í•¨ì„ ë³´ì—¬ì¤€ë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. 3D ì¥ë©´ ì´í•´ë¥¼ ìœ„í•œ UniPLV í”„ë ˆì„ì›Œí¬ ì†Œê°œ

- 2. ì´ë¯¸ì§€ë¥¼ í™œìš©í•œ 3D í¬ì¸íŠ¸ ë° í…ìŠ¤íŠ¸ í†µí•© í•™ìŠµ

- 3. ë‹¤ì¤‘ ëª¨ë‹¬ ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•œ í˜ì‹ ì ì¸ ì „ëµ ì ìš©

- 4. Base-Annotated ë° Annotation-Free ì‘ì—…ì—ì„œ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì—¬ì¤Œ

- 5. ë¯¸ë˜ ì—°êµ¬ ë° ê°œë°œì„ ì§€ì›í•˜ê¸° ìœ„í•´ ì½”ë“œ ê³µê°œí•  ì˜ˆì •

---

*Generated on 2025-09-18 17:06:08*