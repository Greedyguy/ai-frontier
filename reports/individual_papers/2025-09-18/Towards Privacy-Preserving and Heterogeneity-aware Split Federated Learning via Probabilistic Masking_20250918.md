---
keywords:
  - Federated Learning
  - Privacy Attacks
  - Data Heterogeneity
category: cs.AI
publish_date: 2025-09-18
arxiv_id:
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 22:04:17.736241",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Federated Learning",
    "Privacy Attacks",
    "Data Heterogeneity"
  ],
  "rejected_keywords": [
    "Probabilistic Masking"
  ],
  "similarity_scores": {
    "Federated Learning": 0.8,
    "Privacy Attacks": 0.78,
    "Data Heterogeneity": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->

# Towards Privacy-Preserving and Heterogeneity-aware Split Federated Learning via Probabilistic Masking

**Korean Title:** í”„ë¼ì´ë²„ì‹œ ë³´í˜¸ ë° ì´ì§ˆì„± ì¸ì‹ì„ ìœ„í•œ í™•ë¥ ì  ë§ˆìŠ¤í‚¹ ê¸°ë°˜ ë¶„í•  ì—°í•© í•™ìŠµ ì—°êµ¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[digests/daily_digest_20250918|2025-09-18]]        [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Federated Learning|Split Federated Learning]], [[keywords/Privacy Attacks|Privacy Attacks]]
**ğŸš€ Evolved Concepts**: [[keywords/Data Heterogeneity|Data Heterogeneity]]

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[Communication-Efficient and Privacy-Adaptable Mechanism for Federated Learning_20250919|Communication-Efficient and Privacy-Adaptable Mechanism for Federated Learning]] (82.8% similar)
- [[Hierarchical Federated Learning for Social Network with Mobility_20250919|Hierarchical Federated Learning for Social Network with Mobility]] (81.8% similar)
- [[Differential Privacy in Federated Learning_ Mitigating Inference Attacks with Randomized Response_20250917|Differential Privacy in Federated Learning Mitigating Inference Attacks with Randomized Response]] (80.0% similar)
- [[Who to Trust Aggregating Client Knowledge in Logit-Based Federated Learning_20250919|Who to Trust Aggregating Client Knowledge in Logit-Based Federated Learning]] (79.6% similar)
- [[FedAVOT_ Exact Distribution Alignment in Federated Learning via Masked Optimal Transport_20250919|FedAVOT Exact Distribution Alignment in Federated Learning via Masked Optimal Transport]] (79.0% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** Xingchen Wang, Feijie Wu, Chenglin Miao, Tianchun Li, Haoyu Hu, Qiming Cao, Jing Gao, Lu Su

## ğŸ“„ Abstract (ì›ë¬¸)

Split Federated Learning (SFL) has emerged as an efficient alternative to
traditional Federated Learning (FL) by reducing client-side computation through
model partitioning. However, exchanging of intermediate activations and model
updates introduces significant privacy risks, especially from data
reconstruction attacks that recover original inputs from intermediate
representations. Existing defenses using noise injection often degrade model
performance. To overcome these challenges, we present PM-SFL, a scalable and
privacy-preserving SFL framework that incorporates Probabilistic Mask training
to add structured randomness without relying on explicit noise. This mitigates
data reconstruction risks while maintaining model utility. To address data
heterogeneity, PM-SFL employs personalized mask learning that tailors submodel
structures to each client's local data. For system heterogeneity, we introduce
a layer-wise knowledge compensation mechanism, enabling clients with varying
resources to participate effectively under adaptive model splitting.
Theoretical analysis confirms its privacy protection, and experiments on image
and wireless sensing tasks demonstrate that PM-SFL consistently improves
accuracy, communication efficiency, and robustness to privacy attacks, with
particularly strong performance under data and system heterogeneity.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

ìŠ¤í”Œë¦¿ ì—°í•© í•™ìŠµ(Split Federated Learning, SFL)ì€ ëª¨ë¸ ë¶„í• ì„ í†µí•´ í´ë¼ì´ì–¸íŠ¸ ì¸¡ ì—°ì‚°ì„ ì¤„ì„ìœ¼ë¡œì¨ ì „í†µì ì¸ ì—°í•© í•™ìŠµ(Federated Learning, FL)ì— ëŒ€í•œ íš¨ìœ¨ì ì¸ ëŒ€ì•ˆìœ¼ë¡œ ë¶€ìƒí•˜ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì¤‘ê°„ í™œì„±í™” ë° ëª¨ë¸ ì—…ë°ì´íŠ¸ì˜ êµí™˜ì€ íŠ¹íˆ ì¤‘ê°„ í‘œí˜„ì—ì„œ ì›ë˜ ì…ë ¥ì„ ë³µêµ¬í•˜ëŠ” ë°ì´í„° ì¬êµ¬ì„± ê³µê²©ìœ¼ë¡œ ì¸í•´ ìƒë‹¹í•œ í”„ë¼ì´ë²„ì‹œ ìœ„í—˜ì„ ì´ˆë˜í•©ë‹ˆë‹¤. ë…¸ì´ì¦ˆ ì£¼ì…ì„ ì‚¬ìš©í•˜ëŠ” ê¸°ì¡´ ë°©ì–´ ë°©ë²•ì€ ì¢…ì¢… ëª¨ë¸ ì„±ëŠ¥ì„ ì €í•˜ì‹œí‚µë‹ˆë‹¤. ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ëª…ì‹œì ì¸ ë…¸ì´ì¦ˆì— ì˜ì¡´í•˜ì§€ ì•Šê³  êµ¬ì¡°í™”ëœ ë¬´ì‘ìœ„ì„±ì„ ì¶”ê°€í•˜ëŠ” í™•ë¥ ì  ë§ˆìŠ¤í¬ í•™ìŠµì„ í†µí•©í•œ í™•ì¥ ê°€ëŠ¥í•˜ê³  í”„ë¼ì´ë²„ì‹œë¥¼ ë³´ì¥í•˜ëŠ” SFL í”„ë ˆì„ì›Œí¬ì¸ PM-SFLì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ëŠ” ë°ì´í„° ì¬êµ¬ì„± ìœ„í—˜ì„ ì™„í™”í•˜ë©´ì„œ ëª¨ë¸ ìœ ìš©ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤. ë°ì´í„° ì´ì§ˆì„±ì„ í•´ê²°í•˜ê¸° ìœ„í•´, PM-SFLì€ ê° í´ë¼ì´ì–¸íŠ¸ì˜ ë¡œì»¬ ë°ì´í„°ì— ë§ì¶° ì„œë¸Œëª¨ë¸ êµ¬ì¡°ë¥¼ ì¡°ì •í•˜ëŠ” ê°œì¸í™”ëœ ë§ˆìŠ¤í¬ í•™ìŠµì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì‹œìŠ¤í…œ ì´ì§ˆì„±ì— ëŒ€í•´ì„œëŠ”, ì ì‘í˜• ëª¨ë¸ ë¶„í•  í•˜ì—ì„œ ë‹¤ì–‘í•œ ìì›ì„ ê°€ì§„ í´ë¼ì´ì–¸íŠ¸ê°€ íš¨ê³¼ì ìœ¼ë¡œ ì°¸ì—¬í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê³„ì¸µë³„ ì§€ì‹ ë³´ìƒ ë©”ì»¤ë‹ˆì¦˜ì„ ë„ì…í•©ë‹ˆë‹¤. ì´ë¡ ì  ë¶„ì„ì€ í”„ë¼ì´ë²„ì‹œ ë³´í˜¸ë¥¼ í™•ì¸í•˜ë©°, ì´ë¯¸ì§€ ë° ë¬´ì„  ì„¼ì‹± ì‘ì—…ì— ëŒ€í•œ ì‹¤í—˜ì€ PM-SFLì´ ë°ì´í„° ë° ì‹œìŠ¤í…œ ì´ì§ˆì„± í•˜ì—ì„œ íŠ¹íˆ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë³´ì´ë©° ì •í™•ì„±, í†µì‹  íš¨ìœ¨ì„± ë° í”„ë¼ì´ë²„ì‹œ ê³µê²©ì— ëŒ€í•œ ê°•ê±´ì„±ì„ ì§€ì†ì ìœ¼ë¡œ í–¥ìƒì‹œí‚´ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

Split Federated Learning(SFL)ì€ í´ë¼ì´ì–¸íŠ¸ ì¸¡ ê³„ì‚°ì„ ì¤„ì´ê¸° ìœ„í•´ ëª¨ë¸ì„ ë¶„í• í•˜ì—¬ ì „í†µì ì¸ ì—°í•© í•™ìŠµ(FL)ì˜ ëŒ€ì•ˆìœ¼ë¡œ ë“±ì¥í–ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì¤‘ê°„ í™œì„±í™” ë° ëª¨ë¸ ì—…ë°ì´íŠ¸ êµí™˜ì€ ë°ì´í„° ì¬êµ¬ì„± ê³µê²©ìœ¼ë¡œ ì¸í•œ í”„ë¼ì´ë²„ì‹œ ìœ„í—˜ì„ ì´ˆë˜í•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë…¸ì´ì¦ˆ ì£¼ì… ë°©ì–´ëŠ” ëª¨ë¸ ì„±ëŠ¥ì„ ì €í•˜ì‹œí‚µë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” í™•ì¥ ê°€ëŠ¥í•˜ê³  í”„ë¼ì´ë²„ì‹œë¥¼ ë³´í˜¸í•˜ëŠ” SFL í”„ë ˆì„ì›Œí¬ì¸ PM-SFLì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ëŠ” ëª…ì‹œì ì¸ ë…¸ì´ì¦ˆ ì—†ì´ êµ¬ì¡°í™”ëœ ë¬´ì‘ìœ„ì„±ì„ ì¶”ê°€í•˜ëŠ” í™•ë¥ ì  ë§ˆìŠ¤í¬ í›ˆë ¨ì„ í†µí•©í•˜ì—¬ ë°ì´í„° ì¬êµ¬ì„± ìœ„í—˜ì„ ì™„í™”í•˜ë©´ì„œ ëª¨ë¸ ìœ ìš©ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤. ë°ì´í„° ì´ì§ˆì„±ì„ í•´ê²°í•˜ê¸° ìœ„í•´, PM-SFLì€ ê° í´ë¼ì´ì–¸íŠ¸ì˜ ë¡œì»¬ ë°ì´í„°ì— ë§ì¶˜ ê°œì¸í™”ëœ ë§ˆìŠ¤í¬ í•™ìŠµì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì‹œìŠ¤í…œ ì´ì§ˆì„±ì— ëŒ€í•´ì„œëŠ”, ìì›ì— ë”°ë¼ ì ì‘í˜• ëª¨ë¸ ë¶„í• ì„ í†µí•´ ë‹¤ì–‘í•œ í´ë¼ì´ì–¸íŠ¸ê°€ íš¨ê³¼ì ìœ¼ë¡œ ì°¸ì—¬í•  ìˆ˜ ìˆë„ë¡ ë ˆì´ì–´ë³„ ì§€ì‹ ë³´ìƒ ë©”ì»¤ë‹ˆì¦˜ì„ ë„ì…í•©ë‹ˆë‹¤. ì´ë¡ ì  ë¶„ì„ì€ í”„ë¼ì´ë²„ì‹œ ë³´í˜¸ë¥¼ í™•ì¸í–ˆìœ¼ë©°, ì´ë¯¸ì§€ ë° ë¬´ì„  ì„¼ì‹± ì‘ì—… ì‹¤í—˜ì—ì„œ PM-SFLì€ ë°ì´í„° ë° ì‹œìŠ¤í…œ ì´ì§ˆì„± í•˜ì—ì„œ íŠ¹íˆ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë³´ì´ë©° ì •í™•ë„, í†µì‹  íš¨ìœ¨ì„± ë° í”„ë¼ì´ë²„ì‹œ ê³µê²©ì— ëŒ€í•œ ê°•ê±´ì„±ì„ ì§€ì†ì ìœ¼ë¡œ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Split Federated Learning (SFL)ì€ ëª¨ë¸ ë¶„í• ì„ í†µí•´ í´ë¼ì´ì–¸íŠ¸ ì¸¡ ê³„ì‚°ì„ ì¤„ì—¬ ì „í†µì ì¸ Federated Learning (FL)ì˜ íš¨ìœ¨ì ì¸ ëŒ€ì•ˆìœ¼ë¡œ ë¶€ìƒí–ˆìŠµë‹ˆë‹¤.

- 2. PM-SFLì€ ëª…ì‹œì ì¸ ë…¸ì´ì¦ˆì— ì˜ì¡´í•˜ì§€ ì•Šê³  êµ¬ì¡°í™”ëœ ë¬´ì‘ìœ„ì„±ì„ ì¶”ê°€í•˜ëŠ” Probabilistic Mask í›ˆë ¨ì„ í†µí•©í•˜ì—¬ ë°ì´í„° ì¬êµ¬ì„± ê³µê²©ì˜ ìœ„í—˜ì„ ì™„í™”í•©ë‹ˆë‹¤.

- 3. PM-SFLì€ ê°œì¸í™”ëœ ë§ˆìŠ¤í¬ í•™ìŠµì„ í†µí•´ ê° í´ë¼ì´ì–¸íŠ¸ì˜ ë¡œì»¬ ë°ì´í„°ì— ë§ì¶˜ ì„œë¸Œëª¨ë¸ êµ¬ì¡°ë¥¼ ì œê³µí•˜ì—¬ ë°ì´í„° ì´ì§ˆì„±ì„ í•´ê²°í•©ë‹ˆë‹¤.

- 4. ì‹œìŠ¤í…œ ì´ì§ˆì„±ì„ í•´ê²°í•˜ê¸° ìœ„í•´, PM-SFLì€ ê³„ì¸µë³„ ì§€ì‹ ë³´ìƒ ë©”ì»¤ë‹ˆì¦˜ì„ ë„ì…í•˜ì—¬ ë‹¤ì–‘í•œ ìì›ì„ ê°€ì§„ í´ë¼ì´ì–¸íŠ¸ë“¤ì´ ì ì‘í˜• ëª¨ë¸ ë¶„í•  í•˜ì— íš¨ê³¼ì ìœ¼ë¡œ ì°¸ì—¬í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.

- 5. ì´ë¡ ì  ë¶„ì„ê³¼ ì‹¤í—˜ ê²°ê³¼ëŠ” PM-SFLì´ ë°ì´í„° ë° ì‹œìŠ¤í…œ ì´ì§ˆì„± í•˜ì—ì„œë„ ì •í™•ì„±, í†µì‹  íš¨ìœ¨ì„±, í”„ë¼ì´ë²„ì‹œ ê³µê²©ì— ëŒ€í•œ ê°•ê±´ì„±ì„ ì§€ì†ì ìœ¼ë¡œ ê°œì„ í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

---

*Generated on 2025-09-20 05:49:36*