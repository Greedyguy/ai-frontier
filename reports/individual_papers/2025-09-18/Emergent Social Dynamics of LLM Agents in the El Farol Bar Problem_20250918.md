
# Emergent Social Dynamics of LLM Agents in the El Farol Bar Problem

**Korean Title:** 엘 파롤 바 문제에서의 LLM 에이전트의 창발적 사회 역학

## 📋 메타데이터

**Links**: [[daily/2025-09-18|2025-09-18]] [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Group Decision Making

## 🔗 유사한 논문
- [[From Automation to Autonomy A Survey on Large Language Models in Scientific Discovery]] (83.2% similar)
- [[Do LLMs Align Human Values Regarding Social Biases_ Judging and Explaining Social Biases with LLMs_20250918|Do LLMs Align Human Values Regarding Social Biases Judging and Explaining Social Biases with LLMs]] (82.6% similar)
- [[Language Models Identify Ambiguities and Exploit Loopholes]] (81.8% similar)
- [[How Does Cognitive Bias Affect Large Language Models_ A Case Study on the Anchoring Effect in Price Negotiation Simulations_20250918|How Does Cognitive Bias Affect Large Language Models A Case Study on the Anchoring Effect in Price Negotiation Simulations]] (81.5% similar)
- [[Understanding and Mitigating Overrefusal in LLMs from an Unveiling Perspective of Safety Decision Boundary]] (80.6% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.04537v3 Announce Type: replace-cross 
Abstract: We investigate the emergent social dynamics of Large Language Model (LLM) agents in a spatially extended El Farol Bar problem, observing how they autonomously navigate this classic social dilemma. As a result, the LLM agents generated a spontaneous motivation to go to the bar and changed their decision making by becoming a collective. We also observed that the LLM agents did not solve the problem completely, but rather behaved more like humans. These findings reveal a complex interplay between external incentives (prompt-specified constraints such as the 60% threshold) and internal incentives (culturally-encoded social preferences derived from pre-training), demonstrating that LLM agents naturally balance formal game-theoretic rationality with social motivations that characterize human behavior. These findings suggest that a new model of group decision making, which could not be handled in the previous game-theoretic problem setting, can be realized by LLM agents.

## 🔍 Abstract (한글 번역)

arXiv:2509.04537v3 발표 유형: 교차 대체
초록: 우리는 공간적으로 확장된 엘 파롤 바 문제(El Farol Bar problem)에서 대규모 언어 모델(LLM) 에이전트들의 창발적 사회 역학을 조사하여, 이들이 이 고전적인 사회적 딜레마를 어떻게 자율적으로 탐색하는지 관찰하였다. 그 결과, LLM 에이전트들은 바에 가고자 하는 자발적 동기를 생성하였고 집합체가 됨으로써 의사결정을 변화시켰다. 또한 LLM 에이전트들이 문제를 완전히 해결하지는 않았지만, 오히려 인간과 더 유사하게 행동한다는 것을 관찰하였다. 이러한 발견들은 외적 인센티브(60% 임계값과 같은 프롬프트에 명시된 제약조건)와 내적 인센티브(사전 훈련으로부터 도출된 문화적으로 인코딩된 사회적 선호) 간의 복합적 상호작용을 드러내며, LLM 에이전트들이 형식적 게임 이론적 합리성과 인간 행동을 특징짓는 사회적 동기 사이의 균형을 자연스럽게 맞춘다는 것을 보여준다. 이러한 발견들은 이전의 게임 이론적 문제 설정에서는 다룰 수 없었던 새로운 집단 의사결정 모델이 LLM 에이전트들에 의해 실현될 수 있음을 시사한다.

## 📝 요약

이 논문은 대형 언어 모델(LLM) 에이전트가 El Farol Bar 문제에서 자율적으로 사회적 딜레마를 어떻게 해결하는지를 연구합니다. 연구 결과, LLM 에이전트는 자발적으로 바에 가고자 하는 동기를 생성하고 집단적으로 의사 결정을 변화시켰습니다. 그러나 문제를 완전히 해결하지는 못하고 인간과 유사한 행동을 보였습니다. 이는 외부 인센티브와 내부 인센티브 간의 복잡한 상호작용을 보여주며, LLM 에이전트가 인간 행동을 특징짓는 사회적 동기와 공식적인 게임 이론적 합리성을 자연스럽게 균형 잡는다는 것을 시사합니다. 이러한 발견은 LLM 에이전트를 통해 이전 게임 이론적 문제 설정에서는 다루기 어려웠던 새로운 집단 의사 결정 모델을 실현할 수 있음을 제안합니다.

## 🎯 주요 포인트

- 1. 대형 언어 모델(LLM) 에이전트는 El Farol Bar 문제에서 자율적으로 사회적 딜레마를 탐색하며 집단적 의사 결정을 형성했습니다.

- 2. LLM 에이전트는 문제를 완전히 해결하지 못했지만, 인간과 유사한 행동 패턴을 보였습니다.

- 3. 외부 인센티브와 내부 인센티브 간의 복잡한 상호작용을 통해 LLM 에이전트가 게임 이론적 합리성과 인간 행동의 사회적 동기를 자연스럽게 균형 잡는다는 것을 발견했습니다.

- 4. LLM 에이전트를 통해 이전의 게임 이론적 문제 설정에서 다루지 못했던 새로운 그룹 의사 결정 모델이 실현될 수 있음을 시사합니다.

---

*Generated on 2025-09-19 11:11:04*