
# Identity-Preserving Text-to-Video Generation Guided by Simple yet Effective Spatial-Temporal Decoupled Representations

**Korean Title:** ê°„ë‹¨í•˜ë©´ì„œë„ íš¨ê³¼ì ì¸ ê³µê°„-ì‹œê°„ ë¶„ë¦¬ í‘œí˜„ì— ì˜í•´ ì•ˆë‚´ë˜ëŠ” ì‹ ì› ë³´ì¡´ í…ìŠ¤íŠ¸-ë¹„ë””ì˜¤ ìƒì„±

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-18|2025-09-18]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Stage-wise Decoupled Generation

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[Iterative_Prompt_Refinement_for_Safer_Text-to-Image_Generation_20250918|Iterative Prompt Refinement for Safer Text-to-Image Generation]] (81.9% similar)
- [[Kling-Avatar: Grounding Multimodal Instructions for Cascaded Long-Duration Avatar Animation Synthesis]] (81.0% similar)
- [[VSE-MOT_Multi-Object_Tracking_in_Low-Quality_Video_Scenes_Guided_by_Visual_Semantic_Enhancement_20250918|VSE-MOT: Multi-Object Tracking in Low-Quality Video Scenes Guided by Visual Semantic Enhancement]] (80.2% similar)
- [[Generative_Image_Coding_with_Diffusion_Prior_20250918|Generative Image Coding with Diffusion Prior]] (79.7% similar)
- [[AgentCTG_Harnessing_Multi-Agent_Collaboration_for_Fine-Grained_Precise_Control_in_Text_Generation_20250918|AgentCTG: Harnessing Multi-Agent Collaboration for Fine-Grained Precise Control in Text Generation]] (78.1% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2507.04705v2 Announce Type: replace 
Abstract: Identity-preserving text-to-video (IPT2V) generation, which aims to create high-fidelity videos with consistent human identity, has become crucial for downstream applications. However, current end-to-end frameworks suffer a critical spatial-temporal trade-off: optimizing for spatially coherent layouts of key elements (e.g., character identity preservation) often compromises instruction-compliant temporal smoothness, while prioritizing dynamic realism risks disrupting the spatial coherence of visual structures. To tackle this issue, we propose a simple yet effective spatial-temporal decoupled framework that decomposes representations into spatial features for layouts and temporal features for motion dynamics. Specifically, our paper proposes a semantic prompt optimization mechanism and stage-wise decoupled generation paradigm. The former module decouples the prompt into spatial and temporal components. Aligned with the subsequent stage-wise decoupled approach, the spatial prompts guide the text-to-image (T2I) stage to generate coherent spatial features, while the temporal prompts direct the sequential image-to-video (I2V) stage to ensure motion consistency. Experimental results validate that our approach achieves excellent spatiotemporal consistency, demonstrating outstanding performance in identity preservation, text relevance, and video quality. By leveraging this simple yet robust mechanism, our algorithm secures the runner-up position in 2025 ACM MultiMedia Challenge.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2507.04705v2 ë°œí‘œ ìœ í˜•: ëŒ€ì²´
ìš”ì•½: í•­ë“± ë³´ì¡´ í…ìŠ¤íŠ¸-ë¹„ë””ì˜¤ (IPT2V) ìƒì„±ì€ ì¼ê´€ëœ ì¸ê°„ ì‹ ì›ì„ ìœ ì§€í•˜ë©´ì„œ ê³ í’ˆì§ˆ ë¹„ë””ì˜¤ë¥¼ ë§Œë“œëŠ” ê²ƒì„ ëª¨í–¥ìœ¼ë¡œ í•˜ëŠ”ë°, ì´ëŠ” í•˜ë¥˜ ì‘ìš© í”„ë¡œê·¸ë¨ì— ì¤‘ìš”í•´ì¡Œë‹¤. ê·¸ëŸ¬ë‚˜ í˜„ì¬ì˜ end-to-end í”„ë ˆì„ì›Œí¬ëŠ” ê³µê°„ì -ì‹œê°„ì  íŠ¸ë ˆì´ë“œì˜¤í”„ë¥¼ ê²ªê³  ìˆë‹¤: ì£¼ìš” ìš”ì†Œë“¤ì˜ (ì˜ˆ: ìºë¦­í„° ì‹ ì› ë³´ì¡´) ê³µê°„ì  ì¼ê´€ëœ ë ˆì´ì•„ì›ƒì„ ìµœì í™”í•˜ëŠ” ê²ƒì€ ì¢…ì¢… ëª…ë ¹ ì¤€ìˆ˜ì  ì‹œê°„ì  ë¶€ë“œëŸ¬ì›€ì„ í¬ìƒì‹œí‚¤ëŠ” ë°˜ë©´, ë™ì  í˜„ì‹¤ì£¼ì˜ë¥¼ ìš°ì„ ì‹œí•˜ëŠ” ê²ƒì€ ì‹œê°ì  êµ¬ì¡°ì˜ ê³µê°„ì  ì¼ê´€ì„±ì„ ê¹¨ëŠ” ìœ„í—˜ì„ ì•ˆê³  ìˆë‹¤. ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” íš¨ê³¼ì ì´ë©´ì„œë„ ê°„ë‹¨í•œ ê³µê°„-ì‹œê°„ì  ë¶„ë¦¬ëœ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•œë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ë ˆì´ì•„ì›ƒì„ ìœ„í•œ ê³µê°„ì  íŠ¹ì§•ê³¼ ë™ì  ëª¨ì…˜ì„ ìœ„í•œ ì‹œê°„ì  íŠ¹ì§•ìœ¼ë¡œ í‘œí˜„ì„ ë¶„í•´í•œë‹¤. êµ¬ì²´ì ìœ¼ë¡œ, ìš°ë¦¬ì˜ ë…¼ë¬¸ì€ ì˜ë¯¸ë¡ ì  í”„ë¡¬í”„íŠ¸ ìµœì í™” ë©”ì»¤ë‹ˆì¦˜ê³¼ ë‹¨ê³„ë³„ ë¶„ë¦¬ëœ ìƒì„± íŒ¨ëŸ¬ë‹¤ì„ì„ ì œì•ˆí•œë‹¤. ì „ì ëª¨ë“ˆì€ í”„ë¡¬í”„íŠ¸ë¥¼ ê³µê°„ì  ë° ì‹œê°„ì  êµ¬ì„± ìš”ì†Œë¡œ ë¶„ë¦¬í•œë‹¤. ì´ì–´ì§€ëŠ” ë‹¨ê³„ë³„ ë¶„ë¦¬ëœ ì ‘ê·¼ê³¼ ì¼ì¹˜í•˜ê²Œ, ê³µê°„ì  í”„ë¡¬í”„íŠ¸ëŠ” ì¼ê´€ëœ ê³µê°„ì  íŠ¹ì§•ì„ ìƒì„±í•˜ê¸° ìœ„í•´ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ (T2I) ë‹¨ê³„ë¥¼ ì•ˆë‚´í•˜ê³ , ì‹œê°„ì  í”„ë¡¬í”„íŠ¸ëŠ” ìˆœì°¨ì  ì´ë¯¸ì§€-ë¹„ë””ì˜¤ (I2V) ë‹¨ê³„ë¥¼ í†µí•´ ëª¨ì…˜ ì¼ê´€ì„±ì„ ë³´ì¥í•œë‹¤. ì‹¤í—˜ ê²°ê³¼ëŠ” ìš°ë¦¬ì˜ ì ‘ê·¼ ë°©ì‹ì´ ìš°ìˆ˜í•œ ì‹œê³µê°„ì  ì¼ê´€ì„±ì„ ë‹¬ì„±í•˜ë©°, ì‹ ì› ë³´ì¡´, í…ìŠ¤íŠ¸ ê´€ë ¨ì„± ë° ë¹„ë””ì˜¤ í’ˆì§ˆì—ì„œ íƒì›”í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤€ë‹¤ëŠ” ê²ƒì„ ê²€ì¦í•œë‹¤. ì´ ê°„ë‹¨í•˜ë©´ì„œë„ ê²¬ê³ í•œ ë©”ì»¤ë‹ˆì¦˜ì„ í™œìš©í•˜ì—¬, ìš°ë¦¬ì˜ ì•Œê³ ë¦¬ì¦˜ì€ 2025ë…„ ACM MultiMedia Challengeì—ì„œ ì¤€ìš°ìŠ¹ì„ ì°¨ì§€í–ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ê³ í’ˆì§ˆ ë¹„ë””ì˜¤ ìƒì„±ì„ ìœ„í•œ ì‹ ì› ë³´ì¡´ í…ìŠ¤íŠ¸-ë¹„ë””ì˜¤(IPT2V) ìƒì„±ì— ì´ˆì ì„ ë§ì¶”ê³  ìˆë‹¤. í˜„ì¬ì˜ ì—”ë“œ íˆ¬ ì—”ë“œ í”„ë ˆì„ì›Œí¬ëŠ” ê³µê°„ì  ì¼ê´€ì„±ê³¼ ì‹œê°„ì  ë¶€ë“œëŸ¬ì›€ ì‚¬ì´ì˜ ì¤‘ìš”í•œ íŠ¸ë ˆì´ë“œ ì˜¤í”„ë¥¼ ê²ªê³  ìˆëŠ”ë°, ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ê³µê°„ì -ì‹œê°„ì ìœ¼ë¡œ ë¶„ë¦¬ëœ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•˜ê³  ìˆë‹¤. ì´ë¥¼ í†µí•´ ìš°ìˆ˜í•œ ì‹œê³µê°„ ì¼ê´€ì„±ì„ ë‹¬ì„±í•˜ë©°, ì‹ ì› ë³´ì¡´, í…ìŠ¤íŠ¸ ê´€ë ¨ì„± ë° ë¹„ë””ì˜¤ í’ˆì§ˆì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì—ˆë‹¤. ì´ëŸ¬í•œ ê°„ë‹¨í•˜ë©´ì„œë„ ê°•ë ¥í•œ ë©”ì»¤ë‹ˆì¦˜ì„ í™œìš©í•˜ì—¬, í•´ë‹¹ ì•Œê³ ë¦¬ì¦˜ì€ 2025 ACM MultiMedia Challengeì—ì„œ ì¤€ìš°ìŠ¹ì„ ì°¨ì§€í–ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- Identity-preserving text-to-video (IPT2V) generationì€ ë†’ì€ í’ˆì§ˆì˜ ë¹„ë””ì˜¤ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤.

- í˜„ì¬ì˜ end-to-end frameworksëŠ” ê³µê°„ì -ì‹œê°„ì  trade-offì— ì·¨ì•½í•˜ë‹¤.

- ì œì•ˆëœ spatial-temporal decoupled frameworkì€ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤€ë‹¤.

- ì‹¤í—˜ ê²°ê³¼ëŠ” ì œì•ˆëœ ë°©ë²•ì´ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤Œì„ ì…ì¦í•œë‹¤.

---

*Generated on 2025-09-18 17:06:53*