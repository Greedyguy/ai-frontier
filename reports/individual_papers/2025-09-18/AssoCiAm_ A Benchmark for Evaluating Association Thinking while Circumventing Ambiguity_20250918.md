---
keywords:
  - Large Language Models
  - Artificial General Intelligence
  - Association Thinking
category: cs.AI
publish_date: 2025-09-18
arxiv_id: 2509.14171
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 22:39:28.214759",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Models",
    "Artificial General Intelligence",
    "Association Thinking"
  ],
  "rejected_keywords": [
    "Ambiguity"
  ],
  "similarity_scores": {
    "Large Language Models": 0.8,
    "Artificial General Intelligence": 0.78,
    "Association Thinking": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->


# AssoCiAm: A Benchmark for Evaluating Association Thinking while Circumventing Ambiguity

**Korean Title:** AssoCiAm: 모호함을 우회하면서 연상 사고를 평가하는 벤치마크

## 📋 메타데이터

**Links**: [[digests/daily_digest_20250918|2025-09-18]]   [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**⚡ Unique Technical**: [[keywords/Association Thinking|association thinking]]
**🚀 Evolved Concepts**: [[keywords/Artificial General Intelligence|artificial general intelligence]]

## 🔗 유사한 논문
- [[Language Models Identify Ambiguities and Exploit Loopholes]] (82.1% similar)
- [[From_Automation_to_Autonomy_A_Survey_on_Large_Language_Models_in_Scientific_Discovery_20250918|From Automation to Autonomy: A Survey on Large Language Models in Scientific Discovery]] (80.8% similar)
- [[Enhancing Multi-Agent Debate System Performance via Confidence Expression]] (80.8% similar)
- [[Explicit Reasoning Makes Better Judges: A Systematic Study on Accuracy, Efficiency, and Robustness]] (80.6% similar)
- [[LLM-I_LLMs_are_Naturally_Interleaved_Multimodal_Creators_20250918|LLM-I: LLMs are Naturally Interleaved Multimodal Creators]] (79.9% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.14171v1 Announce Type: new 
Abstract: Recent advancements in multimodal large language models (MLLMs) have garnered significant attention, offering a promising pathway toward artificial general intelligence (AGI). Among the essential capabilities required for AGI, creativity has emerged as a critical trait for MLLMs, with association serving as its foundation. Association reflects a model' s ability to think creatively, making it vital to evaluate and understand. While several frameworks have been proposed to assess associative ability, they often overlook the inherent ambiguity in association tasks, which arises from the divergent nature of associations and undermines the reliability of evaluations. To address this issue, we decompose ambiguity into two types-internal ambiguity and external ambiguity-and introduce AssoCiAm, a benchmark designed to evaluate associative ability while circumventing the ambiguity through a hybrid computational method. We then conduct extensive experiments on MLLMs, revealing a strong positive correlation between cognition and association. Additionally, we observe that the presence of ambiguity in the evaluation process causes MLLMs' behavior to become more random-like. Finally, we validate the effectiveness of our method in ensuring more accurate and reliable evaluations. See Project Page for the data and codes.

## 🔍 Abstract (한글 번역)

arXiv:2509.14171v1 발표 유형: 새로운
요약: 다중 모달 대형 언어 모델 (MLLMs)의 최근 발전은 인공 일반 지능 (AGI)으로의 유망한 길을 제시하여 상당한 주목을 받고 있습니다. AGI에 필요한 중요한 능력 중 하나인 창의성은 연상이 그 기초로 떠오르며 MLLMs에 대한 중요한 특성으로 부각되었습니다. 연상은 모델이 창의적으로 사고하는 능력을 반영하며, 이를 평가하고 이해하는 것이 중요합니다. 연상 능력을 평가하기 위해 여러 프레임워크가 제안되었지만, 이러한 프레임워크들은 종종 연상 작업의 본질적인 모호함을 간과하여 연상의 다양성에서 비롯된 모호함이 평가의 신뢰성을 약화시킵니다. 이 문제를 해결하기 위해 우리는 모호함을 내부 모호함과 외부 모호함 두 가지 유형으로 분해하고, 모호함을 우회하는 하이브리드 계산 방법을 통해 연상 능력을 평가하기 위해 설계된 벤치마크인 AssoCiAm을 소개합니다. 그런 다음 MLLMs에 대해 광범위한 실험을 수행하여 인지와 연상 간의 강한 양의 상관 관계를 밝혀냅니다. 또한, 평가 과정에서 모호함의 존재로 인해 MLLMs의 행동이 더 무작위적으로 변하는 것을 관찰합니다. 마지막으로, 우리의 방법이 더 정확하고 신뢰할 수 있는 평가를 보장하는 효과를 검증합니다. 데이터 및 코드에 대한 자세한 내용은 프로젝트 페이지를 참조하십시오.

## 📝 요약

최근 다중 모달 대형 언어 모델(MLLMs)의 발전은 인공 일반 지능(AGI)으로의 유망한 길을 제시하여 중요한 관심을 끌었다. AGI에 필요한 주요 능력 중 하나인 창의성은 연상이 그 기초로 부상하며 MLLMs에게 중요한 특성으로 부각되었다. 연상 능력을 평가하고 이해하는 것은 중요하며, 이를 위해 AssoCiAm이라는 새로운 벤치마크를 소개하고 MLLMs에 대한 실험을 통해 연상과 인지 간의 강한 양의 상관 관계를 밝혀냈다. 또한, 평가과정에서의 모호성은 MLLMs의 행동을 더 무작위적으로 만드는 것을 관찰하고, 보다 정확하고 신뢰할 수 있는 평가를 보장하는 우리의 방법의 효과를 검증하였다.

## 🎯 주요 포인트

- 1. 최근의 다중 모달 대형 언어 모델(MLLMs)의 발전은 인공 일반 지능(AGI)으로의 유망한 길을 제시하고 있다.

- 2. 창의성은 MLLMs에 있어서 중요한 특성으로 부각되고 있으며, 연상은 그 기초로 작용한다.

- 3. 연상 능력을 평가하고 이해하는 것은 매우 중요하며, 이를 위한 새로운 평가 기준인 AssoCiAm이 소개되었다.

---

*Generated on 2025-09-18 16:52:18*