---
keywords:
  - Large Language Models
  - Logical Inference Systems
  - Natural Language Processing
category: cs.AI
publish_date: 2025-09-18
arxiv_id: 2509.13734
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 22:25:34.386301",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Models",
    "Logical Inference Systems",
    "Natural Language Processing"
  ],
  "rejected_keywords": [
    "Compositional Semantics"
  ],
  "similarity_scores": {
    "Large Language Models": 0.8,
    "Logical Inference Systems": 0.77,
    "Natural Language Processing": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->


# Implementing a Logical Inference System for Japanese Comparatives

**Korean Title:** ì¼ë³¸ì–´ ë¹„êµì— ëŒ€í•œ ë…¼ë¦¬ ì¶”ë¡  ì‹œìŠ¤í…œ êµ¬í˜„

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[digests/daily_digest_20250918|2025-09-18]]   [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸŒ Broad Technical**: [[keywords/Natural Language Processing|Natural Language Inference]]
**ğŸ”— Specific Connectable**: [[keywords/Large Language Models|Large Language Models]]
**âš¡ Unique Technical**: [[keywords/Logical Inference Systems|logical inference system]]

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[Explicit Reasoning Makes Better Judges: A Systematic Study on Accuracy, Efficiency, and Robustness]] (76.6% similar)
- [[Early_Stopping_Chain-of-thoughts_in_Large_Language_Models_20250918|Early Stopping Chain-of-thoughts in Large Language Models]] (76.1% similar)
- [[Large_Language_Models_for_Information_Retrieval_A_Survey_20250918|Large Language Models for Information Retrieval: A Survey]] (76.0% similar)
- [[THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning]] (75.5% similar)
- [[MAgICoRe: Multi-Agent, Iterative, Coarse-to-Fine Refinement for Reasoning]] (75.3% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.13734v1 Announce Type: new 
Abstract: Natural Language Inference (NLI) involving comparatives is challenging because it requires understanding quantities and comparative relations expressed by sentences. While some approaches leverage Large Language Models (LLMs), we focus on logic-based approaches grounded in compositional semantics, which are promising for robust handling of numerical and logical expressions. Previous studies along these lines have proposed logical inference systems for English comparatives. However, it has been pointed out that there are several morphological and semantic differences between Japanese and English comparatives. These differences make it difficult to apply such systems directly to Japanese comparatives. To address this gap, this study proposes ccg-jcomp, a logical inference system for Japanese comparatives based on compositional semantics. We evaluate the proposed system on a Japanese NLI dataset containing comparative expressions. We demonstrate the effectiveness of our system by comparing its accuracy with that of existing LLMs.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.13734v1 ë°œí‘œ ìœ í˜•: ìƒˆë¡œìš´
ìš”ì•½: ë¹„êµë¥¼ í¬í•¨í•œ ìì—°ì–´ ì¶”ë¡ (NLI)ì€ ë¬¸ì¥ìœ¼ë¡œ í‘œí˜„ëœ ì–‘ê³¼ ë¹„êµ ê´€ê³„ë¥¼ ì´í•´í•´ì•¼ í•˜ê¸° ë•Œë¬¸ì— ì–´ë ¤ìš´ ê³¼ì œì…ë‹ˆë‹¤. ì¼ë¶€ ì ‘ê·¼ ë°©ì‹ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ í™œìš©í•˜ì§€ë§Œ, ìš°ë¦¬ëŠ” ìˆ˜ì¹˜ ë° ë…¼ë¦¬ í‘œí˜„ì„ ê²¬ê³ í•˜ê²Œ ì²˜ë¦¬í•˜ëŠ” ë…¼ë¦¬ ê¸°ë°˜ ì ‘ê·¼ ë°©ì‹ì— ì´ˆì ì„ ë§ì¶”ê³  ìˆìŠµë‹ˆë‹¤. ì´ì™€ ê´€ë ¨ëœ ì´ì „ ì—°êµ¬ë“¤ì€ ì˜ì–´ ë¹„êµì— ëŒ€í•œ ë…¼ë¦¬ ì¶”ë¡  ì‹œìŠ¤í…œì„ ì œì•ˆí•´ ì™”ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì¼ë³¸ì–´ì™€ ì˜ì–´ ë¹„êµ ì‚¬ì´ì—ëŠ” ì—¬ëŸ¬ í˜•íƒœë¡ ì  ë° ì˜ë¯¸ë¡ ì  ì°¨ì´ê°€ ìˆë‹¤ëŠ” ì ì´ ì§€ì ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì°¨ì´ë¡œ ì¸í•´ ì´ëŸ¬í•œ ì‹œìŠ¤í…œì„ ì¼ë³¸ì–´ ë¹„êµì— ì§ì ‘ ì ìš©í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤. ì´ ê°„ê·¹ì„ í•´ê²°í•˜ê¸° ìœ„í•´ ë³¸ ì—°êµ¬ëŠ” êµ¬ì„± ì˜ë¯¸ë¡ ì— ê¸°ë°˜ì„ ë‘” ì¼ë³¸ì–´ ë¹„êµë¥¼ ìœ„í•œ ë…¼ë¦¬ ì¶”ë¡  ì‹œìŠ¤í…œì¸ ccg-jcompì„ ì œì•ˆí•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ë¹„êµ í‘œí˜„ì„ í¬í•¨í•˜ëŠ” ì¼ë³¸ì–´ NLI ë°ì´í„°ì…‹ì—ì„œ ì œì•ˆëœ ì‹œìŠ¤í…œì„ í‰ê°€í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì‹œìŠ¤í…œì˜ ì •í™•ë„ë¥¼ ê¸°ì¡´ LLMê³¼ ë¹„êµí•˜ì—¬ íš¨ê³¼ë¥¼ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ë³¸ ì—°êµ¬ëŠ” ì¼ë³¸ì–´ ë¹„êµë¬¸ì— ëŒ€í•œ ë…¼ë¦¬ ì¶”ë¡  ì‹œìŠ¤í…œì¸ ccg-jcompì„ ì œì•ˆí•˜ê³ , ì´ë¥¼ ì¼ë³¸ì–´ NLI ë°ì´í„°ì…‹ì— ì ìš©í•˜ì—¬ í‰ê°€í•˜ì˜€ë‹¤. ì´ì „ ì—°êµ¬ë“¤ì€ ì˜ì–´ ë¹„êµë¬¸ì„ ìœ„í•œ ë…¼ë¦¬ ì¶”ë¡  ì‹œìŠ¤í…œì„ ì œì•ˆí•´ì™”ì§€ë§Œ, ì¼ë³¸ì–´ì™€ ì˜ì–´ì˜ í˜•íƒœë¡ ì , ì˜ë¯¸ë¡ ì  ì°¨ì´ë¡œ ì¸í•´ ì§ì ‘ ì ìš©í•˜ê¸° ì–´ë ¤ì› ë‹¤. ccg-jcompì€ í•©ì„± ì˜ë¯¸ë¡ ì— ê¸°ë°˜í•œ ì¼ë³¸ì–´ ë¹„êµë¬¸ì„ ìœ„í•œ ë…¼ë¦¬ ì¶”ë¡  ì‹œìŠ¤í…œìœ¼ë¡œ, ê¸°ì¡´ì˜ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ê³¼ì˜ ì •í™•ë„ë¥¼ ë¹„êµí•˜ì—¬ íš¨ê³¼ì ì„ì„ ì…ì¦í•˜ì˜€ë‹¤. ì´ë¥¼ í†µí•´ ìˆ˜ëŸ‰ê³¼ ë¹„êµ ê´€ê³„ë¥¼ ì´í•´í•˜ëŠ” ë° ì–´ë ¤ì›€ì´ ìˆëŠ” NLI ë¶„ì•¼ì— ìƒˆë¡œìš´ ì ‘ê·¼ ë°©ë²•ì„ ì œì‹œí•˜ì˜€ë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- ìì—°ì–´ ì¶”ë¡ ì—ì„œ ë¹„êµê¸‰ì„ ë‹¤ë£¨ëŠ” ê²ƒì€ ì–‘ê³¼ ë¹„êµ ê´€ê³„ë¥¼ ì´í•´í•´ì•¼ í•˜ê¸° ë•Œë¬¸ì— ì–´ë ¤ì›€ì´ ìˆë‹¤.

- ì´ ì—°êµ¬ëŠ” ì¼ë³¸ì–´ ë¹„êµê¸‰ì„ ìœ„í•œ ë…¼ë¦¬ ì¶”ë¡  ì‹œìŠ¤í…œ ccg-jcompì„ ì œì•ˆí•œë‹¤.

- ê¸°ì¡´ì˜ Large Language Modelsì™€ ë¹„êµí•˜ì—¬ ì œì•ˆëœ ì‹œìŠ¤í…œì˜ íš¨ê³¼ë¥¼ ì¦ëª…í•œë‹¤.

---

*Generated on 2025-09-18 16:50:53*