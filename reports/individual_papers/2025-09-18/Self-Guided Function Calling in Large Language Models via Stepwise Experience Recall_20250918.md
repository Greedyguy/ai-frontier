---
keywords:
  - Large Language Models
  - Stepwise Experience Recall
  - Qwen Models
category: cs.AI
publish_date: 2025-09-18
arxiv_id: 2508.15214
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 22:10:53.357133",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Models",
    "Stepwise Experience Recall",
    "Qwen Models"
  ],
  "rejected_keywords": [
    "ToolQA Benchmark"
  ],
  "similarity_scores": {
    "Large Language Models": 0.8,
    "Stepwise Experience Recall": 0.7,
    "Qwen Models": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->


# Self-Guided Function Calling in Large Language Models via Stepwise Experience Recall

**Korean Title:** 대규모 언어 모델에서의 스텝별 경험 회상을 통한 자기 안내형 함수 호출 유지

## 📋 메타데이터

**Links**: [[digests/daily_digest_20250918|2025-09-18]]   [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🌐 Broad Technical**: [[keywords/Large Language Models|Large Language Models]]
**⚡ Unique Technical**: [[keywords/Stepwise Experience Recall|Stepwise Experience Recall]], [[keywords/Qwen Models|Qwen2.5-7B and Qwen2.5-72B models]]

## 🔗 유사한 논문
- [[THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning]] (82.7% similar)
- [[Large_Language_Models_for_Information_Retrieval_A_Survey_20250918|Large Language Models for Information Retrieval: A Survey]] (82.0% similar)
- [[From_Automation_to_Autonomy_A_Survey_on_Large_Language_Models_in_Scientific_Discovery_20250918|From Automation to Autonomy: A Survey on Large Language Models in Scientific Discovery]] (81.8% similar)
- [[Evaluating_and_Improving_the_Robustness_of_Security_Attack_Detectors_Generated_by_LLMs_20250918|Evaluating and Improving the Robustness of Security Attack Detectors Generated by LLMs]] (81.2% similar)
- [[Explicit Reasoning Makes Better Judges: A Systematic Study on Accuracy, Efficiency, and Robustness]] (80.9% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2508.15214v2 Announce Type: replace 
Abstract: Function calling enables large language models (LLMs) to interact with external systems by leveraging tools and APIs. When faced with multi-step tool usage, LLMs still struggle with tool selection, parameter generation, and tool-chain planning. Existing methods typically rely on manually designing task-specific demonstrations, or retrieving from a curated library. These approaches demand substantial expert effort and prompt engineering becomes increasingly complex and inefficient as tool diversity and task difficulty scale. To address these challenges, we propose a self-guided method, Stepwise Experience Recall (SEER), which performs fine-grained, stepwise retrieval from a continually updated experience pool. Instead of relying on static or manually curated library, SEER incrementally augments the experience pool with past successful trajectories, enabling continuous expansion of the pool and improved model performance over time. Evaluated on the ToolQA benchmark, SEER achieves an average improvement of 6.1% on easy and 4.7% on hard questions. We further test SEER on $\tau$-bench, which includes two real-world domains. Powered by Qwen2.5-7B and Qwen2.5-72B models, SEER demonstrates substantial accuracy gains of 7.44% and 23.38%, respectively.

## 🔍 Abstract (한글 번역)

arXiv:2508.15214v2 발표 유형: 대체
요약: 함수 호출은 대규모 언어 모델(LLMs)이 도구와 API를 활용하여 외부 시스템과 상호 작용할 수 있게 합니다. 다단계 도구 사용에 직면할 때, LLMs는 여전히 도구 선택, 매개변수 생성 및 도구 체인 계획에 어려움을 겪습니다. 기존 방법은 일반적으로 작업별로 수동으로 설계된 데모나 선별된 라이브러리에서 검색하는 것에 의존합니다. 이러한 접근 방식은 상당한 전문가 노력을 요구하며, 도구 다양성과 작업 난이도가 증가함에 따라 공학적으로 점점 복잡하고 비효율적이 됩니다. 이러한 도전에 대처하기 위해, 우리는 Stepwise Experience Recall (SEER)이라는 자기 안내 방법을 제안합니다. SEER은 지속적으로 업데이트되는 경험 풀에서 세밀하고 단계적인 검색을 수행합니다. 정적 또는 수동으로 선별된 라이브러리에 의존하는 대신, SEER은 과거 성공적인 경로를 경험 풀에 점진적으로 추가하여 풀을 계속 확장하고 시간이 지남에 따라 모델 성능을 향상시킵니다. ToolQA 벤치마크에서 평가한 결과, SEER은 쉬운 질문에서 평균 개선률이 6.1%, 어려운 질문에서는 4.7%를 달성했습니다. 우리는 또한 $\tau$-bench에서 SEER을 테스트했는데, 이는 두 개의 실제 세계 도메인을 포함합니다. Qwen2.5-7B 및 Qwen2.5-72B 모델을 기반으로, SEER은 각각 7.44% 및 23.38%의 상당한 정확도 향상을 보여줍니다.

## 📝 요약

이 연구는 대형 언어 모델이 외부 시스템과 상호 작용하기 위해 도구와 API를 활용하는 기능 호출에 초점을 맞추고 있다. 기존 방법은 작업별 데모를 수동으로 설계하거나 취사선택된 라이브러리에서 검색하는 것을 요구하여 전문가 노력이 많이 필요하다. 이러한 도전에 대응하기 위해 본 연구는 Stepwise Experience Recall (SEER)이라는 자가 안내 방법을 제안한다. SEER은 지속적으로 업데이트되는 경험 풀에서 세부적이고 단계적인 검색을 수행하여 모델 성능을 지속적으로 향상시킨다. ToolQA 벤치마크에서 SEER은 쉬운 질문에서 6.1%, 어려운 질문에서 4.7%의 평균 개선을 달성했으며, 실제 세계 도메인을 포함하는 $\tau$-bench에서도 상당한 정확도 향상을 보여주었다.

## 🎯 주요 포인트

- 대규모 언어 모델이 외부 시스템과 상호 작용할 수 있도록 하는 기능 호출은 여전히 도구 선택, 매개변수 생성 및 도구 체인 계획에 어려움을 겪고 있다.

- SEER은 경험 풀을 지속적으로 업데이트하고 성공적인 경로를 증가시킴으로써 모델 성능을 지속적으로 향상시킨다.

- SEER은 ToolQA 벤치마크에서 쉬운 질문에서 6.1%, 어려운 질문에서 4.7%의 평균 향상을 달성한다.

- SEER은 실제 세계 도메인을 포함한 $\tau$-bench에서 Qwen2.5-7B 및 Qwen2.5-72B 모델을 통해 상당한 정확도 향상을 보여준다.

---

*Generated on 2025-09-18 16:55:31*