---
keywords:
  - 3D Geometry
  - Zero-Shot Learning
  - Geometric Vision Models
category: cs.AI
publish_date: 2025-09-18
arxiv_id: 2509.14117
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 22:26:40.764829",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "3D Geometry",
    "Zero-Shot Learning",
    "Geometric Vision Models"
  ],
  "rejected_keywords": [
    "Vision-Language-Action Models",
    "Robotic Agents"
  ],
  "similarity_scores": {
    "3D Geometry": 0.82,
    "Zero-Shot Learning": 0.79,
    "Geometric Vision Models": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->


# GeoAware-VLA: Implicit Geometry Aware Vision-Language-Action Model

**Korean Title:** GeoAware-VLA: ì•”ì‹œì  ê¸°í•˜ ì¸ì‹ ë¹„ì „-ì–¸ì–´-í–‰ë™ ëª¨ë¸

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[digests/daily_digest_20250918|2025-09-18]]   [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸŒ Broad Technical**: [[keywords/3D Geometry|3D geometry]]
**ğŸ”— Specific Connectable**: [[keywords/Zero-Shot Learning|zero-shot generalization]], [[keywords/Geometric Vision Models|geometric vision model]]

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[Enhancing Generalization in Vision-Language-Action Models by Preserving Pretrained Representations]] (86.1% similar)
- [[CLAW_A_Vision-Language-Action_Framework_for_Weight-Aware_Robotic_Grasping_20250918|CLAW: A Vision-Language-Action Framework for Weight-Aware Robotic Grasping]] (83.9% similar)
- [[Embodied_Navigation_Foundation_Model_20250918|Embodied Navigation Foundation Model]] (82.8% similar)
- [[TrajBooster_Boosting_Humanoid_Whole-Body_Manipulation_via_Trajectory-Centric_Learning_20250918|TrajBooster: Boosting Humanoid Whole-Body Manipulation via Trajectory-Centric Learning]] (82.7% similar)
- [[Video-Language Critic: Transferable Reward Functions for Language-Conditioned Robotics]] (81.1% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.14117v1 Announce Type: new 
Abstract: Vision-Language-Action (VLA) models often fail to generalize to novel camera viewpoints, a limitation stemming from their difficulty in inferring robust 3D geometry from 2D images. We introduce GeoAware-VLA, a simple yet effective approach that enhances viewpoint invariance by integrating strong geometric priors into the vision backbone. Instead of training a visual encoder or relying on explicit 3D data, we leverage a frozen, pretrained geometric vision model as a feature extractor. A trainable projection layer then adapts these geometrically-rich features for the policy decoder, relieving it of the burden of learning 3D consistency from scratch. Through extensive evaluations on LIBERO benchmark subsets, we show GeoAware-VLA achieves substantial improvements in zero-shot generalization to novel camera poses, boosting success rates by over 2x in simulation. Crucially, these benefits translate to the physical world; our model shows a significant performance gain on a real robot, especially when evaluated from unseen camera angles. Our approach proves effective across both continuous and discrete action spaces, highlighting that robust geometric grounding is a key component for creating more generalizable robotic agents.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.14117v1 ë°œí‘œ ìœ í˜•: ìƒˆë¡œìš´
ìš”ì•½: Vision-Language-Action (VLA) ëª¨ë¸ì€ ì¢…ì¢… ìƒˆë¡œìš´ ì¹´ë©”ë¼ ì‹œì ì— ëŒ€í•œ ì¼ë°˜í™”ì— ì‹¤íŒ¨í•˜ëŠ”ë°, ì´ëŠ” 2D ì´ë¯¸ì§€ì—ì„œ ê°•ë ¥í•œ 3D ê¸°í•˜í•™ì„ ì¶”ë¡ í•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” GeoAware-VLAë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ì´ëŠ” ê°•ë ¥í•œ ê¸°í•˜í•™ì  ì‚¬ì „ ì§€ì‹ì„ ì‹œê° ë°±ë³¸ì— í†µí•©í•˜ì—¬ ì‹œì  ë¶ˆë³€ì„±ì„ í–¥ìƒì‹œí‚¤ëŠ” ê°„ë‹¨í•˜ë©´ì„œë„ íš¨ê³¼ì ì¸ ë°©ë²•ì…ë‹ˆë‹¤. ì‹œê° ì¸ì½”ë”ë¥¼ í›ˆë ¨í•˜ê±°ë‚˜ ëª…ì‹œì ì¸ 3D ë°ì´í„°ì— ì˜ì¡´í•˜ëŠ” ëŒ€ì‹ , ìš°ë¦¬ëŠ” ì–¼ì–´ë¶™ì€, ì‚¬ì „ í›ˆë ¨ëœ ê¸°í•˜í•™ì  ì‹œê° ëª¨ë¸ì„ íŠ¹ì§• ì¶”ì¶œê¸°ë¡œ í™œìš©í•©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ í•™ìŠµ ê°€ëŠ¥í•œ íˆ¬ì˜ ë ˆì´ì–´ê°€ ì´ëŸ¬í•œ ê¸°í•˜í•™ì ìœ¼ë¡œ í’ë¶€í•œ íŠ¹ì§•ì„ ì •ì±… ë””ì½”ë”ì— ì ì‘ì‹œì¼œ, 3D ì¼ê´€ì„±ì„ ì²˜ìŒë¶€í„° ë°°ìš°ëŠ” ë¶€ë‹´ì„ ëœì–´ì¤ë‹ˆë‹¤. LIBERO ë²¤ì¹˜ë§ˆí¬ í•˜ìœ„ ì§‘í•©ì—ì„œì˜ ê´‘ë²”ìœ„í•œ í‰ê°€ë¥¼ í†µí•´, GeoAware-VLAê°€ ì‹œë®¬ë ˆì´ì…˜ì—ì„œ ìƒˆë¡œìš´ ì¹´ë©”ë¼ ìœ„ì¹˜ì— ëŒ€í•œ ì œë¡œìƒ· ì¼ë°˜í™”ì—ì„œ í° ê°œì„ ì„ ë‹¬ì„±í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ëŠ” ì„±ê³µë¥ ì„ 2ë°° ì´ìƒ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì¤‘ìš”í•œ ì ì€ ì´ëŸ¬í•œ ì´ì ì´ ë¬¼ë¦¬ì  ì„¸ê³„ë¡œ ì´ì–´ì§€ëŠ”ë°, ìš°ë¦¬ ëª¨ë¸ì€ ì‹¤ì œ ë¡œë´‡ì—ì„œ íŠ¹íˆ ë³´ì´ì§€ ì•Šì€ ì¹´ë©”ë¼ ê°ë„ì—ì„œ í‰ê°€ë  ë•Œ ìƒë‹¹í•œ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì ‘ê·¼ ë°©ì‹ì€ ì—°ì†ì ì´ê³  ì´ì‚°ì ì¸ í–‰ë™ ê³µê°„ ëª¨ë‘ì—ì„œ íš¨ê³¼ì ì„ì„ ê°•ì¡°í•˜ë©°, ê²¬ê³ í•œ ê¸°í•˜í•™ì  ê¸°ë°˜ì€ ë³´ë‹¤ ì¼ë°˜í™” ê°€ëŠ¥í•œ ë¡œë´‡ ì—ì´ì „íŠ¸ë¥¼ ë§Œë“œëŠ” ë° ì¤‘ìš”í•œ êµ¬ì„± ìš”ì†Œì„ì„ ê°•ì¡°í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” ìƒˆë¡œìš´ ì¹´ë©”ë¼ ì‹œì ì— ì¼ë°˜í™”í•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªëŠ” Vision-Language-Action (VLA) ëª¨ë¸ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ GeoAware-VLAë¥¼ ì œì•ˆí•œë‹¤. ì´ ë°©ë²•ì€ ê°•ë ¥í•œ ê¸°í•˜í•™ì  ì‚¬ì „ ì§€ì‹ì„ ì‹œê° ë°±ë³¸ì— í†µí•©í•˜ì—¬ ì‹œì  ë¶ˆë³€ì„±ì„ í–¥ìƒì‹œí‚¨ë‹¤. ê¸°ì¡´ì˜ ê¸°í•˜í•™ì  ë¹„ì „ ëª¨ë¸ì„ íŠ¹ì§• ì¶”ì¶œê¸°ë¡œ í™œìš©í•˜ê³ , í•™ìŠµ ê°€ëŠ¥í•œ íˆ¬ì˜ ê³„ì¸µì„ í†µí•´ ì´ëŸ¬í•œ ê¸°í•˜í•™ì ìœ¼ë¡œ í’ë¶€í•œ íŠ¹ì§•ì„ ì •ì±… ë””ì½”ë”ì— ì ì‘ì‹œí‚¨ë‹¤. LIBERO ë²¤ì¹˜ë§ˆí¬ í•˜ìœ„ ì§‘í•©ì—ì„œì˜ í‰ê°€ë¥¼ í†µí•´ GeoAware-VLAê°€ ìƒˆë¡œìš´ ì¹´ë©”ë¼ ìœ„ì¹˜ì— ëŒ€í•œ ì œë¡œìƒ· ì¼ë°˜í™” ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚¤ëŠ” ê²ƒì„ ë³´ì—¬ì£¼ì—ˆìœ¼ë©°, ì´ëŠ” ì‹œë®¬ë ˆì´ì…˜ì—ì„œ ì„±ê³µë¥ ì„ 2ë°° ì´ìƒ í–¥ìƒì‹œì¼°ë‹¤. ë˜í•œ, ì´ ëª¨ë¸ì€ ì‹¤ì œ ë¡œë´‡ì—ì„œë„ ìœ ì˜í•œ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì—¬ì£¼ì—ˆìœ¼ë©°, íŠ¹íˆ ë³¸ ì  ì—†ëŠ” ì¹´ë©”ë¼ ê°ë„ì—ì„œ í‰ê°€í•  ë•Œ ë” í° íš¨ê³¼ë¥¼ ë³´ì˜€ë‹¤. ì—°ì† ë° ì´ì‚° í–‰ë™ ê³µê°„ì—ì„œ íš¨ê³¼ì ì¸ ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚˜ë©°, ê²¬ê³ í•œ ê¸°í•˜í•™ì  ê¸°ë°˜ì€ ë³´ë‹¤ ì¼ë°˜í™”ëœ ë¡œë´‡ ì—ì´ì „íŠ¸ë¥¼ ë§Œë“œëŠ” ë° ì¤‘ìš”í•œ êµ¬ì„± ìš”ì†Œì„ì„ ê°•ì¡°í•œë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. GeoAware-VLAëŠ” ê°•ë ¥í•œ ê¸°í•˜í•™ì  ì‚¬ì „ ì§€ì‹ì„ ì‹œê° ë°±ë³¸ì— í†µí•©í•˜ì—¬ ìƒˆë¡œìš´ ì¹´ë©”ë¼ ì‹œì ì— ëŒ€í•œ ì¼ë°˜í™” ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

- 2. ê¸°í•˜í•™ì ìœ¼ë¡œ í’ë¶€í•œ íŠ¹ì§•ì„ í™œìš©í•˜ì—¬ 3D ì¼ê´€ì„±ì„ í•™ìŠµí•˜ëŠ” ë¶€ë‹´ì„ ì¤„ì´ëŠ” trainable projection layerë¥¼ ë„ì…í•©ë‹ˆë‹¤.

- 3. GeoAware-VLAëŠ” ì‹¤ì œ ë¡œë´‡ì—ì„œë„ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì´ë©°, íŠ¹íˆ ë³´ì´ì§€ ì•ŠëŠ” ì¹´ë©”ë¼ ê°ë„ì—ì„œì˜ ì„±ëŠ¥ í–¥ìƒì„ í™•ì¸í•©ë‹ˆë‹¤.

---

*Generated on 2025-09-18 17:17:29*