---
keywords:
  - Self-Supervised Learning
  - Transformer Architecture
  - Multivariate Anomaly Detection
category: cs.AI
publish_date: 2025-09-18
arxiv_id:
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 22:37:20.407951",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Self-Supervised Learning",
    "Transformer Architecture",
    "Multivariate Anomaly Detection"
  ],
  "rejected_keywords": [
    "Spatio-Temporal Patterns"
  ],
  "similarity_scores": {
    "Self-Supervised Learning": 0.82,
    "Transformer Architecture": 0.8,
    "Multivariate Anomaly Detection": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->

# Beyond Marginals: Learning Joint Spatio-Temporal Patterns for Multivariate Anomaly Detection

**Korean Title:** í•œê³„ì ì„ ë„˜ì–´ì„œ: ë‹¤ë³€ëŸ‰ ì´ìƒ íƒì§€ë¥¼ ìœ„í•œ ê³µë™ ì‹œê³µê°„ íŒ¨í„´ í•™ìŠµ

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[digests/daily_digest_20250918|2025-09-18]]      [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Self-Supervised Learning|Self-supervised contrastive learning]], [[keywords/Transformer Architecture|Transformer encoder]]
**âš¡ Unique Technical**: [[keywords/Multivariate Anomaly Detection|Multivariate anomaly detection]]

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[AnoF-Diff_ One-Step Diffusion-Based Anomaly Detection for Forceful Tool Use_20250918|AnoF-Diff One-Step Diffusion-Based Anomaly Detection for Forceful Tool Use]] (82.1% similar)
- [[Learning Mechanistic Subtypes of Neurodegeneration with a Physics-Informed Variational Autoencoder Mixture Model_20250918|Learning Mechanistic Subtypes of Neurodegeneration with a Physics-Informed Variational Autoencoder Mixture Model]] (79.2% similar)
- [[Preference Isolation Forest for Structure-based Anomaly Detection_20250919|Preference Isolation Forest for Structure-based Anomaly Detection]] (78.3% similar)
- [[DAG_ A Dual Causal Network for Time Series Forecasting with Exogenous Variables_20250919|DAG A Dual Causal Network for Time Series Forecasting with Exogenous Variables]] (78.2% similar)
- [[Data-Driven Distributed Optimization via Aggregative Tracking and Deep-Learning_20250918|Data-Driven Distributed Optimization via Aggregative Tracking and Deep-Learning]] (77.9% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** Padmaksha Roy, Almuatazbellah Boker, Lamine Mili

## ğŸ“„ Abstract (ì›ë¬¸)

In this paper, we aim to improve multivariate anomaly detection (AD) by
modeling the \textit{time-varying non-linear spatio-temporal correlations}
found in multivariate time series data . In multivariate time series data, an
anomaly may be indicated by the simultaneous deviation of interrelated time
series from their expected collective behavior, even when no individual time
series exhibits a clearly abnormal pattern on its own. In many existing
approaches, time series variables are assumed to be (conditionally)
independent, which oversimplifies real-world interactions. Our approach
addresses this by modeling joint dependencies in the latent space and
decoupling the modeling of \textit{marginal distributions, temporal dynamics,
and inter-variable dependencies}. We use a transformer encoder to capture
temporal patterns, and to model spatial (inter-variable) dependencies, we fit a
multi-variate likelihood and a copula. The temporal and the spatial components
are trained jointly in a latent space using a self-supervised contrastive
learning objective to learn meaningful feature representations to separate
normal and anomaly samples.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

ì´ ë…¼ë¬¸ì—ì„œëŠ” ë‹¤ë³€ëŸ‰ ì‹œê³„ì—´ ë°ì´í„°ì—ì„œ ë°œê²¬ë˜ëŠ” \textit{ì‹œê°„ì— ë”°ë¼ ë³€í•˜ëŠ” ë¹„ì„ í˜• ì‹œê³µê°„ ìƒê´€ê´€ê³„}ë¥¼ ëª¨ë¸ë§í•˜ì—¬ ë‹¤ë³€ëŸ‰ ì´ìƒ íƒì§€(AD)ë¥¼ ê°œì„ í•˜ê³ ì í•©ë‹ˆë‹¤. ë‹¤ë³€ëŸ‰ ì‹œê³„ì—´ ë°ì´í„°ì—ì„œ ì´ìƒ í˜„ìƒì€ ê°œë³„ ì‹œê³„ì—´ì´ ëª…í™•í•œ ë¹„ì •ìƒ íŒ¨í„´ì„ ë³´ì´ì§€ ì•Šë”ë¼ë„ ìƒí˜¸ ê´€ë ¨ëœ ì‹œê³„ì—´ì´ ì˜ˆìƒë˜ëŠ” ì§‘í•©ì  í–‰ë™ì—ì„œ ë™ì‹œì— ë²—ì–´ë‚  ë•Œ ë‚˜íƒ€ë‚  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë§ì€ ê¸°ì¡´ ì ‘ê·¼ ë°©ì‹ì—ì„œëŠ” ì‹œê³„ì—´ ë³€ìˆ˜ê°€ (ì¡°ê±´ë¶€ë¡œ) ë…ë¦½ì ì´ë¼ê³  ê°€ì •í•˜ì—¬ ì‹¤ì œ ìƒí˜¸ì‘ìš©ì„ ì§€ë‚˜ì¹˜ê²Œ ë‹¨ìˆœí™”í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì ‘ê·¼ ë°©ì‹ì€ ì ì¬ ê³µê°„ì—ì„œì˜ ê³µë™ ì¢…ì†ì„±ì„ ëª¨ë¸ë§í•˜ê³  \textit{í•œê³„ ë¶„í¬, ì‹œê°„ì  ì—­í•™, ë³€ìˆ˜ ê°„ ì¢…ì†ì„±}ì˜ ëª¨ë¸ë§ì„ ë¶„ë¦¬í•¨ìœ¼ë¡œì¨ ì´ë¥¼ í•´ê²°í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ ì¸ì½”ë”ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œê°„ì  íŒ¨í„´ì„ í¬ì°©í•˜ê³ , ê³µê°„ì (ë³€ìˆ˜ ê°„) ì¢…ì†ì„±ì„ ëª¨ë¸ë§í•˜ê¸° ìœ„í•´ ë‹¤ë³€ëŸ‰ ê°€ëŠ¥ì„±ê³¼ ì½”í’€ë¼ë¥¼ ë§ì¶¥ë‹ˆë‹¤. ì‹œê°„ì  ë° ê³µê°„ì  êµ¬ì„± ìš”ì†ŒëŠ” ì ì¬ ê³µê°„ì—ì„œ ìê¸° ì§€ë„ ëŒ€ì¡° í•™ìŠµ ëª©í‘œë¥¼ ì‚¬ìš©í•˜ì—¬ ì •ìƒ ìƒ˜í”Œê³¼ ì´ìƒ ìƒ˜í”Œì„ êµ¬ë¶„í•  ìˆ˜ ìˆëŠ” ì˜ë¯¸ ìˆëŠ” íŠ¹ì§• í‘œí˜„ì„ í•™ìŠµí•˜ë„ë¡ ê³µë™ìœ¼ë¡œ í›ˆë ¨ë©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë‹¤ë³€ëŸ‰ ì‹œê³„ì—´ ë°ì´í„°ì—ì„œ ì‹œê°„ì— ë”°ë¼ ë³€í™”í•˜ëŠ” ë¹„ì„ í˜• ì‹œê³µê°„ ìƒê´€ê´€ê³„ë¥¼ ëª¨ë¸ë§í•˜ì—¬ ë‹¤ë³€ëŸ‰ ì´ìƒ íƒì§€ë¥¼ ê°œì„ í•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ ë°©ë²•ë“¤ì€ ì‹œê³„ì—´ ë³€ìˆ˜ë¥¼ ë…ë¦½ì ìœ¼ë¡œ ê°€ì •í•˜ì—¬ ì‹¤ì œ ìƒí˜¸ì‘ìš©ì„ ê³¼ë„í•˜ê²Œ ë‹¨ìˆœí™”í•˜ëŠ” ë¬¸ì œë¥¼ ê°–ê³  ìˆìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ëŠ” ì ì¬ ê³µê°„ì—ì„œì˜ ê³µë™ ì˜ì¡´ì„±ì„ ëª¨ë¸ë§í•˜ê³ , ì£¼ë³€ ë¶„í¬, ì‹œê°„ì  ì—­í•™, ë³€ìˆ˜ ê°„ ì˜ì¡´ì„±ì˜ ëª¨ë¸ë§ì„ ë¶„ë¦¬í•˜ì—¬ ì´ë¥¼ í•´ê²°í•©ë‹ˆë‹¤. ì‹œê³„ì—´ íŒ¨í„´ì„ í¬ì°©í•˜ê¸° ìœ„í•´ íŠ¸ëœìŠ¤í¬ë¨¸ ì¸ì½”ë”ë¥¼ ì‚¬ìš©í•˜ê³ , ê³µê°„ì  ì˜ì¡´ì„±ì„ ëª¨ë¸ë§í•˜ê¸° ìœ„í•´ ë‹¤ë³€ëŸ‰ ê°€ëŠ¥ì„±ê³¼ ì½”í“°ë¼ë¥¼ ì ìš©í•©ë‹ˆë‹¤. ì‹œê°„ì  ë° ê³µê°„ì  êµ¬ì„± ìš”ì†ŒëŠ” ìê¸° ì§€ë„ ëŒ€ì¡° í•™ìŠµ ëª©í‘œë¥¼ í†µí•´ ì ì¬ ê³µê°„ì—ì„œ ê³µë™ìœ¼ë¡œ í›ˆë ¨ë˜ì–´ ì •ìƒ ë° ì´ìƒ ìƒ˜í”Œì„ êµ¬ë¶„í•˜ëŠ” ì˜ë¯¸ ìˆëŠ” íŠ¹ì§• í‘œí˜„ì„ í•™ìŠµí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë³¸ ë…¼ë¬¸ì€ ë‹¤ë³€ëŸ‰ ì‹œê³„ì—´ ë°ì´í„°ì—ì„œ ì‹œê°„ì— ë”°ë¼ ë³€í•˜ëŠ” ë¹„ì„ í˜• ì‹œê³µê°„ ìƒê´€ê´€ê³„ë¥¼ ëª¨ë¸ë§í•˜ì—¬ ë‹¤ë³€ëŸ‰ ì´ìƒ íƒì§€ë¥¼ ê°œì„ í•˜ê³ ì í•œë‹¤.

- 2. ê¸°ì¡´ ì ‘ê·¼ë²•ì€ ì‹œê³„ì—´ ë³€ìˆ˜ê°€ ë…ë¦½ì ì´ë¼ê³  ê°€ì •í•˜ì§€ë§Œ, ì´ëŠ” ì‹¤ì œ ìƒí˜¸ì‘ìš©ì„ ê³¼ë„í•˜ê²Œ ë‹¨ìˆœí™”í•œë‹¤.

- 3. ì œì•ˆëœ ë°©ë²•ì€ ì ì¬ ê³µê°„ì—ì„œì˜ ê³µë™ ì˜ì¡´ì„±ì„ ëª¨ë¸ë§í•˜ê³  ì£¼ë³€ ë¶„í¬, ì‹œê°„ì  ë™ì—­í•™, ë³€ìˆ˜ ê°„ ì˜ì¡´ì„±ì˜ ëª¨ë¸ë§ì„ ë¶„ë¦¬í•œë‹¤.

- 4. ì‹œê°„ì  íŒ¨í„´ì„ í¬ì°©í•˜ê¸° ìœ„í•´ íŠ¸ëœìŠ¤í¬ë¨¸ ì¸ì½”ë”ë¥¼ ì‚¬ìš©í•˜ê³ , ê³µê°„ì (ë³€ìˆ˜ ê°„) ì˜ì¡´ì„±ì„ ëª¨ë¸ë§í•˜ê¸° ìœ„í•´ ë‹¤ë³€ëŸ‰ ê°€ëŠ¥ì„±ê³¼ ì½”í’€ë¼ë¥¼ ì ìš©í•œë‹¤.

- 5. ì‹œê°„ì  ë° ê³µê°„ì  êµ¬ì„± ìš”ì†ŒëŠ” ìê¸° ì§€ë„ ëŒ€ì¡° í•™ìŠµ ëª©í‘œë¥¼ ì‚¬ìš©í•˜ì—¬ ì ì¬ ê³µê°„ì—ì„œ ì •ìƒ ë° ì´ìƒ ìƒ˜í”Œì„ êµ¬ë¶„í•  ìˆ˜ ìˆëŠ” ì˜ë¯¸ ìˆëŠ” íŠ¹ì§• í‘œí˜„ì„ í•™ìŠµí•˜ë„ë¡ ê³µë™ìœ¼ë¡œ í›ˆë ¨ëœë‹¤.

---

*Generated on 2025-09-20 01:09:06*