---
keywords:
  - 3D Medical Image Segmentation
  - Transfer Learning
  - Semi-Supervised Learning
category: cs.AI
publish_date: 2025-09-18
arxiv_id:
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 22:10:01.650329",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "3D Medical Image Segmentation",
    "Transfer Learning",
    "Semi-Supervised Learning"
  ],
  "rejected_keywords": [
    "Pretrained Models",
    "Model-Agnostic Framework"
  ],
  "similarity_scores": {
    "3D Medical Image Segmentation": 0.78,
    "Transfer Learning": 0.8,
    "Semi-Supervised Learning": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->

# Semi-Supervised 3D Medical Segmentation from 2D Natural Images Pretrained Model

**Korean Title:** 2D 자연 이미지 사전 학습 모델을 활용한 반지도 학습 3D 의료 분할

## 📋 메타데이터

**Links**: [[digests/daily_digest_20250918|2025-09-18]]        [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Transfer Learning|transfer of knowledge]], [[keywords/Semi-Supervised Learning|semi-supervised setting]]
**⚡ Unique Technical**: [[keywords/3D Medical Image Segmentation|3D medical image segmentation]]

## 🔗 유사한 논문
- [[Semi-MoE_ Mixture-of-Experts meets Semi-Supervised Histopathology Segmentation_20250918|Semi-MoE Mixture-of-Experts meets Semi-Supervised Histopathology Segmentation]] (85.1% similar)
- [[Masked Feature Modeling Enhances Adaptive Segmentation_20250918|Masked Feature Modeling Enhances Adaptive Segmentation]] (81.0% similar)
- [[Mixture of Multicenter Experts in Multimodal AI for Debiased Radiotherapy Target Delineation_20250919|Mixture of Multicenter Experts in Multimodal AI for Debiased Radiotherapy Target Delineation]] (80.9% similar)
- [[DiffCut_ Catalyzing Zero-Shot Semantic Segmentation with Diffusion Features and Recursive Normalized Cut_20250919|DiffCut Catalyzing Zero-Shot Semantic Segmentation with Diffusion Features and Recursive Normalized Cut]] (80.5% similar)
- [[MedFact-R1_ Towards Factual Medical Reasoning via Pseudo-Label Augmentation_20250919|MedFact-R1 Towards Factual Medical Reasoning via Pseudo-Label Augmentation]] (79.3% similar)

## 📋 저자 정보

**Authors:** Pak-Hei Yeung, Jayroop Ramesh, Pengfei Lyu, Ana Namburete, Jagath Rajapakse

## 📄 Abstract (원문)

This paper explores the transfer of knowledge from general vision models
pretrained on 2D natural images to improve 3D medical image segmentation. We
focus on the semi-supervised setting, where only a few labeled 3D medical
images are available, along with a large set of unlabeled images. To tackle
this, we propose a model-agnostic framework that progressively distills
knowledge from a 2D pretrained model to a 3D segmentation model trained from
scratch. Our approach, M&N, involves iterative co-training of the two models
using pseudo-masks generated by each other, along with our proposed learning
rate guided sampling that adaptively adjusts the proportion of labeled and
unlabeled data in each training batch to align with the models' prediction
accuracy and stability, minimizing the adverse effect caused by inaccurate
pseudo-masks. Extensive experiments on multiple publicly available datasets
demonstrate that M&N achieves state-of-the-art performance, outperforming
thirteen existing semi-supervised segmentation approaches under all different
settings. Importantly, ablation studies show that M&N remains model-agnostic,
allowing seamless integration with different architectures. This ensures its
adaptability as more advanced models emerge. The code is available at
https://github.com/pakheiyeung/M-N.

## 🔍 Abstract (한글 번역)

이 논문은 2D 자연 이미지에 대해 사전 학습된 일반적인 비전 모델로부터의 지식 전이를 탐구하여 3D 의료 이미지 분할을 개선하는 방법을 다룹니다. 우리는 소수의 레이블이 있는 3D 의료 이미지와 많은 수의 레이블이 없는 이미지가 제공되는 반지도 학습 환경에 초점을 맞추고 있습니다. 이를 해결하기 위해, 우리는 2D 사전 학습 모델로부터 처음부터 학습된 3D 분할 모델로 점진적으로 지식을 증류하는 모델 비종속적 프레임워크를 제안합니다. 우리의 접근법인 M&N은 서로에 의해 생성된 의사 마스크를 사용하여 두 모델을 반복적으로 공동 학습하는 것을 포함하며, 제안된 학습률 안내 샘플링을 통해 각 학습 배치에서 레이블이 있는 데이터와 레이블이 없는 데이터의 비율을 모델의 예측 정확도와 안정성에 맞추어 적응적으로 조정하여 부정확한 의사 마스크로 인한 부정적 영향을 최소화합니다. 여러 공개 데이터셋에 대한 광범위한 실험 결과, M&N은 모든 다른 설정에서 기존의 13개 반지도 분할 접근법을 능가하여 최첨단 성능을 달성함을 보여줍니다. 중요한 점은, 소거 연구를 통해 M&N이 모델 비종속성을 유지하여 다양한 아키텍처와의 원활한 통합이 가능함을 보여줍니다. 이는 더 발전된 모델이 등장함에 따라 적응성을 보장합니다. 코드는 https://github.com/pakheiyeung/M-N에서 제공됩니다.

## 📝 요약

이 논문은 2D 자연 이미지로 사전 학습된 일반 비전 모델의 지식을 3D 의료 이미지 분할에 적용하는 방법을 연구합니다. 특히, 소수의 라벨이 있는 3D 의료 이미지와 많은 비라벨 이미지가 있는 반지도 학습 환경에 중점을 둡니다. 제안된 M&N 프레임워크는 2D 사전 학습 모델에서 3D 분할 모델로 지식을 점진적으로 전이하며, 두 모델이 서로 생성한 가짜 마스크를 사용하여 반복적으로 공동 학습합니다. 또한, 학습률에 기반한 샘플링을 통해 라벨과 비라벨 데이터의 비율을 조정하여 모델의 예측 정확성과 안정성에 맞추고, 부정확한 가짜 마스크로 인한 부정적 영향을 최소화합니다. 여러 공개 데이터셋에서의 실험 결과, M&N은 기존 13개의 반지도 분할 방법을 능가하는 최첨단 성능을 보였습니다. 추가 연구에서는 M&N이 모델에 구애받지 않으며, 다양한 아키텍처와의 통합이 가능함을 보여줍니다. 이는 더 발전된 모델이 등장할 때도 적응성을 보장합니다. 코드: https://github.com/pakheiyeung/M-N.

## 🎯 주요 포인트

- 1. 2D 자연 이미지로 사전 학습된 일반 비전 모델의 지식을 3D 의료 이미지 분할에 활용하는 방법을 탐구합니다.

- 2. 소수의 라벨링된 3D 의료 이미지와 많은 비라벨링 이미지가 있는 반지도 학습 환경에 초점을 맞춥니다.

- 3. M&N 접근법은 2D 사전 학습 모델과 3D 분할 모델의 반복적인 공동 학습을 통해 지식을 증류합니다.

- 4. 학습률에 기반한 샘플링을 통해 라벨링된 데이터와 비라벨링 데이터의 비율을 조정하여 모델의 예측 정확성과 안정성을 높입니다.

- 5. M&N은 다양한 데이터셋에서 기존의 13개 반지도 분할 방법을 능가하는 최첨단 성능을 보여줍니다.

---

*Generated on 2025-09-20 00:54:50*