# Estimating Respiratory Effort from Nocturnal Breathing Sounds for Obstructive Sleep Apnoea Screening

**Korean Title:** μλ©΄ λ¬΄νΈν΅μ¦ μ„ λ³„μ„ μ„ν• μ•Όκ°„ νΈν΅ μ†λ¦¬λ΅λ¶€ν„° νΈν΅ λ…Έλ ¥ μ¶”μ •

## π“‹ λ©”νƒ€λ°μ΄ν„°

**Links**: [[daily/2025-09-18|2025-09-18]] [[authors/Xiaolei Xu|Xiaolei Xu]] [[authors/Chaoyue Niu|Chaoyue Niu]] [[authors/Guy J. Brown|Guy J. Brown]] [[authors/Hector Romero|Hector Romero]] [[authors/Ning Ma|Ning Ma]] [[categories/cs.AI|cs.AI]]

## π·οΈ μΉ΄ν…κ³ λ¦¬ν™”λ ν‚¤μ›λ“
**π€ Evolved Concepts**: Sensor-free OSA Monitoring

## π”— μ μ‚¬ν• λ…Όλ¬Έ
- [[Out-of-Sight Trajectories_ Tracking, Fusion, and Prediction_20250919|Out-of-Sight Trajectories Tracking, Fusion, and Prediction]] (76.6% similar)
- [[Diffusion-Based Unsupervised Audio-Visual Speech Separation in Noisy Environments with Noise Prior_20250919|Diffusion-Based Unsupervised Audio-Visual Speech Separation in Noisy Environments with Noise Prior]] (76.4% similar)
- [[Explicit Context-Driven Neural Acoustic Modeling for High-Fidelity RIR Generation_20250919|Explicit Context-Driven Neural Acoustic Modeling for High-Fidelity RIR Generation]] (75.9% similar)
- [[Multimodal signal fusion for stress detection using deep neural networks_ a novel approach for converting 1D signals to unified 2D images_20250918|Multimodal signal fusion for stress detection using deep neural networks a novel approach for converting 1D signals to unified 2D images]] (75.7% similar)
- [[Listening, Imagining & Refining_ A Heuristic Optimized ASR Correction Framework with LLMs_20250919|Listening, Imagining & Refining A Heuristic Optimized ASR Correction Framework with LLMs]] (75.2% similar)

## π“‹ μ €μ μ •λ³΄

**Authors:** Xiaolei Xu, Chaoyue Niu, Guy J. Brown, Hector Romero, Ning Ma

## π“„ Abstract (μ›λ¬Έ)

Obstructive sleep apnoea (OSA) is a prevalent condition with significant
health consequences, yet many patients remain undiagnosed due to the complexity
and cost of over-night polysomnography. Acoustic-based screening provides a
scalable alternative, yet performance is limited by environmental noise and the
lack of physiological context. Respiratory effort is a key signal used in
clinical scoring of OSA events, but current approaches require additional
contact sensors that reduce scalability and patient comfort. This paper
presents the first study to estimate respiratory effort directly from nocturnal
audio, enabling physiological context to be recovered from sound alone. We
propose a latent-space fusion framework that integrates the estimated effort
embeddings with acoustic features for OSA detection. Using a dataset of 157
nights from 103 participants recorded in home environments, our respiratory
effort estimator achieves a concordance correlation coefficient of 0.48,
capturing meaningful respiratory dynamics. Fusing effort and audio improves
sensitivity and AUC over audio-only baselines, especially at low
apnoea-hypopnoea index thresholds. The proposed approach requires only
smartphone audio at test time, which enables sensor-free, scalable, and
longitudinal OSA monitoring.

## π” Abstract (ν•κΈ€ λ²μ—­)

νμ‡„μ„± μλ©΄ λ¬΄νΈν΅μ¦(OSA)μ€ κ±΄κ°•μ— μ¤‘λ€ν• μν–¥μ„ λ―ΈμΉλ” ν”ν• μ§ν™μ΄μ§€λ§, μ•Όκ°„ λ‹¤μ›κ²€μ‚¬μ λ³µμ΅μ„±κ³Ό λΉ„μ© λ•λ¬Έμ— λ§μ€ ν™μλ“¤μ΄ μ§„λ‹¨λ°›μ§€ λ»ν•κ³  μμµλ‹λ‹¤. μν–¥ κΈ°λ°μ μ„ λ³„ κ²€μ‚¬λ” ν™•μ¥ κ°€λ¥ν• λ€μ•μ„ μ κ³µν•μ§€λ§, ν™κ²½ μ†μκ³Ό μƒλ¦¬ν•™μ  λ§¥λ½μ λ¶€μ΅±μΌλ΅ μ„±λ¥μ΄ μ ν•λ©λ‹λ‹¤. νΈν΅ λ…Έλ ¥μ€ OSA μ‚¬κ±΄μ μ„μƒ μ μμ— μ‚¬μ©λλ” μ£Όμ” μ‹ νΈμ΄μ§€λ§, ν„μ¬μ μ ‘κ·Όλ²•μ€ ν™•μ¥μ„±κ³Ό ν™μ νΈμ•ν•¨μ„ κ°μ†μ‹ν‚¤λ” μ¶”κ°€ μ ‘μ΄‰ μ„Όμ„λ¥Ό ν•„μ”λ΅ ν•©λ‹λ‹¤. λ³Έ λ…Όλ¬Έμ€ μ•Όκ°„ μ¤λ””μ¤λ΅λ¶€ν„° μ§μ ‘ νΈν΅ λ…Έλ ¥μ„ μ¶”μ •ν•μ—¬ μ†λ¦¬λ§μΌλ΅ μƒλ¦¬ν•™μ  λ§¥λ½μ„ νλ³µν•  μ μλ” μ²« λ²μ§Έ μ—°κµ¬λ¥Ό μ μ‹ν•©λ‹λ‹¤. μ°λ¦¬λ” OSA κ°μ§€λ¥Ό μ„ν•΄ μ¶”μ •λ λ…Έλ ¥ μ„λ² λ”©μ„ μν–¥ νΉμ§•κ³Ό ν†µν•©ν•λ” μ μ¬ κ³µκ°„ μµν•© ν”„λ μ„μ›ν¬λ¥Ό μ μ•ν•©λ‹λ‹¤. κ°€μ • ν™κ²½μ—μ„ λ…Ήμλ 103λ…μ μ°Έκ°€μλ΅λ¶€ν„° μμ§‘λ 157λ°•μ λ°μ΄ν„°μ…‹μ„ μ‚¬μ©ν•μ—¬, μ°λ¦¬μ νΈν΅ λ…Έλ ¥ μ¶”μ •κΈ°λ” 0.48μ μΌμΉ μƒκ΄€ κ³„μλ¥Ό λ‹¬μ„±ν•μ—¬ μλ―Έ μλ” νΈν΅ μ—­ν•™μ„ ν¬μ°©ν•©λ‹λ‹¤. λ…Έλ ¥κ³Ό μ¤λ””μ¤μ μµν•©μ€ μ¤λ””μ¤λ§ μ‚¬μ©ν• κΈ°μ¤€μ„ μ— λΉ„ν•΄ λ―Όκ°λ„μ™€ AUCλ¥Ό ν–¥μƒμ‹ν‚¤λ©°, νΉν λ‚®μ€ λ¬΄νΈν΅-μ €νΈν΅ μ§€μ μ„κ³„κ°’μ—μ„ λ‘λ“λ¬μ§‘λ‹λ‹¤. μ μ•λ μ ‘κ·Όλ²•μ€ ν…μ¤νΈ μ‹ μ¤λ§νΈν° μ¤λ””μ¤λ§ ν•„μ”λ΅ ν•μ—¬, μ„Όμ„ μ—†λ”, ν™•μ¥ κ°€λ¥ν•λ©° μ¥κΈ°μ μΈ OSA λ¨λ‹ν„°λ§μ„ κ°€λ¥ν•κ² ν•©λ‹λ‹¤.

## π“ μ”μ•½

μ΄ λ…Όλ¬Έμ€ μλ©΄ λ¬΄νΈν΅μ¦(OSA) μ§„λ‹¨μ„ μ„ν•΄ μ•Όκ°„ μ¤λ””μ¤μ—μ„ μ§μ ‘ νΈν΅ λ…Έλ ¥μ„ μ¶”μ •ν•λ” μµμ΄μ μ—°κµ¬λ¥Ό μ†κ°ν•©λ‹λ‹¤. κΈ°μ΅΄μ λ³µμ΅ν•κ³  λΉ„μ©μ΄ λ§μ΄ λ“λ” λ°©λ²• λ€μ‹ , μ¤λ§νΈν° μ¤λ””μ¤λ§μΌλ΅ OSAλ¥Ό λ¨λ‹ν„°λ§ν•  μ μλ” μ μ¬ κ³µκ°„ μµν•© ν”„λ μ„μ›ν¬λ¥Ό μ μ•ν•©λ‹λ‹¤. 103λ…μ μ°Έκ°€μ λ°μ΄ν„°λ¥Ό μ‚¬μ©ν•μ—¬, νΈν΅ λ…Έλ ¥ μ¶”μ •κΈ°λ” 0.48μ μΌμΉ μƒκ΄€ κ³„μλ¥Ό κΈ°λ΅ν•λ©° μλ―Έ μλ” νΈν΅ μ—­ν•™μ„ ν¬μ°©ν–μµλ‹λ‹¤. μ΄ λ°©λ²•μ€ μ¤λ””μ¤μ™€ νΈν΅ λ…Έλ ¥μ„ μµν•©ν•μ—¬ λ―Όκ°λ„μ™€ AUCλ¥Ό ν–¥μƒμ‹μΌ, νΉν λ‚®μ€ λ¬΄νΈν΅-μ €νΈν΅ μ§€μ μ„κ³„κ°’μ—μ„ μ„±λ¥μ„ κ°μ„ ν–μµλ‹λ‹¤.

## π― μ£Όμ” ν¬μΈνΈ

- 1. νμ‡„μ„± μλ©΄ λ¬΄νΈν΅μ¦(OSA)μ€ κ±΄κ°•μ— μ‹¬κ°ν• μν–¥μ„ λ―ΈμΉμ§€λ§, μ•Όκ°„ λ‹¤μ›κ²€μ‚¬μ λ³µμ΅μ„±κ³Ό λΉ„μ© λ•λ¬Έμ— λ§μ€ ν™μλ“¤μ΄ μ§„λ‹¨λμ§€ μ•κ³  μμµλ‹λ‹¤.

- 2. λ³Έ μ—°κµ¬λ” μ•Όκ°„ μ¤λ””μ¤λ§μΌλ΅ νΈν΅ λ…Έλ ¥μ„ μ¶”μ •ν•μ—¬ μƒλ¦¬ν•™μ  λ§¥λ½μ„ νλ³µν•  μ μλ” μ²« λ²μ§Έ μ—°κµ¬λ¥Ό μ μ‹ν•©λ‹λ‹¤.

- 3. μ μ•λ μ μ¬ κ³µκ°„ μµν•© ν”„λ μ„μ›ν¬λ” μ¶”μ •λ νΈν΅ λ…Έλ ¥ μ„λ² λ”©μ„ μν–¥ νΉμ„±κ³Ό ν†µν•©ν•μ—¬ OSAλ¥Ό κ°μ§€ν•©λ‹λ‹¤.

- 4. νΈν΅ λ…Έλ ¥κ³Ό μ¤λ””μ¤λ¥Ό μµν•©ν•¨μΌλ΅μ¨ μ¤λ””μ¤λ§ μ‚¬μ©ν• κΈ°μ¤€μ„ μ— λΉ„ν•΄ λ―Όκ°λ„μ™€ AUCκ°€ κ°μ„ λμ—μµλ‹λ‹¤.

- 5. μ μ•λ μ ‘κ·Ό λ°©μ‹μ€ ν…μ¤νΈ μ‹ μ¤λ§νΈν° μ¤λ””μ¤λ§ ν•„μ”λ΅ ν•μ—¬ μ„Όμ„ μ—†λ” ν™•μ¥ κ°€λ¥ν•κ³  μ¥κΈ°μ μΈ OSA λ¨λ‹ν„°λ§μ„ κ°€λ¥ν•κ² ν•©λ‹λ‹¤.

---

*Generated on 2025-09-20 01:43:02*