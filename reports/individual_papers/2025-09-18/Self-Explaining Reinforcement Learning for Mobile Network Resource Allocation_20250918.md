---
keywords:
  - Reinforcement Learning
  - Self-Explaining Neural Networks
  - Neural Networks
category: cs.AI
publish_date: 2025-09-18
arxiv_id:
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 22:10:59.198536",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Reinforcement Learning",
    "Self-Explaining Neural Networks",
    "Neural Networks"
  ],
  "rejected_keywords": [
    "Resource Allocation in Mobile Networks"
  ],
  "similarity_scores": {
    "Reinforcement Learning": 0.88,
    "Self-Explaining Neural Networks": 0.8,
    "Neural Networks": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->

# Self-Explaining Reinforcement Learning for Mobile Network Resource Allocation

**Korean Title:** 모바일 네트워크 자원 할당을 위한 자기 설명 강화 학습

## 📋 메타데이터

**Links**: [[digests/daily_digest_20250918|2025-09-18]]      [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🌐 Broad Technical**: [[keywords/Neural Networks|Deep Neural Networks]]
**🔗 Specific Connectable**: [[keywords/Reinforcement Learning|Reinforcement Learning]]
**⚡ Unique Technical**: [[keywords/Self-Explaining Neural Networks|Self-Explaining Neural Networks]]

## 🔗 유사한 논문
- [[An Explainable AI Framework for Dynamic Resource Management in Vehicular Network Slicing_20250919|An Explainable AI Framework for Dynamic Resource Management in Vehicular Network Slicing]] (83.5% similar)
- [[LEED_ A Highly Efficient and Scalable LLM-Empowered Expert Demonstrations Framework for Multi-Agent Reinforcement Learning_20250919|LEED A Highly Efficient and Scalable LLM-Empowered Expert Demonstrations Framework for Multi-Agent Reinforcement Learning]] (78.5% similar)
- [[Locally Explaining Prediction Behavior via Gradual Interventions and Measuring Property Gradients_20250918|Locally Explaining Prediction Behavior via Gradual Interventions and Measuring Property Gradients]] (78.3% similar)
- [[Opening the Black Box_ Interpretable LLMs via Semantic Resonance Architecture_20250919|Opening the Black Box Interpretable LLMs via Semantic Resonance Architecture]] (78.3% similar)
- [[Anomaly Detection in Offshore Open Radio Access Network Using Long Short-Term Memory Models on a Novel Artificial Intelligence-Driven Cloud-Native Data Platform_20250918|Anomaly Detection in Offshore Open Radio Access Network Using Long Short-Term Memory Models on a Novel Artificial Intelligence-Driven Cloud-Native Data Platform]] (78.3% similar)

## 📋 저자 정보

**Authors:** Konrad Nowosadko, Franco Ruggeri, Ahmad Terra

## 📄 Abstract (원문)

Reinforcement Learning (RL) methods that incorporate deep neural networks
(DNN), though powerful, often lack transparency. Their black-box characteristic
hinders interpretability and reduces trustworthiness, particularly in critical
domains. To address this challenge in RL tasks, we propose a solution based on
Self-Explaining Neural Networks (SENNs) along with explanation extraction
methods to enhance interpretability while maintaining predictive accuracy. Our
approach targets low-dimensionality problems to generate robust local and
global explanations of the model's behaviour. We evaluate the proposed method
on the resource allocation problem in mobile networks, demonstrating that SENNs
can constitute interpretable solutions with competitive performance. This work
highlights the potential of SENNs to improve transparency and trust in
AI-driven decision-making for low-dimensional tasks. Our approach strong
performance on par with the existing state-of-the-art methods, while providing
robust explanations.

## 🔍 Abstract (한글 번역)

강화 학습(RL) 방법은 심층 신경망(DNN)을 통합함으로써 강력한 성능을 발휘하지만, 종종 투명성이 부족합니다. 이러한 블랙박스 특성은 해석 가능성을 저해하고, 특히 중요한 분야에서 신뢰성을 감소시킵니다. RL 작업에서 이 문제를 해결하기 위해, 우리는 예측 정확성을 유지하면서 해석 가능성을 향상시키기 위해 자기 설명 신경망(Self-Explaining Neural Networks, SENNs)과 설명 추출 방법에 기반한 솔루션을 제안합니다. 우리의 접근법은 모델의 행동에 대한 견고한 국소 및 전역 설명을 생성하기 위해 저차원 문제를 대상으로 합니다. 우리는 모바일 네트워크의 자원 할당 문제에 제안된 방법을 평가하여, SENNs가 경쟁력 있는 성능을 갖춘 해석 가능한 솔루션을 구성할 수 있음을 입증합니다. 이 연구는 저차원 작업에 대한 AI 기반 의사 결정에서 SENNs가 투명성과 신뢰를 향상시킬 수 있는 잠재력을 강조합니다. 우리의 접근법은 기존 최첨단 방법과 동등한 강력한 성능을 제공하면서도 견고한 설명을 제공합니다.

## 📝 요약

이 논문은 심층 신경망(DNN)을 활용한 강화 학습(RL) 방법의 불투명성을 해결하기 위해 자기 설명 신경망(SENN)과 설명 추출 방법을 제안합니다. 제안된 방법은 저차원 문제에 적용하여 모델의 행동에 대한 지역 및 전역 설명을 생성하며, 모바일 네트워크의 자원 할당 문제에 적용한 결과, 기존 최첨단 방법과 유사한 성능을 유지하면서도 해석 가능성을 높였습니다. SENN은 AI 기반 의사결정의 투명성과 신뢰성을 향상시킬 잠재력을 보여줍니다.

## 🎯 주요 포인트

- 1. 심층 신경망을 활용한 강화 학습 방법은 강력하지만 투명성이 부족하여 해석 가능성과 신뢰성을 저해한다.

- 2. 본 연구는 자기 설명 신경망(SENN)과 설명 추출 방법을 통해 해석 가능성을 높이는 솔루션을 제안한다.

- 3. 제안된 방법은 저차원 문제를 대상으로 모델의 행동에 대한 강력한 지역 및 전역 설명을 생성한다.

- 4. 모바일 네트워크의 자원 할당 문제에 대한 평가 결과, SENN이 해석 가능한 솔루션을 제공하면서도 경쟁력 있는 성능을 보였다.

- 5. SENN은 AI 기반 의사 결정의 투명성과 신뢰성을 향상시킬 잠재력을 지니고 있다.

---

*Generated on 2025-09-20 02:43:29*