# Can I Trust This Chatbot? Assessing User Privacy in AI-Healthcare Chatbot Applications

**Korean Title:** 이 채팅봇을 신뢰할 수 있을까? AI-헬스케어 채팅봇 애플리케이션에서 사용자 프라이버시 평가

## 📋 메타데이터

**Links**: [[daily/2025-09-18|2025-09-18]] [[authors/Ramazan Yener|Ramazan Yener]] [[authors/Guan-Hung Chen|Guan-Hung Chen]] [[authors/Ece Gumusel|Ece Gumusel]] [[authors/Masooda Bashir|Masooda Bashir]] [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: Privacy Policy Analysis

## 🔗 유사한 논문
- [[Cybersecurity AI_ Humanoid Robots as Attack Vectors_20250918|Cybersecurity AI Humanoid Robots as Attack Vectors]] (78.5% similar)
- [[Enterprise AI Must Enforce Participant-Aware Access Control_20250919|Enterprise AI Must Enforce Participant-Aware Access Control]] (77.8% similar)
- [[Blockchain-Enabled Explainable AI for Trusted Healthcare Systems_20250918|Blockchain-Enabled Explainable AI for Trusted Healthcare Systems]] (77.1% similar)
- [[Why Johnny Can't Use Agents_ Industry Aspirations vs. User Realities with AI Agent Software_20250919|Why Johnny Can't Use Agents Industry Aspirations vs. User Realities with AI Agent Software]] (77.0% similar)
- [[Designing AI-Agents with Personalities_ A Psychometric Approach_20250918|Designing AI-Agents with Personalities A Psychometric Approach]] (76.8% similar)

## 📋 저자 정보

**Authors:** Ramazan Yener, Guan-Hung Chen, Ece Gumusel, Masooda Bashir

## 📄 Abstract (원문)

As Conversational Artificial Intelligence (AI) becomes more integrated into
everyday life, AI-powered chatbot mobile applications are increasingly adopted
across industries, particularly in the healthcare domain. These chatbots offer
accessible and 24/7 support, yet their collection and processing of sensitive
health data present critical privacy concerns. While prior research has
examined chatbot security, privacy issues specific to AI healthcare chatbots
have received limited attention. Our study evaluates the privacy practices of
12 widely downloaded AI healthcare chatbot apps available on the App Store and
Google Play in the United States. We conducted a three-step assessment
analyzing: (1) privacy settings during sign-up, (2) in-app privacy controls,
and (3) the content of privacy policies. The analysis identified significant
gaps in user data protection. Our findings reveal that half of the examined
apps did not present a privacy policy during sign up, and only two provided an
option to disable data sharing at that stage. The majority of apps' privacy
policies failed to address data protection measures. Moreover, users had
minimal control over their personal data. The study provides key insights for
information science researchers, developers, and policymakers to improve
privacy protections in AI healthcare chatbot apps.

## 🔍 Abstract (한글 번역)

대화형 인공지능(AI)이 일상생활에 점점 더 통합됨에 따라, AI 기반의 챗봇 모바일 애플리케이션이 다양한 산업, 특히 의료 분야에서 점점 더 많이 채택되고 있습니다. 이러한 챗봇은 접근 가능하고 24/7 지원을 제공하지만, 민감한 건강 데이터를 수집하고 처리하는 과정에서 중요한 개인정보 보호 문제가 발생합니다. 이전 연구에서는 챗봇 보안에 대해 조사했으나, AI 의료 챗봇에 특화된 개인정보 보호 문제는 제한적으로 다루어졌습니다. 본 연구는 미국의 앱 스토어와 구글 플레이에서 널리 다운로드된 12개의 AI 의료 챗봇 앱의 개인정보 보호 관행을 평가했습니다. 우리는 (1) 가입 시 개인정보 설정, (2) 앱 내 개인정보 제어, (3) 개인정보 보호 정책의 내용을 분석하는 세 단계의 평가를 수행했습니다. 분석 결과 사용자 데이터 보호에 상당한 격차가 있음을 확인했습니다. 조사한 앱의 절반은 가입 시 개인정보 보호 정책을 제시하지 않았으며, 데이터 공유를 비활성화할 수 있는 옵션을 제공한 앱은 두 개에 불과했습니다. 대부분의 앱의 개인정보 보호 정책은 데이터 보호 조치를 다루지 않았습니다. 게다가, 사용자는 자신의 개인 데이터에 대한 통제권이 거의 없었습니다. 본 연구는 정보 과학 연구자, 개발자 및 정책 입안자에게 AI 의료 챗봇 앱의 개인정보 보호를 개선하기 위한 중요한 통찰을 제공합니다.

## 📝 요약

대화형 인공지능(AI)이 일상에 통합됨에 따라, AI 기반 챗봇 모바일 애플리케이션이 특히 의료 분야에서 널리 사용되고 있습니다. 그러나 이러한 챗봇이 민감한 건강 데이터를 수집 및 처리함에 따라 중요한 개인정보 보호 문제가 발생합니다. 본 연구는 미국의 앱 스토어와 구글 플레이에서 널리 다운로드된 12개의 AI 의료 챗봇 앱의 개인정보 보호 관행을 평가했습니다. 가입 시 개인정보 설정, 앱 내 개인정보 제어, 개인정보 보호 정책 내용을 세 단계로 분석한 결과, 사용자 데이터 보호에 상당한 결함이 있음을 발견했습니다. 절반의 앱이 가입 시 개인정보 보호 정책을 제시하지 않았고, 데이터 공유를 비활성화할 수 있는 옵션을 제공한 앱은 두 개에 불과했습니다. 대부분의 앱의 개인정보 보호 정책은 데이터 보호 조치를 다루지 않았으며, 사용자는 개인 데이터에 대한 통제권이 거의 없었습니다. 이 연구는 정보 과학 연구자, 개발자, 정책 입안자에게 AI 의료 챗봇 앱의 개인정보 보호를 개선하기 위한 중요한 통찰을 제공합니다.

## 🎯 주요 포인트

- 1. AI 헬스케어 챗봇 앱의 개인정보 보호 관행을 평가한 결과, 사용자 데이터 보호에 중대한 결함이 발견되었습니다.

- 2. 조사한 앱 중 절반은 가입 시 개인정보 보호 정책을 제시하지 않았으며, 데이터 공유를 비활성화할 수 있는 옵션을 제공한 앱은 두 개에 불과했습니다.

- 3. 대부분의 앱의 개인정보 보호 정책은 데이터 보호 조치를 다루지 않았으며, 사용자들은 자신의 개인 데이터에 대한 통제권이 거의 없었습니다.

- 4. 본 연구는 정보 과학 연구자, 개발자, 정책 입안자에게 AI 헬스케어 챗봇 앱의 개인정보 보호를 개선하기 위한 중요한 통찰을 제공합니다.

---

*Generated on 2025-09-20 05:51:06*