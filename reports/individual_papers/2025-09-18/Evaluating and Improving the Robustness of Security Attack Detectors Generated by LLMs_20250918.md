
# Evaluating and Improving the Robustness of Security Attack Detectors Generated by LLMs

**Korean Title:** LLM에 의해 생성된 보안 공격 탐지기의 견고성을 평가하고 향상시키는 것.

## 📋 메타데이터

**Links**: [[daily/2025-09-18|2025-09-18]] [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Multi-agent RAG

## 🔗 유사한 논문
- [[CyberLLMInstruct: A Pseudo-malicious Dataset Revealing Safety-performance Trade-offs in Cyber Security LLM Fine-tuning]] (85.4% similar)
- [[KBM_Delineating_Knowledge_Boundary_for_Adaptive_Retrieval_in_Large_Language_Models_20250918|KBM: Delineating Knowledge Boundary for Adaptive Retrieval in Large Language Models]] (84.0% similar)
- [[Understanding and Mitigating Overrefusal in LLMs from an Unveiling Perspective of Safety Decision Boundary]] (83.6% similar)
- [[Crash_Report_Enhancement_with_Large_Language_Models_An_Empirical_Study_20250918|Crash Report Enhancement with Large Language Models: An Empirical Study]] (82.7% similar)
- [[Language Models Identify Ambiguities and Exploit Loopholes]] (82.7% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2411.18216v2 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) are increasingly used in software development to generate functions, such as attack detectors, that implement security requirements. A key challenge is ensuring the LLMs have enough knowledge to address specific security requirements, such as information about existing attacks. For this, we propose an approach integrating Retrieval Augmented Generation (RAG) and Self-Ranking into the LLM pipeline. RAG enhances the robustness of the output by incorporating external knowledge sources, while the Self-Ranking technique, inspired by the concept of Self-Consistency, generates multiple reasoning paths and creates ranks to select the most robust detector. Our extensive empirical study targets code generated by LLMs to detect two prevalent injection attacks in web security: Cross-Site Scripting (XSS) and SQL injection (SQLi). Results show a significant improvement in detection performance while employing RAG and Self-Ranking, with an increase of up to 71%pt (on average 37%pt) and up to 43%pt (on average 6%pt) in the F2-Score for XSS and SQLi detection, respectively.

## 🔍 Abstract (한글 번역)

arXiv:2411.18216v2 발표 유형: replace-cross
요약: 대규모 언어 모델 (LLMs)은 보안 요구 사항을 구현하는 공격 탐지기와 같은 기능을 생성하는 데 소프트웨어 개발에서 점점 더 많이 사용되고 있습니다. 주요 도전 과제는 LLMs가 기존 공격에 대한 정보와 같은 특정 보안 요구 사항을 해결하기에 충분한 지식을 갖고 있는지 보장하는 것입니다. 이를 위해 우리는 RAG (검색 증강 생성) 및 Self-Ranking을 LLM 파이프라인에 통합하는 접근 방식을 제안합니다. RAG는 외부 지식 원본을 통합하여 출력의 견고성을 향상시키는 반면, Self-Ranking 기술은 Self-Consistency 개념에서 영감을 받아 여러 추론 경로를 생성하고 가장 견고한 탐지기를 선택하기 위해 순위를 생성합니다. 우리의 광범위한 경험적 연구는 웹 보안에서 LLMs에 의해 생성된 코드를 대상으로 두 가지 주요한 삽입 공격을 탐지합니다: Cross-Site Scripting (XSS) 및 SQL 삽입 (SQLi). 결과는 RAG와 Self-Ranking을 사용할 때 탐지 성능에 상당한 향상이 있음을 보여주며, XSS 및 SQLi 감지에서 각각 최대 71%pt (평균 37%pt) 및 최대 43%pt (평균 6%pt)의 F2-Score 증가가 있습니다.

## 📝 요약

최근 대형 언어 모델(Large Language Models, LLMs)은 보안 요구 사항을 구현하는 공격 탐지기와 같은 함수를 생성하는 데 사용되고 있습니다. 이 논문은 LLM이 특정 보안 요구 사항을 충족하기 위해 충분한 지식을 갖고 있는지 보장하는 것이 중요한 과제라고 제시합니다. 이를 위해 외부 지식 소스를 통합하여 출력의 견고성을 향상시키는 RAG(검색 증강 생성) 및 Self-Ranking 기법을 LLM 파이프라인에 제안합니다. 이를 통해 웹 보안에서 주요한 공격인 Cross-Site Scripting(XSS) 및 SQL Injection(SQLi)을 탐지하는 코드에 대한 실험적 연구를 수행하였고, RAG 및 Self-Ranking을 사용할 때 XSS 및 SQLi 탐지의 F2-Score가 각각 최대 71%pt(평균 37%pt) 및 최대 43%pt(평균 6%pt) 향상되는 것을 보여주었습니다.

## 🎯 주요 포인트

- 1. 대규모 언어 모델은 보안 요구 사항을 구현하는 함수를 생성하는 데 사용되며, 외부 지식 소스를 통합하여 출력의 견고성을 향상시키는 RAG 및 Self-Ranking 기술을 제안한다.

- 2. RAG 및 Self-Ranking을 사용하면 XSS 및 SQLi와 같은 웹 보안 공격을 감지하는 데 성능이 크게 향상되며, F2-Score에서 최대 71%pt 및 43%pt의 증가가 나타난다.

- 3. Self-Ranking 기술은 다중 추론 경로를 생성하고 가장 견고한 탐지기를 선택하기 위해 순위를 생성하여 보안 요구 사항을 충족시키는 데 도움이 된다.

---

*Generated on 2025-09-18 16:49:31*