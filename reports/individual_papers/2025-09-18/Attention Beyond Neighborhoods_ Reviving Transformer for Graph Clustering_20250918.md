# Attention Beyond Neighborhoods: Reviving Transformer for Graph Clustering

**Korean Title:** ì´ì›ƒì„ ë„˜ì–´ì„  ì£¼ì˜: ê·¸ë˜í”„ í´ëŸ¬ìŠ¤í„°ë§ì„ ìœ„í•œ íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ë¶€í™œ

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-18|2025-09-18]] [[authors/Xuanting Xie|Xuanting Xie]] [[authors/Bingheng Li|Bingheng Li]] [[authors/Erlin Pan|Erlin Pan]] [[authors/Rui Hou|Rui Hou]] [[authors/Wenyu Chen|Wenyu Chen]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: Attention Mechanism, Graph Neural Network

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[GraphTorque_ Torque-Driven Rewiring Graph Neural Network_20250918|GraphTorque Torque-Driven Rewiring Graph Neural Network]] (84.3% similar)
- [[Brain-HGCN_ A Hyperbolic Graph Convolutional Network for Brain Functional Network Analysis_20250919|Brain-HGCN A Hyperbolic Graph Convolutional Network for Brain Functional Network Analysis]] (83.4% similar)
- [[Let's Grow an Unbiased Community_ Guiding the Fairness of Graphs via New Links_20250919|Let's Grow an Unbiased Community Guiding the Fairness of Graphs via New Links]] (80.7% similar)
- [[Learning Discrete Abstractions for Visual Rearrangement Tasks Using Vision-Guided Graph Coloring_20250919|Learning Discrete Abstractions for Visual Rearrangement Tasks Using Vision-Guided Graph Coloring]] (80.1% similar)
- [[Physics-Informed GCN-LSTM Framework for Long-Term Forecasting of 2D and 3D Microstructure Evolution_20250918|Physics-Informed GCN-LSTM Framework for Long-Term Forecasting of 2D and 3D Microstructure Evolution]] (79.8% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** Xuanting Xie, Bingheng Li, Erlin Pan, Rui Hou, Wenyu Chen, Zhao Kang

## ğŸ“„ Abstract (ì›ë¬¸)

Attention mechanisms have become a cornerstone in modern neural networks,
driving breakthroughs across diverse domains. However, their application to
graph structured data, where capturing topological connections is essential,
remains underexplored and underperforming compared to Graph Neural Networks
(GNNs), particularly in the graph clustering task. GNN tends to overemphasize
neighborhood aggregation, leading to a homogenization of node representations.
Conversely, Transformer tends to over globalize, highlighting distant nodes at
the expense of meaningful local patterns. This dichotomy raises a key question:
Is attention inherently redundant for unsupervised graph learning? To address
this, we conduct a comprehensive empirical analysis, uncovering the
complementary weaknesses of GNN and Transformer in graph clustering. Motivated
by these insights, we propose the Attentive Graph Clustering Network (AGCN) a
novel architecture that reinterprets the notion that graph is attention. AGCN
directly embeds the attention mechanism into the graph structure, enabling
effective global information extraction while maintaining sensitivity to local
topological cues. Our framework incorporates theoretical analysis to contrast
AGCN behavior with GNN and Transformer and introduces two innovations: (1) a KV
cache mechanism to improve computational efficiency, and (2) a pairwise margin
contrastive loss to boost the discriminative capacity of the attention space.
Extensive experimental results demonstrate that AGCN outperforms
state-of-the-art methods.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì€ í˜„ëŒ€ ì‹ ê²½ë§ì˜ ì´ˆì„ì´ ë˜ì–´ ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ íšê¸°ì ì¸ ë°œì „ì„ ì´ëŒì–´ì™”ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜, ê·¸ë˜í”„ êµ¬ì¡° ë°ì´í„°ë¥¼ ë‹¤ë£¨ëŠ” ë° ìˆì–´, íŠ¹íˆ ê·¸ë˜í”„ í´ëŸ¬ìŠ¤í„°ë§ ì‘ì—…ì—ì„œ, ê·¸ë˜í”„ ì‹ ê²½ë§(GNN)ê³¼ ë¹„êµí•˜ì—¬ ê·¸ ì ìš©ì´ ì¶©ë¶„íˆ íƒêµ¬ë˜ì§€ ì•Šì•˜ê³  ì„±ëŠ¥ì´ ë¶€ì¡±í•œ ìƒí™©ì…ë‹ˆë‹¤. GNNì€ ì´ì›ƒ ì§‘í•©ì˜ ì§‘ê³„ë¥¼ ê³¼ë„í•˜ê²Œ ê°•ì¡°í•˜ëŠ” ê²½í–¥ì´ ìˆì–´ ë…¸ë“œ í‘œí˜„ì˜ ë™ì§ˆí™”ë¥¼ ì´ˆë˜í•©ë‹ˆë‹¤. ë°˜ë©´, TransformerëŠ” ì „ì—­í™”ë¥¼ ê³¼ë„í•˜ê²Œ ì§„í–‰í•˜ì—¬ ì˜ë¯¸ ìˆëŠ” ì§€ì—­ íŒ¨í„´ì„ í¬ìƒí•˜ë©´ì„œ ë¨¼ ë…¸ë“œë¥¼ ê°•ì¡°í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì´ë¶„ë²•ì€ ì£¼ì˜ë¥¼ ê¸°ìš¸ì´ëŠ” ê²ƒì´ ë¹„ì§€ë„ ê·¸ë˜í”„ í•™ìŠµì— ë³¸ì§ˆì ìœ¼ë¡œ ë¶ˆí•„ìš”í•œê°€ë¼ëŠ” ì¤‘ìš”í•œ ì§ˆë¬¸ì„ ì œê¸°í•©ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” GNNê³¼ Transformerì˜ ê·¸ë˜í”„ í´ëŸ¬ìŠ¤í„°ë§ì—ì„œì˜ ìƒí˜¸ ë³´ì™„ì ì¸ ì•½ì ì„ ë°í˜€ë‚´ëŠ” í¬ê´„ì ì¸ ì‹¤ì¦ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ í†µì°°ì— ì˜ê°ì„ ë°›ì•„, ìš°ë¦¬ëŠ” ê·¸ë˜í”„ê°€ ì£¼ì˜ë¼ëŠ” ê°œë…ì„ ì¬í•´ì„í•œ ìƒˆë¡œìš´ ì•„í‚¤í…ì²˜ì¸ ì£¼ì˜ ê·¸ë˜í”„ í´ëŸ¬ìŠ¤í„°ë§ ë„¤íŠ¸ì›Œí¬(AGCN)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. AGCNì€ ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì„ ê·¸ë˜í”„ êµ¬ì¡°ì— ì§ì ‘ ë‚´ì¥í•˜ì—¬, ì§€ì—­ì  ìœ„ìƒ ì‹ í˜¸ì— ëŒ€í•œ ë¯¼ê°ì„±ì„ ìœ ì§€í•˜ë©´ì„œë„ íš¨ê³¼ì ì¸ ì „ì—­ ì •ë³´ ì¶”ì¶œì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ í”„ë ˆì„ì›Œí¬ëŠ” AGCNì˜ í–‰ë™ì„ GNN ë° Transformerì™€ ë¹„êµí•˜ëŠ” ì´ë¡ ì  ë¶„ì„ì„ í¬í•¨í•˜ë©°, ë‘ ê°€ì§€ í˜ì‹ ì„ ë„ì…í•©ë‹ˆë‹¤: (1) ê³„ì‚° íš¨ìœ¨ì„±ì„ ê°œì„ í•˜ê¸° ìœ„í•œ KV ìºì‹œ ë©”ì»¤ë‹ˆì¦˜, (2) ì£¼ì˜ ê³µê°„ì˜ íŒë³„ë ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ìŒë³„ ë§ˆì§„ ëŒ€ì¡° ì†ì‹¤. ê´‘ë²”ìœ„í•œ ì‹¤í—˜ ê²°ê³¼ëŠ” AGCNì´ ìµœì‹  ë°©ë²•ë“¤ì„ ëŠ¥ê°€í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ë³¸ ë…¼ë¬¸ì€ ê·¸ë˜í”„ êµ¬ì¡° ë°ì´í„°ì— ëŒ€í•œ ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì˜ í™œìš©ì„ íƒêµ¬í•˜ë©°, ê·¸ë˜í”„ í´ëŸ¬ìŠ¤í„°ë§ ì‘ì—…ì—ì„œì˜ í•œê³„ë¥¼ ì§€ì í•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ê·¸ë˜í”„ ì‹ ê²½ë§(GNN)ì€ ì´ì›ƒ ì§‘í•©ì— ê³¼ë„í•˜ê²Œ ì§‘ì¤‘í•˜ì—¬ ë…¸ë“œ í‘œí˜„ì˜ ê· ì§ˆí™”ë¥¼ ì´ˆë˜í•˜ê³ , íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” ì „ì—­ ì •ë³´ë¥¼ ê°•ì¡°í•˜ì—¬ ì§€ì—­ì  íŒ¨í„´ì„ ë†“ì¹˜ëŠ” ë¬¸ì œë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ì €ìë“¤ì€ GNNê³¼ íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ìƒí˜¸ ë³´ì™„ì  ì•½ì ì„ ë¶„ì„í•˜ê³ , ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì„ ê·¸ë˜í”„ êµ¬ì¡°ì— ì§ì ‘ í†µí•©í•œ ìƒˆë¡œìš´ ì•„í‚¤í…ì²˜ì¸ Attentive Graph Clustering Network (AGCN)ì„ ì œì•ˆí•©ë‹ˆë‹¤. AGCNì€ ì „ì—­ ì •ë³´ ì¶”ì¶œê³¼ ì§€ì—­ì  í† í´ë¡œì§€ ê°ë„ë¥¼ ë™ì‹œì— ìœ ì§€í•˜ë©°, KV ìºì‹œ ë©”ì»¤ë‹ˆì¦˜ê³¼ ìŒë³„ ë§ˆì§„ ëŒ€ì¡° ì†ì‹¤ì„ ë„ì…í•˜ì—¬ ê³„ì‚° íš¨ìœ¨ì„±ê³¼ ì£¼ì˜ ê³µê°„ì˜ ë³€ë³„ë ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, AGCNì€ ìµœì‹  ê¸°ë²•ë“¤ì„ ëŠ¥ê°€í•˜ëŠ” ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì€ ê·¸ë˜í”„ êµ¬ì¡° ë°ì´í„°ì— ëŒ€í•œ ì ìš©ì´ ë¯¸í¡í•˜ë©°, íŠ¹íˆ ê·¸ë˜í”„ í´ëŸ¬ìŠ¤í„°ë§ ì‘ì—…ì—ì„œ GNNì— ë¹„í•´ ì„±ëŠ¥ì´ ë–¨ì–´ì§„ë‹¤.

- 2. GNNì€ ì´ì›ƒ ì§‘í•©ì˜ ê³¼ë„í•œ ì§‘ê³„ë¡œ ë…¸ë“œ í‘œí˜„ì˜ ë™ì§ˆí™”ë¥¼ ì´ˆë˜í•˜ë©°, TransformerëŠ” ì „ì—­í™”ë¡œ ì¸í•´ ì§€ì—­ íŒ¨í„´ì„ ê°„ê³¼í•œë‹¤.

- 3. AGCNì€ ê·¸ë˜í”„ êµ¬ì¡°ì— ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì„ ì§ì ‘ ë‚´ì¥í•˜ì—¬ ì „ì—­ ì •ë³´ ì¶”ì¶œê³¼ ì§€ì—­ ìœ„ìƒ ì‹ í˜¸ì— ëŒ€í•œ ë¯¼ê°ì„±ì„ ìœ ì§€í•œë‹¤.

- 4. AGCNì€ ê³„ì‚° íš¨ìœ¨ì„±ì„ ë†’ì´ëŠ” KV ìºì‹œ ë©”ì»¤ë‹ˆì¦˜ê³¼ ì£¼ì˜ ê³µê°„ì˜ ë³€ë³„ë ¥ì„ ê°•í™”í•˜ëŠ” ìŒë³„ ë§ˆì§„ ëŒ€ì¡° ì†ì‹¤ì„ ë„ì…í•œë‹¤.

- 5. ì‹¤í—˜ ê²°ê³¼, AGCNì€ ìµœì‹  ê¸°ë²•ë“¤ì„ ëŠ¥ê°€í•˜ëŠ” ì„±ëŠ¥ì„ ë³´ì—¬ì¤€ë‹¤.

---

*Generated on 2025-09-20 01:11:16*