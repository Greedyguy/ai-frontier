---
keywords:
  - Graph Neural Networks
  - Precision Neural Networks
  - Covariance Matrix
category: cs.AI
publish_date: 2025-09-18
arxiv_id:
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 22:15:16.189162",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Graph Neural Networks",
    "Precision Neural Networks",
    "Covariance Matrix"
  ],
  "rejected_keywords": [
    "Optimization"
  ],
  "similarity_scores": {
    "Graph Neural Networks": 0.82,
    "Precision Neural Networks": 0.78,
    "Covariance Matrix": 0.65
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->

# Precision Neural Networks: Joint Graph And Relational Learning

**Korean Title:** ì •ë°€ ì‹ ê²½ë§: ê·¸ë˜í”„ ë° ê´€ê³„ í•™ìŠµì˜ ê²°í•©

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**:      [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸŒ Broad Technical**: [[keywords/Covariance Matrix|Covariance Matrix]]
**ğŸ”— Specific Connectable**: [[keywords/Graph Neural Networks|Graph Neural Networks]]
**âš¡ Unique Technical**: [[keywords/Precision Neural Networks|Precision Neural Networks]]

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[Data-Driven Distributed Optimization via Aggregative Tracking and Deep-Learning_20250918|Data-Driven Distributed Optimization via Aggregative Tracking and Deep-Learning]] (76.8% similar)
- [[GraphTorque_ Torque-Driven Rewiring Graph Neural Network_20250918|GraphTorque Torque-Driven Rewiring Graph Neural Network]] (76.6% similar)
- [[Balancing Sparse RNNs with Hyperparameterization Benefiting Meta-Learning_20250918|Balancing Sparse RNNs with Hyperparameterization Benefiting Meta-Learning]] (76.4% similar)
- [[MaRVIn_ A Cross-Layer Mixed-Precision RISC-V Framework for DNN Inference, from ISA Extension to Hardware Acceleration_20250919|MaRVIn A Cross-Layer Mixed-Precision RISC-V Framework for DNN Inference, from ISA Extension to Hardware Acceleration]] (76.2% similar)
- [[Probabilistic and nonlinear compressive sensing_20250918|Probabilistic and nonlinear compressive sensing]] (75.9% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** Andrea Cavallo, Samuel Rey, Antonio G. Marques, Elvin Isufi

## ğŸ“„ Abstract (ì›ë¬¸)

CoVariance Neural Networks (VNNs) perform convolutions on the graph
determined by the covariance matrix of the data, which enables expressive and
stable covariance-based learning. However, covariance matrices are typically
dense, fail to encode conditional independence, and are often precomputed in a
task-agnostic way, which may hinder performance. To overcome these limitations,
we study Precision Neural Networks (PNNs), i.e., VNNs on the precision matrix
-- the inverse covariance. The precision matrix naturally encodes statistical
independence, often exhibits sparsity, and preserves the covariance spectral
structure. To make precision estimation task-aware, we formulate an
optimization problem that jointly learns the network parameters and the
precision matrix, and solve it via alternating optimization, by sequentially
updating the network weights and the precision estimate. We theoretically bound
the distance between the estimated and true precision matrices at each
iteration, and demonstrate the effectiveness of joint estimation compared to
two-step approaches on synthetic and real-world data.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

ê³µë¶„ì‚° ì‹ ê²½ë§(VNNs)ì€ ë°ì´í„°ì˜ ê³µë¶„ì‚° í–‰ë ¬ì— ì˜í•´ ê²°ì •ëœ ê·¸ë˜í”„ì—ì„œ ì»¨ë³¼ë£¨ì…˜ì„ ìˆ˜í–‰í•˜ì—¬ í‘œí˜„ë ¥ ìˆê³  ì•ˆì •ì ì¸ ê³µë¶„ì‚° ê¸°ë°˜ í•™ìŠµì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê³µë¶„ì‚° í–‰ë ¬ì€ ì¼ë°˜ì ìœ¼ë¡œ ë°€ì§‘ë˜ì–´ ìˆìœ¼ë©° ì¡°ê±´ë¶€ ë…ë¦½ì„±ì„ ì¸ì½”ë”©í•˜ì§€ ëª»í•˜ê³ , ì¢…ì¢… ê³¼ì œì™€ ë¬´ê´€í•˜ê²Œ ì‚¬ì „ ê³„ì‚°ë˜ê¸° ë•Œë¬¸ì— ì„±ëŠ¥ì„ ì €í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì œí•œì„ ê·¹ë³µí•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ì •ë°€ ì‹ ê²½ë§(PNNs), ì¦‰ ì •ë°€ í–‰ë ¬(ê³µë¶„ì‚°ì˜ ì—­í–‰ë ¬)ì—ì„œì˜ VNNsë¥¼ ì—°êµ¬í•©ë‹ˆë‹¤. ì •ë°€ í–‰ë ¬ì€ ìì—°ìŠ¤ëŸ½ê²Œ í†µê³„ì  ë…ë¦½ì„±ì„ ì¸ì½”ë”©í•˜ë©°, ì¢…ì¢… í¬ì†Œì„±ì„ ë‚˜íƒ€ë‚´ê³  ê³µë¶„ì‚°ì˜ ìŠ¤í™íŠ¸ëŸ¼ êµ¬ì¡°ë¥¼ ë³´ì¡´í•©ë‹ˆë‹¤. ì •ë°€ ì¶”ì •ì„ ê³¼ì œì— ë§ê²Œ ë§Œë“¤ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ë„¤íŠ¸ì›Œí¬ ë§¤ê°œë³€ìˆ˜ì™€ ì •ë°€ í–‰ë ¬ì„ ê³µë™ìœ¼ë¡œ í•™ìŠµí•˜ëŠ” ìµœì í™” ë¬¸ì œë¥¼ ìˆ˜ë¦½í•˜ê³ , ë„¤íŠ¸ì›Œí¬ ê°€ì¤‘ì¹˜ì™€ ì •ë°€ ì¶”ì •ì„ ìˆœì°¨ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ì—¬ êµëŒ€ ìµœì í™”ë¥¼ í†µí•´ ì´ë¥¼ í•´ê²°í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ê° ë°˜ë³µì—ì„œ ì¶”ì •ëœ ì •ë°€ í–‰ë ¬ê³¼ ì‹¤ì œ ì •ë°€ í–‰ë ¬ ê°„ì˜ ê±°ë¦¬ë¥¼ ì´ë¡ ì ìœ¼ë¡œ ì œí•œí•˜ê³ , í•©ì„± ë° ì‹¤ì œ ë°ì´í„°ì—ì„œì˜ ë‘ ë‹¨ê³„ ì ‘ê·¼ë²•ê³¼ ë¹„êµí•˜ì—¬ ê³µë™ ì¶”ì •ì˜ íš¨ê³¼ë¥¼ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì—ì„œëŠ” ë°ì´í„°ì˜ ê³µë¶„ì‚° í–‰ë ¬ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ëŠ” CoVariance Neural Networks(VNNs)ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ Precision Neural Networks(PNNs)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. PNNsëŠ” ê³µë¶„ì‚°ì˜ ì—­í–‰ë ¬ì¸ ì •ë°€ë„ í–‰ë ¬ì„ ì‚¬ìš©í•˜ì—¬ í†µê³„ì  ë…ë¦½ì„±ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì¸ì½”ë”©í•˜ê³  í¬ì†Œì„±ì„ ë³´ì…ë‹ˆë‹¤. ì €ìë“¤ì€ ë„¤íŠ¸ì›Œí¬ íŒŒë¼ë¯¸í„°ì™€ ì •ë°€ë„ í–‰ë ¬ì„ ê³µë™ìœ¼ë¡œ í•™ìŠµí•˜ëŠ” ìµœì í™” ë¬¸ì œë¥¼ ì„¤ì •í•˜ê³ , êµëŒ€ ìµœì í™”ë¥¼ í†µí•´ ì´ë¥¼ í•´ê²°í•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ì¶”ì •ëœ ì •ë°€ë„ í–‰ë ¬ê³¼ ì‹¤ì œ í–‰ë ¬ ê°„ì˜ ê±°ë¦¬ë¥¼ ì´ë¡ ì ìœ¼ë¡œ ì œí•œí•˜ë©°, í•©ì„± ë° ì‹¤ì œ ë°ì´í„°ì—ì„œ ê¸°ì¡´ì˜ 2ë‹¨ê³„ ì ‘ê·¼ë²•ë³´ë‹¤ íš¨ê³¼ì ì„ì„ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. CoVariance Neural Networks (VNNs)ëŠ” ë°ì´í„°ì˜ ê³µë¶„ì‚° í–‰ë ¬ì— ì˜í•´ ê²°ì •ëœ ê·¸ë˜í”„ì—ì„œ ì»¨ë³¼ë£¨ì…˜ì„ ìˆ˜í–‰í•˜ì—¬ í‘œí˜„ë ¥ ìˆê³  ì•ˆì •ì ì¸ í•™ìŠµì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.

- 2. ê³µë¶„ì‚° í–‰ë ¬ì€ ì¼ë°˜ì ìœ¼ë¡œ ë°€ì§‘ë˜ì–´ ìˆìœ¼ë©° ì¡°ê±´ë¶€ ë…ë¦½ì„±ì„ ì¸ì½”ë”©í•˜ì§€ ëª»í•˜ê³ , ì‘ì—…ê³¼ ë¬´ê´€í•˜ê²Œ ì‚¬ì „ ê³„ì‚°ë˜ì–´ ì„±ëŠ¥ì„ ì €í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- 3. Precision Neural Networks (PNNs)ëŠ” ê³µë¶„ì‚°ì˜ ì—­í–‰ë ¬ì¸ ì •ë°€ë„ í–‰ë ¬ì„ ì‚¬ìš©í•˜ì—¬ ì´ëŸ¬í•œ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³ ì í•©ë‹ˆë‹¤.

- 4. ì •ë°€ë„ í–‰ë ¬ì€ í†µê³„ì  ë…ë¦½ì„±ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì¸ì½”ë”©í•˜ë©°, í¬ì†Œì„±ì„ ë‚˜íƒ€ë‚´ê³  ê³µë¶„ì‚°ì˜ ìŠ¤í™íŠ¸ëŸ¼ êµ¬ì¡°ë¥¼ ë³´ì¡´í•©ë‹ˆë‹¤.

- 5. ë„¤íŠ¸ì›Œí¬ ë§¤ê°œë³€ìˆ˜ì™€ ì •ë°€ë„ í–‰ë ¬ì„ ê³µë™ìœ¼ë¡œ í•™ìŠµí•˜ëŠ” ìµœì í™” ë¬¸ì œë¥¼ ì œì‹œí•˜ê³ , ì´ë¡ ì ìœ¼ë¡œ ê° ë°˜ë³µì—ì„œ ì¶”ì •ëœ ì •ë°€ë„ í–‰ë ¬ê³¼ ì‹¤ì œ ì •ë°€ë„ í–‰ë ¬ ê°„ì˜ ê±°ë¦¬ë¥¼ ì œí•œí•©ë‹ˆë‹¤.

---

*Generated on 2025-09-20 02:49:58*