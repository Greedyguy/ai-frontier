
# Semantic-Enhanced Cross-Modal Place Recognition for Robust Robot Localization

**Korean Title:** ë¡œë´‡ì˜ ê²¬ê³ í•œ ë¡œë´‡ ìœ„ì¹˜ ê²°ì •ì„ ìœ„í•œ ì˜ë¯¸ ê°•í™”ëœ êµì°¨ ëª¨ë‹¬ ì¥ì†Œ ì¸ì‹

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-18|2025-09-18]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Multi-View Semantic-Geometric Matching

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[FSR-VLN_Fast_and_Slow_Reasoning_for_Vision-Language_Navigation_with_Hierarchical_Multi-modal_Scene_Graph_20250918|FSR-VLN: Fast and Slow Reasoning for Vision-Language Navigation with Hierarchical Multi-modal Scene Graph]] (81.1% similar)
- [[InterKey_Cross-modal_Intersection_Keypoints_for_Global_Localization_on_OpenStreetMap_20250918|InterKey: Cross-modal Intersection Keypoints for Global Localization on OpenStreetMap]] (80.6% similar)
- [[MCGS-SLAM_A_Multi-Camera_SLAM_Framework_Using_Gaussian_Splatting_for_High-Fidelity_Mapping_20250918|MCGS-SLAM: A Multi-Camera SLAM Framework Using Gaussian Splatting for High-Fidelity Mapping]] (80.4% similar)
- [[Search-TTA: A Multimodal Test-Time Adaptation Framework for Visual Search in the Wild]] (80.4% similar)
- [[BIM_Informed_Visual_SLAM_for_Construction_Monitoring_20250918|BIM Informed Visual SLAM for Construction Monitoring]] (79.4% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.13474v1 Announce Type: new 
Abstract: Ensuring accurate localization of robots in environments without GPS capability is a challenging task. Visual Place Recognition (VPR) techniques can potentially achieve this goal, but existing RGB-based methods are sensitive to changes in illumination, weather, and other seasonal changes. Existing cross-modal localization methods leverage the geometric properties of RGB images and 3D LiDAR maps to reduce the sensitivity issues highlighted above. Currently, state-of-the-art methods struggle in complex scenes, fine-grained or high-resolution matching, and situations where changes can occur in viewpoint. In this work, we introduce a framework we call Semantic-Enhanced Cross-Modal Place Recognition (SCM-PR) that combines high-level semantics utilizing RGB images for robust localization in LiDAR maps. Our proposed method introduces: a VMamba backbone for feature extraction of RGB images; a Semantic-Aware Feature Fusion (SAFF) module for using both place descriptors and segmentation masks; LiDAR descriptors that incorporate both semantics and geometry; and a cross-modal semantic attention mechanism in NetVLAD to improve matching. Incorporating the semantic information also was instrumental in designing a Multi-View Semantic-Geometric Matching and a Semantic Consistency Loss, both in a contrastive learning framework. Our experimental work on the KITTI and KITTI-360 datasets show that SCM-PR achieves state-of-the-art performance compared to other cross-modal place recognition methods.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.13474v1 ë°œí‘œ ìœ í˜•: ìƒˆë¡œìš´
ìš”ì•½: GPS ê¸°ëŠ¥ì´ ì—†ëŠ” í™˜ê²½ì—ì„œ ë¡œë´‡ì˜ ì •í™•í•œ ìœ„ì¹˜ ì§€ì •ì„ ë³´ì¥í•˜ëŠ” ê²ƒì€ ì–´ë ¤ìš´ ê³¼ì œì…ë‹ˆë‹¤. ì‹œê°ì  ì¥ì†Œ ì¸ì‹(VPR) ê¸°ìˆ ì€ ì´ ëª©í‘œë¥¼ ë‹¬ì„±í•  ìˆ˜ ìˆì§€ë§Œ, ê¸°ì¡´ì˜ RGB ê¸°ë°˜ ë°©ë²•ì€ ì¡°ëª…, ë‚ ì”¨ ë° ê³„ì ˆ ë³€í™”ì— ë¯¼ê°í•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ êµì°¨ ëª¨ë‹¬ ë¡œì»¬ë¼ì´ì œì´ì…˜ ë°©ë²•ì€ RGB ì´ë¯¸ì§€ì™€ 3D LiDAR ì§€ë„ì˜ ê¸°í•˜í•™ì  íŠ¹ì„±ì„ í™œìš©í•˜ì—¬ ìœ„ì—ì„œ ê°•ì¡°í•œ ë¯¼ê°ì„± ë¬¸ì œë¥¼ ì¤„ì…ë‹ˆë‹¤. í˜„ì¬ ìµœì²¨ë‹¨ ê¸°ìˆ ì€ ë³µì¡í•œ ì¥ë©´, ë¯¸ì„¸í•œ ë˜ëŠ” ê³ í•´ìƒë„ ë§¤ì¹­, ê·¸ë¦¬ê³  ì‹œì  ë³€ê²½ì´ ë°œìƒí•  ìˆ˜ ìˆëŠ” ìƒí™©ì—ì„œ ì–´ë ¤ì›€ì„ ê²ªìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” ìš°ë¦¬ê°€ Semantic-Enhanced Cross-Modal Place Recognition (SCM-PR)ë¼ê³  ë¶€ë¥´ëŠ” í”„ë ˆì„ì›Œí¬ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ì´ëŠ” LiDAR ì§€ë„ì—ì„œ ê°•ë ¥í•œ ìœ„ì¹˜ ì§€ì •ì„ ìœ„í•´ RGB ì´ë¯¸ì§€ë¥¼ í™œìš©í•˜ëŠ” ê³ ìˆ˜ì¤€ ì˜ë¯¸ë¡ ì„ ê²°í•©í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì œì•ˆëœ ë°©ë²•ì€ ë‹¤ìŒì„ ë„ì…í•©ë‹ˆë‹¤: RGB ì´ë¯¸ì§€ì˜ íŠ¹ì§• ì¶”ì¶œì„ ìœ„í•œ VMamba ë°±ë³¸; ì¥ì†Œ ì„¤ëª…ìì™€ ë¶„í•  ë§ˆìŠ¤í¬ë¥¼ ëª¨ë‘ ì‚¬ìš©í•˜ëŠ” Semantic-Aware Feature Fusion (SAFF) ëª¨ë“ˆ; ì˜ë¯¸ë¡ ê³¼ ê¸°í•˜í•™ì„ ëª¨ë‘ í¬í•¨í•˜ëŠ” LiDAR ì„¤ëª…ì; ê·¸ë¦¬ê³  ì¼ì¹˜ë¥¼ ê°œì„ í•˜ê¸° ìœ„í•œ NetVLADì˜ êµì°¨ ëª¨ë‹¬ ì˜ë¯¸ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜. ì˜ë¯¸ ì •ë³´ë¥¼ í†µí•©í•˜ëŠ” ê²ƒì€ ëŒ€ì¡°ì  í•™ìŠµ í”„ë ˆì„ì›Œí¬ì—ì„œ Multi-View Semantic-Geometric Matching ë° Semantic Consistency Lossë¥¼ ì„¤ê³„í•˜ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í–ˆìŠµë‹ˆë‹¤. KITTI ë° KITTI-360 ë°ì´í„°ì…‹ì—ì„œì˜ ì‹¤í—˜ ê²°ê³¼ëŠ” SCM-PRì´ ë‹¤ë¥¸ êµì°¨ ëª¨ë‹¬ ì¥ì†Œ ì¸ì‹ ë°©ë²•ê³¼ ë¹„êµí•˜ì—¬ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í•œë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ë¡œë´‡ì˜ ì •í™•í•œ ìœ„ì¹˜ ì¸ì‹ì€ GPS ê¸°ëŠ¥ì´ ì—†ëŠ” í™˜ê²½ì—ì„œ ì–´ë ¤ìš´ ê³¼ì œì´ë‹¤. ì‹œê°ì  ì¥ì†Œ ì¸ì‹(VPR) ê¸°ìˆ ì€ ì´ ëª©í‘œë¥¼ ë‹¬ì„±í•  ìˆ˜ ìˆì§€ë§Œ ê¸°ì¡´ì˜ RGB ê¸°ë°˜ ë°©ë²•ì€ ì¡°ëª…, ë‚ ì”¨ ë° ê³„ì ˆ ë³€í™”ì— ë¯¼ê°í•˜ë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” RGB ì´ë¯¸ì§€ì˜ ê³ ìˆ˜ì¤€ ì˜ë¯¸ë¡ ì„ í™œìš©í•˜ì—¬ LiDAR ì§€ë„ì—ì„œ ê°•ë ¥í•œ ë¡œë´‡ ìœ„ì¹˜ ì¸ì‹ì„ ìœ„í•œ Semantic-Enhanced Cross-Modal Place Recognition (SCM-PR) í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•œë‹¤. VMamba ë°±ë³¸, Semantic-Aware Feature Fusion ëª¨ë“ˆ, LiDAR ì„¤ëª…ì ë° NetVLADì˜ êµì°¨ ëª¨ë‹¬ ì˜ë¯¸ì£¼ì˜ ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì„ ë„ì…í•˜ì—¬ ìƒíƒœ-ì˜¤ë¸Œ-ë”-ì•„íŠ¸ ë°©ë²•ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- ë¡œë´‡ì˜ ì •í™•í•œ ìœ„ì¹˜ ì§€ì •ì€ GPS ê¸°ëŠ¥ì´ ì—†ëŠ” í™˜ê²½ì—ì„œ ì–´ë ¤ìš´ ê³¼ì œì´ë‹¤.

- ê¸°ì¡´ RGB ê¸°ë°˜ ë°©ë²•ì€ ì¡°ëª…, ë‚ ì”¨ ë° ê³„ì ˆ ë³€í™”ì— ë¯¼ê°í•˜ë‹¤.

- SCM-PRì€ RGB ì´ë¯¸ì§€ì˜ ê³ ìˆ˜ì¤€ ì˜ë¯¸ë¡ ì„ í™œìš©í•˜ì—¬ LiDAR ì§€ë„ì—ì„œ ê°•ë ¥í•œ ìœ„ì¹˜ ì§€ì •ì„ ê²°í•©í•œë‹¤.

- SCM-PRì€ ë‹¤ë¥¸ êµì°¨ ëª¨ë‹¬ ìœ„ì¹˜ ì¸ì‹ ë°©ë²•ê³¼ ë¹„êµí•˜ì—¬ ìµœê³  ìˆ˜ì¤€ì˜ ì„±ëŠ¥ì„ ë‹¬ì„±í•œë‹¤.

---

*Generated on 2025-09-18 16:58:23*