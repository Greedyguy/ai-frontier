---
keywords:
  - In-Context Learning
  - Text-Embedding KNN
  - Foundation Models
category: cs.AI
publish_date: 2025-09-18
arxiv_id: 2509.13395
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 22:07:17.067191",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "In-Context Learning",
    "Text-Embedding KNN",
    "Foundation Models"
  ],
  "rejected_keywords": [
    "Speech Recognition"
  ],
  "similarity_scores": {
    "In-Context Learning": 0.88,
    "Text-Embedding KNN": 0.82,
    "Foundation Models": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->


# TICL: Text-Embedding KNN For Speech In-Context Learning Unlocks Speech Recognition Abilities of Large Multimodal Models

**Korean Title:** TICL: ëŒ€ê·œëª¨ ë‹¤ì¤‘ëª¨ë‹¬ ëª¨ë¸ì˜ ìŒì„± ì¸ì‹ ëŠ¥ë ¥ì„ í™œì„±í™”í•˜ëŠ” ìŒì„± ë§¥ë½ ë‚´ í•™ìŠµì„ ìœ„í•œ í…ìŠ¤íŠ¸ ì„ë² ë”© KNN

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[digests/daily_digest_20250918|2025-09-18]]   [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸŒ Broad Technical**: [[keywords/Foundation Models|Large Multimodal Models]]
**âš¡ Unique Technical**: [[keywords/Text-Embedding KNN|Text-Embedding KNN]]
**ğŸš€ Evolved Concepts**: [[keywords/In-Context Learning|Speech In-Context Learning]]

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[Singular_Value_Few-shot_Adaptation_of_Vision-Language_Models_20250918|Singular Value Few-shot Adaptation of Vision-Language Models]] (80.4% similar)
- [[Omni-CLST Error-aware Curriculum Learning with guided Selective chain-of-Thought for audio question answering]] (80.3% similar)
- [[Privacy-Aware In-Context Learning for Large Language Models]] (79.1% similar)
- [[Self-Guided_Function_Calling_in_Large_Language_Models_via_Stepwise_Experience_Recall_20250918|Self-Guided Function Calling in Large Language Models via Stepwise Experience Recall]] (79.0% similar)
- [[Iterative_Prompt_Refinement_for_Safer_Text-to-Image_Generation_20250918|Iterative Prompt Refinement for Safer Text-to-Image Generation]] (78.4% similar)

ë˜ëŠ” ë” ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ í‘œí˜„ìœ¼ë¡œ:

TICL: í…ìŠ¤íŠ¸ ì„ë² ë”© KNNì„ í™œìš©í•œ ìŒì„± ë§¥ë½ ë‚´ í•™ìŠµ - ëŒ€ê·œëª¨ ë‹¤ì¤‘ëª¨ë‹¬ ëª¨ë¸ì˜ ìŒì„± ì¸ì‹ ëŠ¥ë ¥ ë°œí˜„

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.13395v1 Announce Type: cross 
Abstract: Speech foundation models have recently demonstrated the ability to perform Speech In-Context Learning (SICL). Selecting effective in-context examples is crucial for SICL performance, yet selection methodologies remain underexplored. In this work, we propose Text-Embedding KNN for SICL (TICL), a simple pipeline that uses semantic context to enhance off-the-shelf large multimodal models' speech recognition ability without fine-tuning. Across challenging automatic speech recognition tasks, including accented English, multilingual speech, and children's speech, our method enables models to surpass zero-shot performance with up to 84.7% relative WER reduction. We conduct ablation studies to show the robustness and efficiency of our method.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.13395v1 ë°œí‘œ ìœ í˜•: cross
ì´ˆë¡: ìŒì„± ê¸°ë°˜ ëª¨ë¸ë“¤ì€ ìµœê·¼ ìŒì„± ë¬¸ë§¥ ë‚´ í•™ìŠµ(Speech In-Context Learning, SICL)ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ë³´ì—¬ì£¼ì—ˆë‹¤. íš¨ê³¼ì ì¸ ë¬¸ë§¥ ë‚´ ì˜ˆì‹œë¥¼ ì„ íƒí•˜ëŠ” ê²ƒì€ SICL ì„±ëŠ¥ì— ìˆì–´ ë§¤ìš° ì¤‘ìš”í•˜ì§€ë§Œ, ì„ íƒ ë°©ë²•ë¡ ì€ ì—¬ì „íˆ ì¶©ë¶„íˆ íƒêµ¬ë˜ì§€ ì•Šì€ ìƒíƒœì´ë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” SICLì„ ìœ„í•œ í…ìŠ¤íŠ¸ ì„ë² ë”© KNN(Text-Embedding KNN for SICL, TICL)ì„ ì œì•ˆí•œë‹¤. ì´ëŠ” ì˜ë¯¸ì  ë§¥ë½ì„ í™œìš©í•˜ì—¬ íŒŒì¸íŠœë‹ ì—†ì´ ê¸°ì¡´ì˜ ëŒ€ê·œëª¨ ë‹¤ì¤‘ëª¨ë‹¬ ëª¨ë¸ì˜ ìŒì„± ì¸ì‹ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê°„ë‹¨í•œ íŒŒì´í”„ë¼ì¸ì´ë‹¤. ì–µì–‘ì´ ìˆëŠ” ì˜ì–´, ë‹¤êµ­ì–´ ìŒì„±, ê·¸ë¦¬ê³  ì•„ë™ ìŒì„±ì„ í¬í•¨í•œ ë„ì „ì ì¸ ìë™ ìŒì„± ì¸ì‹ ê³¼ì œë“¤ì—ì„œ, ë³¸ ë°©ë²•ì€ ëª¨ë¸ì´ ìµœëŒ€ 84.7%ì˜ ìƒëŒ€ì  ë‹¨ì–´ ì˜¤ë¥˜ìœ¨(WER) ê°ì†Œë¡œ ì œë¡œìƒ· ì„±ëŠ¥ì„ ëŠ¥ê°€í•  ìˆ˜ ìˆê²Œ í•œë‹¤. ìš°ë¦¬ëŠ” ë³¸ ë°©ë²•ì˜ ê°•ê±´ì„±ê³¼ íš¨ìœ¨ì„±ì„ ë³´ì´ê¸° ìœ„í•´ ì ˆì œ ì—°êµ¬(ablation studies)ë¥¼ ìˆ˜í–‰í•˜ì˜€ë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ìŒì„± ê¸°ì´ˆ ëª¨ë¸ì´ ìµœê·¼ ìŒì„± ë§¥ë½ í•™ìŠµ(SICL)ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ë³´ì—¬ì£¼ì—ˆìœ¼ë‚˜, íš¨ê³¼ì ì¸ ë§¥ë½ ì˜ˆì‹œ ì„ íƒ ë°©ë²•ì€ ì¶©ë¶„íˆ íƒêµ¬ë˜ì§€ ì•Šì•˜ë‹¤ëŠ” ì ì„ ì§€ì í•©ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ì €ìë“¤ì€ Text-Embedding KNN for SICL (TICL)ì´ë¼ëŠ” ê°„ë‹¨í•œ íŒŒì´í”„ë¼ì¸ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ëŒ€í˜• ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì˜ ìŒì„± ì¸ì‹ ëŠ¥ë ¥ì„ ê°•í™”í•˜ë©°, ë³„ë„ì˜ íŒŒì¸íŠœë‹ ì—†ì´ë„ ë‹¤ì–‘í•œ ìë™ ìŒì„± ì¸ì‹ ê³¼ì œì—ì„œ ìµœëŒ€ 84.7%ì˜ ìƒëŒ€ì  WER ê°ì†Œë¥¼ ë‹¬ì„±í•©ë‹ˆë‹¤. ë˜í•œ, ì €ìë“¤ì€ ì´ ë°©ë²•ì˜ ê²¬ê³ ì„±ê³¼ íš¨ìœ¨ì„±ì„ ì…ì¦í•˜ê¸° ìœ„í•´ ì†Œê±° ì—°êµ¬ë¥¼ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ìµœê·¼ ìŒì„± ê¸°ë°˜ ëª¨ë¸ë“¤ì€ ìŒì„± ë‚´ ë§¥ë½ í•™ìŠµ(SICL)ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤.

- 2. íš¨ê³¼ì ì¸ ë§¥ë½ ë‚´ ì˜ˆì‹œ ì„ íƒì´ SICL ì„±ëŠ¥ì— ì¤‘ìš”í•˜ì§€ë§Œ, ì´ì— ëŒ€í•œ ì—°êµ¬ëŠ” ì•„ì§ ë¶€ì¡±í•œ ìƒíƒœì…ë‹ˆë‹¤.

- 3. ë³¸ ì—°êµ¬ì—ì„œëŠ” í…ìŠ¤íŠ¸ ì„ë² ë”© KNNì„ í™œìš©í•œ SICL(TICL) ë°©ë²•ì„ ì œì•ˆí•˜ì—¬, ëŒ€í˜• ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì˜ ìŒì„± ì¸ì‹ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

- 4. ì œì•ˆëœ ë°©ë²•ì€ ì•…ì„¼íŠ¸ê°€ ìˆëŠ” ì˜ì–´, ë‹¤êµ­ì–´ ìŒì„±, ì•„ë™ ìŒì„± ë“± ë‹¤ì–‘í•œ ìë™ ìŒì„± ì¸ì‹ ê³¼ì œì—ì„œ ìµœëŒ€ 84.7%ì˜ ìƒëŒ€ì  WER ê°ì†Œë¥¼ ë‹¬ì„±í•©ë‹ˆë‹¤.

- 5. ì†Œê±° ì—°êµ¬ë¥¼ í†µí•´ ì œì•ˆëœ ë°©ë²•ì˜ ê²¬ê³ ì„±ê³¼ íš¨ìœ¨ì„±ì„ ì…ì¦í•˜ì˜€ìŠµë‹ˆë‹¤.

---

*Generated on 2025-09-19 10:34:58*