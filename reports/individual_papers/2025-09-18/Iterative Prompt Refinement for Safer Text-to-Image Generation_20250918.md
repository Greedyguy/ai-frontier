---
keywords:
  - Large Language Models
  - Multi-Modal Learning
  - Generative Models
category: cs.AI
publish_date: 2025-09-18
arxiv_id: 2509.13760
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 22:24:35.981156",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Models",
    "Multi-Modal Learning",
    "Generative Models"
  ],
  "rejected_keywords": [
    "Computer Vision"
  ],
  "similarity_scores": {
    "Large Language Models": 0.85,
    "Multi-Modal Learning": 0.82,
    "Generative Models": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->


# Iterative Prompt Refinement for Safer Text-to-Image Generation

**Korean Title:** ë³´ë‹¤ ì•ˆì „í•œ í…ìŠ¤íŠ¸ì—ì„œ ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•œ ë°˜ë³µì ì¸ í”„ë¡¬í”„íŠ¸ ì„¸ë¶„í™”

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[digests/daily_digest_20250918|2025-09-18]]   [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Large Language Models|Large Language Models]], [[keywords/Multi-Modal Learning|Vision Language Models]], [[keywords/Generative Models|Text-to-Image models]]

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[Visible Yet Unreadable: A Systematic Blind Spot of Vision Language Models Across Writing Systems]] (82.0% similar)
- [[Identity-Preserving_Text-to-Video_Generation_Guided_by_Simple_yet_Effective_Spatial-Temporal_Decoupled_Representations_20250918|Identity-Preserving Text-to-Video Generation Guided by Simple yet Effective Spatial-Temporal Decoupled Representations]] (81.9% similar)
- [[LLM-I_LLMs_are_Naturally_Interleaved_Multimodal_Creators_20250918|LLM-I: LLMs are Naturally Interleaved Multimodal Creators]] (81.4% similar)
- [[An Empirical Analysis of VLM-based OOD Detection: Mechanisms, Advantages, and Sensitivity]] (81.1% similar)
- [[Understanding and Mitigating Overrefusal in LLMs from an Unveiling Perspective of Safety Decision Boundary]] (81.0% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.13760v1 Announce Type: new 
Abstract: Text-to-Image (T2I) models have made remarkable progress in generating images from text prompts, but their output quality and safety still depend heavily on how prompts are phrased. Existing safety methods typically refine prompts using large language models (LLMs), but they overlook the images produced, which can result in unsafe outputs or unnecessary changes to already safe prompts. To address this, we propose an iterative prompt refinement algorithm that uses Vision Language Models (VLMs) to analyze both the input prompts and the generated images. By leveraging visual feedback, our method refines prompts more effectively, improving safety while maintaining user intent and reliability comparable to existing LLM-based approaches. Additionally, we introduce a new dataset labeled with both textual and visual safety signals using off-the-shelf multi-modal LLM, enabling supervised fine-tuning. Experimental results demonstrate that our approach produces safer outputs without compromising alignment with user intent, offering a practical solution for generating safer T2I content. Our code is available at https://github.com/ku-dmlab/IPR. \textbf{\textcolor{red}WARNING: This paper contains examples of harmful or inappropriate images generated by models.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.13760v1 ë°œí‘œ ìœ í˜•: ìƒˆë¡œìš´
ìš”ì•½: í…ìŠ¤íŠ¸ì—ì„œ ì´ë¯¸ì§€ë¡œ (T2I) ëª¨ë¸ì€ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¡œë¶€í„° ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ë° ë†€ë¼ìš´ ì§„ì „ì„ ì´ë£¨ì—ˆì§€ë§Œ, ê·¸ë“¤ì˜ ì¶œë ¥ í’ˆì§ˆê³¼ ì•ˆì „ì„±ì€ ì—¬ì „íˆ í”„ë¡¬í”„íŠ¸ê°€ ì–´ë–»ê²Œ êµ¬ì„±ë˜ì—ˆëŠ”ì§€ì— í¬ê²Œ ì˜ì¡´í•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ì•ˆì „ ë°©ë²•ì€ ì¼ë°˜ì ìœ¼ë¡œ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ (LLM)ì„ ì‚¬ìš©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ë¥¼ ê°œì„ í•˜ì§€ë§Œ, ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ ê°„ê³¼í•˜ì—¬ ì•ˆì „í•˜ì§€ ì•Šì€ ì¶œë ¥ë¬¼ì´ë‚˜ ì´ë¯¸ ì•ˆì „í•œ í”„ë¡¬í”„íŠ¸ì— ë¶ˆí•„ìš”í•œ ë³€ê²½ì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” Vision Language Models (VLMs)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì…ë ¥ í”„ë¡¬í”„íŠ¸ì™€ ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ëŠ” ë°˜ë³µì ì¸ í”„ë¡¬í”„íŠ¸ ê°œì„  ì•Œê³ ë¦¬ì¦˜ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì‹œê°ì  í”¼ë“œë°±ì„ í™œìš©í•¨ìœ¼ë¡œì¨, ìš°ë¦¬ì˜ ë°©ë²•ì€ í”„ë¡¬í”„íŠ¸ë¥¼ ë” íš¨ê³¼ì ìœ¼ë¡œ ê°œì„ í•˜ì—¬ ì•ˆì „ì„±ì„ í–¥ìƒì‹œí‚¤ë©´ì„œ ê¸°ì¡´ì˜ LLM ê¸°ë°˜ ì ‘ê·¼ ë°©ì‹ê³¼ ë¹„êµ ê°€ëŠ¥í•œ ì‚¬ìš©ì ì˜ë„ì™€ ì‹ ë¢°ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤. ë˜í•œ, ìš°ë¦¬ëŠ” ì˜¤í”„-ë”-ì…€í”„ ë©€í‹°ëª¨ë‹¬ LLMì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ë° ì‹œê°ì  ì•ˆì „ ì‹ í˜¸ë¡œ ë ˆì´ë¸”ì´ ì§€ì •ëœ ìƒˆë¡œìš´ ë°ì´í„°ì…‹ì„ ì†Œê°œí•˜ì—¬ ì§€ë„ëœ ë¯¸ì„¸ ì¡°ì •ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼ëŠ” ìš°ë¦¬ì˜ ì ‘ê·¼ ë°©ì‹ì´ ì‚¬ìš©ì ì˜ë„ì™€ ì¼ì¹˜ë¥¼ ì €í•´í•˜ì§€ ì•Šìœ¼ë©´ì„œ ë” ì•ˆì „í•œ ì¶œë ¥ë¬¼ì„ ìƒì„±í•œë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì£¼ë©°, ë³´ë‹¤ ì•ˆì „í•œ T2I ì½˜í…ì¸ ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•œ ì‹¤ìš©ì ì¸ ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì½”ë“œëŠ” https://github.com/ku-dmlab/IPRì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \textbf{\textcolor{red}ê²½ê³ : ë³¸ ë…¼ë¬¸ì—ëŠ” ëª¨ë¸ì— ì˜í•´ ìƒì„±ëœ í•´ë¡œìš´ ë˜ëŠ” ë¶€ì ì ˆí•œ ì´ë¯¸ì§€ì˜ ì˜ˆì‹œê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” í…ìŠ¤íŠ¸ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ëŠ” ëª¨ë¸ì˜ ì•ˆì „ì„±ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ìƒˆë¡œìš´ ë°©ë²•ì„ ì œì•ˆí•œë‹¤. ê¸°ì¡´ ì•ˆì „ ë°©ë²•ì€ ëŒ€ë¶€ë¶„ í° ì–¸ì–´ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì•ˆì „ì„±ì„ ê°œì„ í•˜ì§€ë§Œ, ì´ë¯¸ì§€ ìƒì„±ë¬¼ì„ ê°„ê³¼í•œë‹¤. ì´ì— ìš°ë¦¬ëŠ” ì‹œê° ì–¸ì–´ ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ì…ë ¥ í…ìŠ¤íŠ¸ì™€ ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ëŠ” ë°˜ë³µì ì¸ í”„ë¡¬í”„íŠ¸ ê°œì„  ì•Œê³ ë¦¬ì¦˜ì„ ì œì•ˆí•œë‹¤. ì‹¤í—˜ ê²°ê³¼ëŠ” ì‚¬ìš©ì ì˜ë„ì™€ ì¼ì¹˜í•˜ë©´ì„œë„ ì•ˆì „í•œ ì¶œë ¥ë¬¼ì„ ìƒì„±í•˜ëŠ” ìš°ë¦¬ì˜ ë°©ë²•ì´ ê¸°ì¡´ ë°©ë²•ê³¼ ë¹„êµí•´ ì•ˆì „ì„±ì„ í–¥ìƒì‹œí‚¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤€ë‹¤. ì´ëŠ” ì•ˆì „í•œ T2I ì½˜í…ì¸  ìƒì„±ì„ ìœ„í•œ ì‹¤ìš©ì ì¸ í•´ê²°ì±…ì„ ì œê³µí•œë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Text-to-Image ëª¨ë¸ì˜ ì•ˆì „ì„± ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì‹œê° ì–¸ì–´ ëª¨ë¸ì„ í™œìš©í•œ ë°˜ë³µì  í”„ë¡¬í”„íŠ¸ ì •ì œ ì•Œê³ ë¦¬ì¦˜ ì œì•ˆ

- 2. ì´ë¯¸ì§€ ìƒì„±ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ê°œì„ í•˜ì—¬ ì•ˆì „ì„± í–¥ìƒ ë° ì‚¬ìš©ì ì˜ë„ ìœ ì§€

- 3. í…ìŠ¤íŠ¸ ë° ì‹œê°ì  ì•ˆì „ ì‹ í˜¸ë¥¼ í™œìš©í•œ ìƒˆë¡œìš´ ë°ì´í„°ì…‹ ë„ì…ìœ¼ë¡œ ì•ˆì „í•œ T2I ì½˜í…ì¸  ìƒì„± ê°€ëŠ¥ì„± ì…ì¦.

---

*Generated on 2025-09-18 17:00:23*