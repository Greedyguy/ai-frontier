# Back to Ear: Perceptually Driven High Fidelity Music Reconstruction

**Korean Title:** ê·€ë¡œ ëŒì•„ê°€ê¸°: ì§€ê°ì ìœ¼ë¡œ êµ¬ë™ë˜ëŠ” ê³ ì¶©ì‹¤ë„ ìŒì•… ì¬êµ¬ì„±

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-18|2025-09-18]] [[authors/Kangdi Wang|Kangdi Wang]] [[authors/Zhiyue Wu|Zhiyue Wu]] [[authors/Dinghao Zhou|Dinghao Zhou]] [[authors/Rui Lin|Rui Lin]] [[authors/Junyu Dai|Junyu Dai]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Perceptual Filter

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[Teacher-Guided Pseudo Supervision and Cross-Modal Alignment for Audio-Visual Video Parsing_20250918|Teacher-Guided Pseudo Supervision and Cross-Modal Alignment for Audio-Visual Video Parsing]] (78.5% similar)
- [[Mitigating data replication in text-to-audio generative diffusion models through anti-memorization guidance_20250919|Mitigating data replication in text-to-audio generative diffusion models through anti-memorization guidance]] (77.7% similar)
- [[Explicit Context-Driven Neural Acoustic Modeling for High-Fidelity RIR Generation_20250919|Explicit Context-Driven Neural Acoustic Modeling for High-Fidelity RIR Generation]] (77.7% similar)
- [[Diffusion-Based Unsupervised Audio-Visual Speech Separation in Noisy Environments with Noise Prior_20250919|Diffusion-Based Unsupervised Audio-Visual Speech Separation in Noisy Environments with Noise Prior]] (77.5% similar)
- [[Listening, Imagining & Refining_ A Heuristic Optimized ASR Correction Framework with LLMs_20250919|Listening, Imagining & Refining A Heuristic Optimized ASR Correction Framework with LLMs]] (77.1% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** Kangdi Wang, Zhiyue Wu, Dinghao Zhou, Rui Lin, Junyu Dai, Tao Jiang

## ğŸ“„ Abstract (ì›ë¬¸)

Variational Autoencoders (VAEs) are essential for large-scale audio tasks
like diffusion-based generation. However, existing open-source models often
neglect auditory perceptual aspects during training, leading to weaknesses in
phase accuracy and stereophonic spatial representation. To address these
challenges, we propose {\epsilon}ar-VAE, an open-source music signal
reconstruction model that rethinks and optimizes the VAE training paradigm. Our
contributions are threefold: (i) A K-weighting perceptual filter applied prior
to loss calculation to align the objective with auditory perception. (ii) Two
novel phase losses: a Correlation Loss for stereo coherence, and a Phase Loss
using its derivatives--Instantaneous Frequency and Group Delay--for precision.
(iii) A new spectral supervision paradigm where magnitude is supervised by all
four Mid/Side/Left/Right components, while phase is supervised only by the LR
components. Experiments show {\epsilon}ar-VAE at 44.1kHz substantially
outperforms leading open-source models across diverse metrics, showing
particular strength in reconstructing high-frequency harmonics and the spatial
characteristics.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

ë³€ë¶„ ì˜¤í† ì¸ì½”ë”(VAEs)ëŠ” í™•ì‚° ê¸°ë°˜ ìƒì„±ê³¼ ê°™ì€ ëŒ€ê·œëª¨ ì˜¤ë””ì˜¤ ì‘ì—…ì— í•„ìˆ˜ì ì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê¸°ì¡´ì˜ ì˜¤í”ˆ ì†ŒìŠ¤ ëª¨ë¸ë“¤ì€ í›ˆë ¨ ê³¼ì •ì—ì„œ ì²­ê°ì  ì§€ê° ì¸¡ë©´ì„ ì¢…ì¢… ê°„ê³¼í•˜ì—¬ ìœ„ìƒ ì •í™•ì„±ê³¼ ì…ì²´ ìŒí–¥ ê³µê°„ í‘œí˜„ì—ì„œ ì•½ì ì„ ë“œëŸ¬ëƒ…ë‹ˆë‹¤. ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” VAE í›ˆë ¨ íŒ¨ëŸ¬ë‹¤ì„ì„ ì¬ê³ í•˜ê³  ìµœì í™”í•œ ì˜¤í”ˆ ì†ŒìŠ¤ ìŒì•… ì‹ í˜¸ ì¬êµ¬ì„± ëª¨ë¸ì¸ {\epsilon}ar-VAEë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ê¸°ì—¬ëŠ” ì„¸ ê°€ì§€ë¡œ ìš”ì•½ë©ë‹ˆë‹¤: (i) ì²­ê°ì  ì§€ê°ê³¼ ëª©í‘œë¥¼ ì¼ì¹˜ì‹œí‚¤ê¸° ìœ„í•´ ì†ì‹¤ ê³„ì‚° ì „ì— K-ê°€ì¤‘ ì§€ê° í•„í„°ë¥¼ ì ìš©í•©ë‹ˆë‹¤. (ii) ë‘ ê°€ì§€ ìƒˆë¡œìš´ ìœ„ìƒ ì†ì‹¤: ìŠ¤í…Œë ˆì˜¤ ì¼ê´€ì„±ì„ ìœ„í•œ ìƒê´€ ì†ì‹¤ê³¼ ì •ë°€ì„±ì„ ìœ„í•œ ìˆœê°„ ì£¼íŒŒìˆ˜ ë° êµ° ì§€ì—°ì„ ì‚¬ìš©í•˜ëŠ” ìœ„ìƒ ì†ì‹¤ì…ë‹ˆë‹¤. (iii) í¬ê¸°ëŠ” ëª¨ë“  Mid/Side/Left/Right êµ¬ì„± ìš”ì†Œì— ì˜í•´ ê°ë…ë˜ê³ , ìœ„ìƒì€ LR êµ¬ì„± ìš”ì†Œì— ì˜í•´ì„œë§Œ ê°ë…ë˜ëŠ” ìƒˆë¡œìš´ ìŠ¤í™íŠ¸ëŸ¼ ê°ë… íŒ¨ëŸ¬ë‹¤ì„ì…ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, 44.1kHzì—ì„œ {\epsilon}ar-VAEëŠ” ë‹¤ì–‘í•œ ì§€í‘œì—ì„œ ì„ ë„ì ì¸ ì˜¤í”ˆ ì†ŒìŠ¤ ëª¨ë¸ë“¤ì„ í¬ê²Œ ëŠ¥ê°€í•˜ë©°, íŠ¹íˆ ê³ ì£¼íŒŒ í•˜ëª¨ë‹‰ìŠ¤ì™€ ê³µê°„ì  íŠ¹ì„±ì„ ì¬êµ¬ì„±í•˜ëŠ” ë° ê°•ì ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

Variational Autoencoders(VAEs)ëŠ” ëŒ€ê·œëª¨ ì˜¤ë””ì˜¤ ì‘ì—…ì— í•„ìˆ˜ì ì´ì§€ë§Œ, ê¸°ì¡´ ëª¨ë¸ë“¤ì€ ì²­ê°ì  ì¸ì‹ì„ ê°„ê³¼í•˜ì—¬ ìœ„ìƒ ì •í™•ì„±ê³¼ ì…ì²´ì  ê³µê°„ í‘œí˜„ì— ì•½ì ì„ ë³´ì…ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ {\epsilon}ar-VAEë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì£¼ìš” ê¸°ì—¬ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤: (i) ì²­ê° ì¸ì‹ê³¼ ì¼ì¹˜ì‹œí‚¤ê¸° ìœ„í•œ K-ê°€ì¤‘ì¹˜ ì§€ê° í•„í„° ì ìš©, (ii) ìŠ¤í…Œë ˆì˜¤ ì¼ê´€ì„±ì„ ìœ„í•œ ìƒê´€ ì†ì‹¤ê³¼ ì •ë°€ì„±ì„ ìœ„í•œ ìœ„ìƒ ì†ì‹¤ ë„ì…, (iii) ìƒˆë¡œìš´ ìŠ¤í™íŠ¸ëŸ¼ ê°ë… íŒ¨ëŸ¬ë‹¤ì„ìœ¼ë¡œ, ì‹¤í—˜ ê²°ê³¼ {\epsilon}ar-VAEëŠ” ê³ ì£¼íŒŒ í•˜ëª¨ë‹‰ìŠ¤ì™€ ê³µê°„ì  íŠ¹ì„± ì¬êµ¬ì„±ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ê¸°ì¡´ ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ì²­ê°ì  ì§€ê°ì„ ê³ ë ¤í•œ K-weighting ì§€ê° í•„í„°ë¥¼ ì†ì‹¤ ê³„ì‚° ì „ì— ì ìš©í•©ë‹ˆë‹¤.

- 2. ìŠ¤í…Œë ˆì˜¤ ì¼ê´€ì„±ì„ ìœ„í•œ ìƒê´€ ì†ì‹¤ê³¼ ì •ë°€ì„±ì„ ìœ„í•œ ìˆœê°„ ì£¼íŒŒìˆ˜ ë° êµ° ì§€ì—°ì„ í™œìš©í•œ ìƒˆë¡œìš´ ìœ„ìƒ ì†ì‹¤ì„ ì œì•ˆí•©ë‹ˆë‹¤.

- 3. ìƒˆë¡œìš´ ìŠ¤í™íŠ¸ëŸ¼ ê°ë… íŒ¨ëŸ¬ë‹¤ì„ì„ ë„ì…í•˜ì—¬, í¬ê¸°ëŠ” Mid/Side/Left/Right ëª¨ë“  êµ¬ì„± ìš”ì†Œë¡œ ê°ë…í•˜ê³ , ìœ„ìƒì€ LR êµ¬ì„± ìš”ì†Œë¡œë§Œ ê°ë…í•©ë‹ˆë‹¤.

- 4. ì‹¤í—˜ ê²°ê³¼, {\epsilon}ar-VAEëŠ” 44.1kHzì—ì„œ ë‹¤ì–‘í•œ ì§€í‘œì—ì„œ ê¸°ì¡´ ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ì„ ëŠ¥ê°€í•˜ë©°, íŠ¹íˆ ê³ ì£¼íŒŒ í•˜ëª¨ë‹‰ ë° ê³µê°„ì  íŠ¹ì„± ì¬êµ¬ì„±ì—ì„œ ê°•ì ì„ ë³´ì…ë‹ˆë‹¤.

---

*Generated on 2025-09-20 02:44:12*