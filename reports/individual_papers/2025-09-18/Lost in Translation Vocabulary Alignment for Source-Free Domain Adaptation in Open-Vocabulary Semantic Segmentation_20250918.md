---
keywords:
  - Open-Vocabulary Semantic Segmentation
  - Vocabulary Alignment
  - Vision Transformers
category: cs.AI
publish_date: 2025-09-18
arxiv_id:
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 22:21:14.036664",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Open-Vocabulary Semantic Segmentation",
    "Vocabulary Alignment",
    "Vision Transformers"
  ],
  "rejected_keywords": [
    "Source-Free Domain Adaptation",
    "Low-Rank Adaptation"
  ],
  "similarity_scores": {
    "Open-Vocabulary Semantic Segmentation": 0.82,
    "Vocabulary Alignment": 0.85,
    "Vision Transformers": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->

# Lost in Translation? Vocabulary Alignment for Source-Free Domain Adaptation in Open-Vocabulary Semantic Segmentation

**Korean Title:** ë²ˆì—­ì—ì„œ ê¸¸ì„ ìƒë‹¤? ê°œë°©í˜• ì–´íœ˜ ì˜ë¯¸ ë¶„í• ì—ì„œ ì†ŒìŠ¤ ì—†ëŠ” ë„ë©”ì¸ ì ì‘ì„ ìœ„í•œ ì–´íœ˜ ì •ë ¬

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[digests/daily_digest_20250918|2025-09-18]]        [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Vision Transformers|Vision Transformers]]
**âš¡ Unique Technical**: [[keywords/Open-Vocabulary Semantic Segmentation|Open-Vocabulary Semantic Segmentation]], [[keywords/Vocabulary Alignment|Vocabulary Alignment]]

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[GeoAware-VLA_ Implicit Geometry Aware Vision-Language-Action Model_20250918|GeoAware-VLA Implicit Geometry Aware Vision-Language-Action Model]] (82.3% similar)
- [[ForceVLA_ Enhancing VLA Models with a Force-aware MoE for Contact-rich Manipulation_20250919|ForceVLA Enhancing VLA Models with a Force-aware MoE for Contact-rich Manipulation]] (80.9% similar)
- [[Middo_ Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning_20250919|Middo Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning]] (80.7% similar)
- [[V-SEAM_ Visual Semantic Editing and Attention Modulating for Causal Interpretability of Vision-Language Models_20250919|V-SEAM Visual Semantic Editing and Attention Modulating for Causal Interpretability of Vision-Language Models]] (80.6% similar)
- [[UnifiedVisual_ A Framework for Constructing Unified Vision-Language Datasets_20250919|UnifiedVisual A Framework for Constructing Unified Vision-Language Datasets]] (80.4% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** Silvio Mazzucco, Carl Persson, Mattia Segu, Pier Luigi Dovesi, Federico Tombari, Luc Van Gool, Matteo Poggi

## ğŸ“„ Abstract (ì›ë¬¸)

We introduce VocAlign, a novel source-free domain adaptation framework
specifically designed for VLMs in open-vocabulary semantic segmentation. Our
method adopts a student-teacher paradigm enhanced with a vocabulary alignment
strategy, which improves pseudo-label generation by incorporating additional
class concepts. To ensure efficiency, we use Low-Rank Adaptation (LoRA) to
fine-tune the model, preserving its original capabilities while minimizing
computational overhead. In addition, we propose a Top-K class selection
mechanism for the student model, which significantly reduces memory
requirements while further improving adaptation performance. Our approach
achieves a notable 6.11 mIoU improvement on the CityScapes dataset and
demonstrates superior performance on zero-shot segmentation benchmarks, setting
a new standard for source-free adaptation in the open-vocabulary setting.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

ìš°ë¦¬ëŠ” ê°œë°©í˜• ì–´íœ˜ ì˜ë¯¸ ë¶„í• ì—ì„œ VLMsì— íŠ¹í™”ëœ ìƒˆë¡œìš´ ì†ŒìŠ¤ í”„ë¦¬ ë„ë©”ì¸ ì ì‘ í”„ë ˆì„ì›Œí¬ì¸ VocAlignì„ ì†Œê°œí•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ë°©ë²•ì€ ì¶”ê°€ì ì¸ í´ë˜ìŠ¤ ê°œë…ì„ í†µí•©í•˜ì—¬ ì˜ì‚¬ ë ˆì´ë¸” ìƒì„±ì„ ê°œì„ í•˜ëŠ” ì–´íœ˜ ì •ë ¬ ì „ëµì´ ê°•í™”ëœ í•™ìƒ-êµì‚¬ íŒ¨ëŸ¬ë‹¤ì„ì„ ì±„íƒí•©ë‹ˆë‹¤. íš¨ìœ¨ì„±ì„ ë³´ì¥í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ëª¨ë¸ì˜ ì›ë˜ ê¸°ëŠ¥ì„ ìœ ì§€í•˜ë©´ì„œ ê³„ì‚° ì˜¤ë²„í—¤ë“œë¥¼ ìµœì†Œí™”í•˜ê¸° ìœ„í•´ ì €ë­í¬ ì ì‘(LoRA)ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•©ë‹ˆë‹¤. ë˜í•œ, ìš°ë¦¬ëŠ” í•™ìƒ ëª¨ë¸ì„ ìœ„í•œ Top-K í´ë˜ìŠ¤ ì„ íƒ ë©”ì»¤ë‹ˆì¦˜ì„ ì œì•ˆí•˜ì—¬ ë©”ëª¨ë¦¬ ìš”êµ¬ ì‚¬í•­ì„ í¬ê²Œ ì¤„ì´ë©´ì„œ ì ì‘ ì„±ëŠ¥ì„ ë”ìš± í–¥ìƒì‹œí‚µë‹ˆë‹¤. ìš°ë¦¬ì˜ ì ‘ê·¼ ë°©ì‹ì€ CityScapes ë°ì´í„°ì…‹ì—ì„œ 6.11 mIoUì˜ ì£¼ëª©í•  ë§Œí•œ í–¥ìƒì„ ë‹¬ì„±í–ˆìœ¼ë©°, ì œë¡œìƒ· ë¶„í•  ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ë©°, ê°œë°©í˜• ì–´íœ˜ ì„¤ì •ì—ì„œ ì†ŒìŠ¤ í”„ë¦¬ ì ì‘ì˜ ìƒˆë¡œìš´ í‘œì¤€ì„ ì„¤ì •í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

VocAlignì€ VLMsì˜ ì˜¤í”ˆ ë³´ìºë·¸ëŸ¬ë¦¬ ì˜ë¯¸ë¡ ì  ë¶„í• ì„ ìœ„í•œ ìƒˆë¡œìš´ ì†ŒìŠ¤ í”„ë¦¬ ë„ë©”ì¸ ì ì‘ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. í•™ìƒ-êµì‚¬ íŒ¨ëŸ¬ë‹¤ì„ê³¼ ì–´íœ˜ ì •ë ¬ ì „ëµì„ ì±„íƒí•˜ì—¬ ì¶”ê°€ í´ë˜ìŠ¤ ê°œë…ì„ í†µí•©í•¨ìœ¼ë¡œì¨ ì˜ì‚¬ ë ˆì´ë¸” ìƒì„±ì„ ê°œì„ í•©ë‹ˆë‹¤. LoRAë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ì—¬ ì›ë˜ì˜ ê¸°ëŠ¥ì„ ìœ ì§€í•˜ë©´ì„œ ê³„ì‚° ë¶€ë‹´ì„ ìµœì†Œí™”í•©ë‹ˆë‹¤. ë˜í•œ, í•™ìƒ ëª¨ë¸ì— ëŒ€í•œ Top-K í´ë˜ìŠ¤ ì„ íƒ ë©”ì»¤ë‹ˆì¦˜ì„ ì œì•ˆí•˜ì—¬ ë©”ëª¨ë¦¬ ìš”êµ¬ ì‚¬í•­ì„ ì¤„ì´ë©´ì„œ ì ì‘ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì´ ì ‘ê·¼ë²•ì€ CityScapes ë°ì´í„°ì…‹ì—ì„œ 6.11 mIoU í–¥ìƒì„ ì´ë£¨ì—ˆê³ , ì œë¡œìƒ· ë¶„í•  ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì—¬ ì†ŒìŠ¤ í”„ë¦¬ ì ì‘ì˜ ìƒˆë¡œìš´ ê¸°ì¤€ì„ ì„¸ì› ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. VocAlignì€ ê°œë°©í˜• ì–´íœ˜ ì˜ë¯¸ ë¶„í• ì„ ìœ„í•œ VLMì— íŠ¹í™”ëœ ì†ŒìŠ¤ ì—†ëŠ” ë„ë©”ì¸ ì ì‘ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.

- 2. í•™ìƒ-êµì‚¬ íŒ¨ëŸ¬ë‹¤ì„ê³¼ ì–´íœ˜ ì •ë ¬ ì „ëµì„ ì±„íƒí•˜ì—¬ ì¶”ê°€ í´ë˜ìŠ¤ ê°œë…ì„ í¬í•¨í•œ ê°€ì§œ ë ˆì´ë¸” ìƒì„±ì„ ê°œì„ í•©ë‹ˆë‹¤.

- 3. Low-Rank Adaptation(LoRA)ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•¨ìœ¼ë¡œì¨ ì›ë˜ì˜ ê¸°ëŠ¥ì„ ìœ ì§€í•˜ë©´ì„œ ê³„ì‚° ì˜¤ë²„í—¤ë“œë¥¼ ìµœì†Œí™”í•©ë‹ˆë‹¤.

- 4. í•™ìƒ ëª¨ë¸ì„ ìœ„í•œ Top-K í´ë˜ìŠ¤ ì„ íƒ ë©”ì»¤ë‹ˆì¦˜ì„ ì œì•ˆí•˜ì—¬ ë©”ëª¨ë¦¬ ìš”êµ¬ ì‚¬í•­ì„ í¬ê²Œ ì¤„ì´ê³  ì ì‘ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

- 5. CityScapes ë°ì´í„°ì…‹ì—ì„œ 6.11 mIoU í–¥ìƒì„ ë‹¬ì„±í•˜ê³ , ì œë¡œìƒ· ë¶„í•  ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

---

*Generated on 2025-09-20 00:45:28*