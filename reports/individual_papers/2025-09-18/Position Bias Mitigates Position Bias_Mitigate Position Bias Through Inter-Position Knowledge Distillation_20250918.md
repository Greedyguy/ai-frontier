---
keywords:
  - Knowledge Distillation
  - Positional Bias
  - Transformer Architecture
category: cs.AI
publish_date: 2025-09-18
arxiv_id: 2508.15709
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-22 22:15:55.694934",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Knowledge Distillation",
    "Positional Bias",
    "Transformer Architecture"
  ],
  "rejected_keywords": [
    "Long-Context Retrieval",
    "Reasoning Paradigms"
  ],
  "similarity_scores": {
    "Knowledge Distillation": 0.8,
    "Positional Bias": 0.78,
    "Transformer Architecture": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true
}
-->


# Position Bias Mitigates Position Bias:Mitigate Position Bias Through Inter-Position Knowledge Distillation

**Korean Title:** ìœ„ì¹˜ í¸í–¥ì´ ìœ„ì¹˜ í¸í–¥ì„ ì™„í™”ì‹œí‚µë‹ˆë‹¤: ìƒí˜¸ ìœ„ì¹˜ ì§€ì‹ ì¦ë¥˜ë¥¼ í†µí•´ ìœ„ì¹˜ í¸í–¥ ì™„í™”í•˜ê¸°

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[digests/daily_digest_20250918|2025-09-18]]   [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Knowledge Distillation|Knowledge Distillation]], [[keywords/Transformer Architecture|Transformer Architecture]]
**âš¡ Unique Technical**: [[keywords/Positional Bias|Positional Bias]]

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[Controllable Pareto Trade-off between Fairness and Accuracy]] (78.5% similar)
- [[Data-Driven_Distributed_Optimization_via_Aggregative_Tracking_and_Deep-Learning_20250918|Data-Driven Distributed Optimization via Aggregative Tracking and Deep-Learning]] (76.8% similar)
- [[PRISM-DP_Spatial_Pose-based_Observations_for_Diffusion-Policies_via_Segmentation,_Mesh_Generation,_and_Pose_Tracking_20250918|PRISM-DP: Spatial Pose-based Observations for Diffusion-Policies via Segmentation, Mesh Generation, and Pose Tracking]] (76.6% similar)
- [[SpecDiff: Accelerating Diffusion Model Inference with Self-Speculation]] (76.3% similar)
- [[Mitigating Query Selection Bias in Referring Video Object Segmentation]] (76.2% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2508.15709v2 Announce Type: replace 
Abstract: Positional bias (PB), manifesting as non-uniform sensitivity across different contextual locations, significantly impairs long-context comprehension and processing capabilities. Previous studies have addressed PB either by modifying the underlying architectures or by employing extensive contextual awareness training. However, the former approach fails to effectively eliminate the substantial performance disparities, while the latter imposes significant data and computational overhead. To address PB effectively, we introduce \textbf{Pos2Distill}, a position to position knowledge distillation framework. Pos2Distill transfers the superior capabilities from advantageous positions to less favorable ones, thereby reducing the huge performance gaps. The conceptual principle is to leverage the inherent, position-induced disparity to counteract the PB itself. We identify distinct manifestations of PB under \textbf{\textsc{r}}etrieval and \textbf{\textsc{r}}easoning paradigms, thereby designing two specialized instantiations: \emph{Pos2Distill-R\textsuperscript{1}} and \emph{Pos2Distill-R\textsuperscript{2}} respectively, both grounded in this core principle. By employing the Pos2Distill approach, we achieve enhanced uniformity and significant performance gains across all contextual positions in long-context retrieval and reasoning tasks. Crucially, both specialized systems exhibit strong cross-task generalization mutually, while achieving superior performance on their respective tasks.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2508.15709v2 ë°œí‘œ ìœ í˜•: ëŒ€ì²´
ìš”ì•½: ìœ„ì¹˜ í¸í–¥(Positional bias, PB)ì€ ì„œë¡œ ë‹¤ë¥¸ ë¬¸ë§¥ì  ìœ„ì¹˜ì—ì„œ ê· ì¼í•˜ì§€ ì•Šì€ ê°ë„ë¥¼ ë‚˜íƒ€ë‚´ë©°, ì¥ë¬¸ ë§¥ë½ ì´í•´ ë° ì²˜ë¦¬ ëŠ¥ë ¥ì„ ì‹¬ê°í•˜ê²Œ ì €í•´í•©ë‹ˆë‹¤. ì´ì „ ì—°êµ¬ë“¤ì€ PBë¥¼ ê¸°ì¡´ ì•„í‚¤í…ì²˜ë¥¼ ìˆ˜ì •í•˜ê±°ë‚˜ ê´‘ë²”ìœ„í•œ ë¬¸ë§¥ ì¸ì‹ í›ˆë ¨ì„ í™œìš©í•˜ì—¬ í•´ê²°í•´ ì™”ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì „ìì˜ ë°©ë²•ì€ ìƒë‹¹í•œ ì„±ëŠ¥ ê²©ì°¨ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì œê±°í•˜ì§€ ëª»í•˜ë©°, í›„ìëŠ” ìƒë‹¹í•œ ë°ì´í„° ë° ê³„ì‚° ë¶€ë‹´ì„ ê°€í•©ë‹ˆë‹¤. PBë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í•´ê²°í•˜ê¸° ìœ„í•´ ìš°ë¦¬ëŠ” \textbf{Pos2Distill}ì´ë¼ëŠ” ìœ„ì¹˜ ê°„ ì§€ì‹ ì¦ë¥˜ í”„ë ˆì„ì›Œí¬ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. Pos2Distillì€ ìœ ë¦¬í•œ ìœ„ì¹˜ì—ì„œ ìš°ìˆ˜í•œ ëŠ¥ë ¥ì„ ë¶ˆë¦¬í•œ ìœ„ì¹˜ë¡œ ì „ë‹¬í•˜ì—¬ ì—„ì²­ë‚œ ì„±ëŠ¥ ê²©ì°¨ë¥¼ ì¤„ì…ë‹ˆë‹¤. ê°œë…ì  ì›ë¦¬ëŠ” ìœ„ì¹˜ì— ì˜í•´ ìœ ë°œëœ ì°¨ì´ë¥¼ í™œìš©í•˜ì—¬ PB ìì²´ë¥¼ ìƒì‡„í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” \textbf{\textsc{r}}ecall ë° \textbf{\textsc{r}}easoning íŒ¨ëŸ¬ë‹¤ì„ì—ì„œ PBì˜ êµ¬ë³„ëœ í‘œí˜„ì„ ì‹ë³„í•˜ê³ , ì´ í•µì‹¬ ì›ë¦¬ì— ê¸°ì´ˆí•œ ë‘ ê°€ì§€ ì „ë¬¸í™”ëœ ì‹¤ì²´í™”ì¸ \emph{Pos2Distill-R\textsuperscript{1}} ë° \emph{Pos2Distill-R\textsuperscript{2}}ë¥¼ ì„¤ê³„í•©ë‹ˆë‹¤. Pos2Distill ì ‘ê·¼ë²•ì„ ì±„íƒí•¨ìœ¼ë¡œì¨, ìš°ë¦¬ëŠ” ì¥ë¬¸ ë§¥ë½ ê²€ìƒ‰ ë° ì¶”ë¡  ì‘ì—…ì—ì„œ ëª¨ë“  ë¬¸ë§¥ì  ìœ„ì¹˜ì—ì„œ í–¥ìƒëœ ê· ì¼ì„±ê³¼ ìƒë‹¹í•œ ì„±ëŠ¥ í–¥ìƒì„ ë‹¬ì„±í•©ë‹ˆë‹¤. ì¤‘ìš”í•œ ì ì€, ë‘ ì „ë¬¸í™”ëœ ì‹œìŠ¤í…œì´ ìƒí˜¸ ê°•í•œ êµì°¨ ì‘ì—… ì¼ë°˜í™”ë¥¼ ë³´ì—¬ì£¼ë©°, ê°ê°ì˜ ì‘ì—…ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë‹¬ì„±í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ìœ„ì¹˜ í¸í–¥(Positional bias, PB)ì´ ê¸´ ë¬¸ë§¥ ì´í•´ ë° ì²˜ë¦¬ ëŠ¥ë ¥ì— ë¯¸ì¹˜ëŠ” ë¶€ì •ì  ì˜í–¥ì„ í•´ì†Œí•˜ê¸° ìœ„í•´ Pos2Distillì´ë¼ëŠ” ì§€ì‹ ì¦ë¥˜ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•œë‹¤. ì´ë¥¼ í†µí•´ ìœ ë¦¬í•œ ìœ„ì¹˜ì—ì„œ ëœ ìœ ë¦¬í•œ ìœ„ì¹˜ë¡œ ìš°ìˆ˜í•œ ëŠ¥ë ¥ì„ ì „ì´ì‹œì¼œ ì„±ëŠ¥ ê²©ì°¨ë¥¼ ì¤„ì¸ë‹¤. PBì˜ íŠ¹ì§•ì„ íŒŒì•…í•˜ì—¬ \textbf{\textsc{r}}etrieval ë° \textbf{\textsc{r}}easoning íŒ¨ëŸ¬ë‹¤ì„ì— ëŒ€í•œ ë‘ ê°€ì§€ íŠ¹í™”ëœ ì‹œìŠ¤í…œì„ ì„¤ê³„í•˜ê³  ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¨ë‹¤. Pos2Distill ì ‘ê·¼ë²•ì„ í†µí•´ ê¸´ ë¬¸ë§¥ ê²€ìƒ‰ ë° ì¶”ë¡  ì‘ì—…ì—ì„œ ëª¨ë“  ìœ„ì¹˜ì—ì„œ ê· ì¼ì„±ê³¼ ì„±ëŠ¥ í–¥ìƒì„ ë‹¬ì„±í•˜ë©°, ê°ê°ì˜ ì‘ì—…ì—ì„œ ìš°ìˆ˜í•œ ì„±ê³¼ë¥¼ ë³´ì—¬ì¤€ë‹¤. ë˜í•œ, ë‘ íŠ¹í™”ëœ ì‹œìŠ¤í…œì€ ìƒí˜¸ ê°•í•œ êµì°¨ ì‘ì—… ì¼ë°˜í™”ë¥¼ ë³´ì—¬ì¤€ë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ìœ„ì¹˜ í¸í–¥ì€ ì¥ê±°ë¦¬ ë§¥ë½ ì´í•´ ë° ì²˜ë¦¬ ëŠ¥ë ¥ì„ ì‹¬ê°í•˜ê²Œ ì €í•´ì‹œí‚¤ë©°, ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ Pos2Distillì´ë¼ëŠ” ì§€ì‹ ì¦ë¥˜ í”„ë ˆì„ì›Œí¬ë¥¼ ì†Œê°œí•¨.

- 2. Pos2Distillì€ ìœ ë¦¬í•œ ìœ„ì¹˜ì—ì„œ ìš°ì›”í•œ ëŠ¥ë ¥ì„ ë¶ˆë¦¬í•œ ìœ„ì¹˜ë¡œ ì´ì „ì‹œì¼œ ì„±ëŠ¥ ê²©ì°¨ë¥¼ ì¤„ì´ëŠ”ë° í™œìš©ë¨.

- 3. Pos2Distillì€ ì¥ê±°ë¦¬ ê²€ìƒ‰ ë° ì¶”ë¡  ì‘ì—…ì—ì„œ ëª¨ë“  ë§¥ë½ ìœ„ì¹˜ì—ì„œ ê· ì¼ì„±ì„ í–¥ìƒì‹œí‚¤ê³  ì„±ëŠ¥ í–¥ìƒì„ ì´ë£¨ì–´ëƒ„.

- 4. Pos2Distillì€ ê°ê° Pos2Distill-R^1 ë° Pos2Distill-R^2ë¡œ ì„¤ê³„ëœ ë‘ ê°€ì§€ íŠ¹í™”ëœ ì‹œìŠ¤í…œì„ í†µí•´ ìœ„ì¹˜ í¸í–¥ì„ ëŒ€ì‘í•˜ëŠ” í•µì‹¬ ì›ì¹™ì— ê¸°ë°˜í•¨.

- 5. ë‘ íŠ¹í™”ëœ ì‹œìŠ¤í…œì€ ìƒí˜¸ ê°•ë ¥í•œ êµì°¨ ì‘ì—… ì¼ë°˜í™”ë¥¼ ë³´ì—¬ì£¼ë©°, ê°ê°ì˜ ì‘ì—…ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë‹¬ì„±í•¨.

---

*Generated on 2025-09-18 16:55:48*