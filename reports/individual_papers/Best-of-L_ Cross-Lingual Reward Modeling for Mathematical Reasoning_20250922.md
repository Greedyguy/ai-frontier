# Best-of-L: Cross-Lingual Reward Modeling for Mathematical Reasoning

**Korean Title:** Best-of-L: 수학적 추론을 위한 교차 언어 보상 모델링

## 📋 메타데이터

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Multilingual Reasoning

## 🔗 유사한 논문
- [[2025-09-19/Enhancing Logical Reasoning in Language Models via Symbolically-Guided Monte Carlo Process Supervision_20250919|Enhancing Logical Reasoning in Language Models via Symbolically-Guided Monte Carlo Process Supervision]] (84.9% similar)
- [[2025-09-22/DivLogicEval_ A Framework for Benchmarking Logical Reasoning Evaluation in Large Language Models_20250922|DivLogicEval A Framework for Benchmarking Logical Reasoning Evaluation in Large Language Models]] (84.9% similar)
- [[2025-09-22/Reward Hacking Mitigation using Verifiable Composite Rewards_20250922|Reward Hacking Mitigation using Verifiable Composite Rewards]] (84.8% similar)
- [[2025-09-22/Exploring Polyglot Harmony_ On Multilingual Data Allocation for Large Language Models Pretraining_20250922|Exploring Polyglot Harmony On Multilingual Data Allocation for Large Language Models Pretraining]] (83.8% similar)
- [[2025-09-17/THOR_ Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning_20250917|THOR Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning]] (83.6% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.15811v1 Announce Type: cross 
Abstract: While the reasoning abilities of large language models (LLMs) continue to advance, it remains unclear how such ability varies across languages in multilingual LLMs and whether different languages produce reasoning paths that complement each other. To investigate this question, we train a reward model to rank generated responses for a given question across languages. Our results show that our cross-lingual reward model substantially improves mathematical reasoning performance compared to using reward modeling within a single language, benefiting even high-resource languages. While English often exhibits the highest performance in multilingual models, we find that cross-lingual sampling particularly benefits English under low sampling budgets. Our findings reveal new opportunities to improve multilingual reasoning by leveraging the complementary strengths of diverse languages.

## 🔍 Abstract (한글 번역)

arXiv:2509.15811v1 발표 유형: 교차  
초록: 대형 언어 모델(LLMs)의 추론 능력이 계속 발전하고 있지만, 다국어 LLM에서 이러한 능력이 언어에 따라 어떻게 달라지는지, 그리고 서로 다른 언어가 서로 보완하는 추론 경로를 생성하는지 여부는 여전히 불분명합니다. 이 질문을 조사하기 위해, 우리는 여러 언어에 걸쳐 주어진 질문에 대한 생성된 응답을 순위 매기는 보상 모델을 훈련합니다. 우리의 결과는 단일 언어 내에서 보상 모델링을 사용하는 것에 비해, 교차 언어 보상 모델이 수학적 추론 성능을 상당히 향상시킨다는 것을 보여주며, 이는 자원이 풍부한 언어에도 이점을 제공합니다. 영어는 종종 다국어 모델에서 가장 높은 성능을 보이지만, 우리는 낮은 샘플링 예산 하에서 교차 언어 샘플링이 특히 영어에 이점을 제공한다는 것을 발견했습니다. 우리의 발견은 다양한 언어의 상호 보완적인 강점을 활용하여 다국어 추론을 개선할 수 있는 새로운 기회를 제시합니다.

## 📝 요약

이 논문은 다국어 대형 언어 모델(LLM)의 추론 능력이 언어별로 어떻게 다른지와 각 언어가 상호 보완적인 추론 경로를 생성할 수 있는지를 연구합니다. 이를 위해, 다양한 언어로 생성된 응답을 평가하는 보상 모델을 훈련했습니다. 연구 결과, 다국어 보상 모델이 단일 언어 보상 모델에 비해 수학적 추론 성능을 크게 향상시켰으며, 자원이 풍부한 언어에도 긍정적인 영향을 미쳤습니다. 특히, 영어는 다국어 모델에서 가장 높은 성능을 보이지만, 낮은 샘플링 예산에서는 다국어 샘플링이 영어 성능을 더욱 향상시킵니다. 이 연구는 다양한 언어의 상호 보완적 강점을 활용하여 다국어 추론을 개선할 수 있는 새로운 가능성을 제시합니다.

## 🎯 주요 포인트

- 1. 대형 언어 모델(LLM)의 추론 능력은 언어에 따라 다르게 나타날 수 있으며, 서로 다른 언어가 상호 보완적인 추론 경로를 생성할 수 있는지에 대한 연구가 필요하다.

- 2. 연구 결과, 다국어 보상 모델은 단일 언어 내 보상 모델링보다 수학적 추론 성능을 크게 향상시키며, 이는 자원이 풍부한 언어에도 이점을 제공한다.

- 3. 영어는 다국어 모델에서 종종 가장 높은 성능을 보이지만, 낮은 샘플링 예산 하에서는 영어도 다국어 샘플링의 혜택을 받을 수 있다.

- 4. 다양한 언어의 상호 보완적 강점을 활용하여 다국어 추론을 개선할 수 있는 새로운 기회가 발견되었다.

---

*Generated on 2025-09-22 14:13:14*