
# An Empirical Analysis of VLM-based OOD Detection: Mechanisms, Advantages, and Sensitivity

**Korean Title:** VLM ê¸°ë°˜ OOD ê°ì§€ì˜ ê²½í—˜ì  ë¶„ì„: ë©”ì»¤ë‹ˆì¦˜, ì¥ì  ë° ë¯¼ê°ë„

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-18|2025-09-18]] [[keywords/evolved/Prompt Phrasing|Prompt Phrasing]] [[keywords/broad/Vision-Language Models|Vision-Language Models]] [[keywords/broad/Zero-shot Learning|Zero-shot Learning]] [[keywords/specific/Semantic Novelty|Semantic Novelty]] [[keywords/unique/CLIP|CLIP]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Semantic Novelty
**ğŸ”¬ Broad Technical**: Vision-Language Models, Zero-shot Out-of-Distribution Detection
**ğŸ”— Specific Connectable**: CLIP
**â­ Unique Technical**: VLM-based OOD Detection

**ArXiv ID**: [2509.13375](https://arxiv.org/abs/2509.13375)
**Published**: 2025-09-18
**Category**: cs.AI
**PDF**: [Download](https://arxiv.org/pdf/2509.13375.pdf)


## ğŸ·ï¸ ì¶”ì¶œëœ í‚¤ì›Œë“œ



`Vision-Language Models` â€¢ 

`Zero-shot Learning` â€¢ 

`Semantic Novelty` â€¢ 

`CLIP` â€¢ 

`Prompt Phrasing`



## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.13375v1 Announce Type: cross 
Abstract: Vision-Language Models (VLMs), such as CLIP, have demonstrated remarkable zero-shot out-of-distribution (OOD) detection capabilities, vital for reliable AI systems. Despite this promising capability, a comprehensive understanding of (1) why they work so effectively, (2) what advantages do they have over single-modal methods, and (3) how is their behavioral robustness -- remains notably incomplete within the research community. This paper presents a systematic empirical analysis of VLM-based OOD detection using in-distribution (ID) and OOD prompts. (1) Mechanisms: We systematically characterize and formalize key operational properties within the VLM embedding space that facilitate zero-shot OOD detection. (2) Advantages: We empirically quantify the superiority of these models over established single-modal approaches, attributing this distinct advantage to the VLM's capacity to leverage rich semantic novelty. (3) Sensitivity: We uncovers a significant and previously under-explored asymmetry in their robustness profile: while exhibiting resilience to common image noise, these VLM-based methods are highly sensitive to prompt phrasing. Our findings contribute a more structured understanding of the strengths and critical vulnerabilities inherent in VLM-based OOD detection, offering crucial, empirically-grounded guidance for developing more robust and reliable future designs.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.13375v1 ë°œí‘œ ìœ í˜•: êµì°¨
ìš”ì•½: CLIPì™€ ê°™ì€ Vision-Language ëª¨ë¸(VLMs)ì€ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” AI ì‹œìŠ¤í…œì— í•„ìˆ˜ì ì¸ í˜ì‹ ì ì¸ ì˜ìƒ-ì–¸ì–´ ëª¨ë¸ë¡œ, ì œë¡œìƒ· ì•„ì›ƒì˜¤ë¸Œë””ìŠ¤íŠ¸ë¦¬ë·°ì…˜(OOD) ê°ì§€ ëŠ¥ë ¥ì„ ë†’ì€ ìˆ˜ì¤€ìœ¼ë¡œ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ìœ ë§í•œ ëŠ¥ë ¥ì—ë„ ë¶ˆêµ¬í•˜ê³ , (1) ì™œ ì´ëŸ¬í•œ ëª¨ë¸ì´ íš¨ê³¼ì ìœ¼ë¡œ ì‘ë™í•˜ëŠ”ì§€, (2) ë‹¨ì¼ ëª¨ë‹¬ ë°©ë²•ì— ë¹„í•´ ì–´ë–¤ ì¥ì ì„ ê°€ì§€ê³  ìˆëŠ”ì§€, (3) ê·¸ë“¤ì˜ í–‰ë™ì ì¸ ê²¬ê³ ì„±ì€ ì—¬ì „íˆ ì—°êµ¬ ì»¤ë®¤ë‹ˆí‹° ë‚´ì—ì„œ ëšœë ·í•˜ê²Œ ë¯¸ì™„ì„±ëœ ìƒíƒœì…ë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì€ ID ë° OOD í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ VLM ê¸°ë°˜ OOD ê°ì§€ì˜ ì²´ê³„ì ì¸ ê²½í—˜ì  ë¶„ì„ì„ ì œì‹œí•©ë‹ˆë‹¤. (1) ë©”ì»¤ë‹ˆì¦˜: ìš°ë¦¬ëŠ” VLM ì„ë² ë”© ê³µê°„ ë‚´ì—ì„œ ì œë¡œìƒ· OOD ê°ì§€ë¥¼ ìš©ì´í•˜ê²Œ í•˜ëŠ” ì£¼ìš” ìš´ì˜ íŠ¹ì„±ì„ ì²´ê³„ì ìœ¼ë¡œ íŠ¹ì„±í™”í•˜ê³  í˜•ì‹í™”í•©ë‹ˆë‹¤. (2) ì¥ì : ì´ëŸ¬í•œ ëª¨ë¸ë“¤ì´ í™•ë¦½ëœ ë‹¨ì¼ ëª¨ë‹¬ ì ‘ê·¼ ë°©ì‹ë³´ë‹¤ ìš°ì›”í•¨ì„ ê²½í—˜ì ìœ¼ë¡œ ì¸¡ì •í•˜ë©°, ì´ ë…íŠ¹í•œ ì¥ì ì„ VLMì˜ í’ë¶€í•œ ì˜ë¯¸ì  ì‹ ì„ í•¨ì„ í™œìš©í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì— ê·€ì†í•©ë‹ˆë‹¤. (3) ë¯¼ê°ë„: ìš°ë¦¬ëŠ” ê·¸ë“¤ì˜ ê²¬ê³ ì„± í”„ë¡œí•„ì—ì„œ ì´ì „ì— íƒêµ¬ë˜ì§€ ì•Šì•˜ë˜ ì¤‘ìš”í•˜ê³  ëŒ€ì¹­ì ì¸ íŠ¹ì„±ì„ ë°œê²¬í•©ë‹ˆë‹¤: ì¼ë°˜ì ì¸ ì´ë¯¸ì§€ ë…¸ì´ì¦ˆì— ëŒ€í•œ ì €í•­ë ¥ì„ ë³´ì´ë©´ì„œë„, ì´ëŸ¬í•œ VLM ê¸°ë°˜ ë°©ë²•ì€ í”„ë¡¬í”„íŠ¸ êµ¬ë¬¸ì— ë§¤ìš° ë¯¼ê°í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì—°êµ¬ ê²°ê³¼ëŠ” VLM ê¸°ë°˜ OOD ê°ì§€ì— ë‚´ì¬ëœ ê°•ì ê³¼ ì¤‘ìš”í•œ ì·¨ì•½ì„±ì— ëŒ€í•œ ë³´ë‹¤ ì²´ê³„ì ì¸ ì´í•´ë¥¼ ì œê³µí•˜ë©°, ë” ê²¬ê³ í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë¯¸ë˜ ë””ìì¸ì„ ê°œë°œí•˜ê¸° ìœ„í•œ ì¤‘ìš”í•˜ê³  ê²½í—˜ì ìœ¼ë¡œ ê¸°ë°˜ëœ ì§€ì¹¨ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ CLIPì™€ ê°™ì€ Vision-Language Models(VLMs)ê°€ ë†€ë¼ìš´ ì œë¡œìƒ· OOD(out-of-distribution) ê°ì§€ ëŠ¥ë ¥ì„ ë³´ì—¬ì£¼ì—ˆì§€ë§Œ, ì´ëŸ¬í•œ íš¨ê³¼ì ì¸ ì‘ë™ ì›ë¦¬, ë‹¨ì¼ ëª¨ë‹¬ ë°©ë²•ë¡ ì— ë¹„í•´ ê°–ëŠ” ì¥ì , ê·¸ë¦¬ê³  í–‰ë™ì ì¸ ê²¬ê³ ì„±ì— ëŒ€í•œ í¬ê´„ì ì¸ ì´í•´ê°€ ë¶€ì¡±í•œ ìƒí™©ì„ ì§€ì í•˜ê³  ìˆë‹¤. ë³¸ ë…¼ë¬¸ì€ VLM ê¸°ë°˜ OOD ê°ì§€ì— ëŒ€í•œ ì²´ê³„ì ì¸ ê²½í—˜ì  ë¶„ì„ì„ ì œì‹œí•˜ë©°, VLM ì„ë² ë”© ê³µê°„ ë‚´ì˜ í•µì‹¬ ìš´ì˜ íŠ¹ì„±ì„ í˜•ì‹í™”í•˜ê³ , ì´ëŸ¬í•œ ëª¨ë¸ì´ í’ë¶€í•œ ì˜ë¯¸ì  ì°½ì˜ì„±ì„ í™œìš©í•˜ëŠ” ëŠ¥ë ¥ìœ¼ë¡œ ì¸í•´ ê¸°ì¡´ì˜ ë‹¨ì¼ ëª¨ë‹¬ ì ‘ê·¼ ë°©ì‹ë³´ë‹¤ ìš°ì›”í•¨ì„ ì‹¤í—˜ì ìœ¼ë¡œ ì¸¡ì •í•˜ì˜€ë‹¤. ë˜í•œ, ì´ë¯¸ì§€ ë…¸ì´ì¦ˆì— ëŒ€í•œ ì €í•­ë ¥ì„ ë³´ì´ì§€ë§Œ í”„ë¡¬í”„íŠ¸ êµ¬ë¬¸ì— ëŒ€í•´ ë¯¼ê°í•œ íŠ¹ì„±ì„ ë°œê²¬í•˜ì—¬, VLM ê¸°ë°˜ ë°©ë²•ì˜ ê°•ì ê³¼ ì¤‘ìš”í•œ ì·¨ì•½ì„±ì— ëŒ€í•œ ë³´ë‹¤ ì²´ê³„ì ì¸ ì´í•´ë¥¼ ì œê³µí•˜ê³ , ë¯¸ë˜ ë””ìì¸ì˜ ë” ê²¬ê³ í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê°œë°œì„ ìœ„í•œ ì¤‘ìš”í•œ ì§€ì¹¨ì„ ì œì‹œí•œë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸


- 1. VLMì€ zero-shot OOD ê°ì§€ ëŠ¥ë ¥ì„ íš¨ê³¼ì ìœ¼ë¡œ ë°œíœ˜í•˜ëŠ”ë° ìˆì–´ì„œ ì¤‘ìš”í•œ ìš´ì˜ íŠ¹ì„±ì„ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ê³  í˜•ì‹í™”í•œë‹¤.

- 2. VLMì€ í’ë¶€í•œ ì˜ë¯¸ì  ì°½ì˜ì„±ì„ í™œìš©í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ìœ¼ë¡œ ê¸°ì¡´ì˜ ë‹¨ì¼ ëª¨ë‹¬ ë°©ë²•ë³´ë‹¤ ìš°ì›”í•¨ì„ ì‹¤í—˜ì ìœ¼ë¡œ ì¸¡ì •í•œë‹¤.

- 3. VLM ê¸°ë°˜ ë°©ë²•ì€ ì¼ë°˜ì ì¸ ì´ë¯¸ì§€ ë…¸ì´ì¦ˆì— ëŒ€í•œ ì €í•­ì„±ì„ ë³´ì´ì§€ë§Œ í”„ë¡¬í”„íŠ¸ êµ¬ë¬¸ì— ëŒ€í•´ ë¯¼ê°í•˜ê²Œ ë°˜ì‘í•œë‹¤.


---

*Generated on 2025-09-18 16:17:46*