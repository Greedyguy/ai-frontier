
# LLM Chatbot-Creation Approaches

**Korean Title:** LLM ì±—ë´‡ ìƒì„± ë°©ë²•ë¡ 

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-18|2025-09-18]] [[keywords/evolved/Hybrid solutions|Hybrid solutions]] [[keywords/broad/Large Language Models|Large Language Models]] [[keywords/broad/Low-code platforms|Low-code platforms]] [[keywords/specific/Retrieval-augmented generation|Retrieval-augmented generation]] [[keywords/unique/LangChain|LangChain]] [[categories/cs.LG|cs.LG]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Hybrid solutions
**ğŸ”¬ Broad Technical**: Large Language Models, Low-code platforms
**ğŸ”— Specific Connectable**: Retrieval-augmented generation
**â­ Unique Technical**: LLaMA

**ArXiv ID**: [2509.13326](https://arxiv.org/abs/2509.13326)
**Published**: 2025-09-18
**Category**: cs.LG
**PDF**: [Download](https://arxiv.org/pdf/2509.13326.pdf)


## ğŸ·ï¸ ì¶”ì¶œëœ í‚¤ì›Œë“œ



`Large Language Models` â€¢ 

`Retrieval-augmented generation` â€¢ 

`Prompt engineering` â€¢ 

`LLaMA` â€¢ 

`Hybrid solutions`



## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.13326v1 Announce Type: cross 
Abstract: This full research-to-practice paper explores approaches for developing course chatbots by comparing low-code platforms and custom-coded solutions in educational contexts. With the rise of Large Language Models (LLMs) like GPT-4 and LLaMA, LLM-based chatbots are being integrated into teaching workflows to automate tasks, provide assistance, and offer scalable support. However, selecting the optimal development strategy requires balancing ease of use, customization, data privacy, and scalability. This study compares two development approaches: low-code platforms like AnythingLLM and Botpress, with custom-coded solutions using LangChain, FAISS, and FastAPI. The research uses Prompt engineering, Retrieval-augmented generation (RAG), and personalization to evaluate chatbot prototypes across technical performance, scalability, and user experience. Findings indicate that while low-code platforms enable rapid prototyping, they face limitations in customization and scaling, while custom-coded systems offer more control but require significant technical expertise. Both approaches successfully implement key research principles such as adaptive feedback loops and conversational continuity. The study provides a framework for selecting the appropriate development strategy based on institutional goals and resources. Future work will focus on hybrid solutions that combine low-code accessibility with modular customization and incorporate multimodal input for intelligent tutoring systems.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.13326v1 ë°œí‘œ ìœ í˜•: êµì°¨
ìš”ì•½: ë³¸ ì—°êµ¬ëŠ” êµìœ¡ì  ë§¥ë½ì—ì„œ ì €ì½”ë“œ í”Œë«í¼ê³¼ ë§ì¶¤ ì½”ë”© ì†”ë£¨ì…˜ì„ ë¹„êµí•˜ì—¬ ì½”ìŠ¤ ì±—ë´‡ì„ ê°œë°œí•˜ëŠ” ë°©ë²•ì„ íƒêµ¬í•˜ëŠ” ì™„ì „í•œ ì—°êµ¬-ì‹¤ë¬´ ë…¼ë¬¸ì´ë‹¤. GPT-4 ë° LLaMAì™€ ê°™ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ (LLM)ì˜ ë“±ì¥ìœ¼ë¡œ LLM ê¸°ë°˜ ì±—ë´‡ì´ ê°€ë¥´ì¹¨ ì›Œí¬í”Œë¡œì— í†µí•©ë˜ì–´ ì‘ì—…ì„ ìë™í™”í•˜ê³  ì§€ì›ì„ ì œê³µí•˜ë©° í™•ì¥ ê°€ëŠ¥í•œ ì§€ì›ì„ ì œê³µí•˜ê³  ìˆë‹¤. ê·¸ëŸ¬ë‚˜ ìµœì ì˜ ê°œë°œ ì „ëµì„ ì„ íƒí•˜ê¸° ìœ„í•´ì„œëŠ” ì‚¬ìš© í¸ì˜ì„±, ë§ì¶¤í™”, ë°ì´í„° ê°œì¸ ì •ë³´ ë³´í˜¸ ë° í™•ì¥ ê°€ëŠ¥ì„±ì„ ê· í˜•ìˆê²Œ ê³ ë ¤í•´ì•¼ í•œë‹¤. ë³¸ ì—°êµ¬ëŠ” AnythingLLM ë° Botpressì™€ ê°™ì€ ì €ì½”ë“œ í”Œë«í¼ê³¼ LangChain, FAISS ë° FastAPIë¥¼ ì‚¬ìš©í•œ ë§ì¶¤ ì½”ë”© ì†”ë£¨ì…˜ì„ ë¹„êµí•˜ëŠ” ë‘ ê°€ì§€ ê°œë°œ ì ‘ê·¼ë²•ì„ ë¹„êµí•œë‹¤. ì´ ì—°êµ¬ëŠ” í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§, ê²€ìƒ‰ ë³´ê°• ìƒì„± (RAG) ë° ê°œì¸í™”ë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°ìˆ ì  ì„±ëŠ¥, í™•ì¥ ê°€ëŠ¥ì„± ë° ì‚¬ìš©ì ê²½í—˜ì„ í†µí•´ ì±—ë´‡ í”„ë¡œí† íƒ€ì…ì„ í‰ê°€í•œë‹¤. ì—°êµ¬ ê²°ê³¼ëŠ” ì €ì½”ë“œ í”Œë«í¼ì´ ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ì§€ë§Œ ë§ì¶¤í™”ì™€ í™•ì¥ì— ì œí•œì´ ìˆìœ¼ë©°, ë§ì¶¤ ì½”ë”© ì‹œìŠ¤í…œì€ ë” ë§ì€ ì œì–´ë¥¼ ì œê³µí•˜ì§€ë§Œ ìƒë‹¹í•œ ê¸°ìˆ ì  ì „ë¬¸ ì§€ì‹ì´ í•„ìš”í•˜ë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤€ë‹¤. ë‘ ê°€ì§€ ì ‘ê·¼ ë°©ì‹ ëª¨ë‘ ì ì‘í˜• í”¼ë“œë°± ë£¨í”„ì™€ ëŒ€í™”ì˜ ì—°ì†ì„±ê³¼ ê°™ì€ ì£¼ìš” ì—°êµ¬ ì›ì¹™ì„ ì„±ê³µì ìœ¼ë¡œ êµ¬í˜„í•œë‹¤. ì´ ì—°êµ¬ëŠ” ê¸°ê´€ì˜ ëª©í‘œì™€ ìì›ì— ê¸°ë°˜í•˜ì—¬ ì ì ˆí•œ ê°œë°œ ì „ëµì„ ì„ íƒí•˜ê¸° ìœ„í•œ í”„ë ˆì„ì›Œí¬ë¥¼ ì œê³µí•œë‹¤. ë¯¸ë˜ ì‘ì—…ì€ ì €ì½”ë“œ ì ‘ê·¼ì„±ê³¼ ëª¨ë“ˆì‹ ë§ì¶¤í™”ë¥¼ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ì†”ë£¨ì…˜ì— ì´ˆì ì„ ë§ì¶”ê³  ì§€ëŠ¥í˜• ì§€ë„ ì‹œìŠ¤í…œì— ë‹¤ì¤‘ ëª¨ë‹¬ ì…ë ¥ì„ í†µí•©í•  ê²ƒì´ë‹¤.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” êµìœ¡ í™˜ê²½ì—ì„œ ì €ì½”ë“œ í”Œë«í¼ê³¼ ë§ì¶¤í˜• ì½”ë”© ì†”ë£¨ì…˜ì„ ë¹„êµí•˜ì—¬ ê°•ì˜ ì±—ë´‡ì„ ê°œë°œí•˜ëŠ” ë°©ë²•ì„ íƒêµ¬í•˜ëŠ” ì—°êµ¬ì´ë‹¤. ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(GPT-4, LLaMA)ì˜ ë“±ì¥ìœ¼ë¡œ LLM ê¸°ë°˜ ì±—ë´‡ì´ ê°€ë¥´ì¹˜ëŠ” ì—…ë¬´ ìë™í™”, ì§€ì› ì œê³µ, í™•ì¥ ê°€ëŠ¥í•œ ì§€ì›ì„ ìœ„í•´ êµìœ¡ ì›Œí¬í”Œë¡œì— í†µí•©ë˜ê³  ìˆë‹¤. ë³¸ ì—°êµ¬ëŠ” AnythingLLM, Botpressì™€ LangChain, FAISS, FastAPIë¥¼ ì‚¬ìš©í•œ ë‘ ê°€ì§€ ê°œë°œ ì ‘ê·¼ ë°©ì‹ì„ ë¹„êµí•˜ë©°, Prompt engineering, RAG, ê°œì¸í™”ë¥¼ ì‚¬ìš©í•˜ì—¬ ì±—ë´‡ í”„ë¡œí† íƒ€ì…ì˜ ê¸°ìˆ  ì„±ëŠ¥, í™•ì¥ì„±, ì‚¬ìš©ì ê²½í—˜ì„ í‰ê°€í•œë‹¤. ê²°ê³¼ëŠ” ì €ì½”ë“œ í”Œë«í¼ì€ ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ì§€ë§Œ ë§ì¶¤í™”ì™€ í™•ì¥ì„±ì— ì œì•½ì´ ìˆê³ , ë§ì¶¤í˜• ì‹œìŠ¤í…œì€ ë” ë§ì€ ì œì–´ë¥¼ ì œê³µí•˜ì§€ë§Œ ìƒë‹¹í•œ ê¸°ìˆ ì  ì „ë¬¸ ì§€ì‹ì´ í•„ìš”í•˜ë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤€ë‹¤. ì—°êµ¬ëŠ” ê¸°ê´€ì˜ ëª©í‘œì™€ ìì›ì— ê¸°ë°˜í•˜ì—¬ ì ì ˆí•œ ê°œë°œ ì „ëµì„ ì„ íƒí•˜ê¸° ìœ„í•œ í”„ë ˆì„ì›Œí¬ë¥¼ ì œê³µí•˜ë©°, ë¯¸ë˜ ì—°êµ¬ëŠ” ì €ì½”ë“œ ì ‘ê·¼ì„±ê³¼ ëª¨ë“ˆì‹ ë§ì¶¤í™”ë¥¼ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ì†”ë£¨ì…˜ ë° ì§€ëŠ¥í˜• ì§€ë„ ì‹œìŠ¤í…œì„ ìœ„í•œ ë‹¤ì¤‘ ëª¨ë‹¬ ì…ë ¥ì„ í†µí•©í•  ê²ƒì´ë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸


- 1. êµìœ¡ì  ë§¥ë½ì—ì„œ low-code í”Œë«í¼ê³¼ ì‚¬ìš©ì ì •ì˜ëœ ì†”ë£¨ì…˜ì„ ë¹„êµí•˜ì—¬ ì½”ìŠ¤ ì±—ë´‡ì„ ê°œë°œí•˜ëŠ” ë°©ë²•ì„ íƒêµ¬í•¨.

- 2. LLM ê¸°ë°˜ ì±—ë´‡ì´ ê°€ë¥´ì¹˜ëŠ” ì—…ë¬´ë¥¼ ìë™í™”í•˜ê³  í™•ì¥ ê°€ëŠ¥í•œ ì§€ì›ì„ ì œê³µí•˜ê¸° ìœ„í•´ êµìœ¡ ì›Œí¬í”Œë¡œì— í†µí•©ë˜ê³  ìˆìŒ.

- 3. low-code í”Œë«í¼ì€ ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘ì„ ê°€ëŠ¥ì¼€í•˜ì§€ë§Œ ì‚¬ìš©ì ì •ì˜ì™€ í™•ì¥ì„±ì— ì œì•½ì´ ìˆìœ¼ë©°, ì‚¬ìš©ì ì •ì˜ëœ ì‹œìŠ¤í…œì€ ë” ë§ì€ ì œì–´ë¥¼ ì œê³µí•˜ì§€ë§Œ ìƒë‹¹í•œ ê¸°ìˆ ì  ì „ë¬¸ ì§€ì‹ì´ í•„ìš”í•¨.


---

*Generated on 2025-09-18 16:40:43*