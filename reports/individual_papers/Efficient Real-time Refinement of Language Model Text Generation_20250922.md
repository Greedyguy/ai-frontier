# Efficient Real-time Refinement of Language Model Text Generation

**Korean Title:** ì–¸ì–´ ëª¨ë¸ í…ìŠ¤íŠ¸ ìƒì„±ì˜ íš¨ìœ¨ì ì¸ ì‹¤ì‹œê°„ ì •ì œ

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: On-the-fly Refinement

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Relevance to Utility_ Process-Supervised Rewrite for RAG_20250922|Relevance to Utility Process-Supervised Rewrite for RAG]] (84.8% similar)
- [[2025-09-17/DSCC-HS_ A Dynamic Self-Reinforcing Framework for Hallucination Suppression in Large Language Models_20250917|DSCC-HS A Dynamic Self-Reinforcing Framework for Hallucination Suppression in Large Language Models]] (84.4% similar)
- [[2025-09-22/Think, Verbalize, then Speak_ Bridging Complex Thoughts and Comprehensible Speech_20250922|Think, Verbalize, then Speak Bridging Complex Thoughts and Comprehensible Speech]] (84.1% similar)
- [[2025-09-18/Evolving Language Models without Labels_ Majority Drives Selection, Novelty Promotes Variation_20250918|Evolving Language Models without Labels Majority Drives Selection, Novelty Promotes Variation]] (83.7% similar)
- [[2025-09-19/DetectAnyLLM_ Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models_20250919|DetectAnyLLM Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models]] (83.7% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2501.07824v5 Announce Type: replace-cross 
Abstract: Large language models (LLMs) have shown remarkable performance across a wide range of natural language tasks. However, a critical challenge remains in that they sometimes generate factually incorrect answers. To address this, while many previous work has focused on identifying errors in their generation and further refining them, they are slow in deployment since they are designed to verify the response from LLMs only after their entire generation (from the first to last tokens) is done. Further, we observe that once LLMs generate incorrect tokens early on, there is a higher likelihood that subsequent tokens will also be factually incorrect. To this end, in this work, we propose Streaming-VR (Streaming Verification and Refinement), a novel approach designed to enhance the efficiency of verification and refinement of LLM outputs. Specifically, the proposed Streaming-VR enables on-the-fly verification and correction of tokens as they are being generated, similar to a streaming process, ensuring that each subset of tokens is checked and refined in real-time by another LLM as the LLM constructs its response. Through comprehensive evaluations on multiple datasets, we demonstrate that our approach not only enhances the factual accuracy of LLMs, but also offers a more efficient solution compared to prior refinement methods.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2501.07824v5 ë°œí‘œ ìœ í˜•: êµì°¨ ëŒ€ì²´  
ì´ˆë¡: ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì€ ë‹¤ì–‘í•œ ìì—°ì–´ ì‘ì—…ì—ì„œ ë†€ë¼ìš´ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ë“¤ì€ ë•Œë•Œë¡œ ì‚¬ì‹¤ê³¼ ë‹¤ë¥¸ ë‹µë³€ì„ ìƒì„±í•œë‹¤ëŠ” ì¤‘ìš”í•œ ë¬¸ì œê°€ ë‚¨ì•„ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ë§ì€ ì´ì „ ì—°êµ¬ë“¤ì€ ìƒì„± ê³¼ì •ì—ì„œì˜ ì˜¤ë¥˜ë¥¼ ì‹ë³„í•˜ê³  ì´ë¥¼ ë” ì •êµí•˜ê²Œ ë‹¤ë“¬ëŠ” ë° ì´ˆì ì„ ë§ì¶”ì—ˆì§€ë§Œ, ì´ëŸ¬í•œ ë°©ë²•ë“¤ì€ LLMì˜ ì „ì²´ ìƒì„±(ì²« ë²ˆì§¸ í† í°ë¶€í„° ë§ˆì§€ë§‰ í† í°ê¹Œì§€)ì´ ì™„ë£Œëœ í›„ì—ë§Œ ì‘ë‹µì„ ê²€ì¦í•˜ë„ë¡ ì„¤ê³„ë˜ì–´ ìˆì–´ ë°°í¬ ì†ë„ê°€ ëŠë¦½ë‹ˆë‹¤. ë˜í•œ, LLMì´ ì´ˆê¸°ì— ì˜ëª»ëœ í† í°ì„ ìƒì„±í•˜ë©´ ì´í›„ì˜ í† í°ë“¤ë„ ì‚¬ì‹¤ê³¼ ë‹¤ë¥¼ ê°€ëŠ¥ì„±ì´ ë†’ì•„ì§„ë‹¤ëŠ” ê²ƒì„ ê´€ì°°í–ˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ë³¸ ì—°êµ¬ì—ì„œëŠ” LLM ì¶œë ¥ì˜ ê²€ì¦ ë° ì •ì œë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ì„¤ê³„ëœ ìƒˆë¡œìš´ ì ‘ê·¼ë²•ì¸ ìŠ¤íŠ¸ë¦¬ë°-VR(ìŠ¤íŠ¸ë¦¬ë° ê²€ì¦ ë° ì •ì œ)ì„ ì œì•ˆí•©ë‹ˆë‹¤. êµ¬ì²´ì ìœ¼ë¡œ, ì œì•ˆëœ ìŠ¤íŠ¸ë¦¬ë°-VRì€ ìŠ¤íŠ¸ë¦¬ë° í”„ë¡œì„¸ìŠ¤ì™€ ìœ ì‚¬í•˜ê²Œ í† í°ì´ ìƒì„±ë˜ëŠ” ë™ì•ˆ ì‹¤ì‹œê°„ìœ¼ë¡œ ê²€ì¦ ë° ìˆ˜ì •í•  ìˆ˜ ìˆë„ë¡ í•˜ì—¬, LLMì´ ì‘ë‹µì„ êµ¬ì„±í•  ë•Œ ë‹¤ë¥¸ LLMì´ ê° í† í°ì˜ í•˜ìœ„ ì§‘í•©ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ í™•ì¸í•˜ê³  ì •ì œí•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. ì—¬ëŸ¬ ë°ì´í„°ì…‹ì— ëŒ€í•œ í¬ê´„ì ì¸ í‰ê°€ë¥¼ í†µí•´, ìš°ë¦¬ì˜ ì ‘ê·¼ë²•ì´ LLMì˜ ì‚¬ì‹¤ì  ì •í™•ì„±ì„ í–¥ìƒì‹œí‚¬ ë¿ë§Œ ì•„ë‹ˆë¼ ì´ì „ì˜ ì •ì œ ë°©ë²•ì— ë¹„í•´ ë” íš¨ìœ¨ì ì¸ ì†”ë£¨ì…˜ì„ ì œê³µí•¨ì„ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ ë‹¤ì–‘í•œ ìì—°ì–´ ì‘ì—…ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì´ì§€ë§Œ, ì‚¬ì‹¤ì ìœ¼ë¡œ ë¶€ì •í™•í•œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ê¸°ì¡´ ì—°êµ¬ë“¤ì€ ì´ëŸ¬í•œ ì˜¤ë¥˜ë¥¼ ì‹ë³„í•˜ê³  ìˆ˜ì •í•˜ëŠ” ë° ì´ˆì ì„ ë§ì·„ìœ¼ë‚˜, ì „ì²´ ì‘ë‹µ ìƒì„± í›„ ê²€ì¦í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì¸í•´ ë°°í¬ê°€ ëŠë¦½ë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ìŠ¤íŠ¸ë¦¬ë°-VR(Streaming Verification and Refinement)ì´ë¼ëŠ” ìƒˆë¡œìš´ ì ‘ê·¼ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ìŠ¤íŠ¸ë¦¬ë°-VRì€ LLMì´ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë™ì•ˆ ì‹¤ì‹œê°„ìœ¼ë¡œ í† í°ì„ ê²€ì¦í•˜ê³  ìˆ˜ì •í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ê° í† í° ì§‘í•©ì´ ìƒì„±ë  ë•Œë§ˆë‹¤ ë‹¤ë¥¸ LLMì´ ì¦‰ì‹œ ê²€í† í•˜ê³  ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—¬ëŸ¬ ë°ì´í„°ì…‹ì— ëŒ€í•œ í‰ê°€ ê²°ê³¼, ì´ ë°©ë²•ì´ LLMì˜ ì‚¬ì‹¤ì  ì •í™•ì„±ì„ ë†’ì´ê³  ê¸°ì¡´ ë°©ë²•ë³´ë‹¤ íš¨ìœ¨ì ì¸ ì†”ë£¨ì…˜ì„ ì œê³µí•¨ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ ìì—°ì–´ ì²˜ë¦¬ ì‘ì—…ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì´ì§€ë§Œ, ì‚¬ì‹¤ì ìœ¼ë¡œ ë¶€ì •í™•í•œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë¬¸ì œê°€ ìˆë‹¤.

- 2. ê¸°ì¡´ ë°©ë²•ë“¤ì€ LLMì˜ ì „ì²´ ìƒì„±ì´ ì™„ë£Œëœ í›„ì— ì‘ë‹µì„ ê²€ì¦í•˜ì—¬ ë°°í¬ ì†ë„ê°€ ëŠë¦¬ë‹¤ëŠ” í•œê³„ê°€ ìˆë‹¤.

- 3. ì´ˆê¸° ë‹¨ê³„ì—ì„œ ì˜ëª»ëœ í† í°ì´ ìƒì„±ë˜ë©´ ì´í›„ì˜ í† í°ë„ ì‚¬ì‹¤ì ìœ¼ë¡œ ë¶€ì •í™•í•  ê°€ëŠ¥ì„±ì´ ë†’ë‹¤.

- 4. ìŠ¤íŠ¸ë¦¬ë°-VR(Streaming Verification and Refinement)ì€ í† í°ì´ ìƒì„±ë˜ëŠ” ì¦‰ì‹œ ì‹¤ì‹œê°„ìœ¼ë¡œ ê²€ì¦ ë° ìˆ˜ì •í•˜ëŠ” ìƒˆë¡œìš´ ì ‘ê·¼ë²•ì´ë‹¤.

- 5. ì œì•ˆëœ ë°©ë²•ì€ ì—¬ëŸ¬ ë°ì´í„°ì…‹ì—ì„œ í‰ê°€í•œ ê²°ê³¼, ì‚¬ì‹¤ì  ì •í™•ì„±ì„ í–¥ìƒì‹œí‚¤ê³  ê¸°ì¡´ ë°©ë²•ë³´ë‹¤ íš¨ìœ¨ì ì¸ ì†”ë£¨ì…˜ì„ ì œê³µí•œë‹¤.

---

*Generated on 2025-09-22 14:41:04*