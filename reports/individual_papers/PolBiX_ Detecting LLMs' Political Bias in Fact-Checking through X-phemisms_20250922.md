# PolBiX: Detecting LLMs' Political Bias in Fact-Checking through X-phemisms

**Korean Title:** 폴비엑스(PolBiX): X-페미즘을 통한 대규모 언어 모델(LLM)의 정치적 편향 탐지

## 📋 메타데이터

## 📋 메타데이터

**Links**: [[reports/digests/daily_digest_20250922|2025-09-22]] [[keywords/evolved/Political Bias Detection|Political Bias Detection]] [[keywords/specific/Fact-checking|Fact-checking]] [[keywords/broad/Large Language Models|Large Language Models]] [[keywords/broad/Natural Language Processing|Natural Language Processing]] [[keywords/unique/X-phemisms|X-phemisms]] [[categories/cs.CL|cs.CL]] [[2025-09-17/Simulating a Bias Mitigation Scenario in Large Language Models_20250917|Simulating a Bias Mitigation Scenario in Large Language Models]] (85.6% similar) [[2025-09-22/Exploring the Impact of Personality Traits on LLM Bias and Toxicity_20250922|Exploring the Impact of Personality Traits on LLM Bias and Toxicity]] (84.5% similar) [[2025-09-19/Large Language Model probabilities cannot distinguish between possible and impossible language_20250919|Large Language Model probabilities cannot distinguish between possible and impossible language]] (83.4% similar)

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Political Bias Detection
**🔗 Specific Connectable**: Fact Checking
**🔬 Broad Technical**: Large Language Models, Natural Language Processing
**⭐ Unique Technical**: X-phemisms
## 🔗 유사한 논문
- [[2025-09-17/Simulating a Bias Mitigation Scenario in Large Language Models_20250917|Simulating a Bias Mitigation Scenario in Large Language Models]] (85.6% similar)
- [[2025-09-22/Exploring the Impact of Personality Traits on LLM Bias and Toxicity_20250922|Exploring the Impact of Personality Traits on LLM Bias and Toxicity]] (84.5% similar)
- [[2025-09-19/Large Language Model probabilities cannot distinguish between possible and impossible language_20250919|Large Language Model probabilities cannot distinguish between possible and impossible language]] (83.4% similar)
- [[2025-09-19/Assessing Historical Structural Oppression Worldwide via Rule-Guided Prompting of Large Language Models_20250919|Assessing Historical Structural Oppression Worldwide via Rule-Guided Prompting of Large Language Models]] (83.2% similar)
- [[2025-09-19/CLEAR_ A Comprehensive Linguistic Evaluation of Argument Rewriting by Large Language Models_20250919|CLEAR A Comprehensive Linguistic Evaluation of Argument Rewriting by Large Language Models]] (82.6% similar)


**ArXiv ID**: [2509.15335](https://arxiv.org/abs/2509.15335)
**Published**: 2025-09-22
**Category**: cs.CL
**PDF**: [Download](https://arxiv.org/pdf/2509.15335.pdf)


**ArXiv ID**: [2509.15335](https://arxiv.org/abs/2509.15335)
**Published**: 2025-09-22
**Category**: cs.CL
**PDF**: [Download](https://arxiv.org/pdf/2509.15335.pdf)

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Political Bias Detection
**🔗 Specific Connectable**: Fact Checking
**⭐ Unique Technical**: X-phemisms
**🔬 Broad Technical**: Large Language Models, Natural Language Processing

## 🏷️ 추출된 키워드



`Large Language Models` • 

`Natural Language Processing` • 

`Fact-checking` • 

`X-phemisms` • 

`Political Bias Detection`



## 🔗 유사한 논문

Similar papers will be displayed here based on embedding similarity.

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.15335v1 Announce Type: new 
Abstract: Large Language Models are increasingly used in applications requiring objective assessment, which could be compromised by political bias. Many studies found preferences for left-leaning positions in LLMs, but downstream effects on tasks like fact-checking remain underexplored. In this study, we systematically investigate political bias through exchanging words with euphemisms or dysphemisms in German claims. We construct minimal pairs of factually equivalent claims that differ in political connotation, to assess the consistency of LLMs in classifying them as true or false. We evaluate six LLMs and find that, more than political leaning, the presence of judgmental words significantly influences truthfulness assessment. While a few models show tendencies of political bias, this is not mitigated by explicitly calling for objectivism in prompts.

## 🔍 Abstract (한글 번역)

arXiv:2509.15335v1 발표 유형: 신규  
초록: 대형 언어 모델(LLM)은 점점 더 객관적인 평가가 필요한 응용 프로그램에 사용되고 있으며, 이는 정치적 편향에 의해 손상될 수 있습니다. 많은 연구에서 LLM이 좌파 성향을 선호한다는 것을 발견했지만, 사실 확인과 같은 작업에 대한 하류 효과는 충분히 탐구되지 않았습니다. 이 연구에서는 독일어 주장에서 완곡어법이나 비완곡어법으로 단어를 교환하여 정치적 편향을 체계적으로 조사합니다. 우리는 정치적 함축이 다른 사실적으로 동등한 주장 쌍을 구성하여 LLM이 이를 진실 또는 거짓으로 분류하는 일관성을 평가합니다. 여섯 개의 LLM을 평가한 결과, 정치적 성향보다는 판단적인 단어의 존재가 진실성 평가에 크게 영향을 미친다는 것을 발견했습니다. 일부 모델은 정치적 편향의 경향을 보이지만, 이는 프롬프트에서 객관성을 명시적으로 요구한다고 해서 완화되지 않습니다.

## 📝 요약

이 연구는 대형 언어 모델(LLM)의 정치적 편향이 사실 확인 작업에 미치는 영향을 조사합니다. 독일어 주장에서 완곡어법과 경멸어법을 교환하여 정치적 함축이 다른 사실적으로 동등한 주장 쌍을 구성하고, LLM이 이를 진실 또는 거짓으로 분류하는 일관성을 평가합니다. 여섯 개의 LLM을 평가한 결과, 정치적 성향보다 판단적인 단어의 존재가 진실성 평가에 더 큰 영향을 미친다는 것을 발견했습니다. 일부 모델은 정치적 편향을 보였으나, 객관성을 강조하는 프롬프트로 이를 완화할 수는 없었습니다.

## 🎯 주요 포인트


- 1. 대형 언어 모델(LLM)은 정치적 편향으로 인해 객관적인 평가가 필요한 응용 프로그램에서 문제가 발생할 수 있다.

- 2. 연구는 독일어 주장에서 완곡어법이나 경멸어법을 사용하여 정치적 편향을 체계적으로 조사한다.

- 3. 정치적 함축이 다른 사실적으로 동등한 주장 쌍을 구성하여 LLM의 일관성을 평가한다.

- 4. 여섯 개의 LLM을 평가한 결과, 판단적 단어의 존재가 진실성 평가에 큰 영향을 미친다.

- 5. 일부 모델은 정치적 편향을 보이지만, 프롬프트에서 객관성을 강조한다고 해서 편향이 완화되지는 않는다.


---

*Generated on 2025-09-22 16:19:24*