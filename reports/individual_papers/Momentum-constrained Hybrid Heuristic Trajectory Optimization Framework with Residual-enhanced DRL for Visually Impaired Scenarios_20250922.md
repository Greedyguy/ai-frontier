# Momentum-constrained Hybrid Heuristic Trajectory Optimization Framework with Residual-enhanced DRL for Visually Impaired Scenarios

**Korean Title:** ëª¨ë©˜í…€ ì œì•½ í•˜ì´ë¸Œë¦¬ë“œ íœ´ë¦¬ìŠ¤í‹± ê¶¤ì  ìµœì í™” í”„ë ˆì„ì›Œí¬ì™€ ì”ì—¬ ê°•í™” ì‹¬ì¸µ ê°•í™” í•™ìŠµì„ í†µí•œ ì‹œê° ì¥ì•  ì‹œë‚˜ë¦¬ì˜¤ ëŒ€ì‘

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Residual-enhanced DRL

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Scalable Multi-Objective Robot Reinforcement Learning through Gradient Conflict Resolution_20250919|Scalable Multi-Objective Robot Reinforcement Learning through Gradient Conflict Resolution]] (82.2% similar)
- [[2025-09-19/PA-MPPI_ Perception-Aware Model Predictive Path Integral Control for Quadrotor Navigation in Unknown Environments_20250919|PA-MPPI Perception-Aware Model Predictive Path Integral Control for Quadrotor Navigation in Unknown Environments]] (81.8% similar)
- [[2025-09-19/Multi-Fidelity Hybrid Reinforcement Learning via Information Gain Maximization_20250919|Multi-Fidelity Hybrid Reinforcement Learning via Information Gain Maximization]] (81.4% similar)
- [[2025-09-19/Optimal Control of Markov Decision Processes for Efficiency with Linear Temporal Logic Tasks_20250919|Optimal Control of Markov Decision Processes for Efficiency with Linear Temporal Logic Tasks]] (81.1% similar)
- [[2025-09-18/Disturbance-Aware Dynamical Trajectory Planning for Air-Land Bimodal Vehicles_20250918|Disturbance-Aware Dynamical Trajectory Planning for Air-Land Bimodal Vehicles]] (80.4% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15582v1 Announce Type: cross 
Abstract: This paper proposes a momentum-constrained hybrid heuristic trajectory optimization framework (MHHTOF) tailored for assistive navigation in visually impaired scenarios, integrating trajectory sampling generation, optimization and evaluation with residual-enhanced deep reinforcement learning (DRL). In the first stage, heuristic trajectory sampling cluster (HTSC) is generated in the Frenet coordinate system using third-order interpolation with fifth-order polynomials and momentum-constrained trajectory optimization (MTO) constraints to ensure smoothness and feasibility. After first stage cost evaluation, the second stage leverages a residual-enhanced actor-critic network with LSTM-based temporal feature modeling to adaptively refine trajectory selection in the Cartesian coordinate system. A dual-stage cost modeling mechanism (DCMM) with weight transfer aligns semantic priorities across stages, supporting human-centered optimization. Experimental results demonstrate that the proposed LSTM-ResB-PPO achieves significantly faster convergence, attaining stable policy performance in approximately half the training iterations required by the PPO baseline, while simultaneously enhancing both reward outcomes and training stability. Compared to baseline method, the selected model reduces average cost and cost variance by 30.3% and 53.3%, and lowers ego and obstacle risks by over 77%. These findings validate the framework's effectiveness in enhancing robustness, safety, and real-time feasibility in complex assistive planning tasks.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15582v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ë³¸ ë…¼ë¬¸ì€ ì‹œê° ì¥ì• ì¸ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œì˜ ë³´ì¡° ë‚´ë¹„ê²Œì´ì…˜ì„ ìœ„í•´ ëª¨ë©˜í…€ ì œì•½ í•˜ì´ë¸Œë¦¬ë“œ íœ´ë¦¬ìŠ¤í‹± ê¶¤ì  ìµœì í™” í”„ë ˆì„ì›Œí¬(MHHTOF)ë¥¼ ì œì•ˆí•˜ë©°, ê¶¤ì  ìƒ˜í”Œë§ ìƒì„±, ìµœì í™” ë° í‰ê°€ë¥¼ ì”ì°¨ ê°•í™” ì‹¬ì¸µ í•™ìŠµ(DRL)ê³¼ í†µí•©í•©ë‹ˆë‹¤. ì²« ë²ˆì§¸ ë‹¨ê³„ì—ì„œëŠ” í”„ë ˆë„¤ ì¢Œí‘œê³„ì—ì„œ 5ì°¨ ë‹¤í•­ì‹ì„ ì‚¬ìš©í•œ 3ì°¨ ë³´ê°„ê³¼ ëª¨ë©˜í…€ ì œì•½ ê¶¤ì  ìµœì í™”(MTO) ì œì•½ì„ í†µí•´ íœ´ë¦¬ìŠ¤í‹± ê¶¤ì  ìƒ˜í”Œë§ í´ëŸ¬ìŠ¤í„°(HTSC)ë¥¼ ìƒì„±í•˜ì—¬ ë¶€ë“œëŸ¬ì›€ê³¼ ì‹¤í–‰ ê°€ëŠ¥ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤. ì²« ë²ˆì§¸ ë‹¨ê³„ì˜ ë¹„ìš© í‰ê°€ í›„, ë‘ ë²ˆì§¸ ë‹¨ê³„ì—ì„œëŠ” LSTM ê¸°ë°˜ì˜ ì‹œê°„ì  íŠ¹ì§• ëª¨ë¸ë§ì„ ê°–ì¶˜ ì”ì°¨ ê°•í™” ì•¡í„°-í¬ë¦¬í‹± ë„¤íŠ¸ì›Œí¬ë¥¼ í™œìš©í•˜ì—¬ ë°ì¹´ë¥´íŠ¸ ì¢Œí‘œê³„ì—ì„œ ê¶¤ì  ì„ íƒì„ ì ì‘ì ìœ¼ë¡œ ê°œì„ í•©ë‹ˆë‹¤. ê°€ì¤‘ì¹˜ ì „ì´ë¥¼ í†µí•œ ì´ì¤‘ ë‹¨ê³„ ë¹„ìš© ëª¨ë¸ë§ ë©”ì»¤ë‹ˆì¦˜(DCMM)ì€ ë‹¨ê³„ ê°„ ì˜ë¯¸ì  ìš°ì„ ìˆœìœ„ë¥¼ ì •ë ¬í•˜ì—¬ ì¸ê°„ ì¤‘ì‹¬ì˜ ìµœì í™”ë¥¼ ì§€ì›í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼ì— ë”°ë¥´ë©´, ì œì•ˆëœ LSTM-ResB-PPOëŠ” PPO ê¸°ì¤€ì„ ì´ ìš”êµ¬í•˜ëŠ” í›ˆë ¨ ë°˜ë³µ íšŸìˆ˜ì˜ ì ˆë°˜ ì •ë„ì—ì„œ ì•ˆì •ì ì¸ ì •ì±… ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ë©°, ë³´ìƒ ê²°ê³¼ì™€ í›ˆë ¨ ì•ˆì •ì„±ì„ ë™ì‹œì— í–¥ìƒì‹œí‚µë‹ˆë‹¤. ê¸°ì¤€ ë°©ë²•ê³¼ ë¹„êµí•  ë•Œ, ì„ íƒëœ ëª¨ë¸ì€ í‰ê·  ë¹„ìš©ê³¼ ë¹„ìš© ë³€ë™ì„±ì„ ê°ê° 30.3% ë° 53.3% ê°ì†Œì‹œí‚¤ê³ , ìì•„ ë° ì¥ì• ë¬¼ ìœ„í—˜ì„ 77% ì´ìƒ ì¤„ì…ë‹ˆë‹¤. ì´ëŸ¬í•œ ê²°ê³¼ëŠ” ë³µì¡í•œ ë³´ì¡° ê³„íš ì‘ì—…ì—ì„œ í”„ë ˆì„ì›Œí¬ì˜ ê²¬ê³ ì„±, ì•ˆì „ì„± ë° ì‹¤ì‹œê°„ ì‹¤í–‰ ê°€ëŠ¥ì„±ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° ìˆì–´ íš¨ê³¼ì ì„ì„ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì‹œê° ì¥ì• ì¸ì„ ìœ„í•œ ë³´ì¡° ë‚´ë¹„ê²Œì´ì…˜ì— ì í•©í•œ ëª¨ë©˜í…€ ì œì•½ í•˜ì´ë¸Œë¦¬ë“œ íœ´ë¦¬ìŠ¤í‹± ê²½ë¡œ ìµœì í™” í”„ë ˆì„ì›Œí¬(MHHTOF)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ê²½ë¡œ ìƒ˜í”Œ ìƒì„±, ìµœì í™” ë° í‰ê°€ë¥¼ ì”ì°¨ ê°•í™” í•™ìŠµ(DRL)ê³¼ í†µí•©í•©ë‹ˆë‹¤. ì²« ë²ˆì§¸ ë‹¨ê³„ì—ì„œëŠ” í”„ë ˆë„¤ ì¢Œí‘œê³„ì—ì„œ 5ì°¨ ë‹¤í•­ì‹ê³¼ ëª¨ë©˜í…€ ì œì•½ ê²½ë¡œ ìµœì í™”(MTO) ì œì•½ì„ ì‚¬ìš©í•˜ì—¬ íœ´ë¦¬ìŠ¤í‹± ê²½ë¡œ ìƒ˜í”Œë§ í´ëŸ¬ìŠ¤í„°(HTSC)ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ë‘ ë²ˆì§¸ ë‹¨ê³„ì—ì„œëŠ” LSTM ê¸°ë°˜ì˜ ì”ì°¨ ê°•í™” ì•¡í„°-í¬ë¦¬í‹± ë„¤íŠ¸ì›Œí¬ë¥¼ í™œìš©í•˜ì—¬ ê²½ë¡œ ì„ íƒì„ ì ì‘ì ìœ¼ë¡œ ê°œì„ í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ LSTM-ResB-PPOëŠ” PPO ê¸°ì¤€ë³´ë‹¤ ì•½ ì ˆë°˜ì˜ í›ˆë ¨ ë°˜ë³µìœ¼ë¡œ ì•ˆì •ì ì¸ ì •ì±… ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ë©°, ë³´ìƒ ê²°ê³¼ì™€ í›ˆë ¨ ì•ˆì •ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ë˜í•œ, í‰ê·  ë¹„ìš©ê³¼ ë¹„ìš© ë³€ë™ì„±ì„ ê°ê° 30.3%ì™€ 53.3% ì¤„ì´ê³ , ìì•„ ë° ì¥ì• ë¬¼ ìœ„í—˜ì„ 77% ì´ìƒ ê°ì†Œì‹œí‚µë‹ˆë‹¤. ì´ëŸ¬í•œ ê²°ê³¼ëŠ” ë³µì¡í•œ ë³´ì¡° ê³„íš ì‘ì—…ì—ì„œ í”„ë ˆì„ì›Œí¬ì˜ íš¨ê³¼ì„±ì„ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì´ ë…¼ë¬¸ì€ ì‹œê° ì¥ì• ì¸ì„ ìœ„í•œ ë³´ì¡° ë‚´ë¹„ê²Œì´ì…˜ì— ì í•©í•œ ëª¨ë©˜í…€ ì œì•½ í•˜ì´ë¸Œë¦¬ë“œ íœ´ë¦¬ìŠ¤í‹± ê²½ë¡œ ìµœì í™” í”„ë ˆì„ì›Œí¬(MHHTOF)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.

- 2. ì²« ë²ˆì§¸ ë‹¨ê³„ì—ì„œëŠ” í”„ë ˆë„¤ ì¢Œí‘œê³„ì—ì„œ 3ì°¨ ë³´ê°„ë²•ê³¼ 5ì°¨ ë‹¤í•­ì‹, ëª¨ë©˜í…€ ì œì•½ ê²½ë¡œ ìµœì í™”(MTO) ì œì•½ì„ ì‚¬ìš©í•˜ì—¬ íœ´ë¦¬ìŠ¤í‹± ê²½ë¡œ ìƒ˜í”Œë§ í´ëŸ¬ìŠ¤í„°(HTSC)ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

- 3. ë‘ ë²ˆì§¸ ë‹¨ê³„ì—ì„œëŠ” ì”ì°¨ ê°•í™”ëœ ì•¡í„°-í¬ë¦¬í‹± ë„¤íŠ¸ì›Œí¬ì™€ LSTM ê¸°ë°˜ì˜ ì‹œê°„ì  íŠ¹ì§• ëª¨ë¸ë§ì„ í™œìš©í•˜ì—¬ ê²½ë¡œ ì„ íƒì„ ì ì‘ì ìœ¼ë¡œ ê°œì„ í•©ë‹ˆë‹¤.

- 4. ì œì•ˆëœ LSTM-ResB-PPOëŠ” PPO ê¸°ì¤€ì„ ë³´ë‹¤ ì•½ ì ˆë°˜ì˜ í›ˆë ¨ ë°˜ë³µì—ì„œ ì•ˆì •ì ì¸ ì •ì±… ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ë©°, ë³´ìƒ ê²°ê³¼ì™€ í›ˆë ¨ ì•ˆì •ì„±ì„ ë™ì‹œì— í–¥ìƒì‹œí‚µë‹ˆë‹¤.

- 5. ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ëª¨ë¸ì€ í‰ê·  ë¹„ìš©ê³¼ ë¹„ìš© ë³€ë™ì„±ì„ ê°ê° 30.3%ì™€ 53.3% ê°ì†Œì‹œí‚¤ê³ , ìì•„ ë° ì¥ì• ë¬¼ ìœ„í—˜ì„ 77% ì´ìƒ ë‚®ì¶¥ë‹ˆë‹¤.

---

*Generated on 2025-09-22 14:04:34*