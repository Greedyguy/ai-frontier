# SightSound-R1: Cross-Modal Reasoning Distillation from Vision to Audio Language Models

**Korean Title:** SightSound-R1: ì‹œê°ì—ì„œ ì˜¤ë””ì˜¤ ì–¸ì–´ ëª¨ë¸ë¡œì˜ êµì°¨ ëª¨ë‹¬ ì¶”ë¡  ì¦ë¥˜

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Audio-Visual Question Answering

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/Omni-CLST_ Error-aware Curriculum Learning with guided Selective chain-of-Thought for audio question answering_20250918|Omni-CLST Error-aware Curriculum Learning with guided Selective chain-of-Thought for audio question answering]] (85.5% similar)
- [[2025-09-19/Cross-Modal Knowledge Distillation for Speech Large Language Models_20250919|Cross-Modal Knowledge Distillation for Speech Large Language Models]] (84.2% similar)
- [[2025-09-18/Spatial Audio Motion Understanding and Reasoning_20250918|Spatial Audio Motion Understanding and Reasoning]] (83.7% similar)
- [[2025-09-22/ORCA_ Agentic Reasoning For Hallucination and Adversarial Robustness in Vision-Language Models_20250922|ORCA Agentic Reasoning For Hallucination and Adversarial Robustness in Vision-Language Models]] (83.0% similar)
- [[2025-09-19/ThinkAct_ Vision-Language-Action Reasoning via Reinforced Visual Latent Planning_20250919|ThinkAct Vision-Language-Action Reasoning via Reinforced Visual Latent Planning]] (81.9% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15661v1 Announce Type: cross 
Abstract: While large audio-language models (LALMs) have demonstrated state-of-the-art audio understanding, their reasoning capability in complex soundscapes still falls behind large vision-language models (LVLMs). Compared to the visual domain, one bottleneck is the lack of large-scale chain-of-thought audio data to teach LALM stepwise reasoning. To circumvent this data and modality gap, we present SightSound-R1, a cross-modal distillation framework that transfers advanced reasoning from a stronger LVLM teacher to a weaker LALM student on the same audio-visual question answering (AVQA) dataset. SightSound-R1 consists of three core steps: (i) test-time scaling to generate audio-focused chains of thought (CoT) from an LVLM teacher, (ii) audio-grounded validation to filter hallucinations, and (iii) a distillation pipeline with supervised fine-tuning (SFT) followed by Group Relative Policy Optimization (GRPO) for the LALM student. Results show that SightSound-R1 improves LALM reasoning performance both in the in-domain AVQA test set as well as in unseen auditory scenes and questions, outperforming both pretrained and label-only distilled baselines. Thus, we conclude that vision reasoning can be effectively transferred to audio models and scaled with abundant audio-visual data.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15661v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ëŒ€í˜• ì˜¤ë””ì˜¤-ì–¸ì–´ ëª¨ë¸(LALMs)ì€ ìµœì²¨ë‹¨ ì˜¤ë””ì˜¤ ì´í•´ë¥¼ ë³´ì—¬ì£¼ì—ˆì§€ë§Œ, ë³µì¡í•œ ì‚¬ìš´ë“œìŠ¤ì¼€ì´í”„ì—ì„œì˜ ì¶”ë¡  ëŠ¥ë ¥ì€ ì—¬ì „íˆ ëŒ€í˜• ë¹„ì „-ì–¸ì–´ ëª¨ë¸(LVLMs)ì— ë’¤ì²˜ì ¸ ìˆìŠµë‹ˆë‹¤. ì‹œê°ì  ë„ë©”ì¸ê³¼ ë¹„êµí•  ë•Œ, í•˜ë‚˜ì˜ ë³‘ëª© í˜„ìƒì€ LALMì˜ ë‹¨ê³„ë³„ ì¶”ë¡ ì„ ê°€ë¥´ì¹  ëŒ€ê·œëª¨ ì—°ì‡„ ì‚¬ê³  ì˜¤ë””ì˜¤ ë°ì´í„°ì˜ ë¶€ì¡±ì…ë‹ˆë‹¤. ì´ëŸ¬í•œ ë°ì´í„° ë° ëª¨ë‹¬ë¦¬í‹° ê²©ì°¨ë¥¼ í•´ì†Œí•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” SightSound-R1ì„ ì œì‹œí•©ë‹ˆë‹¤. ì´ëŠ” ê°•ë ¥í•œ LVLM êµì‚¬ë¡œë¶€í„° ì•½í•œ LALM í•™ìƒì—ê²Œ ë™ì¼í•œ ì˜¤ë””ì˜¤-ë¹„ì£¼ì–¼ ì§ˆë¬¸ ì‘ë‹µ(AVQA) ë°ì´í„°ì…‹ì—ì„œ ê³ ê¸‰ ì¶”ë¡ ì„ ì „ì´í•˜ëŠ” êµì°¨ ëª¨ë‹¬ ì¦ë¥˜ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. SightSound-R1ì€ ì„¸ ê°€ì§€ í•µì‹¬ ë‹¨ê³„ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤: (i) LVLM êµì‚¬ë¡œë¶€í„° ì˜¤ë””ì˜¤ ì¤‘ì‹¬ì˜ ì‚¬ê³  ì‚¬ìŠ¬(CoT)ì„ ìƒì„±í•˜ê¸° ìœ„í•œ í…ŒìŠ¤íŠ¸ ì‹œê°„ í™•ì¥, (ii) í™˜ê°ì„ ê±¸ëŸ¬ë‚´ê¸° ìœ„í•œ ì˜¤ë””ì˜¤ ê¸°ë°˜ ê²€ì¦, (iii) LALM í•™ìƒì„ ìœ„í•œ ê°ë… í•˜ì— ë¯¸ì„¸ ì¡°ì •(SFT) í›„ ê·¸ë£¹ ìƒëŒ€ ì •ì±… ìµœì í™”(GRPO)ë¥¼ í¬í•¨í•˜ëŠ” ì¦ë¥˜ íŒŒì´í”„ë¼ì¸. ê²°ê³¼ëŠ” SightSound-R1ì´ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ê³¼ ë ˆì´ë¸”ë§Œ ì¦ë¥˜ëœ ê¸°ì¤€ì„ ì„ ëŠ¥ê°€í•˜ì—¬, ë„ë©”ì¸ ë‚´ AVQA í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¿ë§Œ ì•„ë‹ˆë¼ ë³´ì§€ ëª»í•œ ì²­ê°ì  ì¥ë©´ê³¼ ì§ˆë¬¸ì—ì„œë„ LALMì˜ ì¶”ë¡  ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚´ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë”°ë¼ì„œ ìš°ë¦¬ëŠ” ë¹„ì „ ì¶”ë¡ ì´ ì˜¤ë””ì˜¤ ëª¨ë¸ë¡œ íš¨ê³¼ì ìœ¼ë¡œ ì „ì´ë  ìˆ˜ ìˆìœ¼ë©°, í’ë¶€í•œ ì˜¤ë””ì˜¤-ë¹„ì£¼ì–¼ ë°ì´í„°ë¡œ í™•ì¥ë  ìˆ˜ ìˆìŒì„ ê²°ë¡ ì§€ì—ˆìŠµë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€ê·œëª¨ ì˜¤ë””ì˜¤-ì–¸ì–´ ëª¨ë¸(LALM)ì˜ ë³µì¡í•œ ì†Œë¦¬ í™˜ê²½ì—ì„œì˜ ì¶”ë¡  ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ SightSound-R1ì´ë¼ëŠ” êµì°¨ ëª¨ë‹¬ ì¦ë¥˜ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ëŠ” ê°•ë ¥í•œ ì‹œê°-ì–¸ì–´ ëª¨ë¸(LVLM)ë¡œë¶€í„° ì˜¤ë””ì˜¤-ë¹„ì£¼ì–¼ ì§ˆë¬¸ ì‘ë‹µ(AVQA) ë°ì´í„°ì…‹ì—ì„œ ì¶”ë¡  ëŠ¥ë ¥ì„ ì „ì´í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. SightSound-R1ì€ LVLM êµì‚¬ë¡œë¶€í„° ì˜¤ë””ì˜¤ ì¤‘ì‹¬ì˜ ì‚¬ê³  ì²´ì¸ì„ ìƒì„±í•˜ê³ , ì˜¤ë””ì˜¤ ê¸°ë°˜ ê²€ì¦ì„ í†µí•´ ì˜¤ë¥˜ë¥¼ ê±¸ëŸ¬ë‚´ë©°, ì§€ë„ í•™ìŠµê³¼ ê·¸ë£¹ ìƒëŒ€ ì •ì±… ìµœì í™”ë¥¼ í†µí•´ LALM í•™ìƒ ëª¨ë¸ì„ ê°œì„ í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì´ ë°©ë²•ì€ LALMì˜ ì¶”ë¡  ì„±ëŠ¥ì„ í–¥ìƒì‹œì¼œ ìƒˆë¡œìš´ ì˜¤ë””ì˜¤ ì¥ë©´ê³¼ ì§ˆë¬¸ì—ì„œë„ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ì´ëŠ” ì‹œê°ì  ì¶”ë¡ ì´ ì˜¤ë””ì˜¤ ëª¨ë¸ë¡œ íš¨ê³¼ì ìœ¼ë¡œ ì „ì´ë  ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì˜¤ë””ì˜¤-ì–¸ì–´ ëª¨ë¸(LALM)ì€ ìµœì²¨ë‹¨ ì˜¤ë””ì˜¤ ì´í•´ë¥¼ ë³´ì—¬ì£¼ì§€ë§Œ, ë³µì¡í•œ ì†Œë¦¬ í™˜ê²½ì—ì„œì˜ ì¶”ë¡  ëŠ¥ë ¥ì€ ì—¬ì „íˆ ëŒ€í˜• ë¹„ì „-ì–¸ì–´ ëª¨ë¸(LVLM)ì— ë’¤ì²˜ì§„ë‹¤.

- 2. SightSound-R1ì€ ê°•ë ¥í•œ LVLM êµì‚¬ì˜ ê³ ê¸‰ ì¶”ë¡  ëŠ¥ë ¥ì„ ì•½í•œ LALM í•™ìƒì—ê²Œ ì „ì´ì‹œí‚¤ëŠ” êµì°¨ ëª¨ë‹¬ ì¦ë¥˜ í”„ë ˆì„ì›Œí¬ì´ë‹¤.

- 3. SightSound-R1ì€ LVLM êµì‚¬ë¡œë¶€í„° ì˜¤ë””ì˜¤ ì¤‘ì‹¬ì˜ ì‚¬ê³  ì‚¬ìŠ¬(CoT)ì„ ìƒì„±í•˜ê³ , ì˜¤ë””ì˜¤ ê¸°ë°˜ ê²€ì¦ì„ í†µí•´ í™˜ê°ì„ í•„í„°ë§í•˜ë©°, ê°ë…ëœ ë¯¸ì„¸ ì¡°ì •(SFT)ê³¼ ê·¸ë£¹ ìƒëŒ€ ì •ì±… ìµœì í™”(GRPO)ë¥¼ í¬í•¨í•œ ì¦ë¥˜ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ êµ¬ì„±ëœë‹¤.

- 4. SightSound-R1ì€ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ê³¼ ë ˆì´ë¸”ë§Œì„ ì‚¬ìš©í•œ ì¦ë¥˜ ê¸°ë°˜ì„ ëŠ¥ê°€í•˜ë©°, LALMì˜ ì¶”ë¡  ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¨ë‹¤.

- 5. ì‹œê°ì  ì¶”ë¡ ì€ ì˜¤ë””ì˜¤ ëª¨ë¸ë¡œ íš¨ê³¼ì ìœ¼ë¡œ ì „ì´ë  ìˆ˜ ìˆìœ¼ë©°, í’ë¶€í•œ ì˜¤ë””ì˜¤-ë¹„ì£¼ì–¼ ë°ì´í„°ë¥¼ í†µí•´ í™•ì¥ë  ìˆ˜ ìˆë‹¤.

---

*Generated on 2025-09-22 14:07:07*