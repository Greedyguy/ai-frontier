# Noise-Robustness Through Noise: Asymmetric LoRA Adaption with Poisoning Expert

**Korean Title:** ì†ŒìŒì— ì˜í•œ ì†ŒìŒ ê²¬ê³ ì„±: ì¤‘ë… ì „ë¬¸ê°€ë¥¼ í†µí•œ ë¹„ëŒ€ì¹­ LoRA ì ì‘

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Noise Robust Adaptation

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-17/Mixture of Low-Rank Adapter Experts in Generalizable Audio Deepfake Detection_20250917|Mixture of Low-Rank Adapter Experts in Generalizable Audio Deepfake Detection]] (82.7% similar)
- [[2025-09-18/Adaptive LoRA Experts Allocation and Selection for Federated Fine-Tuning_20250918|Adaptive LoRA Experts Allocation and Selection for Federated Fine-Tuning]] (80.2% similar)
- [[2025-09-19/Opening the Black Box_ Interpretable LLMs via Semantic Resonance Architecture_20250919|Opening the Black Box Interpretable LLMs via Semantic Resonance Architecture]] (80.0% similar)
- [[2025-09-18/Not All Degradations Are Equal_ A Targeted Feature Denoising Framework for Generalizable Image Super-Resolution_20250918|Not All Degradations Are Equal A Targeted Feature Denoising Framework for Generalizable Image Super-Resolution]] (79.7% similar)
- [[2025-09-18/LNE-Blocking_ An Efficient Framework for Contamination Mitigation Evaluation on Large Language Models_20250918|LNE-Blocking An Efficient Framework for Contamination Mitigation Evaluation on Large Language Models]] (79.5% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2505.23868v4 Announce Type: replace-cross 
Abstract: Current parameter-efficient fine-tuning methods for adapting pre-trained language models to downstream tasks are susceptible to interference from noisy data. Conventional noise-handling approaches either rely on laborious data pre-processing or employ model architecture modifications prone to error accumulation. In contrast to existing noise-process paradigms, we propose a noise-robust adaptation method via asymmetric LoRA poisoning experts (LoPE), a novel framework that enhances model robustness to noise only with generated noisy data. Drawing inspiration from the mixture-of-experts architecture, LoPE strategically integrates a dedicated poisoning expert in an asymmetric LoRA configuration. Through a two-stage paradigm, LoPE performs noise injection on the poisoning expert during fine-tuning to enhance its noise discrimination and processing ability. During inference, we selectively mask the dedicated poisoning expert to leverage purified knowledge acquired by normal experts for noise-robust output. Extensive experiments demonstrate that LoPE achieves strong performance and robustness purely through the low-cost noise injection, which completely eliminates the requirement of data cleaning.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2505.23868v4 ë°œí‘œ ìœ í˜•: êµì°¨ êµì²´  
ì´ˆë¡: ì‚¬ì „ í•™ìŠµëœ ì–¸ì–´ ëª¨ë¸ì„ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—…ì— ì ì‘ì‹œí‚¤ê¸° ìœ„í•œ í˜„ì¬ì˜ ë§¤ê°œë³€ìˆ˜ íš¨ìœ¨ì  ë¯¸ì„¸ ì¡°ì • ë°©ë²•ì€ ì¡ìŒì´ ë§ì€ ë°ì´í„°ë¡œë¶€í„°ì˜ ê°„ì„­ì— ì·¨ì•½í•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ì¡ìŒ ì²˜ë¦¬ ì ‘ê·¼ë²•ì€ ë²ˆê±°ë¡œìš´ ë°ì´í„° ì „ì²˜ë¦¬ì— ì˜ì¡´í•˜ê±°ë‚˜ ì˜¤ë¥˜ ëˆ„ì ì— ì·¨ì•½í•œ ëª¨ë¸ ì•„í‚¤í…ì²˜ ìˆ˜ì •ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ì¡ìŒ ì²˜ë¦¬ íŒ¨ëŸ¬ë‹¤ì„ê³¼ ë‹¬ë¦¬, ìš°ë¦¬ëŠ” ìƒì„±ëœ ì¡ìŒ ë°ì´í„°ë§Œìœ¼ë¡œ ëª¨ë¸ì˜ ì¡ìŒì— ëŒ€í•œ ê°•ê±´ì„±ì„ í–¥ìƒì‹œí‚¤ëŠ” ë¹„ëŒ€ì¹­ LoRA ì¤‘ë… ì „ë¬¸ê°€(LoPE)ë¥¼ í†µí•œ ì¡ìŒ ê°•ê±´ ì ì‘ ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì „ë¬¸ê°€ í˜¼í•© ì•„í‚¤í…ì²˜ì—ì„œ ì˜ê°ì„ ë°›ì•„, LoPEëŠ” ë¹„ëŒ€ì¹­ LoRA êµ¬ì„±ì—ì„œ ì „ìš© ì¤‘ë… ì „ë¬¸ê°€ë¥¼ ì „ëµì ìœ¼ë¡œ í†µí•©í•©ë‹ˆë‹¤. ë‘ ë‹¨ê³„ íŒ¨ëŸ¬ë‹¤ì„ì„ í†µí•´, LoPEëŠ” ë¯¸ì„¸ ì¡°ì • ì¤‘ ì¤‘ë… ì „ë¬¸ê°€ì— ëŒ€í•œ ì¡ìŒ ì£¼ì…ì„ ìˆ˜í–‰í•˜ì—¬ ì¡ìŒ íŒë³„ ë° ì²˜ë¦¬ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì¶”ë¡  ì‹œ, ìš°ë¦¬ëŠ” ì „ìš© ì¤‘ë… ì „ë¬¸ê°€ë¥¼ ì„ íƒì ìœ¼ë¡œ ë§ˆìŠ¤í‚¹í•˜ì—¬ ì •ìƒ ì „ë¬¸ê°€ê°€ íšë“í•œ ì •ì œëœ ì§€ì‹ì„ í™œìš©í•˜ì—¬ ì¡ìŒ ê°•ê±´ ì¶œë ¥ì„ ìƒì„±í•©ë‹ˆë‹¤. ê´‘ë²”ìœ„í•œ ì‹¤í—˜ì„ í†µí•´ LoPEëŠ” ë°ì´í„° ì •ë¦¬ì˜ í•„ìš”ì„±ì„ ì™„ì „íˆ ì œê±°í•˜ëŠ” ì €ë¹„ìš© ì¡ìŒ ì£¼ì…ë§Œìœ¼ë¡œ ê°•ë ¥í•œ ì„±ëŠ¥ê³¼ ê°•ê±´ì„±ì„ ë‹¬ì„±í•¨ì„ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì‚¬ì „ í•™ìŠµëœ ì–¸ì–´ ëª¨ë¸ì„ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—…ì— ì ì‘ì‹œí‚¤ëŠ” ê³¼ì •ì—ì„œ ë°œìƒí•˜ëŠ” ë…¸ì´ì¦ˆ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ë°©ë²•ë¡ ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë…¸ì´ì¦ˆ ì²˜ë¦¬ ë°©ë²•ì€ ë°ì´í„° ì „ì²˜ë¦¬ë‚˜ ëª¨ë¸ êµ¬ì¡° ë³€ê²½ì— ì˜ì¡´í•˜ì—¬ ì˜¤ë¥˜ê°€ ë°œìƒí•  ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤. ì´ì— ë°˜í•´, ì €ìë“¤ì€ ë¹„ëŒ€ì¹­ LoRA í¬ì´ì¦ˆë‹ ì „ë¬¸ê°€(LoPE)ë¥¼ í™œìš©í•œ ë…¸ì´ì¦ˆì— ê°•í•œ ì ì‘ ë°©ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤. LoPEëŠ” ì „ë¬¸ê°€ í˜¼í•© êµ¬ì¡°ì—ì„œ ì˜ê°ì„ ë°›ì•„, ë¹„ëŒ€ì¹­ LoRA êµ¬ì„±ì—ì„œ í¬ì´ì¦ˆë‹ ì „ë¬¸ê°€ë¥¼ í†µí•©í•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ë‘ ë‹¨ê³„ë¡œ ì´ë£¨ì–´ì§€ë©°, ë¯¸ì„¸ ì¡°ì • ê³¼ì •ì—ì„œ í¬ì´ì¦ˆë‹ ì „ë¬¸ê°€ì— ë…¸ì´ì¦ˆë¥¼ ì£¼ì…í•˜ì—¬ ë…¸ì´ì¦ˆ ì‹ë³„ ë° ì²˜ë¦¬ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì¶”ë¡  ì‹œì—ëŠ” í¬ì´ì¦ˆë‹ ì „ë¬¸ê°€ë¥¼ ì„ íƒì ìœ¼ë¡œ ë§ˆìŠ¤í‚¹í•˜ì—¬ ì •ì œëœ ì§€ì‹ì„ í™œìš©í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, LoPEëŠ” ë°ì´í„° ì •ì œ ì—†ì´ë„ ê°•ë ¥í•œ ì„±ëŠ¥ê³¼ ë…¸ì´ì¦ˆì— ëŒ€í•œ ê²¬ê³ í•¨ì„ ì €ë¹„ìš©ìœ¼ë¡œ ë‹¬ì„±í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ê¸°ì¡´ì˜ íŒŒë¼ë¯¸í„° íš¨ìœ¨ì  ë¯¸ì„¸ ì¡°ì • ë°©ë²•ì€ ë…¸ì´ì¦ˆ ë°ì´í„°ì— ì·¨ì•½í•˜ë©°, ì¼ë°˜ì ì¸ ë…¸ì´ì¦ˆ ì²˜ë¦¬ ë°©ë²•ì€ ë°ì´í„° ì „ì²˜ë¦¬ë‚˜ ëª¨ë¸ êµ¬ì¡° ìˆ˜ì •ì— ì˜ì¡´í•©ë‹ˆë‹¤.

- 2. ì œì•ˆëœ LoPE(ë¹„ëŒ€ì¹­ LoRA ì¤‘ë… ì „ë¬¸ê°€)ëŠ” ìƒì„±ëœ ë…¸ì´ì¦ˆ ë°ì´í„°ë§Œìœ¼ë¡œ ëª¨ë¸ì˜ ë…¸ì´ì¦ˆì— ëŒ€í•œ ê°•ê±´ì„±ì„ í–¥ìƒì‹œí‚¤ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.

- 3. LoPEëŠ” ì „ë¬¸ê°€ í˜¼í•© ì•„í‚¤í…ì²˜ì—ì„œ ì˜ê°ì„ ë°›ì•„, ë¹„ëŒ€ì¹­ LoRA êµ¬ì„±ì—ì„œ ì „ìš© ì¤‘ë… ì „ë¬¸ê°€ë¥¼ í†µí•©í•˜ì—¬ ë…¸ì´ì¦ˆ ì£¼ì…ì„ í†µí•´ ë…¸ì´ì¦ˆ êµ¬ë³„ ë° ì²˜ë¦¬ ëŠ¥ë ¥ì„ ê°•í™”í•©ë‹ˆë‹¤.

- 4. ì¶”ë¡  ì‹œ, ì „ìš© ì¤‘ë… ì „ë¬¸ê°€ë¥¼ ì„ íƒì ìœ¼ë¡œ ë§ˆìŠ¤í‚¹í•˜ì—¬ ì •ê·œ ì „ë¬¸ê°€ê°€ ìŠµë“í•œ ì •ì œëœ ì§€ì‹ì„ í™œìš©í•˜ì—¬ ë…¸ì´ì¦ˆì— ê°•ê±´í•œ ì¶œë ¥ì„ ìƒì„±í•©ë‹ˆë‹¤.

- 5. ê´‘ë²”ìœ„í•œ ì‹¤í—˜ ê²°ê³¼, LoPEëŠ” ì €ë¹„ìš©ì˜ ë…¸ì´ì¦ˆ ì£¼ì…ë§Œìœ¼ë¡œë„ ê°•ë ¥í•œ ì„±ëŠ¥ê³¼ ê°•ê±´ì„±ì„ ë‹¬ì„±í•˜ë©°, ë°ì´í„° ì •ì œì˜ í•„ìš”ì„±ì„ ì™„ì „íˆ ì œê±°í•©ë‹ˆë‹¤.

---

*Generated on 2025-09-22 14:52:02*