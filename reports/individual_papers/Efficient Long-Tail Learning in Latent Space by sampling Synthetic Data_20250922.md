# Efficient Long-Tail Learning in Latent Space by sampling Synthetic Data

**Korean Title:** ì ì¬ ê³µê°„ì—ì„œ í•©ì„± ë°ì´í„°ë¥¼ ìƒ˜í”Œë§í•˜ì—¬ íš¨ìœ¨ì ì¸ ë¡±í…Œì¼ í•™ìŠµ

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Synthetic Data Generation

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Latent Zoning Network_ A Unified Principle for Generative Modeling, Representation Learning, and Classification_20250922|Latent Zoning Network A Unified Principle for Generative Modeling, Representation Learning, and Classification]] (84.8% similar)
- [[2025-09-19/Superpose Task-specific Features for Model Merging_20250919|Superpose Task-specific Features for Model Merging]] (84.0% similar)
- [[2025-09-17/Consistent View Alignment Improves Foundation Models for 3D Medical Image Segmentation_20250917|Consistent View Alignment Improves Foundation Models for 3D Medical Image Segmentation]] (83.7% similar)
- [[2025-09-19/Middo_ Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning_20250919|Middo Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning]] (83.1% similar)
- [[2025-09-22/LiteLong_ Resource-Efficient Long-Context Data Synthesis for LLMs_20250922|LiteLong Resource-Efficient Long-Context Data Synthesis for LLMs]] (82.7% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15859v1 Announce Type: new 
Abstract: Imbalanced classification datasets pose significant challenges in machine learning, often leading to biased models that perform poorly on underrepresented classes. With the rise of foundation models, recent research has focused on the full, partial, and parameter-efficient fine-tuning of these models to deal with long-tail classification. Despite the impressive performance of these works on the benchmark datasets, they still fail to close the gap with the networks trained using the balanced datasets and still require substantial computational resources, even for relatively smaller datasets. Underscoring the importance of computational efficiency and simplicity, in this work we propose a novel framework that leverages the rich semantic latent space of Vision Foundation Models to generate synthetic data and train a simple linear classifier using a mixture of real and synthetic data for long-tail classification. The computational efficiency gain arises from the number of trainable parameters that are reduced to just the number of parameters in the linear model. Our method sets a new state-of-the-art for the CIFAR-100-LT benchmark and demonstrates strong performance on the Places-LT benchmark, highlighting the effectiveness and adaptability of our simple and effective approach.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15859v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: ë¶ˆê· í˜•í•œ ë¶„ë¥˜ ë°ì´í„°ì…‹ì€ ê¸°ê³„ í•™ìŠµì—ì„œ ìƒë‹¹í•œ ë„ì „ì„ ì œê¸°í•˜ë©°, ì¢…ì¢… ê³¼ì†Œ ëŒ€í‘œëœ í´ë˜ìŠ¤ì—ì„œ ì„±ëŠ¥ì´ ì €ì¡°í•œ í¸í–¥ëœ ëª¨ë¸ì„ ì´ˆë˜í•©ë‹ˆë‹¤. ê¸°ì´ˆ ëª¨ë¸ì˜ ë¶€ìƒê³¼ í•¨ê»˜, ìµœê·¼ ì—°êµ¬ëŠ” ì´ëŸ¬í•œ ëª¨ë¸ì˜ ì „ì²´, ë¶€ë¶„, ê·¸ë¦¬ê³  ë§¤ê°œë³€ìˆ˜ íš¨ìœ¨ì ì¸ ë¯¸ì„¸ ì¡°ì •ì„ í†µí•´ ë¡±í…Œì¼ ë¶„ë¥˜ë¥¼ ë‹¤ë£¨ëŠ” ë° ì´ˆì ì„ ë§ì¶”ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì—°êµ¬ë“¤ì´ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì—ì„œ ì¸ìƒì ì¸ ì„±ëŠ¥ì„ ë³´ì˜€ìŒì—ë„ ë¶ˆêµ¬í•˜ê³ , ì—¬ì „íˆ ê· í˜• ì¡íŒ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ í›ˆë ¨ëœ ë„¤íŠ¸ì›Œí¬ì™€ì˜ ê²©ì°¨ë¥¼ í•´ì†Œí•˜ì§€ ëª»í•˜ë©°, ë¹„êµì  ì‘ì€ ë°ì´í„°ì…‹ì—ì„œë„ ìƒë‹¹í•œ ê³„ì‚° ìì›ì„ ìš”êµ¬í•©ë‹ˆë‹¤. ê³„ì‚° íš¨ìœ¨ì„±ê³¼ ë‹¨ìˆœì„±ì˜ ì¤‘ìš”ì„±ì„ ê°•ì¡°í•˜ë©°, ë³¸ ì—°êµ¬ì—ì„œëŠ” Vision Foundation Modelsì˜ í’ë¶€í•œ ì˜ë¯¸ë¡ ì  ì ì¬ ê³µê°„ì„ í™œìš©í•˜ì—¬ í•©ì„± ë°ì´í„°ë¥¼ ìƒì„±í•˜ê³ , ì‹¤ì œ ë°ì´í„°ì™€ í•©ì„± ë°ì´í„°ë¥¼ í˜¼í•©í•˜ì—¬ ê°„ë‹¨í•œ ì„ í˜• ë¶„ë¥˜ê¸°ë¥¼ í›ˆë ¨í•˜ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê³„ì‚° íš¨ìœ¨ì„±ì˜ í–¥ìƒì€ ì„ í˜• ëª¨ë¸ì˜ ë§¤ê°œë³€ìˆ˜ ìˆ˜ë¡œ ì¤„ì–´ë“  í›ˆë ¨ ê°€ëŠ¥í•œ ë§¤ê°œë³€ìˆ˜ì˜ ìˆ˜ì—ì„œ ë¹„ë¡¯ë©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ë°©ë²•ì€ CIFAR-100-LT ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìƒˆë¡œìš´ ìµœì²¨ë‹¨ ì„±ê³¼ë¥¼ ê¸°ë¡í•˜ê³ , Places-LT ë²¤ì¹˜ë§ˆí¬ì—ì„œë„ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ë©°, ìš°ë¦¬ì˜ ê°„ë‹¨í•˜ê³  íš¨ê³¼ì ì¸ ì ‘ê·¼ ë°©ì‹ì˜ íš¨ê³¼ì„±ê³¼ ì ì‘ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë¶ˆê· í˜•í•œ ë¶„ë¥˜ ë°ì´í„°ì…‹ì—ì„œ ë°œìƒí•˜ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ê¸°ì´ˆ ëª¨ë¸ë“¤ì€ ì—¬ì „íˆ ê· í˜• ì¡íŒ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•œ ë„¤íŠ¸ì›Œí¬ì— ë¹„í•´ ì„±ëŠ¥ì´ ë–¨ì–´ì§€ê³ , ë§ì€ ê³„ì‚° ìì›ì„ í•„ìš”ë¡œ í•©ë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” Vision Foundation Modelsì˜ í’ë¶€í•œ ì˜ë¯¸ë¡ ì  ì ì¬ ê³µê°„ì„ í™œìš©í•˜ì—¬ í•©ì„± ë°ì´í„°ë¥¼ ìƒì„±í•˜ê³ , ì‹¤ì œ ë°ì´í„°ì™€ í•©ì„± ë°ì´í„°ë¥¼ í˜¼í•©í•˜ì—¬ ê°„ë‹¨í•œ ì„ í˜• ë¶„ë¥˜ê¸°ë¥¼ í›ˆë ¨í•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ í›ˆë ¨ ê°€ëŠ¥í•œ ë§¤ê°œë³€ìˆ˜ ìˆ˜ë¥¼ ì„ í˜• ëª¨ë¸ì˜ ë§¤ê°œë³€ìˆ˜ ìˆ˜ë¡œ ì¤„ì—¬ ê³„ì‚° íš¨ìœ¨ì„±ì„ ë†’ì…ë‹ˆë‹¤. ì œì•ˆëœ ë°©ë²•ì€ CIFAR-100-LT ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥ì„ ê¸°ë¡í–ˆìœ¼ë©°, Places-LT ë²¤ì¹˜ë§ˆí¬ì—ì„œë„ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë¶ˆê· í˜•í•œ ë¶„ë¥˜ ë°ì´í„°ì…‹ì€ ë¨¸ì‹ ëŸ¬ë‹ì—ì„œ í¸í–¥ëœ ëª¨ë¸ì„ ì´ˆë˜í•˜ì—¬ ì†Œìˆ˜ í´ë˜ìŠ¤ì—ì„œ ì„±ëŠ¥ì´ ì €í•˜ë˜ëŠ” ë¬¸ì œë¥¼ ì•¼ê¸°í•œë‹¤.

- 2. ë³¸ ì—°êµ¬ëŠ” ë¹„ì „ ê¸°ë°˜ ëª¨ë¸ì˜ í’ë¶€í•œ ì˜ë¯¸ë¡ ì  ì ì¬ ê³µê°„ì„ í™œìš©í•˜ì—¬ í•©ì„± ë°ì´í„°ë¥¼ ìƒì„±í•˜ê³ , ì‹¤ì œ ë°ì´í„°ì™€ í•©ì„± ë°ì´í„°ë¥¼ í˜¼í•©í•˜ì—¬ ê°„ë‹¨í•œ ì„ í˜• ë¶„ë¥˜ê¸°ë¥¼ í›ˆë ¨í•˜ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•œë‹¤.

- 3. ì œì•ˆëœ ë°©ë²•ì€ CIFAR-100-LT ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥ì„ ê¸°ë¡í•˜ì˜€ìœ¼ë©°, Places-LT ë²¤ì¹˜ë§ˆí¬ì—ì„œë„ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤€ë‹¤.

- 4. ì œì•ˆëœ ë°©ë²•ì€ ì„ í˜• ëª¨ë¸ì˜ ë§¤ê°œë³€ìˆ˜ ìˆ˜ë¡œ í›ˆë ¨ ê°€ëŠ¥í•œ ë§¤ê°œë³€ìˆ˜ë¥¼ ì¤„ì—¬ ê³„ì‚° íš¨ìœ¨ì„±ì„ í¬ê²Œ í–¥ìƒì‹œí‚¨ë‹¤.

---

*Generated on 2025-09-22 15:26:28*