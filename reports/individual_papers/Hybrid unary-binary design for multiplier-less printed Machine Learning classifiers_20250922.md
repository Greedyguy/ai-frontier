# Hybrid unary-binary design for multiplier-less printed Machine Learning classifiers

**Korean Title:** 하이브리드 단항-이항 설계: 곱셈기 없는 인쇄형 머신러닝 분류기

## 📋 메타데이터

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: Architecture Aware Training

## 🔗 유사한 논문
- [[2025-09-18/Low-rank surrogate modeling and stochastic zero-order optimization for training of neural networks with black-box layers_20250918|Low-rank surrogate modeling and stochastic zero-order optimization for training of neural networks with black-box layers]] (83.3% similar)
- [[2025-09-18/The Energy-Efficient Hierarchical Neural Network with Fast FPGA-Based Incremental Learning_20250918|The Energy-Efficient Hierarchical Neural Network with Fast FPGA-Based Incremental Learning]] (81.7% similar)
- [[2025-09-19/MaRVIn_ A Cross-Layer Mixed-Precision RISC-V Framework for DNN Inference, from ISA Extension to Hardware Acceleration_20250919|MaRVIn A Cross-Layer Mixed-Precision RISC-V Framework for DNN Inference, from ISA Extension to Hardware Acceleration]] (80.0% similar)
- [[2025-09-19/eIQ Neutron_ Redefining Edge-AI Inference with Integrated NPU and Compiler Innovations_20250919|eIQ Neutron Redefining Edge-AI Inference with Integrated NPU and Compiler Innovations]] (79.2% similar)
- [[2025-09-22/Sparsity May Be All You Need_ Sparse Random Parameter Adaptation_20250922|Sparsity May Be All You Need Sparse Random Parameter Adaptation]] (79.2% similar)

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.15316v1 Announce Type: new 
Abstract: Printed Electronics (PE) provide a flexible, cost-efficient alternative to silicon for implementing machine learning (ML) circuits, but their large feature sizes limit classifier complexity. Leveraging PE's low fabrication and NRE costs, designers can tailor hardware to specific ML models, simplifying circuit design. This work explores alternative arithmetic and proposes a hybrid unary-binary architecture that removes costly encoders and enables efficient, multiplier-less execution of MLP classifiers. We also introduce architecture-aware training to further improve area and power efficiency. Evaluation on six datasets shows average reductions of 46% in area and 39% in power, with minimal accuracy loss, surpassing other state-of-the-art MLP designs.

## 🔍 Abstract (한글 번역)

arXiv:2509.15316v1 발표 유형: 신규  
초록: 인쇄 전자(Printed Electronics, PE)는 기계 학습(ML) 회로 구현에 있어 실리콘에 대한 유연하고 비용 효율적인 대안을 제공하지만, 큰 피처 크기로 인해 분류기 복잡성이 제한됩니다. PE의 낮은 제조 및 비반복적 엔지니어링(NRE) 비용을 활용하여, 설계자는 특정 ML 모델에 맞춘 하드웨어를 설계하여 회로 설계를 단순화할 수 있습니다. 본 연구는 대체 산술을 탐구하고, 비용이 많이 드는 인코더를 제거하고 다층 퍼셉트론(MLP) 분류기의 효율적인 곱셈기 없는 실행을 가능하게 하는 하이브리드 유니터리-바이너리 아키텍처를 제안합니다. 또한, 영역 및 전력 효율성을 더욱 향상시키기 위해 아키텍처 인식 훈련을 도입합니다. 여섯 개의 데이터셋에 대한 평가 결과, 평균적으로 영역은 46%, 전력은 39% 감소하며, 다른 최첨단 MLP 설계를 능가하는 최소한의 정확도 손실을 보였습니다.

## 📝 요약

이 논문은 인쇄 전자(PE)를 활용한 기계 학습(ML) 회로 설계의 효율성을 탐구합니다. PE는 실리콘 대비 유연하고 비용 효율적이지만, 큰 특징 크기로 인해 분류기 복잡성이 제한됩니다. 이를 해결하기 위해, 저자는 하이브리드 유니터리-바이너리 아키텍처를 제안하여 고가의 인코더를 제거하고, 곱셈기 없이 MLP 분류기를 효율적으로 실행할 수 있도록 했습니다. 또한, 아키텍처 인식 훈련을 도입하여 면적과 전력 효율성을 개선했습니다. 6개의 데이터셋 평가 결과, 평균적으로 면적은 46%, 전력은 39% 감소하면서도 정확도 손실은 최소화되어 기존 MLP 설계를 능가했습니다.

## 🎯 주요 포인트

- 1. 인쇄 전자(PE)는 실리콘에 비해 유연하고 비용 효율적인 기계 학습(ML) 회로 구현 대안을 제공하지만, 큰 특징 크기로 인해 분류기 복잡성이 제한된다.

- 2. PE의 낮은 제작 및 NRE 비용을 활용하여 하드웨어를 특정 ML 모델에 맞게 조정할 수 있으며, 이는 회로 설계를 단순화한다.

- 3. 본 연구는 대안적인 산술 방식을 탐구하고, 비용이 많이 드는 인코더를 제거하며 효율적인 곱셈기 없는 MLP 분류기 실행을 가능하게 하는 하이브리드 유니터리-바이너리 아키텍처를 제안한다.

- 4. 아키텍처 인식 훈련을 도입하여 면적 및 전력 효율성을 더욱 향상시킨다.

- 5. 여섯 개의 데이터셋 평가 결과, 평균적으로 면적 46% 및 전력 39% 감소를 보이며, 정확도 손실이 최소화되어 다른 최첨단 MLP 설계를 능가한다.

---

*Generated on 2025-09-22 15:09:47*