# GP3: A 3D Geometry-Aware Policy with Multi-View Images for Robotic Manipulation

**Korean Title:** GP3: ë¡œë´‡ ì¡°ì‘ì„ ìœ„í•œ ë‹¤ì¤‘ ë·° ì´ë¯¸ì§€ë¥¼ í™œìš©í•œ 3D ê¸°í•˜í•™ ì¸ì‹ ì •ì±…

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: Multi-view Observations, Spatial Encoder

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/GAF_ Gaussian Action Field as a Dynamic World Model for Robotic Manipulation_20250919|GAF Gaussian Action Field as a Dynamic World Model for Robotic Manipulation]] (85.0% similar)
- [[2025-09-17/Prompt2Auto_ From Motion Prompt to Automated Control via Geometry-Invariant One-Shot Gaussian Process Learning_20250917|Prompt2Auto From Motion Prompt to Automated Control via Geometry-Invariant One-Shot Gaussian Process Learning]] (84.6% similar)
- [[2025-09-18/PRISM-DP_ Spatial Pose-based Observations for Diffusion-Policies via Segmentation, Mesh Generation, and Pose Tracking_20250918|PRISM-DP Spatial Pose-based Observations for Diffusion-Policies via Segmentation, Mesh Generation, and Pose Tracking]] (84.2% similar)
- [[2025-09-18/Hybrid Diffusion Policies with Projective Geometric Algebra for Efficient Robot Manipulation Learning_20250918|Hybrid Diffusion Policies with Projective Geometric Algebra for Efficient Robot Manipulation Learning]] (84.0% similar)
- [[2025-09-19/Semantic Exploration and Dense Mapping of Complex Environments using Ground Robot with Panoramic LiDAR-Camera Fusion_20250919|Semantic Exploration and Dense Mapping of Complex Environments using Ground Robot with Panoramic LiDAR-Camera Fusion]] (82.6% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15733v1 Announce Type: cross 
Abstract: Effective robotic manipulation relies on a precise understanding of 3D scene geometry, and one of the most straightforward ways to acquire such geometry is through multi-view observations. Motivated by this, we present GP3 -- a 3D geometry-aware robotic manipulation policy that leverages multi-view input. GP3 employs a spatial encoder to infer dense spatial features from RGB observations, which enable the estimation of depth and camera parameters, leading to a compact yet expressive 3D scene representation tailored for manipulation. This representation is fused with language instructions and translated into continuous actions via a lightweight policy head. Comprehensive experiments demonstrate that GP3 consistently outperforms state-of-the-art methods on simulated benchmarks. Furthermore, GP3 transfers effectively to real-world robots without depth sensors or pre-mapped environments, requiring only minimal fine-tuning. These results highlight GP3 as a practical, sensor-agnostic solution for geometry-aware robotic manipulation.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15733v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: íš¨ê³¼ì ì¸ ë¡œë´‡ ì¡°ì‘ì€ 3D ì¥ë©´ ê¸°í•˜í•™ì— ëŒ€í•œ ì •í™•í•œ ì´í•´ì— ì˜ì¡´í•˜ë©°, ì´ëŸ¬í•œ ê¸°í•˜í•™ì„ íšë“í•˜ëŠ” ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²• ì¤‘ í•˜ë‚˜ëŠ” ë‹¤ì¤‘ ì‹œì  ê´€ì°°ì„ í†µí•´ì„œì…ë‹ˆë‹¤. ì´ì— ì˜ê°ì„ ë°›ì•„, ìš°ë¦¬ëŠ” ë‹¤ì¤‘ ì‹œì  ì…ë ¥ì„ í™œìš©í•˜ëŠ” 3D ê¸°í•˜í•™ ì¸ì‹ ë¡œë´‡ ì¡°ì‘ ì •ì±…ì¸ GP3ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. GP3ëŠ” RGB ê´€ì°°ë¡œë¶€í„° ë°€ì§‘ ê³µê°„ íŠ¹ì§•ì„ ì¶”ë¡ í•˜ê¸° ìœ„í•´ ê³µê°„ ì¸ì½”ë”ë¥¼ ì‚¬ìš©í•˜ë©°, ì´ë¥¼ í†µí•´ ê¹Šì´ ë° ì¹´ë©”ë¼ ë§¤ê°œë³€ìˆ˜ë¥¼ ì¶”ì •í•˜ì—¬ ì¡°ì‘ì— ì í•©í•œ ê°„ê²°í•˜ë©´ì„œë„ í‘œí˜„ë ¥ ìˆëŠ” 3D ì¥ë©´ í‘œí˜„ì„ ìƒì„±í•©ë‹ˆë‹¤. ì´ í‘œí˜„ì€ ì–¸ì–´ ì§€ì‹œì™€ ê²°í•©ë˜ì–´ ê²½ëŸ‰ ì •ì±… í—¤ë“œë¥¼ í†µí•´ ì—°ì†ì ì¸ í–‰ë™ìœ¼ë¡œ ë³€í™˜ë©ë‹ˆë‹¤. ì¢…í•©ì ì¸ ì‹¤í—˜ì„ í†µí•´ GP3ê°€ ì‹œë®¬ë ˆì´ì…˜ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìµœì²¨ë‹¨ ë°©ë²•ë“¤ì„ ì¼ê´€ë˜ê²Œ ëŠ¥ê°€í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë”ìš±ì´, GP3ëŠ” ê¹Šì´ ì„¼ì„œë‚˜ ì‚¬ì „ ë§¤í•‘ëœ í™˜ê²½ ì—†ì´ë„ ì‹¤ì œ ë¡œë´‡ì— íš¨ê³¼ì ìœ¼ë¡œ ì „ì´ë˜ë©°, ìµœì†Œí•œì˜ ë¯¸ì„¸ ì¡°ì •ë§Œ í•„ìš”ë¡œ í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ê²°ê³¼ëŠ” GP3ê°€ ê¸°í•˜í•™ ì¸ì‹ ë¡œë´‡ ì¡°ì‘ì„ ìœ„í•œ ì‹¤ìš©ì ì´ê³  ì„¼ì„œì— êµ¬ì• ë°›ì§€ ì•ŠëŠ” ì†”ë£¨ì…˜ì„ì„ ê°•ì¡°í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì—ì„œëŠ” ë‹¤ì¤‘ ê´€ì°°ì„ í™œìš©í•œ 3D ê¸°í•˜í•™ì  ì´í•´ë¥¼ í†µí•´ ë¡œë´‡ ì¡°ì‘ì„ ê°œì„ í•˜ëŠ” GP3ë¼ëŠ” ì •ì±…ì„ ì œì•ˆí•©ë‹ˆë‹¤. GP3ëŠ” RGB ê´€ì°°ì—ì„œ ë°€ë„ ìˆëŠ” ê³µê°„ íŠ¹ì§•ì„ ì¶”ë¡ í•˜ëŠ” ê³µê°„ ì¸ì½”ë”ë¥¼ ì‚¬ìš©í•˜ì—¬ ê¹Šì´ì™€ ì¹´ë©”ë¼ ë§¤ê°œë³€ìˆ˜ë¥¼ ì¶”ì •í•˜ê³ , ì´ë¥¼ í†µí•´ ì¡°ì‘ì— ì í•©í•œ 3D ì¥ë©´ í‘œí˜„ì„ ìƒì„±í•©ë‹ˆë‹¤. ì´ í‘œí˜„ì€ ì–¸ì–´ ì§€ì‹œì™€ ê²°í•©ë˜ì–´ ì—°ì†ì ì¸ í–‰ë™ìœ¼ë¡œ ë³€í™˜ë©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, GP3ëŠ” ì‹œë®¬ë ˆì´ì…˜ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìµœì‹  ê¸°ë²•ë“¤ì„ ëŠ¥ê°€í•˜ë©°, ê¹Šì´ ì„¼ì„œë‚˜ ì‚¬ì „ ë§¤í•‘ëœ í™˜ê²½ ì—†ì´ë„ ì‹¤ì œ ë¡œë´‡ì— íš¨ê³¼ì ìœ¼ë¡œ ì ìš©ë  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤. ì´ëŠ” GP3ê°€ ì„¼ì„œì— êµ¬ì• ë°›ì§€ ì•ŠëŠ” ì‹¤ìš©ì ì¸ ê¸°í•˜í•™ ì¸ì‹ ë¡œë´‡ ì¡°ì‘ ì†”ë£¨ì…˜ì„ì„ ê°•ì¡°í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. GP3ëŠ” ë‹¤ì¤‘ ì‹œì  ì…ë ¥ì„ í™œìš©í•˜ì—¬ 3D ê¸°í•˜í•™ì  ì •ë³´ë¥¼ ì´í•´í•˜ëŠ” ë¡œë´‡ ì¡°ì‘ ì •ì±…ì„ ì œì•ˆí•©ë‹ˆë‹¤.

- 2. GP3ëŠ” RGB ê´€ì°°ì—ì„œ ë°€ì§‘ ê³µê°„ íŠ¹ì§•ì„ ì¶”ë¡ í•˜ì—¬ ê¹Šì´ ë° ì¹´ë©”ë¼ ë§¤ê°œë³€ìˆ˜ë¥¼ ì¶”ì •í•©ë‹ˆë‹¤.

- 3. ì´ ì‹œìŠ¤í…œì€ ì–¸ì–´ ì§€ì¹¨ê³¼ ê²°í•©í•˜ì—¬ ì—°ì†ì ì¸ í–‰ë™ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê²½ëŸ‰ ì •ì±… í—¤ë“œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

- 4. GP3ëŠ” ì‹œë®¬ë ˆì´ì…˜ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìµœì²¨ë‹¨ ë°©ë²•ë“¤ì„ ì¼ê´€ë˜ê²Œ ëŠ¥ê°€í•˜ëŠ” ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.

- 5. GP3ëŠ” ê¹Šì´ ì„¼ì„œë‚˜ ì‚¬ì „ ë§¤í•‘ëœ í™˜ê²½ ì—†ì´ë„ ìµœì†Œí•œì˜ ë¯¸ì„¸ ì¡°ì •ìœ¼ë¡œ ì‹¤ì œ ë¡œë´‡ì— íš¨ê³¼ì ìœ¼ë¡œ ì ìš©ë©ë‹ˆë‹¤.

---

*Generated on 2025-09-22 14:09:33*