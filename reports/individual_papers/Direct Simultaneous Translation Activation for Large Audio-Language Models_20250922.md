# Direct Simultaneous Translation Activation for Large Audio-Language Models

**Korean Title:** ëŒ€í˜• ì˜¤ë””ì˜¤-ì–¸ì–´ ëª¨ë¸ì„ ìœ„í•œ ì§ì ‘ ë™ì‹œ ë²ˆì—­ í™œì„±í™”

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[reports/digests/daily_digest_20250922|2025-09-22]] [[keywords/evolved/Simultaneous Data Augmentation|Simultaneous Data Augmentation]] [[keywords/specific/Read Write Strategies|Read Write Strategies]] [[keywords/broad/Simultaneous Speech to Text Translation|Simultaneous Speech to Text Translation]] [[keywords/broad/Large Audio Language Models|Large Audio Language Models]] [[keywords/unique/Simultaneous Self Augmentation|Simultaneous Self Augmentation]] [[categories/cs.CL|cs.CL]] [[2025-09-22/Exploring Fine-Tuning of Large Audio Language Models for Spoken Language Understanding under Limited Speech data_20250922|Exploring Fine-Tuning of Large Audio Language Models for Spoken Language Understanding under Limited Speech data]] (83.1% similar) [[2025-09-22/Chunk Based Speech Pre-training with High Resolution Finite Scalar Quantization_20250922|Chunk Based Speech Pre-training with High Resolution Finite Scalar Quantization]] (82.0% similar) [[2025-09-19/SpeechOp_ Inference-Time Task Composition for Generative Speech Processing_20250919|SpeechOp: Inference-Time Task Composition for Generative Speech Processing]] (81.9% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: Self Augmentation
**ğŸ”¬ Broad Technical**: Simultaneous Speech to Text Translation, Large Audio Language Models
**â­ Unique Technical**: Simultaneous Self Augmentation
## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Exploring Fine-Tuning of Large Audio Language Models for Spoken Language Understanding under Limited Speech data_20250922|Exploring Fine-Tuning of Large Audio Language Models for Spoken Language Understanding under Limited Speech data]] (83.1% similar)
- [[2025-09-22/Chunk Based Speech Pre-training with High Resolution Finite Scalar Quantization_20250922|Chunk Based Speech Pre-training with High Resolution Finite Scalar Quantization]] (82.0% similar)
- [[2025-09-19/SpeechOp_ Inference-Time Task Composition for Generative Speech Processing_20250919|SpeechOp Inference-Time Task Composition for Generative Speech Processing]] (81.9% similar)
- [[2025-09-17/SSL-SSAW_ Self-Supervised Learning with Sigmoid Self-Attention Weighting for Question-Based Sign Language Translation_20250917|SSL-SSAW Self-Supervised Learning with Sigmoid Self-Attention Weighting for Question-Based Sign Language Translation]] (81.8% similar)
- [[2025-09-19/Hybrid Autoregressive-Diffusion Model for Real-Time Sign Language Production_20250919|Hybrid Autoregressive-Diffusion Model for Real-Time Sign Language Production]] (81.3% similar)


**ArXiv ID**: [2509.15692](https://arxiv.org/abs/2509.15692)
**Published**: 2025-09-22
**Category**: cs.CL
**PDF**: [Download](https://arxiv.org/pdf/2509.15692.pdf)


**ArXiv ID**: [2509.15692](https://arxiv.org/abs/2509.15692)
**Published**: 2025-09-22
**Category**: cs.CL
**PDF**: [Download](https://arxiv.org/pdf/2509.15692.pdf)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: Self Augmentation
**â­ Unique Technical**: Simultaneous Self Augmentation
**ğŸ”¬ Broad Technical**: Simultaneous Speech to Text Translation, Large Audio Language Models

## ğŸ·ï¸ ì¶”ì¶œëœ í‚¤ì›Œë“œ



`Simultaneous Speech-to-Text Translation` â€¢ 

`Large Audio-Language Models` â€¢ 

`Read-Write Strategies` â€¢ 

`Simultaneous Self-Augmentation` â€¢ 

`Simultaneous Data Augmentation`



## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸

Similar papers will be displayed here based on embedding similarity.

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15692v1 Announce Type: cross 
Abstract: Simultaneous speech-to-text translation (Simul-S2TT) aims to translate speech into target text in real time, outputting translations while receiving source speech input, rather than waiting for the entire utterance to be spoken. Simul-S2TT research often modifies model architectures to implement read-write strategies. However, with the rise of large audio-language models (LALMs), a key challenge is how to directly activate Simul-S2TT capabilities in base models without additional architectural changes. In this paper, we introduce {\bf Simul}taneous {\bf S}elf-{\bf A}ugmentation ({\bf SimulSA}), a strategy that utilizes LALMs' inherent capabilities to obtain simultaneous data by randomly truncating speech and constructing partially aligned translation. By incorporating them into offline SFT data, SimulSA effectively bridges the distribution gap between offline translation during pretraining and simultaneous translation during inference. Experimental results demonstrate that augmenting only about {\bf 1\%} of the simultaneous data, compared to the full offline SFT data, can significantly activate LALMs' Simul-S2TT capabilities without modifications to model architecture or decoding strategy.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15692v1 ë°œí‘œ ìœ í˜•: êµì°¨  
ì´ˆë¡: ë™ì‹œ ìŒì„±-í…ìŠ¤íŠ¸ ë²ˆì—­(Simul-S2TT)ì€ ë°œí™” ì „ì²´ê°€ ëë‚˜ê¸°ë¥¼ ê¸°ë‹¤ë¦¬ì§€ ì•Šê³ , ì†ŒìŠ¤ ìŒì„± ì…ë ¥ì„ ë°›ìœ¼ë©´ì„œ ë²ˆì—­ì„ ì¶œë ¥í•˜ì—¬ ìŒì„±ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª©í‘œ í…ìŠ¤íŠ¸ë¡œ ë²ˆì—­í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤. Simul-S2TT ì—°êµ¬ëŠ” ì¢…ì¢… ì½ê¸°-ì“°ê¸° ì „ëµì„ êµ¬í˜„í•˜ê¸° ìœ„í•´ ëª¨ë¸ ì•„í‚¤í…ì²˜ë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ëŒ€í˜• ì˜¤ë””ì˜¤-ì–¸ì–´ ëª¨ë¸(LALMs)ì˜ ë¶€ìƒê³¼ í•¨ê»˜, ì¶”ê°€ì ì¸ ì•„í‚¤í…ì²˜ ë³€ê²½ ì—†ì´ ê¸°ë³¸ ëª¨ë¸ì—ì„œ Simul-S2TT ê¸°ëŠ¥ì„ ì§ì ‘ í™œì„±í™”í•˜ëŠ” ê²ƒì´ ì£¼ìš” ê³¼ì œì…ë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” LALMsì˜ ê³ ìœ í•œ ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ ìŒì„±ì„ ë¬´ì‘ìœ„ë¡œ ì˜ë¼ë‚´ê³  ë¶€ë¶„ì ìœ¼ë¡œ ì •ë ¬ëœ ë²ˆì—­ì„ êµ¬ì„±í•¨ìœ¼ë¡œì¨ ë™ì‹œ ë°ì´í„°ë¥¼ ì–»ëŠ” ì „ëµì¸ {\bf Simul}taneous {\bf S}elf-{\bf A}ugmentation ({\bf SimulSA})ì„ ì†Œê°œí•©ë‹ˆë‹¤. ì´ë¥¼ ì˜¤í”„ë¼ì¸ SFT ë°ì´í„°ì— í†µí•©í•¨ìœ¼ë¡œì¨, SimulSAëŠ” ì‚¬ì „ í•™ìŠµ ì¤‘ ì˜¤í”„ë¼ì¸ ë²ˆì—­ê³¼ ì¶”ë¡  ì¤‘ ë™ì‹œ ë²ˆì—­ ê°„ì˜ ë¶„í¬ ê²©ì°¨ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì—°ê²°í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ëª¨ë¸ ì•„í‚¤í…ì²˜ë‚˜ ë””ì½”ë”© ì „ëµì„ ìˆ˜ì •í•˜ì§€ ì•Šê³ ë„ ì „ì²´ ì˜¤í”„ë¼ì¸ SFT ë°ì´í„°ì— ë¹„í•´ ì•½ {\bf 1\%}ì˜ ë™ì‹œ ë°ì´í„°ë§Œì„ ì¦ê°•í•¨ìœ¼ë¡œì¨ LALMsì˜ Simul-S2TT ê¸°ëŠ¥ì„ í¬ê²Œ í™œì„±í™”í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì‹¤ì‹œê°„ ìŒì„±-í…ìŠ¤íŠ¸ ë²ˆì—­(Simul-S2TT)ì˜ ìƒˆë¡œìš´ ì ‘ê·¼ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ ì—°êµ¬ëŠ” ëª¨ë¸ êµ¬ì¡°ë¥¼ ìˆ˜ì •í•˜ì—¬ ë²ˆì—­ì„ ìˆ˜í–‰í•˜ì§€ë§Œ, ì´ ë…¼ë¬¸ì—ì„œëŠ” ëŒ€í˜• ì˜¤ë””ì˜¤-ì–¸ì–´ ëª¨ë¸(LALMs)ì„ í™œìš©í•˜ì—¬ êµ¬ì¡° ë³€ê²½ ì—†ì´ Simul-S2TT ê¸°ëŠ¥ì„ í™œì„±í™”í•˜ëŠ” ë°©ë²•ì„ íƒêµ¬í•©ë‹ˆë‹¤. ì œì•ˆëœ SimulSA(Simultaneous Self-Augmentation) ì „ëµì€ ìŒì„±ì„ ë¬´ì‘ìœ„ë¡œ ì˜ë¼ë‚´ê³  ë¶€ë¶„ì ìœ¼ë¡œ ì •ë ¬ëœ ë²ˆì—­ì„ ìƒì„±í•˜ì—¬ ë™ì‹œ ë°ì´í„°ë¥¼ ì–»ìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì‚¬ì „ í•™ìŠµ ì‹œ ì˜¤í”„ë¼ì¸ ë²ˆì—­ê³¼ ì¶”ë¡  ì‹œ ì‹¤ì‹œê°„ ë²ˆì—­ ê°„ì˜ ë¶„í¬ ì°¨ì´ë¥¼ ì¤„ì…ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì „ì²´ ì˜¤í”„ë¼ì¸ ë°ì´í„°ì˜ ì•½ 1%ë§Œì„ ë™ì‹œ ë°ì´í„°ë¡œ ì¦ê°•í•´ë„ ëª¨ë¸ êµ¬ì¡°ë‚˜ ë””ì½”ë”© ì „ëµì˜ ë³€ê²½ ì—†ì´ LALMsì˜ Simul-S2TT ê¸°ëŠ¥ì„ í¬ê²Œ í™œì„±í™”í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸


- 1. Simul-S2TTëŠ” ì‹¤ì‹œê°„ìœ¼ë¡œ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë²ˆì—­í•˜ëŠ” ê¸°ìˆ ë¡œ, ì „ì²´ ë°œí™”ê°€ ëë‚˜ê¸° ì „ì— ë²ˆì—­ì„ ì¶œë ¥í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•œë‹¤.

- 2. SimulSAëŠ” ëŒ€í˜• ì˜¤ë””ì˜¤-ì–¸ì–´ ëª¨ë¸(LALMs)ì˜ ë‚´ì¬ëœ ëŠ¥ë ¥ì„ í™œìš©í•˜ì—¬, ìŒì„±ì„ ë¬´ì‘ìœ„ë¡œ ì˜ë¼ë‚´ê³  ë¶€ë¶„ì ìœ¼ë¡œ ì •ë ¬ëœ ë²ˆì—­ì„ êµ¬ì„±í•˜ëŠ” ì „ëµì´ë‹¤.

- 3. SimulSAëŠ” ì‚¬ì „ í›ˆë ¨ ì¤‘ ì˜¤í”„ë¼ì¸ ë²ˆì—­ê³¼ ì¶”ë¡  ì¤‘ ë™ì‹œ ë²ˆì—­ ê°„ì˜ ë¶„í¬ ì°¨ì´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì¤„ì¸ë‹¤.

- 4. SimulSAë¥¼ í†µí•´ ì „ì²´ ì˜¤í”„ë¼ì¸ SFT ë°ì´í„°ì˜ ì•½ 1%ë§Œì„ ë™ì‹œ ë°ì´í„°ë¡œ ì¦ê°•í•˜ì—¬, ëª¨ë¸ ì•„í‚¤í…ì²˜ë‚˜ ë””ì½”ë”© ì „ëµì„ ë³€ê²½í•˜ì§€ ì•Šê³ ë„ LALMsì˜ Simul-S2TT ê¸°ëŠ¥ì„ í™œì„±í™”í•  ìˆ˜ ìˆë‹¤.


---

*Generated on 2025-09-22 16:32:12*