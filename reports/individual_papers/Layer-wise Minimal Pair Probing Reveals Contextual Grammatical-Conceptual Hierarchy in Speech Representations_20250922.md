# Layer-wise Minimal Pair Probing Reveals Contextual Grammatical-Conceptual Hierarchy in Speech Representations

**Korean Title:** ì¸µë³„ ìµœì†Œ ìŒ íƒìƒ‰ì„ í†µí•´ ìŒì„± í‘œí˜„ì—ì„œ ë§¥ë½ì  ë¬¸ë²•-ê°œë…ì  ê³„ì¸µ êµ¬ì¡°ë¥¼ ë°íˆë‹¤

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[reports/digests/daily_digest_20250922|2025-09-22]] [[keywords/evolved/Contextual Grammatical-Conceptual Hierarchy|Contextual Grammatical-Conceptual Hierarchy]] [[keywords/specific/Self-supervised Learning|Self-supervised Learning]] [[keywords/specific/Automatic Speech Recognition|Automatic Speech Recognition]] [[keywords/broad/Transformer|Transformer]] [[keywords/broad/Speech Language Models|Speech Language Models]] [[categories/cs.CL|cs.CL]] [[2025-09-22/Exploring Fine-Tuning of Large Audio Language Models for Spoken Language Understanding under Limited Speech data_20250922|Exploring Fine-Tuning of Large Audio Language Models for Spoken Language Understanding under Limited Speech data]] (82.3% similar) [[2025-09-22/Session-Level Spoken Language Assessment with a Multimodal Foundation Model via Multi-Target Learning_20250922|Session-Level Spoken Language Assessment with a Multimodal Foundation Model via Multi-Target Learning]] (81.9% similar) [[2025-09-17/Do Large Language Models Understand Word Senses_20250917|Do Large Language Models Understand Word Senses?]] (81.7% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: Self-supervised Learning, Automatic Speech Recognition
**ğŸ”¬ Broad Technical**: Transformer, Speech Language Models
## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Exploring Fine-Tuning of Large Audio Language Models for Spoken Language Understanding under Limited Speech data_20250922|Exploring Fine-Tuning of Large Audio Language Models for Spoken Language Understanding under Limited Speech data]] (82.3% similar)
- [[2025-09-22/Session-Level Spoken Language Assessment with a Multimodal Foundation Model via Multi-Target Learning_20250922|Session-Level Spoken Language Assessment with a Multimodal Foundation Model via Multi-Target Learning]] (81.9% similar)
- [[2025-09-17/Do Large Language Models Understand Word Senses_20250917|Do Large Language Models Understand Word Senses]] (81.7% similar)
- [[2025-09-18/TICL_ Text-Embedding KNN For Speech In-Context Learning Unlocks Speech Recognition Abilities of Large Multimodal Models_20250918|TICL Text-Embedding KNN For Speech In-Context Learning Unlocks Speech Recognition Abilities of Large Multimodal Models]] (81.3% similar)
- [[2025-09-22/How do Language Models Generate Slang_ A Systematic Comparison between Human and Machine-Generated Slang Usages_20250922|How do Language Models Generate Slang A Systematic Comparison between Human and Machine-Generated Slang Usages]] (81.2% similar)


**ArXiv ID**: [2509.15655](https://arxiv.org/abs/2509.15655)
**Published**: 2025-09-22
**Category**: cs.CL
**PDF**: [Download](https://arxiv.org/pdf/2509.15655.pdf)


**ArXiv ID**: [2509.15655](https://arxiv.org/abs/2509.15655)
**Published**: 2025-09-22
**Category**: cs.CL
**PDF**: [Download](https://arxiv.org/pdf/2509.15655.pdf)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Contextual Grammatical-Conceptual Hierarchy
**ğŸ”— Specific Connectable**: Self-supervised Learning
**â­ Unique Technical**: Layer-wise Minimal Pair Probing
**ğŸ”¬ Broad Technical**: Transformer, Speech Language Models

## ğŸ·ï¸ ì¶”ì¶œëœ í‚¤ì›Œë“œ



`Transformer` â€¢ 

`Speech Language Models` â€¢ 

`Self-supervised Learning` â€¢ 

`Layer-wise Minimal Pair Probing` â€¢ 

`Contextual Grammatical-Conceptual Hierarchy`



## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸

Similar papers will be displayed here based on embedding similarity.

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15655v1 Announce Type: new 
Abstract: Transformer-based speech language models (SLMs) have significantly improved neural speech recognition and understanding. While existing research has examined how well SLMs encode shallow acoustic and phonetic features, the extent to which SLMs encode nuanced syntactic and conceptual features remains unclear. By drawing parallels with linguistic competence assessments for large language models, this study is the first to systematically evaluate the presence of contextual syntactic and semantic features across SLMs for self-supervised learning (S3M), automatic speech recognition (ASR), speech compression (codec), and as the encoder for auditory large language models (AudioLLMs). Through minimal pair designs and diagnostic feature analysis across 71 tasks spanning diverse linguistic levels, our layer-wise and time-resolved analysis uncovers that 1) all speech encode grammatical features more robustly than conceptual ones.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15655v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ ìŒì„± ì–¸ì–´ ëª¨ë¸(SLM)ì€ ì‹ ê²½ ìŒì„± ì¸ì‹ ë° ì´í•´ë¥¼ í¬ê²Œ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤. ê¸°ì¡´ ì—°êµ¬ì—ì„œëŠ” SLMì´ ì–•ì€ ìŒí–¥ ë° ìŒì„±ì  íŠ¹ì§•ì„ ì–¼ë§ˆë‚˜ ì˜ ì¸ì½”ë”©í•˜ëŠ”ì§€ì— ëŒ€í•´ ì¡°ì‚¬í–ˆì§€ë§Œ, SLMì´ ë¯¸ë¬˜í•œ êµ¬ë¬¸ì  ë° ê°œë…ì  íŠ¹ì§•ì„ ì–´ëŠ ì •ë„ë¡œ ì¸ì½”ë”©í•˜ëŠ”ì§€ëŠ” ì—¬ì „íˆ ë¶ˆë¶„ëª…í•©ë‹ˆë‹¤. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì— ëŒ€í•œ ì–¸ì–´ì  ëŠ¥ë ¥ í‰ê°€ì™€ì˜ ìœ ì‚¬ì„±ì„ í†µí•´, ë³¸ ì—°êµ¬ëŠ” ìê°€ ì§€ë„ í•™ìŠµ(S3M), ìë™ ìŒì„± ì¸ì‹(ASR), ìŒì„± ì••ì¶•(ì½”ë±), ê·¸ë¦¬ê³  ì²­ê° ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(AudioLLMs)ì˜ ì¸ì½”ë”ë¡œì„œ SLM ì „ë°˜ì— ê±¸ì³ ë§¥ë½ì  êµ¬ë¬¸ ë° ì˜ë¯¸ì  íŠ¹ì§•ì˜ ì¡´ì¬ë¥¼ ì²´ê³„ì ìœ¼ë¡œ í‰ê°€í•œ ìµœì´ˆì˜ ì—°êµ¬ì…ë‹ˆë‹¤. ìµœì†Œ ìŒ ì„¤ê³„ ë° ë‹¤ì–‘í•œ ì–¸ì–´ ìˆ˜ì¤€ì— ê±¸ì¹œ 71ê°œ ê³¼ì œì˜ ì§„ë‹¨ì  íŠ¹ì§• ë¶„ì„ì„ í†µí•´, ì¸µë³„ ë° ì‹œê°„ í•´ìƒ ë¶„ì„ì„ í†µí•´ 1) ëª¨ë“  ìŒì„±ì€ ê°œë…ì  íŠ¹ì§•ë³´ë‹¤ ë¬¸ë²•ì  íŠ¹ì§•ì„ ë” ê°•ë ¥í•˜ê²Œ ì¸ì½”ë”©í•œë‹¤ëŠ” ê²ƒì„ ë°í˜€ëƒˆìŠµë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” Transformer ê¸°ë°˜ ìŒì„± ì–¸ì–´ ëª¨ë¸(SLMs)ì´ ìŒì„± ì¸ì‹ ë° ì´í•´ì—ì„œ ì¤‘ìš”í•œ ë°œì „ì„ ì´ë£¨ì—ˆì§€ë§Œ, ë¬¸ë²•ì  ë° ê°œë…ì  íŠ¹ì§•ì„ ì–¼ë§ˆë‚˜ ì˜ ì¸ì½”ë”©í•˜ëŠ”ì§€ëŠ” ëª…í™•í•˜ì§€ ì•Šë‹¤ëŠ” ë¬¸ì œë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. SLMsì˜ ë¬¸ë§¥ì  ë¬¸ë²• ë° ì˜ë¯¸ì  íŠ¹ì§•ì„ ì²´ê³„ì ìœ¼ë¡œ í‰ê°€í•œ ìµœì´ˆì˜ ì—°êµ¬ë¡œ, ìê°€ ì§€ë„ í•™ìŠµ(S3M), ìë™ ìŒì„± ì¸ì‹(ASR), ìŒì„± ì••ì¶•(codec), ì²­ê° ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(AudioLLMs)ì—ì„œì˜ ì—­í• ì„ ë¶„ì„í•©ë‹ˆë‹¤. 71ê°œì˜ ë‹¤ì–‘í•œ ì–¸ì–´ ìˆ˜ì¤€ ê³¼ì œë¥¼ í†µí•´ ìµœì†Œ ìŒ ì„¤ê³„ ë° ì§„ë‹¨ì  íŠ¹ì§• ë¶„ì„ì„ ìˆ˜í–‰í•œ ê²°ê³¼, ëª¨ë“  ìŒì„± ëª¨ë¸ì´ ê°œë…ì  íŠ¹ì§•ë³´ë‹¤ ë¬¸ë²•ì  íŠ¹ì§•ì„ ë” ê°•ë ¥í•˜ê²Œ ì¸ì½”ë”©í•œë‹¤ëŠ” ê²ƒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸


- 1. Transformer ê¸°ë°˜ ìŒì„± ì–¸ì–´ ëª¨ë¸(SLMs)ì€ ì‹ ê²½ ìŒì„± ì¸ì‹ ë° ì´í•´ë¥¼ í¬ê²Œ í–¥ìƒì‹œì¼°ë‹¤.

- 2. SLMsê°€ ì–•ì€ ìŒí–¥ ë° ìŒì„± íŠ¹ì§•ì„ ì¸ì½”ë”©í•˜ëŠ” ëŠ¥ë ¥ì€ ì—°êµ¬ë˜ì—ˆìœ¼ë‚˜, êµ¬ë¬¸ì  ë° ê°œë…ì  íŠ¹ì§• ì¸ì½”ë”© ëŠ¥ë ¥ì€ ëª…í™•í•˜ì§€ ì•Šë‹¤.

- 3. ë³¸ ì—°êµ¬ëŠ” SLMsê°€ ë¬¸ë§¥ì  êµ¬ë¬¸ ë° ì˜ë¯¸ì  íŠ¹ì§•ì„ ì¸ì½”ë”©í•˜ëŠ” ì •ë„ë¥¼ ì²´ê³„ì ìœ¼ë¡œ í‰ê°€í•œ ìµœì´ˆì˜ ì—°êµ¬ì´ë‹¤.

- 4. 71ê°œ ê³¼ì œë¥¼ í†µí•œ ê³„ì¸µë³„ ë° ì‹œê°„ í•´ìƒ ë¶„ì„ ê²°ê³¼, ìŒì„±ì€ ê°œë…ì  íŠ¹ì§•ë³´ë‹¤ ë¬¸ë²•ì  íŠ¹ì§•ì„ ë” ê°•ë ¥í•˜ê²Œ ì¸ì½”ë”©í•œë‹¤.


---

*Generated on 2025-09-22 16:25:21*