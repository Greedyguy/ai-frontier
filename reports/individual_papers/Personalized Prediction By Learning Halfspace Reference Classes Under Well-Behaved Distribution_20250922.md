# Personalized Prediction By Learning Halfspace Reference Classes Under Well-Behaved Distribution

**Korean Title:** ê°œì„ ëœ ë¶„í¬ í•˜ì—ì„œ ë°˜ê³µê°„ ê¸°ì¤€ í´ë˜ìŠ¤ë¥¼ í•™ìŠµí•˜ì—¬ ê°œì¸í™”ëœ ì˜ˆì¸¡

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Personalized Prediction

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Communication-Efficient and Privacy-Adaptable Mechanism for Federated Learning_20250919|Communication-Efficient and Privacy-Adaptable Mechanism for Federated Learning]] (79.7% similar)
- [[2025-09-22/Inference Offloading for Cost-Sensitive Binary Classification at the Edge_20250922|Inference Offloading for Cost-Sensitive Binary Classification at the Edge]] (79.6% similar)
- [[2025-09-18/Post-Hoc Split-Point Self-Consistency Verification for Efficient, Unified Quantification of Aleatoric and Epistemic Uncertainty in Deep Learning_20250918|Post-Hoc Split-Point Self-Consistency Verification for Efficient, Unified Quantification of Aleatoric and Epistemic Uncertainty in Deep Learning]] (79.6% similar)
- [[2025-09-18/Locally Explaining Prediction Behavior via Gradual Interventions and Measuring Property Gradients_20250918|Locally Explaining Prediction Behavior via Gradual Interventions and Measuring Property Gradients]] (79.5% similar)
- [[2025-09-22/Probabilistic Conformal Coverage Guarantees in Small-Data Settings_20250922|Probabilistic Conformal Coverage Guarantees in Small-Data Settings]] (79.3% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.15592v1 Announce Type: new 
Abstract: In machine learning applications, predictive models are trained to serve future queries across the entire data distribution. Real-world data often demands excessively complex models to achieve competitive performance, however, sacrificing interpretability. Hence, the growing deployment of machine learning models in high-stakes applications, such as healthcare, motivates the search for methods for accurate and explainable predictions. This work proposes a Personalized Prediction scheme, where an easy-to-interpret predictor is learned per query. In particular, we wish to produce a "sparse linear" classifier with competitive performance specifically on some sub-population that includes the query point. The goal of this work is to study the PAC-learnability of this prediction model for sub-populations represented by "halfspaces" in a label-agnostic setting. We first give a distribution-specific PAC-learning algorithm for learning reference classes for personalized prediction. By leveraging both the reference-class learning algorithm and a list learner of sparse linear representations, we prove the first upper bound, $O(\mathrm{opt}^{1/4} )$, for personalized prediction with sparse linear classifiers and homogeneous halfspace subsets. We also evaluate our algorithms on a variety of standard benchmark data sets.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.15592v1 ë°œí‘œ ìœ í˜•: ì‹ ê·œ  
ì´ˆë¡: ê¸°ê³„ í•™ìŠµ ì‘ìš© ë¶„ì•¼ì—ì„œ ì˜ˆì¸¡ ëª¨ë¸ì€ ì „ì²´ ë°ì´í„° ë¶„í¬ì— ê±¸ì³ ë¯¸ë˜ì˜ ì¿¼ë¦¬ë¥¼ ì²˜ë¦¬í•˜ë„ë¡ í›ˆë ¨ë©ë‹ˆë‹¤. ì‹¤ì œ ë°ì´í„°ëŠ” ê²½ìŸë ¥ ìˆëŠ” ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ê¸° ìœ„í•´ ì§€ë‚˜ì¹˜ê²Œ ë³µì¡í•œ ëª¨ë¸ì„ ìš”êµ¬í•˜ëŠ” ê²½ìš°ê°€ ë§ì§€ë§Œ, ì´ëŠ” í•´ì„ ê°€ëŠ¥ì„±ì„ í¬ìƒí•©ë‹ˆë‹¤. ë”°ë¼ì„œ ì˜ë£Œì™€ ê°™ì€ ê³ ìœ„í—˜ ì‘ìš© ë¶„ì•¼ì—ì„œ ê¸°ê³„ í•™ìŠµ ëª¨ë¸ì˜ ì‚¬ìš©ì´ ì¦ê°€í•¨ì— ë”°ë¼ ì •í™•í•˜ê³  ì„¤ëª… ê°€ëŠ¥í•œ ì˜ˆì¸¡ ë°©ë²•ì„ ì°¾ëŠ” ê²ƒì´ ì¤‘ìš”í•´ì¡ŒìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ëŠ” ì¿¼ë¦¬ë§ˆë‹¤ í•´ì„í•˜ê¸° ì‰¬ìš´ ì˜ˆì¸¡ê¸°ë¥¼ í•™ìŠµí•˜ëŠ” ê°œì¸í™”ëœ ì˜ˆì¸¡ ë°©ì‹ì„ ì œì•ˆí•©ë‹ˆë‹¤. íŠ¹íˆ, ìš°ë¦¬ëŠ” ì¿¼ë¦¬ í¬ì¸íŠ¸ë¥¼ í¬í•¨í•˜ëŠ” ì¼ë¶€ í•˜ìœ„ ì¸êµ¬ì—ì„œ ê²½ìŸë ¥ ìˆëŠ” ì„±ëŠ¥ì„ ê°€ì§„ "í¬ì†Œ ì„ í˜•" ë¶„ë¥˜ê¸°ë¥¼ ìƒì„±í•˜ê³ ì í•©ë‹ˆë‹¤. ì´ ì—°êµ¬ì˜ ëª©í‘œëŠ” ë ˆì´ë¸”ì— ë¬´ê´€í•œ ì„¤ì •ì—ì„œ "ë°˜ê³µê°„"ìœ¼ë¡œ í‘œí˜„ë˜ëŠ” í•˜ìœ„ ì¸êµ¬ì— ëŒ€í•œ ì´ ì˜ˆì¸¡ ëª¨ë¸ì˜ PAC í•™ìŠµ ê°€ëŠ¥ì„±ì„ ì—°êµ¬í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ë¨¼ì € ê°œì¸í™”ëœ ì˜ˆì¸¡ì„ ìœ„í•œ ì°¸ì¡° í´ë˜ìŠ¤ë¥¼ í•™ìŠµí•˜ê¸° ìœ„í•œ ë¶„í¬ íŠ¹í™” PAC í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì„ ì œì‹œí•©ë‹ˆë‹¤. ì°¸ì¡° í´ë˜ìŠ¤ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ê³¼ í¬ì†Œ ì„ í˜• í‘œí˜„ì˜ ë¦¬ìŠ¤íŠ¸ í•™ìŠµê¸°ë¥¼ í™œìš©í•˜ì—¬, í¬ì†Œ ì„ í˜• ë¶„ë¥˜ê¸°ì™€ ë™ì§ˆì  ë°˜ê³µê°„ í•˜ìœ„ ì§‘í•©ì„ ì‚¬ìš©í•œ ê°œì¸í™”ëœ ì˜ˆì¸¡ì— ëŒ€í•œ ìµœì´ˆì˜ ìƒí•œì„ , $O(\mathrm{opt}^{1/4} )$, ì„ ì¦ëª…í•©ë‹ˆë‹¤. ë˜í•œ ë‹¤ì–‘í•œ í‘œì¤€ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° ì„¸íŠ¸ì—ì„œ ìš°ë¦¬ì˜ ì•Œê³ ë¦¬ì¦˜ì„ í‰ê°€í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” ê³ ìœ„í—˜ ë¶„ì•¼ì—ì„œì˜ ê¸°ê³„ í•™ìŠµ ëª¨ë¸ì˜ í•´ì„ ê°€ëŠ¥ì„±ê³¼ ì •í™•ì„±ì„ ê°œì„ í•˜ê¸° ìœ„í•´ ê°œì¸í™”ëœ ì˜ˆì¸¡ ë°©ì‹ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê° ì¿¼ë¦¬ì— ëŒ€í•´ í•´ì„ì´ ì‰¬ìš´ ì˜ˆì¸¡ê¸°ë¥¼ í•™ìŠµí•˜ì—¬, íŠ¹ì • í•˜ìœ„ ì§‘ë‹¨ì—ì„œ ê²½ìŸë ¥ ìˆëŠ” ì„±ëŠ¥ì„ ë°œíœ˜í•˜ëŠ” "í¬ì†Œ ì„ í˜•" ë¶„ë¥˜ê¸°ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ë ˆì´ë¸”ì— ë¬´ê´€í•œ ì„¤ì •ì—ì„œ í•˜ìœ„ ì§‘ë‹¨ì„ ë‚˜íƒ€ë‚´ëŠ” "ë°˜ê³µê°„"ì— ëŒ€í•œ PAC-í•™ìŠµ ê°€ëŠ¥ì„±ì„ ì¡°ì‚¬í•©ë‹ˆë‹¤. ì—°êµ¬ ê²°ê³¼, ê°œì¸í™”ëœ ì˜ˆì¸¡ì„ ìœ„í•œ ì°¸ì¡° í´ë˜ìŠ¤ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ê³¼ í¬ì†Œ ì„ í˜• í‘œí˜„ì˜ ëª©ë¡ í•™ìŠµê¸°ë¥¼ í™œìš©í•˜ì—¬, í¬ì†Œ ì„ í˜• ë¶„ë¥˜ê¸°ì™€ ë™ì§ˆì  ë°˜ê³µê°„ í•˜ìœ„ ì§‘í•©ì„ ì‚¬ìš©í•˜ëŠ” ê°œì¸í™”ëœ ì˜ˆì¸¡ì— ëŒ€í•´ ìµœì´ˆì˜ ìƒí•œì„  $O(\mathrm{opt}^{1/4} )$ì„ ì¦ëª…í–ˆìŠµë‹ˆë‹¤. ë‹¤ì–‘í•œ í‘œì¤€ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° ì„¸íŠ¸ì—ì„œ ì•Œê³ ë¦¬ì¦˜ì„ í‰ê°€í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì˜ ë³µì¡ì„±ì€ ì„±ëŠ¥ì„ ë†’ì´ì§€ë§Œ í•´ì„ ê°€ëŠ¥ì„±ì„ í¬ìƒì‹œí‚¨ë‹¤.

- 2. ì´ ì—°êµ¬ëŠ” ê° ì¿¼ë¦¬ì— ëŒ€í•´ í•´ì„ì´ ì‰¬ìš´ ì˜ˆì¸¡ê¸°ë¥¼ í•™ìŠµí•˜ëŠ” ê°œì¸í™”ëœ ì˜ˆì¸¡ ë°©ì‹ì„ ì œì•ˆí•œë‹¤.

- 3. ì¿¼ë¦¬ í¬ì¸íŠ¸ë¥¼ í¬í•¨í•˜ëŠ” í•˜ìœ„ ì¸êµ¬ ì§‘ë‹¨ì— ëŒ€í•´ ê²½ìŸë ¥ ìˆëŠ” ì„±ëŠ¥ì„ ê°€ì§„ "í¬ì†Œ ì„ í˜•" ë¶„ë¥˜ê¸°ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì´ ëª©í‘œì´ë‹¤.

- 4. ê°œì¸í™”ëœ ì˜ˆì¸¡ì„ ìœ„í•œ PAC-í•™ìŠµ ê°€ëŠ¥ì„±ì„ ì—°êµ¬í•˜ë©°, ë ˆì´ë¸”ì— ë¬´ê´€í•œ ì„¤ì •ì—ì„œ "ë°˜ê³µê°„"ìœ¼ë¡œ í‘œí˜„ëœ í•˜ìœ„ ì¸êµ¬ ì§‘ë‹¨ì„ ëŒ€ìƒìœ¼ë¡œ í•œë‹¤.

- 5. ì œì•ˆëœ ì•Œê³ ë¦¬ì¦˜ì€ ë‹¤ì–‘í•œ í‘œì¤€ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° ì„¸íŠ¸ì—ì„œ í‰ê°€ë˜ì—ˆë‹¤.

---

*Generated on 2025-09-22 15:20:50*