# LLMs Can Compensate for Deficiencies in Visual Representations

**Korean Title:** LLMì€ ì‹œê°ì  í‘œí˜„ì˜ ê²°í•¨ì„ ë³´ì™„í•  ìˆ˜ ìˆë‹¤.

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Dynamic Division of Labor in VLMs

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Robust Vision-Language Models via Tensor Decomposition_ A Defense Against Adversarial Attacks_20250922|Robust Vision-Language Models via Tensor Decomposition A Defense Against Adversarial Attacks]] (87.4% similar)
- [[2025-09-19/V-SEAM_ Visual Semantic Editing and Attention Modulating for Causal Interpretability of Vision-Language Models_20250919|V-SEAM Visual Semantic Editing and Attention Modulating for Causal Interpretability of Vision-Language Models]] (84.7% similar)
- [[2025-09-18/Singular Value Few-shot Adaptation of Vision-Language Models_20250918|Singular Value Few-shot Adaptation of Vision-Language Models]] (84.1% similar)
- [[2025-09-18/LLM-I_ LLMs are Naturally Interleaved Multimodal Creators_20250918|LLM-I LLMs are Naturally Interleaved Multimodal Creators]] (83.5% similar)
- [[2025-09-19/Decoupled Proxy Alignment_ Mitigating Language Prior Conflict for Multimodal Alignment in MLLM_20250919|Decoupled Proxy Alignment Mitigating Language Prior Conflict for Multimodal Alignment in MLLM]] (83.3% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2506.05439v2 Announce Type: replace-cross 
Abstract: Many vision-language models (VLMs) that prove very effective at a range of multimodal task, build on CLIP-based vision encoders, which are known to have various limitations. We investigate the hypothesis that the strong language backbone in VLMs compensates for possibly weak visual features by contextualizing or enriching them. Using three CLIP-based VLMs, we perform controlled self-attention ablations on a carefully designed probing task. Our findings show that despite known limitations, CLIP visual representations offer ready-to-read semantic information to the language decoder. However, in scenarios of reduced contextualization in the visual representations, the language decoder can largely compensate for the deficiency and recover performance. This suggests a dynamic division of labor in VLMs and motivates future architectures that offload more visual processing to the language decoder.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2506.05439v2 ë°œí‘œ ìœ í˜•: êµì°¨ ëŒ€ì²´  
ì´ˆë¡: ë‹¤ì–‘í•œ ë©€í‹°ëª¨ë‹¬ ì‘ì—…ì—ì„œ ë§¤ìš° íš¨ê³¼ì ì¸ ê²ƒìœ¼ë¡œ ì…ì¦ëœ ë§ì€ ë¹„ì „-ì–¸ì–´ ëª¨ë¸(VLM)ì€ ì—¬ëŸ¬ ê°€ì§€ ì œí•œ ì‚¬í•­ì´ ìˆëŠ” ê²ƒìœ¼ë¡œ ì•Œë ¤ì§„ CLIP ê¸°ë°˜ ë¹„ì „ ì¸ì½”ë”ë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¶•ë©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” VLMì˜ ê°•ë ¥í•œ ì–¸ì–´ ë°±ë³¸ì´ ì‹œê°ì  íŠ¹ì§•ì´ ì•½í•  ìˆ˜ ìˆëŠ” ë¶€ë¶„ì„ ë§¥ë½í™”í•˜ê±°ë‚˜ í’ë¶€í•˜ê²Œ í•˜ì—¬ ë³´ì™„í•œë‹¤ëŠ” ê°€ì„¤ì„ ì¡°ì‚¬í•©ë‹ˆë‹¤. ì„¸ ê°€ì§€ CLIP ê¸°ë°˜ VLMì„ ì‚¬ìš©í•˜ì—¬ ì‹ ì¤‘í•˜ê²Œ ì„¤ê³„ëœ íƒìƒ‰ ì‘ì—…ì—ì„œ ì œì–´ëœ ìê¸° ì£¼ì˜ ì†Œê±°ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì—°êµ¬ ê²°ê³¼ëŠ” ì•Œë ¤ì§„ ì œí•œ ì‚¬í•­ì—ë„ ë¶ˆêµ¬í•˜ê³  CLIP ì‹œê°ì  í‘œí˜„ì´ ì–¸ì–´ ë””ì½”ë”ì— ì¤€ë¹„ëœ ì˜ë¯¸ ì •ë³´ë¥¼ ì œê³µí•œë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì‹œê°ì  í‘œí˜„ì—ì„œ ë§¥ë½í™”ê°€ ì¤„ì–´ë“  ì‹œë‚˜ë¦¬ì˜¤ì—ì„œëŠ” ì–¸ì–´ ë””ì½”ë”ê°€ ì£¼ë¡œ ê²°í•ì„ ë³´ì™„í•˜ê³  ì„±ëŠ¥ì„ íšŒë³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” VLMì—ì„œì˜ ë™ì  ì‘ì—… ë¶„ë‹´ì„ ì‹œì‚¬í•˜ë©°, ë” ë§ì€ ì‹œê°ì  ì²˜ë¦¬ë¥¼ ì–¸ì–´ ë””ì½”ë”ë¡œ ì „ê°€í•˜ëŠ” ë¯¸ë˜ ì•„í‚¤í…ì²˜ì— ëŒ€í•œ ë™ê¸°ë¥¼ ë¶€ì—¬í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ CLIP ê¸°ë°˜ ë¹„ì „-ì–¸ì–´ ëª¨ë¸(VLM)ì˜ ì‹œê° ì¸ì½”ë”ê°€ ê°€ì§„ í•œê³„ë¥¼ ì–¸ì–´ ë°±ë³¸ì´ ë³´ì™„í•  ìˆ˜ ìˆë‹¤ëŠ” ê°€ì„¤ì„ ê²€ì¦í•©ë‹ˆë‹¤. ì„¸ ê°€ì§€ CLIP ê¸°ë°˜ VLMì„ ì‚¬ìš©í•˜ì—¬ ìê°€ ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì„ ì¡°ì ˆí•œ ì‹¤í—˜ì„ ìˆ˜í–‰í•œ ê²°ê³¼, CLIPì˜ ì‹œê° í‘œí˜„ì´ ì–¸ì–´ ë””ì½”ë”ì— ì˜ë¯¸ ì •ë³´ë¥¼ ì œê³µí•¨ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ì‹œê° í‘œí˜„ì˜ ë§¥ë½í™”ê°€ ì¤„ì–´ë“  ìƒí™©ì—ì„œë„ ì–¸ì–´ ë””ì½”ë”ê°€ ì„±ëŠ¥ì„ íšŒë³µí•  ìˆ˜ ìˆìŒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” VLMì—ì„œ ì‹œê° ì²˜ë¦¬ì˜ ì¼ë¶€ë¥¼ ì–¸ì–´ ë””ì½”ë”ì— ë§¡ê¸°ëŠ” ìƒˆë¡œìš´ ì•„í‚¤í…ì²˜ ê°œë°œì„ ì œì•ˆí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. CLIP ê¸°ë°˜ ë¹„ì „ ì¸ì½”ë”ëŠ” ì—¬ëŸ¬ í•œê³„ê°€ ìˆì§€ë§Œ, VLMì˜ ê°•ë ¥í•œ ì–¸ì–´ ë°±ë³¸ì´ ì´ë¥¼ ë³´ì™„í•  ìˆ˜ ìˆë‹¤.

- 2. ì‹¤í—˜ ê²°ê³¼, CLIPì˜ ë¹„ì£¼ì–¼ í‘œí˜„ì€ ì–¸ì–´ ë””ì½”ë”ì— ì¦‰ì‹œ í•´ë… ê°€ëŠ¥í•œ ì˜ë¯¸ ì •ë³´ë¥¼ ì œê³µí•œë‹¤.

- 3. ë¹„ì£¼ì–¼ í‘œí˜„ì˜ ë§¥ë½í™”ê°€ ì¤„ì–´ë“  ìƒí™©ì—ì„œë„ ì–¸ì–´ ë””ì½”ë”ê°€ ì„±ëŠ¥ì„ íšŒë³µí•  ìˆ˜ ìˆë‹¤.

- 4. VLMì—ì„œëŠ” ë¹„ì£¼ì–¼ ì²˜ë¦¬ì™€ ì–¸ì–´ ë””ì½”ë”© ê°„ì˜ ë™ì  ì—­í•  ë¶„ë‹´ì´ ì¡´ì¬í•œë‹¤.

- 5. í–¥í›„ ì•„í‚¤í…ì²˜ëŠ” ë” ë§ì€ ë¹„ì£¼ì–¼ ì²˜ë¦¬ë¥¼ ì–¸ì–´ ë””ì½”ë”ì— ë§¡ê¸°ëŠ” ë°©í–¥ìœ¼ë¡œ ë°œì „í•  ê°€ëŠ¥ì„±ì´ ìˆë‹¤.

---

*Generated on 2025-09-22 14:53:41*