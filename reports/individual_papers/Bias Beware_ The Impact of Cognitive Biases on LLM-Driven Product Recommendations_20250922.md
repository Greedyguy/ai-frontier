# Bias Beware: The Impact of Cognitive Biases on LLM-Driven Product Recommendations

**Korean Title:** 편향 주의: 대형 언어 모델 기반 제품 추천에 대한 인지 편향의 영향

## 📋 메타데이터

## 📋 메타데이터

**Links**: [[reports/digests/daily_digest_20250922|2025-09-22]] [[keywords/evolved/Human Psychological Principles|Human Psychological Principles]] [[keywords/specific/Adversarial Manipulation|Adversarial Manipulation]] [[keywords/broad/Large Language Models|Large Language Models]] [[keywords/unique/Cognitive Bias Strategies|Cognitive Bias Strategies]] [[categories/cs.CL|cs.CL]] [[2025-09-17/Simulating a Bias Mitigation Scenario in Large Language Models_20250917|Simulating a Bias Mitigation Scenario in Large Language Models]] (88.2% similar) [[2025-09-18/How Does Cognitive Bias Affect Large Language Models A Case Study on the Anchoring Effect in Price Negotiation Simulations_20250918|How Does Cognitive Bias Affect Large Language Models? A Case Study on the Anchoring Effect in Price Negotiation Simulations]] (87.9% similar) [[2025-09-18/Do LLMs Align Human Values Regarding Social Biases Judging and Explaining Social Biases with LLMs_20250918|Do LLMs Align Human Values Regarding Social Biases? Judging and Explaining Social Biases with LLMs]] (86.4% similar)

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Bias-aware Product Recommendations
**🔗 Specific Connectable**: Adversarial Manipulation
**🔬 Broad Technical**: Large Language Models
**⭐ Unique Technical**: Cognitive Bias Strategies
## 🔗 유사한 논문
- [[2025-09-17/Simulating a Bias Mitigation Scenario in Large Language Models_20250917|Simulating a Bias Mitigation Scenario in Large Language Models]] (88.2% similar)
- [[2025-09-18/How Does Cognitive Bias Affect Large Language Models A Case Study on the Anchoring Effect in Price Negotiation Simulations_20250918|How Does Cognitive Bias Affect Large Language Models A Case Study on the Anchoring Effect in Price Negotiation Simulations]] (87.9% similar)
- [[2025-09-18/Do LLMs Align Human Values Regarding Social Biases Judging and Explaining Social Biases with LLMs_20250918|Do LLMs Align Human Values Regarding Social Biases Judging and Explaining Social Biases with LLMs]] (86.4% similar)
- [[2025-09-22/Exploring the Impact of Personality Traits on LLM Bias and Toxicity_20250922|Exploring the Impact of Personality Traits on LLM Bias and Toxicity]] (86.0% similar)
- [[2025-09-22/REFER_ Mitigating Bias in Opinion Summarisation via Frequency Framed Prompting_20250922|REFER Mitigating Bias in Opinion Summarisation via Frequency Framed Prompting]] (84.5% similar)


**ArXiv ID**: [2502.01349](https://arxiv.org/abs/2502.01349)
**Published**: 2025-09-22
**Category**: cs.CL
**PDF**: [Download](https://arxiv.org/pdf/2502.01349.pdf)


**ArXiv ID**: [2502.01349](https://arxiv.org/abs/2502.01349)
**Published**: 2025-09-22
**Category**: cs.CL
**PDF**: [Download](https://arxiv.org/pdf/2502.01349.pdf)

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Psychological Principles in AI
**🔗 Specific Connectable**: Adversarial Manipulation
**⭐ Unique Technical**: Cognitive Bias Strategies
**🔬 Broad Technical**: Large Language Models

## 🏷️ 추출된 키워드



`Large Language Models` • 

`Adversarial Manipulation` • 

`Cognitive Bias Strategies` • 

`Black-box Adversarial Strategies`



## 🔗 유사한 논문

Similar papers will be displayed here based on embedding similarity.

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2502.01349v3 Announce Type: replace 
Abstract: The advent of Large Language Models (LLMs) has revolutionized product recommenders, yet their susceptibility to adversarial manipulation poses critical challenges, particularly in real-world commercial applications. Our approach is the first one to tap into human psychological principles, seamlessly modifying product descriptions, making such manipulations hard to detect. In this work, we investigate cognitive biases as black-box adversarial strategies, drawing parallels between their effects on LLMs and human purchasing behavior. Through extensive evaluation across models of varying scale, we find that certain biases, such as social proof, consistently boost product recommendation rate and ranking, while others, like scarcity and exclusivity, surprisingly reduce visibility. Our results demonstrate that cognitive biases are deeply embedded in state-of-the-art LLMs, leading to highly unpredictable behavior in product recommendations and posing significant challenges for effective mitigation.

## 🔍 Abstract (한글 번역)

arXiv:2502.01349v3 발표 유형: 교체  
초록: 대형 언어 모델(LLMs)의 등장은 제품 추천 시스템에 혁신을 가져왔지만, 이들이 적대적 조작에 취약하다는 점은 특히 실제 상업적 응용에서 중요한 도전 과제를 제기합니다. 우리의 접근법은 인간 심리학 원칙을 활용하여 제품 설명을 매끄럽게 수정함으로써 이러한 조작을 감지하기 어렵게 만드는 최초의 시도입니다. 이 연구에서는 인지 편향을 블랙박스 적대적 전략으로 조사하여, LLM과 인간의 구매 행동에 미치는 영향을 비교합니다. 다양한 규모의 모델에 대한 광범위한 평가를 통해, 사회적 증거와 같은 특정 편향이 제품 추천 비율과 순위를 일관되게 높이는 반면, 희소성과 독점성 같은 다른 편향은 놀랍게도 가시성을 감소시킨다는 것을 발견했습니다. 우리의 결과는 인지 편향이 최첨단 LLM에 깊이 내재되어 있어 제품 추천에서 매우 예측 불가능한 행동을 초래하며 효과적인 완화를 위한 중요한 도전 과제를 제시한다는 것을 보여줍니다.

## 📝 요약

대형 언어 모델(LLM)의 발전은 제품 추천 시스템에 혁신을 가져왔지만, 적대적 조작에 취약하다는 문제가 있습니다. 본 연구는 인간의 심리적 원칙을 활용하여 제품 설명을 수정함으로써 이러한 조작을 탐지하기 어렵게 만드는 최초의 접근법을 제안합니다. 우리는 인지 편향을 블랙박스 적대적 전략으로 조사하여, LLM과 인간의 구매 행동에 미치는 영향을 비교했습니다. 다양한 규모의 모델 평가를 통해, 사회적 증거와 같은 편향은 제품 추천률과 순위를 높이는 반면, 희소성과 독점성은 가시성을 감소시킨다는 것을 발견했습니다. 이러한 결과는 인지 편향이 최신 LLM에 깊이 내재되어 있어 제품 추천에서 예측 불가능한 행동을 초래하고, 효과적인 완화에 큰 도전 과제를 제시함을 보여줍니다.

## 🎯 주요 포인트


- 1. 대형 언어 모델(LLMs)의 발전은 제품 추천 시스템에 혁신을 가져왔으나, 적대적 조작에 취약하여 상업적 응용에 중요한 도전 과제를 제기한다.

- 2. 본 연구는 인간의 심리적 원칙을 활용하여 제품 설명을 교묘하게 수정함으로써 조작을 탐지하기 어렵게 만드는 최초의 접근법을 제시한다.

- 3. 인지 편향을 블랙박스 적대 전략으로 조사한 결과, 사회적 증거와 같은 편향은 제품 추천율과 순위를 일관되게 높이는 반면, 희소성과 독점성은 가시성을 감소시키는 것으로 나타났다.

- 4. 인지 편향이 최첨단 LLM에 깊이 내재되어 있어 제품 추천에서 예측 불가능한 행동을 초래하고 효과적인 완화를 위한 중요한 도전 과제를 제시한다.


---

*Generated on 2025-09-22 16:33:13*