# MTS-DMAE: Dual-Masked Autoencoder for Unsupervised Multivariate Time Series Representation Learning

**Korean Title:** MTS-DMAE: ë¹„ì§€ë„ ë‹¤ë³€ëŸ‰ ì‹œê³„ì—´ í‘œí˜„ í•™ìŠµì„ ìœ„í•œ ì´ì¤‘ ë§ˆìŠ¤í¬ ìë™ ì¸ì½”ë”

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: Masked Autoencoder, Representation Learning

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/Masked Feature Modeling Enhances Adaptive Segmentation_20250918|Masked Feature Modeling Enhances Adaptive Segmentation]] (81.5% similar)
- [[2025-09-22/VMDNet_ Time Series Forecasting with Leakage-Free Samplewise Variational Mode Decomposition and Multibranch Decoding_20250922|VMDNet Time Series Forecasting with Leakage-Free Samplewise Variational Mode Decomposition and Multibranch Decoding]] (80.7% similar)
- [[2025-09-17/Bridging Past and Future_ Distribution-Aware Alignment for Time Series Forecasting_20250917|Bridging Past and Future Distribution-Aware Alignment for Time Series Forecasting]] (80.6% similar)
- [[2025-09-18/Beyond Marginals_ Learning Joint Spatio-Temporal Patterns for Multivariate Anomaly Detection_20250918|Beyond Marginals Learning Joint Spatio-Temporal Patterns for Multivariate Anomaly Detection]] (80.3% similar)
- [[2025-09-18/CSMoE_ An Efficient Remote Sensing Foundation Model with Soft Mixture-of-Experts_20250918|CSMoE An Efficient Remote Sensing Foundation Model with Soft Mixture-of-Experts]] (80.2% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.16078v1 Announce Type: new 
Abstract: Unsupervised multivariate time series (MTS) representation learning aims to extract compact and informative representations from raw sequences without relying on labels, enabling efficient transfer to diverse downstream tasks. In this paper, we propose Dual-Masked Autoencoder (DMAE), a novel masked time-series modeling framework for unsupervised MTS representation learning. DMAE formulates two complementary pretext tasks: (1) reconstructing masked values based on visible attributes, and (2) estimating latent representations of masked features, guided by a teacher encoder. To further improve representation quality, we introduce a feature-level alignment constraint that encourages the predicted latent representations to align with the teacher's outputs. By jointly optimizing these objectives, DMAE learns temporally coherent and semantically rich representations. Comprehensive evaluations across classification, regression, and forecasting tasks demonstrate that our approach achieves consistent and superior performance over competitive baselines.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.16078v1 ë°œí‘œ ìœ í˜•: ìƒˆë¡œìš´ ê²ƒ  
ì´ˆë¡: ë¹„ì§€ë„ ë‹¤ë³€ëŸ‰ ì‹œê³„ì—´(MTS) í‘œí˜„ í•™ìŠµì€ ë ˆì´ë¸”ì— ì˜ì¡´í•˜ì§€ ì•Šê³  ì›ì‹œ ì‹œí€€ìŠ¤ë¡œë¶€í„° ê°„ê²°í•˜ê³  ì •ë³´ê°€ í’ë¶€í•œ í‘œí˜„ì„ ì¶”ì¶œí•˜ì—¬ ë‹¤ì–‘í•œ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—…ìœ¼ë¡œì˜ íš¨ìœ¨ì ì¸ ì „ì´ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤. ì´ ë…¼ë¬¸ì—ì„œëŠ” ë¹„ì§€ë„ MTS í‘œí˜„ í•™ìŠµì„ ìœ„í•œ ìƒˆë¡œìš´ ë§ˆìŠ¤í¬ë“œ ì‹œê³„ì—´ ëª¨ë¸ë§ í”„ë ˆì„ì›Œí¬ì¸ Dual-Masked Autoencoder (DMAE)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. DMAEëŠ” ë‘ ê°€ì§€ ìƒí˜¸ ë³´ì™„ì ì¸ ì‚¬ì „ ì‘ì—…ì„ êµ¬ì„±í•©ë‹ˆë‹¤: (1) ë³´ì´ëŠ” ì†ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ ë§ˆìŠ¤í¬ëœ ê°’ì„ ì¬êµ¬ì„±í•˜ê³ , (2) êµì‚¬ ì¸ì½”ë”ì— ì˜í•´ ì•ˆë‚´ë˜ëŠ” ë§ˆìŠ¤í¬ëœ íŠ¹ì§•ì˜ ì ì¬ í‘œí˜„ì„ ì¶”ì •í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. í‘œí˜„ì˜ í’ˆì§ˆì„ ë”ìš± í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ì˜ˆì¸¡ëœ ì ì¬ í‘œí˜„ì´ êµì‚¬ì˜ ì¶œë ¥ê³¼ ì •ë ¬ë˜ë„ë¡ ìœ ë„í•˜ëŠ” íŠ¹ì§• ìˆ˜ì¤€ì˜ ì •ë ¬ ì œì•½ì„ ë„ì…í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ëª©í‘œë¥¼ ê³µë™ìœ¼ë¡œ ìµœì í™”í•¨ìœ¼ë¡œì¨ DMAEëŠ” ì‹œê°„ì ìœ¼ë¡œ ì¼ê´€ë˜ê³  ì˜ë¯¸ì ìœ¼ë¡œ í’ë¶€í•œ í‘œí˜„ì„ í•™ìŠµí•©ë‹ˆë‹¤. ë¶„ë¥˜, íšŒê·€ ë° ì˜ˆì¸¡ ì‘ì—… ì „ë°˜ì— ê±¸ì¹œ ì¢…í•©ì ì¸ í‰ê°€ë¥¼ í†µí•´ ìš°ë¦¬ì˜ ì ‘ê·¼ ë°©ì‹ì´ ê²½ìŸë ¥ ìˆëŠ” ê¸°ì¤€ì„ ì— ë¹„í•´ ì¼ê´€ë˜ê³  ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë‹¬ì„±í•¨ì„ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë¹„ì§€ë„ ë‹¤ë³€ëŸ‰ ì‹œê³„ì—´(MTS) í‘œí˜„ í•™ìŠµì„ ìœ„í•œ ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ì¸ Dual-Masked Autoencoder (DMAE)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. DMAEëŠ” ë‘ ê°€ì§€ ë³´ì¡° ê³¼ì œë¥¼ í†µí•´ ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ëª¨ë¸ë§í•©ë‹ˆë‹¤: (1) ë³´ì´ëŠ” ì†ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ ë§ˆìŠ¤í‚¹ëœ ê°’ì„ ì¬êµ¬ì„±í•˜ê³ , (2) êµì‚¬ ì¸ì½”ë”ì˜ ì§€ë„ë¥¼ ë°›ì•„ ë§ˆìŠ¤í‚¹ëœ íŠ¹ì§•ì˜ ì ì¬ í‘œí˜„ì„ ì¶”ì •í•©ë‹ˆë‹¤. ë˜í•œ, ì˜ˆì¸¡ëœ ì ì¬ í‘œí˜„ì´ êµì‚¬ì˜ ì¶œë ¥ê³¼ ì¼ì¹˜í•˜ë„ë¡ í•˜ëŠ” íŠ¹ì§• ìˆ˜ì¤€ ì •ë ¬ ì œì•½ì„ ë„ì…í•˜ì—¬ í‘œí˜„ì˜ í’ˆì§ˆì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì´ëŸ¬í•œ ëª©í‘œë¥¼ ê³µë™ ìµœì í™”í•¨ìœ¼ë¡œì¨ DMAEëŠ” ì‹œê°„ì ìœ¼ë¡œ ì¼ê´€ë˜ê³  ì˜ë¯¸ì ìœ¼ë¡œ í’ë¶€í•œ í‘œí˜„ì„ í•™ìŠµí•©ë‹ˆë‹¤. ë¶„ë¥˜, íšŒê·€, ì˜ˆì¸¡ ì‘ì—…ì— ëŒ€í•œ ì¢…í•©ì ì¸ í‰ê°€ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì´ ê¸°ì¡´ì˜ ê²½ìŸ ë°©ë²•ë“¤ë³´ë‹¤ ì¼ê´€ë˜ê³  ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì„ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Dual-Masked Autoencoder (DMAE)ëŠ” ë¹„ì§€ë„ ë‹¤ë³€ëŸ‰ ì‹œê³„ì—´ í‘œí˜„ í•™ìŠµì„ ìœ„í•œ ìƒˆë¡œìš´ ë§ˆìŠ¤í‚¹ ì‹œê³„ì—´ ëª¨ë¸ë§ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.

- 2. DMAEëŠ” ë‘ ê°€ì§€ ë³´ì™„ì ì¸ ì‚¬ì „ ê³¼ì œë¥¼ ì„¤ì •í•˜ì—¬, ê°€ì‹œ ì†ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ ë§ˆìŠ¤í‚¹ëœ ê°’ì„ ì¬êµ¬ì„±í•˜ê³ , êµì‚¬ ì¸ì½”ë”ì˜ ì§€ë„ë¥¼ ë°›ì•„ ë§ˆìŠ¤í‚¹ëœ íŠ¹ì§•ì˜ ì ì¬ í‘œí˜„ì„ ì¶”ì •í•©ë‹ˆë‹¤.

- 3. í‘œí˜„ì˜ ì§ˆì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´, ì˜ˆì¸¡ëœ ì ì¬ í‘œí˜„ì´ êµì‚¬ì˜ ì¶œë ¥ê³¼ ì •ë ¬ë˜ë„ë¡ í•˜ëŠ” íŠ¹ì§• ìˆ˜ì¤€ì˜ ì •ë ¬ ì œì•½ì„ ë„ì…í–ˆìŠµë‹ˆë‹¤.

- 4. DMAEëŠ” ì‹œê°„ì ìœ¼ë¡œ ì¼ê´€ë˜ê³  ì˜ë¯¸ì ìœ¼ë¡œ í’ë¶€í•œ í‘œí˜„ì„ í•™ìŠµí•˜ë©°, ë¶„ë¥˜, íšŒê·€, ì˜ˆì¸¡ ì‘ì—… ì „ë°˜ì—ì„œ ê²½ìŸë ¥ ìˆëŠ” ê¸°ì¤€ë³´ë‹¤ ì¼ê´€ë˜ê³  ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

---

*Generated on 2025-09-22 15:31:34*