# Spatial Understanding from Videos: Structured Prompts Meet Simulation Data

**Korean Title:** ë¹„ë””ì˜¤ë¡œë¶€í„°ì˜ ê³µê°„ ì´í•´: êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ì™€ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ì˜ ë§Œë‚¨

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-22|2025-09-22]] [[categories/cs.AI|cs.AI]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Vision-Language Models

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/See&Trek_ Training-Free Spatial Prompting for Multimodal Large Language Model_20250922|See&Trek Training-Free Spatial Prompting for Multimodal Large Language Model]] (85.3% similar)
- [[2025-09-22/GRE Suite_ Geo-localization Inference via Fine-Tuned Vision-Language Models and Enhanced Reasoning Chains_20250922|GRE Suite Geo-localization Inference via Fine-Tuned Vision-Language Models and Enhanced Reasoning Chains]] (84.7% similar)
- [[2025-09-19/SPATIALGEN_ Layout-guided 3D Indoor Scene Generation_20250919|SPATIALGEN Layout-guided 3D Indoor Scene Generation]] (83.1% similar)
- [[2025-09-19/V-SEAM_ Visual Semantic Editing and Attention Modulating for Causal Interpretability of Vision-Language Models_20250919|V-SEAM Visual Semantic Editing and Attention Modulating for Causal Interpretability of Vision-Language Models]] (83.0% similar)
- [[2025-09-22/SmolRGPT_ Efficient Spatial Reasoning for Warehouse Environments with 600M Parameters_20250922|SmolRGPT Efficient Spatial Reasoning for Warehouse Environments with 600M Parameters]] (82.9% similar)

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2506.03642v2 Announce Type: replace-cross 
Abstract: Visual-spatial understanding, the ability to infer object relationships and layouts from visual input, is fundamental to downstream tasks such as robotic navigation and embodied interaction. However, existing methods face spatial uncertainty and data scarcity, limiting the 3D spatial reasoning capability of pre-trained vision-language models (VLMs). To address these challenges, we present a unified framework for enhancing 3D spatial reasoning in pre-trained VLMs without modifying their architecture. This framework combines SpatialMind, a structured prompting strategy that decomposes complex scenes and questions into interpretable reasoning steps, with ScanForgeQA, a scalable question-answering dataset built from diverse 3D simulation scenes through an automated construction process designed for fine-tuning. Extensive experiments across multiple benchmarks demonstrate the individual and combined effectiveness of our prompting and fine-tuning strategies, and yield insights that may inspire future research on visual-spatial understanding.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2506.03642v2 ë°œí‘œ ìœ í˜•: êµì°¨ êµì²´  
ì´ˆë¡: ì‹œê°-ê³µê°„ì  ì´í•´, ì¦‰ ì‹œê° ì…ë ¥ìœ¼ë¡œë¶€í„° ê°ì²´ ê´€ê³„ì™€ ë°°ì¹˜ë¥¼ ì¶”ë¡ í•˜ëŠ” ëŠ¥ë ¥ì€ ë¡œë´‡ ë‚´ë¹„ê²Œì´ì…˜ ë° êµ¬í˜„ëœ ìƒí˜¸ì‘ìš©ê³¼ ê°™ì€ í›„ì† ì‘ì—…ì— í•„ìˆ˜ì ì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê¸°ì¡´ ë°©ë²•ë“¤ì€ ê³µê°„ì  ë¶ˆí™•ì‹¤ì„±ê³¼ ë°ì´í„° ë¶€ì¡±ì— ì§ë©´í•˜ì—¬ ì‚¬ì „ í•™ìŠµëœ ë¹„ì „-ì–¸ì–´ ëª¨ë¸(VLMs)ì˜ 3D ê³µê°„ ì¶”ë¡  ëŠ¥ë ¥ì„ ì œí•œí•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ì‚¬ì „ í•™ìŠµëœ VLMsì˜ ì•„í‚¤í…ì²˜ë¥¼ ìˆ˜ì •í•˜ì§€ ì•Šê³  3D ê³µê°„ ì¶”ë¡ ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ í†µí•© í”„ë ˆì„ì›Œí¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ë³µì¡í•œ ì¥ë©´ê³¼ ì§ˆë¬¸ì„ í•´ì„ ê°€ëŠ¥í•œ ì¶”ë¡  ë‹¨ê³„ë¡œ ë¶„í•´í•˜ëŠ” êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ ì „ëµì¸ SpatialMindì™€, ë¯¸ì„¸ ì¡°ì •ì„ ìœ„í•´ ì„¤ê³„ëœ ìë™í™”ëœ êµ¬ì¶• ê³¼ì •ì„ í†µí•´ ë‹¤ì–‘í•œ 3D ì‹œë®¬ë ˆì´ì…˜ ì¥ë©´ì—ì„œ êµ¬ì¶•ëœ í™•ì¥ ê°€ëŠ¥í•œ ì§ˆë¬¸-ì‘ë‹µ ë°ì´í„°ì…‹ì¸ ScanForgeQAë¥¼ ê²°í•©í•©ë‹ˆë‹¤. ì—¬ëŸ¬ ë²¤ì¹˜ë§ˆí¬ì— ê±¸ì¹œ ê´‘ë²”ìœ„í•œ ì‹¤í—˜ì€ ìš°ë¦¬ì˜ í”„ë¡¬í”„íŠ¸ ë° ë¯¸ì„¸ ì¡°ì • ì „ëµì˜ ê°œë³„ì  ë° ê²°í•©ëœ íš¨ê³¼ë¥¼ ì…ì¦í•˜ë©°, ì‹œê°-ê³µê°„ì  ì´í•´ì— ëŒ€í•œ ë¯¸ë˜ ì—°êµ¬ì— ì˜ê°ì„ ì¤„ ìˆ˜ ìˆëŠ” í†µì°°ë ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì‚¬ì „ í•™ìŠµëœ ë¹„ì „-ì–¸ì–´ ëª¨ë¸(VLM)ì˜ 3D ê³µê°„ ì¶”ë¡  ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ í†µí•© í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ ë°©ë²•ë“¤ì´ ê³µê°„ì  ë¶ˆí™•ì‹¤ì„±ê³¼ ë°ì´í„° ë¶€ì¡± ë¬¸ì œë¥¼ ê²ªëŠ” ë°˜ë©´, ì´ ì—°êµ¬ëŠ” VLMì˜ êµ¬ì¡°ë¥¼ ë³€ê²½í•˜ì§€ ì•Šê³ ë„ ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³ ì í•©ë‹ˆë‹¤. ì œì•ˆëœ í”„ë ˆì„ì›Œí¬ëŠ” ë³µì¡í•œ ì¥ë©´ê³¼ ì§ˆë¬¸ì„ í•´ì„ ê°€ëŠ¥í•œ ì¶”ë¡  ë‹¨ê³„ë¡œ ë¶„í•´í•˜ëŠ” êµ¬ì¡°ì  í”„ë¡¬í”„íŠ¸ ì „ëµì¸ SpatialMindì™€ ë‹¤ì–‘í•œ 3D ì‹œë®¬ë ˆì´ì…˜ ì¥ë©´ì—ì„œ ìë™ìœ¼ë¡œ êµ¬ì¶•ëœ ëŒ€ê·œëª¨ ì§ˆë¬¸-ì‘ë‹µ ë°ì´í„°ì…‹ì¸ ScanForgeQAë¥¼ ê²°í•©í•©ë‹ˆë‹¤. ì—¬ëŸ¬ ë²¤ì¹˜ë§ˆí¬ë¥¼ í†µí•œ ì‹¤í—˜ ê²°ê³¼, í”„ë¡¬í”„íŠ¸ì™€ ë¯¸ì„¸ ì¡°ì • ì „ëµì˜ ê°œë³„ì  ë° ê²°í•©ì  íš¨ê³¼ê°€ ì…ì¦ë˜ì—ˆìœ¼ë©°, ì´ëŠ” í–¥í›„ ì‹œê°-ê³µê°„ ì´í•´ ì—°êµ¬ì— ì˜ê°ì„ ì¤„ ìˆ˜ ìˆëŠ” í†µì°°ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì‹œê°-ê³µê°„ì  ì´í•´ëŠ” ë¡œë´‡ ë‚´ë¹„ê²Œì´ì…˜ ë° êµ¬í˜„ëœ ìƒí˜¸ì‘ìš©ê³¼ ê°™ì€ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—…ì— í•„ìˆ˜ì ì´ë‹¤.

- 2. ê¸°ì¡´ ë°©ë²•ì€ ê³µê°„ì  ë¶ˆí™•ì‹¤ì„±ê³¼ ë°ì´í„° ë¶€ì¡± ë¬¸ì œë¡œ ì¸í•´ ì‚¬ì „ í•™ìŠµëœ ë¹„ì „-ì–¸ì–´ ëª¨ë¸ì˜ 3D ê³µê°„ ì¶”ë¡  ëŠ¥ë ¥ì´ ì œí•œëœë‹¤.

- 3. SpatialMindëŠ” ë³µì¡í•œ ì¥ë©´ê³¼ ì§ˆë¬¸ì„ í•´ì„ ê°€ëŠ¥í•œ ì¶”ë¡  ë‹¨ê³„ë¡œ ë¶„í•´í•˜ëŠ” êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ ì „ëµì´ë‹¤.

- 4. ScanForgeQAëŠ” ë‹¤ì–‘í•œ 3D ì‹œë®¬ë ˆì´ì…˜ ì¥ë©´ì—ì„œ ìë™í™”ëœ êµ¬ì¶• ê³¼ì •ì„ í†µí•´ ë§Œë“¤ì–´ì§„ í™•ì¥ ê°€ëŠ¥í•œ ì§ˆë¬¸-ì‘ë‹µ ë°ì´í„°ì…‹ì´ë‹¤.

- 5. ì—¬ëŸ¬ ë²¤ì¹˜ë§ˆí¬ì—ì„œì˜ ê´‘ë²”ìœ„í•œ ì‹¤í—˜ì€ í”„ë¡¬í”„íŠ¸ ë° ë¯¸ì„¸ ì¡°ì • ì „ëµì˜ ê°œë³„ ë° ê²°í•©ëœ íš¨ê³¼ë¥¼ ì…ì¦í•œë‹¤.

---

*Generated on 2025-09-22 14:53:20*