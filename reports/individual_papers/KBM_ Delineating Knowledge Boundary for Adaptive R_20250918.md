
# KBM: Delineating Knowledge Boundary for Adaptive Retrieval in Large Language Models

**Korean Title:** KBM: ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì—ì„œ ì ì‘í˜• ê²€ìƒ‰ì„ ìœ„í•œ ì§€ì‹ ê²½ê³„ ì„ ì •

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-18|2025-09-18]] [[keywords/evolved/Multi-hop problems|Multi-hop problems]] [[keywords/broad/Large Language Models|Large Language Models]] [[keywords/broad/Retrieval-Augmented Generation|Retrieval-Augmented Generation]] [[keywords/specific/Knowledge Boundary Model|Knowledge Boundary Model]] [[keywords/unique/KBM|KBM]] [[categories/cs.CL|cs.CL]]

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Multi-hop problems
**ğŸ”¬ Broad Technical**: Large Language Models, Retrieval-Augmented Generation
**ğŸ”— Specific Connectable**: Knowledge Boundary Model
**â­ Unique Technical**: KBM

**ArXiv ID**: [2411.06207](https://arxiv.org/abs/2411.06207)
**Published**: 2025-09-18
**Category**: cs.CL
**PDF**: [Download](https://arxiv.org/pdf/2411.06207.pdf)


## ğŸ·ï¸ ì¶”ì¶œëœ í‚¤ì›Œë“œ



`Large Language Models` â€¢ 

`Retrieval-Augmented Generation` â€¢ 

`Knowledge Boundary Model` â€¢ 

`KBM` â€¢ 

`Multi-hop problems`



## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2411.06207v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) often struggle with dynamically changing knowledge and handling unknown static information. Retrieval-Augmented Generation (RAG) is employed to tackle these challenges and has a significant impact on improving LLM performance. In fact, we find that not all questions need to trigger RAG. By retrieving parts of knowledge unknown to the LLM and allowing the LLM to answer the rest, we can effectively reduce both time and computational costs. In our work, we propose a Knowledge Boundary Model (KBM) to express the known/unknown of a given question, and to determine whether a RAG needs to be triggered. Experiments conducted on 11 English and Chinese datasets illustrate that the KBM effectively delineates the knowledge boundary, significantly decreasing the proportion of retrievals required for optimal end-to-end performance. Furthermore, we evaluate the effectiveness of KBM in three complex scenarios: dynamic knowledge, long-tail static knowledge, and multi-hop problems, as well as its functionality as an external LLM plug-in.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2411.06207v2 ë°œí‘œ ìœ í˜•: ëŒ€ì²´
ìš”ì•½: ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLMs)ì€ ì¢…ì¢… ë™ì ìœ¼ë¡œ ë³€í™”í•˜ëŠ” ì§€ì‹ê³¼ ì•Œë ¤ì§€ì§€ ì•Šì€ ì •ì  ì •ë³´ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªìŠµë‹ˆë‹¤. ê²€ìƒ‰ ë³´ê°• ìƒì„±(RAG)ì€ ì´ëŸ¬í•œ ë„ì „ì— ëŒ€ì²˜í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë˜ë©° LLM ì„±ëŠ¥ í–¥ìƒì— ìƒë‹¹í•œ ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤. ì‚¬ì‹¤, ìš°ë¦¬ëŠ” ëª¨ë“  ì§ˆë¬¸ì´ RAGë¥¼ ë°œë™ì‹œí‚¬ í•„ìš”ê°€ ì—†ë‹¤ëŠ” ê²ƒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. LLMì´ ì•Œì§€ ëª»í•˜ëŠ” ì§€ì‹ì˜ ì¼ë¶€ë¥¼ ê²€ìƒ‰í•˜ì—¬ ë‚˜ë¨¸ì§€ë¥¼ ëŒ€ë‹µí•˜ê²Œ í•¨ìœ¼ë¡œì¨ ì‹œê°„ê³¼ ê³„ì‚° ë¹„ìš©ì„ íš¨ê³¼ì ìœ¼ë¡œ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” ì£¼ì–´ì§„ ì§ˆë¬¸ì˜ ì•Œë ¤ì§„/ì•Œë ¤ì§€ì§€ ì•Šì€ ê²ƒì„ í‘œí˜„í•˜ê³  RAGë¥¼ ë°œë™í•´ì•¼ í•˜ëŠ”ì§€ ê²°ì •í•˜ê¸° ìœ„í•´ ì§€ì‹ ê²½ê³„ ëª¨ë¸(KBM)ì„ ì œì•ˆí•©ë‹ˆë‹¤. 11ê°œì˜ ì˜ì–´ ë° ì¤‘êµ­ì–´ ë°ì´í„°ì…‹ì—ì„œ ìˆ˜í–‰ëœ ì‹¤í—˜ì€ KBMì´ ì§€ì‹ ê²½ê³„ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ êµ¬ë¶„í•˜ë©° ìµœì ì˜ end-to-end ì„±ëŠ¥ì„ ìœ„í•´ í•„ìš”í•œ ê²€ìƒ‰ ë¹„ìœ¨ì„ í¬ê²Œ ê°ì†Œì‹œí‚¨ë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë˜í•œ, ìš°ë¦¬ëŠ” KBMì˜ íš¨ê³¼ë¥¼ í‰ê°€í•˜ê¸° ìœ„í•´ ë™ì  ì§€ì‹, ë¡±í…Œì¼ ì •ì  ì§€ì‹, ë©€í‹°-í™‰ ë¬¸ì œì™€ ê°™ì€ ì„¸ ê°€ì§€ ë³µì¡í•œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ê·¸ ê¸°ëŠ¥ì„±ì„ í™•ì¸í•˜ê³  ì™¸ë¶€ LLM í”ŒëŸ¬ê·¸ì¸ìœ¼ë¡œì„œì˜ ê¸°ëŠ¥ì„±ì„ í‰ê°€í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì´ ë™ì ìœ¼ë¡œ ë³€í™”í•˜ëŠ” ì§€ì‹ê³¼ ì•Œë ¤ì§€ì§€ ì•Šì€ ì •ì  ì •ë³´ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ê²€ìƒ‰ ë³´ê°• ìƒì„±(RAG)ì„ ì‚¬ìš©í•œë‹¤. ìš°ë¦¬ëŠ” ëª¨ë“  ì§ˆë¬¸ì´ RAGë¥¼ ìœ ë°œì‹œí‚¬ í•„ìš”ê°€ ì—†ìŒì„ ë°œê²¬í•˜ì˜€ê³ , LLMì´ ì•Œì§€ ëª»í•˜ëŠ” ì§€ì‹ì˜ ì¼ë¶€ë¥¼ ê²€ìƒ‰í•˜ì—¬ ë‚˜ë¨¸ì§€ë¥¼ ëŒ€ë‹µí•˜ë„ë¡ í•¨ìœ¼ë¡œì¨ ì‹œê°„ê³¼ ê³„ì‚° ë¹„ìš©ì„ íš¨ê³¼ì ìœ¼ë¡œ ì¤„ì¼ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ ì…ì¦í•˜ì˜€ë‹¤. ìš°ë¦¬ëŠ” ì£¼ì–´ì§„ ì§ˆë¬¸ì˜ ì•Œë ¤ì§„/ì•Œë ¤ì§€ì§€ ì•Šì€ ë¶€ë¶„ì„ ë‚˜íƒ€ë‚´ê³  RAGë¥¼ ìœ ë°œí•´ì•¼ í•˜ëŠ”ì§€ë¥¼ ê²°ì •í•˜ê¸° ìœ„í•´ ì§€ì‹ ê²½ê³„ ëª¨ë¸(KBM)ì„ ì œì•ˆí•œë‹¤. ì˜ì–´ì™€ ì¤‘êµ­ì–´ ë°ì´í„°ì…‹ì—ì„œ ìˆ˜í–‰ëœ ì‹¤í—˜ ê²°ê³¼, KBMì€ ì§€ì‹ ê²½ê³„ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ë‚˜íƒ€ë‚´ì–´ ìµœì ì˜ ì„±ëŠ¥ì„ ìœ„í•´ í•„ìš”í•œ ê²€ìƒ‰ ë¹„ìœ¨ì„ í¬ê²Œ ê°ì†Œì‹œí‚¨ë‹¤. ë˜í•œ, ìš°ë¦¬ëŠ” ë™ì  ì§€ì‹, ì¥ê¸°ì  ì •ì  ì§€ì‹, ë‹¤ì¤‘ ì í”„ ë¬¸ì œì™€ ê°™ì€ ì„¸ ê°€ì§€ ë³µì¡í•œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ KBMì˜ íš¨ê³¼ì„±ì„ í‰ê°€í•˜ì˜€ìœ¼ë©° ì™¸ë¶€ LLM í”ŒëŸ¬ê·¸ì¸ìœ¼ë¡œì„œì˜ ê¸°ëŠ¥ì„±ì„ í™•ì¸í•˜ì˜€ë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸


- ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì€ ë™ì ìœ¼ë¡œ ë³€í•˜ëŠ” ì§€ì‹ê³¼ ì•Œë ¤ì§€ì§€ ì•Šì€ ì •ì  ì •ë³´ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤.

- RAGëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° ì¤‘ìš”í•œ ì˜í–¥ì„ ë¯¸ì¹œë‹¤.

- ì§€ì‹ ê²½ê³„ ëª¨ë¸(KBM)ì€ ì§ˆë¬¸ì˜ ì•Œë ¤ì§„/ì•Œë ¤ì§€ì§€ ì•Šì€ ë¶€ë¶„ì„ í‘œí˜„í•˜ê³  RAGë¥¼ íŠ¸ë¦¬ê±°í•  í•„ìš”ì„±ì„ ê²°ì •í•˜ëŠ” ë° íš¨ê³¼ì ì´ë‹¤.


---

*Generated on 2025-09-18 16:54:15*