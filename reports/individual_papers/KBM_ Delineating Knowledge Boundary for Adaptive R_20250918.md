
# KBM: Delineating Knowledge Boundary for Adaptive Retrieval in Large Language Models

**Korean Title:** KBM: 대규모 언어 모델에서 적응형 검색을 위한 지식 경계 선정

## 📋 메타데이터

**Links**: [[daily/2025-09-18|2025-09-18]] [[keywords/evolved/Multi-hop problems|Multi-hop problems]] [[keywords/broad/Large Language Models|Large Language Models]] [[keywords/broad/Retrieval-Augmented Generation|Retrieval-Augmented Generation]] [[keywords/specific/Knowledge Boundary Model|Knowledge Boundary Model]] [[keywords/unique/KBM|KBM]] [[categories/cs.CL|cs.CL]]

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Multi-hop problems
**🔬 Broad Technical**: Large Language Models, Retrieval-Augmented Generation
**🔗 Specific Connectable**: Knowledge Boundary Model
**⭐ Unique Technical**: KBM

**ArXiv ID**: [2411.06207](https://arxiv.org/abs/2411.06207)
**Published**: 2025-09-18
**Category**: cs.CL
**PDF**: [Download](https://arxiv.org/pdf/2411.06207.pdf)


## 🏷️ 추출된 키워드



`Large Language Models` • 

`Retrieval-Augmented Generation` • 

`Knowledge Boundary Model` • 

`KBM` • 

`Multi-hop problems`



## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2411.06207v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) often struggle with dynamically changing knowledge and handling unknown static information. Retrieval-Augmented Generation (RAG) is employed to tackle these challenges and has a significant impact on improving LLM performance. In fact, we find that not all questions need to trigger RAG. By retrieving parts of knowledge unknown to the LLM and allowing the LLM to answer the rest, we can effectively reduce both time and computational costs. In our work, we propose a Knowledge Boundary Model (KBM) to express the known/unknown of a given question, and to determine whether a RAG needs to be triggered. Experiments conducted on 11 English and Chinese datasets illustrate that the KBM effectively delineates the knowledge boundary, significantly decreasing the proportion of retrievals required for optimal end-to-end performance. Furthermore, we evaluate the effectiveness of KBM in three complex scenarios: dynamic knowledge, long-tail static knowledge, and multi-hop problems, as well as its functionality as an external LLM plug-in.

## 🔍 Abstract (한글 번역)

arXiv:2411.06207v2 발표 유형: 대체
요약: 대규모 언어 모델(LLMs)은 종종 동적으로 변화하는 지식과 알려지지 않은 정적 정보를 처리하는 데 어려움을 겪습니다. 검색 보강 생성(RAG)은 이러한 도전에 대처하기 위해 사용되며 LLM 성능 향상에 상당한 영향을 미칩니다. 사실, 우리는 모든 질문이 RAG를 발동시킬 필요가 없다는 것을 발견했습니다. LLM이 알지 못하는 지식의 일부를 검색하여 나머지를 대답하게 함으로써 시간과 계산 비용을 효과적으로 줄일 수 있습니다. 본 연구에서는 주어진 질문의 알려진/알려지지 않은 것을 표현하고 RAG를 발동해야 하는지 결정하기 위해 지식 경계 모델(KBM)을 제안합니다. 11개의 영어 및 중국어 데이터셋에서 수행된 실험은 KBM이 지식 경계를 효과적으로 구분하며 최적의 end-to-end 성능을 위해 필요한 검색 비율을 크게 감소시킨다는 것을 보여줍니다. 또한, 우리는 KBM의 효과를 평가하기 위해 동적 지식, 롱테일 정적 지식, 멀티-홉 문제와 같은 세 가지 복잡한 시나리오에서 그 기능성을 확인하고 외부 LLM 플러그인으로서의 기능성을 평가합니다.

## 📝 요약

이 연구는 대규모 언어 모델이 동적으로 변화하는 지식과 알려지지 않은 정적 정보를 처리하는 데 어려움을 겪는 문제를 해결하기 위해 검색 보강 생성(RAG)을 사용한다. 우리는 모든 질문이 RAG를 유발시킬 필요가 없음을 발견하였고, LLM이 알지 못하는 지식의 일부를 검색하여 나머지를 대답하도록 함으로써 시간과 계산 비용을 효과적으로 줄일 수 있다는 것을 입증하였다. 우리는 주어진 질문의 알려진/알려지지 않은 부분을 나타내고 RAG를 유발해야 하는지를 결정하기 위해 지식 경계 모델(KBM)을 제안한다. 영어와 중국어 데이터셋에서 수행된 실험 결과, KBM은 지식 경계를 효과적으로 나타내어 최적의 성능을 위해 필요한 검색 비율을 크게 감소시킨다. 또한, 우리는 동적 지식, 장기적 정적 지식, 다중 점프 문제와 같은 세 가지 복잡한 시나리오에서 KBM의 효과성을 평가하였으며 외부 LLM 플러그인으로서의 기능성을 확인하였다.

## 🎯 주요 포인트


- 대형 언어 모델은 동적으로 변하는 지식과 알려지지 않은 정적 정보를 처리하는 데 어려움을 겪는다.

- RAG는 대형 언어 모델의 성능을 향상시키는 데 중요한 영향을 미친다.

- 지식 경계 모델(KBM)은 질문의 알려진/알려지지 않은 부분을 표현하고 RAG를 트리거할 필요성을 결정하는 데 효과적이다.


---

*Generated on 2025-09-18 16:54:15*