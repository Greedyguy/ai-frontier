# Permutation recovery of spikes in noisy high-dimensional tensor estimation

**Korean Title:** ë…¸ì´ì¦ˆê°€ ìˆëŠ” ê³ ì°¨ì› í…ì„œ ì¶”ì •ì—ì„œ ìŠ¤íŒŒì´í¬ì˜ ìˆœì—´ ë³µì›

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[reports/digests/daily_digest_20250922|2025-09-22]] [[keywords/evolved/Permutation Recovery|Permutation Recovery]] [[keywords/specific/Gradient Flow|Gradient Flow]] [[keywords/specific/Maximum Likelihood Estimation|Maximum Likelihood Estimation]] [[keywords/broad/High Dimensional Estimation|High Dimensional Estimation]] [[keywords/unique/Multi Spiked Tensor Problem|Multi Spiked Tensor Problem]] [[categories/cs.LG|cs.LG]] [[2025-09-22/Personalized Federated Learning with Heat-Kernel Enhanced Tensorized Multi-View Clustering_20250922|Personalized Federated Learning with Heat-Kernel Enhanced Tensorized Multi-View Clustering]] (79.5% similar) [[2025-09-18/Probabilistic and nonlinear compressive sensing_20250918|Probabilistic and nonlinear compressive sensing]] (79.1% similar) [[2025-09-22/Adversarial Graph Fusion for Incomplete Multi-view Semi-supervised Learning with Tensorial Imputation_20250922|Adversarial Graph Fusion for Incomplete Multi-view Semi-supervised Learning with Tensorial Imputation]] (78.7% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: Gradient Flow, Maximum Likelihood Estimation
**ğŸ”¬ Broad Technical**: High-dimensional Estimation
**â­ Unique Technical**: Multi-spiked Tensor Problem
## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Personalized Federated Learning with Heat-Kernel Enhanced Tensorized Multi-View Clustering_20250922|Personalized Federated Learning with Heat-Kernel Enhanced Tensorized Multi-View Clustering]] (79.5% similar)
- [[2025-09-18/Probabilistic and nonlinear compressive sensing_20250918|Probabilistic and nonlinear compressive sensing]] (79.1% similar)
- [[2025-09-22/Adversarial Graph Fusion for Incomplete Multi-view Semi-supervised Learning with Tensorial Imputation_20250922|Adversarial Graph Fusion for Incomplete Multi-view Semi-supervised Learning with Tensorial Imputation]] (78.7% similar)
- [[2025-09-18/Sampling Method for Generalized Graph Signals with Pre-selected Vertices via DC Optimization_20250918|Sampling Method for Generalized Graph Signals with Pre-selected Vertices via DC Optimization]] (78.5% similar)
- [[2025-09-19/Structure-Preserving Margin Distribution Learning for High-Order Tensor Data with Low-Rank Decomposition_20250919|Structure-Preserving Margin Distribution Learning for High-Order Tensor Data with Low-Rank Decomposition]] (78.2% similar)


**ArXiv ID**: [2412.14650](https://arxiv.org/abs/2412.14650)
**Published**: 2025-09-22
**Category**: cs.LG
**PDF**: [Download](https://arxiv.org/pdf/2412.14650.pdf)


**ArXiv ID**: [2412.14650](https://arxiv.org/abs/2412.14650)
**Published**: 2025-09-22
**Category**: cs.LG
**PDF**: [Download](https://arxiv.org/pdf/2412.14650.pdf)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸš€ Evolved Concepts**: Permutation Recovery
**ğŸ”— Specific Connectable**: Gradient Flow, Maximum Likelihood Estimation
**â­ Unique Technical**: Multi Spiked Tensor Problem
**ğŸ”¬ Broad Technical**: High Dimensional Estimation

## ğŸ·ï¸ ì¶”ì¶œëœ í‚¤ì›Œë“œ



`High-dimensional Estimation` â€¢ 

`Gradient Flow` â€¢ 

`Maximum Likelihood Estimation` â€¢ 

`Multi-spiked Tensor Problem` â€¢ 

`Permutation Recovery`



## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸

Similar papers will be displayed here based on embedding similarity.

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2412.14650v3 Announce Type: replace-cross 
Abstract: We study the dynamics of gradient flow in high dimensions for the multi-spiked tensor problem, where the goal is to estimate $r$ unknown signal vectors (spikes) from noisy Gaussian tensor observations. Specifically, we analyze the maximum likelihood estimation procedure, which involves optimizing a highly nonconvex random function. We determine the sample complexity required for gradient flow to efficiently recover all spikes, without imposing any assumptions on the separation of the signal-to-noise ratios (SNRs). More precisely, our results provide the sample complexity required to guarantee recovery of the spikes up to a permutation. Our work builds on our companion paper [Ben Arous, Gerbelot, Piccolo 2024], which studies Langevin dynamics and determines the sample complexity and separation conditions for the SNRs necessary for ensuring exact recovery of the spikes (where the recovered permutation matches the identity). During the recovery process, the correlations between the estimators and the hidden vectors increase in a sequential manner. The order in which these correlations become significant depends on their initial values and the corresponding SNRs, which ultimately determines the permutation of the recovered spikes.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2412.14650v3 ë°œí‘œ ìœ í˜•: êµì°¨ êµì²´  
ì´ˆë¡: ìš°ë¦¬ëŠ” ë‹¤ì¤‘ ìŠ¤íŒŒì´í¬ í…ì„œ ë¬¸ì œì—ì„œ ê³ ì°¨ì›ì—ì„œì˜ ê·¸ë˜ë””ì–¸íŠ¸ íë¦„ì˜ ë™ì—­í•™ì„ ì—°êµ¬í•©ë‹ˆë‹¤. ì´ ë¬¸ì œì˜ ëª©í‘œëŠ” ë…¸ì´ì¦ˆê°€ ìˆëŠ” ê°€ìš°ì‹œì•ˆ í…ì„œ ê´€ì¸¡ì¹˜ë¡œë¶€í„° $r$ê°œì˜ ì•Œë ¤ì§€ì§€ ì•Šì€ ì‹ í˜¸ ë²¡í„°(ìŠ¤íŒŒì´í¬)ë¥¼ ì¶”ì •í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. êµ¬ì²´ì ìœ¼ë¡œ, ìš°ë¦¬ëŠ” ê³ ë„ë¡œ ë¹„ë³¼ë¡ì¸ ëœë¤ í•¨ìˆ˜ë¥¼ ìµœì í™”í•˜ëŠ” ìµœëŒ€ ìš°ë„ ì¶”ì • ì ˆì°¨ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì‹ í˜¸ ëŒ€ ì¡ìŒë¹„(SNR)ì˜ ë¶„ë¦¬ì— ëŒ€í•œ ê°€ì •ì„ ë‘ì§€ ì•Šê³ , ê·¸ë˜ë””ì–¸íŠ¸ íë¦„ì´ ëª¨ë“  ìŠ¤íŒŒì´í¬ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ë³µêµ¬í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ìƒ˜í”Œ ë³µì¡ë„ë¥¼ ê²°ì •í•©ë‹ˆë‹¤. ë³´ë‹¤ ì •í™•í•˜ê²ŒëŠ”, ìš°ë¦¬ì˜ ê²°ê³¼ëŠ” ìŠ¤íŒŒì´í¬ë¥¼ ìˆœì—´ê¹Œì§€ ë³µêµ¬í•  ìˆ˜ ìˆë„ë¡ ë³´ì¥í•˜ëŠ” ë° í•„ìš”í•œ ìƒ˜í”Œ ë³µì¡ë„ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì—°êµ¬ëŠ” ë™ë°˜ ë…¼ë¬¸ [Ben Arous, Gerbelot, Piccolo 2024]ì— ê¸°ë°˜ì„ ë‘ê³  ìˆìœ¼ë©°, ì´ ë…¼ë¬¸ì€ ë‘ì£¼ë±… ë™ì—­í•™ì„ ì—°êµ¬í•˜ê³  ìŠ¤íŒŒì´í¬ì˜ ì •í™•í•œ ë³µêµ¬ë¥¼ ë³´ì¥í•˜ê¸° ìœ„í•´ í•„ìš”í•œ SNRì˜ ìƒ˜í”Œ ë³µì¡ë„ì™€ ë¶„ë¦¬ ì¡°ê±´ì„ ê²°ì •í•©ë‹ˆë‹¤(ë³µêµ¬ëœ ìˆœì—´ì´ í•­ë“±ê³¼ ì¼ì¹˜í•˜ëŠ” ê²½ìš°). ë³µêµ¬ ê³¼ì •ì—ì„œ ì¶”ì •ì¹˜ì™€ ìˆ¨ê²¨ì§„ ë²¡í„° ê°„ì˜ ìƒê´€ê´€ê³„ëŠ” ìˆœì°¨ì ìœ¼ë¡œ ì¦ê°€í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ìƒê´€ê´€ê³„ê°€ ì¤‘ìš”í•´ì§€ëŠ” ìˆœì„œëŠ” ì´ˆê¸° ê°’ê³¼ í•´ë‹¹ SNRì— ë”°ë¼ ë‹¬ë¼ì§€ë©°, ì´ëŠ” ê¶ê·¹ì ìœ¼ë¡œ ë³µêµ¬ëœ ìŠ¤íŒŒì´í¬ì˜ ìˆœì—´ì„ ê²°ì •í•©ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë‹¤ì¤‘ ìŠ¤íŒŒì´í¬ í…ì„œ ë¬¸ì œì—ì„œ ê³ ì°¨ì› ê·¸ë˜ë””ì–¸íŠ¸ íë¦„ì˜ ë™ì—­í•™ì„ ì—°êµ¬í•©ë‹ˆë‹¤. ëª©í‘œëŠ” ì¡ìŒì´ ìˆëŠ” ê°€ìš°ì‹œì•ˆ í…ì„œ ê´€ì¸¡ì¹˜ë¡œë¶€í„° $r$ê°œì˜ ë¯¸ì§€ ì‹ í˜¸ ë²¡í„°(ìŠ¤íŒŒì´í¬)ë¥¼ ì¶”ì •í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì €ìë“¤ì€ ìµœëŒ€ ê°€ëŠ¥ë„ ì¶”ì • ì ˆì°¨ë¥¼ ë¶„ì„í•˜ì—¬, ì‹ í˜¸ ëŒ€ ì¡ìŒë¹„(SNR)ì˜ ë¶„ë¦¬ ê°€ì • ì—†ì´ ëª¨ë“  ìŠ¤íŒŒì´í¬ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ë³µêµ¬í•˜ê¸° ìœ„í•œ ìƒ˜í”Œ ë³µì¡ë„ë¥¼ ê·œëª…í–ˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ë™ë£Œ ë…¼ë¬¸ [Ben Arous, Gerbelot, Piccolo 2024]ì— ê¸°ë°˜í•˜ë©°, í•´ë‹¹ ë…¼ë¬¸ì—ì„œëŠ” ë‘ì£¼ë±… ë™ì—­í•™ì„ í†µí•´ ìŠ¤íŒŒì´í¬ì˜ ì •í™•í•œ ë³µêµ¬ë¥¼ ìœ„í•œ ìƒ˜í”Œ ë³µì¡ë„ì™€ SNR ë¶„ë¦¬ ì¡°ê±´ì„ ì œì‹œí–ˆìŠµë‹ˆë‹¤. ë³µêµ¬ ê³¼ì •ì—ì„œ ì¶”ì •ì¹˜ì™€ ìˆ¨ê²¨ì§„ ë²¡í„° ê°„ì˜ ìƒê´€ê´€ê³„ëŠ” ìˆœì°¨ì ìœ¼ë¡œ ì¦ê°€í•˜ë©°, ì´ˆê¸° ê°’ê³¼ SNRì— ë”°ë¼ ë³µêµ¬ëœ ìŠ¤íŒŒì´í¬ì˜ ìˆœì„œê°€ ê²°ì •ë©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸


- 1. ê³ ì°¨ì›ì—ì„œ ë‹¤ì¤‘ ìŠ¤íŒŒì´í¬ í…ì„œ ë¬¸ì œì˜ ê¸°ìš¸ê¸° íë¦„ ë™ì—­í•™ì„ ì—°êµ¬í•˜ì—¬ ë…¸ì´ì¦ˆê°€ ìˆëŠ” ê°€ìš°ì‹œì•ˆ í…ì„œ ê´€ì¸¡ì¹˜ë¡œë¶€í„° ì‹ í˜¸ ë²¡í„°ë¥¼ ì¶”ì •í•˜ëŠ” ë¬¸ì œë¥¼ ë‹¤ë£¹ë‹ˆë‹¤.

- 2. ìµœëŒ€ ê°€ëŠ¥ë„ ì¶”ì • ì ˆì°¨ë¥¼ ë¶„ì„í•˜ì—¬, ì‹ í˜¸ ëŒ€ ì¡ìŒ ë¹„ìœ¨(SNR)ì˜ ë¶„ë¦¬ì— ëŒ€í•œ ê°€ì • ì—†ì´ ëª¨ë“  ìŠ¤íŒŒì´í¬ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ë³µêµ¬í•˜ê¸° ìœ„í•œ ìƒ˜í”Œ ë³µì¡ì„±ì„ ê²°ì •í•©ë‹ˆë‹¤.

- 3. ì—°êµ¬ ê²°ê³¼ëŠ” ìŠ¤íŒŒì´í¬ë¥¼ ìˆœì—´ê¹Œì§€ ë³µêµ¬í•  ìˆ˜ ìˆëŠ” ìƒ˜í”Œ ë³µì¡ì„±ì„ ì œê³µí•˜ë©°, ì´ëŠ” ë™ë°˜ ë…¼ë¬¸ì—ì„œ ì œì‹œëœ SNRì˜ ë¶„ë¦¬ ì¡°ê±´ê³¼ ìƒ˜í”Œ ë³µì¡ì„±ì— ê¸°ë°˜í•©ë‹ˆë‹¤.

- 4. ë³µêµ¬ ê³¼ì •ì—ì„œ ì¶”ì •ì¹˜ì™€ ìˆ¨ê²¨ì§„ ë²¡í„° ê°„ì˜ ìƒê´€ê´€ê³„ëŠ” ì´ˆê¸° ê°’ê³¼ í•´ë‹¹ SNRì— ë”°ë¼ ìˆœì°¨ì ìœ¼ë¡œ ì¦ê°€í•˜ë©°, ì´ëŠ” ë³µêµ¬ëœ ìŠ¤íŒŒì´í¬ì˜ ìˆœì—´ì„ ê²°ì •í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-22 16:08:25*