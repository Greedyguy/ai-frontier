---
keywords:
  - Transformer
  - High Dynamic Range Imaging
  - Multi-Exposure Fusion
  - Inverted Residual Embedding
  - Dynamic Tanh
category: cs.CV
publish_date: 2025-09-25
arxiv_id: 2509.19779
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-26T09:06:51.080299",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Transformer",
    "High Dynamic Range Imaging",
    "Multi-Exposure Fusion",
    "Inverted Residual Embedding",
    "Dynamic Tanh"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Transformer": 0.85,
    "High Dynamic Range Imaging": 0.8,
    "Multi-Exposure Fusion": 0.78,
    "Inverted Residual Embedding": 0.77,
    "Dynamic Tanh": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Vision Transformer",
        "canonical": "Transformer",
        "aliases": [
          "ViT"
        ],
        "category": "broad_technical",
        "rationale": "Transformers are a foundational model in deep learning, and linking to them aids in understanding the architectural basis of the proposed framework.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "High Dynamic Range Imaging",
        "canonical": "High Dynamic Range Imaging",
        "aliases": [
          "HDR Imaging"
        ],
        "category": "unique_technical",
        "rationale": "HDR Imaging is a specific application area that benefits from the proposed method, providing a direct link to the paper's focus.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Multi-Exposure Fusion",
        "canonical": "Multi-Exposure Fusion",
        "aliases": [
          "MEF"
        ],
        "category": "unique_technical",
        "rationale": "MEF is a key technique discussed in the paper, essential for understanding the proposed HDR reconstruction approach.",
        "novelty_score": 0.65,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Inverted Residual Embedding",
        "canonical": "Inverted Residual Embedding",
        "aliases": [
          "IRE"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel component introduced in the paper, crucial for achieving the lightweight design of the model.",
        "novelty_score": 0.75,
        "connectivity_score": 0.55,
        "specificity_score": 0.88,
        "link_intent_score": 0.77
      },
      {
        "surface": "Dynamic Tanh",
        "canonical": "Dynamic Tanh",
        "aliases": [
          "DyT"
        ],
        "category": "unique_technical",
        "rationale": "Dynamic Tanh is a specific activation function variant proposed in the paper, relevant for its role in reducing computational complexity.",
        "novelty_score": 0.68,
        "connectivity_score": 0.5,
        "specificity_score": 0.82,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "edge devices",
      "computational efficiency"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Vision Transformer",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "High Dynamic Range Imaging",
      "resolved_canonical": "High Dynamic Range Imaging",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Multi-Exposure Fusion",
      "resolved_canonical": "Multi-Exposure Fusion",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Inverted Residual Embedding",
      "resolved_canonical": "Inverted Residual Embedding",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.55,
        "specificity": 0.88,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Dynamic Tanh",
      "resolved_canonical": "Dynamic Tanh",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.5,
        "specificity": 0.82,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# EfficienT-HDR: An Efficient Transformer-Based Framework via Multi-Exposure Fusion for HDR Reconstruction

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19779.pdf)
**Category**: cs.CV
**Published**: 2025-09-25
**ArXiv ID**: [2509.19779](https://arxiv.org/abs/2509.19779)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/PhysHDR_ When Lighting Meets Materials and Scene Geometry in HDR Reconstruction_20250923|PhysHDR: When Lighting Meets Materials and Scene Geometry in HDR Reconstruction]] (86.3% similar)
- [[2025-09-23/DT-NeRF_ A Diffusion and Transformer-Based Optimization Approach for Neural Radiance Fields in 3D Reconstruction_20250923|DT-NeRF: A Diffusion and Transformer-Based Optimization Approach for Neural Radiance Fields in 3D Reconstruction]] (84.1% similar)
- [[2025-09-24/Improving the color accuracy of lighting estimation models_20250924|Improving the color accuracy of lighting estimation models]] (83.8% similar)
- [[2025-09-22/DSDNet_ Raw Domain Demoir\'eing via Dual Color-Space Synergy_20250922|DSDNet: Raw Domain Demoir\'eing via Dual Color-Space Synergy]] (83.8% similar)
- [[2025-09-24/Lightweight Vision Transformer with Window and Spatial Attention for Food Image Classification_20250924|Lightweight Vision Transformer with Window and Spatial Attention for Food Image Classification]] (83.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Transformer|Transformer]]
**âš¡ Unique Technical**: [[keywords/High Dynamic Range Imaging|High Dynamic Range Imaging]], [[keywords/Multi-Exposure Fusion|Multi-Exposure Fusion]], [[keywords/Inverted Residual Embedding|Inverted Residual Embedding]], [[keywords/Dynamic Tanh|Dynamic Tanh]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19779v1 Announce Type: new 
Abstract: Achieving high-quality High Dynamic Range (HDR) imaging on resource-constrained edge devices is a critical challenge in computer vision, as its performance directly impacts downstream tasks such as intelligent surveillance and autonomous driving. Multi-Exposure Fusion (MEF) is a mainstream technique to achieve this goal; however, existing methods generally face the dual bottlenecks of high computational costs and ghosting artifacts, hindering their widespread deployment. To this end, this study proposes a light-weight Vision Transformer architecture designed explicitly for HDR reconstruction to overcome these limitations. This study is based on the Context-Aware Vision Transformer and begins by converting input images to the YCbCr color space to separate luminance and chrominance information. It then employs an Intersection-Aware Adaptive Fusion (IAAF) module to suppress ghosting effectively. To further achieve a light-weight design, we introduce Inverted Residual Embedding (IRE), Dynamic Tanh (DyT), and propose Enhanced Multi-Scale Dilated Convolution (E-MSDC) to reduce computational complexity at multiple levels. Our study ultimately contributes two model versions: a main version for high visual quality and a light-weight version with advantages in computational efficiency, both of which achieve an excellent balance between performance and image quality. Experimental results demonstrate that, compared to the baseline, the main version reduces FLOPS by approximately 67% and increases inference speed by more than fivefold on CPU and 2.5 times on an edge device. These results confirm that our method provides an efficient and ghost-free HDR imaging solution for edge devices, demonstrating versatility and practicality across various dynamic scenarios.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” ìì› ì œì•½ì´ ìˆëŠ” ì—£ì§€ ë””ë°”ì´ìŠ¤ì—ì„œ ê³ í’ˆì§ˆ HDR ì´ë¯¸ì§•ì„ êµ¬í˜„í•˜ê¸° ìœ„í•œ ê²½ëŸ‰ ë¹„ì „ íŠ¸ëœìŠ¤í¬ë¨¸ ì•„í‚¤í…ì²˜ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë‹¤ì¤‘ ë…¸ì¶œ ìœµí•©(MEF) ê¸°ë²•ì€ ë†’ì€ ê³„ì‚° ë¹„ìš©ê³¼ ê³ ìŠ¤íŠ¸ í˜„ìƒ ë¬¸ì œë¥¼ ê²ªê³  ìˆëŠ”ë°, ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë³¸ ì—°êµ¬ëŠ” Context-Aware Vision Transformerë¥¼ ê¸°ë°˜ìœ¼ë¡œ YCbCr ìƒ‰ ê³µê°„ ë³€í™˜ê³¼ Intersection-Aware Adaptive Fusion(IAAF) ëª¨ë“ˆì„ í™œìš©í•˜ì—¬ ê³ ìŠ¤íŠ¸ í˜„ìƒì„ ì–µì œí•©ë‹ˆë‹¤. ë˜í•œ, Inverted Residual Embedding(IRE), Dynamic Tanh(DyT), Enhanced Multi-Scale Dilated Convolution(E-MSDC)ì„ ë„ì…í•˜ì—¬ ê³„ì‚° ë³µì¡ì„±ì„ ì¤„ì˜€ìŠµë‹ˆë‹¤. ì—°êµ¬ ê²°ê³¼, ì œì•ˆëœ ëª¨ë¸ì€ ì„±ëŠ¥ê³¼ ì´ë¯¸ì§€ í’ˆì§ˆì˜ ê· í˜•ì„ ìœ ì§€í•˜ë©´ì„œë„ ê³„ì‚° íš¨ìœ¨ì„±ì„ í¬ê²Œ í–¥ìƒì‹œì¼°ìœ¼ë©°, ì‹¤í—˜ ê²°ê³¼ CPUì—ì„œ FLOPSë¥¼ ì•½ 67% ì¤„ì´ê³  ì¶”ë¡  ì†ë„ë¥¼ 5ë°° ì´ìƒ, ì—£ì§€ ë””ë°”ì´ìŠ¤ì—ì„œëŠ” 2.5ë°° ì¦ê°€ì‹œì¼°ìŠµë‹ˆë‹¤. ì´ë¡œì¨ ë‹¤ì–‘í•œ ë™ì  ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ íš¨ìœ¨ì ì´ê³  ê³ ìŠ¤íŠ¸ ì—†ëŠ” HDR ì´ë¯¸ì§• ì†”ë£¨ì…˜ì„ ì œê³µí•¨ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë³¸ ì—°êµ¬ëŠ” ìì› ì œì•½ì´ ìˆëŠ” ì—£ì§€ ë””ë°”ì´ìŠ¤ì—ì„œ ê³ í’ˆì§ˆ HDR ì´ë¯¸ì§•ì„ ìœ„í•œ ê²½ëŸ‰ ë¹„ì „ íŠ¸ëœìŠ¤í¬ë¨¸ ì•„í‚¤í…ì²˜ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.
- 2. ì…ë ¥ ì´ë¯¸ì§€ë¥¼ YCbCr ìƒ‰ìƒ ê³µê°„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ íœ˜ë„ì™€ ìƒ‰ì°¨ ì •ë³´ë¥¼ ë¶„ë¦¬í•˜ê³ , êµì°¨ ì¸ì‹ ì ì‘ ìœµí•© ëª¨ë“ˆ(IAAF)ì„ ì‚¬ìš©í•˜ì—¬ ê³ ìŠ¤íŠ¸ í˜„ìƒì„ íš¨ê³¼ì ìœ¼ë¡œ ì–µì œí•©ë‹ˆë‹¤.
- 3. ê²½ëŸ‰ ì„¤ê³„ë¥¼ ìœ„í•´ Inverted Residual Embedding (IRE), Dynamic Tanh (DyT), ê·¸ë¦¬ê³  Enhanced Multi-Scale Dilated Convolution (E-MSDC)ì„ ë„ì…í•˜ì—¬ ì—¬ëŸ¬ ìˆ˜ì¤€ì—ì„œ ê³„ì‚° ë³µì¡ì„±ì„ ì¤„ì…ë‹ˆë‹¤.
- 4. ì‹¤í—˜ ê²°ê³¼, ì£¼ ë²„ì „ì€ FLOPSë¥¼ ì•½ 67% ê°ì†Œì‹œí‚¤ê³  CPUì—ì„œ ì¶”ë¡  ì†ë„ë¥¼ 5ë°° ì´ìƒ, ì—£ì§€ ë””ë°”ì´ìŠ¤ì—ì„œ 2.5ë°° ì¦ê°€ì‹œí‚µë‹ˆë‹¤.
- 5. ì œì•ˆëœ ë°©ë²•ì€ ì—£ì§€ ë””ë°”ì´ìŠ¤ì—ì„œ íš¨ìœ¨ì ì´ê³  ê³ ìŠ¤íŠ¸ ì—†ëŠ” HDR ì´ë¯¸ì§• ì†”ë£¨ì…˜ì„ ì œê³µí•˜ë©°, ë‹¤ì–‘í•œ ë™ì  ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì‹¤ìš©ì„±ê³¼ ë²”ìš©ì„±ì„ ì…ì¦í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-26 09:06:51*