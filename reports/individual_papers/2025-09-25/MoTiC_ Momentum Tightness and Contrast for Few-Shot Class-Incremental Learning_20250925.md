---
keywords:
  - Few-Shot Learning
  - Self-supervised Learning
  - Momentum Tightness and Contrast
  - Bayesian Analysis
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2509.19664
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T15:43:02.935355",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Few-Shot Learning",
    "Self-supervised Learning",
    "Momentum Tightness and Contrast",
    "Bayesian Analysis"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Few-Shot Learning": 0.85,
    "Self-supervised Learning": 0.8,
    "Momentum Tightness and Contrast": 0.78,
    "Bayesian Analysis": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Few-Shot Class-Incremental Learning",
        "canonical": "Few-Shot Learning",
        "aliases": [
          "FSCIL"
        ],
        "category": "specific_connectable",
        "rationale": "Links to the concept of learning from limited data while adapting to new classes, a trending topic in machine learning.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.82,
        "link_intent_score": 0.85
      },
      {
        "surface": "Contrastive Learning",
        "canonical": "Self-supervised Learning",
        "aliases": [
          "Contrastive Learning"
        ],
        "category": "specific_connectable",
        "rationale": "Connects to the self-supervised learning paradigm, enhancing feature representation learning.",
        "novelty_score": 0.45,
        "connectivity_score": 0.79,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Momentum Tightness and Contrast",
        "canonical": "Momentum Tightness and Contrast",
        "aliases": [
          "MoTiC"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel framework specific to the paper, enhancing feature space representation.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Bayesian Analysis",
        "canonical": "Bayesian Analysis",
        "aliases": [],
        "category": "broad_technical",
        "rationale": "Provides a statistical approach to align class priors, relevant to many machine learning methods.",
        "novelty_score": 0.4,
        "connectivity_score": 0.7,
        "specificity_score": 0.65,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Few-Shot Class-Incremental Learning",
      "resolved_canonical": "Few-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.82,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Contrastive Learning",
      "resolved_canonical": "Self-supervised Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.79,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Momentum Tightness and Contrast",
      "resolved_canonical": "Momentum Tightness and Contrast",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Bayesian Analysis",
      "resolved_canonical": "Bayesian Analysis",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.7,
        "specificity": 0.65,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# MoTiC: Momentum Tightness and Contrast for Few-Shot Class-Incremental Learning

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19664.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2509.19664](https://arxiv.org/abs/2509.19664)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Min_ Mixture of Noise for Pre-Trained Model-Based Class-Incremental Learning_20250923|Min: Mixture of Noise for Pre-Trained Model-Based Class-Incremental Learning]] (85.1% similar)
- [[2025-09-24/Hyperbolic Coarse-to-Fine Few-Shot Class-Incremental Learning_20250924|Hyperbolic Coarse-to-Fine Few-Shot Class-Incremental Learning]] (83.0% similar)
- [[2025-09-22/Efficient Long-Tail Learning in Latent Space by sampling Synthetic Data_20250922|Efficient Long-Tail Learning in Latent Space by sampling Synthetic Data]] (82.4% similar)
- [[2025-09-19/Seeing 3D Through 2D Lenses_ 3D Few-Shot Class-Incremental Learning via Cross-Modal Geometric Rectification_20250919|Seeing 3D Through 2D Lenses: 3D Few-Shot Class-Incremental Learning via Cross-Modal Geometric Rectification]] (81.9% similar)
- [[2025-09-24/Class-wise Balancing Data Replay for Federated Class-Incremental Learning_20250924|Class-wise Balancing Data Replay for Federated Class-Incremental Learning]] (81.7% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Bayesian Analysis|Bayesian Analysis]]
**ğŸ”— Specific Connectable**: [[keywords/Few-Shot Learning|Few-Shot Learning]], [[keywords/Self-supervised Learning|Self-supervised Learning]]
**âš¡ Unique Technical**: [[keywords/Momentum Tightness and Contrast|Momentum Tightness and Contrast]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19664v1 Announce Type: cross 
Abstract: Few-Shot Class-Incremental Learning (FSCIL) must contend with the dual challenge of learning new classes from scarce samples while preserving old class knowledge. Existing methods use the frozen feature extractor and class-averaged prototypes to mitigate against catastrophic forgetting and overfitting. However, new-class prototypes suffer significant estimation bias due to extreme data scarcity, whereas base-class prototypes benefit from sufficient data. In this work, we theoretically demonstrate that aligning the new-class priors with old-class statistics via Bayesian analysis reduces variance and improves prototype accuracy. Furthermore, we propose large-scale contrastive learning to enforce cross-category feature tightness. To further enrich feature diversity and inject prior information for new-class prototypes, we integrate momentum self-supervision and virtual categories into the Momentum Tightness and Contrast framework (MoTiC), constructing a feature space with rich representations and enhanced interclass cohesion. Experiments on three FSCIL benchmarks produce state-of-the-art performances, particularly on the fine-grained task CUB-200, validating our method's ability to reduce estimation bias and improve incremental learning robustness.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ Few-Shot Class-Incremental Learning (FSCIL)ì—ì„œ ìƒˆë¡œìš´ í´ë˜ìŠ¤ë¥¼ ì ì€ ìƒ˜í”Œë¡œ í•™ìŠµí•˜ë©´ì„œ ê¸°ì¡´ í´ë˜ìŠ¤ì˜ ì§€ì‹ì„ ìœ ì§€í•˜ëŠ” ë¬¸ì œë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. ê¸°ì¡´ ë°©ë²•ë“¤ì€ ê³ ì •ëœ íŠ¹ì§• ì¶”ì¶œê¸°ì™€ í´ë˜ìŠ¤ í‰ê·  í”„ë¡œí† íƒ€ì…ì„ ì‚¬ìš©í•˜ì—¬ ë§ê°ê³¼ ê³¼ì í•©ì„ ë°©ì§€í•˜ì§€ë§Œ, ìƒˆë¡œìš´ í´ë˜ìŠ¤ì˜ í”„ë¡œí† íƒ€ì…ì€ ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ì¸í•´ í° ì¶”ì • í¸í–¥ì„ ê²ªìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ëŠ” ë² ì´ì§€ì•ˆ ë¶„ì„ì„ í†µí•´ ìƒˆë¡œìš´ í´ë˜ìŠ¤ì˜ ì‚¬ì „ ì •ë³´ë¥¼ ê¸°ì¡´ í´ë˜ìŠ¤ í†µê³„ì™€ ì •ë ¬í•˜ë©´ ë¶„ì‚°ì´ ì¤„ê³  í”„ë¡œí† íƒ€ì… ì •í™•ë„ê°€ í–¥ìƒë¨ì„ ì´ë¡ ì ìœ¼ë¡œ ì¦ëª…í•©ë‹ˆë‹¤. ë˜í•œ, ëŒ€ê·œëª¨ ëŒ€ì¡° í•™ìŠµì„ í†µí•´ ë²”ì£¼ ê°„ íŠ¹ì§•ì˜ ë°€ë„ë¥¼ ê°•í™”í•˜ê³ , ëª¨ë©˜í…€ ìê¸° ì§€ë„ í•™ìŠµê³¼ ê°€ìƒ ì¹´í…Œê³ ë¦¬ë¥¼ í†µí•©í•˜ì—¬ íŠ¹ì§• ë‹¤ì–‘ì„±ì„ í’ë¶€í•˜ê²Œ í•©ë‹ˆë‹¤. ì œì•ˆëœ MoTiC í”„ë ˆì„ì›Œí¬ëŠ” í’ë¶€í•œ í‘œí˜„ê³¼ í–¥ìƒëœ í´ë˜ìŠ¤ ê°„ ê²°ì†ë ¥ì„ ê°€ì§„ íŠ¹ì§• ê³µê°„ì„ êµ¬ì¶•í•©ë‹ˆë‹¤. ì„¸ ê°€ì§€ FSCIL ë²¤ì¹˜ë§ˆí¬ ì‹¤í—˜ì—ì„œ íŠ¹íˆ ì„¸ë°€í•œ ì‘ì—…ì¸ CUB-200ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ë©°, ì¶”ì • í¸í–¥ì„ ì¤„ì´ê³  ì¦ë¶„ í•™ìŠµì˜ ê°•ê±´ì„±ì„ í–¥ìƒì‹œí‚¤ëŠ” ë°©ë²•ì˜ ìœ íš¨ì„±ì„ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Few-Shot Class-Incremental Learning (FSCIL)ì€ ìƒˆë¡œìš´ í´ë˜ìŠ¤ í•™ìŠµ ì‹œ ìƒ˜í”Œ ë¶€ì¡± ë¬¸ì œì™€ ê¸°ì¡´ í´ë˜ìŠ¤ ì§€ì‹ ë³´ì¡´ ë¬¸ì œë¥¼ ë™ì‹œì— í•´ê²°í•´ì•¼ í•©ë‹ˆë‹¤.
- 2. ê¸°ì¡´ ë°©ë²•ë“¤ì€ ê³ ì •ëœ íŠ¹ì§• ì¶”ì¶œê¸°ì™€ í´ë˜ìŠ¤ í‰ê·  í”„ë¡œí† íƒ€ì…ì„ ì‚¬ìš©í•˜ì—¬ ë§ê°ê³¼ ê³¼ì í•©ì„ ì™„í™”í•˜ë ¤ê³  í•©ë‹ˆë‹¤.
- 3. ìƒˆë¡œìš´ í´ë˜ìŠ¤ì˜ í”„ë¡œí† íƒ€ì…ì€ ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ì¸í•´ í° ì¶”ì • í¸í–¥ì„ ê²ªëŠ” ë°˜ë©´, ê¸°ë³¸ í´ë˜ìŠ¤ í”„ë¡œí† íƒ€ì…ì€ ì¶©ë¶„í•œ ë°ì´í„°ë¥¼ í™œìš©í•©ë‹ˆë‹¤.
- 4. ë³¸ ì—°êµ¬ì—ì„œëŠ” ë² ì´ì§€ì•ˆ ë¶„ì„ì„ í†µí•´ ìƒˆë¡œìš´ í´ë˜ìŠ¤ì˜ ì‚¬ì „ ì •ë³´ë¥¼ ê¸°ì¡´ í´ë˜ìŠ¤ í†µê³„ì™€ ì •ë ¬í•˜ì—¬ ë¶„ì‚°ì„ ì¤„ì´ê³  í”„ë¡œí† íƒ€ì… ì •í™•ì„±ì„ í–¥ìƒì‹œí‚´ì„ ì´ë¡ ì ìœ¼ë¡œ ì…ì¦í•©ë‹ˆë‹¤.
- 5. ì œì•ˆëœ MoTiC í”„ë ˆì„ì›Œí¬ëŠ” ëª¨ë©˜í…€ ìê¸° ì§€ë„ í•™ìŠµê³¼ ê°€ìƒ ì¹´í…Œê³ ë¦¬ë¥¼ í†µí•©í•˜ì—¬ í’ë¶€í•œ í‘œí˜„ê³¼ í–¥ìƒëœ í´ë˜ìŠ¤ ê°„ ê²°ì†ë ¥ì„ ê°€ì§„ íŠ¹ì§• ê³µê°„ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-25 15:43:02*