---
keywords:
  - Vision-Language Model
  - Spatial Reasoning
  - OmniSpatial Benchmark
  - Cognitive Psychology
  - PointGraph
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2506.03135
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T16:26:49.314862",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Vision-Language Model",
    "Spatial Reasoning",
    "OmniSpatial Benchmark",
    "Cognitive Psychology",
    "PointGraph"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Vision-Language Model": 0.85,
    "Spatial Reasoning": 0.78,
    "OmniSpatial Benchmark": 0.82,
    "Cognitive Psychology": 0.7,
    "PointGraph": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Vision-Language Models",
        "canonical": "Vision-Language Model",
        "aliases": [
          "VLMs"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-Language Models are central to the paper's focus on spatial reasoning and are a trending topic.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Spatial Reasoning",
        "canonical": "Spatial Reasoning",
        "aliases": [
          "Spatial Logic",
          "Spatial Interaction"
        ],
        "category": "unique_technical",
        "rationale": "Spatial Reasoning is the primary focus of the benchmark introduced in the paper, offering unique insights.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "OmniSpatial",
        "canonical": "OmniSpatial Benchmark",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "OmniSpatial is a newly introduced benchmark, making it a unique and significant contribution of the paper.",
        "novelty_score": 0.85,
        "connectivity_score": 0.6,
        "specificity_score": 0.9,
        "link_intent_score": 0.82
      },
      {
        "surface": "Cognitive Psychology",
        "canonical": "Cognitive Psychology",
        "aliases": [],
        "category": "broad_technical",
        "rationale": "Cognitive Psychology provides the theoretical foundation for the spatial reasoning tasks discussed.",
        "novelty_score": 0.3,
        "connectivity_score": 0.75,
        "specificity_score": 0.65,
        "link_intent_score": 0.7
      },
      {
        "surface": "PointGraph",
        "canonical": "PointGraph",
        "aliases": [
          "Scene Graph Cues"
        ],
        "category": "unique_technical",
        "rationale": "PointGraph is a novel strategy proposed in the paper to enhance spatial reasoning, highlighting its uniqueness.",
        "novelty_score": 0.75,
        "connectivity_score": 0.55,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Vision-Language Models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Spatial Reasoning",
      "resolved_canonical": "Spatial Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "OmniSpatial",
      "resolved_canonical": "OmniSpatial Benchmark",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.6,
        "specificity": 0.9,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Cognitive Psychology",
      "resolved_canonical": "Cognitive Psychology",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.75,
        "specificity": 0.65,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "PointGraph",
      "resolved_canonical": "PointGraph",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.55,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# OmniSpatial: Towards Comprehensive Spatial Reasoning Benchmark for Vision Language Models

## 📋 메타데이터

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2506.03135.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2506.03135](https://arxiv.org/abs/2506.03135)

## 🔗 유사한 논문
- [[2025-09-24/How Far are VLMs from Visual Spatial Intelligence? A Benchmark-Driven Perspective_20250924|How Far are VLMs from Visual Spatial Intelligence? A Benchmark-Driven Perspective]] (89.2% similar)
- [[2025-09-22/Spatial Understanding from Videos_ Structured Prompts Meet Simulation Data_20250922|Spatial Understanding from Videos: Structured Prompts Meet Simulation Data]] (87.7% similar)
- [[2025-09-23/SD-VLM_ Spatial Measuring and Understanding with Depth-Encoded Vision-Language Models_20250923|SD-VLM: Spatial Measuring and Understanding with Depth-Encoded Vision-Language Models]] (86.3% similar)
- [[2025-09-23/FoREST_ Frame of Reference Evaluation in Spatial Reasoning Tasks_20250923|FoREST: Frame of Reference Evaluation in Spatial Reasoning Tasks]] (85.3% similar)
- [[2025-09-22/GRE Suite_ Geo-localization Inference via Fine-Tuned Vision-Language Models and Enhanced Reasoning Chains_20250922|GRE Suite: Geo-localization Inference via Fine-Tuned Vision-Language Models and Enhanced Reasoning Chains]] (84.9% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Cognitive Psychology|Cognitive Psychology]]
**⚡ Unique Technical**: [[keywords/Spatial Reasoning|Spatial Reasoning]], [[keywords/OmniSpatial Benchmark|OmniSpatial Benchmark]], [[keywords/PointGraph|PointGraph]]
**🚀 Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2506.03135v2 Announce Type: replace-cross 
Abstract: Spatial reasoning is a key aspect of cognitive psychology and remains a bottleneck for current vision-language models (VLMs). While extensive research has aimed to evaluate or improve VLMs' understanding of basic spatial relations, such as distinguishing left from right, near from far, and object counting, these tasks cover only the most elementary layer of spatial reasoning and are largely approaching saturation in the latest reasoning models. In this work, we introduce OmniSpatial, a comprehensive and challenging benchmark for spatial reasoning, grounded in cognitive psychology. OmniSpatial covers four major categories: dynamic reasoning, complex spatial logic, spatial interaction, and perspective-taking, with 50 fine-grained subcategories. Through careful manual annotation, we construct over 8.4K question-answer pairs. Extensive experiments show that both open- and closed-source VLMs exhibit significant limitations in comprehensive spatial reasoning. We also explore two strategies-PointGraph (explicit scene graph cues) and SpatialCoT (novel-view chain-of-thought)-to bolster spatial reasoning.

## 📝 요약

이 논문은 인지 심리학에 기반한 포괄적인 공간 추론 벤치마크인 OmniSpatial을 소개합니다. OmniSpatial은 동적 추론, 복잡한 공간 논리, 공간 상호작용, 관점 전환 등 네 가지 주요 범주와 50개의 세부 범주로 구성되어 있으며, 8,400개 이상의 질문-답변 쌍을 포함합니다. 연구 결과, 현재의 비전-언어 모델(VLMs)은 포괄적인 공간 추론에서 상당한 한계를 보였습니다. 이를 개선하기 위해 명시적 장면 그래프 단서를 활용한 PointGraph와 새로운 관점의 사고 체인을 이용한 SpatialCoT 두 가지 전략을 제안합니다.

## 🎯 주요 포인트

- 1. 공간 추론은 인지 심리학의 핵심 측면이며, 현재의 비전-언어 모델(VLMs)의 병목 현상으로 남아있다.
- 2. OmniSpatial은 인지 심리학에 기반한 포괄적이고 도전적인 공간 추론 벤치마크로, 동적 추론, 복잡한 공간 논리, 공간 상호작용, 관점 취하기의 네 가지 주요 범주를 포함한다.
- 3. OmniSpatial은 50개의 세부 범주를 포함하여 8,400개 이상의 질문-답변 쌍을 구축하였다.
- 4. 실험 결과, 개방형 및 폐쇄형 VLMs 모두 포괄적인 공간 추론에서 상당한 한계를 보였다.
- 5. 공간 추론을 강화하기 위해 PointGraph(명시적 장면 그래프 단서)와 SpatialCoT(새로운 관점의 사고 사슬) 두 가지 전략을 탐구하였다.


---

*Generated on 2025-09-25 16:26:49*