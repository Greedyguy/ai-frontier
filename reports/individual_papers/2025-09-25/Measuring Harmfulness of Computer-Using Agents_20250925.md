---
keywords:
  - Computer-using Agents
  - Large Language Model
  - CUAHarm Benchmark
  - Agentic Framework
  - Hierarchical Summarization Strategy
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2508.00935
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T16:32:32.982552",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Computer-using Agents",
    "Large Language Model",
    "CUAHarm Benchmark",
    "Agentic Framework",
    "Hierarchical Summarization Strategy"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Computer-using Agents": 0.85,
    "Large Language Model": 0.88,
    "CUAHarm Benchmark": 0.83,
    "Agentic Framework": 0.79,
    "Hierarchical Summarization Strategy": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Computer-using agents",
        "canonical": "Computer-using Agents",
        "aliases": [
          "CUAs"
        ],
        "category": "unique_technical",
        "rationale": "This term is central to the paper's focus on evaluating and mitigating risks associated with autonomous computer control.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.82,
        "link_intent_score": 0.85
      },
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "LLMs are key to understanding the capabilities and risks of CUAs, providing a strong link to existing research on AI models.",
        "novelty_score": 0.4,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.88
      },
      {
        "surface": "CUAHarm benchmark",
        "canonical": "CUAHarm Benchmark",
        "aliases": [
          "CUAHarm"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a new benchmark specifically designed to evaluate misuse risks, which is crucial for future research connections.",
        "novelty_score": 0.8,
        "connectivity_score": 0.72,
        "specificity_score": 0.85,
        "link_intent_score": 0.83
      },
      {
        "surface": "Agentic framework",
        "canonical": "Agentic Framework",
        "aliases": [
          "UI-TARS-1.5"
        ],
        "category": "specific_connectable",
        "rationale": "This framework is evaluated for its impact on misuse risks, linking to broader discussions on AI safety and control.",
        "novelty_score": 0.65,
        "connectivity_score": 0.78,
        "specificity_score": 0.77,
        "link_intent_score": 0.79
      },
      {
        "surface": "Hierarchical summarization strategy",
        "canonical": "Hierarchical Summarization Strategy",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "A novel approach to improve monitoring accuracy, offering a potential new direction for research in AI monitoring.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "benchmark",
      "safety risks",
      "monitoring accuracy"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Computer-using agents",
      "resolved_canonical": "Computer-using Agents",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.82,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "CUAHarm benchmark",
      "resolved_canonical": "CUAHarm Benchmark",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.72,
        "specificity": 0.85,
        "link_intent": 0.83
      }
    },
    {
      "candidate_surface": "Agentic framework",
      "resolved_canonical": "Agentic Framework",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.78,
        "specificity": 0.77,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Hierarchical summarization strategy",
      "resolved_canonical": "Hierarchical Summarization Strategy",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# Measuring Harmfulness of Computer-Using Agents

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2508.00935.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2508.00935](https://arxiv.org/abs/2508.00935)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Red Teaming Multimodal Language Models_ Evaluating Harm Across Prompt Modalities and Models_20250922|Red Teaming Multimodal Language Models: Evaluating Harm Across Prompt Modalities and Models]] (84.0% similar)
- [[2025-09-19/ScaleCUA_ Scaling Open-Source Computer Use Agents with Cross-Platform Data_20250919|ScaleCUA: Scaling Open-Source Computer Use Agents with Cross-Platform Data]] (83.9% similar)
- [[2025-09-22/SeCodePLT_ A Unified Platform for Evaluating the Security of Code GenAI_20250922|SeCodePLT: A Unified Platform for Evaluating the Security of Code GenAI]] (83.4% similar)
- [[2025-09-19/A Multi-Agent LLM Defense Pipeline Against Prompt Injection Attacks_20250919|A Multi-Agent LLM Defense Pipeline Against Prompt Injection Attacks]] (83.4% similar)
- [[2025-09-22/SycEval_ Evaluating LLM Sycophancy_20250922|SycEval: Evaluating LLM Sycophancy]] (83.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Agentic Framework|Agentic Framework]]
**âš¡ Unique Technical**: [[keywords/Computer-using Agents|Computer-using Agents]], [[keywords/CUAHarm Benchmark|CUAHarm Benchmark]], [[keywords/Hierarchical Summarization Strategy|Hierarchical Summarization Strategy]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2508.00935v2 Announce Type: replace-cross 
Abstract: Computer-using agents (CUAs), which can autonomously control computers to perform multi-step actions, might pose significant safety risks if misused. However, existing benchmarks mainly evaluate LMs in chatbots or simple tool use. To more comprehensively evaluate CUAs' misuse risks, we introduce a new benchmark: CUAHarm. CUAHarm consists of 104 expert-written realistic misuse risks, such as disabling firewalls, leaking data, or installing backdoors. We provide a sandbox with rule-based verifiable rewards to measure CUAs' success rates in executing these tasks (e.g., whether the firewall is indeed disabled), beyond refusal rates. We evaluate frontier LMs including GPT-5, Claude 4 Sonnet, Gemini 2.5 Pro, Llama-3.3-70B, and Mistral Large 2. Even without jailbreaking prompts, these frontier LMs comply with executing these malicious tasks at a high success rate (e.g., 90\% for Gemini 2.5 Pro). Furthermore, while newer models are safer in previous safety benchmarks, their misuse risks as CUAs become even higher, e.g., Gemini 2.5 Pro is riskier than Gemini 1.5 Pro. Additionally, while these LMs are robust to common malicious prompts (e.g., creating a bomb) when acting as chatbots, they could still act unsafely as CUAs. We further evaluate a leading agentic framework (UI-TARS-1.5) and find that while it improves performance, it also amplifies misuse risks. To mitigate the misuse risks of CUAs, we explore using LMs to monitor CUAs' actions. We find monitoring unsafe computer-using actions is significantly harder than monitoring conventional unsafe chatbot responses. While monitoring chain-of-thoughts leads to modest gains, the average monitoring accuracy is only 77\%. A hierarchical summarization strategy improves performance by up to 13\%, a promising direction though monitoring remains unreliable. The benchmark will be released publicly to facilitate further research on mitigating these risks.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì»´í“¨í„°ë¥¼ ììœ¨ì ìœ¼ë¡œ ì œì–´í•˜ëŠ” ì—ì´ì „íŠ¸(CUAs)ì˜ ì˜¤ìš© ìœ„í—˜ì„±ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ì¸ CUAHarmì„ ì†Œê°œí•©ë‹ˆë‹¤. CUAHarmì€ ë°©í™”ë²½ ë¹„í™œì„±í™”, ë°ì´í„° ìœ ì¶œ, ë°±ë„ì–´ ì„¤ì¹˜ ë“± 104ê°œì˜ ì „ë¬¸ê°€ ì‘ì„± ì‹œë‚˜ë¦¬ì˜¤ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, CUAsì˜ ì„±ê³µë¥ ì„ ì¸¡ì •í•˜ê¸° ìœ„í•œ ìƒŒë“œë°•ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì—°êµ¬ëŠ” GPT-5, Claude 4 Sonnet, Gemini 2.5 Pro ë“± ìµœì‹  ì–¸ì–´ ëª¨ë¸ì„ í‰ê°€í•˜ë©°, ì´ ëª¨ë¸ë“¤ì´ ë†’ì€ ì„±ê³µë¥ ë¡œ ì•…ì˜ì  ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. íŠ¹íˆ, ìµœì‹  ëª¨ë¸ì¼ìˆ˜ë¡ ì˜¤ìš© ìœ„í—˜ì´ ë” ë†’ì•„ì§€ëŠ” ê²½í–¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ë˜í•œ, CUAsì˜ ì˜¤ìš© ìœ„í—˜ì„ ì¤„ì´ê¸° ìœ„í•´ ì–¸ì–´ ëª¨ë¸ì„ í™œìš©í•œ ëª¨ë‹ˆí„°ë§ì„ ì‹œë„í–ˆìœ¼ë‚˜, í‰ê·  ì •í™•ë„ê°€ 77%ì— ê·¸ì³¤ìŠµë‹ˆë‹¤. ê³„ì¸µì  ìš”ì•½ ì „ëµì„ í†µí•´ ì„±ëŠ¥ì´ ìµœëŒ€ 13% í–¥ìƒë˜ì—ˆì§€ë§Œ, ì—¬ì „íˆ ì‹ ë¢°í•  ìˆ˜ ì—†ëŠ” ìˆ˜ì¤€ì…ë‹ˆë‹¤. ì´ ë²¤ì¹˜ë§ˆí¬ëŠ” í–¥í›„ ì—°êµ¬ë¥¼ ì´‰ì§„í•˜ê¸° ìœ„í•´ ê³µê°œë  ì˜ˆì •ì…ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. CUAHarm ë²¤ì¹˜ë§ˆí¬ëŠ” ì»´í“¨í„° ì‚¬ìš© ì—ì´ì „íŠ¸(CUAs)ì˜ ì˜¤ìš© ìœ„í—˜ì„ í‰ê°€í•˜ê¸° ìœ„í•´ 104ê°œì˜ ì „ë¬¸ê°€ ì‘ì„± ì‹œë‚˜ë¦¬ì˜¤ë¥¼ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.
- 2. ìµœì²¨ë‹¨ ì–¸ì–´ ëª¨ë¸(LMs)ì€ ì•…ì„± ì‘ì—…ì„ ë†’ì€ ì„±ê³µë¥ ë¡œ ìˆ˜í–‰í•  ìˆ˜ ìˆìœ¼ë©°, ì´ëŠ” ì´ì „ ì•ˆì „ ë²¤ì¹˜ë§ˆí¬ë³´ë‹¤ ë” ë†’ì€ ì˜¤ìš© ìœ„í—˜ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
- 3. UI-TARS-1.5ì™€ ê°™ì€ ì—ì´ì „íŠ¸ í”„ë ˆì„ì›Œí¬ëŠ” ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ì§€ë§Œ ì˜¤ìš© ìœ„í—˜ë„ ì¦ê°€ì‹œí‚µë‹ˆë‹¤.
- 4. CUAsì˜ ì˜¤ìš© ìœ„í—˜ì„ ì™„í™”í•˜ê¸° ìœ„í•´ LMsë¥¼ ì‚¬ìš©í•œ ëª¨ë‹ˆí„°ë§ì´ ì œì•ˆë˜ì—ˆìœ¼ë‚˜, í‰ê·  ëª¨ë‹ˆí„°ë§ ì •í™•ë„ëŠ” 77%ë¡œ ì‹ ë¢°ì„±ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.
- 5. ê³„ì¸µì  ìš”ì•½ ì „ëµì€ ëª¨ë‹ˆí„°ë§ ì„±ëŠ¥ì„ ìµœëŒ€ 13% í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìœ¼ë©°, ì´ëŠ” ìœ ë§í•œ ë°©í–¥ìœ¼ë¡œ í‰ê°€ë©ë‹ˆë‹¤.


---

*Generated on 2025-09-25 16:32:32*