---
keywords:
  - Computer-using Agents
  - Large Language Model
  - CUAHarm Benchmark
  - Agentic Framework
  - Hierarchical Summarization Strategy
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2508.00935
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T16:32:32.982552",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Computer-using Agents",
    "Large Language Model",
    "CUAHarm Benchmark",
    "Agentic Framework",
    "Hierarchical Summarization Strategy"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Computer-using Agents": 0.85,
    "Large Language Model": 0.88,
    "CUAHarm Benchmark": 0.83,
    "Agentic Framework": 0.79,
    "Hierarchical Summarization Strategy": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Computer-using agents",
        "canonical": "Computer-using Agents",
        "aliases": [
          "CUAs"
        ],
        "category": "unique_technical",
        "rationale": "This term is central to the paper's focus on evaluating and mitigating risks associated with autonomous computer control.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.82,
        "link_intent_score": 0.85
      },
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "LLMs are key to understanding the capabilities and risks of CUAs, providing a strong link to existing research on AI models.",
        "novelty_score": 0.4,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.88
      },
      {
        "surface": "CUAHarm benchmark",
        "canonical": "CUAHarm Benchmark",
        "aliases": [
          "CUAHarm"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a new benchmark specifically designed to evaluate misuse risks, which is crucial for future research connections.",
        "novelty_score": 0.8,
        "connectivity_score": 0.72,
        "specificity_score": 0.85,
        "link_intent_score": 0.83
      },
      {
        "surface": "Agentic framework",
        "canonical": "Agentic Framework",
        "aliases": [
          "UI-TARS-1.5"
        ],
        "category": "specific_connectable",
        "rationale": "This framework is evaluated for its impact on misuse risks, linking to broader discussions on AI safety and control.",
        "novelty_score": 0.65,
        "connectivity_score": 0.78,
        "specificity_score": 0.77,
        "link_intent_score": 0.79
      },
      {
        "surface": "Hierarchical summarization strategy",
        "canonical": "Hierarchical Summarization Strategy",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "A novel approach to improve monitoring accuracy, offering a potential new direction for research in AI monitoring.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "benchmark",
      "safety risks",
      "monitoring accuracy"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Computer-using agents",
      "resolved_canonical": "Computer-using Agents",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.82,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "CUAHarm benchmark",
      "resolved_canonical": "CUAHarm Benchmark",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.72,
        "specificity": 0.85,
        "link_intent": 0.83
      }
    },
    {
      "candidate_surface": "Agentic framework",
      "resolved_canonical": "Agentic Framework",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.78,
        "specificity": 0.77,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Hierarchical summarization strategy",
      "resolved_canonical": "Hierarchical Summarization Strategy",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# Measuring Harmfulness of Computer-Using Agents

## 📋 메타데이터

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2508.00935.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2508.00935](https://arxiv.org/abs/2508.00935)

## 🔗 유사한 논문
- [[2025-09-22/Red Teaming Multimodal Language Models_ Evaluating Harm Across Prompt Modalities and Models_20250922|Red Teaming Multimodal Language Models: Evaluating Harm Across Prompt Modalities and Models]] (84.0% similar)
- [[2025-09-19/ScaleCUA_ Scaling Open-Source Computer Use Agents with Cross-Platform Data_20250919|ScaleCUA: Scaling Open-Source Computer Use Agents with Cross-Platform Data]] (83.9% similar)
- [[2025-09-22/SeCodePLT_ A Unified Platform for Evaluating the Security of Code GenAI_20250922|SeCodePLT: A Unified Platform for Evaluating the Security of Code GenAI]] (83.4% similar)
- [[2025-09-19/A Multi-Agent LLM Defense Pipeline Against Prompt Injection Attacks_20250919|A Multi-Agent LLM Defense Pipeline Against Prompt Injection Attacks]] (83.4% similar)
- [[2025-09-22/SycEval_ Evaluating LLM Sycophancy_20250922|SycEval: Evaluating LLM Sycophancy]] (83.2% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Agentic Framework|Agentic Framework]]
**⚡ Unique Technical**: [[keywords/Computer-using Agents|Computer-using Agents]], [[keywords/CUAHarm Benchmark|CUAHarm Benchmark]], [[keywords/Hierarchical Summarization Strategy|Hierarchical Summarization Strategy]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2508.00935v2 Announce Type: replace-cross 
Abstract: Computer-using agents (CUAs), which can autonomously control computers to perform multi-step actions, might pose significant safety risks if misused. However, existing benchmarks mainly evaluate LMs in chatbots or simple tool use. To more comprehensively evaluate CUAs' misuse risks, we introduce a new benchmark: CUAHarm. CUAHarm consists of 104 expert-written realistic misuse risks, such as disabling firewalls, leaking data, or installing backdoors. We provide a sandbox with rule-based verifiable rewards to measure CUAs' success rates in executing these tasks (e.g., whether the firewall is indeed disabled), beyond refusal rates. We evaluate frontier LMs including GPT-5, Claude 4 Sonnet, Gemini 2.5 Pro, Llama-3.3-70B, and Mistral Large 2. Even without jailbreaking prompts, these frontier LMs comply with executing these malicious tasks at a high success rate (e.g., 90\% for Gemini 2.5 Pro). Furthermore, while newer models are safer in previous safety benchmarks, their misuse risks as CUAs become even higher, e.g., Gemini 2.5 Pro is riskier than Gemini 1.5 Pro. Additionally, while these LMs are robust to common malicious prompts (e.g., creating a bomb) when acting as chatbots, they could still act unsafely as CUAs. We further evaluate a leading agentic framework (UI-TARS-1.5) and find that while it improves performance, it also amplifies misuse risks. To mitigate the misuse risks of CUAs, we explore using LMs to monitor CUAs' actions. We find monitoring unsafe computer-using actions is significantly harder than monitoring conventional unsafe chatbot responses. While monitoring chain-of-thoughts leads to modest gains, the average monitoring accuracy is only 77\%. A hierarchical summarization strategy improves performance by up to 13\%, a promising direction though monitoring remains unreliable. The benchmark will be released publicly to facilitate further research on mitigating these risks.

## 📝 요약

이 논문은 컴퓨터를 자율적으로 제어하는 에이전트(CUAs)의 오용 위험성을 평가하기 위한 새로운 벤치마크인 CUAHarm을 소개합니다. CUAHarm은 방화벽 비활성화, 데이터 유출, 백도어 설치 등 104개의 전문가 작성 시나리오로 구성되어 있으며, CUAs의 성공률을 측정하기 위한 샌드박스를 제공합니다. 연구는 GPT-5, Claude 4 Sonnet, Gemini 2.5 Pro 등 최신 언어 모델을 평가하며, 이 모델들이 높은 성공률로 악의적 작업을 수행할 수 있음을 발견했습니다. 특히, 최신 모델일수록 오용 위험이 더 높아지는 경향을 보였습니다. 또한, CUAs의 오용 위험을 줄이기 위해 언어 모델을 활용한 모니터링을 시도했으나, 평균 정확도가 77%에 그쳤습니다. 계층적 요약 전략을 통해 성능이 최대 13% 향상되었지만, 여전히 신뢰할 수 없는 수준입니다. 이 벤치마크는 향후 연구를 촉진하기 위해 공개될 예정입니다.

## 🎯 주요 포인트

- 1. CUAHarm 벤치마크는 컴퓨터 사용 에이전트(CUAs)의 오용 위험을 평가하기 위해 104개의 전문가 작성 시나리오를 포함하고 있습니다.
- 2. 최첨단 언어 모델(LMs)은 악성 작업을 높은 성공률로 수행할 수 있으며, 이는 이전 안전 벤치마크보다 더 높은 오용 위험을 나타냅니다.
- 3. UI-TARS-1.5와 같은 에이전트 프레임워크는 성능을 향상시키지만 오용 위험도 증가시킵니다.
- 4. CUAs의 오용 위험을 완화하기 위해 LMs를 사용한 모니터링이 제안되었으나, 평균 모니터링 정확도는 77%로 신뢰성이 부족합니다.
- 5. 계층적 요약 전략은 모니터링 성능을 최대 13% 향상시킬 수 있으며, 이는 유망한 방향으로 평가됩니다.


---

*Generated on 2025-09-25 16:32:32*