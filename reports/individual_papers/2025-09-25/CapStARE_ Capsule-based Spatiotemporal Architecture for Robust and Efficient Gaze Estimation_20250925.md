---
keywords:
  - Capsule-based Spatiotemporal Architecture
  - Attention Mechanism
  - Dual GRU Decoders
  - Gaze Estimation
  - ConvNeXt Backbone
category: cs.CV
publish_date: 2025-09-25
arxiv_id: 2509.19936
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-26T09:09:42.680350",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Capsule-based Spatiotemporal Architecture",
    "Attention Mechanism",
    "Dual GRU Decoders",
    "Gaze Estimation",
    "ConvNeXt Backbone"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Capsule-based Spatiotemporal Architecture": 0.8,
    "Attention Mechanism": 0.85,
    "Dual GRU Decoders": 0.75,
    "Gaze Estimation": 0.88,
    "ConvNeXt Backbone": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Capsule-based Spatiotemporal Architecture",
        "canonical": "Capsule-based Spatiotemporal Architecture",
        "aliases": [
          "CapStARE"
        ],
        "category": "unique_technical",
        "rationale": "This represents a novel architecture combining capsules and spatiotemporal modeling, which is central to the paper's contributions.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "Attention Routing",
        "canonical": "Attention Mechanism",
        "aliases": [
          "Attention Routing"
        ],
        "category": "specific_connectable",
        "rationale": "Attention mechanisms are crucial for the model's performance and connect well with existing literature on neural networks.",
        "novelty_score": 0.5,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Dual GRU Decoders",
        "canonical": "Dual GRU Decoders",
        "aliases": [
          "GRU Decoders"
        ],
        "category": "unique_technical",
        "rationale": "The dual GRU decoders are a specific technical innovation that supports the model's temporal dynamics handling.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.75
      },
      {
        "surface": "Gaze Estimation",
        "canonical": "Gaze Estimation",
        "aliases": [
          "Eye Tracking"
        ],
        "category": "specific_connectable",
        "rationale": "Gaze estimation is a key application area, linking to broader fields like computer vision and human-computer interaction.",
        "novelty_score": 0.4,
        "connectivity_score": 0.85,
        "specificity_score": 0.8,
        "link_intent_score": 0.88
      },
      {
        "surface": "ConvNeXt Backbone",
        "canonical": "ConvNeXt Backbone",
        "aliases": [
          "ConvNeXt"
        ],
        "category": "unique_technical",
        "rationale": "The use of a ConvNeXt backbone is a specific technical choice that impacts model performance and efficiency.",
        "novelty_score": 0.65,
        "connectivity_score": 0.55,
        "specificity_score": 0.75,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "real-time inference",
      "state-of-the-art performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Capsule-based Spatiotemporal Architecture",
      "resolved_canonical": "Capsule-based Spatiotemporal Architecture",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Attention Routing",
      "resolved_canonical": "Attention Mechanism",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Dual GRU Decoders",
      "resolved_canonical": "Dual GRU Decoders",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Gaze Estimation",
      "resolved_canonical": "Gaze Estimation",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.85,
        "specificity": 0.8,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "ConvNeXt Backbone",
      "resolved_canonical": "ConvNeXt Backbone",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.55,
        "specificity": 0.75,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# CapStARE: Capsule-based Spatiotemporal Architecture for Robust and Efficient Gaze Estimation

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19936.pdf)
**Category**: cs.CV
**Published**: 2025-09-25
**ArXiv ID**: [2509.19936](https://arxiv.org/abs/2509.19936)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Beat on Gaze_ Learning Stylized Generation of Gaze and Head Dynamics_20250923|Beat on Gaze: Learning Stylized Generation of Gaze and Head Dynamics]] (81.5% similar)
- [[2025-09-23/CGTGait_ Collaborative Graph and Transformer for Gait Emotion Recognition_20250923|CGTGait: Collaborative Graph and Transformer for Gait Emotion Recognition]] (81.2% similar)
- [[2025-09-19/Roll Your Eyes_ Gaze Redirection via Explicit 3D Eyeball Rotation_20250919|Roll Your Eyes: Gaze Redirection via Explicit 3D Eyeball Rotation]] (80.9% similar)
- [[2025-09-23/ST-GS_ Vision-Based 3D Semantic Occupancy Prediction with Spatial-Temporal Gaussian Splatting_20250923|ST-GS: Vision-Based 3D Semantic Occupancy Prediction with Spatial-Temporal Gaussian Splatting]] (80.8% similar)
- [[2025-09-22/Global Regulation and Excitation via Attention Tuning for Stereo Matching_20250922|Global Regulation and Excitation via Attention Tuning for Stereo Matching]] (80.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Attention Mechanism|Attention Mechanism]], [[keywords/Gaze Estimation|Gaze Estimation]]
**âš¡ Unique Technical**: [[keywords/Capsule-based Spatiotemporal Architecture|Capsule-based Spatiotemporal Architecture]], [[keywords/Dual GRU Decoders|Dual GRU Decoders]], [[keywords/ConvNeXt Backbone|ConvNeXt Backbone]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19936v1 Announce Type: new 
Abstract: We introduce CapStARE, a capsule-based spatio-temporal architecture for gaze estimation that integrates a ConvNeXt backbone, capsule formation with attention routing, and dual GRU decoders specialized for slow and rapid gaze dynamics. This modular design enables efficient part-whole reasoning and disentangled temporal modeling, achieving state-of-the-art performance on ETH-XGaze (3.36) and MPIIFaceGaze (2.65) while maintaining real-time inference (< 10 ms). The model also generalizes well to unconstrained conditions in Gaze360 (9.06) and human-robot interaction scenarios in RT-GENE (4.76), outperforming or matching existing methods with fewer parameters and greater interpretability. These results demonstrate that CapStARE offers a practical and robust solution for real-time gaze estimation in interactive systems. The related code and results for this article can be found on: https://github.com/toukapy/capsStare

## ğŸ“ ìš”ì•½

CapStAREëŠ” ì‹œì„  ì¶”ì •ì„ ìœ„í•œ ìº¡ìŠ ê¸°ë°˜ ì‹œê³µê°„ ì•„í‚¤í…ì²˜ë¡œ, ConvNeXt ë°±ë³¸, ì£¼ì˜ ë¼ìš°íŒ…ì„ í†µí•œ ìº¡ìŠ í˜•ì„±, ê·¸ë¦¬ê³  ëŠë¦¬ê³  ë¹ ë¥¸ ì‹œì„  ë™ì‘ì— íŠ¹í™”ëœ ì´ì¤‘ GRU ë””ì½”ë”ë¥¼ í†µí•©í•©ë‹ˆë‹¤. ì´ ëª¨ë“ˆì‹ ì„¤ê³„ëŠ” íš¨ìœ¨ì ì¸ ë¶€ë¶„-ì „ì²´ ì¶”ë¡ ê³¼ ë¶„ë¦¬ëœ ì‹œê°„ ëª¨ë¸ë§ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ì—¬, ETH-XGazeì™€ MPIIFaceGaze ë°ì´í„°ì…‹ì—ì„œ ê°ê° 3.36ê³¼ 2.65ì˜ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ë©° ì‹¤ì‹œê°„ ì¶”ë¡ ì„ ìœ ì§€í•©ë‹ˆë‹¤. ë˜í•œ Gaze360ê³¼ RT-GENE ì‹œë‚˜ë¦¬ì˜¤ì—ì„œë„ ìš°ìˆ˜í•œ ì¼ë°˜í™” ì„±ëŠ¥ì„ ë³´ì´ë©°, ì ì€ íŒŒë¼ë¯¸í„°ë¡œ ê¸°ì¡´ ë°©ë²•ë“¤ì„ ëŠ¥ê°€í•˜ê±°ë‚˜ ë™ë“±í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤. ì´ëŠ” CapStAREê°€ ëŒ€í™”í˜• ì‹œìŠ¤í…œì—ì„œ ì‹¤ì‹œê°„ ì‹œì„  ì¶”ì •ì„ ìœ„í•œ ì‹¤ìš©ì ì´ê³  ê²¬ê³ í•œ ì†”ë£¨ì…˜ì„ì„ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. CapStAREëŠ” ConvNeXt ë°±ë³¸ê³¼ ìº¡ìŠ í˜•ì„±, ì£¼ì˜ ë¼ìš°íŒ…, ì´ì¤‘ GRU ë””ì½”ë”ë¥¼ í†µí•©í•˜ì—¬ ì‹œê³µê°„ì  ì‹œì„  ì¶”ì •ì„ ìˆ˜í–‰í•˜ëŠ” ìº¡ìŠ ê¸°ë°˜ ì•„í‚¤í…ì²˜ì…ë‹ˆë‹¤.
- 2. ì´ ëª¨ë“ˆí˜• ì„¤ê³„ëŠ” íš¨ìœ¨ì ì¸ ë¶€ë¶„-ì „ì²´ ì¶”ë¡ ê³¼ ë¶„ë¦¬ëœ ì‹œê°„ ëª¨ë¸ë§ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ì—¬ ETH-XGazeì™€ MPIIFaceGazeì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í•©ë‹ˆë‹¤.
- 3. CapStAREëŠ” ì‹¤ì‹œê°„ ì¶”ë¡ ì„ ìœ ì§€í•˜ë©´ì„œ Gaze360 ë° RT-GENEì™€ ê°™ì€ ë¹„ì œì•½ ì¡°ê±´ ë° ì¸ê°„-ë¡œë´‡ ìƒí˜¸ì‘ìš© ì‹œë‚˜ë¦¬ì˜¤ì—ì„œë„ ê¸°ì¡´ ë°©ë²•ë³´ë‹¤ ë” ì ì€ íŒŒë¼ë¯¸í„°ë¡œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.
- 4. ì´ ëª¨ë¸ì€ ëŒ€í™”í˜• ì‹œìŠ¤í…œì—ì„œ ì‹¤ì‹œê°„ ì‹œì„  ì¶”ì •ì„ ìœ„í•œ ì‹¤ìš©ì ì´ê³  ê²¬ê³ í•œ ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.
- 5. ê´€ë ¨ ì½”ë“œì™€ ê²°ê³¼ëŠ” GitHubì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤: https://github.com/toukapy/capsStare


---

*Generated on 2025-09-26 09:09:42*