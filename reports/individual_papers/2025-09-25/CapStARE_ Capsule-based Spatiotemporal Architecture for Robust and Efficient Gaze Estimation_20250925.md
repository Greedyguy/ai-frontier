---
keywords:
  - Capsule-based Spatiotemporal Architecture
  - Attention Mechanism
  - Dual GRU Decoders
  - Gaze Estimation
  - ConvNeXt Backbone
category: cs.CV
publish_date: 2025-09-25
arxiv_id: 2509.19936
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-26T09:09:42.680350",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Capsule-based Spatiotemporal Architecture",
    "Attention Mechanism",
    "Dual GRU Decoders",
    "Gaze Estimation",
    "ConvNeXt Backbone"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Capsule-based Spatiotemporal Architecture": 0.8,
    "Attention Mechanism": 0.85,
    "Dual GRU Decoders": 0.75,
    "Gaze Estimation": 0.88,
    "ConvNeXt Backbone": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Capsule-based Spatiotemporal Architecture",
        "canonical": "Capsule-based Spatiotemporal Architecture",
        "aliases": [
          "CapStARE"
        ],
        "category": "unique_technical",
        "rationale": "This represents a novel architecture combining capsules and spatiotemporal modeling, which is central to the paper's contributions.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "Attention Routing",
        "canonical": "Attention Mechanism",
        "aliases": [
          "Attention Routing"
        ],
        "category": "specific_connectable",
        "rationale": "Attention mechanisms are crucial for the model's performance and connect well with existing literature on neural networks.",
        "novelty_score": 0.5,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Dual GRU Decoders",
        "canonical": "Dual GRU Decoders",
        "aliases": [
          "GRU Decoders"
        ],
        "category": "unique_technical",
        "rationale": "The dual GRU decoders are a specific technical innovation that supports the model's temporal dynamics handling.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.75
      },
      {
        "surface": "Gaze Estimation",
        "canonical": "Gaze Estimation",
        "aliases": [
          "Eye Tracking"
        ],
        "category": "specific_connectable",
        "rationale": "Gaze estimation is a key application area, linking to broader fields like computer vision and human-computer interaction.",
        "novelty_score": 0.4,
        "connectivity_score": 0.85,
        "specificity_score": 0.8,
        "link_intent_score": 0.88
      },
      {
        "surface": "ConvNeXt Backbone",
        "canonical": "ConvNeXt Backbone",
        "aliases": [
          "ConvNeXt"
        ],
        "category": "unique_technical",
        "rationale": "The use of a ConvNeXt backbone is a specific technical choice that impacts model performance and efficiency.",
        "novelty_score": 0.65,
        "connectivity_score": 0.55,
        "specificity_score": 0.75,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "real-time inference",
      "state-of-the-art performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Capsule-based Spatiotemporal Architecture",
      "resolved_canonical": "Capsule-based Spatiotemporal Architecture",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Attention Routing",
      "resolved_canonical": "Attention Mechanism",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Dual GRU Decoders",
      "resolved_canonical": "Dual GRU Decoders",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Gaze Estimation",
      "resolved_canonical": "Gaze Estimation",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.85,
        "specificity": 0.8,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "ConvNeXt Backbone",
      "resolved_canonical": "ConvNeXt Backbone",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.55,
        "specificity": 0.75,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# CapStARE: Capsule-based Spatiotemporal Architecture for Robust and Efficient Gaze Estimation

## 📋 메타데이터

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19936.pdf)
**Category**: cs.CV
**Published**: 2025-09-25
**ArXiv ID**: [2509.19936](https://arxiv.org/abs/2509.19936)

## 🔗 유사한 논문
- [[2025-09-23/Beat on Gaze_ Learning Stylized Generation of Gaze and Head Dynamics_20250923|Beat on Gaze: Learning Stylized Generation of Gaze and Head Dynamics]] (81.5% similar)
- [[2025-09-23/CGTGait_ Collaborative Graph and Transformer for Gait Emotion Recognition_20250923|CGTGait: Collaborative Graph and Transformer for Gait Emotion Recognition]] (81.2% similar)
- [[2025-09-19/Roll Your Eyes_ Gaze Redirection via Explicit 3D Eyeball Rotation_20250919|Roll Your Eyes: Gaze Redirection via Explicit 3D Eyeball Rotation]] (80.9% similar)
- [[2025-09-23/ST-GS_ Vision-Based 3D Semantic Occupancy Prediction with Spatial-Temporal Gaussian Splatting_20250923|ST-GS: Vision-Based 3D Semantic Occupancy Prediction with Spatial-Temporal Gaussian Splatting]] (80.8% similar)
- [[2025-09-22/Global Regulation and Excitation via Attention Tuning for Stereo Matching_20250922|Global Regulation and Excitation via Attention Tuning for Stereo Matching]] (80.5% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Attention Mechanism|Attention Mechanism]], [[keywords/Gaze Estimation|Gaze Estimation]]
**⚡ Unique Technical**: [[keywords/Capsule-based Spatiotemporal Architecture|Capsule-based Spatiotemporal Architecture]], [[keywords/Dual GRU Decoders|Dual GRU Decoders]], [[keywords/ConvNeXt Backbone|ConvNeXt Backbone]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.19936v1 Announce Type: new 
Abstract: We introduce CapStARE, a capsule-based spatio-temporal architecture for gaze estimation that integrates a ConvNeXt backbone, capsule formation with attention routing, and dual GRU decoders specialized for slow and rapid gaze dynamics. This modular design enables efficient part-whole reasoning and disentangled temporal modeling, achieving state-of-the-art performance on ETH-XGaze (3.36) and MPIIFaceGaze (2.65) while maintaining real-time inference (< 10 ms). The model also generalizes well to unconstrained conditions in Gaze360 (9.06) and human-robot interaction scenarios in RT-GENE (4.76), outperforming or matching existing methods with fewer parameters and greater interpretability. These results demonstrate that CapStARE offers a practical and robust solution for real-time gaze estimation in interactive systems. The related code and results for this article can be found on: https://github.com/toukapy/capsStare

## 📝 요약

CapStARE는 시선 추정을 위한 캡슐 기반 시공간 아키텍처로, ConvNeXt 백본, 주의 라우팅을 통한 캡슐 형성, 그리고 느리고 빠른 시선 동작에 특화된 이중 GRU 디코더를 통합합니다. 이 모듈식 설계는 효율적인 부분-전체 추론과 분리된 시간 모델링을 가능하게 하여, ETH-XGaze와 MPIIFaceGaze 데이터셋에서 각각 3.36과 2.65의 최첨단 성능을 달성하며 실시간 추론을 유지합니다. 또한 Gaze360과 RT-GENE 시나리오에서도 우수한 일반화 성능을 보이며, 적은 파라미터로 기존 방법들을 능가하거나 동등한 성능을 보입니다. 이는 CapStARE가 대화형 시스템에서 실시간 시선 추정을 위한 실용적이고 견고한 솔루션임을 입증합니다.

## 🎯 주요 포인트

- 1. CapStARE는 ConvNeXt 백본과 캡슐 형성, 주의 라우팅, 이중 GRU 디코더를 통합하여 시공간적 시선 추정을 수행하는 캡슐 기반 아키텍처입니다.
- 2. 이 모듈형 설계는 효율적인 부분-전체 추론과 분리된 시간 모델링을 가능하게 하여 ETH-XGaze와 MPIIFaceGaze에서 최첨단 성능을 달성합니다.
- 3. CapStARE는 실시간 추론을 유지하면서 Gaze360 및 RT-GENE와 같은 비제약 조건 및 인간-로봇 상호작용 시나리오에서도 기존 방법보다 더 적은 파라미터로 우수한 성능을 보입니다.
- 4. 이 모델은 대화형 시스템에서 실시간 시선 추정을 위한 실용적이고 견고한 솔루션을 제공합니다.
- 5. 관련 코드와 결과는 GitHub에서 확인할 수 있습니다: https://github.com/toukapy/capsStare


---

*Generated on 2025-09-26 09:09:42*