---
keywords:
  - Large Language Model
  - Multimodal Learning
  - Surgical Scene Understanding
  - Attention Mechanism
  - Robot-Assisted Surgery
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2506.17873
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T16:28:26.830298",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Multimodal Learning",
    "Surgical Scene Understanding",
    "Attention Mechanism",
    "Robot-Assisted Surgery"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Multimodal Learning": 0.82,
    "Surgical Scene Understanding": 0.8,
    "Attention Mechanism": 0.78,
    "Robot-Assisted Surgery": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Model",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "It is a foundational technology in the paper, connecting to various applications in AI.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Multimodal Large Language Models",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal LLMs"
        ],
        "category": "specific_connectable",
        "rationale": "This connects the paper to the growing field of integrating multiple data types in AI.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "Surgical scene understanding",
        "canonical": "Surgical Scene Understanding",
        "aliases": [
          "Surgical Video Analysis"
        ],
        "category": "unique_technical",
        "rationale": "This is a unique application area that the paper addresses, linking to medical AI research.",
        "novelty_score": 0.75,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Multi-frequency Fusion Attention",
        "canonical": "Attention Mechanism",
        "aliases": [
          "Fusion Attention"
        ],
        "category": "specific_connectable",
        "rationale": "This is a specific technique that enhances understanding of video content, linking to advanced AI methods.",
        "novelty_score": 0.65,
        "connectivity_score": 0.85,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "robot-assisted surgery",
        "canonical": "Robot-Assisted Surgery",
        "aliases": [
          "Robotic Surgery"
        ],
        "category": "unique_technical",
        "rationale": "This is a specific application domain that benefits from the proposed model, linking to robotics in healthcare.",
        "novelty_score": 0.7,
        "connectivity_score": 0.75,
        "specificity_score": 0.88,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Model",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Multimodal Large Language Models",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Surgical scene understanding",
      "resolved_canonical": "Surgical Scene Understanding",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Multi-frequency Fusion Attention",
      "resolved_canonical": "Attention Mechanism",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.85,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "robot-assisted surgery",
      "resolved_canonical": "Robot-Assisted Surgery",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.75,
        "specificity": 0.88,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# SurgVidLM: Towards Multi-grained Surgical Video Understanding with Large Language Model

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2506.17873.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2506.17873](https://arxiv.org/abs/2506.17873)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Surgical-MambaLLM_ Mamba2-enhanced Multimodal Large Language Model for VQLA in Robotic Surgery_20250923|Surgical-MambaLLM: Mamba2-enhanced Multimodal Large Language Model for VQLA in Robotic Surgery]] (88.4% similar)
- [[2025-09-22/Data-Efficient Learning for Generalizable Surgical Video Understanding_20250922|Data-Efficient Learning for Generalizable Surgical Video Understanding]] (86.2% similar)
- [[2025-09-19/Unleashing the Potential of Multimodal LLMs for Zero-Shot Spatio-Temporal Video Grounding_20250919|Unleashing the Potential of Multimodal LLMs for Zero-Shot Spatio-Temporal Video Grounding]] (83.6% similar)
- [[2025-09-24/LongLLaVA_ Scaling Multi-modal LLMs to 1000 Images Efficiently via a Hybrid Architecture_20250924|LongLLaVA: Scaling Multi-modal LLMs to 1000 Images Efficiently via a Hybrid Architecture]] (83.2% similar)
- [[2025-09-22/Enhancing Sa2VA for Referent Video Object Segmentation_ 2nd Solution for 7th LSVOS RVOS Track_20250922|Enhancing Sa2VA for Referent Video Object Segmentation: 2nd Solution for 7th LSVOS RVOS Track]] (83.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]], [[keywords/Attention Mechanism|Attention Mechanism]]
**âš¡ Unique Technical**: [[keywords/Surgical Scene Understanding|Surgical Scene Understanding]], [[keywords/Robot-Assisted Surgery|Robot-Assisted Surgery]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2506.17873v2 Announce Type: replace-cross 
Abstract: Surgical scene understanding is critical for surgical training and robotic decision-making in robot-assisted surgery. Recent advances in Multimodal Large Language Models (MLLMs) have demonstrated great potential for advancing scene perception in the medical domain, facilitating surgeons to understand surgical scenes and procedures. However, these methods are primarily oriented towards image-based analysis or global video understanding, overlooking the fine-grained video reasoning that is crucial for analyzing specific processes and capturing detailed task execution within a surgical procedure. To bridge this gap, we propose SurgVidLM, the first video language model designed to address both full and fine-grained surgical video comprehension. To train our SurgVidLM, we construct the SVU-31K that is a large-scale dataset with over 31K video-instruction pairs, enabling both holistic understanding and detailed analysis of surgical procedures. Building on this resource, SurgVidLM incorporates a two-stage StageFocus mechanism: the first stage extracts global procedural context, while the second stage performs high-frequency local analysis guided by temporal cues. We also develop the Multi-frequency Fusion Attention to effectively integrate low- and high-frequency visual tokens, ensuring the preservation of critical task-specific details. Experimental results demonstrate that SurgVidLM significantly outperforms state-of-the-art Vid-LLMs of comparable parameter scale in both full and fine-grained video understanding tasks, showcasing its superior capability in capturing the context of complex robot-assisted surgeries. Our code and dataset will be publicly accessible soon.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë¡œë´‡ ë³´ì¡° ìˆ˜ìˆ ì—ì„œ ì¤‘ìš”í•œ ìˆ˜ìˆ  ì¥ë©´ ì´í•´ë¥¼ ê°œì„ í•˜ê¸° ìœ„í•´ SurgVidLMì´ë¼ëŠ” ë¹„ë””ì˜¤ ì–¸ì–´ ëª¨ë¸ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë‹¤ì¤‘ëª¨ë“œ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì€ ì´ë¯¸ì§€ ê¸°ë°˜ ë¶„ì„ì— ì¹˜ì¤‘í–ˆìœ¼ë‚˜, SurgVidLMì€ ì „ì²´ì ì¸ ì´í•´ì™€ ì„¸ë¶€ì ì¸ ë¶„ì„ì„ ëª¨ë‘ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ 31,000ê°œ ì´ìƒì˜ ë¹„ë””ì˜¤-ì„¤ëª… ìŒìœ¼ë¡œ êµ¬ì„±ëœ ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ SVU-31Kë¥¼ êµ¬ì¶•í•˜ì˜€ê³ , ë‘ ë‹¨ê³„ì˜ StageFocus ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´ ì „ë°˜ì ì¸ ì ˆì°¨ ë§¥ë½ê³¼ ì„¸ë¶€ì ì¸ ì‘ì—…ì„ ë¶„ì„í•©ë‹ˆë‹¤. ë˜í•œ, Multi-frequency Fusion Attentionì„ í†µí•´ ì‹œê°ì  ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í†µí•©í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, SurgVidLMì€ ê¸°ì¡´ ëª¨ë¸ë³´ë‹¤ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì´ë©°, ë³µì¡í•œ ë¡œë´‡ ìˆ˜ìˆ ì˜ ë§¥ë½ì„ ì˜ í¬ì°©í•©ë‹ˆë‹¤. ì½”ë“œì™€ ë°ì´í„°ì…‹ì€ ê³§ ê³µê°œë  ì˜ˆì •ì…ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. SurgVidLMì€ ë¡œë´‡ ë³´ì¡° ìˆ˜ìˆ ì—ì„œ ì „ì²´ ë° ì„¸ë¶€ì ì¸ ìˆ˜ìˆ  ë¹„ë””ì˜¤ ì´í•´ë¥¼ ëª©í‘œë¡œ í•˜ëŠ” ìµœì´ˆì˜ ë¹„ë””ì˜¤ ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤.
- 2. SurgVidLMì€ 31K ì´ìƒì˜ ë¹„ë””ì˜¤-ì„¤ëª… ìŒì„ í¬í•¨í•œ ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ SVU-31Kë¥¼ í™œìš©í•˜ì—¬ ìˆ˜ìˆ  ì ˆì°¨ì˜ ì „ì²´ì  ì´í•´ì™€ ì„¸ë¶€ ë¶„ì„ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
- 3. StageFocus ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´ ì²« ë²ˆì§¸ ë‹¨ê³„ì—ì„œ ì „ë°˜ì ì¸ ì ˆì°¨ì  ë§¥ë½ì„ ì¶”ì¶œí•˜ê³ , ë‘ ë²ˆì§¸ ë‹¨ê³„ì—ì„œ ì‹œê°„ì  ë‹¨ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„¸ë¶€ì ì¸ ì§€ì—­ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
- 4. Multi-frequency Fusion Attentionì„ ê°œë°œí•˜ì—¬ ì €ì£¼íŒŒ ë° ê³ ì£¼íŒŒ ì‹œê° í† í°ì„ íš¨ê³¼ì ìœ¼ë¡œ í†µí•©í•˜ê³ , ì¤‘ìš”í•œ ì‘ì—… ì„¸ë¶€ ì‚¬í•­ì„ ë³´ì¡´í•©ë‹ˆë‹¤.
- 5. ì‹¤í—˜ ê²°ê³¼, SurgVidLMì€ ìœ ì‚¬í•œ íŒŒë¼ë¯¸í„° ê·œëª¨ì˜ ìµœì‹  Vid-LLMsë³´ë‹¤ ì „ì²´ ë° ì„¸ë¶€ì ì¸ ë¹„ë””ì˜¤ ì´í•´ ì‘ì—…ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.


---

*Generated on 2025-09-25 16:28:26*