---
keywords:
  - Machine Translation
  - Large Language Model
  - Translation Evaluation
  - Model Rotation
  - xCOMET
category: cs.CL
publish_date: 2025-09-25
arxiv_id: 2509.19611
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-26T08:43:58.287973",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Machine Translation",
    "Large Language Model",
    "Translation Evaluation",
    "Model Rotation",
    "xCOMET"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Machine Translation": 0.82,
    "Large Language Model": 0.8,
    "Translation Evaluation": 0.78,
    "Model Rotation": 0.77,
    "xCOMET": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "machine translation systems",
        "canonical": "Machine Translation",
        "aliases": [
          "MT",
          "translation systems"
        ],
        "category": "specific_connectable",
        "rationale": "Machine Translation is a key area within NLP and connects well with translation evaluation tasks.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "language models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "language models"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are central to the paper's focus on translation evaluation.",
        "novelty_score": 0.45,
        "connectivity_score": 0.92,
        "specificity_score": 0.65,
        "link_intent_score": 0.8
      },
      {
        "surface": "translation evaluation",
        "canonical": "Translation Evaluation",
        "aliases": [
          "evaluation of translation",
          "translation quality assessment"
        ],
        "category": "unique_technical",
        "rationale": "This is a unique technical concept central to the paper's methodology.",
        "novelty_score": 0.7,
        "connectivity_score": 0.75,
        "specificity_score": 0.82,
        "link_intent_score": 0.78
      },
      {
        "surface": "model rotation",
        "canonical": "Model Rotation",
        "aliases": [
          "rotation of models"
        ],
        "category": "unique_technical",
        "rationale": "Model rotation is a specific technique introduced in the paper, relevant for linking novel methods.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      },
      {
        "surface": "xCOMET",
        "canonical": "xCOMET",
        "aliases": [
          "COMET",
          "xCOMET evaluation"
        ],
        "category": "unique_technical",
        "rationale": "xCOMET is a specific evaluation system used as a benchmark in the study.",
        "novelty_score": 0.68,
        "connectivity_score": 0.67,
        "specificity_score": 0.85,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "quality"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "machine translation systems",
      "resolved_canonical": "Machine Translation",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "language models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.92,
        "specificity": 0.65,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "translation evaluation",
      "resolved_canonical": "Translation Evaluation",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.75,
        "specificity": 0.82,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "model rotation",
      "resolved_canonical": "Model Rotation",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "xCOMET",
      "resolved_canonical": "xCOMET",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.67,
        "specificity": 0.85,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Evaluating Language Translation Models by Playing Telephone

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19611.pdf)
**Category**: cs.CL
**Published**: 2025-09-25
**ArXiv ID**: [2509.19611](https://arxiv.org/abs/2509.19611)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/Audio-Based Crowd-Sourced Evaluation of Machine Translation Quality_20250918|Audio-Based Crowd-Sourced Evaluation of Machine Translation Quality]] (85.3% similar)
- [[2025-09-23/Extending Automatic Machine Translation Evaluation to Book-Length Documents_20250923|Extending Automatic Machine Translation Evaluation to Book-Length Documents]] (85.0% similar)
- [[2025-09-17/Long-context Reference-based MT Quality Estimation_20250917|Long-context Reference-based MT Quality Estimation]] (84.8% similar)
- [[2025-09-24/Please Translate Again_ Two Simple Experiments on Whether Human-Like Reasoning Helps Translation_20250924|Please Translate Again: Two Simple Experiments on Whether Human-Like Reasoning Helps Translation]] (84.4% similar)
- [[2025-09-25/Feeding Two Birds or Favoring One? Adequacy-Fluency Tradeoffs in Evaluation and Meta-Evaluation of Machine Translation_20250925|Feeding Two Birds or Favoring One? Adequacy-Fluency Tradeoffs in Evaluation and Meta-Evaluation of Machine Translation]] (84.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Machine Translation|Machine Translation]]
**âš¡ Unique Technical**: [[keywords/Translation Evaluation|Translation Evaluation]], [[keywords/Model Rotation|Model Rotation]], [[keywords/xCOMET|xCOMET]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19611v1 Announce Type: new 
Abstract: Our ability to efficiently and accurately evaluate the quality of machine translation systems has been outrun by the effectiveness of current language models--which limits the potential for further improving these models on more challenging tasks like long-form and literary translation. We propose an unsupervised method to generate training data for translation evaluation over different document lengths and application domains by repeated rounds of translation between source and target languages. We evaluate evaluation systems trained on texts mechanically generated using both model rotation and language translation approaches, demonstrating improved performance over a popular translation evaluation system (xCOMET) on two different tasks: (i) scoring the quality of a given translation against a human reference and (ii) selecting which of two translations is generationally closer to an original source document.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ê¸°ê³„ ë²ˆì—­ ì‹œìŠ¤í…œì˜ í’ˆì§ˆ í‰ê°€ë¥¼ ê°œì„ í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ë¹„ì§€ë„ í•™ìŠµ ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ ì–¸ì–´ ëª¨ë¸ì˜ íš¨ê³¼ê°€ ë›°ì–´ë‚˜ì§€ë§Œ, ì¥ë¬¸ ë° ë¬¸í•™ ë²ˆì—­ê³¼ ê°™ì€ ë” ì–´ë ¤ìš´ ì‘ì—…ì—ì„œì˜ ê°œì„  ê°€ëŠ¥ì„±ì„ ì œí•œí•˜ê³  ìˆìŠµë‹ˆë‹¤. ì œì•ˆëœ ë°©ë²•ì€ ì›ë¬¸ê³¼ ë²ˆì—­ë¬¸ ê°„ì˜ ë°˜ë³µ ë²ˆì—­ì„ í†µí•´ ë‹¤ì–‘í•œ ë¬¸ì„œ ê¸¸ì´ì™€ ì‘ìš© ë¶„ì•¼ì— ëŒ€í•œ í›ˆë ¨ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ëª¨ë¸ íšŒì „ ë° ì–¸ì–´ ë²ˆì—­ ì ‘ê·¼ë²•ì„ ì‚¬ìš©í•˜ì—¬ ê¸°ê³„ì ìœ¼ë¡œ ìƒì„±ëœ í…ìŠ¤íŠ¸ë¡œ í›ˆë ¨ëœ í‰ê°€ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ë©°, ì¸ê¸° ìˆëŠ” ë²ˆì—­ í‰ê°€ ì‹œìŠ¤í…œì¸ xCOMETë³´ë‹¤ ë‘ ê°€ì§€ ì‘ì—…ì—ì„œ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤: (i) ì£¼ì–´ì§„ ë²ˆì—­ì˜ í’ˆì§ˆì„ ì¸ê°„ ì°¸ì¡°ì™€ ë¹„êµí•˜ì—¬ í‰ê°€í•˜ëŠ” ê²ƒê³¼ (ii) ë‘ ë²ˆì—­ ì¤‘ ì›ë³¸ ë¬¸ì„œì— ë” ê°€ê¹Œìš´ ë²ˆì—­ì„ ì„ íƒí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. í˜„ì¬ ì–¸ì–´ ëª¨ë¸ì˜ íš¨ê³¼ì„±ì€ ê¸°ê³„ ë²ˆì—­ ì‹œìŠ¤í…œì˜ í’ˆì§ˆ í‰ê°€ ëŠ¥ë ¥ì„ ì´ˆê³¼í•˜ê³  ìˆì–´, ì¥ë¬¸ ë° ë¬¸í•™ ë²ˆì—­ê³¼ ê°™ì€ ë” ë„ì „ì ì¸ ì‘ì—…ì—ì„œ ëª¨ë¸ ê°œì„ ì˜ ì ì¬ë ¥ì„ ì œí•œí•˜ê³  ìˆë‹¤.
- 2. ìš°ë¦¬ëŠ” ì†ŒìŠ¤ì™€ íƒ€ê²Ÿ ì–¸ì–´ ê°„ì˜ ë°˜ë³µ ë²ˆì—­ì„ í†µí•´ ë‹¤ì–‘í•œ ë¬¸ì„œ ê¸¸ì´ì™€ ì‘ìš© ë¶„ì•¼ì— ëŒ€í•œ ë²ˆì—­ í‰ê°€ í›ˆë ¨ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ë¹„ì§€ë„ í•™ìŠµ ë°©ë²•ì„ ì œì•ˆí•œë‹¤.
- 3. ëª¨ë¸ íšŒì „ ë° ì–¸ì–´ ë²ˆì—­ ì ‘ê·¼ ë°©ì‹ì„ ì‚¬ìš©í•˜ì—¬ ê¸°ê³„ì ìœ¼ë¡œ ìƒì„±ëœ í…ìŠ¤íŠ¸ë¡œ í›ˆë ¨ëœ í‰ê°€ ì‹œìŠ¤í…œì€ ì¸ê¸° ìˆëŠ” ë²ˆì—­ í‰ê°€ ì‹œìŠ¤í…œ(xCOMET)ë³´ë‹¤ ë‘ ê°€ì§€ ì‘ì—…ì—ì„œ í–¥ìƒëœ ì„±ëŠ¥ì„ ë³´ì—¬ì¤€ë‹¤.
- 4. ì œì•ˆëœ ì‹œìŠ¤í…œì€ ì£¼ì–´ì§„ ë²ˆì—­ì˜ í’ˆì§ˆì„ ì¸ê°„ ì°¸ì¡°ì™€ ë¹„êµí•˜ì—¬ í‰ê°€í•˜ê³ , ë‘ ë²ˆì—­ ì¤‘ ì›ë³¸ ì†ŒìŠ¤ ë¬¸ì„œì— ë” ê°€ê¹Œìš´ ë²ˆì—­ì„ ì„ íƒí•˜ëŠ” ì‘ì—…ì—ì„œ ì„±ëŠ¥ì„ ì…ì¦í•œë‹¤.


---

*Generated on 2025-09-26 08:43:58*