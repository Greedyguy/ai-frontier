---
keywords:
  - Large Language Model
  - Approximate Bayesian Computation
  - Predictive Probability
  - Expected Calibration Error
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2509.19375
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T15:32:27.897020",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Approximate Bayesian Computation",
    "Predictive Probability",
    "Expected Calibration Error"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Approximate Bayesian Computation": 0.8,
    "Predictive Probability": 0.78,
    "Expected Calibration Error": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's focus, linking to a well-established concept in AI.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.8,
        "link_intent_score": 0.85
      },
      {
        "surface": "Approximate Bayesian Computation",
        "canonical": "Approximate Bayesian Computation",
        "aliases": [
          "ABC"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel approach for uncertainty quantification in LLMs.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "predictive probabilities",
        "canonical": "Predictive Probability",
        "aliases": [
          "predictive probabilities"
        ],
        "category": "specific_connectable",
        "rationale": "Key concept for understanding the output of LLMs in this context.",
        "novelty_score": 0.5,
        "connectivity_score": 0.7,
        "specificity_score": 0.75,
        "link_intent_score": 0.78
      },
      {
        "surface": "Expected Calibration Error",
        "canonical": "Expected Calibration Error",
        "aliases": [
          "ECE"
        ],
        "category": "specific_connectable",
        "rationale": "Important metric for evaluating model calibration, relevant to the paper's findings.",
        "novelty_score": 0.55,
        "connectivity_score": 0.72,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "model logits",
      "elicited probabilities"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.8,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Approximate Bayesian Computation",
      "resolved_canonical": "Approximate Bayesian Computation",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "predictive probabilities",
      "resolved_canonical": "Predictive Probability",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.7,
        "specificity": 0.75,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Expected Calibration Error",
      "resolved_canonical": "Expected Calibration Error",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.72,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Uncertainty Quantification of Large Language Models using Approximate Bayesian Computation

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19375.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2509.19375](https://arxiv.org/abs/2509.19375)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Calibrating LLM Confidence by Probing Perturbed Representation Stability_20250922|Calibrating LLM Confidence by Probing Perturbed Representation Stability]] (86.9% similar)
- [[2025-09-22/Quantifying Self-Awareness of Knowledge in Large Language Models_20250922|Quantifying Self-Awareness of Knowledge in Large Language Models]] (85.9% similar)
- [[2025-09-17/Simulating a Bias Mitigation Scenario in Large Language Models_20250917|Simulating a Bias Mitigation Scenario in Large Language Models]] (85.7% similar)
- [[2025-09-22/Quantifying Uncertainty in Natural Language Explanations of Large Language Models for Question Answering_20250922|Quantifying Uncertainty in Natural Language Explanations of Large Language Models for Question Answering]] (85.5% similar)
- [[2025-09-24/Advances in Large Language Models for Medicine_20250924|Advances in Large Language Models for Medicine]] (85.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Predictive Probability|Predictive Probability]], [[keywords/Expected Calibration Error|Expected Calibration Error]]
**âš¡ Unique Technical**: [[keywords/Approximate Bayesian Computation|Approximate Bayesian Computation]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19375v1 Announce Type: cross 
Abstract: Despite their widespread applications, Large Language Models (LLMs) often struggle to express uncertainty, posing a challenge for reliable deployment in high stakes and safety critical domains like clinical diagnostics. Existing standard baseline methods such as model logits and elicited probabilities produce overconfident and poorly calibrated estimates. In this work, we propose Approximate Bayesian Computation (ABC), a likelihood-free Bayesian inference, based approach that treats LLMs as a stochastic simulator to infer posterior distributions over predictive probabilities. We evaluate our ABC approach on two clinically relevant benchmarks: a synthetic oral lesion diagnosis dataset and the publicly available GretelAI symptom-to-diagnosis dataset. Compared to standard baselines, our approach improves accuracy by up to 46.9\%, reduces Brier scores by 74.4\%, and enhances calibration as measured by Expected Calibration Error (ECE) and predictive entropy.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ë¶ˆí™•ì‹¤ì„± í‘œí˜„ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ Approximate Bayesian Computation (ABC) ë°©ë²•ë¡ ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ëª¨ë¸ ë¡œê·¸ì‡ ë° í™•ë¥  ì¶”ì • ë°©ì‹ì€ ê³¼ì‹ í•˜ê³  ë³´ì •ì´ ì˜ ì•ˆ ë˜ëŠ” ë¬¸ì œë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ABCëŠ” LLMì„ í™•ë¥ ì  ì‹œë®¬ë ˆì´í„°ë¡œ ê°„ì£¼í•˜ì—¬ ì˜ˆì¸¡ í™•ë¥ ì˜ ì‚¬í›„ ë¶„í¬ë¥¼ ì¶”ë¡ í•˜ëŠ” ì ‘ê·¼ë²•ì…ë‹ˆë‹¤. ì´ ë°©ë²•ì€ êµ¬ê°• ë³‘ë³€ ì§„ë‹¨ ë°ì´í„°ì…‹ê³¼ GretelAI ì¦ìƒ-ì§„ë‹¨ ë°ì´í„°ì…‹ì—ì„œ í‰ê°€ë˜ì—ˆìœ¼ë©°, ê¸°ì¡´ ë°©ë²•ì— ë¹„í•´ ì •í™•ë„ë¥¼ ìµœëŒ€ 46.9% í–¥ìƒì‹œí‚¤ê³ , Brier ì ìˆ˜ë¥¼ 74.4% ê°ì†Œì‹œí‚¤ë©°, ë³´ì • ì˜¤ë¥˜(ECE)ì™€ ì˜ˆì¸¡ ì—”íŠ¸ë¡œí”¼ ì¸¡ë©´ì—ì„œ ê°œì„ ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì€ ë¶ˆí™•ì‹¤ì„±ì„ í‘œí˜„í•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªì–´ ì‹ ë¢°ì„± ìˆëŠ” ë°°í¬ì— ë„ì „ ê³¼ì œë¥¼ ì œê¸°í•©ë‹ˆë‹¤.
- 2. ê¸°ì¡´ì˜ ëª¨ë¸ ë¡œì§“ ë° í™•ë¥  ì¶”ì • ë°©ë²•ì€ ê³¼ì‹ í•˜ê³  ì˜ëª»ëœ ë³´ì •ì„ ì´ˆë˜í•©ë‹ˆë‹¤.
- 3. ë³¸ ì—°êµ¬ì—ì„œëŠ” LLMsë¥¼ í™•ë¥ ì  ì‹œë®¬ë ˆì´í„°ë¡œ ì·¨ê¸‰í•˜ì—¬ ì˜ˆì¸¡ í™•ë¥ ì˜ ì‚¬í›„ ë¶„í¬ë¥¼ ì¶”ë¡ í•˜ëŠ” ABC ì ‘ê·¼ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤.
- 4. ì œì•ˆëœ ABC ì ‘ê·¼ë²•ì€ ë‘ ê°€ì§€ ì„ìƒì ìœ¼ë¡œ ê´€ë ¨ëœ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ê¸°ì¡´ ë°©ë²•ë³´ë‹¤ ì •í™•ì„±ì„ ìµœëŒ€ 46.9% í–¥ìƒì‹œí‚µë‹ˆë‹¤.
- 5. Brier ì ìˆ˜ë¥¼ 74.4% ê°ì†Œì‹œí‚¤ê³ , ECE ë° ì˜ˆì¸¡ ì—”íŠ¸ë¡œí”¼ë¡œ ì¸¡ì •í•œ ë³´ì • ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.


---

*Generated on 2025-09-25 15:32:27*