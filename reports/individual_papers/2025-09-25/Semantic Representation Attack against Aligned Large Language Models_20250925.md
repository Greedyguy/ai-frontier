---
keywords:
  - Large Language Model
  - Semantic Representation Attack
  - Semantic Representation Heuristic Search
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2509.19360
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T15:29:43.231312",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Semantic Representation Attack",
    "Semantic Representation Heuristic Search"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Semantic Representation Attack": 0.8,
    "Semantic Representation Heuristic Search": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's focus on adversarial attacks, linking to existing work on LLMs.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Semantic Representation Attack",
        "canonical": "Semantic Representation Attack",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Introduces a novel attack method specific to the paper, enhancing understanding of new adversarial techniques.",
        "novelty_score": 0.95,
        "connectivity_score": 0.6,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "Semantic Representation Heuristic Search",
        "canonical": "Semantic Representation Heuristic Search",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "A specific algorithm proposed in the paper, crucial for understanding the implementation of the attack.",
        "novelty_score": 0.92,
        "connectivity_score": 0.55,
        "specificity_score": 0.88,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "attack success rates",
      "harmful outputs",
      "prompt naturalness"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Semantic Representation Attack",
      "resolved_canonical": "Semantic Representation Attack",
      "decision": "linked",
      "scores": {
        "novelty": 0.95,
        "connectivity": 0.6,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Semantic Representation Heuristic Search",
      "resolved_canonical": "Semantic Representation Heuristic Search",
      "decision": "linked",
      "scores": {
        "novelty": 0.92,
        "connectivity": 0.55,
        "specificity": 0.88,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# Semantic Representation Attack against Aligned Large Language Models

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19360.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2509.19360](https://arxiv.org/abs/2509.19360)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Sugar-Coated Poison_ Benign Generation Unlocks LLM Jailbreaking_20250923|Sugar-Coated Poison: Benign Generation Unlocks LLM Jailbreaking]] (90.0% similar)
- [[2025-09-23/Targeting Alignment_ Extracting Safety Classifiers of Aligned LLMs_20250923|Targeting Alignment: Extracting Safety Classifiers of Aligned LLMs]] (87.7% similar)
- [[2025-09-23/MIST_ Jailbreaking Black-box Large Language Models via Iterative Semantic Tuning_20250923|MIST: Jailbreaking Black-box Large Language Models via Iterative Semantic Tuning]] (86.9% similar)
- [[2025-09-23/Revisiting Backdoor Attacks on LLMs_ A Stealthy and Practical Poisoning Framework via Harmless Inputs_20250923|Revisiting Backdoor Attacks on LLMs: A Stealthy and Practical Poisoning Framework via Harmless Inputs]] (86.7% similar)
- [[2025-09-22/SABER_ Uncovering Vulnerabilities in Safety Alignment via Cross-Layer Residual Connection_20250922|SABER: Uncovering Vulnerabilities in Safety Alignment via Cross-Layer Residual Connection]] (86.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**âš¡ Unique Technical**: [[keywords/Semantic Representation Attack|Semantic Representation Attack]], [[keywords/Semantic Representation Heuristic Search|Semantic Representation Heuristic Search]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19360v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) increasingly employ alignment techniques to prevent harmful outputs. Despite these safeguards, attackers can circumvent them by crafting prompts that induce LLMs to generate harmful content.
  Current methods typically target exact affirmative responses, such as ``Sure, here is...'', suffering from limited convergence, unnatural prompts, and high computational costs.
  We introduce Semantic Representation Attack, a novel paradigm that fundamentally reconceptualizes adversarial objectives against aligned LLMs.
  Rather than targeting exact textual patterns, our approach exploits the semantic representation space comprising diverse responses with equivalent harmful meanings.
  This innovation resolves the inherent trade-off between attack efficacy and prompt naturalness that plagues existing methods.
  The Semantic Representation Heuristic Search algorithm is proposed to efficiently generate semantically coherent and concise adversarial prompts by maintaining interpretability during incremental expansion.
  We establish rigorous theoretical guarantees for semantic convergence and demonstrate that our method achieves unprecedented attack success rates (89.41\% averaged across 18 LLMs, including 100\% on 11 models) while maintaining stealthiness and efficiency.
  Comprehensive experimental results confirm the overall superiority of our Semantic Representation Attack.
  The code will be publicly available.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì˜ ì •ë ¬ ê¸°ë²•ì„ ìš°íšŒí•˜ì—¬ ìœ í•´í•œ ì¶œë ¥ì„ ìƒì„±í•˜ëŠ” ìƒˆë¡œìš´ ê³µê²© ë°©ë²•ì¸ 'ì˜ë¯¸ í‘œí˜„ ê³µê²©'ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ ë°©ë²•ì€ íŠ¹ì • ë¬¸êµ¬ë¥¼ ëª©í‘œë¡œ í•˜ì—¬ ì œí•œëœ ìˆ˜ë ´ì„±ê³¼ ë†’ì€ ê³„ì‚° ë¹„ìš© ë¬¸ì œë¥¼ ê²ªì—ˆìŠµë‹ˆë‹¤. ë°˜ë©´, ì œì•ˆëœ ë°©ë²•ì€ ë‹¤ì–‘í•œ ìœ í•´ ì˜ë¯¸ë¥¼ ê°€ì§„ ì‘ë‹µì˜ ì˜ë¯¸ í‘œí˜„ ê³µê°„ì„ í™œìš©í•˜ì—¬ ê³µê²© íš¨ê³¼ì™€ ìì—°ìŠ¤ëŸ¬ìš´ í”„ë¡¬í”„íŠ¸ ê°„ì˜ ê· í˜•ì„ í•´ê²°í•©ë‹ˆë‹¤. 'ì˜ë¯¸ í‘œí˜„ íœ´ë¦¬ìŠ¤í‹± ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜'ì„ í†µí•´ í•´ì„ ê°€ëŠ¥ì„±ì„ ìœ ì§€í•˜ë©´ì„œ íš¨ìœ¨ì ì¸ ê³µê²© í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ 18ê°œì˜ LLMì—ì„œ í‰ê·  89.41%ì˜ ë†’ì€ ê³µê²© ì„±ê³µë¥ ì„ ê¸°ë¡í•˜ë©°, 11ê°œ ëª¨ë¸ì—ì„œëŠ” 100%ì˜ ì„±ê³µë¥ ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼ëŠ” ì œì•ˆëœ ë°©ë²•ì˜ ìš°ìˆ˜ì„±ì„ ì…ì¦í•˜ë©°, ì½”ë“œëŠ” ê³µê°œë  ì˜ˆì •ì…ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì˜ ì •ë ¬ ê¸°ìˆ ì„ ìš°íšŒí•˜ëŠ” ìƒˆë¡œìš´ ê³µê²© íŒ¨ëŸ¬ë‹¤ì„ì¸ 'Semantic Representation Attack'ì„ ì†Œê°œí•©ë‹ˆë‹¤.
- 2. ê¸°ì¡´ì˜ ì •í™•í•œ í…ìŠ¤íŠ¸ íŒ¨í„´ì„ ëª©í‘œë¡œ í•˜ëŠ” ë°©ë²• ëŒ€ì‹ , ë‹¤ì–‘í•œ ë°˜ì‘ì˜ ì˜ë¯¸ì  í‘œí˜„ ê³µê°„ì„ í™œìš©í•˜ì—¬ ê³µê²© ëª©í‘œë¥¼ ì¬êµ¬ì„±í•©ë‹ˆë‹¤.
- 3. ì œì•ˆëœ 'Semantic Representation Heuristic Search' ì•Œê³ ë¦¬ì¦˜ì€ í•´ì„ ê°€ëŠ¥ì„±ì„ ìœ ì§€í•˜ë©´ì„œ ì˜ë¯¸ì ìœ¼ë¡œ ì¼ê´€ëœ ê³µê²© í”„ë¡¬í”„íŠ¸ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
- 4. ì´ ë°©ë²•ì€ 18ê°œì˜ LLMì—ì„œ í‰ê·  89.41%, 11ê°œì˜ ëª¨ë¸ì—ì„œ 100%ì˜ ê³µê²© ì„±ê³µë¥ ì„ ë‹¬ì„±í•˜ë©°, ìŠ¤í…”ìŠ¤ì„±ê³¼ íš¨ìœ¨ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤.
- 5. ì‹¤í—˜ ê²°ê³¼ëŠ” 'Semantic Representation Attack'ì˜ ì „ë°˜ì ì¸ ìš°ìˆ˜ì„±ì„ í™•ì¸í•˜ë©°, ì½”ë“œë„ ê³µê°œë  ì˜ˆì •ì…ë‹ˆë‹¤.


---

*Generated on 2025-09-25 15:29:43*