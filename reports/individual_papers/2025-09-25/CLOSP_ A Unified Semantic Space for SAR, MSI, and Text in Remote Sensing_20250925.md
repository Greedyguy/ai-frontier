---
keywords:
  - Contrastive Language Optical SAR Pretraining
  - GeoCLOSP
  - Synthetic Aperture Radar
  - Multispectral Imaging
  - Text-to-Image Retrieval
category: cs.CL
publish_date: 2025-09-25
arxiv_id: 2507.10403
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-26T08:59:03.647491",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Contrastive Language Optical SAR Pretraining",
    "GeoCLOSP",
    "Synthetic Aperture Radar",
    "Multispectral Imaging",
    "Text-to-Image Retrieval"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Contrastive Language Optical SAR Pretraining": 0.92,
    "GeoCLOSP": 0.89,
    "Synthetic Aperture Radar": 0.86,
    "Multispectral Imaging": 0.81,
    "Text-to-Image Retrieval": 0.84
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "CLOSP",
        "canonical": "Contrastive Language Optical SAR Pretraining",
        "aliases": [
          "CLOSP"
        ],
        "category": "unique_technical",
        "rationale": "CLOSP is a novel framework that aligns optical and SAR images, crucial for linking multimodal data in remote sensing.",
        "novelty_score": 0.85,
        "connectivity_score": 0.68,
        "specificity_score": 0.88,
        "link_intent_score": 0.92
      },
      {
        "surface": "GeoCLOSP",
        "canonical": "GeoCLOSP",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "GeoCLOSP integrates geographic coordinates, enhancing specificity for location-dependent tasks in remote sensing.",
        "novelty_score": 0.78,
        "connectivity_score": 0.64,
        "specificity_score": 0.85,
        "link_intent_score": 0.89
      },
      {
        "surface": "Synthetic Aperture Radar",
        "canonical": "Synthetic Aperture Radar",
        "aliases": [
          "SAR"
        ],
        "category": "broad_technical",
        "rationale": "SAR is a key sensor technology in remote sensing, providing unique data for multimodal integration.",
        "novelty_score": 0.45,
        "connectivity_score": 0.79,
        "specificity_score": 0.68,
        "link_intent_score": 0.86
      },
      {
        "surface": "Multispectral Images",
        "canonical": "Multispectral Imaging",
        "aliases": [
          "MSI"
        ],
        "category": "specific_connectable",
        "rationale": "Multispectral imaging is essential for capturing diverse spectral data, facilitating multimodal analysis.",
        "novelty_score": 0.52,
        "connectivity_score": 0.75,
        "specificity_score": 0.72,
        "link_intent_score": 0.81
      },
      {
        "surface": "Text-to-Image Retrieval",
        "canonical": "Text-to-Image Retrieval",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Text-to-image retrieval is a critical task in remote sensing, linking textual descriptions to visual data.",
        "novelty_score": 0.58,
        "connectivity_score": 0.82,
        "specificity_score": 0.77,
        "link_intent_score": 0.84
      }
    ],
    "ban_list_suggestions": [
      "disaster response",
      "climate monitoring",
      "land cover systems"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "CLOSP",
      "resolved_canonical": "Contrastive Language Optical SAR Pretraining",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.68,
        "specificity": 0.88,
        "link_intent": 0.92
      }
    },
    {
      "candidate_surface": "GeoCLOSP",
      "resolved_canonical": "GeoCLOSP",
      "decision": "linked",
      "scores": {
        "novelty": 0.78,
        "connectivity": 0.64,
        "specificity": 0.85,
        "link_intent": 0.89
      }
    },
    {
      "candidate_surface": "Synthetic Aperture Radar",
      "resolved_canonical": "Synthetic Aperture Radar",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.79,
        "specificity": 0.68,
        "link_intent": 0.86
      }
    },
    {
      "candidate_surface": "Multispectral Images",
      "resolved_canonical": "Multispectral Imaging",
      "decision": "linked",
      "scores": {
        "novelty": 0.52,
        "connectivity": 0.75,
        "specificity": 0.72,
        "link_intent": 0.81
      }
    },
    {
      "candidate_surface": "Text-to-Image Retrieval",
      "resolved_canonical": "Text-to-Image Retrieval",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.82,
        "specificity": 0.77,
        "link_intent": 0.84
      }
    }
  ]
}
-->

# CLOSP: A Unified Semantic Space for SAR, MSI, and Text in Remote Sensing

## 📋 메타데이터

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2507.10403.pdf)
**Category**: cs.CL
**Published**: 2025-09-25
**ArXiv ID**: [2507.10403](https://arxiv.org/abs/2507.10403)

## 🔗 유사한 논문
- [[2025-09-22/SAR-TEXT_ A Large-Scale SAR Image-Text Dataset Built with SAR-Narrator and Progressive Transfer Learning_20250922|SAR-TEXT: A Large-Scale SAR Image-Text Dataset Built with SAR-Narrator and Progressive Transfer Learning]] (84.0% similar)
- [[2025-09-22/RSCC_ A Large-Scale Remote Sensing Change Caption Dataset for Disaster Events_20250922|RSCC: A Large-Scale Remote Sensing Change Caption Dataset for Disaster Events]] (81.7% similar)
- [[2025-09-22/LC-SLab -- An Object-based Deep Learning Framework for Large-scale Land Cover Classification from Satellite Imagery and Sparse In-situ Labels_20250922|LC-SLab -- An Object-based Deep Learning Framework for Large-scale Land Cover Classification from Satellite Imagery and Sparse In-situ Labels]] (81.5% similar)
- [[2025-09-24/OSDA_ A Framework for Open-Set Discovery and Automatic Interpretation of Land-cover in Remote Sensing Imagery_20250924|OSDA: A Framework for Open-Set Discovery and Automatic Interpretation of Land-cover in Remote Sensing Imagery]] (81.4% similar)
- [[2025-09-25/CellCLIP -- Learning Perturbation Effects in Cell Painting via Text-Guided Contrastive Learning_20250925|CellCLIP -- Learning Perturbation Effects in Cell Painting via Text-Guided Contrastive Learning]] (81.3% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Synthetic Aperture Radar|Synthetic Aperture Radar]]
**🔗 Specific Connectable**: [[keywords/Multispectral Imaging|Multispectral Imaging]], [[keywords/Text-to-Image Retrieval|Text-to-Image Retrieval]]
**⚡ Unique Technical**: [[keywords/Contrastive Language Optical SAR Pretraining|Contrastive Language Optical SAR Pretraining]], [[keywords/GeoCLOSP|GeoCLOSP]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2507.10403v2 Announce Type: replace-cross 
Abstract: Retrieving relevant imagery from vast satellite archives is crucial for applications like disaster response and long-term climate monitoring. However, most text-to-image retrieval systems are limited to RGB data, failing to exploit the unique physical information captured by other sensors, such as the all-weather structural sensitivity of Synthetic Aperture Radar (SAR) or the spectral signatures in optical multispectral data. To bridge this gap, we introduce CrisisLandMark, a new large-scale corpus of over 647,000 Sentinel-1 SAR and Sentinel-2 multispectral images paired with structured textual annotations for land cover, land use, and crisis events harmonized from authoritative land cover systems (CORINE and Dynamic World) and crisis-specific sources. We then present CLOSP (Contrastive Language Optical SAR Pretraining), a novel framework that uses text as a bridge to align unpaired optical and SAR images into a unified embedding space. Our experiments show that CLOSP achieves a new state-of-the-art, improving retrieval nDGC@1000 by 54% over existing models. Additionally, we find that the unified training strategy overcomes the inherent difficulty of interpreting SAR imagery by transferring rich semantic knowledge from the optical domain with indirect interaction. Furthermore, GeoCLOSP, which integrates geographic coordinates into our framework, creates a powerful trade-off between generality and specificity: while the CLOSP excels at general semantic tasks, the GeoCLOSP becomes a specialized expert for retrieving location-dependent crisis events and rare geographic features. This work highlights that the integration of diverse sensor data and geographic context is essential for unlocking the full potential of remote sensing archives.

## 📝 요약

이 논문은 위성 이미지 검색의 한계를 극복하기 위해 CrisisLandMark라는 대규모 데이터셋을 소개하고, CLOSP라는 새로운 프레임워크를 제안합니다. CrisisLandMark는 Sentinel-1 SAR 및 Sentinel-2 다중 스펙트럼 이미지와 구조화된 텍스트 주석을 포함하여 다양한 센서 데이터를 통합합니다. CLOSP는 텍스트를 매개로 광학 및 SAR 이미지를 통합 임베딩 공간에 정렬하여, 기존 모델 대비 검색 성능을 54% 향상시켰습니다. 또한, GeoCLOSP는 지리적 좌표를 통합하여 일반적 작업과 위치 의존적 위기 이벤트 검색에 특화된 성능을 발휘합니다. 이 연구는 다양한 센서 데이터와 지리적 맥락의 통합이 원격 탐사의 잠재력을 극대화하는 데 필수적임을 강조합니다.

## 🎯 주요 포인트

- 1. CrisisLandMark는 647,000개 이상의 Sentinel-1 SAR 및 Sentinel-2 다중 스펙트럼 이미지와 구조화된 텍스트 주석을 포함하는 대규모 코퍼스를 소개합니다.
- 2. CLOSP는 텍스트를 매개로 하여 짝이 없는 광학 및 SAR 이미지를 통합 임베딩 공간으로 정렬하는 새로운 프레임워크입니다.
- 3. CLOSP는 기존 모델 대비 검색 nDGC@1000을 54% 향상시키며 새로운 최첨단 성능을 달성합니다.
- 4. GeoCLOSP는 지리적 좌표를 통합하여 위치 의존적 위기 사건 및 희귀 지리적 특징 검색에 특화된 전문가 역할을 합니다.
- 5. 다양한 센서 데이터와 지리적 맥락의 통합은 원격 감지 아카이브의 잠재력을 최대한 발휘하는 데 필수적입니다.


---

*Generated on 2025-09-26 08:59:03*