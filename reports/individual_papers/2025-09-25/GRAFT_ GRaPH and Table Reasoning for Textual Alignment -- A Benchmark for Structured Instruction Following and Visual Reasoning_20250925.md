---
keywords:
  - GRAFT Benchmark
  - Visual Reasoning
  - Instruction Following
  - Visual-Textual Alignment
  - Reasoning Taxonomy
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2508.15690
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T16:13:16.888420",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "GRAFT Benchmark",
    "Visual Reasoning",
    "Instruction Following",
    "Visual-Textual Alignment",
    "Reasoning Taxonomy"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "GRAFT Benchmark": 0.88,
    "Visual Reasoning": 0.82,
    "Instruction Following": 0.8,
    "Visual-Textual Alignment": 0.85,
    "Reasoning Taxonomy": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "GRAFT",
        "canonical": "GRAFT Benchmark",
        "aliases": [
          "GRAFT Framework"
        ],
        "category": "unique_technical",
        "rationale": "GRAFT is a novel benchmark specifically designed for evaluating multimodal models, which is crucial for linking in the context of structured reasoning tasks.",
        "novelty_score": 0.85,
        "connectivity_score": 0.7,
        "specificity_score": 0.9,
        "link_intent_score": 0.88
      },
      {
        "surface": "visual reasoning",
        "canonical": "Visual Reasoning",
        "aliases": [
          "Visual Analysis"
        ],
        "category": "specific_connectable",
        "rationale": "Visual reasoning is a key component of multimodal learning, making it highly relevant for linking to vision-language models and related concepts.",
        "novelty_score": 0.55,
        "connectivity_score": 0.85,
        "specificity_score": 0.8,
        "link_intent_score": 0.82
      },
      {
        "surface": "instruction-following",
        "canonical": "Instruction Following",
        "aliases": [
          "Instruction Adherence"
        ],
        "category": "specific_connectable",
        "rationale": "Instruction following is a critical task in AI models, especially in the context of structured tasks and multimodal benchmarks.",
        "novelty_score": 0.6,
        "connectivity_score": 0.78,
        "specificity_score": 0.75,
        "link_intent_score": 0.8
      },
      {
        "surface": "visual-textual alignment",
        "canonical": "Visual-Textual Alignment",
        "aliases": [
          "Image-Text Alignment"
        ],
        "category": "specific_connectable",
        "rationale": "This concept is essential for understanding the relationship between visual and textual data, a core aspect of multimodal models.",
        "novelty_score": 0.58,
        "connectivity_score": 0.83,
        "specificity_score": 0.78,
        "link_intent_score": 0.85
      },
      {
        "surface": "taxonomy of reasoning types",
        "canonical": "Reasoning Taxonomy",
        "aliases": [
          "Reasoning Types"
        ],
        "category": "unique_technical",
        "rationale": "A taxonomy of reasoning types provides a structured approach to evaluate reasoning capabilities, important for linking to evaluation standards.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "structured multimodal benchmark",
      "programmatically generated charts"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "GRAFT",
      "resolved_canonical": "GRAFT Benchmark",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.7,
        "specificity": 0.9,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "visual reasoning",
      "resolved_canonical": "Visual Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.85,
        "specificity": 0.8,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "instruction-following",
      "resolved_canonical": "Instruction Following",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.78,
        "specificity": 0.75,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "visual-textual alignment",
      "resolved_canonical": "Visual-Textual Alignment",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.83,
        "specificity": 0.78,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "taxonomy of reasoning types",
      "resolved_canonical": "Reasoning Taxonomy",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# GRAFT: GRaPH and Table Reasoning for Textual Alignment -- A Benchmark for Structured Instruction Following and Visual Reasoning

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2508.15690.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2508.15690](https://arxiv.org/abs/2508.15690)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/GRIP_ A Graph-Based Reasoning Instruction Producer_20250923|GRIP: A Graph-Based Reasoning Instruction Producer]] (81.8% similar)
- [[2025-09-24/TableMind_ An Autonomous Programmatic Agent for Tool-Augmented Table Reasoning_20250924|TableMind: An Autonomous Programmatic Agent for Tool-Augmented Table Reasoning]] (81.2% similar)
- [[2025-09-22/GRE Suite_ Geo-localization Inference via Fine-Tuned Vision-Language Models and Enhanced Reasoning Chains_20250922|GRE Suite: Geo-localization Inference via Fine-Tuned Vision-Language Models and Enhanced Reasoning Chains]] (80.5% similar)
- [[2025-09-23/GRPO-LEAD_ A Difficulty-Aware Reinforcement Learning Approach for Concise Mathematical Reasoning in Language Models_20250923|GRPO-LEAD: A Difficulty-Aware Reinforcement Learning Approach for Concise Mathematical Reasoning in Language Models]] (80.4% similar)
- [[2025-09-23/CAMBench-QR _ A Structure-Aware Benchmark for Post-Hoc Explanations with QR Understanding_20250923|CAMBench-QR : A Structure-Aware Benchmark for Post-Hoc Explanations with QR Understanding]] (80.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Visual Reasoning|Visual Reasoning]], [[keywords/Instruction Following|Instruction Following]], [[keywords/Visual-Textual Alignment|Visual-Textual Alignment]]
**âš¡ Unique Technical**: [[keywords/GRAFT Benchmark|GRAFT Benchmark]], [[keywords/Reasoning Taxonomy|Reasoning Taxonomy]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2508.15690v2 Announce Type: replace 
Abstract: GRAFT is a structured multimodal benchmark for evaluating models on instruction-following, visual reasoning, and visual-textual alignment tasks. It features programmatically generated charts and synthetically rendered tables, created with Python visualization libraries to ensure control over data semantics, structure, and clarity. Each GRAFT instance pairs a chart or table image with a systematically generated, multi-step analytical question based solely on visual content. Answers are provided in structured formats such as JSON or YAML, supporting consistent evaluation of both reasoning and output format. The benchmark introduces a taxonomy of reasoning types including comparison, trend identification, ranking, aggregation, proportion estimation, and anomaly detection to enable comprehensive assessment. Reference answers follow strict factual and formatting guidelines for precise, aspect-based evaluation. GRAFT offers a unified, scalable framework for fine-grained benchmarking of multimodal models on visually grounded, structured reasoning tasks, setting a new evaluation standard in this field.

## ğŸ“ ìš”ì•½

GRAFTëŠ” ëª…ë ¹ì–´ ìˆ˜í–‰, ì‹œê°ì  ì¶”ë¡ , ì‹œê°-í…ìŠ¤íŠ¸ ì •ë ¬ ê³¼ì œë¥¼ í‰ê°€í•˜ê¸° ìœ„í•œ êµ¬ì¡°í™”ëœ ë©€í‹°ëª¨ë‹¬ ë²¤ì¹˜ë§ˆí¬ì…ë‹ˆë‹¤. Python ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒì„±ëœ ì°¨íŠ¸ì™€ í…Œì´ë¸”ì„ í†µí•´ ë°ì´í„°ì˜ ì˜ë¯¸, êµ¬ì¡°, ëª…í™•ì„±ì„ ì œì–´í•©ë‹ˆë‹¤. ê° GRAFT ì¸ìŠ¤í„´ìŠ¤ëŠ” ì°¨íŠ¸ ë˜ëŠ” í…Œì´ë¸” ì´ë¯¸ì§€ì™€ ì‹œê°ì  ì½˜í…ì¸ ì— ê¸°ë°˜í•œ ë‹¤ë‹¨ê³„ ë¶„ì„ ì§ˆë¬¸ì„ ìŒìœ¼ë¡œ ì œê³µí•©ë‹ˆë‹¤. ë‹µë³€ì€ JSON ë˜ëŠ” YAML í˜•ì‹ìœ¼ë¡œ ì œê³µë˜ì–´ ì¼ê´€ëœ í‰ê°€ë¥¼ ì§€ì›í•©ë‹ˆë‹¤. ë¹„êµ, ì¶”ì„¸ ì‹ë³„, ìˆœìœ„ ë§¤ê¸°ê¸°, ì§‘ê³„, ë¹„ìœ¨ ì¶”ì •, ì´ìƒ íƒì§€ ë“± ë‹¤ì–‘í•œ ì¶”ë¡  ìœ í˜•ì˜ ë¶„ë¥˜ ì²´ê³„ë¥¼ ë„ì…í•˜ì—¬ í¬ê´„ì ì¸ í‰ê°€ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤. GRAFTëŠ” ì‹œê°ì ìœ¼ë¡œ ê¸°ë°˜í•œ êµ¬ì¡°ì  ì¶”ë¡  ì‘ì—…ì— ëŒ€í•œ ì„¸ë°€í•œ ë²¤ì¹˜ë§ˆí‚¹ì„ ìœ„í•œ í†µí•©ì ì´ê³  í™•ì¥ ê°€ëŠ¥í•œ í”„ë ˆì„ì›Œí¬ë¥¼ ì œê³µí•˜ì—¬ ì´ ë¶„ì•¼ì˜ ìƒˆë¡œìš´ í‰ê°€ ê¸°ì¤€ì„ ì œì‹œí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. GRAFTëŠ” ëª¨ë¸ì˜ ì§€ì‹œ ë”°ë¥´ê¸°, ì‹œê°ì  ì¶”ë¡ , ì‹œê°-í…ìŠ¤íŠ¸ ì •ë ¬ ì‘ì—…ì„ í‰ê°€í•˜ê¸° ìœ„í•œ êµ¬ì¡°í™”ëœ ë©€í‹°ëª¨ë‹¬ ë²¤ì¹˜ë§ˆí¬ì…ë‹ˆë‹¤.
- 2. ì´ ë²¤ì¹˜ë§ˆí¬ëŠ” Python ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒì„±ëœ ì°¨íŠ¸ì™€ í…Œì´ë¸”ì„ íŠ¹ì§•ìœ¼ë¡œ í•˜ë©°, ë°ì´í„° ì˜ë¯¸, êµ¬ì¡° ë° ëª…í™•ì„±ì„ ì œì–´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- 3. GRAFTëŠ” ë¹„êµ, ì¶”ì„¸ ì‹ë³„, ìˆœìœ„ ë§¤ê¸°ê¸°, ì§‘ê³„, ë¹„ìœ¨ ì¶”ì •, ì´ìƒ íƒì§€ ë“± ë‹¤ì–‘í•œ ì¶”ë¡  ìœ í˜•ì˜ ë¶„ë¥˜ ì²´ê³„ë¥¼ ë„ì…í•˜ì—¬ í¬ê´„ì ì¸ í‰ê°€ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
- 4. ì°¸ì¡° ë‹µë³€ì€ ì •í™•í•˜ê³  í˜•ì‹ì ì¸ í‰ê°€ë¥¼ ìœ„í•´ ì—„ê²©í•œ ì‚¬ì‹¤ ë° í˜•ì‹ ì§€ì¹¨ì„ ë”°ë¦…ë‹ˆë‹¤.
- 5. GRAFTëŠ” ì‹œê°ì ìœ¼ë¡œ ê¸°ë°˜ì„ ë‘” êµ¬ì¡°ì  ì¶”ë¡  ì‘ì—…ì— ëŒ€í•œ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì˜ ì„¸ë°€í•œ ë²¤ì¹˜ë§ˆí‚¹ì„ ìœ„í•œ í†µí•©ì ì´ê³  í™•ì¥ ê°€ëŠ¥í•œ í”„ë ˆì„ì›Œí¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.


---

*Generated on 2025-09-25 16:13:16*