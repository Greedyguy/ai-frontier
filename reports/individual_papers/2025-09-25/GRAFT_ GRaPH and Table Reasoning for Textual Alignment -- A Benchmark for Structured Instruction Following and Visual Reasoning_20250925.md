---
keywords:
  - GRAFT Benchmark
  - Visual Reasoning
  - Instruction Following
  - Visual-Textual Alignment
  - Reasoning Taxonomy
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2508.15690
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T16:13:16.888420",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "GRAFT Benchmark",
    "Visual Reasoning",
    "Instruction Following",
    "Visual-Textual Alignment",
    "Reasoning Taxonomy"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "GRAFT Benchmark": 0.88,
    "Visual Reasoning": 0.82,
    "Instruction Following": 0.8,
    "Visual-Textual Alignment": 0.85,
    "Reasoning Taxonomy": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "GRAFT",
        "canonical": "GRAFT Benchmark",
        "aliases": [
          "GRAFT Framework"
        ],
        "category": "unique_technical",
        "rationale": "GRAFT is a novel benchmark specifically designed for evaluating multimodal models, which is crucial for linking in the context of structured reasoning tasks.",
        "novelty_score": 0.85,
        "connectivity_score": 0.7,
        "specificity_score": 0.9,
        "link_intent_score": 0.88
      },
      {
        "surface": "visual reasoning",
        "canonical": "Visual Reasoning",
        "aliases": [
          "Visual Analysis"
        ],
        "category": "specific_connectable",
        "rationale": "Visual reasoning is a key component of multimodal learning, making it highly relevant for linking to vision-language models and related concepts.",
        "novelty_score": 0.55,
        "connectivity_score": 0.85,
        "specificity_score": 0.8,
        "link_intent_score": 0.82
      },
      {
        "surface": "instruction-following",
        "canonical": "Instruction Following",
        "aliases": [
          "Instruction Adherence"
        ],
        "category": "specific_connectable",
        "rationale": "Instruction following is a critical task in AI models, especially in the context of structured tasks and multimodal benchmarks.",
        "novelty_score": 0.6,
        "connectivity_score": 0.78,
        "specificity_score": 0.75,
        "link_intent_score": 0.8
      },
      {
        "surface": "visual-textual alignment",
        "canonical": "Visual-Textual Alignment",
        "aliases": [
          "Image-Text Alignment"
        ],
        "category": "specific_connectable",
        "rationale": "This concept is essential for understanding the relationship between visual and textual data, a core aspect of multimodal models.",
        "novelty_score": 0.58,
        "connectivity_score": 0.83,
        "specificity_score": 0.78,
        "link_intent_score": 0.85
      },
      {
        "surface": "taxonomy of reasoning types",
        "canonical": "Reasoning Taxonomy",
        "aliases": [
          "Reasoning Types"
        ],
        "category": "unique_technical",
        "rationale": "A taxonomy of reasoning types provides a structured approach to evaluate reasoning capabilities, important for linking to evaluation standards.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "structured multimodal benchmark",
      "programmatically generated charts"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "GRAFT",
      "resolved_canonical": "GRAFT Benchmark",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.7,
        "specificity": 0.9,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "visual reasoning",
      "resolved_canonical": "Visual Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.85,
        "specificity": 0.8,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "instruction-following",
      "resolved_canonical": "Instruction Following",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.78,
        "specificity": 0.75,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "visual-textual alignment",
      "resolved_canonical": "Visual-Textual Alignment",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.83,
        "specificity": 0.78,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "taxonomy of reasoning types",
      "resolved_canonical": "Reasoning Taxonomy",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# GRAFT: GRaPH and Table Reasoning for Textual Alignment -- A Benchmark for Structured Instruction Following and Visual Reasoning

## 📋 메타데이터

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2508.15690.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2508.15690](https://arxiv.org/abs/2508.15690)

## 🔗 유사한 논문
- [[2025-09-23/GRIP_ A Graph-Based Reasoning Instruction Producer_20250923|GRIP: A Graph-Based Reasoning Instruction Producer]] (81.8% similar)
- [[2025-09-24/TableMind_ An Autonomous Programmatic Agent for Tool-Augmented Table Reasoning_20250924|TableMind: An Autonomous Programmatic Agent for Tool-Augmented Table Reasoning]] (81.2% similar)
- [[2025-09-22/GRE Suite_ Geo-localization Inference via Fine-Tuned Vision-Language Models and Enhanced Reasoning Chains_20250922|GRE Suite: Geo-localization Inference via Fine-Tuned Vision-Language Models and Enhanced Reasoning Chains]] (80.5% similar)
- [[2025-09-23/GRPO-LEAD_ A Difficulty-Aware Reinforcement Learning Approach for Concise Mathematical Reasoning in Language Models_20250923|GRPO-LEAD: A Difficulty-Aware Reinforcement Learning Approach for Concise Mathematical Reasoning in Language Models]] (80.4% similar)
- [[2025-09-23/CAMBench-QR _ A Structure-Aware Benchmark for Post-Hoc Explanations with QR Understanding_20250923|CAMBench-QR : A Structure-Aware Benchmark for Post-Hoc Explanations with QR Understanding]] (80.2% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Visual Reasoning|Visual Reasoning]], [[keywords/Instruction Following|Instruction Following]], [[keywords/Visual-Textual Alignment|Visual-Textual Alignment]]
**⚡ Unique Technical**: [[keywords/GRAFT Benchmark|GRAFT Benchmark]], [[keywords/Reasoning Taxonomy|Reasoning Taxonomy]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2508.15690v2 Announce Type: replace 
Abstract: GRAFT is a structured multimodal benchmark for evaluating models on instruction-following, visual reasoning, and visual-textual alignment tasks. It features programmatically generated charts and synthetically rendered tables, created with Python visualization libraries to ensure control over data semantics, structure, and clarity. Each GRAFT instance pairs a chart or table image with a systematically generated, multi-step analytical question based solely on visual content. Answers are provided in structured formats such as JSON or YAML, supporting consistent evaluation of both reasoning and output format. The benchmark introduces a taxonomy of reasoning types including comparison, trend identification, ranking, aggregation, proportion estimation, and anomaly detection to enable comprehensive assessment. Reference answers follow strict factual and formatting guidelines for precise, aspect-based evaluation. GRAFT offers a unified, scalable framework for fine-grained benchmarking of multimodal models on visually grounded, structured reasoning tasks, setting a new evaluation standard in this field.

## 📝 요약

GRAFT는 명령어 수행, 시각적 추론, 시각-텍스트 정렬 과제를 평가하기 위한 구조화된 멀티모달 벤치마크입니다. Python 시각화 라이브러리를 사용하여 생성된 차트와 테이블을 통해 데이터의 의미, 구조, 명확성을 제어합니다. 각 GRAFT 인스턴스는 차트 또는 테이블 이미지와 시각적 콘텐츠에 기반한 다단계 분석 질문을 쌍으로 제공합니다. 답변은 JSON 또는 YAML 형식으로 제공되어 일관된 평가를 지원합니다. 비교, 추세 식별, 순위 매기기, 집계, 비율 추정, 이상 탐지 등 다양한 추론 유형의 분류 체계를 도입하여 포괄적인 평가가 가능합니다. GRAFT는 시각적으로 기반한 구조적 추론 작업에 대한 세밀한 벤치마킹을 위한 통합적이고 확장 가능한 프레임워크를 제공하여 이 분야의 새로운 평가 기준을 제시합니다.

## 🎯 주요 포인트

- 1. GRAFT는 모델의 지시 따르기, 시각적 추론, 시각-텍스트 정렬 작업을 평가하기 위한 구조화된 멀티모달 벤치마크입니다.
- 2. 이 벤치마크는 Python 시각화 라이브러리를 사용하여 생성된 차트와 테이블을 특징으로 하며, 데이터 의미, 구조 및 명확성을 제어할 수 있습니다.
- 3. GRAFT는 비교, 추세 식별, 순위 매기기, 집계, 비율 추정, 이상 탐지 등 다양한 추론 유형의 분류 체계를 도입하여 포괄적인 평가를 가능하게 합니다.
- 4. 참조 답변은 정확하고 형식적인 평가를 위해 엄격한 사실 및 형식 지침을 따릅니다.
- 5. GRAFT는 시각적으로 기반을 둔 구조적 추론 작업에 대한 멀티모달 모델의 세밀한 벤치마킹을 위한 통합적이고 확장 가능한 프레임워크를 제공합니다.


---

*Generated on 2025-09-25 16:13:16*