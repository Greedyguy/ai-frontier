---
keywords:
  - Neural Network
  - Feature Reliance Analysis
  - ConvNeXt Architecture
  - Transformer
  - Domain-Agnostic Framework
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2509.20234
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T16:03:54.559399",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Neural Network",
    "Feature Reliance Analysis",
    "ConvNeXt Architecture",
    "Transformer",
    "Domain-Agnostic Framework"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Neural Network": 0.85,
    "Feature Reliance Analysis": 0.78,
    "ConvNeXt Architecture": 0.77,
    "Transformer": 0.8,
    "Domain-Agnostic Framework": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Convolutional Neural Networks",
        "canonical": "Neural Network",
        "aliases": [
          "CNN",
          "ConvNet"
        ],
        "category": "broad_technical",
        "rationale": "Linking to 'Neural Network' helps connect discussions on architecture and feature reliance in deep learning.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "feature reliance",
        "canonical": "Feature Reliance Analysis",
        "aliases": [
          "feature use",
          "feature dependence"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel concept of analyzing feature reliance, crucial for understanding model biases.",
        "novelty_score": 0.75,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "ConvNeXt",
        "canonical": "ConvNeXt Architecture",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Represents a specific modern architecture that mitigates texture bias, relevant for architectural comparisons.",
        "novelty_score": 0.8,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      },
      {
        "surface": "Vision Transformers",
        "canonical": "Transformer",
        "aliases": [
          "ViTs"
        ],
        "category": "broad_technical",
        "rationale": "Links to the broader category of Transformers, emphasizing their role in reducing texture bias.",
        "novelty_score": 0.5,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "domain-agnostic framework",
        "canonical": "Domain-Agnostic Framework",
        "aliases": [
          "cross-domain framework"
        ],
        "category": "unique_technical",
        "rationale": "Highlights a novel approach applicable across various domains, enhancing cross-domain analysis.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.75,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "texture-biased",
      "cue-conflict experiment",
      "systematic suppression"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Convolutional Neural Networks",
      "resolved_canonical": "Neural Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "feature reliance",
      "resolved_canonical": "Feature Reliance Analysis",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "ConvNeXt",
      "resolved_canonical": "ConvNeXt Architecture",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Vision Transformers",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "domain-agnostic framework",
      "resolved_canonical": "Domain-Agnostic Framework",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.75,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# ImageNet-trained CNNs are not biased towards texture: Revisiting feature reliance through controlled suppression

## 📋 메타데이터

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.20234.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2509.20234](https://arxiv.org/abs/2509.20234)

## 🔗 유사한 논문
- [[2025-09-24/A Rigorous Behavior Assessment of CNNs Using a Data-Domain Sampling Regime_20250924|A Rigorous Behavior Assessment of CNNs Using a Data-Domain Sampling Regime]] (82.9% similar)
- [[2025-09-22/Incorporating Visual Cortical Lateral Connection Properties into CNN_ Recurrent Activation and Excitatory-Inhibitory Separation_20250922|Incorporating Visual Cortical Lateral Connection Properties into CNN: Recurrent Activation and Excitatory-Inhibitory Separation]] (82.9% similar)
- [[2025-09-24/Fix your downsampling ASAP! Be natively more robust via Aliasing and Spectral Artifact free Pooling_20250924|Fix your downsampling ASAP! Be natively more robust via Aliasing and Spectral Artifact free Pooling]] (81.2% similar)
- [[2025-09-23/Pulling Back the Curtain on ReLU Networks_20250923|Pulling Back the Curtain on ReLU Networks]] (80.4% similar)
- [[2025-09-19/Leveraging Geometric Visual Illusions as Perceptual Inductive Biases for Vision Models_20250919|Leveraging Geometric Visual Illusions as Perceptual Inductive Biases for Vision Models]] (80.4% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Neural Network|Neural Network]], [[keywords/Transformer|Transformer]]
**⚡ Unique Technical**: [[keywords/Feature Reliance Analysis|Feature Reliance Analysis]], [[keywords/ConvNeXt Architecture|ConvNeXt Architecture]], [[keywords/Domain-Agnostic Framework|Domain-Agnostic Framework]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.20234v1 Announce Type: cross 
Abstract: The hypothesis that Convolutional Neural Networks (CNNs) are inherently texture-biased has shaped much of the discourse on feature use in deep learning. We revisit this hypothesis by examining limitations in the cue-conflict experiment by Geirhos et al. To address these limitations, we propose a domain-agnostic framework that quantifies feature reliance through systematic suppression of shape, texture, and color cues, avoiding the confounds of forced-choice conflicts. By evaluating humans and neural networks under controlled suppression conditions, we find that CNNs are not inherently texture-biased but predominantly rely on local shape features. Nonetheless, this reliance can be substantially mitigated through modern training strategies or architectures (ConvNeXt, ViTs). We further extend the analysis across computer vision, medical imaging, and remote sensing, revealing that reliance patterns differ systematically: computer vision models prioritize shape, medical imaging models emphasize color, and remote sensing models exhibit a stronger reliance towards texture. Code is available at https://github.com/tomburgert/feature-reliance.

## 📝 요약

이 논문은 CNN이 본질적으로 텍스처에 편향되어 있다는 기존 가설을 재검토합니다. Geirhos 등의 실험의 한계를 극복하기 위해, 모양, 텍스처, 색상 단서를 체계적으로 억제하여 특징 의존성을 정량화하는 도메인 비특이적 프레임워크를 제안합니다. 이를 통해 CNN이 본질적으로 텍스처에 편향된 것이 아니라 주로 지역적 모양 특징에 의존함을 발견했습니다. 이러한 의존성은 현대의 훈련 전략이나 아키텍처(ConvNeXt, ViTs)를 통해 크게 완화될 수 있습니다. 또한, 컴퓨터 비전, 의료 영상, 원격 감지 분야에서 모델의 의존 패턴이 체계적으로 다르다는 것을 밝혔습니다. 컴퓨터 비전 모델은 모양을, 의료 영상 모델은 색상을, 원격 감지 모델은 텍스처에 더 강하게 의존합니다.

## 🎯 주요 포인트

- 1. 기존의 CNN이 본질적으로 텍스처에 편향되어 있다는 가설을 재검토하여, CNN이 본질적으로 텍스처에 편향된 것이 아니라 주로 지역적 형태(feature)에 의존한다는 것을 발견했습니다.
- 2. Geirhos et al.의 큐-갈등 실험의 한계를 극복하기 위해, 형태, 텍스처, 색상 큐를 체계적으로 억제하여 특징 의존성을 정량화하는 도메인에 구애받지 않는 프레임워크를 제안했습니다.
- 3. 현대적인 훈련 전략이나 아키텍처(ConvNeXt, ViTs)를 통해 CNN의 형태 의존성을 상당히 완화할 수 있음을 발견했습니다.
- 4. 컴퓨터 비전, 의료 영상, 원격 감지 분야에서의 분석을 확장하여, 각 분야의 모델들이 형태, 색상, 텍스처에 대한 의존 패턴이 체계적으로 다르다는 것을 밝혔습니다.
- 5. 연구의 코드는 https://github.com/tomburgert/feature-reliance에서 제공됩니다.


---

*Generated on 2025-09-25 16:03:54*