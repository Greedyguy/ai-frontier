---
keywords:
  - Neural Network
  - Quantization
  - Sparsification
  - Straight-Through Estimator
  - Denoising Dequantization Transform
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2409.09245
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T16:16:28.558791",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Neural Network",
    "Quantization",
    "Sparsification",
    "Straight-Through Estimator",
    "Denoising Dequantization Transform"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Neural Network": 0.85,
    "Quantization": 0.8,
    "Sparsification": 0.78,
    "Straight-Through Estimator": 0.7,
    "Denoising Dequantization Transform": 0.65
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Neural Networks",
        "canonical": "Neural Network",
        "aliases": [
          "Neural Nets"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's focus on training methods, providing a strong link to existing neural network research.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Quantization",
        "canonical": "Quantization",
        "aliases": [
          "Quantizing"
        ],
        "category": "unique_technical",
        "rationale": "A key technical process discussed in the paper, crucial for understanding precision in neural networks.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.8
      },
      {
        "surface": "Sparsification",
        "canonical": "Sparsification",
        "aliases": [
          "Sparse Training"
        ],
        "category": "unique_technical",
        "rationale": "Essential for linking research on reducing neural network complexity and enhancing efficiency.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.75,
        "link_intent_score": 0.78
      },
      {
        "surface": "Straight-Through Estimator",
        "canonical": "Straight-Through Estimator",
        "aliases": [
          "STE"
        ],
        "category": "unique_technical",
        "rationale": "A specific technique addressed in the paper, relevant for understanding the proposed improvements.",
        "novelty_score": 0.6,
        "connectivity_score": 0.5,
        "specificity_score": 0.85,
        "link_intent_score": 0.7
      },
      {
        "surface": "Denoising Dequantization Transform",
        "canonical": "Denoising Dequantization Transform",
        "aliases": [
          "DDT"
        ],
        "category": "unique_technical",
        "rationale": "Introduced as a novel solution in the paper, critical for linking to new methods in neural network training.",
        "novelty_score": 0.8,
        "connectivity_score": 0.4,
        "specificity_score": 0.9,
        "link_intent_score": 0.65
      }
    ],
    "ban_list_suggestions": [
      "method",
      "process",
      "approach"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Neural Networks",
      "resolved_canonical": "Neural Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Quantization",
      "resolved_canonical": "Quantization",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Sparsification",
      "resolved_canonical": "Sparsification",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.75,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Straight-Through Estimator",
      "resolved_canonical": "Straight-Through Estimator",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.5,
        "specificity": 0.85,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Denoising Dequantization Transform",
      "resolved_canonical": "Denoising Dequantization Transform",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.4,
        "specificity": 0.9,
        "link_intent": 0.65
      }
    }
  ]
}
-->

# Robust Training of Neural Networks at Arbitrary Precision and Sparsity

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2409.09245.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2409.09245](https://arxiv.org/abs/2409.09245)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Dynamical Low-Rank Compression of Neural Networks with Robustness under Adversarial Attacks_20250923|Dynamical Low-Rank Compression of Neural Networks with Robustness under Adversarial Attacks]] (84.0% similar)
- [[2025-09-22/MEC-Quant_ Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training_20250922|MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training]] (82.7% similar)
- [[2025-09-23/Machine Learning for Quantum Noise Reduction_20250923|Machine Learning for Quantum Noise Reduction]] (82.3% similar)
- [[2025-09-22/Flavors of Margin_ Implicit Bias of Steepest Descent in Homogeneous Neural Networks_20250922|Flavors of Margin: Implicit Bias of Steepest Descent in Homogeneous Neural Networks]] (82.3% similar)
- [[2025-09-24/Energy-convergence trade off for the training of neural networks on bio-inspired hardware_20250924|Energy-convergence trade off for the training of neural networks on bio-inspired hardware]] (81.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Neural Network|Neural Network]]
**âš¡ Unique Technical**: [[keywords/Quantization|Quantization]], [[keywords/Sparsification|Sparsification]], [[keywords/Straight-Through Estimator|Straight-Through Estimator]], [[keywords/Denoising Dequantization Transform|Denoising Dequantization Transform]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2409.09245v2 Announce Type: replace-cross 
Abstract: The discontinuous operations inherent in quantization and sparsification introduce a long-standing obstacle to backpropagation, particularly in ultra-low precision and sparse regimes. The standard Straight-Through Estimator (STE) is widely used to address this, but the well-understood mismatch between its quantization-aware forward pass and quantization-oblivious backward pass leads to unmanaged error that can corrupt the learning process. We solve this by introducing a denoising dequantization transform derived from a principled ridge regression objective. This transform makes the entire learning process aware of and robust to the quantization error that STE's surrogate gradient bypasses, by creating an explicit, corrective gradient path. We extend this principle to sparsification by viewing it as a special form of quantization that maps insignificant values to zero. Our unified framework allows existing models to be trained at a wide spectrum of precisions and sparsity levels with off-the-shelf recipes, achieving stable training of fully binary (A1W1) and sparse sub-1-bit networks where other methods falter. This approach yields state-of-the-art results and provides a theoretically-grounded path to hyper-efficient neural networks.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì–‘ìí™”ì™€ í¬ì†Œí™” ê³¼ì •ì—ì„œ ë°œìƒí•˜ëŠ” ë¶ˆì—°ì†ì  ì—°ì‚°ì´ ì—­ì „íŒŒì— ë¯¸ì¹˜ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ìƒˆë¡œìš´ ë°©ë²•ë¡ ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ Straight-Through Estimator(STE)ëŠ” ì–‘ìí™” ì¸ì‹ ì „ë°© íŒ¨ìŠ¤ì™€ ì–‘ìí™” ë¬´ì‹œ í›„ë°© íŒ¨ìŠ¤ ê°„ì˜ ë¶ˆì¼ì¹˜ë¡œ ì¸í•´ í•™ìŠµ ê³¼ì •ì— ì˜¤ë¥˜ë¥¼ ì´ˆë˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ì €ìë“¤ì€ ì›ì¹™ì ì¸ ë¦¿ì§€ íšŒê·€ ëª©í‘œì—ì„œ íŒŒìƒëœ ë””ë…¸ì´ì§• ë””í€€íƒ€ì´ì œì´ì…˜ ë³€í™˜ì„ ë„ì…í•˜ì—¬, ì–‘ìí™” ì˜¤ë¥˜ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ë³´ì •í•˜ëŠ” ê²½ë¡œë¥¼ ì œê³µí•©ë‹ˆë‹¤. ë˜í•œ, í¬ì†Œí™”ë¥¼ ì–‘ìí™”ì˜ íŠ¹ë³„í•œ í˜•íƒœë¡œ ë³´ê³  ì´ë¥¼ í†µí•©í•˜ì—¬ ë‹¤ì–‘í•œ ì •ë°€ë„ì™€ í¬ì†Œì„± ìˆ˜ì¤€ì—ì„œ ì•ˆì •ì ì¸ í•™ìŠµì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ì´ ì ‘ê·¼ë²•ì€ ì™„ì „ ì´ì§„ ë° í¬ì†Œ ì„œë¸Œ 1ë¹„íŠ¸ ë„¤íŠ¸ì›Œí¬ì—ì„œ ìµœì²¨ë‹¨ ê²°ê³¼ë¥¼ ë‹¬ì„±í•˜ë©°, ì´ë¡ ì ìœ¼ë¡œ íš¨ìœ¨ì ì¸ ì‹ ê²½ë§ ì„¤ê³„ì˜ ê¸¸ì„ ì œì‹œí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì–‘ìí™” ë° í¬ì†Œí™”ì˜ ë¶ˆì—°ì†ì  ì—°ì‚°ì€ ì´ˆì €ì •ë°€ ë° í¬ì†Œ í™˜ê²½ì—ì„œ ì—­ì „íŒŒì— ì¥ì• ë¥¼ ì´ˆë˜í•œë‹¤.
- 2. í‘œì¤€ ì§ì„  ì¶”ì •ê¸°(STE)ëŠ” ì–‘ìí™” ì¸ì‹ ì „ë°© íŒ¨ìŠ¤ì™€ ì–‘ìí™” ë¹„ì¸ì‹ í›„ë°© íŒ¨ìŠ¤ ê°„ì˜ ë¶ˆì¼ì¹˜ë¡œ ì¸í•´ í•™ìŠµ ê³¼ì •ì— ì˜¤ë¥˜ë¥¼ ìœ ë°œí•  ìˆ˜ ìˆë‹¤.
- 3. ë³¸ ì—°êµ¬ëŠ” ì›ì¹™ì ì¸ ëŠ¥ì„  íšŒê·€ ëª©í‘œì—ì„œ íŒŒìƒëœ ì¡ìŒ ì œê±° ë””ì–‘ìí™” ë³€í™˜ì„ ë„ì…í•˜ì—¬ ì´ ë¬¸ì œë¥¼ í•´ê²°í•œë‹¤.
- 4. ì œì•ˆëœ ë³€í™˜ì€ STEì˜ ëŒ€ì²´ ê²½ì‚¬ê°€ ìš°íšŒí•˜ëŠ” ì–‘ìí™” ì˜¤ë¥˜ì— ëŒ€í•´ í•™ìŠµ ê³¼ì •ì„ ì¸ì‹í•˜ê³  ê²¬ê³ í•˜ê²Œ ë§Œë“ ë‹¤.
- 5. ë³¸ ì ‘ê·¼ë²•ì€ ì™„ì „ ì´ì§„ ë° í¬ì†Œ ì„œë¸Œ 1ë¹„íŠ¸ ë„¤íŠ¸ì›Œí¬ì˜ ì•ˆì •ì ì¸ í•™ìŠµì„ ê°€ëŠ¥í•˜ê²Œ í•˜ë©°, ì´ë¡ ì ìœ¼ë¡œ ê·¼ê±° ìˆëŠ” ì´ˆíš¨ìœ¨ ì‹ ê²½ë§ìœ¼ë¡œì˜ ê²½ë¡œë¥¼ ì œê³µí•œë‹¤.


---

*Generated on 2025-09-25 16:16:28*