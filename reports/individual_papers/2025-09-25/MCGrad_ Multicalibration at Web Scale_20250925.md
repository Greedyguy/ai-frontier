---
keywords:
  - MCGrad
  - Multicalibration
  - Machine Learning
  - Logarithmic Loss
  - Precision-Recall Curve
category: cs.LG
publish_date: 2025-09-25
arxiv_id: 2509.19884
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T16:41:14.429108",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "MCGrad",
    "Multicalibration",
    "Machine Learning",
    "Logarithmic Loss",
    "Precision-Recall Curve"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "MCGrad": 0.8,
    "Multicalibration": 0.78,
    "Machine Learning": 0.7,
    "Logarithmic Loss": 0.72,
    "Precision-Recall Curve": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "MCGrad",
        "canonical": "MCGrad",
        "aliases": [
          "Multicalibration Gradient"
        ],
        "category": "unique_technical",
        "rationale": "MCGrad is a novel algorithm introduced in the paper, representing a unique contribution to multicalibration techniques.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "multicalibration",
        "canonical": "Multicalibration",
        "aliases": [
          "multi-calibration"
        ],
        "category": "specific_connectable",
        "rationale": "Multicalibration is a key concept in the paper, essential for understanding the algorithm's purpose and application.",
        "novelty_score": 0.7,
        "connectivity_score": 0.85,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "machine learning-based systems",
        "canonical": "Machine Learning",
        "aliases": [
          "ML systems"
        ],
        "category": "broad_technical",
        "rationale": "Machine Learning is the foundational technology context for the algorithm, connecting it to a broader technical framework.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.7
      },
      {
        "surface": "log loss",
        "canonical": "Logarithmic Loss",
        "aliases": [
          "log loss",
          "logarithmic loss"
        ],
        "category": "specific_connectable",
        "rationale": "Logarithmic Loss is a critical evaluation metric discussed in relation to the algorithm's performance.",
        "novelty_score": 0.6,
        "connectivity_score": 0.75,
        "specificity_score": 0.85,
        "link_intent_score": 0.72
      },
      {
        "surface": "Area Under the Precision-Recall Curve",
        "canonical": "Precision-Recall Curve",
        "aliases": [
          "PRAUC",
          "Area Under PRAUC"
        ],
        "category": "specific_connectable",
        "rationale": "Precision-Recall Curve is a significant metric for evaluating the algorithm's impact on model performance.",
        "novelty_score": 0.55,
        "connectivity_score": 0.8,
        "specificity_score": 0.88,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "algorithm",
      "performance",
      "results"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "MCGrad",
      "resolved_canonical": "MCGrad",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "multicalibration",
      "resolved_canonical": "Multicalibration",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.85,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "machine learning-based systems",
      "resolved_canonical": "Machine Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "log loss",
      "resolved_canonical": "Logarithmic Loss",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.75,
        "specificity": 0.85,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "Area Under the Precision-Recall Curve",
      "resolved_canonical": "Precision-Recall Curve",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.8,
        "specificity": 0.88,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# MCGrad:: Multicalibration at Web Scale

## 📋 메타데이터

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19884.pdf)
**Category**: cs.LG
**Published**: 2025-09-25
**ArXiv ID**: [2509.19884](https://arxiv.org/abs/2509.19884)

## 🔗 유사한 논문
- [[2025-09-23/Auditability and the Landscape of Distance to Multicalibration_20250923|Auditability and the Landscape of Distance to Multicalibration]] (85.1% similar)
- [[2025-09-23/Continual Multimodal Contrastive Learning_20250923|Continual Multimodal Contrastive Learning]] (81.3% similar)
- [[2025-09-23/MCP_ A Control-Theoretic Orchestration Framework for Synergistic Efficiency and Interpretability in Multimodal Large Language Models_20250923|MCP: A Control-Theoretic Orchestration Framework for Synergistic Efficiency and Interpretability in Multimodal Large Language Models]] (80.7% similar)
- [[2025-09-23/Learning to Learn with Contrastive Meta-Objective_20250923|Learning to Learn with Contrastive Meta-Objective]] (80.5% similar)
- [[2025-09-25/Multi-population Ensemble Genetic Programming via Cooperative Coevolution and Multi-view Learning for Classification_20250925|Multi-population Ensemble Genetic Programming via Cooperative Coevolution and Multi-view Learning for Classification]] (80.3% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Machine Learning|Machine Learning]]
**🔗 Specific Connectable**: [[keywords/Multicalibration|Multicalibration]], [[keywords/Logarithmic Loss|Logarithmic Loss]], [[keywords/Precision-Recall Curve|Precision-Recall Curve]]
**⚡ Unique Technical**: [[keywords/MCGrad|MCGrad]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.19884v1 Announce Type: new 
Abstract: We propose MCGrad, a novel and scalable multicalibration algorithm. Multicalibration - calibration in sub-groups of the data - is an important property for the performance of machine learning-based systems. Existing multicalibration methods have thus far received limited traction in industry. We argue that this is because existing methods (1) require such subgroups to be manually specified, which ML practitioners often struggle with, (2) are not scalable, or (3) may harm other notions of model performance such as log loss and Area Under the Precision-Recall Curve (PRAUC). MCGrad does not require explicit specification of protected groups, is scalable, and often improves other ML evaluation metrics instead of harming them. MCGrad has been in production at Meta, and is now part of hundreds of production models. We present results from these deployments as well as results on public datasets.

## 📝 요약

MCGrad는 새로운 확장 가능한 멀티캘리브레이션 알고리즘으로, 데이터의 하위 그룹에서의 캘리브레이션을 개선하여 머신러닝 시스템의 성능을 향상시킵니다. 기존 방법들은 하위 그룹을 수동으로 지정해야 하고, 확장성이 부족하며, 다른 성능 지표에 부정적 영향을 미칠 수 있습니다. 그러나 MCGrad는 보호 그룹을 명시적으로 지정할 필요가 없고, 확장 가능하며, 오히려 다른 평가 지표를 개선합니다. 이 알고리즘은 Meta에서 실제로 사용되고 있으며, 수백 개의 모델에 적용되고 있습니다. 논문에서는 실제 배포 결과와 공개 데이터셋에 대한 결과를 제시합니다.

## 🎯 주요 포인트

- 1. MCGrad는 새로운 확장 가능한 다중 보정 알고리즘으로, 데이터의 하위 그룹에서의 보정을 통해 머신러닝 시스템의 성능을 향상시킵니다.
- 2. 기존의 다중 보정 방법은 하위 그룹을 수동으로 지정해야 하고 확장성이 부족하며, 다른 모델 성능 지표에 부정적인 영향을 미칠 수 있습니다.
- 3. MCGrad는 보호 그룹의 명시적 지정이 필요 없고 확장 가능하며, 다른 머신러닝 평가 지표를 개선하는 경향이 있습니다.
- 4. MCGrad는 Meta에서 실제로 사용되고 있으며, 수백 개의 생산 모델에 통합되어 있습니다.
- 5. MCGrad의 배포 결과와 공개 데이터셋에서의 성능 결과가 제시되었습니다.


---

*Generated on 2025-09-25 16:41:14*