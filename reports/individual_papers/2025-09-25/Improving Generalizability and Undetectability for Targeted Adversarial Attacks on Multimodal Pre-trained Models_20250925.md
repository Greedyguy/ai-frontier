---
keywords:
  - Multimodal Learning
  - Adversarial Attacks
  - Proxy Targeted Attack
  - Anomaly Detection
category: cs.CV
publish_date: 2025-09-25
arxiv_id: 2509.19994
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-26T09:11:09.400427",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multimodal Learning",
    "Adversarial Attacks",
    "Proxy Targeted Attack",
    "Anomaly Detection"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multimodal Learning": 0.85,
    "Adversarial Attacks": 0.78,
    "Proxy Targeted Attack": 0.7,
    "Anomaly Detection": 0.68
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multimodal pre-trained models",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal Models",
          "Multimodal Pre-trained"
        ],
        "category": "specific_connectable",
        "rationale": "Multimodal Learning is a key area connecting various data modalities, making it crucial for linking across related research.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Targeted Adversarial Attacks",
        "canonical": "Adversarial Attacks",
        "aliases": [
          "Targeted AEs",
          "Adversarial Examples"
        ],
        "category": "unique_technical",
        "rationale": "Adversarial Attacks are central to security concerns in AI, providing strong links to research on model robustness.",
        "novelty_score": 0.65,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Proxy Targeted Attack",
        "canonical": "Proxy Targeted Attack",
        "aliases": [
          "PTA"
        ],
        "category": "unique_technical",
        "rationale": "The proposed method, Proxy Targeted Attack, is novel and specific to the paper, offering a unique link to this research.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.7
      },
      {
        "surface": "Anomaly Detection Methods",
        "canonical": "Anomaly Detection",
        "aliases": [
          "Detection Methods"
        ],
        "category": "broad_technical",
        "rationale": "Anomaly Detection is a broad technique applicable across various domains, linking to research on security and model evaluation.",
        "novelty_score": 0.4,
        "connectivity_score": 0.82,
        "specificity_score": 0.6,
        "link_intent_score": 0.68
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "experiment"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multimodal pre-trained models",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Targeted Adversarial Attacks",
      "resolved_canonical": "Adversarial Attacks",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Proxy Targeted Attack",
      "resolved_canonical": "Proxy Targeted Attack",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Anomaly Detection Methods",
      "resolved_canonical": "Anomaly Detection",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.82,
        "specificity": 0.6,
        "link_intent": 0.68
      }
    }
  ]
}
-->

# Improving Generalizability and Undetectability for Targeted Adversarial Attacks on Multimodal Pre-trained Models

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19994.pdf)
**Category**: cs.CV
**Published**: 2025-09-25
**ArXiv ID**: [2509.19994](https://arxiv.org/abs/2509.19994)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-25/Universal Camouflage Attack on Vision-Language Models for Autonomous Driving_20250925|Universal Camouflage Attack on Vision-Language Models for Autonomous Driving]] (83.2% similar)
- [[2025-09-25/BiTAA_ A Bi-Task Adversarial Attack for Object Detection and Depth Estimation via 3D Gaussian Splatting_20250925|BiTAA: A Bi-Task Adversarial Attack for Object Detection and Depth Estimation via 3D Gaussian Splatting]] (83.1% similar)
- [[2025-09-24/Latent Danger Zone_ Distilling Unified Attention for Cross-Architecture Black-box Attacks_20250924|Latent Danger Zone: Distilling Unified Attention for Cross-Architecture Black-box Attacks]] (82.9% similar)
- [[2025-09-23/DeepInsert_ Early Layer Bypass for Efficient and Performant Multimodal Understanding_20250923|DeepInsert: Early Layer Bypass for Efficient and Performant Multimodal Understanding]] (82.8% similar)
- [[2025-09-24/Backdoor Attack with Invisible Triggers Based on Model Architecture Modification_20250924|Backdoor Attack with Invisible Triggers Based on Model Architecture Modification]] (82.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Anomaly Detection|Anomaly Detection]]
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**âš¡ Unique Technical**: [[keywords/Adversarial Attacks|Adversarial Attacks]], [[keywords/Proxy Targeted Attack|Proxy Targeted Attack]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19994v1 Announce Type: new 
Abstract: Multimodal pre-trained models (e.g., ImageBind), which align distinct data modalities into a shared embedding space, have shown remarkable success across downstream tasks. However, their increasing adoption raises serious security concerns, especially regarding targeted adversarial attacks. In this paper, we show that existing targeted adversarial attacks on multimodal pre-trained models still have limitations in two aspects: generalizability and undetectability. Specifically, the crafted targeted adversarial examples (AEs) exhibit limited generalization to partially known or semantically similar targets in cross-modal alignment tasks (i.e., limited generalizability) and can be easily detected by simple anomaly detection methods (i.e., limited undetectability). To address these limitations, we propose a novel method called Proxy Targeted Attack (PTA), which leverages multiple source-modal and target-modal proxies to optimize targeted AEs, ensuring they remain evasive to defenses while aligning with multiple potential targets. We also provide theoretical analyses to highlight the relationship between generalizability and undetectability and to ensure optimal generalizability while meeting the specified requirements for undetectability. Furthermore, experimental results demonstrate that our PTA can achieve a high success rate across various related targets and remain undetectable against multiple anomaly detection methods.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë©€í‹°ëª¨ë‹¬ ì‚¬ì „ í•™ìŠµ ëª¨ë¸ì— ëŒ€í•œ ê¸°ì¡´ì˜ í‘œì  ì ëŒ€ì  ê³µê²©ì´ ì¼ë°˜í™” ê°€ëŠ¥ì„±ê³¼ íƒì§€ íšŒí”¼ ì¸¡ë©´ì—ì„œ í•œê³„ë¥¼ ê°€ì§€ê³  ìˆìŒì„ ì§€ì í•©ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ì €ìë“¤ì€ Proxy Targeted Attack (PTA)ë¼ëŠ” ìƒˆë¡œìš´ ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. PTAëŠ” ì—¬ëŸ¬ ì†ŒìŠ¤ ë° íƒ€ê²Ÿ ëª¨ë‹¬ í”„ë¡ì‹œë¥¼ í™œìš©í•˜ì—¬ í‘œì  ì ëŒ€ì  ì˜ˆì œë¥¼ ìµœì í™”í•˜ë©°, ë‹¤ì–‘í•œ ì ì¬ì  í‘œì ê³¼ì˜ ì •ë ¬ì„ ìœ ì§€í•˜ë©´ì„œ ë°©ì–´ë¥¼ íšŒí”¼í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ë°©ë²•ì€ ì´ë¡ ì  ë¶„ì„ì„ í†µí•´ ì¼ë°˜í™” ê°€ëŠ¥ì„±ê³¼ íƒì§€ íšŒí”¼ ê°„ì˜ ê´€ê³„ë¥¼ ì„¤ëª…í•˜ê³ , ì‹¤í—˜ ê²°ê³¼ë¥¼ í†µí•´ ë†’ì€ ì„±ê³µë¥ ê³¼ íƒì§€ íšŒí”¼ ì„±ëŠ¥ì„ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë‹¤ì¤‘ëª¨ë‹¬ ì‚¬ì „ í•™ìŠµ ëª¨ë¸ì€ ë³´ì•ˆ ë¬¸ì œ, íŠ¹íˆ í‘œì  ì ëŒ€ì  ê³µê²©ì— ì·¨ì•½í•˜ë‹¤.
- 2. ê¸°ì¡´ì˜ í‘œì  ì ëŒ€ì  ê³µê²©ì€ ì¼ë°˜í™” ê°€ëŠ¥ì„±ê³¼ íƒì§€ ë¶ˆê°€ì„±ì—ì„œ í•œê³„ë¥¼ ê°€ì§€ê³  ìˆë‹¤.
- 3. Proxy Targeted Attack (PTA) ë°©ë²•ì€ ë‹¤ì¤‘ ì†ŒìŠ¤ ë° íƒ€ê²Ÿ ëª¨ë‹¬ í”„ë¡ì‹œë¥¼ í™œìš©í•˜ì—¬ í‘œì  ì ëŒ€ì  ì˜ˆì œë¥¼ ìµœì í™”í•œë‹¤.
- 4. PTAëŠ” ë‹¤ì–‘í•œ ê´€ë ¨ íƒ€ê²Ÿì— ëŒ€í•´ ë†’ì€ ì„±ê³µë¥ ì„ ë³´ì´ë©°, ì—¬ëŸ¬ ì´ìƒ íƒì§€ ë°©ë²•ì— ëŒ€í•´ íƒì§€ë˜ì§€ ì•ŠëŠ”ë‹¤.
- 5. ì´ë¡ ì  ë¶„ì„ì„ í†µí•´ ì¼ë°˜í™” ê°€ëŠ¥ì„±ê³¼ íƒì§€ ë¶ˆê°€ì„± ê°„ì˜ ê´€ê³„ë¥¼ ê°•ì¡°í•˜ê³  ìµœì ì˜ ì¼ë°˜í™” ê°€ëŠ¥ì„±ì„ ë³´ì¥í•œë‹¤.


---

*Generated on 2025-09-26 09:11:09*