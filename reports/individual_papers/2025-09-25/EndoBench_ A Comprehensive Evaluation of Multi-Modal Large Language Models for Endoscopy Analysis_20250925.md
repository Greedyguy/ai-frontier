---
keywords:
  - Large Language Model
  - Endoscopic Procedures
  - Vision-Language Model
  - Visual Question Answering
  - Medical-Specialized Models
category: cs.CV
publish_date: 2025-09-25
arxiv_id: 2505.23601
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-26T09:25:37.337133",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Endoscopic Procedures",
    "Vision-Language Model",
    "Visual Question Answering",
    "Medical-Specialized Models"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.82,
    "Endoscopic Procedures": 0.78,
    "Vision-Language Model": 0.8,
    "Visual Question Answering": 0.79,
    "Medical-Specialized Models": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multi-Modal Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "MLLM",
          "Multi-Modal LLM"
        ],
        "category": "broad_technical",
        "rationale": "Connects to the broader concept of language models used in various technical domains.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.82
      },
      {
        "surface": "Endoscopic Procedures",
        "canonical": "Endoscopic Procedures",
        "aliases": [
          "Endoscopy"
        ],
        "category": "unique_technical",
        "rationale": "Central to the paper's focus on medical applications and specific to the domain of endoscopy.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Vision-Language Model",
        "canonical": "Vision-Language Model",
        "aliases": [
          "VLM"
        ],
        "category": "evolved_concepts",
        "rationale": "Represents a key area of research in combining visual and textual data processing.",
        "novelty_score": 0.68,
        "connectivity_score": 0.83,
        "specificity_score": 0.72,
        "link_intent_score": 0.8
      },
      {
        "surface": "Visual Question Answering",
        "canonical": "Visual Question Answering",
        "aliases": [
          "VQA"
        ],
        "category": "specific_connectable",
        "rationale": "A specific task that bridges computer vision and natural language processing.",
        "novelty_score": 0.6,
        "connectivity_score": 0.85,
        "specificity_score": 0.78,
        "link_intent_score": 0.79
      },
      {
        "surface": "Medical-Specialized Models",
        "canonical": "Medical-Specialized Models",
        "aliases": [
          "Medical ML Models"
        ],
        "category": "unique_technical",
        "rationale": "Highlights the specialization of models for medical applications, crucial for domain-specific insights.",
        "novelty_score": 0.7,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "benchmark",
      "performance",
      "experiment"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multi-Modal Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Endoscopic Procedures",
      "resolved_canonical": "Endoscopic Procedures",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Vision-Language Model",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.83,
        "specificity": 0.72,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Visual Question Answering",
      "resolved_canonical": "Visual Question Answering",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.85,
        "specificity": 0.78,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Medical-Specialized Models",
      "resolved_canonical": "Medical-Specialized Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# EndoBench: A Comprehensive Evaluation of Multi-Modal Large Language Models for Endoscopy Analysis

## 📋 메타데이터

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2505.23601.pdf)
**Category**: cs.CV
**Published**: 2025-09-25
**ArXiv ID**: [2505.23601](https://arxiv.org/abs/2505.23601)

## 🔗 유사한 논문
- [[2025-09-22/EyePCR_ A Comprehensive Benchmark for Fine-Grained Perception, Knowledge Comprehension and Clinical Reasoning in Ophthalmic Surgery_20250922|EyePCR: A Comprehensive Benchmark for Fine-Grained Perception, Knowledge Comprehension and Clinical Reasoning in Ophthalmic Surgery]] (87.1% similar)
- [[2025-09-25/EchoBench_ Benchmarking Sycophancy in Medical Large Vision-Language Models_20250925|EchoBench: Benchmarking Sycophancy in Medical Large Vision-Language Models]] (86.2% similar)
- [[2025-09-24/Zero-shot Monocular Metric Depth for Endoscopic Images_20250924|Zero-shot Monocular Metric Depth for Endoscopic Images]] (84.8% similar)
- [[2025-09-23/EngiBench_ A Benchmark for Evaluating Large Language Models on Engineering Problem Solving_20250923|EngiBench: A Benchmark for Evaluating Large Language Models on Engineering Problem Solving]] (84.6% similar)
- [[2025-09-23/From Scores to Steps_ Diagnosing and Improving LLM Performance in Evidence-Based Medical Calculations_20250923|From Scores to Steps: Diagnosing and Improving LLM Performance in Evidence-Based Medical Calculations]] (84.4% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Visual Question Answering|Visual Question Answering]]
**⚡ Unique Technical**: [[keywords/Endoscopic Procedures|Endoscopic Procedures]], [[keywords/Medical-Specialized Models|Medical-Specialized Models]]
**🚀 Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2505.23601v2 Announce Type: replace 
Abstract: Endoscopic procedures are essential for diagnosing and treating internal diseases, and multi-modal large language models (MLLMs) are increasingly applied to assist in endoscopy analysis. However, current benchmarks are limited, as they typically cover specific endoscopic scenarios and a small set of clinical tasks, failing to capture the real-world diversity of endoscopic scenarios and the full range of skills needed in clinical workflows. To address these issues, we introduce EndoBench, the first comprehensive benchmark specifically designed to assess MLLMs across the full spectrum of endoscopic practice with multi-dimensional capacities. EndoBench encompasses 4 distinct endoscopic scenarios, 12 specialized clinical tasks with 12 secondary subtasks, and 5 levels of visual prompting granularities, resulting in 6,832 rigorously validated VQA pairs from 21 diverse datasets. Our multi-dimensional evaluation framework mirrors the clinical workflow--spanning anatomical recognition, lesion analysis, spatial localization, and surgical operations--to holistically gauge the perceptual and diagnostic abilities of MLLMs in realistic scenarios. We benchmark 23 state-of-the-art models, including general-purpose, medical-specialized, and proprietary MLLMs, and establish human clinician performance as a reference standard. Our extensive experiments reveal: (1) proprietary MLLMs outperform open-source and medical-specialized models overall, but still trail human experts; (2) medical-domain supervised fine-tuning substantially boosts task-specific accuracy; and (3) model performance remains sensitive to prompt format and clinical task complexity. EndoBench establishes a new standard for evaluating and advancing MLLMs in endoscopy, highlighting both progress and persistent gaps between current models and expert clinical reasoning. We publicly release our benchmark and code.

## 📝 요약

EndoBench는 내시경 분석을 돕는 다중 모달 대형 언어 모델(MLLMs)의 평가를 위한 포괄적인 벤치마크로, 내시경 실무 전반을 아우르는 첫 번째 평가 도구입니다. 4가지 내시경 시나리오와 12개의 임상 과제, 5단계의 시각적 프롬프트를 포함하여 6,832개의 VQA 쌍을 제공합니다. 23개의 최신 모델을 평가한 결과, 독점 MLLMs가 전반적으로 우수하지만 여전히 인간 전문가에 미치지 못하며, 의료 분야의 감독 학습이 정확성을 크게 향상시킨다는 것을 발견했습니다. EndoBench는 내시경 분야의 MLLMs 발전을 위한 새로운 기준을 제시합니다.

## 🎯 주요 포인트

- 1. EndoBench는 다차원적 역량을 통해 내시경 실습의 전체 스펙트럼을 평가하기 위해 설계된 최초의 포괄적인 벤치마크입니다.
- 2. EndoBench는 4개의 내시경 시나리오, 12개의 전문 임상 작업과 12개의 부차적 작업, 5단계의 시각적 프롬프트 세분화를 포함합니다.
- 3. 실험 결과, 독점 MLLM이 오픈소스 및 의료 전문 모델보다 우수하지만 여전히 인간 전문가에 비해 뒤처지는 것으로 나타났습니다.
- 4. 의료 도메인에서의 감독된 미세 조정은 작업별 정확도를 크게 향상시킵니다.
- 5. 모델 성능은 프롬프트 형식과 임상 작업의 복잡성에 민감하게 반응합니다.


---

*Generated on 2025-09-26 09:25:37*