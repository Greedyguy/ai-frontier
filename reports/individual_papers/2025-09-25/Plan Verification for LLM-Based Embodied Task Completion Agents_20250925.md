---
keywords:
  - Large Language Model
  - Plan Verification
  - Embodied AI
  - Imitation Learning
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2509.02761
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T16:13:33.214600",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Plan Verification",
    "Embodied AI",
    "Imitation Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Plan Verification": 0.78,
    "Embodied AI": 0.8,
    "Imitation Learning": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Model",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's methodology, enabling connections to a wide range of AI and NLP literature.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Plan Verification",
        "canonical": "Plan Verification",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "A unique concept introduced in the paper, crucial for understanding the iterative framework proposed.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Embodied AI",
        "canonical": "Embodied AI",
        "aliases": [
          "Embodied Artificial Intelligence"
        ],
        "category": "specific_connectable",
        "rationale": "Key application domain of the study, linking to research in robotics and AI.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Imitation Learning",
        "canonical": "Imitation Learning",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Relevant for linking to machine learning methods focused on learning from demonstrations.",
        "novelty_score": 0.4,
        "connectivity_score": 0.75,
        "specificity_score": 0.65,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "experiment"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Model",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Plan Verification",
      "resolved_canonical": "Plan Verification",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Embodied AI",
      "resolved_canonical": "Embodied AI",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Imitation Learning",
      "resolved_canonical": "Imitation Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.75,
        "specificity": 0.65,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# Plan Verification for LLM-Based Embodied Task Completion Agents

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.02761.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2509.02761](https://arxiv.org/abs/2509.02761)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates_20250923|Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates]] (85.8% similar)
- [[2025-09-24/LogicGuard_ Improving Embodied LLM agents through Temporal Logic based Critics_20250924|LogicGuard: Improving Embodied LLM agents through Temporal Logic based Critics]] (85.1% similar)
- [[2025-09-19/ThinkAct_ Vision-Language-Action Reasoning via Reinforced Visual Latent Planning_20250919|ThinkAct: Vision-Language-Action Reasoning via Reinforced Visual Latent Planning]] (84.9% similar)
- [[2025-09-24/Reflect before Act_ Proactive Error Correction in Language Models_20250924|Reflect before Act: Proactive Error Correction in Language Models]] (84.9% similar)
- [[2025-09-23/Runaway is Ashamed, But Helpful_ On the Early-Exit Behavior of Large Language Model-based Agents in Embodied Environments_20250923|Runaway is Ashamed, But Helpful: On the Early-Exit Behavior of Large Language Model-based Agents in Embodied Environments]] (84.7% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Embodied AI|Embodied AI]], [[keywords/Imitation Learning|Imitation Learning]]
**âš¡ Unique Technical**: [[keywords/Plan Verification|Plan Verification]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.02761v3 Announce Type: replace 
Abstract: Large language model (LLM) based task plans and corresponding human demonstrations for embodied AI may be noisy, with unnecessary actions, redundant navigation, and logical errors that reduce policy quality. We propose an iterative verification framework in which a Judge LLM critiques action sequences and a Planner LLM applies the revisions, yielding progressively cleaner and more spatially coherent trajectories. Unlike rule-based approaches, our method relies on natural language prompting, enabling broad generalization across error types including irrelevant actions, contradictions, and missing steps. On a set of manually annotated actions from the TEACh embodied AI dataset, our framework achieves up to 90% recall and 100% precision across four state-of-the-art LLMs (GPT o4-mini, DeepSeek-R1, Gemini 2.5, LLaMA 4 Scout). The refinement loop converges quickly, with 96.5% of sequences requiring at most three iterations, while improving both temporal efficiency and spatial action organization. Crucially, the method preserves human error-recovery patterns rather than collapsing them, supporting future work on robust corrective behavior. By establishing plan verification as a reliable LLM capability for spatial planning and action refinement, we provide a scalable path to higher-quality training data for imitation learning in embodied AI.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ì²´í™”ëœ AIì˜ ì‘ì—… ê³„íšê³¼ ì¸ê°„ ì‹œì—°ì´ ë¶ˆí•„ìš”í•œ í–‰ë™, ì¤‘ë³µëœ ì´ë™, ë…¼ë¦¬ì  ì˜¤ë¥˜ë¡œ ì¸í•´ ì •ì±… í’ˆì§ˆì´ ì €í•˜ë  ìˆ˜ ìˆìŒì„ ì§€ì í•©ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, íŒì‚¬ LLMì´ í–‰ë™ ìˆœì„œë¥¼ ë¹„íŒí•˜ê³  ê³„íšì LLMì´ ìˆ˜ì • ì‚¬í•­ì„ ì ìš©í•˜ëŠ” ë°˜ë³µ ê²€ì¦ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ìì—°ì–´ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ì–‘í•œ ì˜¤ë¥˜ ìœ í˜•ì— ëŒ€í•´ ì¼ë°˜í™”í•  ìˆ˜ ìˆìœ¼ë©°, TEACh ë°ì´í„°ì…‹ì—ì„œ ë†’ì€ ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ë¹ ë¥´ê²Œ ìˆ˜ë ´í•˜ë©°, ì¸ê°„ì˜ ì˜¤ë¥˜ íšŒë³µ íŒ¨í„´ì„ ìœ ì§€í•˜ì—¬ ì²´í™”ëœ AIì˜ ëª¨ë°© í•™ìŠµì„ ìœ„í•œ ê³ í’ˆì§ˆ êµìœ¡ ë°ì´í„°ë¥¼ ì œê³µí•˜ëŠ” ë° ê¸°ì—¬í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM) ê¸°ë°˜ì˜ ì‘ì—… ê³„íšê³¼ ì¸ê°„ ì‹œì—°ì€ ë¶ˆí•„ìš”í•œ í–‰ë™, ì¤‘ë³µëœ íƒìƒ‰, ë…¼ë¦¬ì  ì˜¤ë¥˜ë¡œ ì¸í•´ ì •ì±… í’ˆì§ˆì´ ì €í•˜ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- 2. ì œì•ˆëœ ë°˜ë³µ ê²€ì¦ í”„ë ˆì„ì›Œí¬ëŠ” Judge LLMì´ í–‰ë™ ì‹œí€€ìŠ¤ë¥¼ ë¹„íŒí•˜ê³  Planner LLMì´ ìˆ˜ì • ì‚¬í•­ì„ ì ìš©í•˜ì—¬ ì ì§„ì ìœ¼ë¡œ ë” ê¹¨ë—í•˜ê³  ê³µê°„ì ìœ¼ë¡œ ì¼ê´€ëœ ê²½ë¡œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
- 3. ì´ ë°©ë²•ì€ ìì—°ì–´ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ê´€ë ¨ ì—†ëŠ” í–‰ë™, ëª¨ìˆœ, ëˆ„ë½ëœ ë‹¨ê³„ ë“± ë‹¤ì–‘í•œ ì˜¤ë¥˜ ìœ í˜•ì— ëŒ€í•´ ê´‘ë²”ìœ„í•œ ì¼ë°˜í™”ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
- 4. TEACh embodied AI ë°ì´í„°ì…‹ì˜ ìˆ˜ë™ ì£¼ì„ëœ í–‰ë™ ì„¸íŠ¸ì—ì„œ, ì œì•ˆëœ í”„ë ˆì„ì›Œí¬ëŠ” ë„¤ ê°€ì§€ ìµœì²¨ë‹¨ LLMì—ì„œ ìµœëŒ€ 90%ì˜ ì¬í˜„ìœ¨ê³¼ 100%ì˜ ì •ë°€ë„ë¥¼ ë‹¬ì„±í•©ë‹ˆë‹¤.
- 5. ì´ ë°©ë²•ì€ ì¸ê°„ì˜ ì˜¤ë¥˜ íšŒë³µ íŒ¨í„´ì„ ìœ ì§€í•˜ë©´ì„œ ê³µê°„ ê³„íš ë° í–‰ë™ ì •ì œë¥¼ ìœ„í•œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” LLM ê¸°ëŠ¥ìœ¼ë¡œ ê³„íš ê²€ì¦ì„ í™•ë¦½í•˜ì—¬ ëª¨ë°© í•™ìŠµì„ ìœ„í•œ ê³ í’ˆì§ˆ í›ˆë ¨ ë°ì´í„°ë¡œì˜ í™•ì¥ ê°€ëŠ¥í•œ ê²½ë¡œë¥¼ ì œê³µí•©ë‹ˆë‹¤.


---

*Generated on 2025-09-25 16:13:33*