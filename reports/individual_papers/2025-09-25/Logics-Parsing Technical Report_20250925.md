---
keywords:
  - Vision-Language Model
  - Optical Character Recognition
  - Reinforcement Learning
  - Logics-Parsing
  - LogicsParsingBench
category: cs.CV
publish_date: 2025-09-25
arxiv_id: 2509.19760
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-26T09:06:15.992429",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Vision-Language Model",
    "Optical Character Recognition",
    "Reinforcement Learning",
    "Logics-Parsing",
    "LogicsParsingBench"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Vision-Language Model": 0.85,
    "Optical Character Recognition": 0.8,
    "Reinforcement Learning": 0.78,
    "Logics-Parsing": 0.7,
    "LogicsParsingBench": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Vision-Language models",
        "canonical": "Vision-Language Model",
        "aliases": [
          "LVLM"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-Language Models are crucial for linking multimodal learning and document analysis advancements.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.68,
        "link_intent_score": 0.85
      },
      {
        "surface": "Optical Character Recognition",
        "canonical": "Optical Character Recognition",
        "aliases": [
          "OCR"
        ],
        "category": "specific_connectable",
        "rationale": "OCR is a key component in document parsing, connecting to broader text recognition technologies.",
        "novelty_score": 0.4,
        "connectivity_score": 0.79,
        "specificity_score": 0.72,
        "link_intent_score": 0.8
      },
      {
        "surface": "reinforcement learning",
        "canonical": "Reinforcement Learning",
        "aliases": [],
        "category": "broad_technical",
        "rationale": "Reinforcement Learning is central to optimizing model performance, linking to adaptive learning strategies.",
        "novelty_score": 0.35,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.78
      },
      {
        "surface": "Logics-Parsing",
        "canonical": "Logics-Parsing",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Logics-Parsing represents a novel approach in document parsing, offering unique insights into layout analysis.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.7
      },
      {
        "surface": "LogicsParsingBench",
        "canonical": "LogicsParsingBench",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "LogicsParsingBench is a unique dataset for evaluating document parsing models, enhancing research reproducibility.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.88,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "document parsing task",
      "structured outputs",
      "complex document types"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Vision-Language models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.68,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Optical Character Recognition",
      "resolved_canonical": "Optical Character Recognition",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.79,
        "specificity": 0.72,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "reinforcement learning",
      "resolved_canonical": "Reinforcement Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.35,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Logics-Parsing",
      "resolved_canonical": "Logics-Parsing",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "LogicsParsingBench",
      "resolved_canonical": "LogicsParsingBench",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.88,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# Logics-Parsing Technical Report

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19760.pdf)
**Category**: cs.CV
**Published**: 2025-09-25
**ArXiv ID**: [2509.19760](https://arxiv.org/abs/2509.19760)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/EquiBench_ Benchmarking Large Language Models' Reasoning about Program Semantics via Equivalence Checking_20250923|EquiBench: Benchmarking Large Language Models' Reasoning about Program Semantics via Equivalence Checking]] (82.3% similar)
- [[2025-09-23/Seeing is Believing? Mitigating OCR Hallucinations in Multimodal Large Language Models_20250923|Seeing is Believing? Mitigating OCR Hallucinations in Multimodal Large Language Models]] (82.2% similar)
- [[2025-09-19/UnifiedVisual_ A Framework for Constructing Unified Vision-Language Datasets_20250919|UnifiedVisual: A Framework for Constructing Unified Vision-Language Datasets]] (82.2% similar)
- [[2025-09-23/When Big Models Train Small Ones_ Label-Free Model Parity Alignment for Efficient Visual Question Answering using Small VLMs_20250923|When Big Models Train Small Ones: Label-Free Model Parity Alignment for Efficient Visual Question Answering using Small VLMs]] (82.2% similar)
- [[2025-09-23/Open Vision Reasoner_ Transferring Linguistic Cognitive Behavior for Visual Reasoning_20250923|Open Vision Reasoner: Transferring Linguistic Cognitive Behavior for Visual Reasoning]] (82.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Reinforcement Learning|Reinforcement Learning]]
**ğŸ”— Specific Connectable**: [[keywords/Optical Character Recognition|Optical Character Recognition]]
**âš¡ Unique Technical**: [[keywords/Logics-Parsing|Logics-Parsing]], [[keywords/LogicsParsingBench|LogicsParsingBench]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19760v1 Announce Type: new 
Abstract: Recent advances in Large Vision-Language models (LVLM) have spurred significant progress in document parsing task. Compared to traditional pipeline-based methods, end-to-end paradigms have shown their excellence in converting PDF images into structured outputs through integrated Optical Character Recognition (OCR), table recognition, mathematical formula recognition and so on. However, the absence of explicit analytical stages for document layouts and reading orders limits the LVLM's capability in handling complex document types such as multi-column newspapers or posters. To address this limitation, we propose in this report Logics-Parsing: an end-to-end LVLM-based model augmented with reinforcement learning. Our model incorporates meticulously designed reward mechanisms to optimize complex layout analysis and reading order inference. In addition, we expand the model's versatility by incorporating diverse data types such as chemical formulas and handwritten Chinese characters into supervised fine-tuning. Finally, to enable rigorous evaluation of our approach, we introduce LogicsParsingBench, a curated set of 1,078 page-level PDF images spanning nine major categories and over twenty sub-categories, which will be released later. Comprehensive experiments conducted on LogicsParsingBench have validated the efficacy and State-of-the-art (SOTA) performance of our proposed model across diverse document analysis scenarios. Project Page: https://github.com/alibaba/Logics-Parsing

## ğŸ“ ìš”ì•½

ìµœê·¼ ëŒ€í˜• ë¹„ì „-ì–¸ì–´ ëª¨ë¸(LVLM)ì˜ ë°œì „ì€ ë¬¸ì„œ íŒŒì‹± ì‘ì—…ì— í° ì§„ì „ì„ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤. ê¸°ì¡´ì˜ íŒŒì´í”„ë¼ì¸ ê¸°ë°˜ ë°©ë²•ê³¼ ë‹¬ë¦¬, í†µí•©ëœ ê´‘í•™ ë¬¸ì ì¸ì‹(OCR), í‘œ ì¸ì‹, ìˆ˜ì‹ ì¸ì‹ì„ í†µí•´ PDF ì´ë¯¸ì§€ë¥¼ êµ¬ì¡°í™”ëœ ì¶œë ¥ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì¢…ë‹¨ ê°„ íŒ¨ëŸ¬ë‹¤ì„ì´ ìš°ìˆ˜ì„±ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë³µì¡í•œ ë¬¸ì„œ ë ˆì´ì•„ì›ƒê³¼ ì½ê¸° ìˆœì„œë¥¼ ëª…ì‹œì ìœ¼ë¡œ ë¶„ì„í•˜ì§€ ëª»í•´ ë‹¤ì¤‘ ì—´ ì‹ ë¬¸ì´ë‚˜ í¬ìŠ¤í„°ì™€ ê°™ì€ ë³µì¡í•œ ë¬¸ì„œ ìœ í˜•ì„ ì²˜ë¦¬í•˜ëŠ” ë° í•œê³„ê°€ ìˆì—ˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ê°•í™” í•™ìŠµì„ í†µí•´ í–¥ìƒëœ Logics-Parsing ëª¨ë¸ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ë³µì¡í•œ ë ˆì´ì•„ì›ƒ ë¶„ì„ê³¼ ì½ê¸° ìˆœì„œ ì¶”ë¡ ì„ ìµœì í™”í•˜ê¸° ìœ„í•´ ì •êµí•˜ê²Œ ì„¤ê³„ëœ ë³´ìƒ ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•©í•©ë‹ˆë‹¤. ë˜í•œ, í™”í•™ì‹ê³¼ ì†ìœ¼ë¡œ ì“´ í•œìë¥¼ í¬í•¨í•œ ë‹¤ì–‘í•œ ë°ì´í„° ìœ í˜•ì„ ê°ë… í•™ìŠµì— í¬í•¨í•˜ì—¬ ëª¨ë¸ì˜ ë²”ìš©ì„±ì„ í™•ì¥í–ˆìŠµë‹ˆë‹¤. ìš°ë¦¬ì˜ ì ‘ê·¼ ë°©ì‹ì„ ì—„ê²©í•˜ê²Œ í‰ê°€í•˜ê¸° ìœ„í•´, 9ê°œì˜ ì£¼ìš” ì¹´í…Œê³ ë¦¬ì™€ 20ê°œ ì´ìƒì˜ í•˜ìœ„ ì¹´í…Œê³ ë¦¬ë¥¼ í¬í•¨í•˜ëŠ” 1,078ê°œì˜ í˜ì´ì§€ ìˆ˜ì¤€ PDF ì´ë¯¸ì§€ë¡œ êµ¬ì„±ëœ LogicsParsingBenchë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ì´ ë°ì´í„°ì…‹ì„ í†µí•´ ìˆ˜í–‰ëœ ì¢…í•© ì‹¤í—˜ì€ ë‹¤ì–‘í•œ ë¬¸ì„œ ë¶„ì„ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì œì•ˆëœ ëª¨ë¸ì˜ íš¨ëŠ¥ê³¼ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€ê·œëª¨ ë¹„ì „-ì–¸ì–´ ëª¨ë¸(LVLM)ì€ ë¬¸ì„œ íŒŒì‹± ì‘ì—…ì—ì„œ ì¤‘ìš”í•œ ë°œì „ì„ ì´ë£¨ì—ˆë‹¤.
- 2. ê¸°ì¡´ íŒŒì´í”„ë¼ì¸ ê¸°ë°˜ ë°©ë²•ê³¼ ë¹„êµí•˜ì—¬, ì—”ë“œíˆ¬ì—”ë“œ íŒ¨ëŸ¬ë‹¤ì„ì€ PDF ì´ë¯¸ì§€ë¥¼ êµ¬ì¡°í™”ëœ ì¶œë ¥ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ë° ìš°ìˆ˜ì„±ì„ ë³´ì˜€ë‹¤.
- 3. ë³µì¡í•œ ë¬¸ì„œ ë ˆì´ì•„ì›ƒê³¼ ì½ê¸° ìˆœì„œë¥¼ ë¶„ì„í•˜ëŠ” ëª…ì‹œì  ë‹¨ê³„ê°€ ì—†ì–´ LVLMì˜ ë³µì¡í•œ ë¬¸ì„œ ì²˜ë¦¬ ëŠ¥ë ¥ì´ ì œí•œëœë‹¤.
- 4. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ê°•í™” í•™ìŠµì„ í™œìš©í•œ Logics-Parsing ëª¨ë¸ì„ ì œì•ˆí•˜ì—¬ ë³µì¡í•œ ë ˆì´ì•„ì›ƒ ë¶„ì„ê³¼ ì½ê¸° ìˆœì„œ ì¶”ë¡ ì„ ìµœì í™”í–ˆë‹¤.
- 5. LogicsParsingBenchë¼ëŠ” í‰ê°€ ì„¸íŠ¸ë¥¼ ë„ì…í•˜ì—¬ ë‹¤ì–‘í•œ ë¬¸ì„œ ë¶„ì„ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì œì•ˆëœ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ê²€ì¦í–ˆë‹¤.


---

*Generated on 2025-09-26 09:06:15*