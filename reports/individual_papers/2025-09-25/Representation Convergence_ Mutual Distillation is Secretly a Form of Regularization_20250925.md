---
keywords:
  - Mutual Distillation
  - Reinforcement Learning
  - Invariant Representations
  - Generalization
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2501.02481
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T16:18:30.995691",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Mutual Distillation",
    "Reinforcement Learning",
    "Invariant Representations",
    "Generalization"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Mutual Distillation": 0.72,
    "Reinforcement Learning": 0.85,
    "Invariant Representations": 0.8,
    "Generalization": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "mutual distillation",
        "canonical": "Mutual Distillation",
        "aliases": [
          "policy distillation",
          "distillation between policies"
        ],
        "category": "unique_technical",
        "rationale": "Mutual distillation is a novel concept in reinforcement learning that enhances policy robustness, making it a unique technical term with potential for new connections.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.78,
        "link_intent_score": 0.72
      },
      {
        "surface": "reinforcement learning",
        "canonical": "Reinforcement Learning",
        "aliases": [
          "RL"
        ],
        "category": "broad_technical",
        "rationale": "Reinforcement learning is a foundational concept in machine learning, providing strong connectivity across various research topics.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "invariant representations",
        "canonical": "Invariant Representations",
        "aliases": [
          "stable representations",
          "consistent representations"
        ],
        "category": "specific_connectable",
        "rationale": "Invariant representations are crucial for generalization in machine learning, linking to concepts like robustness and feature extraction.",
        "novelty_score": 0.68,
        "connectivity_score": 0.78,
        "specificity_score": 0.82,
        "link_intent_score": 0.8
      },
      {
        "surface": "generalization performance",
        "canonical": "Generalization",
        "aliases": [
          "generalization ability",
          "generalization capacity"
        ],
        "category": "specific_connectable",
        "rationale": "Generalization is a key goal in machine learning, connecting to diverse areas such as model evaluation and transfer learning.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "regularization",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "mutual distillation",
      "resolved_canonical": "Mutual Distillation",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.78,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "reinforcement learning",
      "resolved_canonical": "Reinforcement Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "invariant representations",
      "resolved_canonical": "Invariant Representations",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.78,
        "specificity": 0.82,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "generalization performance",
      "resolved_canonical": "Generalization",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# Representation Convergence: Mutual Distillation is Secretly a Form of Regularization

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2501.02481.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2501.02481](https://arxiv.org/abs/2501.02481)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Rectified Robust Policy Optimization for Model-Uncertain Constrained Reinforcement Learning without Strong Duality_20250923|Rectified Robust Policy Optimization for Model-Uncertain Constrained Reinforcement Learning without Strong Duality]] (83.1% similar)
- [[2025-09-23/Model Guidance via Robust Feature Attribution_20250923|Model Guidance via Robust Feature Attribution]] (82.5% similar)
- [[2025-09-18/Data coarse graining can improve model performance_20250918|Data coarse graining can improve model performance]] (81.8% similar)
- [[2025-09-24/Stability and Generalization of Adversarial Diffusion Training_20250924|Stability and Generalization of Adversarial Diffusion Training]] (81.7% similar)
- [[2025-09-22/Nonconvex Regularization for Feature Selection in Reinforcement Learning_20250922|Nonconvex Regularization for Feature Selection in Reinforcement Learning]] (81.7% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Reinforcement Learning|Reinforcement Learning]]
**ğŸ”— Specific Connectable**: [[keywords/Invariant Representations|Invariant Representations]], [[keywords/Generalization|Generalization]]
**âš¡ Unique Technical**: [[keywords/Mutual Distillation|Mutual Distillation]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2501.02481v5 Announce Type: replace-cross 
Abstract: In this paper, we argue that mutual distillation between reinforcement learning policies serves as an implicit regularization, preventing them from overfitting to irrelevant features. We highlight two separate contributions: (i) Theoretically, for the first time, we prove that enhancing the policy robustness to irrelevant features leads to improved generalization performance. (ii) Empirically, we demonstrate that mutual distillation between policies contributes to such robustness, enabling the spontaneous emergence of invariant representations over pixel inputs. Ultimately, we do not claim to achieve state-of-the-art performance but rather focus on uncovering the underlying principles of generalization and deepening our understanding of its mechanisms.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì—ì„œëŠ” ê°•í™” í•™ìŠµ ì •ì±… ê°„ì˜ ìƒí˜¸ ì¦ë¥˜ê°€ ì•”ë¬µì ì¸ ì •ê·œí™” ì—­í• ì„ í•˜ì—¬ ë¶ˆí•„ìš”í•œ íŠ¹ì§•ì— ëŒ€í•œ ê³¼ì í•©ì„ ë°©ì§€í•œë‹¤ê³  ì£¼ì¥í•©ë‹ˆë‹¤. ì£¼ìš” ê¸°ì—¬ëŠ” ë‘ ê°€ì§€ì…ë‹ˆë‹¤. ì²«ì§¸, ì´ë¡ ì ìœ¼ë¡œ ì •ì±…ì˜ ë¶ˆí•„ìš”í•œ íŠ¹ì§•ì— ëŒ€í•œ ê°•ê±´ì„±ì„ ê°•í™”í•˜ë©´ ì¼ë°˜í™” ì„±ëŠ¥ì´ í–¥ìƒëœë‹¤ëŠ” ê²ƒì„ ì²˜ìŒìœ¼ë¡œ ì¦ëª…í–ˆìŠµë‹ˆë‹¤. ë‘˜ì§¸, ì‹¤í—˜ì ìœ¼ë¡œ ì •ì±… ê°„ ìƒí˜¸ ì¦ë¥˜ê°€ ì´ëŸ¬í•œ ê°•ê±´ì„±ì— ê¸°ì—¬í•˜ì—¬ í”½ì…€ ì…ë ¥ì— ëŒ€í•œ ë¶ˆë³€ í‘œí˜„ì˜ ìë°œì  í˜•ì„±ì„ ê°€ëŠ¥í•˜ê²Œ í•¨ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ì£¼ì¥í•˜ê¸°ë³´ë‹¤ëŠ” ì¼ë°˜í™”ì˜ ê¸°ë³¸ ì›ë¦¬ë¥¼ ë°íˆê³  ê·¸ ë©”ì»¤ë‹ˆì¦˜ì— ëŒ€í•œ ì´í•´ë¥¼ ì‹¬í™”í•˜ëŠ” ë° ì¤‘ì ì„ ë‘¡ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ê°•í™” í•™ìŠµ ì •ì±… ê°„ ìƒí˜¸ ì¦ë¥˜ëŠ” ì•”ë¬µì  ì •ê·œí™”ë¡œ ì‘ìš©í•˜ì—¬ ê´€ë ¨ ì—†ëŠ” íŠ¹ì§•ì— ëŒ€í•œ ê³¼ì í•©ì„ ë°©ì§€í•œë‹¤.
- 2. ì •ì±…ì˜ ê´€ë ¨ ì—†ëŠ” íŠ¹ì§•ì— ëŒ€í•œ ê°•ê±´ì„±ì„ í–¥ìƒì‹œí‚¤ë©´ ì¼ë°˜í™” ì„±ëŠ¥ì´ ê°œì„ ëœë‹¤ëŠ” ê²ƒì„ ì´ë¡ ì ìœ¼ë¡œ ì²˜ìŒìœ¼ë¡œ ì¦ëª…í•˜ì˜€ë‹¤.
- 3. ì •ì±… ê°„ ìƒí˜¸ ì¦ë¥˜ê°€ í”½ì…€ ì…ë ¥ì— ëŒ€í•œ ë¶ˆë³€ í‘œí˜„ì˜ ìë°œì  ì¶œí˜„ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ì—¬ ê°•ê±´ì„±ì— ê¸°ì—¬í•¨ì„ ì‹¤ì¦ì ìœ¼ë¡œ ë³´ì—¬ì£¼ì—ˆë‹¤.
- 4. ë³¸ ì—°êµ¬ëŠ” ìµœì²¨ë‹¨ ì„±ëŠ¥ ë‹¬ì„±ì„ ëª©í‘œë¡œ í•˜ê¸°ë³´ë‹¤ëŠ” ì¼ë°˜í™”ì˜ ê¸°ë³¸ ì›ë¦¬ë¥¼ ë°íˆê³  ê·¸ ë©”ì»¤ë‹ˆì¦˜ì— ëŒ€í•œ ì´í•´ë¥¼ ì‹¬í™”í•˜ëŠ” ë° ì¤‘ì ì„ ë‘”ë‹¤.


---

*Generated on 2025-09-25 16:18:30*