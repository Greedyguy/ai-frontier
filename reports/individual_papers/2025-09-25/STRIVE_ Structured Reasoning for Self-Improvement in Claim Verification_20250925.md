---
keywords:
  - Claim Verification
  - Self-supervised Learning
  - Reasoning Chains
  - Claim Decomposition
  - Evidence Grounding
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2502.11959
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T16:09:48.413236",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Claim Verification",
    "Self-supervised Learning",
    "Reasoning Chains",
    "Claim Decomposition",
    "Evidence Grounding"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Claim Verification": 0.85,
    "Self-supervised Learning": 0.8,
    "Reasoning Chains": 0.78,
    "Claim Decomposition": 0.77,
    "Evidence Grounding": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Claim Verification",
        "canonical": "Claim Verification",
        "aliases": [
          "Fact Checking",
          "Claim Validation"
        ],
        "category": "unique_technical",
        "rationale": "Central to the paper's focus, linking to related verification methods.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.85
      },
      {
        "surface": "Self-Improvement",
        "canonical": "Self-supervised Learning",
        "aliases": [
          "Self-Enhancement",
          "Self-Optimization"
        ],
        "category": "specific_connectable",
        "rationale": "Aligns with self-supervised learning techniques, enhancing connectivity.",
        "novelty_score": 0.5,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Reasoning Chains",
        "canonical": "Reasoning Chains",
        "aliases": [
          "Logical Sequences",
          "Inference Chains"
        ],
        "category": "unique_technical",
        "rationale": "Key concept for structured reasoning, enabling links to logical frameworks.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.75,
        "link_intent_score": 0.78
      },
      {
        "surface": "Claim Decomposition",
        "canonical": "Claim Decomposition",
        "aliases": [
          "Claim Breakdown",
          "Claim Analysis"
        ],
        "category": "unique_technical",
        "rationale": "Specific technique introduced in the paper, useful for linking to decomposition methods.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      },
      {
        "surface": "Evidence Grounding",
        "canonical": "Evidence Grounding",
        "aliases": [
          "Evidence Anchoring",
          "Evidence Verification"
        ],
        "category": "unique_technical",
        "rationale": "Essential for linking to evidence-based reasoning approaches.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.8,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "experiment"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Claim Verification",
      "resolved_canonical": "Claim Verification",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Self-Improvement",
      "resolved_canonical": "Self-supervised Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Reasoning Chains",
      "resolved_canonical": "Reasoning Chains",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.75,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Claim Decomposition",
      "resolved_canonical": "Claim Decomposition",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Evidence Grounding",
      "resolved_canonical": "Evidence Grounding",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.8,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# STRIVE: Structured Reasoning for Self-Improvement in Claim Verification

## 📋 메타데이터

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2502.11959.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2502.11959](https://arxiv.org/abs/2502.11959)

## 🔗 유사한 논문
- [[2025-09-25/Calibrated Reasoning_ An Explanatory Verifier for Dynamic and Efficient Problem-Solving_20250925|Calibrated Reasoning: An Explanatory Verifier for Dynamic and Efficient Problem-Solving]] (84.5% similar)
- [[2025-09-22/FLARE_ Faithful Logic-Aided Reasoning and Exploration_20250922|FLARE: Faithful Logic-Aided Reasoning and Exploration]] (82.0% similar)
- [[2025-09-22/ConCISE_ Confidence-guided Compression in Step-by-step Efficient Reasoning_20250922|ConCISE: Confidence-guided Compression in Step-by-step Efficient Reasoning]] (81.6% similar)
- [[2025-09-24/Unveiling Chain of Step Reasoning for Vision-Language Models with Fine-grained Rewards_20250924|Unveiling Chain of Step Reasoning for Vision-Language Models with Fine-grained Rewards]] (81.4% similar)
- [[2025-09-23/Step Guided Reasoning_ Improving Mathematical Reasoning using Guidance Generation and Step Reasoning_20250923|Step Guided Reasoning: Improving Mathematical Reasoning using Guidance Generation and Step Reasoning]] (80.8% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Self-supervised Learning|Self-supervised Learning]]
**⚡ Unique Technical**: [[keywords/Claim Verification|Claim Verification]], [[keywords/Reasoning Chains|Reasoning Chains]], [[keywords/Claim Decomposition|Claim Decomposition]], [[keywords/Evidence Grounding|Evidence Grounding]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2502.11959v2 Announce Type: replace 
Abstract: Claim verification is the task of determining whether a claim is supported or refuted by evidence. Self-improvement methods, where reasoning chains are generated and those leading to correct results are selected for training, have succeeded in tasks like mathematical problem solving. However, in claim verification, this approach struggles. Low-quality reasoning chains may falsely match binary truth labels, introducing faulty reasoning into the self-improvement process and ultimately degrading performance. To address this, we propose STRIVE: Structured Reasoning for Self-Improved Verification. Our method introduces a structured reasoning design with Claim Decomposition, Entity Analysis, and Evidence Grounding Verification. These components improve reasoning quality, reduce errors, and provide additional supervision signals for self-improvement. STRIVE begins with a warm-up phase, where the base model is fine-tuned on a small number of annotated examples to learn the structured reasoning design. It is then applied to generate reasoning chains for all training examples, selecting only those that are correct and structurally sound for subsequent self-improvement training. We demonstrate that STRIVE achieves significant improvements over baseline models, with a 31.4% performance gain over the base model and 20.7% over Chain of Thought on the HOVER datasets, highlighting its effectiveness.

## 📝 요약

논문은 주장의 진위 여부를 검증하는 작업에서 기존의 자기 개선 방법이 겪는 문제를 해결하기 위해 STRIVE라는 새로운 방법을 제안합니다. 기존 방법은 잘못된 추론이 자기 개선 과정에 포함되어 성능 저하를 초래할 수 있었습니다. STRIVE는 주장의 분해, 엔티티 분석, 증거 기반 검증을 포함한 구조화된 추론 설계를 도입하여 추론의 질을 향상시키고 오류를 줄입니다. 초기에는 소수의 주석이 달린 예제로 모델을 미세 조정한 후, 모든 훈련 예제에 대해 올바르고 구조적으로 타당한 추론 체인을 선택하여 자기 개선 훈련에 사용합니다. 실험 결과, STRIVE는 HOVER 데이터셋에서 기본 모델 대비 31.4%, 기존 방법인 Chain of Thought 대비 20.7%의 성능 향상을 보여 그 효과를 입증했습니다.

## 🎯 주요 포인트

- 1. STRIVE는 주장의 검증을 위해 구조화된 추론 설계를 도입하여 추론의 질을 향상시키고 오류를 줄입니다.
- 2. Claim Decomposition, Entity Analysis, Evidence Grounding Verification을 통해 추가적인 감독 신호를 제공합니다.
- 3. STRIVE는 소수의 주석이 달린 예제로 모델을 미세 조정하는 워밍업 단계를 거쳐, 모든 훈련 예제에 대한 추론 체인을 생성합니다.
- 4. STRIVE는 HOVER 데이터셋에서 기본 모델 대비 31.4%, Chain of Thought 대비 20.7%의 성능 향상을 보여줍니다.
- 5. 잘못된 추론 체인이 이진 진리 레이블과 잘못 일치하는 문제를 해결하기 위해, STRIVE는 올바르고 구조적으로 건전한 추론 체인만을 선택하여 자기 개선 훈련에 사용합니다.


---

*Generated on 2025-09-25 16:09:48*