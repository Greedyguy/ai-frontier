---
keywords:
  - Agentic AI
  - Medical Imaging Analysis
  - Vision-Language Model
  - Spatial Omics
  - Active Learning
category: cs.CV
publish_date: 2025-09-25
arxiv_id: 2509.20279
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-26T09:15:23.074633",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Agentic AI",
    "Medical Imaging Analysis",
    "Vision-Language Model",
    "Spatial Omics",
    "Active Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Agentic AI": 0.78,
    "Medical Imaging Analysis": 0.82,
    "Vision-Language Model": 0.8,
    "Spatial Omics": 0.77,
    "Active Learning": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Agentic AI",
        "canonical": "Agentic AI",
        "aliases": [
          "Autonomous AI",
          "Self-directed AI"
        ],
        "category": "unique_technical",
        "rationale": "Agentic AI represents a novel approach in AI systems that autonomously plan and execute tasks, crucial for linking advancements in AI autonomy.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.82,
        "link_intent_score": 0.78
      },
      {
        "surface": "Medical Imaging Analysis",
        "canonical": "Medical Imaging Analysis",
        "aliases": [
          "Medical Image Processing",
          "Radiological Analysis"
        ],
        "category": "specific_connectable",
        "rationale": "This term connects various AI applications in healthcare, particularly linking to imaging techniques and analysis.",
        "novelty_score": 0.55,
        "connectivity_score": 0.87,
        "specificity_score": 0.79,
        "link_intent_score": 0.82
      },
      {
        "surface": "Vision-Language Models",
        "canonical": "Vision-Language Model",
        "aliases": [
          "VLM",
          "Vision-Language AI"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-Language Models are a key area of AI research, linking visual and textual data processing, crucial for cross-modal applications.",
        "novelty_score": 0.6,
        "connectivity_score": 0.85,
        "specificity_score": 0.78,
        "link_intent_score": 0.8
      },
      {
        "surface": "Spatial Omics",
        "canonical": "Spatial Omics",
        "aliases": [
          "Spatial Transcriptomics",
          "Spatial Genomics"
        ],
        "category": "unique_technical",
        "rationale": "Spatial Omics is a cutting-edge field that enhances understanding of spatial cellular contexts, linking genomics and spatial data analysis.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      },
      {
        "surface": "Active Learning",
        "canonical": "Active Learning",
        "aliases": [
          "Interactive Learning",
          "Human-in-the-loop Learning"
        ],
        "category": "specific_connectable",
        "rationale": "Active Learning is vital for improving AI models with minimal data, linking to adaptive learning strategies.",
        "novelty_score": 0.58,
        "connectivity_score": 0.83,
        "specificity_score": 0.76,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "Real-time Analysis",
      "Tool Factories"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Agentic AI",
      "resolved_canonical": "Agentic AI",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.82,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Medical Imaging Analysis",
      "resolved_canonical": "Medical Imaging Analysis",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.87,
        "specificity": 0.79,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Vision-Language Models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.85,
        "specificity": 0.78,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Spatial Omics",
      "resolved_canonical": "Spatial Omics",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Active Learning",
      "resolved_canonical": "Active Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.83,
        "specificity": 0.76,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# A co-evolving agentic AI system for medical imaging analysis

## 📋 메타데이터

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.20279.pdf)
**Category**: cs.CV
**Published**: 2025-09-25
**ArXiv ID**: [2509.20279](https://arxiv.org/abs/2509.20279)

## 🔗 유사한 논문
- [[2025-09-19/OpenLens AI_ Fully Autonomous Research Agent for Health Infomatics_20250919|OpenLens AI: Fully Autonomous Research Agent for Health Infomatics]] (85.1% similar)
- [[2025-09-23/The SAGES Critical View of Safety Challenge_ A Global Benchmark for AI-Assisted Surgical Quality Assessment_20250923|The SAGES Critical View of Safety Challenge: A Global Benchmark for AI-Assisted Surgical Quality Assessment]] (82.3% similar)
- [[2025-09-23/Medical AI Consensus_ A Multi-Agent Framework for Radiology Report Generation and Evaluation_20250923|Medical AI Consensus: A Multi-Agent Framework for Radiology Report Generation and Evaluation]] (82.3% similar)
- [[2025-09-22/Data-Efficient Learning for Generalizable Surgical Video Understanding_20250922|Data-Efficient Learning for Generalizable Surgical Video Understanding]] (82.3% similar)
- [[2025-09-23/Towards a Transparent and Interpretable AI Model for Medical Image Classifications_20250923|Towards a Transparent and Interpretable AI Model for Medical Image Classifications]] (82.1% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Medical Imaging Analysis|Medical Imaging Analysis]], [[keywords/Active Learning|Active Learning]]
**⚡ Unique Technical**: [[keywords/Agentic AI|Agentic AI]], [[keywords/Spatial Omics|Spatial Omics]]
**🚀 Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.20279v1 Announce Type: new 
Abstract: Agentic AI is rapidly advancing in healthcare and biomedical research. However, in medical image analysis, their performance and adoption remain limited due to the lack of a robust ecosystem, insufficient toolsets, and the absence of real-time interactive expert feedback. Here we present "TissueLab", a co-evolving agentic AI system that allows researchers to ask direct questions, automatically plan and generate explainable workflows, and conduct real-time analyses where experts can visualize intermediate results and refine them. TissueLab integrates tool factories across pathology, radiology, and spatial omics domains. By standardizing inputs, outputs, and capabilities of diverse tools, the system determines when and how to invoke them to address research and clinical questions. Across diverse tasks with clinically meaningful quantifications that inform staging, prognosis, and treatment planning, TissueLab achieves state-of-the-art performance compared with end-to-end vision-language models (VLMs) and other agentic AI systems such as GPT-5. Moreover, TissueLab continuously learns from clinicians, evolving toward improved classifiers and more effective decision strategies. With active learning, it delivers accurate results in unseen disease contexts within minutes, without requiring massive datasets or prolonged retraining. Released as a sustainable open-source ecosystem, TissueLab aims to accelerate computational research and translational adoption in medical imaging while establishing a foundation for the next generation of medical AI.

## 📝 요약

"TissueLab"는 의료 영상 분석에서 에이전트 AI의 성능과 채택을 개선하기 위해 개발된 시스템입니다. 이 시스템은 연구자들이 직접 질문을 하고, 설명 가능한 워크플로를 자동으로 계획 및 생성하며, 전문가가 중간 결과를 시각화하고 수정할 수 있는 실시간 분석을 제공합니다. 병리학, 방사선학, 공간 오믹스 분야의 도구를 통합하여 다양한 연구 및 임상 질문에 대응할 수 있도록 표준화된 입력, 출력, 기능을 제공합니다. TissueLab은 다양한 임상적 의미를 가진 작업에서 최첨단 성능을 달성하며, 지속적인 학습을 통해 더 나은 분류기와 효과적인 의사 결정 전략으로 발전합니다. 또한, 대규모 데이터셋이나 긴 재훈련 없이도 새로운 질병 상황에서 정확한 결과를 빠르게 제공합니다. 이 시스템은 오픈 소스로 제공되어 의료 영상 분야의 연구와 실용적 채택을 가속화하는 것을 목표로 합니다.

## 🎯 주요 포인트

- 1. TissueLab는 연구자들이 직접 질문을 하고, 설명 가능한 워크플로우를 자동으로 계획 및 생성하며, 실시간 분석을 수행할 수 있도록 지원하는 에이전틱 AI 시스템입니다.
- 2. 이 시스템은 병리학, 방사선학, 공간 오믹스 도메인 전반에 걸쳐 도구 공장을 통합하여 다양한 도구의 입력, 출력 및 기능을 표준화합니다.
- 3. TissueLab는 임상적으로 의미 있는 정량화 작업에서 최첨단 성능을 달성하며, GPT-5와 같은 다른 에이전틱 AI 시스템과 비교하여 우수한 성능을 보입니다.
- 4. 이 시스템은 임상 전문가로부터 지속적으로 학습하여 더 나은 분류기와 효과적인 의사 결정 전략으로 발전합니다.
- 5. TissueLab는 지속 가능한 오픈 소스 생태계로 출시되어 의료 영상 분야에서의 계산 연구와 번역적 채택을 가속화하는 것을 목표로 합니다.


---

*Generated on 2025-09-26 09:15:23*