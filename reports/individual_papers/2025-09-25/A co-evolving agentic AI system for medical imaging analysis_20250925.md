---
keywords:
  - Agentic AI
  - Medical Imaging Analysis
  - Vision-Language Model
  - Spatial Omics
  - Active Learning
category: cs.CV
publish_date: 2025-09-25
arxiv_id: 2509.20279
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-26T09:15:23.074633",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Agentic AI",
    "Medical Imaging Analysis",
    "Vision-Language Model",
    "Spatial Omics",
    "Active Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Agentic AI": 0.78,
    "Medical Imaging Analysis": 0.82,
    "Vision-Language Model": 0.8,
    "Spatial Omics": 0.77,
    "Active Learning": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Agentic AI",
        "canonical": "Agentic AI",
        "aliases": [
          "Autonomous AI",
          "Self-directed AI"
        ],
        "category": "unique_technical",
        "rationale": "Agentic AI represents a novel approach in AI systems that autonomously plan and execute tasks, crucial for linking advancements in AI autonomy.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.82,
        "link_intent_score": 0.78
      },
      {
        "surface": "Medical Imaging Analysis",
        "canonical": "Medical Imaging Analysis",
        "aliases": [
          "Medical Image Processing",
          "Radiological Analysis"
        ],
        "category": "specific_connectable",
        "rationale": "This term connects various AI applications in healthcare, particularly linking to imaging techniques and analysis.",
        "novelty_score": 0.55,
        "connectivity_score": 0.87,
        "specificity_score": 0.79,
        "link_intent_score": 0.82
      },
      {
        "surface": "Vision-Language Models",
        "canonical": "Vision-Language Model",
        "aliases": [
          "VLM",
          "Vision-Language AI"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-Language Models are a key area of AI research, linking visual and textual data processing, crucial for cross-modal applications.",
        "novelty_score": 0.6,
        "connectivity_score": 0.85,
        "specificity_score": 0.78,
        "link_intent_score": 0.8
      },
      {
        "surface": "Spatial Omics",
        "canonical": "Spatial Omics",
        "aliases": [
          "Spatial Transcriptomics",
          "Spatial Genomics"
        ],
        "category": "unique_technical",
        "rationale": "Spatial Omics is a cutting-edge field that enhances understanding of spatial cellular contexts, linking genomics and spatial data analysis.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      },
      {
        "surface": "Active Learning",
        "canonical": "Active Learning",
        "aliases": [
          "Interactive Learning",
          "Human-in-the-loop Learning"
        ],
        "category": "specific_connectable",
        "rationale": "Active Learning is vital for improving AI models with minimal data, linking to adaptive learning strategies.",
        "novelty_score": 0.58,
        "connectivity_score": 0.83,
        "specificity_score": 0.76,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "Real-time Analysis",
      "Tool Factories"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Agentic AI",
      "resolved_canonical": "Agentic AI",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.82,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Medical Imaging Analysis",
      "resolved_canonical": "Medical Imaging Analysis",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.87,
        "specificity": 0.79,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Vision-Language Models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.85,
        "specificity": 0.78,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Spatial Omics",
      "resolved_canonical": "Spatial Omics",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Active Learning",
      "resolved_canonical": "Active Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.83,
        "specificity": 0.76,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# A co-evolving agentic AI system for medical imaging analysis

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.20279.pdf)
**Category**: cs.CV
**Published**: 2025-09-25
**ArXiv ID**: [2509.20279](https://arxiv.org/abs/2509.20279)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/OpenLens AI_ Fully Autonomous Research Agent for Health Infomatics_20250919|OpenLens AI: Fully Autonomous Research Agent for Health Infomatics]] (85.1% similar)
- [[2025-09-23/The SAGES Critical View of Safety Challenge_ A Global Benchmark for AI-Assisted Surgical Quality Assessment_20250923|The SAGES Critical View of Safety Challenge: A Global Benchmark for AI-Assisted Surgical Quality Assessment]] (82.3% similar)
- [[2025-09-23/Medical AI Consensus_ A Multi-Agent Framework for Radiology Report Generation and Evaluation_20250923|Medical AI Consensus: A Multi-Agent Framework for Radiology Report Generation and Evaluation]] (82.3% similar)
- [[2025-09-22/Data-Efficient Learning for Generalizable Surgical Video Understanding_20250922|Data-Efficient Learning for Generalizable Surgical Video Understanding]] (82.3% similar)
- [[2025-09-23/Towards a Transparent and Interpretable AI Model for Medical Image Classifications_20250923|Towards a Transparent and Interpretable AI Model for Medical Image Classifications]] (82.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Medical Imaging Analysis|Medical Imaging Analysis]], [[keywords/Active Learning|Active Learning]]
**âš¡ Unique Technical**: [[keywords/Agentic AI|Agentic AI]], [[keywords/Spatial Omics|Spatial Omics]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.20279v1 Announce Type: new 
Abstract: Agentic AI is rapidly advancing in healthcare and biomedical research. However, in medical image analysis, their performance and adoption remain limited due to the lack of a robust ecosystem, insufficient toolsets, and the absence of real-time interactive expert feedback. Here we present "TissueLab", a co-evolving agentic AI system that allows researchers to ask direct questions, automatically plan and generate explainable workflows, and conduct real-time analyses where experts can visualize intermediate results and refine them. TissueLab integrates tool factories across pathology, radiology, and spatial omics domains. By standardizing inputs, outputs, and capabilities of diverse tools, the system determines when and how to invoke them to address research and clinical questions. Across diverse tasks with clinically meaningful quantifications that inform staging, prognosis, and treatment planning, TissueLab achieves state-of-the-art performance compared with end-to-end vision-language models (VLMs) and other agentic AI systems such as GPT-5. Moreover, TissueLab continuously learns from clinicians, evolving toward improved classifiers and more effective decision strategies. With active learning, it delivers accurate results in unseen disease contexts within minutes, without requiring massive datasets or prolonged retraining. Released as a sustainable open-source ecosystem, TissueLab aims to accelerate computational research and translational adoption in medical imaging while establishing a foundation for the next generation of medical AI.

## ğŸ“ ìš”ì•½

"TissueLab"ëŠ” ì˜ë£Œ ì˜ìƒ ë¶„ì„ì—ì„œ ì—ì´ì „íŠ¸ AIì˜ ì„±ëŠ¥ê³¼ ì±„íƒì„ ê°œì„ í•˜ê¸° ìœ„í•´ ê°œë°œëœ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œì€ ì—°êµ¬ìë“¤ì´ ì§ì ‘ ì§ˆë¬¸ì„ í•˜ê³ , ì„¤ëª… ê°€ëŠ¥í•œ ì›Œí¬í”Œë¡œë¥¼ ìë™ìœ¼ë¡œ ê³„íš ë° ìƒì„±í•˜ë©°, ì „ë¬¸ê°€ê°€ ì¤‘ê°„ ê²°ê³¼ë¥¼ ì‹œê°í™”í•˜ê³  ìˆ˜ì •í•  ìˆ˜ ìˆëŠ” ì‹¤ì‹œê°„ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤. ë³‘ë¦¬í•™, ë°©ì‚¬ì„ í•™, ê³µê°„ ì˜¤ë¯¹ìŠ¤ ë¶„ì•¼ì˜ ë„êµ¬ë¥¼ í†µí•©í•˜ì—¬ ë‹¤ì–‘í•œ ì—°êµ¬ ë° ì„ìƒ ì§ˆë¬¸ì— ëŒ€ì‘í•  ìˆ˜ ìˆë„ë¡ í‘œì¤€í™”ëœ ì…ë ¥, ì¶œë ¥, ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. TissueLabì€ ë‹¤ì–‘í•œ ì„ìƒì  ì˜ë¯¸ë¥¼ ê°€ì§„ ì‘ì—…ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ë©°, ì§€ì†ì ì¸ í•™ìŠµì„ í†µí•´ ë” ë‚˜ì€ ë¶„ë¥˜ê¸°ì™€ íš¨ê³¼ì ì¸ ì˜ì‚¬ ê²°ì • ì „ëµìœ¼ë¡œ ë°œì „í•©ë‹ˆë‹¤. ë˜í•œ, ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì´ë‚˜ ê¸´ ì¬í›ˆë ¨ ì—†ì´ë„ ìƒˆë¡œìš´ ì§ˆë³‘ ìƒí™©ì—ì„œ ì •í™•í•œ ê²°ê³¼ë¥¼ ë¹ ë¥´ê²Œ ì œê³µí•©ë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œì€ ì˜¤í”ˆ ì†ŒìŠ¤ë¡œ ì œê³µë˜ì–´ ì˜ë£Œ ì˜ìƒ ë¶„ì•¼ì˜ ì—°êµ¬ì™€ ì‹¤ìš©ì  ì±„íƒì„ ê°€ì†í™”í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. TissueLabëŠ” ì—°êµ¬ìë“¤ì´ ì§ì ‘ ì§ˆë¬¸ì„ í•˜ê³ , ì„¤ëª… ê°€ëŠ¥í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ìë™ìœ¼ë¡œ ê³„íš ë° ìƒì„±í•˜ë©°, ì‹¤ì‹œê°„ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•˜ëŠ” ì—ì´ì „í‹± AI ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
- 2. ì´ ì‹œìŠ¤í…œì€ ë³‘ë¦¬í•™, ë°©ì‚¬ì„ í•™, ê³µê°„ ì˜¤ë¯¹ìŠ¤ ë„ë©”ì¸ ì „ë°˜ì— ê±¸ì³ ë„êµ¬ ê³µì¥ì„ í†µí•©í•˜ì—¬ ë‹¤ì–‘í•œ ë„êµ¬ì˜ ì…ë ¥, ì¶œë ¥ ë° ê¸°ëŠ¥ì„ í‘œì¤€í™”í•©ë‹ˆë‹¤.
- 3. TissueLabëŠ” ì„ìƒì ìœ¼ë¡œ ì˜ë¯¸ ìˆëŠ” ì •ëŸ‰í™” ì‘ì—…ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ë©°, GPT-5ì™€ ê°™ì€ ë‹¤ë¥¸ ì—ì´ì „í‹± AI ì‹œìŠ¤í…œê³¼ ë¹„êµí•˜ì—¬ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.
- 4. ì´ ì‹œìŠ¤í…œì€ ì„ìƒ ì „ë¬¸ê°€ë¡œë¶€í„° ì§€ì†ì ìœ¼ë¡œ í•™ìŠµí•˜ì—¬ ë” ë‚˜ì€ ë¶„ë¥˜ê¸°ì™€ íš¨ê³¼ì ì¸ ì˜ì‚¬ ê²°ì • ì „ëµìœ¼ë¡œ ë°œì „í•©ë‹ˆë‹¤.
- 5. TissueLabëŠ” ì§€ì† ê°€ëŠ¥í•œ ì˜¤í”ˆ ì†ŒìŠ¤ ìƒíƒœê³„ë¡œ ì¶œì‹œë˜ì–´ ì˜ë£Œ ì˜ìƒ ë¶„ì•¼ì—ì„œì˜ ê³„ì‚° ì—°êµ¬ì™€ ë²ˆì—­ì  ì±„íƒì„ ê°€ì†í™”í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-26 09:15:23*