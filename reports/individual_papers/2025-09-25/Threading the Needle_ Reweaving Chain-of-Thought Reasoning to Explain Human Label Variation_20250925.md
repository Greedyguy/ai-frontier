---
keywords:
  - Large Language Model
  - Chain-of-Thought Reasoning
  - Human Label Variation
  - Discourse Segmenters
category: cs.CL
publish_date: 2025-09-25
arxiv_id: 2505.23368
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-26T08:55:17.580320",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Chain-of-Thought Reasoning",
    "Human Label Variation",
    "Discourse Segmenters"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Chain-of-Thought Reasoning": 0.8,
    "Human Label Variation": 0.78,
    "Discourse Segmenters": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Language Models"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's discussion on reasoning and label variation, linking to broader NLP concepts.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Chain-of-Thought Reasoning",
        "canonical": "Chain-of-Thought Reasoning",
        "aliases": [
          "CoT Reasoning",
          "Reasoning Chains"
        ],
        "category": "unique_technical",
        "rationale": "A novel reasoning approach that underpins the methodology discussed in the paper.",
        "novelty_score": 0.75,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.8
      },
      {
        "surface": "Human Label Variation",
        "canonical": "Human Label Variation",
        "aliases": [
          "Label Variation",
          "HLV"
        ],
        "category": "unique_technical",
        "rationale": "Key concept for understanding the variability in human annotations, central to the paper's evaluation framework.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.75,
        "link_intent_score": 0.78
      },
      {
        "surface": "Discourse Segmenters",
        "canonical": "Discourse Segmenters",
        "aliases": [
          "Linguistic Segmenters"
        ],
        "category": "specific_connectable",
        "rationale": "Important for extracting reasoning components, linking to linguistic processing techniques.",
        "novelty_score": 0.65,
        "connectivity_score": 0.68,
        "specificity_score": 0.72,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "method",
      "framework",
      "dataset"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Chain-of-Thought Reasoning",
      "resolved_canonical": "Chain-of-Thought Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Human Label Variation",
      "resolved_canonical": "Human Label Variation",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.75,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Discourse Segmenters",
      "resolved_canonical": "Discourse Segmenters",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.68,
        "specificity": 0.72,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Threading the Needle: Reweaving Chain-of-Thought Reasoning to Explain Human Label Variation

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2505.23368.pdf)
**Category**: cs.CL
**Published**: 2025-09-25
**ArXiv ID**: [2505.23368](https://arxiv.org/abs/2505.23368)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates_20250923|Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates]] (87.4% similar)
- [[2025-09-23/Does Reasoning Introduce Bias? A Study of Social Bias Evaluation and Mitigation in LLM Reasoning_20250923|Does Reasoning Introduce Bias? A Study of Social Bias Evaluation and Mitigation in LLM Reasoning]] (87.0% similar)
- [[2025-09-25/HoT_ Highlighted Chain of Thought for Referencing Supporting Facts from Inputs_20250925|HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs]] (86.4% similar)
- [[2025-09-24/LiTEx_ A Linguistic Taxonomy of Explanations for Understanding Within-Label Variation in Natural Language Inference_20250924|LiTEx: A Linguistic Taxonomy of Explanations for Understanding Within-Label Variation in Natural Language Inference]] (86.0% similar)
- [[2025-09-24/Please Translate Again_ Two Simple Experiments on Whether Human-Like Reasoning Helps Translation_20250924|Please Translate Again: Two Simple Experiments on Whether Human-Like Reasoning Helps Translation]] (85.9% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Discourse Segmenters|Discourse Segmenters]]
**âš¡ Unique Technical**: [[keywords/Chain-of-Thought Reasoning|Chain-of-Thought Reasoning]], [[keywords/Human Label Variation|Human Label Variation]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2505.23368v3 Announce Type: replace 
Abstract: The recent rise of reasoning-tuned Large Language Models (LLMs)--which generate chains of thought (CoTs) before giving the final answer--has attracted significant attention and offers new opportunities for gaining insights into human label variation, which refers to plausible differences in how multiple annotators label the same data instance. Prior work has shown that LLM-generated explanations can help align model predictions with human label distributions, but typically adopt a reverse paradigm: producing explanations based on given answers. In contrast, CoTs provide a forward reasoning path that may implicitly embed rationales for each answer option, before generating the answers. We thus propose a novel LLM-based pipeline enriched with linguistically-grounded discourse segmenters to extract supporting and opposing statements for each answer option from CoTs with improved accuracy. We also propose a rank-based HLV evaluation framework that prioritizes the ranking of answers over exact scores, which instead favor direct comparison of label distributions. Our method outperforms a direct generation method as well as baselines on three datasets, and shows better alignment of ranking methods with humans, highlighting the effectiveness of our approach.

## ğŸ“ ìš”ì•½

ìµœê·¼ ë…¼ë¦¬ ì¡°ì •ëœ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì´ ì£¼ëª©ë°›ê³  ìˆìœ¼ë©°, ì´ëŠ” ìµœì¢… ë‹µë³€ì„ ì œì‹œí•˜ê¸° ì „ì— ì‚¬ê³ ì˜ íë¦„(CoTs)ì„ ìƒì„±í•˜ì—¬ ì¸ê°„ì˜ ë¼ë²¨ ë³€ì´ë¥¼ ì´í•´í•˜ëŠ” ë° ìƒˆë¡œìš´ ê¸°íšŒë¥¼ ì œê³µí•©ë‹ˆë‹¤. ê¸°ì¡´ ì—°êµ¬ëŠ” LLMì´ ìƒì„±í•œ ì„¤ëª…ì´ ëª¨ë¸ ì˜ˆì¸¡ì„ ì¸ê°„ ë¼ë²¨ ë¶„í¬ì™€ ë§ì¶”ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì£¼ì—ˆì§€ë§Œ, ì¼ë°˜ì ìœ¼ë¡œ ì£¼ì–´ì§„ ë‹µë³€ì„ ê¸°ë°˜ìœ¼ë¡œ ì„¤ëª…ì„ ìƒì„±í•˜ëŠ” ì—­ë°©í–¥ ì ‘ê·¼ ë°©ì‹ì„ ì±„íƒí–ˆìŠµë‹ˆë‹¤. ì´ì— ë°˜í•´ CoTsëŠ” ê° ë‹µë³€ ì˜µì…˜ì— ëŒ€í•œ ì´ìœ ë¥¼ ì•”ë¬µì ìœ¼ë¡œ í¬í•¨í•  ìˆ˜ ìˆëŠ” ìˆœë°©í–¥ ì¶”ë¡  ê²½ë¡œë¥¼ ì œê³µí•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” CoTsì—ì„œ ê° ë‹µë³€ ì˜µì…˜ì— ëŒ€í•œ ì§€ì§€ ë° ë°˜ëŒ€ ì§„ìˆ ì„ ì¶”ì¶œí•˜ê¸° ìœ„í•´ ì–¸ì–´ì ìœ¼ë¡œ ê¸°ë°˜ì„ ë‘” ë‹´í™” ë¶„í• ê¸°ë¥¼ í™œìš©í•œ ìƒˆë¡œìš´ LLM ê¸°ë°˜ íŒŒì´í”„ë¼ì¸ì„ ì œì•ˆí•©ë‹ˆë‹¤. ë˜í•œ, ë‹µë³€ì˜ ìˆœìœ„ë¥¼ ìš°ì„ ì‹œí•˜ëŠ” ìˆœìœ„ ê¸°ë°˜ HLV í‰ê°€ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•˜ì—¬ ë¼ë²¨ ë¶„í¬ì˜ ì§ì ‘ ë¹„êµë¥¼ ì„ í˜¸í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ë°©ë²•ì€ ì„¸ ê°€ì§€ ë°ì´í„°ì…‹ì—ì„œ ì§ì ‘ ìƒì„± ë°©ë²• ë° ê¸°ì¤€ì„ ì„ ëŠ¥ê°€í•˜ë©°, ì¸ê°„ê³¼ì˜ ìˆœìœ„ ë°©ë²• ì •ë ¬ì—ì„œ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ìµœê·¼ì˜ ì¶”ë¡  ì¡°ì • ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ ë‹µë³€ì„ ìƒì„±í•˜ê¸° ì „ì— ì‚¬ê³ ì˜ ì—°ì‡„(CoTs)ë¥¼ ìƒì„±í•˜ì—¬ ì¸ê°„ì˜ ë ˆì´ë¸” ë³€ë™ì— ëŒ€í•œ í†µì°°ë ¥ì„ ì œê³µí•œë‹¤.
- 2. CoTsëŠ” ê° ë‹µë³€ ì˜µì…˜ì— ëŒ€í•œ ê·¼ê±°ë¥¼ ì•”ë¬µì ìœ¼ë¡œ í¬í•¨í•  ìˆ˜ ìˆëŠ” ìˆœë°©í–¥ ì¶”ë¡  ê²½ë¡œë¥¼ ì œê³µí•œë‹¤.
- 3. ìš°ë¦¬ëŠ” CoTsì—ì„œ ê° ë‹µë³€ ì˜µì…˜ì— ëŒ€í•œ ì§€ì§€ ë° ë°˜ëŒ€ ì§„ìˆ ì„ ì¶”ì¶œí•˜ê¸° ìœ„í•´ ì–¸ì–´ì ìœ¼ë¡œ ê¸°ë°˜ì„ ë‘” ë‹´í™” ë¶„í• ê¸°ë¥¼ í™œìš©í•œ ìƒˆë¡œìš´ LLM ê¸°ë°˜ íŒŒì´í”„ë¼ì¸ì„ ì œì•ˆí•œë‹¤.
- 4. ì œì•ˆëœ ë°©ë²•ì€ ì„¸ ê°€ì§€ ë°ì´í„°ì…‹ì—ì„œ ì§ì ‘ ìƒì„± ë°©ë²• ë° ê¸°ì¤€ì„ ì„ ëŠ¥ê°€í•˜ë©°, ì¸ê°„ê³¼ì˜ ìˆœìœ„ ë°©ë²• ì •ë ¬ì—ì„œ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì¤€ë‹¤.
- 5. ë­í¬ ê¸°ë°˜ HLV í‰ê°€ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•˜ì—¬ ì •í™•í•œ ì ìˆ˜ë³´ë‹¤ ë ˆì´ë¸” ë¶„í¬ì˜ ì§ì ‘ ë¹„êµë¥¼ ìš°ì„ ì‹œí•œë‹¤.


---

*Generated on 2025-09-26 08:55:17*