---
keywords:
  - AI Governance
  - Voluntary Commitments
  - Public Transparency
  - Model Weight Security
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2508.08345
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T16:33:28.903572",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "AI Governance",
    "Voluntary Commitments",
    "Public Transparency",
    "Model Weight Security"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "AI Governance": 0.78,
    "Voluntary Commitments": 0.72,
    "Public Transparency": 0.74,
    "Model Weight Security": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "AI governance",
        "canonical": "AI Governance",
        "aliases": [
          "Artificial Intelligence Governance"
        ],
        "category": "unique_technical",
        "rationale": "AI governance is a critical emerging field that connects policy, ethics, and technology, making it a unique technical concept.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.82,
        "link_intent_score": 0.78
      },
      {
        "surface": "voluntary commitments",
        "canonical": "Voluntary Commitments",
        "aliases": [
          "Self-imposed Obligations"
        ],
        "category": "unique_technical",
        "rationale": "Voluntary commitments are a specific governance mechanism relevant to international policy discussions.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.77,
        "link_intent_score": 0.72
      },
      {
        "surface": "public transparency",
        "canonical": "Public Transparency",
        "aliases": [
          "Openness",
          "Disclosure"
        ],
        "category": "unique_technical",
        "rationale": "Public transparency is vital for accountability in AI governance, linking policy and ethical considerations.",
        "novelty_score": 0.68,
        "connectivity_score": 0.7,
        "specificity_score": 0.75,
        "link_intent_score": 0.74
      },
      {
        "surface": "model weight security",
        "canonical": "Model Weight Security",
        "aliases": [
          "Model Security"
        ],
        "category": "specific_connectable",
        "rationale": "Model weight security is a specific technical concern in AI, relevant to discussions on data protection and integrity.",
        "novelty_score": 0.65,
        "connectivity_score": 0.72,
        "specificity_score": 0.78,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "commitments",
      "guidelines",
      "score"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "AI governance",
      "resolved_canonical": "AI Governance",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.82,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "voluntary commitments",
      "resolved_canonical": "Voluntary Commitments",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.77,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "public transparency",
      "resolved_canonical": "Public Transparency",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.7,
        "specificity": 0.75,
        "link_intent": 0.74
      }
    },
    {
      "candidate_surface": "model weight security",
      "resolved_canonical": "Model Weight Security",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.72,
        "specificity": 0.78,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# Do AI Companies Make Good on Voluntary Commitments to the White House?

## 📋 메타데이터

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2508.08345.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2508.08345](https://arxiv.org/abs/2508.08345)

## 🔗 유사한 논문
- [[2025-09-22/Who is Responsible When AI Fails? Mapping Causes, Entities, and Consequences of AI Privacy and Ethical Incidents_20250922|Who is Responsible When AI Fails? Mapping Causes, Entities, and Consequences of AI Privacy and Ethical Incidents]] (84.5% similar)
- [[2025-09-24/Perceptions of AI Across Sectors_ A Comparative Review of Public Attitudes_20250924|Perceptions of AI Across Sectors: A Comparative Review of Public Attitudes]] (81.4% similar)
- [[2025-09-25/Responsible AI Technical Report_20250925|Responsible AI Technical Report]] (81.4% similar)
- [[2025-09-23/"I think this is fair''_ Uncovering the Complexities of Stakeholder Decision-Making in AI Fairness Assessment_20250923|"I think this is fair'': Uncovering the Complexities of Stakeholder Decision-Making in AI Fairness Assessment]] (81.0% similar)
- [[2025-09-24/An Artificial Intelligence Value at Risk Approach_ Metrics and Models_20250924|An Artificial Intelligence Value at Risk Approach: Metrics and Models]] (80.8% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Model Weight Security|Model Weight Security]]
**⚡ Unique Technical**: [[keywords/AI Governance|AI Governance]], [[keywords/Voluntary Commitments|Voluntary Commitments]], [[keywords/Public Transparency|Public Transparency]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2508.08345v2 Announce Type: replace-cross 
Abstract: Voluntary commitments are central to international AI governance, as demonstrated by recent voluntary guidelines from the White House to the G7, from Bletchley Park to Seoul. How do major AI companies make good on their commitments? We score companies based on their publicly disclosed behavior by developing a detailed rubric based on their eight voluntary commitments to the White House in 2023. We find significant heterogeneity: while the highest-scoring company (OpenAI) scores a 83% overall on our rubric, the average score across all companies is just 53%. The companies demonstrate systemically poor performance for their commitment to model weight security with an average score of 17%: 11 of the 16 companies receive 0% for this commitment. Our analysis highlights a clear structural shortcoming that future AI governance initiatives should correct: when companies make public commitments, they should proactively disclose how they meet their commitments to provide accountability, and these disclosures should be verifiable. To advance policymaking on corporate AI governance, we provide three directed recommendations that address underspecified commitments, the role of complex AI supply chains, and public transparency that could be applied towards AI governance initiatives worldwide.

## 📝 요약

이 논문은 국제 AI 거버넌스에서 자발적 약속의 중요성을 강조하며, 주요 AI 기업들이 이러한 약속을 어떻게 이행하는지를 평가합니다. 연구진은 2023년 백악관의 8가지 자발적 약속을 기준으로 기업들의 공개된 행동을 평가하는 세부 기준을 개발했습니다. 분석 결과, 기업 간 이행 수준의 차이가 크며, OpenAI가 83%로 가장 높은 점수를 받은 반면, 전체 평균은 53%에 불과했습니다. 특히 모델 가중치 보안에 대한 이행은 평균 17%로 매우 저조했습니다. 연구는 기업들이 약속 이행을 투명하게 공개하고 검증 가능하게 해야 한다는 구조적 문제를 지적하며, AI 거버넌스 개선을 위한 세 가지 정책 제안을 제시합니다.

## 🎯 주요 포인트

- 1. 주요 AI 기업들의 자발적 약속 이행에 대한 평가에서 OpenAI가 가장 높은 점수인 83%를 기록했으나, 전체 평균은 53%에 불과합니다.
- 2. 모델 가중치 보안에 대한 약속 이행에서 기업들의 성과가 매우 저조하며, 평균 점수는 17%로 16개 기업 중 11개가 0%를 기록했습니다.
- 3. 기업들이 공공 약속을 할 때, 이행 방법을 투명하게 공개하고 검증 가능하도록 해야 한다는 구조적 문제점이 드러났습니다.
- 4. 기업 AI 거버넌스 정책 발전을 위해 불충분한 약속, 복잡한 AI 공급망의 역할, 공공 투명성에 대한 세 가지 권고안을 제시합니다.


---

*Generated on 2025-09-25 16:33:28*