---
keywords:
  - Cross-Frequency Transfer Learning
  - Foundation Forecasting Models
  - Neural Network
  - Synthetic Dataset Pre-training
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2509.19465
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T15:36:30.202173",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Cross-Frequency Transfer Learning",
    "Foundation Forecasting Models",
    "Neural Network",
    "Synthetic Dataset Pre-training"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Cross-Frequency Transfer Learning": 0.78,
    "Foundation Forecasting Models": 0.77,
    "Neural Network": 0.7,
    "Synthetic Dataset Pre-training": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Cross-Frequency Transfer Learning",
        "canonical": "Cross-Frequency Transfer Learning",
        "aliases": [
          "CFTL"
        ],
        "category": "unique_technical",
        "rationale": "This is a specific technique central to the paper's methodology, offering a unique perspective on transfer learning.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Foundation Forecasting Models",
        "canonical": "Foundation Forecasting Models",
        "aliases": [
          "FFMs"
        ],
        "category": "unique_technical",
        "rationale": "The paper focuses on improving these models, making them a key concept for linking related research.",
        "novelty_score": 0.72,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      },
      {
        "surface": "Neural Forecasting Networks",
        "canonical": "Neural Network",
        "aliases": [
          "Neural Forecasting Models"
        ],
        "category": "broad_technical",
        "rationale": "These networks are adapted for the CFTL setup, linking to broader neural network research.",
        "novelty_score": 0.55,
        "connectivity_score": 0.85,
        "specificity_score": 0.65,
        "link_intent_score": 0.7
      },
      {
        "surface": "Synthetic Dataset Pre-training",
        "canonical": "Synthetic Dataset Pre-training",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "This technique is shown to improve model accuracy, making it a valuable link to data preparation strategies.",
        "novelty_score": 0.68,
        "connectivity_score": 0.73,
        "specificity_score": 0.78,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "benchmarking practices",
      "summary statistics",
      "test leakage"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Cross-Frequency Transfer Learning",
      "resolved_canonical": "Cross-Frequency Transfer Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Foundation Forecasting Models",
      "resolved_canonical": "Foundation Forecasting Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Neural Forecasting Networks",
      "resolved_canonical": "Neural Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.85,
        "specificity": 0.65,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Synthetic Dataset Pre-training",
      "resolved_canonical": "Synthetic Dataset Pre-training",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.73,
        "specificity": 0.78,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# A Realistic Evaluation of Cross-Frequency Transfer Learning and Foundation Forecasting Models

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19465.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2509.19465](https://arxiv.org/abs/2509.19465)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Less is More_ Unlocking Specialization of Time Series Foundation Models via Structured Pruning_20250923|Less is More: Unlocking Specialization of Time Series Foundation Models via Structured Pruning]] (83.6% similar)
- [[2025-09-22/Modeling Temporal Dependencies within the Target for Long-Term Time Series Forecasting_20250922|Modeling Temporal Dependencies within the Target for Long-Term Time Series Forecasting]] (83.0% similar)
- [[2025-09-17/TFMAdapter_ Lightweight Instance-Level Adaptation of Foundation Models for Forecasting with Covariates_20250917|TFMAdapter: Lightweight Instance-Level Adaptation of Foundation Models for Forecasting with Covariates]] (82.4% similar)
- [[2025-09-22/StFT_ Spatio-temporal Fourier Transformer for Long-term Dynamics Prediction_20250922|StFT: Spatio-temporal Fourier Transformer for Long-term Dynamics Prediction]] (82.4% similar)
- [[2025-09-24/MOMEMTO_ Patch-based Memory Gate Model in Time Series Foundation Model_20250924|MOMEMTO: Patch-based Memory Gate Model in Time Series Foundation Model]] (81.4% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Neural Network|Neural Network]]
**ğŸ”— Specific Connectable**: [[keywords/Synthetic Dataset Pre-training|Synthetic Dataset Pre-training]]
**âš¡ Unique Technical**: [[keywords/Cross-Frequency Transfer Learning|Cross-Frequency Transfer Learning]], [[keywords/Foundation Forecasting Models|Foundation Forecasting Models]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19465v1 Announce Type: cross 
Abstract: Cross-frequency transfer learning (CFTL) has emerged as a popular framework for curating large-scale time series datasets to pre-train foundation forecasting models (FFMs). Although CFTL has shown promise, current benchmarking practices fall short of accurately assessing its performance. This shortcoming stems from many factors: an over-reliance on small-scale evaluation datasets; inadequate treatment of sample size when computing summary statistics; reporting of suboptimal statistical models; and failing to account for non-negligible risks of overlap between pre-training and test datasets. To address these limitations, we introduce a unified reimplementation of widely-adopted neural forecasting networks, adapting them for the CFTL setup; we pre-train only on proprietary and synthetic data, being careful to prevent test leakage; and we evaluate on 15 large, diverse public forecast competition datasets. Our empirical analysis reveals that statistical models' accuracy is frequently underreported. Notably, we confirm that statistical models and their ensembles consistently outperform existing FFMs by more than 8.2% in sCRPS, and by more than 20% MASE, across datasets. However, we also find that synthetic dataset pre-training does improve the accuracy of a FFM by 7% percent.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€ê·œëª¨ ì‹œê³„ì—´ ë°ì´í„°ì…‹ì„ í™œìš©í•œ ê¸°ì´ˆ ì˜ˆì¸¡ ëª¨ë¸(FFM) ì‚¬ì „ í•™ìŠµì„ ìœ„í•œ êµì°¨ ì£¼íŒŒìˆ˜ ì „ì´ í•™ìŠµ(CFTL)ì˜ ì„±ëŠ¥ í‰ê°€ ë¬¸ì œë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. ê¸°ì¡´ í‰ê°€ ë°©ì‹ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´, ì €ìë“¤ì€ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ì‹ ê²½ë§ ì˜ˆì¸¡ ëª¨ë¸ì„ CFTLì— ë§ê²Œ ì¬êµ¬í˜„í•˜ê³ , ì‚¬ì „ í•™ìŠµ ì‹œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ëˆ„ì¶œì„ ë°©ì§€í•˜ë©°, 15ê°œì˜ ëŒ€ê·œëª¨ ê³µê³µ ì˜ˆì¸¡ ëŒ€íšŒ ë°ì´í„°ì…‹ì—ì„œ í‰ê°€ë¥¼ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. ê·¸ ê²°ê³¼, í†µê³„ ëª¨ë¸ì˜ ì •í™•ë„ê°€ ìì£¼ ê³¼ì†Œí‰ê°€ë˜ì—ˆìœ¼ë©°, í†µê³„ ëª¨ë¸ê³¼ ê·¸ ì•™ìƒë¸”ì´ ê¸°ì¡´ FFMë³´ë‹¤ í‰ê· ì ìœ¼ë¡œ 8.2% ì´ìƒì˜ sCRPSì™€ 20% ì´ìƒì˜ MASEì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ë˜í•œ, í•©ì„± ë°ì´í„°ì…‹ì„ í†µí•œ ì‚¬ì „ í•™ìŠµì´ FFMì˜ ì •í™•ì„±ì„ 7% í–¥ìƒì‹œí‚¨ë‹¤ëŠ” ì‚¬ì‹¤ë„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. CFTLì€ ëŒ€ê·œëª¨ ì‹œê³„ì—´ ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬ ì˜ˆì¸¡ ëª¨ë¸ì„ ì‚¬ì „ í›ˆë ¨í•˜ëŠ” ì¸ê¸° ìˆëŠ” í”„ë ˆì„ì›Œí¬ë¡œ ë¶€ìƒí•˜ê³  ìˆë‹¤.
- 2. í˜„ì¬ì˜ ë²¤ì¹˜ë§ˆí‚¹ ê´€í–‰ì€ CFTLì˜ ì„±ëŠ¥ì„ ì •í™•íˆ í‰ê°€í•˜ì§€ ëª»í•˜ê³  ìˆë‹¤.
- 3. ë‹¤ì–‘í•œ ìš”ì¸ë“¤ì´ ì´ëŸ¬í•œ í‰ê°€ì˜ í•œê³„ë¥¼ ì´ˆë˜í•˜ë©°, íŠ¹íˆ ì†Œê·œëª¨ í‰ê°€ ë°ì´í„°ì…‹ì— ëŒ€í•œ ê³¼ë„í•œ ì˜ì¡´ê³¼ ìƒ˜í”Œ í¬ê¸° ì²˜ë¦¬ì˜ ë¶€ì ì ˆí•¨ ë“±ì´ ë¬¸ì œë¡œ ì§€ì ëœë‹¤.
- 4. ì—°êµ¬ì—ì„œëŠ” CFTL ì„¤ì •ì— ë§ê²Œ ì‹ ê²½ë§ ì˜ˆì¸¡ ëª¨ë¸ì„ í†µí•© ì¬êµ¬í˜„í•˜ê³ , ë…ì ì  ë° í•©ì„± ë°ì´í„°ë¡œë§Œ ì‚¬ì „ í›ˆë ¨ì„ ìˆ˜í–‰í•˜ì—¬ í…ŒìŠ¤íŠ¸ ëˆ„ì¶œì„ ë°©ì§€í•˜ì˜€ë‹¤.
- 5. ì‹¤ì¦ ë¶„ì„ ê²°ê³¼, í†µê³„ ëª¨ë¸ê³¼ ê·¸ ì•™ìƒë¸”ì´ ê¸°ì¡´ FFMsë³´ë‹¤ sCRPSì—ì„œ 8.2% ì´ìƒ, MASEì—ì„œ 20% ì´ìƒ ë” ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤.


---

*Generated on 2025-09-25 15:36:30*