---
keywords:
  - Synthetic Robot Pose Generation
  - RGB-D Data Augmentation
  - Imitation Learning
  - Stable Diffusion
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2509.19454
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T15:35:52.460298",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Synthetic Robot Pose Generation",
    "RGB-D Data Augmentation",
    "Imitation Learning",
    "Stable Diffusion"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Synthetic Robot Pose Generation": 0.8,
    "RGB-D Data Augmentation": 0.78,
    "Imitation Learning": 0.75,
    "Stable Diffusion": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Synthetic Robot Pose Generation",
        "canonical": "Synthetic Robot Pose Generation",
        "aliases": [
          "ROPA"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel method introduced in the paper, crucial for understanding the specific data augmentation technique discussed.",
        "novelty_score": 0.9,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "RGB-D Bimanual Data Augmentation",
        "canonical": "RGB-D Data Augmentation",
        "aliases": [
          "Bimanual Data Augmentation"
        ],
        "category": "specific_connectable",
        "rationale": "This connects to the broader topic of data augmentation in computer vision, specifically for RGB-D data.",
        "novelty_score": 0.7,
        "connectivity_score": 0.85,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Imitation Learning",
        "canonical": "Imitation Learning",
        "aliases": [
          "Learning from Demonstration"
        ],
        "category": "broad_technical",
        "rationale": "Imitation learning is a foundational concept in machine learning, relevant to the training methods discussed.",
        "novelty_score": 0.4,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.75
      },
      {
        "surface": "Stable Diffusion",
        "canonical": "Stable Diffusion",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Stable Diffusion is a key technique used in the paper for generating synthetic data, linking to broader diffusion models.",
        "novelty_score": 0.5,
        "connectivity_score": 0.8,
        "specificity_score": 0.75,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Synthetic Robot Pose Generation",
      "resolved_canonical": "Synthetic Robot Pose Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.9,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "RGB-D Bimanual Data Augmentation",
      "resolved_canonical": "RGB-D Data Augmentation",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.85,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Imitation Learning",
      "resolved_canonical": "Imitation Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Stable Diffusion",
      "resolved_canonical": "Stable Diffusion",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.8,
        "specificity": 0.75,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# ROPA: Synthetic Robot Pose Generation for RGB-D Bimanual Data Augmentation

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19454.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2509.19454](https://arxiv.org/abs/2509.19454)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/\textsc{Gen2Real}_ Towards Demo-Free Dexterous Manipulation by Harnessing Generated Video_20250918|\textsc{Gen2Real}: Towards Demo-Free Dexterous Manipulation by Harnessing Generated Video]] (85.7% similar)
- [[2025-09-23/End-to-end RL Improves Dexterous Grasping Policies_20250923|End-to-end RL Improves Dexterous Grasping Policies]] (85.0% similar)
- [[2025-09-23/Latent Policy Steering with Embodiment-Agnostic Pretrained World Models_20250923|Latent Policy Steering with Embodiment-Agnostic Pretrained World Models]] (84.6% similar)
- [[2025-09-24/MV-UMI_ A Scalable Multi-View Interface for Cross-Embodiment Learning_20250924|MV-UMI: A Scalable Multi-View Interface for Cross-Embodiment Learning]] (84.2% similar)
- [[2025-09-23/Leveraging RGB Images for Pre-Training of Event-Based Hand Pose Estimation_20250923|Leveraging RGB Images for Pre-Training of Event-Based Hand Pose Estimation]] (84.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Imitation Learning|Imitation Learning]]
**ğŸ”— Specific Connectable**: [[keywords/RGB-D Data Augmentation|RGB-D Data Augmentation]], [[keywords/Stable Diffusion|Stable Diffusion]]
**âš¡ Unique Technical**: [[keywords/Synthetic Robot Pose Generation|Synthetic Robot Pose Generation]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19454v1 Announce Type: cross 
Abstract: Training robust bimanual manipulation policies via imitation learning requires demonstration data with broad coverage over robot poses, contacts, and scene contexts. However, collecting diverse and precise real-world demonstrations is costly and time-consuming, which hinders scalability. Prior works have addressed this with data augmentation, typically for either eye-in-hand (wrist camera) setups with RGB inputs or for generating novel images without paired actions, leaving augmentation for eye-to-hand (third-person) RGB-D training with new action labels less explored. In this paper, we propose Synthetic Robot Pose Generation for RGB-D Bimanual Data Augmentation (ROPA), an offline imitation learning data augmentation method that fine-tunes Stable Diffusion to synthesize third-person RGB and RGB-D observations of novel robot poses. Our approach simultaneously generates corresponding joint-space action labels while employing constrained optimization to enforce physical consistency through appropriate gripper-to-object contact constraints in bimanual scenarios. We evaluate our method on 5 simulated and 3 real-world tasks. Our results across 2625 simulation trials and 300 real-world trials demonstrate that ROPA outperforms baselines and ablations, showing its potential for scalable RGB and RGB-D data augmentation in eye-to-hand bimanual manipulation. Our project website is available at: https://ropaaug.github.io/.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëª¨ë°© í•™ìŠµì„ í†µí•œ ê²¬ê³ í•œ ì–‘ì† ì¡°ì‘ ì •ì±… í›ˆë ¨ì„ ìœ„í•´ ë‹¤ì–‘í•œ ë¡œë´‡ ìì„¸ì™€ ì ‘ì´‰, ì¥ë©´ ë§¥ë½ì„ í¬í•¨í•˜ëŠ” ì‹œì—° ë°ì´í„°ë¥¼ í•„ìš”ë¡œ í•˜ì§€ë§Œ, ì‹¤ì œ ì‹œì—° ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ê²ƒì€ ë¹„ìš©ì´ ë§ì´ ë“¤ê³  ì‹œê°„ì´ ì†Œìš”ëœë‹¤ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê³ ì í•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ì œì•ˆëœ ë°©ë²•ë¡ ì€ ROPA(Synthetic Robot Pose Generation for RGB-D Bimanual Data Augmentation)ë¡œ, Stable Diffusionì„ í™œìš©í•˜ì—¬ ìƒˆë¡œìš´ ë¡œë´‡ ìì„¸ì˜ ì œ3ì ì‹œì  RGB ë° RGB-D ê´€ì¸¡ì„ ìƒì„±í•˜ê³ , ë¬¼ë¦¬ì  ì¼ê´€ì„±ì„ ìœ ì§€í•˜ê¸° ìœ„í•´ ì œì•½ ìµœì í™”ë¥¼ ì‚¬ìš©í•˜ì—¬ ì ì ˆí•œ ê·¸ë¦¬í¼-ê°ì²´ ì ‘ì´‰ ì œì•½ì„ ì ìš©í•©ë‹ˆë‹¤. 5ê°œì˜ ì‹œë®¬ë ˆì´ì…˜ ë° 3ê°œì˜ ì‹¤ì œ ê³¼ì œë¥¼ í†µí•´ í‰ê°€í•œ ê²°ê³¼, ROPAëŠ” ê¸°ì¡´ ë°©ë²•ë“¤ì„ ëŠ¥ê°€í•˜ë©°, eye-to-hand ì–‘ì† ì¡°ì‘ì—ì„œì˜ í™•ì¥ ê°€ëŠ¥í•œ ë°ì´í„° ì¦ê°• ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ROPAëŠ” ìƒˆë¡œìš´ ë¡œë´‡ ìì„¸ì˜ RGB ë° RGB-D ê´€ì°°ì„ í•©ì„±í•˜ì—¬ ëª¨ë°© í•™ìŠµ ë°ì´í„° ì¦ê°•ì„ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.
- 2. ì´ ë°©ë²•ì€ ë¬¼ë¦¬ì  ì¼ê´€ì„±ì„ ìœ ì§€í•˜ê¸° ìœ„í•´ ê·¸ë¦¬í¼ì™€ ê°ì²´ ê°„ì˜ ì ‘ì´‰ ì œì•½ì„ í™œìš©í•˜ì—¬ ì ì ˆí•œ ì¡°ì¸íŠ¸ ê³µê°„ í–‰ë™ ë ˆì´ë¸”ì„ ìƒì„±í•©ë‹ˆë‹¤.
- 3. 5ê°œì˜ ì‹œë®¬ë ˆì´ì…˜ ì‘ì—…ê³¼ 3ê°œì˜ ì‹¤ì œ ì‘ì—…ì—ì„œ ROPAì˜ ì„±ëŠ¥ì„ í‰ê°€í–ˆìœ¼ë©°, ì´ 2625íšŒì˜ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í—˜ê³¼ 300íšŒì˜ ì‹¤ì œ ì‹¤í—˜ì—ì„œ ê¸°ì¡´ ë°©ë²•ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ê³¼ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.
- 4. ROPAëŠ” eye-to-hand ë°©ì‹ì˜ ì–‘ì† ì¡°ì‘ì—ì„œ RGB ë° RGB-D ë°ì´í„° ì¦ê°•ì˜ í™•ì¥ ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.


---

*Generated on 2025-09-25 15:35:52*