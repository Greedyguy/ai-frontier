---
keywords:
  - Transformer
  - Large Language Model
  - Multimodal Learning
  - Non-Autoregressive Audio Diffusion
  - Speech-in Speech-out Conversational Systems
category: cs.CL
publish_date: 2025-09-25
arxiv_id: 2509.20072
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-26T08:47:40.398446",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Transformer",
    "Large Language Model",
    "Multimodal Learning",
    "Non-Autoregressive Audio Diffusion",
    "Speech-in Speech-out Conversational Systems"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Transformer": 0.85,
    "Large Language Model": 0.8,
    "Multimodal Learning": 0.82,
    "Non-Autoregressive Audio Diffusion": 0.78,
    "Speech-in Speech-out Conversational Systems": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Transformer",
        "canonical": "Transformer",
        "aliases": [],
        "category": "broad_technical",
        "rationale": "Transformers are central to the proposed model architecture, facilitating connections with other Transformer-based research.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Large Language Model",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "The model builds on pretrained large language models, linking it to a wide array of similar research.",
        "novelty_score": 0.25,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.8
      },
      {
        "surface": "Multimodal",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal"
        ],
        "category": "specific_connectable",
        "rationale": "The paper focuses on integrating audio and text, a key aspect of multimodal learning.",
        "novelty_score": 0.55,
        "connectivity_score": 0.85,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "Non-Autoregressive Audio Diffusion",
        "canonical": "Non-Autoregressive Audio Diffusion",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This is a novel approach introduced in the paper, differentiating it from traditional autoregressive models.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Speech-in Speech-out Conversational Systems",
        "canonical": "Speech-in Speech-out Conversational Systems",
        "aliases": [
          "Conversational Systems"
        ],
        "category": "unique_technical",
        "rationale": "The paper targets advancements in conversational systems, which is a specific application area.",
        "novelty_score": 0.68,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "autoregressive",
      "pipeline"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Transformer",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Large Language Model",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.25,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Multimodal",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.85,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Non-Autoregressive Audio Diffusion",
      "resolved_canonical": "Non-Autoregressive Audio Diffusion",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Speech-in Speech-out Conversational Systems",
      "resolved_canonical": "Speech-in Speech-out Conversational Systems",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# From Text to Talk: Audio-Language Model Needs Non-Autoregressive Joint Training

## 📋 메타데이터

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.20072.pdf)
**Category**: cs.CL
**Published**: 2025-09-25
**ArXiv ID**: [2509.20072](https://arxiv.org/abs/2509.20072)

## 🔗 유사한 논문
- [[2025-09-24/Pay More Attention To Audio_ Mitigating Imbalance of Cross-Modal Attention in Large Audio Language Models_20250924|Pay More Attention To Audio: Mitigating Imbalance of Cross-Modal Attention in Large Audio Language Models]] (86.0% similar)
- [[2025-09-24/Large Language Models Implicitly Learn to See and Hear Just By Reading_20250924|Large Language Models Implicitly Learn to See and Hear Just By Reading]] (85.7% similar)
- [[2025-09-25/Frame-Stacked Local Transformers For Efficient Multi-Codebook Speech Generation_20250925|Frame-Stacked Local Transformers For Efficient Multi-Codebook Speech Generation]] (84.9% similar)
- [[2025-09-24/Explore the Reinforcement Learning for the LLM based ASR and TTS system_20250924|Explore the Reinforcement Learning for the LLM based ASR and TTS system]] (84.2% similar)
- [[2025-09-24/Teaching Audio Models to Reason_ A Unified Framework for Source- and Layer-wise Distillation_20250924|Teaching Audio Models to Reason: A Unified Framework for Source- and Layer-wise Distillation]] (83.7% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Transformer|Transformer]], [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**⚡ Unique Technical**: [[keywords/Non-Autoregressive Audio Diffusion|Non-Autoregressive Audio Diffusion]], [[keywords/Speech-in Speech-out Conversational Systems|Speech-in Speech-out Conversational Systems]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.20072v1 Announce Type: new 
Abstract: Recent advances in large language models have attracted significant interest in extending their capabilities to multimodal scenarios, particularly for speech-in speech-out conversational systems. However, existing multimodal models handling interleaved audio and text, such as MOSHI require complex multi stage training pipelines, incurring substantial computational costs. Moreover, these models uniformly apply autoregressive generation to both text and audio tokens, overlooking a fundamental asymmetry in their dependency structures: while text tokens exhibit strong target target dependencies requiring causal ordering, audio tokens are predominantly driven by source target dependencies, where audio outputs primarily condition on source text rather than preceding audio tokens. In this work, we propose TtT, a unified audio-text modeling framework that integrates AR text generation with non-autoregressive audio diffusion within a single Transformer architecture initialized from a pretrained LLM.

## 📝 요약

최근 대형 언어 모델의 발전으로 음성 대 음성 대화 시스템 등 다중 모달 시나리오로의 확장이 주목받고 있습니다. 기존 모델들은 복잡한 다단계 학습 과정을 필요로 하며, 텍스트와 오디오 토큰 모두에 동일한 자동회귀 생성을 적용해 비효율적입니다. 본 연구에서는 사전 학습된 대형 언어 모델을 기반으로, 자동회귀 텍스트 생성과 비자동회귀 오디오 확산을 통합한 TtT라는 통합 오디오-텍스트 모델링 프레임워크를 제안합니다. 이를 통해 텍스트와 오디오 토큰의 비대칭적 의존 구조를 효과적으로 처리할 수 있습니다.

## 🎯 주요 포인트

- 1. 대형 언어 모델의 발전으로 인해 음성 대 음성 대화 시스템을 포함한 다중 모달 시나리오로의 확장이 주목받고 있습니다.
- 2. 기존의 다중 모달 모델은 복잡한 다단계 훈련 과정이 필요하여 상당한 계산 비용이 발생합니다.
- 3. 텍스트와 오디오 토큰의 의존 구조가 다름에도 불구하고, 기존 모델은 두 토큰 모두에 자동회귀 생성을 적용합니다.
- 4. 본 연구에서는 사전 훈련된 LLM에서 초기화된 단일 Transformer 아키텍처 내에서 AR 텍스트 생성과 비자동회귀 오디오 확산을 통합하는 TtT 프레임워크를 제안합니다.


---

*Generated on 2025-09-26 08:47:40*