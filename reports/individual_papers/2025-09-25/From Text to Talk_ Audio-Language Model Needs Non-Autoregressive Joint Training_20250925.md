---
keywords:
  - Transformer
  - Large Language Model
  - Multimodal Learning
  - Non-Autoregressive Audio Diffusion
  - Speech-in Speech-out Conversational Systems
category: cs.CL
publish_date: 2025-09-25
arxiv_id: 2509.20072
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-26T08:47:40.398446",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Transformer",
    "Large Language Model",
    "Multimodal Learning",
    "Non-Autoregressive Audio Diffusion",
    "Speech-in Speech-out Conversational Systems"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Transformer": 0.85,
    "Large Language Model": 0.8,
    "Multimodal Learning": 0.82,
    "Non-Autoregressive Audio Diffusion": 0.78,
    "Speech-in Speech-out Conversational Systems": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Transformer",
        "canonical": "Transformer",
        "aliases": [],
        "category": "broad_technical",
        "rationale": "Transformers are central to the proposed model architecture, facilitating connections with other Transformer-based research.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Large Language Model",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "The model builds on pretrained large language models, linking it to a wide array of similar research.",
        "novelty_score": 0.25,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.8
      },
      {
        "surface": "Multimodal",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal"
        ],
        "category": "specific_connectable",
        "rationale": "The paper focuses on integrating audio and text, a key aspect of multimodal learning.",
        "novelty_score": 0.55,
        "connectivity_score": 0.85,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "Non-Autoregressive Audio Diffusion",
        "canonical": "Non-Autoregressive Audio Diffusion",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This is a novel approach introduced in the paper, differentiating it from traditional autoregressive models.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Speech-in Speech-out Conversational Systems",
        "canonical": "Speech-in Speech-out Conversational Systems",
        "aliases": [
          "Conversational Systems"
        ],
        "category": "unique_technical",
        "rationale": "The paper targets advancements in conversational systems, which is a specific application area.",
        "novelty_score": 0.68,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "autoregressive",
      "pipeline"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Transformer",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Large Language Model",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.25,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Multimodal",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.85,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Non-Autoregressive Audio Diffusion",
      "resolved_canonical": "Non-Autoregressive Audio Diffusion",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Speech-in Speech-out Conversational Systems",
      "resolved_canonical": "Speech-in Speech-out Conversational Systems",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# From Text to Talk: Audio-Language Model Needs Non-Autoregressive Joint Training

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.20072.pdf)
**Category**: cs.CL
**Published**: 2025-09-25
**ArXiv ID**: [2509.20072](https://arxiv.org/abs/2509.20072)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-24/Pay More Attention To Audio_ Mitigating Imbalance of Cross-Modal Attention in Large Audio Language Models_20250924|Pay More Attention To Audio: Mitigating Imbalance of Cross-Modal Attention in Large Audio Language Models]] (86.0% similar)
- [[2025-09-24/Large Language Models Implicitly Learn to See and Hear Just By Reading_20250924|Large Language Models Implicitly Learn to See and Hear Just By Reading]] (85.7% similar)
- [[2025-09-25/Frame-Stacked Local Transformers For Efficient Multi-Codebook Speech Generation_20250925|Frame-Stacked Local Transformers For Efficient Multi-Codebook Speech Generation]] (84.9% similar)
- [[2025-09-24/Explore the Reinforcement Learning for the LLM based ASR and TTS system_20250924|Explore the Reinforcement Learning for the LLM based ASR and TTS system]] (84.2% similar)
- [[2025-09-24/Teaching Audio Models to Reason_ A Unified Framework for Source- and Layer-wise Distillation_20250924|Teaching Audio Models to Reason: A Unified Framework for Source- and Layer-wise Distillation]] (83.7% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Transformer|Transformer]], [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**âš¡ Unique Technical**: [[keywords/Non-Autoregressive Audio Diffusion|Non-Autoregressive Audio Diffusion]], [[keywords/Speech-in Speech-out Conversational Systems|Speech-in Speech-out Conversational Systems]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.20072v1 Announce Type: new 
Abstract: Recent advances in large language models have attracted significant interest in extending their capabilities to multimodal scenarios, particularly for speech-in speech-out conversational systems. However, existing multimodal models handling interleaved audio and text, such as MOSHI require complex multi stage training pipelines, incurring substantial computational costs. Moreover, these models uniformly apply autoregressive generation to both text and audio tokens, overlooking a fundamental asymmetry in their dependency structures: while text tokens exhibit strong target target dependencies requiring causal ordering, audio tokens are predominantly driven by source target dependencies, where audio outputs primarily condition on source text rather than preceding audio tokens. In this work, we propose TtT, a unified audio-text modeling framework that integrates AR text generation with non-autoregressive audio diffusion within a single Transformer architecture initialized from a pretrained LLM.

## ğŸ“ ìš”ì•½

ìµœê·¼ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ ë°œì „ìœ¼ë¡œ ìŒì„± ëŒ€ ìŒì„± ëŒ€í™” ì‹œìŠ¤í…œ ë“± ë‹¤ì¤‘ ëª¨ë‹¬ ì‹œë‚˜ë¦¬ì˜¤ë¡œì˜ í™•ì¥ì´ ì£¼ëª©ë°›ê³  ìˆìŠµë‹ˆë‹¤. ê¸°ì¡´ ëª¨ë¸ë“¤ì€ ë³µì¡í•œ ë‹¤ë‹¨ê³„ í•™ìŠµ ê³¼ì •ì„ í•„ìš”ë¡œ í•˜ë©°, í…ìŠ¤íŠ¸ì™€ ì˜¤ë””ì˜¤ í† í° ëª¨ë‘ì— ë™ì¼í•œ ìë™íšŒê·€ ìƒì„±ì„ ì ìš©í•´ ë¹„íš¨ìœ¨ì ì…ë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” ì‚¬ì „ í•™ìŠµëœ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ, ìë™íšŒê·€ í…ìŠ¤íŠ¸ ìƒì„±ê³¼ ë¹„ìë™íšŒê·€ ì˜¤ë””ì˜¤ í™•ì‚°ì„ í†µí•©í•œ TtTë¼ëŠ” í†µí•© ì˜¤ë””ì˜¤-í…ìŠ¤íŠ¸ ëª¨ë¸ë§ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ í…ìŠ¤íŠ¸ì™€ ì˜¤ë””ì˜¤ í† í°ì˜ ë¹„ëŒ€ì¹­ì  ì˜ì¡´ êµ¬ì¡°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ ë°œì „ìœ¼ë¡œ ì¸í•´ ìŒì„± ëŒ€ ìŒì„± ëŒ€í™” ì‹œìŠ¤í…œì„ í¬í•¨í•œ ë‹¤ì¤‘ ëª¨ë‹¬ ì‹œë‚˜ë¦¬ì˜¤ë¡œì˜ í™•ì¥ì´ ì£¼ëª©ë°›ê³  ìˆìŠµë‹ˆë‹¤.
- 2. ê¸°ì¡´ì˜ ë‹¤ì¤‘ ëª¨ë‹¬ ëª¨ë¸ì€ ë³µì¡í•œ ë‹¤ë‹¨ê³„ í›ˆë ¨ ê³¼ì •ì´ í•„ìš”í•˜ì—¬ ìƒë‹¹í•œ ê³„ì‚° ë¹„ìš©ì´ ë°œìƒí•©ë‹ˆë‹¤.
- 3. í…ìŠ¤íŠ¸ì™€ ì˜¤ë””ì˜¤ í† í°ì˜ ì˜ì¡´ êµ¬ì¡°ê°€ ë‹¤ë¦„ì—ë„ ë¶ˆêµ¬í•˜ê³ , ê¸°ì¡´ ëª¨ë¸ì€ ë‘ í† í° ëª¨ë‘ì— ìë™íšŒê·€ ìƒì„±ì„ ì ìš©í•©ë‹ˆë‹¤.
- 4. ë³¸ ì—°êµ¬ì—ì„œëŠ” ì‚¬ì „ í›ˆë ¨ëœ LLMì—ì„œ ì´ˆê¸°í™”ëœ ë‹¨ì¼ Transformer ì•„í‚¤í…ì²˜ ë‚´ì—ì„œ AR í…ìŠ¤íŠ¸ ìƒì„±ê³¼ ë¹„ìë™íšŒê·€ ì˜¤ë””ì˜¤ í™•ì‚°ì„ í†µí•©í•˜ëŠ” TtT í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.


---

*Generated on 2025-09-26 08:47:40*