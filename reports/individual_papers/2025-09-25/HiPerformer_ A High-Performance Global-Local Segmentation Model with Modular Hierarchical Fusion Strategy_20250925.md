---
keywords:
  - Transformer
  - Local-Global Feature Fusion
  - Progressive Pyramid Aggregation
  - Computer Vision
category: cs.CV
publish_date: 2025-09-25
arxiv_id: 2509.20280
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-26T09:15:39.624802",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Transformer",
    "Local-Global Feature Fusion",
    "Progressive Pyramid Aggregation",
    "Computer Vision"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Transformer": 0.85,
    "Local-Global Feature Fusion": 0.78,
    "Progressive Pyramid Aggregation": 0.8,
    "Computer Vision": 0.82
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "CNN-Transformer hybrid architectures",
        "canonical": "Transformer",
        "aliases": [
          "CNN-Transformer",
          "Hybrid Transformer"
        ],
        "category": "broad_technical",
        "rationale": "Transformers are a key component in the hybrid architecture, linking to broader technical discussions in neural network design.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Local-Global Feature Fusion",
        "canonical": "Local-Global Feature Fusion",
        "aliases": [
          "LGFF"
        ],
        "category": "unique_technical",
        "rationale": "This module is a novel approach to feature integration, offering a unique perspective in segmentation models.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.82,
        "link_intent_score": 0.78
      },
      {
        "surface": "Progressive Pyramid Aggregation",
        "canonical": "Progressive Pyramid Aggregation",
        "aliases": [
          "PPA"
        ],
        "category": "unique_technical",
        "rationale": "PPA is a distinctive method proposed to enhance feature representation, providing a new angle on multi-scale processing.",
        "novelty_score": 0.78,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "medical image segmentation",
        "canonical": "Computer Vision",
        "aliases": [
          "medical segmentation"
        ],
        "category": "broad_technical",
        "rationale": "Medical image segmentation is a specific application within computer vision, linking to a broad technical field.",
        "novelty_score": 0.4,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.82
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance",
      "accuracy",
      "robustness"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "CNN-Transformer hybrid architectures",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Local-Global Feature Fusion",
      "resolved_canonical": "Local-Global Feature Fusion",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.82,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Progressive Pyramid Aggregation",
      "resolved_canonical": "Progressive Pyramid Aggregation",
      "decision": "linked",
      "scores": {
        "novelty": 0.78,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "medical image segmentation",
      "resolved_canonical": "Computer Vision",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.82
      }
    }
  ]
}
-->

# HiPerformer: A High-Performance Global-Local Segmentation Model with Modular Hierarchical Fusion Strategy

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.20280.pdf)
**Category**: cs.CV
**Published**: 2025-09-25
**ArXiv ID**: [2509.20280](https://arxiv.org/abs/2509.20280)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/pFedSAM_ Personalized Federated Learning of Segment Anything Model for Medical Image Segmentation_20250922|pFedSAM: Personalized Federated Learning of Segment Anything Model for Medical Image Segmentation]] (83.0% similar)
- [[2025-09-23/DCFFSNet_ Deep Connectivity Feature Fusion Separation Network for Medical Image Segmentation_20250923|DCFFSNet: Deep Connectivity Feature Fusion Separation Network for Medical Image Segmentation]] (82.7% similar)
- [[2025-09-22/UniMRSeg_ Unified Modality-Relax Segmentation via Hierarchical Self-Supervised Compensation_20250922|UniMRSeg: Unified Modality-Relax Segmentation via Hierarchical Self-Supervised Compensation]] (81.9% similar)
- [[2025-09-23/A Semantic Segmentation Algorithm for Pleural Effusion Based on DBIF-AUNet_20250923|A Semantic Segmentation Algorithm for Pleural Effusion Based on DBIF-AUNet]] (81.8% similar)
- [[2025-09-23/3D Cell Oversegmentation Correction via Geo-Wasserstein Divergence_20250923|3D Cell Oversegmentation Correction via Geo-Wasserstein Divergence]] (81.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Transformer|Transformer]], [[keywords/Computer Vision|Computer Vision]]
**âš¡ Unique Technical**: [[keywords/Local-Global Feature Fusion|Local-Global Feature Fusion]], [[keywords/Progressive Pyramid Aggregation|Progressive Pyramid Aggregation]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.20280v1 Announce Type: new 
Abstract: Both local details and global context are crucial in medical image segmentation, and effectively integrating them is essential for achieving high accuracy. However, existing mainstream methods based on CNN-Transformer hybrid architectures typically employ simple feature fusion techniques such as serial stacking, endpoint concatenation, or pointwise addition, which struggle to address the inconsistencies between features and are prone to information conflict and loss. To address the aforementioned challenges, we innovatively propose HiPerformer. The encoder of HiPerformer employs a novel modular hierarchical architecture that dynamically fuses multi-source features in parallel, enabling layer-wise deep integration of heterogeneous information. The modular hierarchical design not only retains the independent modeling capability of each branch in the encoder, but also ensures sufficient information transfer between layers, effectively avoiding the degradation of features and information loss that come with traditional stacking methods. Furthermore, we design a Local-Global Feature Fusion (LGFF) module to achieve precise and efficient integration of local details and global semantic information, effectively alleviating the feature inconsistency problem and resulting in a more comprehensive feature representation. To further enhance multi-scale feature representation capabilities and suppress noise interference, we also propose a Progressive Pyramid Aggregation (PPA) module to replace traditional skip connections. Experiments on eleven public datasets demonstrate that the proposed method outperforms existing segmentation techniques, demonstrating higher segmentation accuracy and robustness. The code is available at https://github.com/xzphappy/HiPerformer.

## ğŸ“ ìš”ì•½

HiPerformerëŠ” ì˜ë£Œ ì˜ìƒ ë¶„í• ì—ì„œ ì§€ì—­ì  ì„¸ë¶€ì‚¬í•­ê³¼ ì „ì—­ì  ë§¥ë½ì„ íš¨ê³¼ì ìœ¼ë¡œ í†µí•©í•˜ê¸° ìœ„í•´ ì œì•ˆëœ ìƒˆë¡œìš´ ë°©ë²•ë¡ ì…ë‹ˆë‹¤. ê¸°ì¡´ CNN-Transformer í˜¼í•© ì•„í‚¤í…ì²˜ì˜ ë‹¨ìˆœí•œ íŠ¹ì§• ìœµí•© ê¸°ë²•ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´, HiPerformerëŠ” ëª¨ë“ˆí˜• ê³„ì¸µì  ì•„í‚¤í…ì²˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ì–‘í•œ ì¶œì²˜ì˜ íŠ¹ì§•ì„ ë³‘ë ¬ë¡œ ìœµí•©í•˜ê³ , ê³„ì¸µë³„ë¡œ ì´ì§ˆì ì¸ ì •ë³´ë¥¼ ê¹Šì´ ìˆê²Œ í†µí•©í•©ë‹ˆë‹¤. ë˜í•œ, Local-Global Feature Fusion (LGFF) ëª¨ë“ˆì„ í†µí•´ ì§€ì—­ì  ì„¸ë¶€ì‚¬í•­ê³¼ ì „ì—­ì  ì˜ë¯¸ ì •ë³´ë¥¼ ì •ë°€í•˜ê²Œ í†µí•©í•˜ë©°, Progressive Pyramid Aggregation (PPA) ëª¨ë“ˆì„ ë„ì…í•˜ì—¬ ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ íŠ¹ì§• í‘œí˜„ì„ ê°•í™”í•˜ê³  ì¡ìŒ ê°„ì„­ì„ ì–µì œí•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, HiPerformerëŠ” ê¸°ì¡´ ë¶„í•  ê¸°ë²•ë³´ë‹¤ ë†’ì€ ì •í™•ì„±ê³¼ ê°•ê±´ì„±ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. HiPerformerëŠ” ì˜ë£Œ ì´ë¯¸ì§€ ë¶„í• ì—ì„œ ì§€ì—­ì  ì„¸ë¶€ ì‚¬í•­ê³¼ ì „ì—­ì  ë¬¸ë§¥ì„ íš¨ê³¼ì ìœ¼ë¡œ í†µí•©í•˜ê¸° ìœ„í•´ ì„¤ê³„ëœ í˜ì‹ ì ì¸ ëª¨ë“ˆí˜• ê³„ì¸µì  ì•„í‚¤í…ì²˜ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.
- 2. HiPerformerì˜ ì¸ì½”ë”ëŠ” ë³‘ë ¬ë¡œ ë‹¤ì¤‘ ì†ŒìŠ¤ íŠ¹ì§•ì„ ë™ì ìœ¼ë¡œ ìœµí•©í•˜ì—¬ ì´ì§ˆì ì¸ ì •ë³´ë¥¼ ê³„ì¸µì ìœ¼ë¡œ ê¹Šì´ í†µí•©í•©ë‹ˆë‹¤.
- 3. Local-Global Feature Fusion (LGFF) ëª¨ë“ˆì„ í†µí•´ ì§€ì—­ì  ì„¸ë¶€ ì‚¬í•­ê³¼ ì „ì—­ì  ì˜ë¯¸ ì •ë³´ë¥¼ ì •ë°€í•˜ê³  íš¨ìœ¨ì ìœ¼ë¡œ í†µí•©í•˜ì—¬ íŠ¹ì§• ë¶ˆì¼ì¹˜ ë¬¸ì œë¥¼ ì™„í™”í•©ë‹ˆë‹¤.
- 4. Progressive Pyramid Aggregation (PPA) ëª¨ë“ˆì„ ë„ì…í•˜ì—¬ ì „í†µì ì¸ ìŠ¤í‚µ ì—°ê²°ì„ ëŒ€ì²´í•˜ê³ , ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ íŠ¹ì§• í‘œí˜„ ëŠ¥ë ¥ì„ ê°•í™”í•˜ë©° ë…¸ì´ì¦ˆ ê°„ì„­ì„ ì–µì œí•©ë‹ˆë‹¤.
- 5. ì—´í•œ ê°œì˜ ê³µê°œ ë°ì´í„°ì…‹ ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì´ ê¸°ì¡´ ë¶„í•  ê¸°ìˆ ë³´ë‹¤ ë†’ì€ ì •í™•ì„±ê³¼ ê°•ì¸ì„±ì„ ë³´ì…ë‹ˆë‹¤.


---

*Generated on 2025-09-26 09:15:39*