---
keywords:
  - Large Language Model
  - Retrieval Augmented Generation
  - Sentence-level Attribution Framework
  - Source Attribution
category: cs.CL
publish_date: 2025-09-25
arxiv_id: 2505.12621
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-26T08:54:23.383222",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Retrieval Augmented Generation",
    "Sentence-level Attribution Framework",
    "Source Attribution"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Retrieval Augmented Generation": 0.9,
    "Sentence-level Attribution Framework": 0.8,
    "Source Attribution": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Large Language Model"
        ],
        "category": "broad_technical",
        "rationale": "This is a fundamental concept in the paper, linking to a broad technical category relevant to the field.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Retrieve-Augmented Generation",
        "canonical": "Retrieval Augmented Generation",
        "aliases": [
          "RAG"
        ],
        "category": "specific_connectable",
        "rationale": "A trending concept that is central to the proposed framework, enhancing connectivity with recent advancements.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.78,
        "link_intent_score": 0.9
      },
      {
        "surface": "Sentence-level Attribution Framework",
        "canonical": "Sentence-level Attribution Framework",
        "aliases": [
          "SAFE"
        ],
        "category": "unique_technical",
        "rationale": "A unique technical contribution of the paper, offering new insights into attribution methods.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "source attribution",
        "canonical": "Source Attribution",
        "aliases": [
          "attribution"
        ],
        "category": "specific_connectable",
        "rationale": "Key to understanding the paper's focus on reliability and verification in LLM outputs.",
        "novelty_score": 0.45,
        "connectivity_score": 0.82,
        "specificity_score": 0.72,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "method",
      "accuracy",
      "dataset"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Retrieve-Augmented Generation",
      "resolved_canonical": "Retrieval Augmented Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.78,
        "link_intent": 0.9
      }
    },
    {
      "candidate_surface": "Sentence-level Attribution Framework",
      "resolved_canonical": "Sentence-level Attribution Framework",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "source attribution",
      "resolved_canonical": "Source Attribution",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.82,
        "specificity": 0.72,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# SAFE: Improving LLM Systems using Sentence-Level In-generation Attribution

## 📋 메타데이터

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2505.12621.pdf)
**Category**: cs.CL
**Published**: 2025-09-25
**ArXiv ID**: [2505.12621](https://arxiv.org/abs/2505.12621)

## 🔗 유사한 논문
- [[2025-09-24/Safe-SAIL_ Towards a Fine-grained Safety Landscape of Large Language Models via Sparse Autoencoder Interpretation Framework_20250924|Safe-SAIL: Towards a Fine-grained Safety Landscape of Large Language Models via Sparse Autoencoder Interpretation Framework]] (85.0% similar)
- [[2025-09-18/Evaluating and Improving the Robustness of Security Attack Detectors Generated by LLMs_20250918|Evaluating and Improving the Robustness of Security Attack Detectors Generated by LLMs]] (84.0% similar)
- [[2025-09-23/Sugar-Coated Poison_ Benign Generation Unlocks LLM Jailbreaking_20250923|Sugar-Coated Poison: Benign Generation Unlocks LLM Jailbreaking]] (83.9% similar)
- [[2025-09-22/SABER_ Uncovering Vulnerabilities in Safety Alignment via Cross-Layer Residual Connection_20250922|SABER: Uncovering Vulnerabilities in Safety Alignment via Cross-Layer Residual Connection]] (83.8% similar)
- [[2025-09-22/Toxicity Red-Teaming_ Benchmarking LLM Safety in Singapore's Low-Resource Languages_20250922|Toxicity Red-Teaming: Benchmarking LLM Safety in Singapore's Low-Resource Languages]] (83.7% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Retrieval Augmented Generation|Retrieval Augmented Generation]], [[keywords/Source Attribution|Source Attribution]]
**⚡ Unique Technical**: [[keywords/Sentence-level Attribution Framework|Sentence-level Attribution Framework]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2505.12621v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) are increasingly applied in various science domains, yet their broader adoption remains constrained by a critical challenge: the lack of trustworthy, verifiable outputs. Current LLMs often generate answers without reliable source attribution, or worse, with incorrect attributions, posing a barrier to their use in scientific and high-stakes settings, where traceability and accountability are paramount. To be reliable, attribution systems require high accuracy for short-length attribution on retrieved data, i.e., attribution to a sentence within a document rather than the entire document. We propose SAFE, a Sentence-level A ttribution FramEwork for Retrieve-Augmented Generation (RAG) systems that attributes generated sentences during generation. This allows users to verify sentences as they read them and correct the model when the attribution indicates the generated text is not grounded in the documents, increasing the safety of LLM systems. This framework consists of two steps: predicting the required number of references for a sentence, and attributing the sentence. Our approach achieved 95% accuracy in the first step, which translated to 2.1\~6.0% improvements in the accuracy (normalized for maximum possible accuracy) of all attribution algorithms in our clean dataset, when compared to their top-1 accuracy. We also applied SAFE in real-world scenarios with documents containing hundreds to thousands of sentences. In these settings, SAFE reliably attributed sentences to their source documents, demonstrating that the method generalizes beyond controlled benchmarks. The SAFE framework and the training dataset are publicly available on GitHub.

## 📝 요약

대형 언어 모델(LLM)의 과학 분야 활용이 증가하고 있지만, 신뢰할 수 있는 출처 표기가 부족하여 널리 채택되지 못하고 있습니다. 이를 해결하기 위해, 우리는 문장 수준의 출처 표기 프레임워크인 SAFE를 제안합니다. SAFE는 생성된 문장에 대해 출처를 명확히 하여 사용자가 문장을 검증하고, 출처가 문서에 기반하지 않을 경우 수정할 수 있도록 합니다. 이 프레임워크는 문장에 필요한 참조 수를 예측하고, 문장을 출처에 연결하는 두 단계로 구성됩니다. 우리의 접근법은 첫 번째 단계에서 95%의 정확도를 달성했으며, 모든 출처 표기 알고리즘의 정확도를 2.1~6.0% 향상시켰습니다. SAFE는 실제 문서에도 적용되어 신뢰할 수 있는 출처 표기를 보장하며, GitHub에서 프레임워크와 데이터셋을 공개하고 있습니다.

## 🎯 주요 포인트

- 1. 대형 언어 모델(LLM)의 신뢰할 수 있는 출처 표기가 부족하여 과학 및 고위험 환경에서의 사용이 제한되고 있다.
- 2. SAFE는 문장 수준의 출처 표기를 통해 생성된 문장을 검증하고, 출처가 문서에 기반하지 않을 경우 수정할 수 있도록 한다.
- 3. SAFE 프레임워크는 문장에 필요한 참조 수를 예측하고, 문장을 출처에 연결하는 두 단계로 구성된다.
- 4. SAFE는 실제 환경에서도 문장을 정확히 출처 문서에 연결하여, 통제된 벤치마크를 넘어 일반화할 수 있음을 보여주었다.
- 5. SAFE 프레임워크와 학습 데이터셋은 GitHub에서 공개적으로 이용 가능하다.


---

*Generated on 2025-09-26 08:54:23*