---
keywords:
  - Large Language Model
  - Retrieval Augmented Generation
  - Sentence-level Attribution Framework
  - Source Attribution
category: cs.CL
publish_date: 2025-09-25
arxiv_id: 2505.12621
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-26T08:54:23.383222",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Retrieval Augmented Generation",
    "Sentence-level Attribution Framework",
    "Source Attribution"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Retrieval Augmented Generation": 0.9,
    "Sentence-level Attribution Framework": 0.8,
    "Source Attribution": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Large Language Model"
        ],
        "category": "broad_technical",
        "rationale": "This is a fundamental concept in the paper, linking to a broad technical category relevant to the field.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Retrieve-Augmented Generation",
        "canonical": "Retrieval Augmented Generation",
        "aliases": [
          "RAG"
        ],
        "category": "specific_connectable",
        "rationale": "A trending concept that is central to the proposed framework, enhancing connectivity with recent advancements.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.78,
        "link_intent_score": 0.9
      },
      {
        "surface": "Sentence-level Attribution Framework",
        "canonical": "Sentence-level Attribution Framework",
        "aliases": [
          "SAFE"
        ],
        "category": "unique_technical",
        "rationale": "A unique technical contribution of the paper, offering new insights into attribution methods.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "source attribution",
        "canonical": "Source Attribution",
        "aliases": [
          "attribution"
        ],
        "category": "specific_connectable",
        "rationale": "Key to understanding the paper's focus on reliability and verification in LLM outputs.",
        "novelty_score": 0.45,
        "connectivity_score": 0.82,
        "specificity_score": 0.72,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "method",
      "accuracy",
      "dataset"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Retrieve-Augmented Generation",
      "resolved_canonical": "Retrieval Augmented Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.78,
        "link_intent": 0.9
      }
    },
    {
      "candidate_surface": "Sentence-level Attribution Framework",
      "resolved_canonical": "Sentence-level Attribution Framework",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "source attribution",
      "resolved_canonical": "Source Attribution",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.82,
        "specificity": 0.72,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# SAFE: Improving LLM Systems using Sentence-Level In-generation Attribution

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2505.12621.pdf)
**Category**: cs.CL
**Published**: 2025-09-25
**ArXiv ID**: [2505.12621](https://arxiv.org/abs/2505.12621)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-24/Safe-SAIL_ Towards a Fine-grained Safety Landscape of Large Language Models via Sparse Autoencoder Interpretation Framework_20250924|Safe-SAIL: Towards a Fine-grained Safety Landscape of Large Language Models via Sparse Autoencoder Interpretation Framework]] (85.0% similar)
- [[2025-09-18/Evaluating and Improving the Robustness of Security Attack Detectors Generated by LLMs_20250918|Evaluating and Improving the Robustness of Security Attack Detectors Generated by LLMs]] (84.0% similar)
- [[2025-09-23/Sugar-Coated Poison_ Benign Generation Unlocks LLM Jailbreaking_20250923|Sugar-Coated Poison: Benign Generation Unlocks LLM Jailbreaking]] (83.9% similar)
- [[2025-09-22/SABER_ Uncovering Vulnerabilities in Safety Alignment via Cross-Layer Residual Connection_20250922|SABER: Uncovering Vulnerabilities in Safety Alignment via Cross-Layer Residual Connection]] (83.8% similar)
- [[2025-09-22/Toxicity Red-Teaming_ Benchmarking LLM Safety in Singapore's Low-Resource Languages_20250922|Toxicity Red-Teaming: Benchmarking LLM Safety in Singapore's Low-Resource Languages]] (83.7% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Retrieval Augmented Generation|Retrieval Augmented Generation]], [[keywords/Source Attribution|Source Attribution]]
**âš¡ Unique Technical**: [[keywords/Sentence-level Attribution Framework|Sentence-level Attribution Framework]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2505.12621v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) are increasingly applied in various science domains, yet their broader adoption remains constrained by a critical challenge: the lack of trustworthy, verifiable outputs. Current LLMs often generate answers without reliable source attribution, or worse, with incorrect attributions, posing a barrier to their use in scientific and high-stakes settings, where traceability and accountability are paramount. To be reliable, attribution systems require high accuracy for short-length attribution on retrieved data, i.e., attribution to a sentence within a document rather than the entire document. We propose SAFE, a Sentence-level A ttribution FramEwork for Retrieve-Augmented Generation (RAG) systems that attributes generated sentences during generation. This allows users to verify sentences as they read them and correct the model when the attribution indicates the generated text is not grounded in the documents, increasing the safety of LLM systems. This framework consists of two steps: predicting the required number of references for a sentence, and attributing the sentence. Our approach achieved 95% accuracy in the first step, which translated to 2.1\~6.0% improvements in the accuracy (normalized for maximum possible accuracy) of all attribution algorithms in our clean dataset, when compared to their top-1 accuracy. We also applied SAFE in real-world scenarios with documents containing hundreds to thousands of sentences. In these settings, SAFE reliably attributed sentences to their source documents, demonstrating that the method generalizes beyond controlled benchmarks. The SAFE framework and the training dataset are publicly available on GitHub.

## ğŸ“ ìš”ì•½

ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ê³¼í•™ ë¶„ì•¼ í™œìš©ì´ ì¦ê°€í•˜ê³  ìˆì§€ë§Œ, ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¶œì²˜ í‘œê¸°ê°€ ë¶€ì¡±í•˜ì—¬ ë„ë¦¬ ì±„íƒë˜ì§€ ëª»í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ë¬¸ì¥ ìˆ˜ì¤€ì˜ ì¶œì²˜ í‘œê¸° í”„ë ˆì„ì›Œí¬ì¸ SAFEë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. SAFEëŠ” ìƒì„±ëœ ë¬¸ì¥ì— ëŒ€í•´ ì¶œì²˜ë¥¼ ëª…í™•íˆ í•˜ì—¬ ì‚¬ìš©ìê°€ ë¬¸ì¥ì„ ê²€ì¦í•˜ê³ , ì¶œì²˜ê°€ ë¬¸ì„œì— ê¸°ë°˜í•˜ì§€ ì•Šì„ ê²½ìš° ìˆ˜ì •í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ë¬¸ì¥ì— í•„ìš”í•œ ì°¸ì¡° ìˆ˜ë¥¼ ì˜ˆì¸¡í•˜ê³ , ë¬¸ì¥ì„ ì¶œì²˜ì— ì—°ê²°í•˜ëŠ” ë‘ ë‹¨ê³„ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì ‘ê·¼ë²•ì€ ì²« ë²ˆì§¸ ë‹¨ê³„ì—ì„œ 95%ì˜ ì •í™•ë„ë¥¼ ë‹¬ì„±í–ˆìœ¼ë©°, ëª¨ë“  ì¶œì²˜ í‘œê¸° ì•Œê³ ë¦¬ì¦˜ì˜ ì •í™•ë„ë¥¼ 2.1~6.0% í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤. SAFEëŠ” ì‹¤ì œ ë¬¸ì„œì—ë„ ì ìš©ë˜ì–´ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¶œì²˜ í‘œê¸°ë¥¼ ë³´ì¥í•˜ë©°, GitHubì—ì„œ í”„ë ˆì„ì›Œí¬ì™€ ë°ì´í„°ì…‹ì„ ê³µê°œí•˜ê³  ìˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¶œì²˜ í‘œê¸°ê°€ ë¶€ì¡±í•˜ì—¬ ê³¼í•™ ë° ê³ ìœ„í—˜ í™˜ê²½ì—ì„œì˜ ì‚¬ìš©ì´ ì œí•œë˜ê³  ìˆë‹¤.
- 2. SAFEëŠ” ë¬¸ì¥ ìˆ˜ì¤€ì˜ ì¶œì²˜ í‘œê¸°ë¥¼ í†µí•´ ìƒì„±ëœ ë¬¸ì¥ì„ ê²€ì¦í•˜ê³ , ì¶œì²˜ê°€ ë¬¸ì„œì— ê¸°ë°˜í•˜ì§€ ì•Šì„ ê²½ìš° ìˆ˜ì •í•  ìˆ˜ ìˆë„ë¡ í•œë‹¤.
- 3. SAFE í”„ë ˆì„ì›Œí¬ëŠ” ë¬¸ì¥ì— í•„ìš”í•œ ì°¸ì¡° ìˆ˜ë¥¼ ì˜ˆì¸¡í•˜ê³ , ë¬¸ì¥ì„ ì¶œì²˜ì— ì—°ê²°í•˜ëŠ” ë‘ ë‹¨ê³„ë¡œ êµ¬ì„±ëœë‹¤.
- 4. SAFEëŠ” ì‹¤ì œ í™˜ê²½ì—ì„œë„ ë¬¸ì¥ì„ ì •í™•íˆ ì¶œì²˜ ë¬¸ì„œì— ì—°ê²°í•˜ì—¬, í†µì œëœ ë²¤ì¹˜ë§ˆí¬ë¥¼ ë„˜ì–´ ì¼ë°˜í™”í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì£¼ì—ˆë‹¤.
- 5. SAFE í”„ë ˆì„ì›Œí¬ì™€ í•™ìŠµ ë°ì´í„°ì…‹ì€ GitHubì—ì„œ ê³µê°œì ìœ¼ë¡œ ì´ìš© ê°€ëŠ¥í•˜ë‹¤.


---

*Generated on 2025-09-26 08:54:23*