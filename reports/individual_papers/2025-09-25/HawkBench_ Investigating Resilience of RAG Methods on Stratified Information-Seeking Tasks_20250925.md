---
keywords:
  - Retrieval Augmented Generation
  - HawkBench
  - Information-Seeking Tasks
  - Multi-Domain Corpora
  - Dynamic Task Strategies
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2502.13465
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T16:19:37.964656",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Retrieval Augmented Generation",
    "HawkBench",
    "Information-Seeking Tasks",
    "Multi-Domain Corpora",
    "Dynamic Task Strategies"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Retrieval Augmented Generation": 0.9,
    "HawkBench": 0.85,
    "Information-Seeking Tasks": 0.8,
    "Multi-Domain Corpora": 0.77,
    "Dynamic Task Strategies": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "RAG",
        "canonical": "Retrieval Augmented Generation",
        "aliases": [
          "RAG methods"
        ],
        "category": "specific_connectable",
        "rationale": "RAG is central to the paper's focus on evaluating information-seeking tasks, making it a key concept for linking.",
        "novelty_score": 0.45,
        "connectivity_score": 0.85,
        "specificity_score": 0.88,
        "link_intent_score": 0.9
      },
      {
        "surface": "HawkBench",
        "canonical": "HawkBench",
        "aliases": [
          "HawkBench benchmark"
        ],
        "category": "unique_technical",
        "rationale": "HawkBench is a unique benchmark introduced in the paper, essential for understanding the evaluation of RAG methods.",
        "novelty_score": 0.95,
        "connectivity_score": 0.7,
        "specificity_score": 0.92,
        "link_intent_score": 0.85
      },
      {
        "surface": "information-seeking tasks",
        "canonical": "Information-Seeking Tasks",
        "aliases": [
          "information-seeking scenarios"
        ],
        "category": "broad_technical",
        "rationale": "These tasks are a fundamental aspect of the study, providing context for the evaluation of RAG methods.",
        "novelty_score": 0.4,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "multi-domain corpora",
        "canonical": "Multi-Domain Corpora",
        "aliases": [
          "multi-domain datasets"
        ],
        "category": "specific_connectable",
        "rationale": "The integration of multi-domain corpora is crucial for understanding the paper's approach to mitigating corpus bias.",
        "novelty_score": 0.55,
        "connectivity_score": 0.78,
        "specificity_score": 0.82,
        "link_intent_score": 0.77
      },
      {
        "surface": "dynamic task strategies",
        "canonical": "Dynamic Task Strategies",
        "aliases": [
          "adaptive task strategies"
        ],
        "category": "unique_technical",
        "rationale": "Dynamic task strategies are highlighted as necessary for improving RAG generalizability, making them a key concept.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "evaluation"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "RAG",
      "resolved_canonical": "Retrieval Augmented Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.85,
        "specificity": 0.88,
        "link_intent": 0.9
      }
    },
    {
      "candidate_surface": "HawkBench",
      "resolved_canonical": "HawkBench",
      "decision": "linked",
      "scores": {
        "novelty": 0.95,
        "connectivity": 0.7,
        "specificity": 0.92,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "information-seeking tasks",
      "resolved_canonical": "Information-Seeking Tasks",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "multi-domain corpora",
      "resolved_canonical": "Multi-Domain Corpora",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.78,
        "specificity": 0.82,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "dynamic task strategies",
      "resolved_canonical": "Dynamic Task Strategies",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# HawkBench: Investigating Resilience of RAG Methods on Stratified Information-Seeking Tasks

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2502.13465.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2502.13465](https://arxiv.org/abs/2502.13465)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Measuring Risk of Bias in Biomedical Reports_ The RoBBR Benchmark_20250923|Measuring Risk of Bias in Biomedical Reports: The RoBBR Benchmark]] (83.8% similar)
- [[2025-09-25/FHIR-AgentBench_ Benchmarking LLM Agents for Realistic Interoperable EHR Question Answering_20250925|FHIR-AgentBench: Benchmarking LLM Agents for Realistic Interoperable EHR Question Answering]] (82.8% similar)
- [[2025-09-19/Engineering RAG Systems for Real-World Applications_ Design, Development, and Evaluation_20250919|Engineering RAG Systems for Real-World Applications: Design, Development, and Evaluation]] (82.5% similar)
- [[2025-09-19/Enhancing Retrieval Augmentation via Adversarial Collaboration_20250919|Enhancing Retrieval Augmentation via Adversarial Collaboration]] (82.1% similar)
- [[2025-09-24/SIRAG_ Towards Stable and Interpretable RAG with A Process-Supervised Multi-Agent Framework_20250924|SIRAG: Towards Stable and Interpretable RAG with A Process-Supervised Multi-Agent Framework]] (81.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Information-Seeking Tasks|Information-Seeking Tasks]]
**ğŸ”— Specific Connectable**: [[keywords/Retrieval Augmented Generation|Retrieval Augmented Generation]], [[keywords/Multi-Domain Corpora|Multi-Domain Corpora]]
**âš¡ Unique Technical**: [[keywords/HawkBench|HawkBench]], [[keywords/Dynamic Task Strategies|Dynamic Task Strategies]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2502.13465v2 Announce Type: replace-cross 
Abstract: In real-world information-seeking scenarios, users have dynamic and diverse needs, requiring RAG systems to demonstrate adaptable resilience. To comprehensively evaluate the resilience of current RAG methods, we introduce HawkBench, a human-labeled, multi-domain benchmark designed to rigorously assess RAG performance across categorized task types. By stratifying tasks based on information-seeking behaviors, HawkBench provides a systematic evaluation of how well RAG systems adapt to diverse user needs.
  Unlike existing benchmarks, which focus primarily on specific task types (mostly factoid queries) and rely on varying knowledge bases, HawkBench offers: (1) systematic task stratification to cover a broad range of query types, including both factoid and rationale queries, (2) integration of multi-domain corpora across all task types to mitigate corpus bias, and (3) rigorous annotation for high-quality evaluation.
  HawkBench includes 1,600 high-quality test samples, evenly distributed across domains and task types. Using this benchmark, we evaluate representative RAG methods, analyzing their performance in terms of answer quality and response latency. Our findings highlight the need for dynamic task strategies that integrate decision-making, query interpretation, and global knowledge understanding to improve RAG generalizability. We believe HawkBench serves as a pivotal benchmark for advancing the resilience of RAG methods and their ability to achieve general-purpose information seeking.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì •ë³´íƒìƒ‰ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì‚¬ìš©ìì˜ ë‹¤ì–‘í•œ ìš”êµ¬ì— ì ì‘í•  ìˆ˜ ìˆëŠ” RAG(ì •ë³´ ê²€ìƒ‰ ë° ìƒì„±) ì‹œìŠ¤í…œì˜ íšŒë³µë ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•´ HawkBenchë¼ëŠ” ë²¤ì¹˜ë§ˆí¬ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. HawkBenchëŠ” ì¸ê°„ì´ ë¼ë²¨ë§í•œ ë‹¤ì¤‘ ë„ë©”ì¸ ë²¤ì¹˜ë§ˆí¬ë¡œ, ë‹¤ì–‘í•œ ì •ë³´íƒìƒ‰ í–‰ë™ì— ê¸°ë°˜í•œ ì²´ê³„ì ì¸ ê³¼ì œ ë¶„ë¥˜ë¥¼ í†µí•´ RAG ì‹œìŠ¤í…œì˜ ì ì‘ë ¥ì„ í‰ê°€í•©ë‹ˆë‹¤. ê¸°ì¡´ ë²¤ì¹˜ë§ˆí¬ì™€ ë‹¬ë¦¬, HawkBenchëŠ” ì‚¬ì‹¤ ì§ˆì˜ì™€ ê·¼ê±° ì§ˆì˜ë¥¼ í¬í•¨í•œ ë‹¤ì–‘í•œ ì§ˆì˜ ìœ í˜•ì„ ë‹¤ë£¨ê³ , ë‹¤ì¤‘ ë„ë©”ì¸ ì½”í¼ìŠ¤ë¥¼ í†µí•©í•˜ì—¬ í¸í–¥ì„ ì¤„ì´ë©°, ì—„ê²©í•œ ì£¼ì„ì„ í†µí•´ í‰ê°€ì˜ ì§ˆì„ ë†’ì…ë‹ˆë‹¤. 1,600ê°œì˜ ê³ í’ˆì§ˆ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œì„ í¬í•¨í•˜ë©°, RAG ë°©ë²•ì˜ ì‘ë‹µ í’ˆì§ˆê³¼ ì§€ì—° ì‹œê°„ì„ ë¶„ì„í•©ë‹ˆë‹¤. ì—°êµ¬ ê²°ê³¼, RAG ì‹œìŠ¤í…œì˜ ì¼ë°˜í™” ê°€ëŠ¥ì„±ì„ ë†’ì´ê¸° ìœ„í•´ ì˜ì‚¬ê²°ì •, ì§ˆì˜ í•´ì„, ì „ë°˜ì ì¸ ì§€ì‹ ì´í•´ë¥¼ í†µí•©í•œ ë™ì  ê³¼ì œ ì „ëµì˜ í•„ìš”ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤. HawkBenchëŠ” RAG ë°©ë²•ì˜ íšŒë³µë ¥ í–¥ìƒì— ì¤‘ìš”í•œ ê¸°ì—¬ë¥¼ í•  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. HawkBenchëŠ” ë‹¤ì–‘í•œ ì‚¬ìš©ì ìš”êµ¬ì— ì ì‘í•˜ëŠ” RAG ì‹œìŠ¤í…œì˜ íšŒë³µë ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•´ ì„¤ê³„ëœ ì¸ê°„ ë¼ë²¨ë§ ê¸°ë°˜ì˜ ë‹¤ì¤‘ ë„ë©”ì¸ ë²¤ì¹˜ë§ˆí¬ì…ë‹ˆë‹¤.
- 2. HawkBenchëŠ” ì •ë³´ íƒìƒ‰ í–‰ë™ì— ë”°ë¼ ì‘ì—…ì„ ê³„ì¸µí™”í•˜ì—¬ RAG ì‹œìŠ¤í…œì´ ë‹¤ì–‘í•œ ì¿¼ë¦¬ ìœ í˜•ì— ì–¼ë§ˆë‚˜ ì˜ ì ì‘í•˜ëŠ”ì§€ë¥¼ ì²´ê³„ì ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤.
- 3. ì´ ë²¤ì¹˜ë§ˆí¬ëŠ” ì‚¬ì‹¤ì  ì¿¼ë¦¬ì™€ ë…¼ë¦¬ì  ì¿¼ë¦¬ë¥¼ í¬í•¨í•œ ê´‘ë²”ìœ„í•œ ì¿¼ë¦¬ ìœ í˜•ì„ í¬ê´„í•˜ë„ë¡ ì‘ì—…ì„ ì²´ê³„ì ìœ¼ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.
- 4. HawkBenchëŠ” ëª¨ë“  ì‘ì—… ìœ í˜•ì— ê±¸ì³ ë‹¤ì¤‘ ë„ë©”ì¸ ì½”í¼ìŠ¤ë¥¼ í†µí•©í•˜ì—¬ ì½”í¼ìŠ¤ í¸í–¥ì„ ì™„í™”í•˜ê³ , ì—„ê²©í•œ ì£¼ì„ì„ í†µí•´ ê³ í’ˆì§ˆ í‰ê°€ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
- 5. ì—°êµ¬ ê²°ê³¼ëŠ” RAG ì‹œìŠ¤í…œì˜ ì¼ë°˜í™” ê°€ëŠ¥ì„±ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ì˜ì‚¬ ê²°ì •, ì¿¼ë¦¬ í•´ì„ ë° ê¸€ë¡œë²Œ ì§€ì‹ ì´í•´ë¥¼ í†µí•©í•˜ëŠ” ë™ì  ì‘ì—… ì „ëµì˜ í•„ìš”ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-25 16:19:37*