---
keywords:
  - Few-Shot Learning
  - Zero-Shot Learning
  - Multimodal Learning
  - MMSE-Proxy Prompting
  - Reasoning-augmented Prompting
category: cs.LG
publish_date: 2025-09-25
arxiv_id: 2509.19926
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T16:42:32.178612",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Few-Shot Learning",
    "Zero-Shot Learning",
    "Multimodal Learning",
    "MMSE-Proxy Prompting",
    "Reasoning-augmented Prompting"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Few-Shot Learning": 0.78,
    "Zero-Shot Learning": 0.77,
    "Multimodal Learning": 0.79,
    "MMSE-Proxy Prompting": 0.72,
    "Reasoning-augmented Prompting": 0.71
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Few-Shot Prompting",
        "canonical": "Few-Shot Learning",
        "aliases": [
          "Few-Shot Prompting"
        ],
        "category": "specific_connectable",
        "rationale": "Few-Shot Learning is a trending concept that enhances model adaptability with minimal data, relevant to the study's methodology.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.72,
        "link_intent_score": 0.78
      },
      {
        "surface": "Zero-Shot Prompting",
        "canonical": "Zero-Shot Learning",
        "aliases": [
          "Zero-Shot Prompting"
        ],
        "category": "specific_connectable",
        "rationale": "Zero-Shot Learning is a key concept in leveraging models without task-specific training, aligning with the paper's approach.",
        "novelty_score": 0.58,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.77
      },
      {
        "surface": "Multimodal LLM",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal Language Model"
        ],
        "category": "specific_connectable",
        "rationale": "Multimodal Learning is crucial for integrating diverse data types, which is central to the paper's methodology.",
        "novelty_score": 0.6,
        "connectivity_score": 0.87,
        "specificity_score": 0.75,
        "link_intent_score": 0.79
      },
      {
        "surface": "MMSE-Proxy Prompting",
        "canonical": "MMSE-Proxy Prompting",
        "aliases": [
          "MMSE Anchored Prompting"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel technique specific to the study, linking cognitive assessment with model prompting.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.72
      },
      {
        "surface": "Reasoning-augmented Prompting",
        "canonical": "Reasoning-augmented Prompting",
        "aliases": [
          "Reasoning Enhanced Prompting"
        ],
        "category": "unique_technical",
        "rationale": "This method enhances interpretability and aligns with the study's focus on reasoning capabilities.",
        "novelty_score": 0.7,
        "connectivity_score": 0.68,
        "specificity_score": 0.78,
        "link_intent_score": 0.71
      }
    ],
    "ban_list_suggestions": [
      "Prompting",
      "Accuracy",
      "AUC"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Few-Shot Prompting",
      "resolved_canonical": "Few-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.72,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Zero-Shot Prompting",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Multimodal LLM",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.87,
        "specificity": 0.75,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "MMSE-Proxy Prompting",
      "resolved_canonical": "MMSE-Proxy Prompting",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "Reasoning-augmented Prompting",
      "resolved_canonical": "Reasoning-augmented Prompting",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.68,
        "specificity": 0.78,
        "link_intent": 0.71
      }
    }
  ]
}
-->

# MMSE-Calibrated Few-Shot Prompting for Alzheimer's Detection

## 📋 메타데이터

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19926.pdf)
**Category**: cs.LG
**Published**: 2025-09-25
**ArXiv ID**: [2509.19926](https://arxiv.org/abs/2509.19926)

## 🔗 유사한 논문
- [[2025-09-19/PMPO_ Probabilistic Metric Prompt Optimization for Small and Large Language Models_20250919|PMPO: Probabilistic Metric Prompt Optimization for Small and Large Language Models]] (83.6% similar)
- [[2025-09-25/PromptCoT 2.0_ Scaling Prompt Synthesis for Large Language Model Reasoning_20250925|PromptCoT 2.0: Scaling Prompt Synthesis for Large Language Model Reasoning]] (81.7% similar)
- [[2025-09-23/QA-prompting_ Improving Summarization with Large Language Models using Question-Answering_20250923|QA-prompting: Improving Summarization with Large Language Models using Question-Answering]] (81.6% similar)
- [[2025-09-22/A Layered Multi-Expert Framework for Long-Context Mental Health Assessments_20250922|A Layered Multi-Expert Framework for Long-Context Mental Health Assessments]] (81.4% similar)
- [[2025-09-19/Calibration-Aware Prompt Learning for Medical Vision-Language Models_20250919|Calibration-Aware Prompt Learning for Medical Vision-Language Models]] (81.4% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Few-Shot Learning|Few-Shot Learning]], [[keywords/Zero-Shot Learning|Zero-Shot Learning]], [[keywords/Multimodal Learning|Multimodal Learning]]
**⚡ Unique Technical**: [[keywords/MMSE-Proxy Prompting|MMSE-Proxy Prompting]], [[keywords/Reasoning-augmented Prompting|Reasoning-augmented Prompting]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.19926v1 Announce Type: new 
Abstract: Prompting large language models is a training-free method for detecting Alzheimer's disease from speech transcripts. Using the ADReSS dataset, we revisit zero-shot prompting and study few-shot prompting with a class-balanced protocol using nested interleave and a strict schema, sweeping up to 20 examples per class. We evaluate two variants achieving state-of-the-art prompting results. (i) MMSE-Proxy Prompting: each few-shot example carries a probability anchored to Mini-Mental State Examination bands via a deterministic mapping, enabling AUC computing; this reaches 0.82 accuracy and 0.86 AUC (ii) Reasoning-augmented Prompting: few-shot examples pool is generated with a multimodal LLM (GPT-5) that takes as input the Cookie Theft image, transcript, and MMSE to output a reasoning and MMSE-aligned probability; evaluation remains transcript-only and reaches 0.82 accuracy and 0.83 AUC. To our knowledge, this is the first ADReSS study to anchor elicited probabilities to MMSE and to use multimodal construction to improve interpretability.

## 📝 요약

이 논문은 대형 언어 모델을 활용하여 훈련 없이도 음성 전사에서 알츠하이머 병을 감지하는 방법을 제시합니다. ADReSS 데이터셋을 사용하여 제로샷 및 퓨샷 프롬팅을 연구하였으며, 클래스 균형 프로토콜을 통해 최대 20개의 예시를 사용했습니다. 두 가지 주요 방법론을 평가했으며, 첫 번째는 MMSE-Proxy 프롬팅으로, MMSE 밴드에 기반한 확률을 부여하여 AUC를 계산하며 0.82의 정확도와 0.86의 AUC를 달성했습니다. 두 번째는 Reasoning-augmented 프롬팅으로, GPT-5를 사용하여 다중 모달 입력을 통해 추론과 MMSE 정렬 확률을 생성하여 0.82의 정확도와 0.83의 AUC를 기록했습니다. 이는 MMSE에 기반한 확률을 도입하고 다중 모달 구성을 통해 해석 가능성을 향상시킨 최초의 연구입니다.

## 🎯 주요 포인트

- 1. 대형 언어 모델을 활용한 프롬프트 기법은 훈련 없이도 음성 전사본에서 알츠하이머병을 감지할 수 있는 방법이다.
- 2. ADReSS 데이터셋을 사용하여 제로샷 프롬프트와 클래스 균형 프로토콜을 통한 퓨샷 프롬프트를 연구하였다.
- 3. MMSE-Proxy 프롬프트는 Mini-Mental State Examination 밴드에 확률을 연결하여 AUC를 계산하며, 0.82의 정확도와 0.86의 AUC를 달성하였다.
- 4. Reasoning-augmented 프롬프트는 멀티모달 LLM을 사용하여 추론 및 MMSE 정렬 확률을 생성하며, 0.82의 정확도와 0.83의 AUC를 기록하였다.
- 5. 본 연구는 ADReSS 연구 중 최초로 MMSE에 확률을 연결하고 멀티모달 구성을 통해 해석 가능성을 향상시켰다.


---

*Generated on 2025-09-25 16:42:32*