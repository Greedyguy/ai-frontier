---
keywords:
  - Large Language Model
  - Model Merging
  - Instruction Fine-Tuning
  - Linguistic Competence
category: cs.CL
publish_date: 2025-09-25
arxiv_id: 2509.19476
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-26T08:42:33.051971",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Model Merging",
    "Instruction Fine-Tuning",
    "Linguistic Competence"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Model Merging": 0.88,
    "Instruction Fine-Tuning": 0.82,
    "Linguistic Competence": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "language models",
        "canonical": "Large Language Model",
        "aliases": [
          "LM",
          "language model"
        ],
        "category": "broad_technical",
        "rationale": "Connects to a broad range of topics in NLP and model merging discussions.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.5,
        "link_intent_score": 0.85
      },
      {
        "surface": "model merging",
        "canonical": "Model Merging",
        "aliases": [
          "merging methods",
          "merge models"
        ],
        "category": "unique_technical",
        "rationale": "Central to the paper's focus, offering insights into combining model capabilities.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.88
      },
      {
        "surface": "instruction fine-tuned",
        "canonical": "Instruction Fine-Tuning",
        "aliases": [
          "fine-tuned instructions"
        ],
        "category": "specific_connectable",
        "rationale": "Relevant for understanding model adaptation techniques.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.82
      },
      {
        "surface": "linguistic competence",
        "canonical": "Linguistic Competence",
        "aliases": [
          "language competence"
        ],
        "category": "specific_connectable",
        "rationale": "Highlights the internal evaluation aspect of language models.",
        "novelty_score": 0.6,
        "connectivity_score": 0.7,
        "specificity_score": 0.75,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "behavior",
      "evaluation",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "language models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.5,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "model merging",
      "resolved_canonical": "Model Merging",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "instruction fine-tuned",
      "resolved_canonical": "Instruction Fine-Tuning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "linguistic competence",
      "resolved_canonical": "Linguistic Competence",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.7,
        "specificity": 0.75,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# A Pipeline to Assess Merging Methods via Behavior and Internals

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19476.pdf)
**Category**: cs.CL
**Published**: 2025-09-25
**ArXiv ID**: [2509.19476](https://arxiv.org/abs/2509.19476)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-24/OptMerge_ Unifying Multimodal LLM Capabilities and Modalities via Model Merging_20250924|OptMerge: Unifying Multimodal LLM Capabilities and Modalities via Model Merging]] (88.4% similar)
- [[2025-09-24/Exploring Model Kinship for Merging Large Language Models_20250924|Exploring Model Kinship for Merging Large Language Models]] (88.1% similar)
- [[2025-09-23/AIMMerging_ Adaptive Iterative Model Merging Using Training Trajectories for Language Model Continual Learning_20250923|AIMMerging: Adaptive Iterative Model Merging Using Training Trajectories for Language Model Continual Learning]] (85.1% similar)
- [[2025-09-18/FroM_ Frobenius Norm-Based Data-Free Adaptive Model Merging_20250918|FroM: Frobenius Norm-Based Data-Free Adaptive Model Merging]] (83.0% similar)
- [[2025-09-19/Superpose Task-specific Features for Model Merging_20250919|Superpose Task-specific Features for Model Merging]] (82.9% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Instruction Fine-Tuning|Instruction Fine-Tuning]], [[keywords/Linguistic Competence|Linguistic Competence]]
**âš¡ Unique Technical**: [[keywords/Model Merging|Model Merging]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19476v1 Announce Type: new 
Abstract: Merging methods combine the weights of multiple language models (LMs) to leverage their capacities, such as for domain adaptation. While existing studies investigate merged models from a solely behavioral perspective, we offer the first comprehensive view by assessing and connecting their behavior and internals. We present a novel evaluation pipeline that first merges multiple parent LMs, and then evaluates the merged models in comparison to the initial ones based on their behavior on downstream tasks, like MMLU, and the internal encoded linguistic competence. We showcase this pipeline by assessing the merging of instruction fine-tuned with math- and code-adapted LMs from the Qwen2.5 family. Our results show that merging methods impacts behavior and internals differently. While the performance of merged models is typically between that of the two parent models, their encoded information about linguistic phenomena, particularly in morphology and syntax, can surpass the parent models. Moreover, we find weak ranking correlation between this behavior and internal evaluation. With our pipeline and initial results, we emphasize the need for more comprehensive evaluations of model merging methods to gain a faithful understanding of their capabilities and reliability, beyond potential superficial behavioral advances.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì—¬ëŸ¬ ì–¸ì–´ ëª¨ë¸(LM)ì˜ ê°€ì¤‘ì¹˜ë¥¼ ê²°í•©í•˜ì—¬ ë„ë©”ì¸ ì ì‘ ë“±ì˜ ìš©ë„ë¡œ í™œìš©í•˜ëŠ” ë³‘í•© ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤. ê¸°ì¡´ ì—°êµ¬ë“¤ì´ ì£¼ë¡œ ëª¨ë¸ì˜ í–‰ë™ì  ì¸¡ë©´ì— ì´ˆì ì„ ë§ì¶˜ ë°˜ë©´, ë³¸ ì—°êµ¬ëŠ” í–‰ë™ê³¼ ë‚´ë¶€ êµ¬ì¡°ë¥¼ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤. ìƒˆë¡œìš´ í‰ê°€ íŒŒì´í”„ë¼ì¸ì„ ì œì•ˆí•˜ì—¬, ì—¬ëŸ¬ ë¶€ëª¨ LMsë¥¼ ë³‘í•©í•œ í›„, MMLUì™€ ê°™ì€ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—…ì—ì„œì˜ í–‰ë™ê³¼ ë‚´ë¶€ ì–¸ì–´ ëŠ¥ë ¥ì„ ë¹„êµ í‰ê°€í•©ë‹ˆë‹¤. Qwen2.5 ê³„ì—´ì˜ ìˆ˜í•™ ë° ì½”ë“œ ì ì‘ LMsì™€ì˜ ë³‘í•©ì„ í†µí•´ ì´ íŒŒì´í”„ë¼ì¸ì„ ì‹œì—°í•©ë‹ˆë‹¤. ê²°ê³¼ì ìœ¼ë¡œ ë³‘í•©ëœ ëª¨ë¸ì˜ ì„±ëŠ¥ì€ ì¼ë°˜ì ìœ¼ë¡œ ë¶€ëª¨ ëª¨ë¸ ì‚¬ì´ì— ìœ„ì¹˜í•˜ì§€ë§Œ, í˜•íƒœë¡ ê³¼ êµ¬ë¬¸ë¡  ê°™ì€ ì–¸ì–´ í˜„ìƒì— ëŒ€í•œ ì •ë³´ëŠ” ë¶€ëª¨ ëª¨ë¸ì„ ëŠ¥ê°€í•  ìˆ˜ ìˆìŒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, í–‰ë™ê³¼ ë‚´ë¶€ í‰ê°€ ê°„ì˜ ìƒê´€ê´€ê³„ëŠ” ì•½í•˜ë‹¤ëŠ” ê²ƒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ê²°ê³¼ëŠ” ëª¨ë¸ ë³‘í•© ë°©ë²•ì˜ ëŠ¥ë ¥ê³¼ ì‹ ë¢°ì„±ì„ ë³´ë‹¤ ì¶©ì‹¤íˆ ì´í•´í•˜ê¸° ìœ„í•´ í¬ê´„ì ì¸ í‰ê°€ì˜ í•„ìš”ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë³‘í•© ë°©ë²•ì€ ì—¬ëŸ¬ ì–¸ì–´ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ ê²°í•©í•˜ì—¬ ë„ë©”ì¸ ì ì‘ê³¼ ê°™ì€ ê¸°ëŠ¥ì„ í™œìš©í•©ë‹ˆë‹¤.
- 2. ë³¸ ì—°êµ¬ëŠ” ë³‘í•©ëœ ëª¨ë¸ì˜ í–‰ë™ê³¼ ë‚´ë¶€ êµ¬ì¡°ë¥¼ í‰ê°€í•˜ê³  ì—°ê²°í•˜ì—¬ ì¢…í•©ì ì¸ ê´€ì ì„ ì œê³µí•©ë‹ˆë‹¤.
- 3. ì œì•ˆëœ í‰ê°€ íŒŒì´í”„ë¼ì¸ì€ ì—¬ëŸ¬ ë¶€ëª¨ ì–¸ì–´ ëª¨ë¸ì„ ë³‘í•©í•˜ê³ , ë³‘í•©ëœ ëª¨ë¸ì„ ì´ˆê¸° ëª¨ë¸ê³¼ ë¹„êµí•˜ì—¬ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—…ì—ì„œì˜ í–‰ë™ê³¼ ë‚´ë¶€ ì–¸ì–´ ëŠ¥ë ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.
- 4. ë³‘í•©ëœ ëª¨ë¸ì˜ ì„±ëŠ¥ì€ ì¼ë°˜ì ìœ¼ë¡œ ë‘ ë¶€ëª¨ ëª¨ë¸ì˜ ì„±ëŠ¥ ì‚¬ì´ì— ìœ„ì¹˜í•˜ì§€ë§Œ, í˜•íƒœë¡  ë° êµ¬ë¬¸ë¡ ê³¼ ê°™ì€ ì–¸ì–´ í˜„ìƒì— ëŒ€í•œ ì •ë³´ëŠ” ë¶€ëª¨ ëª¨ë¸ì„ ëŠ¥ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- 5. ë³‘í•© ë°©ë²•ì— ëŒ€í•œ ë” í¬ê´„ì ì¸ í‰ê°€ê°€ í•„ìš”í•˜ë©°, ì´ëŠ” ëª¨ë¸ì˜ ê¸°ëŠ¥ê³¼ ì‹ ë¢°ì„±ì„ ì´í•´í•˜ëŠ” ë° ì¤‘ìš”í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-26 08:42:33*