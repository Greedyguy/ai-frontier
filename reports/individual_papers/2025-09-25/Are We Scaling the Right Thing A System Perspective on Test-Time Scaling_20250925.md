---
keywords:
  - Test-time Scaling
  - Large Language Model
  - Tensor Parallelism
  - Speculative Decoding
  - System-driven Perspective
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2509.19645
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T15:40:44.899159",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Test-time Scaling",
    "Large Language Model",
    "Tensor Parallelism",
    "Speculative Decoding",
    "System-driven Perspective"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Test-time Scaling": 0.78,
    "Large Language Model": 0.85,
    "Tensor Parallelism": 0.72,
    "Speculative Decoding": 0.74,
    "System-driven Perspective": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Test-time scaling",
        "canonical": "Test-time Scaling",
        "aliases": [
          "TTS"
        ],
        "category": "unique_technical",
        "rationale": "Test-time scaling is a novel concept focusing on optimizing inference time performance, which is crucial for linking system performance discussions.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.82,
        "link_intent_score": 0.78
      },
      {
        "surface": "Large language models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "Large language models are central to the discussion of scaling and optimization, providing a strong link to existing research in language processing.",
        "novelty_score": 0.4,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Tensor parallelism",
        "canonical": "Tensor Parallelism",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Tensor parallelism is a specific optimization technique relevant to scaling discussions, enhancing connectivity with parallel computing research.",
        "novelty_score": 0.58,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.72
      },
      {
        "surface": "Speculative decoding",
        "canonical": "Speculative Decoding",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Speculative decoding is an emerging technique in model inference, offering new insights into efficiency improvements.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.78,
        "link_intent_score": 0.74
      },
      {
        "surface": "System-driven perspective",
        "canonical": "System-driven Perspective",
        "aliases": [
          "System Perspective"
        ],
        "category": "unique_technical",
        "rationale": "A system-driven perspective introduces a holistic view on optimization, linking to broader system performance evaluations.",
        "novelty_score": 0.68,
        "connectivity_score": 0.6,
        "specificity_score": 0.72,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "compute-optimal",
      "system-optimal",
      "paradigm shift"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Test-time scaling",
      "resolved_canonical": "Test-time Scaling",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.82,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Large language models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Tensor parallelism",
      "resolved_canonical": "Tensor Parallelism",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "Speculative decoding",
      "resolved_canonical": "Speculative Decoding",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.78,
        "link_intent": 0.74
      }
    },
    {
      "candidate_surface": "System-driven perspective",
      "resolved_canonical": "System-driven Perspective",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.6,
        "specificity": 0.72,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# Are We Scaling the Right Thing? A System Perspective on Test-Time Scaling

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19645.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2509.19645](https://arxiv.org/abs/2509.19645)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Mitigating Strategy-Selection Bias in Reasoning for More Effective Test-Time Scaling_20250923|Mitigating Strategy-Selection Bias in Reasoning for More Effective Test-Time Scaling]] (89.9% similar)
- [[2025-09-24/Investigating Test-Time Scaling with Reranking for Machine Translation_20250924|Investigating Test-Time Scaling with Reranking for Machine Translation]] (87.6% similar)
- [[2025-09-23/LTA-thinker_ Latent Thought-Augmented Training Framework for Large Language Models on Complex Reasoning_20250923|LTA-thinker: Latent Thought-Augmented Training Framework for Large Language Models on Complex Reasoning]] (85.8% similar)
- [[2025-09-17/Slim-SC_ Thought Pruning for Efficient Scaling with Self-Consistency_20250917|Slim-SC: Thought Pruning for Efficient Scaling with Self-Consistency]] (85.4% similar)
- [[2025-09-23/Temporal Scaling Law for Large Language Models_20250923|Temporal Scaling Law for Large Language Models]] (84.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Tensor Parallelism|Tensor Parallelism]]
**âš¡ Unique Technical**: [[keywords/Test-time Scaling|Test-time Scaling]], [[keywords/Speculative Decoding|Speculative Decoding]], [[keywords/System-driven Perspective|System-driven Perspective]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19645v1 Announce Type: cross 
Abstract: Test-time scaling (TTS) has recently emerged as a promising direction to exploit the hidden reasoning capabilities of pre-trained large language models (LLMs). However, existing scaling methods narrowly focus on the compute-optimal Pareto-frontier, ignoring the simple fact that compute-optimal is not always system-optimal. In this work, we propose a system-driven perspective on TTS, analyzing how reasoning models scale against practical metrics, such as latency and cost-per-token. By evaluating the impact of popular optimizations such as tensor parallelism and speculative decoding, our preliminary analysis reveals the limitations of current methods and calls for a paradigm shift toward holistic, system-aware evaluations that capture the true essence of scaling laws at inference time.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ í…ŒìŠ¤íŠ¸ ì‹œ í™•ì¥(TTS) ë°©ë²•ë¡ ì„ í†µí•´ ì‚¬ì „ í•™ìŠµëœ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì ì¬ì  ì¶”ë¡  ëŠ¥ë ¥ì„ í™œìš©í•˜ëŠ” ìƒˆë¡œìš´ ì ‘ê·¼ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ ë°©ë²•ë“¤ì´ ì£¼ë¡œ ê³„ì‚° ìµœì í™”ì— ì§‘ì¤‘í•˜ëŠ” ë°˜ë©´, ì´ ì—°êµ¬ëŠ” ì‹œìŠ¤í…œ ìµœì í™”ë¥¼ ê³ ë ¤í•˜ì—¬ ì§€ì—° ì‹œê°„ ë° í† í°ë‹¹ ë¹„ìš©ê³¼ ê°™ì€ ì‹¤ìš©ì  ì§€í‘œì— ëŒ€í•œ ëª¨ë¸ì˜ í™•ì¥ì„±ì„ ë¶„ì„í•©ë‹ˆë‹¤. í…ì„œ ë³‘ë ¬ ì²˜ë¦¬ì™€ ì¶”ì¸¡ ë””ì½”ë”© ë“±ì˜ ìµœì í™” ê¸°ë²•ì´ ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ í‰ê°€í•œ ê²°ê³¼, í˜„ì¬ ë°©ë²•ì˜ í•œê³„ë¥¼ ë“œëŸ¬ë‚´ë©°, ì¶”ë¡  ì‹œ í™•ì¥ ë²•ì¹™ì˜ ë³¸ì§ˆì„ í¬ì°©í•˜ê¸° ìœ„í•œ ì‹œìŠ¤í…œ ì¸ì‹ í‰ê°€ì˜ í•„ìš”ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. í…ŒìŠ¤íŠ¸ ì‹œ ìŠ¤ì¼€ì¼ë§(TTS)ì€ ì‚¬ì „ í•™ìŠµëœ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ ìˆ¨ê²¨ì§„ ì¶”ë¡  ëŠ¥ë ¥ì„ í™œìš©í•˜ëŠ” ìœ ë§í•œ ë°©í–¥ìœ¼ë¡œ ì£¼ëª©ë°›ê³  ìˆë‹¤.
- 2. ê¸°ì¡´ì˜ ìŠ¤ì¼€ì¼ë§ ë°©ë²•ì€ ê³„ì‚° ìµœì ì˜ íŒŒë ˆí†  ê²½ê³„ì—ë§Œ ì§‘ì¤‘í•˜ì—¬ ì‹œìŠ¤í…œ ìµœì ì´ í•­ìƒ ê³„ì‚° ìµœì ê³¼ ì¼ì¹˜í•˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ì ì„ ê°„ê³¼í•˜ê³  ìˆë‹¤.
- 3. ë³¸ ì—°êµ¬ì—ì„œëŠ” ì§€ì—° ì‹œê°„ ë° í† í°ë‹¹ ë¹„ìš©ê³¼ ê°™ì€ ì‹¤ìš©ì ì¸ ì§€í‘œì— ëŒ€í•œ ì¶”ë¡  ëª¨ë¸ì˜ ìŠ¤ì¼€ì¼ë§ì„ ë¶„ì„í•˜ëŠ” ì‹œìŠ¤í…œ ì¤‘ì‹¬ì˜ ê´€ì ì„ ì œì•ˆí•œë‹¤.
- 4. í…ì„œ ë³‘ë ¬ ì²˜ë¦¬ ë° ì¶”ì¸¡ ë””ì½”ë”©ê³¼ ê°™ì€ ìµœì í™”ì˜ ì˜í–¥ì„ í‰ê°€í•œ ê²°ê³¼, í˜„ì¬ ë°©ë²•ì˜ í•œê³„ë¥¼ ë“œëŸ¬ë‚´ê³  ì¶”ë¡  ì‹œ ìŠ¤ì¼€ì¼ë§ ë²•ì¹™ì˜ ë³¸ì§ˆì„ í¬ì°©í•˜ëŠ” ì „ì²´ì ì´ê³  ì‹œìŠ¤í…œ ì¸ì‹ì ì¸ í‰ê°€ë¡œì˜ íŒ¨ëŸ¬ë‹¤ì„ ì „í™˜ì´ í•„ìš”í•¨ì„ ê°•ì¡°í•œë‹¤.


---

*Generated on 2025-09-25 15:40:44*