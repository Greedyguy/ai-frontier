---
keywords:
  - Large Language Model
  - Neural Network
  - Neural Network
  - Sentiment Analysis
  - Deep Learning
category: cs.CL
publish_date: 2025-09-25
arxiv_id: 2509.19346
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-26T08:42:05.461322",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Neural Network",
    "Neural Network",
    "Sentiment Analysis",
    "Deep Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Neural Network": 0.8,
    "Sentiment Analysis": 0.78,
    "Deep Learning": 0.83
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Model",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "Essential for linking to discussions about advanced AI models and their applications.",
        "novelty_score": 0.45,
        "connectivity_score": 0.92,
        "specificity_score": 0.68,
        "link_intent_score": 0.85
      },
      {
        "surface": "Convolutional Neural Networks",
        "canonical": "Neural Network",
        "aliases": [
          "CNN"
        ],
        "category": "broad_technical",
        "rationale": "Connects to foundational neural network architectures used in deep learning.",
        "novelty_score": 0.4,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.82
      },
      {
        "surface": "Bidirectional Long Short Term Memory Networks",
        "canonical": "Neural Network",
        "aliases": [
          "Bi-LSTM"
        ],
        "category": "broad_technical",
        "rationale": "Relevant for linking to discussions on sequence modeling and memory in neural networks.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.72,
        "link_intent_score": 0.8
      },
      {
        "surface": "Sentiment Analysis",
        "canonical": "Sentiment Analysis",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Central to the paper's focus on evaluating user feedback.",
        "novelty_score": 0.55,
        "connectivity_score": 0.87,
        "specificity_score": 0.75,
        "link_intent_score": 0.78
      },
      {
        "surface": "Deep Learning Classification",
        "canonical": "Deep Learning",
        "aliases": [],
        "category": "broad_technical",
        "rationale": "Highlights the use of deep learning techniques in classification tasks.",
        "novelty_score": 0.48,
        "connectivity_score": 0.89,
        "specificity_score": 0.69,
        "link_intent_score": 0.83
      }
    ],
    "ban_list_suggestions": [
      "user reviews",
      "Google Play Store",
      "balanced classes"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Model",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.92,
        "specificity": 0.68,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Convolutional Neural Networks",
      "resolved_canonical": "Neural Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Bidirectional Long Short Term Memory Networks",
      "resolved_canonical": "Neural Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.72,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Sentiment Analysis",
      "resolved_canonical": "Sentiment Analysis",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.87,
        "specificity": 0.75,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Deep Learning Classification",
      "resolved_canonical": "Deep Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.48,
        "connectivity": 0.89,
        "specificity": 0.69,
        "link_intent": 0.83
      }
    }
  ]
}
-->

# Benchmarking ChatGPT and DeepSeek in April 2025: A Novel Dual Perspective Sentiment Analysis Using Lexicon-Based and Deep Learning Approaches

## 📋 메타데이터

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19346.pdf)
**Category**: cs.CL
**Published**: 2025-09-25
**ArXiv ID**: [2509.19346](https://arxiv.org/abs/2509.19346)

## 🔗 유사한 논문
- [[2025-09-24/Trace Is In Sentences_ Unbiased Lightweight ChatGPT-Generated Text Detector_20250924|Trace Is In Sentences: Unbiased Lightweight ChatGPT-Generated Text Detector]] (83.2% similar)
- [[2025-09-23/SENSE-7_ Taxonomy and Dataset for Measuring User Perceptions of Empathy in Sustained Human-AI Conversations_20250923|SENSE-7: Taxonomy and Dataset for Measuring User Perceptions of Empathy in Sustained Human-AI Conversations]] (83.1% similar)
- [[2025-09-22/MEDAL_ A Framework for Benchmarking LLMs as Multilingual Open-Domain Dialogue Evaluators_20250922|MEDAL: A Framework for Benchmarking LLMs as Multilingual Open-Domain Dialogue Evaluators]] (82.8% similar)
- [[2025-09-24/Reading Between the Lines_ Scalable User Feedback via Implicit Sentiment in Developer Prompts_20250924|Reading Between the Lines: Scalable User Feedback via Implicit Sentiment in Developer Prompts]] (82.7% similar)
- [[2025-09-23/"What's Up, Doc?"_ Analyzing How Users Seek Health Information in Large-Scale Conversational AI Datasets_20250923|"What's Up, Doc?": Analyzing How Users Seek Health Information in Large-Scale Conversational AI Datasets]] (82.1% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]], [[keywords/Neural Network|Neural Network]], [[keywords/Neural Network|Neural Network]], [[keywords/Deep Learning|Deep Learning]]
**🔗 Specific Connectable**: [[keywords/Sentiment Analysis|Sentiment Analysis]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.19346v1 Announce Type: new 
Abstract: This study presents a novel dual-perspective approach to analyzing user reviews for ChatGPT and DeepSeek on the Google Play Store, integrating lexicon-based sentiment analysis (TextBlob) with deep learning classification models, including Convolutional Neural Networks (CNN) and Bidirectional Long Short Term Memory (Bi LSTM) Networks. Unlike prior research, which focuses on either lexicon-based strategies or predictive deep learning models in isolation, this study conducts an extensive investigation into user satisfaction with Large Language Model (LLM) based applications. A Dataset of 4,000 authentic user reviews was collected, which were carefully preprocessed and subjected to oversampling to achieve balanced classes. The balanced test set of 1,700 Reviews were used for model testing. Results from the experiments reveal that ChatGPT received significantly more positive sentiment than DeepSeek. Furthermore, deep learning based classification demonstrated superior performance over lexicon analysis, with CNN outperforming Bi-LSTM by achieving 96.41 percent accuracy and near perfect classification of negative reviews, alongside high F1-scores for neutral and positive sentiments. This research sets a new methodological standard for measuring sentiment in LLM-based applications and provides practical insights for developers and researchers seeking to improve user-centric AI system design.

## 📝 요약

이 연구는 Google Play Store에서 ChatGPT와 DeepSeek의 사용자 리뷰를 분석하기 위해 새로운 이중 관점 접근 방식을 제시합니다. 이 방법은 어휘 기반 감성 분석(TextBlob)과 심층 학습 분류 모델(CNN 및 Bi-LSTM)을 통합합니다. 4,000개의 실제 사용자 리뷰를 수집하고, 균형 잡힌 클래스 구성을 위해 오버샘플링을 수행했습니다. 실험 결과, ChatGPT가 DeepSeek보다 긍정적인 감성을 더 많이 받았으며, CNN이 Bi-LSTM보다 높은 96.41%의 정확도를 기록하며 우수한 성능을 보였습니다. 이 연구는 LLM 기반 애플리케이션의 감성 측정에 대한 새로운 방법론적 기준을 제시하고, 사용자 중심 AI 시스템 설계를 개선하기 위한 실용적인 통찰을 제공합니다.

## 🎯 주요 포인트

- 1. 이 연구는 ChatGPT와 DeepSeek의 사용자 리뷰를 분석하기 위해 감정 분석과 딥러닝 분류 모델을 통합한 새로운 이중 관점 접근 방식을 제시합니다.
- 2. 4,000개의 실제 사용자 리뷰 데이터셋을 수집하고, 클래스 균형을 맞추기 위해 오버샘플링을 수행했습니다.
- 3. 실험 결과, ChatGPT가 DeepSeek보다 긍정적인 감정을 더 많이 받았으며, CNN이 Bi-LSTM보다 높은 정확도(96.41%)를 기록했습니다.
- 4. 딥러닝 기반 분류는 감정 분석보다 우수한 성능을 보였으며, 특히 부정적 리뷰의 분류에서 거의 완벽한 결과를 나타냈습니다.
- 5. 이 연구는 LLM 기반 애플리케이션의 감정 측정을 위한 새로운 방법론적 기준을 설정하고, 사용자 중심의 AI 시스템 설계를 개선하기 위한 실질적인 통찰을 제공합니다.


---

*Generated on 2025-09-26 08:42:05*