---
keywords:
  - Large Language Model
  - Declarative Query Language
  - Type Checker
  - Hybrid Data Source
  - Multi-hop Question Answering
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2509.20208
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T16:01:54.979043",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Declarative Query Language",
    "Type Checker",
    "Hybrid Data Source",
    "Multi-hop Question Answering"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Declarative Query Language": 0.78,
    "Type Checker": 0.77,
    "Hybrid Data Source": 0.72,
    "Multi-hop Question Answering": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Model",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are central to the paper's discussion on integrating LLM functions in declarative programs.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Declarative Query Languages",
        "canonical": "Declarative Query Language",
        "aliases": [
          "SQL",
          "Query Language"
        ],
        "category": "specific_connectable",
        "rationale": "The paper focuses on integrating LLMs with declarative query languages, making it a key concept for linking.",
        "novelty_score": 0.58,
        "connectivity_score": 0.75,
        "specificity_score": 0.72,
        "link_intent_score": 0.78
      },
      {
        "surface": "Type Checkers",
        "canonical": "Type Checker",
        "aliases": [
          "Type System"
        ],
        "category": "unique_technical",
        "rationale": "Type checkers are crucial for ensuring the alignment of generated outputs with database rules.",
        "novelty_score": 0.62,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      },
      {
        "surface": "Hybrid Data Sources",
        "canonical": "Hybrid Data Source",
        "aliases": [
          "Mixed Data Source"
        ],
        "category": "unique_technical",
        "rationale": "The use of hybrid data sources is a novel aspect of the paper's approach to query execution.",
        "novelty_score": 0.67,
        "connectivity_score": 0.68,
        "specificity_score": 0.76,
        "link_intent_score": 0.72
      },
      {
        "surface": "Multi-hop Question Answering",
        "canonical": "Multi-hop Question Answering",
        "aliases": [
          "Multi-hop QA"
        ],
        "category": "specific_connectable",
        "rationale": "The paper demonstrates improvements in multi-hop question answering, a specific application area.",
        "novelty_score": 0.55,
        "connectivity_score": 0.8,
        "specificity_score": 0.78,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "orchestrations",
      "performance bottlenecks"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Model",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Declarative Query Languages",
      "resolved_canonical": "Declarative Query Language",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.75,
        "specificity": 0.72,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Type Checkers",
      "resolved_canonical": "Type Checker",
      "decision": "linked",
      "scores": {
        "novelty": 0.62,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Hybrid Data Sources",
      "resolved_canonical": "Hybrid Data Source",
      "decision": "linked",
      "scores": {
        "novelty": 0.67,
        "connectivity": 0.68,
        "specificity": 0.76,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "Multi-hop Question Answering",
      "resolved_canonical": "Multi-hop Question Answering",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.8,
        "specificity": 0.78,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Play by the Type Rules: Inferring Constraints for LLM Functions in Declarative Programs

## 📋 메타데이터

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.20208.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2509.20208](https://arxiv.org/abs/2509.20208)

## 🔗 유사한 논문
- [[2025-09-23/TranSQL+_ Serving Large Language Models with SQL on Low-Resource Hardware_20250923|TranSQL+: Serving Large Language Models with SQL on Low-Resource Hardware]] (86.3% similar)
- [[2025-09-22/Are LLMs Better Formalizers than Solvers on Complex Problems?_20250922|Are LLMs Better Formalizers than Solvers on Complex Problems?]] (84.8% similar)
- [[2025-09-22/A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages_20250922|A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages]] (83.8% similar)
- [[2025-09-22/Adaptive Self-improvement LLM Agentic System for ML Library Development_20250922|Adaptive Self-improvement LLM Agentic System for ML Library Development]] (83.6% similar)
- [[2025-09-25/Reverse Engineering User Stories from Code using Large Language Models_20250925|Reverse Engineering User Stories from Code using Large Language Models]] (83.3% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Declarative Query Language|Declarative Query Language]], [[keywords/Multi-hop Question Answering|Multi-hop Question Answering]]
**⚡ Unique Technical**: [[keywords/Type Checker|Type Checker]], [[keywords/Hybrid Data Source|Hybrid Data Source]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.20208v1 Announce Type: cross 
Abstract: Integrating LLM powered operators in declarative query languages allows for the combination of cheap and interpretable functions with powerful, generalizable language model reasoning. However, in order to benefit from the optimized execution of a database query language like SQL, generated outputs must align with the rules enforced by both type checkers and database contents. Current approaches address this challenge with orchestrations consisting of many LLM-based post-processing calls to ensure alignment between generated outputs and database values, introducing performance bottlenecks. We perform a study on the ability of various sized open-source language models to both parse and execute functions within a query language based on SQL, showing that small language models can excel as function executors over hybrid data sources. Then, we propose an efficient solution to enforce the well-typedness of LLM functions, demonstrating 7% accuracy improvement on a multi-hop question answering dataset with 53% improvement in latency over comparable solutions. We make our implementation available at https://github.com/parkervg/blendsql

## 📝 요약

이 논문은 대규모 언어 모델(LLM)을 선언적 쿼리 언어에 통합하여 저렴하고 해석 가능한 함수와 강력한 언어 모델 추론을 결합하는 방법을 제안합니다. SQL과 같은 데이터베이스 쿼리 언어의 최적화된 실행을 활용하기 위해서는 생성된 출력이 타입 검사기와 데이터베이스 내용의 규칙과 일치해야 합니다. 기존 방법은 많은 LLM 기반 후처리 호출을 통해 이 문제를 해결하지만 성능 병목을 초래합니다. 본 연구는 다양한 크기의 오픈소스 언어 모델이 SQL 기반 쿼리 언어에서 함수 실행자로서의 역할을 수행할 수 있음을 보여주며, 작은 언어 모델이 하이브리드 데이터 소스에서 뛰어난 성능을 발휘할 수 있음을 입증합니다. 또한, LLM 함수의 타입 일관성을 보장하는 효율적인 솔루션을 제안하여, 유사한 솔루션 대비 7%의 정확도 향상과 53%의 지연 시간 개선을 달성했습니다. 구현 코드는 GitHub에서 제공됩니다.

## 🎯 주요 포인트

- 1. 선언적 쿼리 언어에 LLM 기반 연산자를 통합하면 저렴하고 해석 가능한 함수와 강력한 언어 모델 추론을 결합할 수 있다.
- 2. 생성된 출력이 타입 검사기와 데이터베이스 내용의 규칙에 맞아야 SQL과 같은 데이터베이스 쿼리 언어의 최적화된 실행을 활용할 수 있다.
- 3. 현재 접근 방식은 LLM 기반 후처리 호출을 통해 생성된 출력과 데이터베이스 값의 정렬을 보장하지만, 이는 성능 병목을 초래한다.
- 4. 다양한 크기의 오픈 소스 언어 모델이 SQL 기반 쿼리 언어 내에서 함수 파싱 및 실행 능력을 연구한 결과, 작은 언어 모델이 하이브리드 데이터 소스에서 함수 실행자로 우수함을 보여준다.
- 5. LLM 함수의 올바른 타입을 강제하는 효율적인 솔루션을 제안하여, 유사한 솔루션 대비 53%의 지연 시간 개선과 함께 멀티 홉 질문 응답 데이터셋에서 7%의 정확도 향상을 달성했다.


---

*Generated on 2025-09-25 16:01:54*