---
keywords:
  - Federated Learning
  - Black-Box Discrete Prompt Learning
  - Large Language Model
  - Query Efficiency
  - FedOne
category: cs.LG
publish_date: 2025-09-25
arxiv_id: 2506.14929
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T17:08:24.363676",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Federated Learning",
    "Black-Box Discrete Prompt Learning",
    "Large Language Model",
    "Query Efficiency",
    "FedOne"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Federated Learning": 0.85,
    "Black-Box Discrete Prompt Learning": 0.8,
    "Large Language Model": 0.82,
    "Query Efficiency": 0.78,
    "FedOne": 0.83
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Federated Learning",
        "canonical": "Federated Learning",
        "aliases": [
          "FL"
        ],
        "category": "broad_technical",
        "rationale": "Federated Learning is central to the paper's methodology and connects to existing works on distributed model training.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Black-Box Discrete Prompt Learning",
        "canonical": "Black-Box Discrete Prompt Learning",
        "aliases": [
          "BDPL"
        ],
        "category": "unique_technical",
        "rationale": "This is a unique method introduced in the paper, crucial for understanding the proposed framework.",
        "novelty_score": 0.78,
        "connectivity_score": 0.52,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Large Language Model",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "LLMs are integral to the paper's context, linking to broader discussions on cloud-based AI models.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.82
      },
      {
        "surface": "Query Efficiency",
        "canonical": "Query Efficiency",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Query efficiency is a key metric in the paper, relevant for optimizing federated learning processes.",
        "novelty_score": 0.55,
        "connectivity_score": 0.7,
        "specificity_score": 0.72,
        "link_intent_score": 0.78
      },
      {
        "surface": "FedOne",
        "canonical": "FedOne",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "FedOne is a novel framework proposed in the paper, central to its contributions.",
        "novelty_score": 0.82,
        "connectivity_score": 0.6,
        "specificity_score": 0.88,
        "link_intent_score": 0.83
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Federated Learning",
      "resolved_canonical": "Federated Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Black-Box Discrete Prompt Learning",
      "resolved_canonical": "Black-Box Discrete Prompt Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.78,
        "connectivity": 0.52,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Large Language Model",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Query Efficiency",
      "resolved_canonical": "Query Efficiency",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.7,
        "specificity": 0.72,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "FedOne",
      "resolved_canonical": "FedOne",
      "decision": "linked",
      "scores": {
        "novelty": 0.82,
        "connectivity": 0.6,
        "specificity": 0.88,
        "link_intent": 0.83
      }
    }
  ]
}
-->

# FedOne: Query-Efficient Federated Learning for Black-box Discrete Prompt Learning

## 📋 메타데이터

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2506.14929.pdf)
**Category**: cs.LG
**Published**: 2025-09-25
**ArXiv ID**: [2506.14929](https://arxiv.org/abs/2506.14929)

## 🔗 유사한 논문
- [[2025-09-19/An Empirical Study of Federated Prompt Learning for Vision Language Model_20250919|An Empirical Study of Federated Prompt Learning for Vision Language Model]] (84.6% similar)
- [[2025-09-23/FedEL_ Federated Elastic Learning for Heterogeneous Devices_20250923|FedEL: Federated Elastic Learning for Heterogeneous Devices]] (80.8% similar)
- [[2025-09-18/Adaptive LoRA Experts Allocation and Selection for Federated Fine-Tuning_20250918|Adaptive LoRA Experts Allocation and Selection for Federated Fine-Tuning]] (80.6% similar)
- [[2025-09-19/A Multi-To-One Interview Paradigm for Efficient MLLM Evaluation_20250919|A Multi-To-One Interview Paradigm for Efficient MLLM Evaluation]] (80.5% similar)
- [[2025-09-24/Dynamic Prompt Fusion for Multi-Task and Cross-Domain Adaptation in LLMs_20250924|Dynamic Prompt Fusion for Multi-Task and Cross-Domain Adaptation in LLMs]] (80.4% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Federated Learning|Federated Learning]], [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Query Efficiency|Query Efficiency]]
**⚡ Unique Technical**: [[keywords/Black-Box Discrete Prompt Learning|Black-Box Discrete Prompt Learning]], [[keywords/FedOne|FedOne]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2506.14929v2 Announce Type: replace 
Abstract: Black-Box Discrete Prompt Learning is a prompt-tuning method that optimizes discrete prompts without accessing model parameters or gradients, making the prompt tuning on a cloud-based Large Language Model (LLM) feasible. Adapting federated learning to BDPL could further enhance prompt tuning performance by leveraging data from diverse sources. However, all previous research on federated black-box prompt tuning had neglected the substantial query cost associated with the cloud-based LLM service. To address this gap, we conducted a theoretical analysis of query efficiency within the context of federated black-box prompt tuning. Our findings revealed that degrading FedAvg to activate only one client per round, a strategy we called \textit{FedOne}, enabled optimal query efficiency in federated black-box prompt learning. Building on this insight, we proposed the FedOne framework, a federated black-box discrete prompt learning method designed to maximize query efficiency when interacting with cloud-based LLMs. We conducted numerical experiments on various aspects of our framework, demonstrating a significant improvement in query efficiency, which aligns with our theoretical results.

## 📝 요약

이 논문은 블랙박스 이산 프롬프트 학습(BDPL) 방법론을 제안하며, 모델의 매개변수나 기울기에 접근하지 않고도 클라우드 기반 대형 언어 모델(LLM)에서 프롬프트 튜닝을 가능하게 합니다. 기존 연구들은 클라우드 기반 LLM 서비스의 높은 쿼리 비용을 간과했지만, 본 연구는 이 문제를 해결하기 위해 연방 블랙박스 프롬프트 튜닝의 쿼리 효율성을 이론적으로 분석했습니다. 분석 결과, FedAvg를 변형하여 매 라운드마다 하나의 클라이언트만 활성화하는 'FedOne' 전략이 최적의 쿼리 효율성을 달성함을 밝혔습니다. 이를 바탕으로 FedOne 프레임워크를 제안하여 클라우드 기반 LLM과의 상호작용 시 쿼리 효율성을 극대화했습니다. 다양한 실험을 통해 이 프레임워크가 쿼리 효율성을 크게 향상시킨다는 것을 입증했습니다.

## 🎯 주요 포인트

- 1. Black-Box Discrete Prompt Learning은 모델 파라미터나 기울기에 접근하지 않고도 프롬프트 최적화를 가능하게 하여 클라우드 기반 대형 언어 모델에서의 프롬프트 튜닝을 실현합니다.
- 2. 연합 학습을 BDPL에 적용하면 다양한 소스로부터의 데이터를 활용하여 프롬프트 튜닝 성능을 향상시킬 수 있습니다.
- 3. 기존 연구들은 클라우드 기반 LLM 서비스와 관련된 상당한 쿼리 비용을 간과했으나, 본 연구는 연합 블랙박스 프롬프트 튜닝의 쿼리 효율성을 이론적으로 분석했습니다.
- 4. FedAvg를 한 라운드당 하나의 클라이언트만 활성화하는 \textit{FedOne} 전략으로 변형하면 최적의 쿼리 효율성을 달성할 수 있음을 발견했습니다.
- 5. 제안된 FedOne 프레임워크는 클라우드 기반 LLM과 상호작용 시 쿼리 효율성을 극대화하도록 설계된 연합 블랙박스 이산 프롬프트 학습 방법입니다.


---

*Generated on 2025-09-25 17:08:24*