---
keywords:
  - Large Language Model
  - Few-Shot Learning
  - Mutation-Based Fuzzing
  - Prompt Engineering
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2509.19533
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T15:38:12.157699",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Few-Shot Learning",
    "Mutation-Based Fuzzing",
    "Prompt Engineering"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Few-Shot Learning": 0.78,
    "Mutation-Based Fuzzing": 0.8,
    "Prompt Engineering": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "reasoning LLM"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are central to the paper's framework and connect to a wide range of machine learning topics.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Few-Shot Learning",
        "canonical": "Few-Shot Learning",
        "aliases": [
          "few-shot prompts"
        ],
        "category": "specific_connectable",
        "rationale": "Few-Shot Learning is a key technique explored for improving mutation quality, linking to recent trends in machine learning.",
        "novelty_score": 0.58,
        "connectivity_score": 0.79,
        "specificity_score": 0.72,
        "link_intent_score": 0.78
      },
      {
        "surface": "Mutation-Based Fuzzing",
        "canonical": "Mutation-Based Fuzzing",
        "aliases": [
          "fuzzing mutation loop"
        ],
        "category": "unique_technical",
        "rationale": "This is a unique technical process central to the paper's methodology, connecting fuzzing with LLMs.",
        "novelty_score": 0.72,
        "connectivity_score": 0.67,
        "specificity_score": 0.81,
        "link_intent_score": 0.8
      },
      {
        "surface": "Prompt Engineering",
        "canonical": "Prompt Engineering",
        "aliases": [
          "prompt-based learning"
        ],
        "category": "specific_connectable",
        "rationale": "Prompt Engineering is crucial for optimizing LLM performance in the context of fuzzing.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "security vulnerabilities",
      "coverage-guided tools",
      "response latency"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Few-Shot Learning",
      "resolved_canonical": "Few-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.79,
        "specificity": 0.72,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Mutation-Based Fuzzing",
      "resolved_canonical": "Mutation-Based Fuzzing",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.67,
        "specificity": 0.81,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Prompt Engineering",
      "resolved_canonical": "Prompt Engineering",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Semantic-Aware Fuzzing: An Empirical Framework for LLM-Guided, Reasoning-Driven Input Mutation

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19533.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2509.19533](https://arxiv.org/abs/2509.19533)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Adaptive Distraction_ Probing LLM Contextual Robustness with Automated Tree Search_20250923|Adaptive Distraction: Probing LLM Contextual Robustness with Automated Tree Search]] (84.5% similar)
- [[2025-09-23/Sugar-Coated Poison_ Benign Generation Unlocks LLM Jailbreaking_20250923|Sugar-Coated Poison: Benign Generation Unlocks LLM Jailbreaking]] (84.5% similar)
- [[2025-09-19/A Multi-Agent LLM Defense Pipeline Against Prompt Injection Attacks_20250919|A Multi-Agent LLM Defense Pipeline Against Prompt Injection Attacks]] (84.2% similar)
- [[2025-09-23/MIST_ Jailbreaking Black-box Large Language Models via Iterative Semantic Tuning_20250923|MIST: Jailbreaking Black-box Large Language Models via Iterative Semantic Tuning]] (84.1% similar)
- [[2025-09-24/Evaluating Large Language Models for Detecting Antisemitism_20250924|Evaluating Large Language Models for Detecting Antisemitism]] (84.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Few-Shot Learning|Few-Shot Learning]], [[keywords/Prompt Engineering|Prompt Engineering]]
**âš¡ Unique Technical**: [[keywords/Mutation-Based Fuzzing|Mutation-Based Fuzzing]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19533v1 Announce Type: cross 
Abstract: Security vulnerabilities in Internet-of-Things devices, mobile platforms, and autonomous systems remain critical. Traditional mutation-based fuzzers -- while effectively explore code paths -- primarily perform byte- or bit-level edits without semantic reasoning. Coverage-guided tools such as AFL++ use dictionaries, grammars, and splicing heuristics to impose shallow structural constraints, leaving deeper protocol logic, inter-field dependencies, and domain-specific semantics unaddressed. Conversely, reasoning-capable large language models (LLMs) can leverage pretraining knowledge to understand input formats, respect complex constraints, and propose targeted mutations, much like an experienced reverse engineer or testing expert. However, lacking ground truth for "correct" mutation reasoning makes supervised fine-tuning impractical, motivating explorations of off-the-shelf LLMs via prompt-based few-shot learning. To bridge this gap, we present an open-source microservices framework that integrates reasoning LLMs with AFL++ on Google's FuzzBench, tackling asynchronous execution and divergent hardware demands (GPU- vs. CPU-intensive) of LLMs and fuzzers. We evaluate four research questions: (R1) How can reasoning LLMs be integrated into the fuzzing mutation loop? (R2) Do few-shot prompts yield higher-quality mutations than zero-shot? (R3) Can prompt engineering with off-the-shelf models improve fuzzing directly? and (R4) Which open-source reasoning LLMs perform best under prompt-only conditions? Experiments with Llama3.3, Deepseek-r1-Distill-Llama-70B, QwQ-32B, and Gemma3 highlight Deepseek as the most promising. Mutation effectiveness depends more on prompt complexity and model choice than shot count. Response latency and throughput bottlenecks remain key obstacles, offering directions for future work.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì‚¬ë¬¼ì¸í„°ë„·(IoT) ê¸°ê¸°, ëª¨ë°”ì¼ í”Œë«í¼, ììœ¨ ì‹œìŠ¤í…œì˜ ë³´ì•ˆ ì·¨ì•½ì ì„ í•´ê²°í•˜ê¸° ìœ„í•´ ì „í†µì ì¸ í¼ì§• ê¸°ë²•ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³ ì í•©ë‹ˆë‹¤. ê¸°ì¡´ í¼ì €ëŠ” ì£¼ë¡œ ë°”ì´íŠ¸ë‚˜ ë¹„íŠ¸ ìˆ˜ì¤€ì˜ í¸ì§‘ì„ ìˆ˜í–‰í•˜ë©°, ë³µì¡í•œ í”„ë¡œí† ì½œ ë…¼ë¦¬ë‚˜ ë„ë©”ì¸ë³„ ì˜ë¯¸ë¥¼ ì¶©ë¶„íˆ ê³ ë ¤í•˜ì§€ ëª»í•©ë‹ˆë‹¤. ì´ì— ë°˜í•´, ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ ì‚¬ì „ í•™ìŠµëœ ì§€ì‹ì„ í™œìš©í•˜ì—¬ ì…ë ¥ í˜•ì‹ì„ ì´í•´í•˜ê³  ë³µì¡í•œ ì œì•½ì„ ì¤€ìˆ˜í•˜ë©°, ëª©í‘œ ì§€í–¥ì ì¸ ë³€ì´ë¥¼ ì œì•ˆí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ "ì˜¬ë°”ë¥¸" ë³€ì´ì— ëŒ€í•œ ê¸°ì¤€ì´ ì—†ì–´ ì§€ë„ í•™ìŠµì´ ì–´ë ¤ìš´ ìƒí™©ì—ì„œ, ì´ ì—°êµ¬ëŠ” LLMê³¼ AFL++ë¥¼ í†µí•©í•œ ì˜¤í”ˆì†ŒìŠ¤ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ë¹„ë™ê¸° ì‹¤í–‰ê³¼ í•˜ë“œì›¨ì–´ ìš”êµ¬ì‚¬í•­ì„ ì¡°ìœ¨í•˜ë©°, LLMì„ í¼ì§• ë³€ì´ ë£¨í”„ì— í†µí•©í•˜ëŠ” ë°©ë²•, few-shot í”„ë¡¬í”„íŠ¸ì˜ íš¨ê³¼, í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì˜ ì§ì ‘ì ì¸ í¼ì§• ê°œì„  ê°€ëŠ¥ì„±, ê·¸ë¦¬ê³  ìµœì ì˜ ì˜¤í”ˆì†ŒìŠ¤ LLMì„ í‰ê°€í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, Deepseek ëª¨ë¸ì´ ê°€ì¥ ìœ ë§í•˜ë©°, ë³€ì´ íš¨ê³¼ëŠ” í”„ë¡¬í”„íŠ¸ ë³µì¡ì„±ê³¼ ëª¨ë¸ ì„ íƒì— í¬ê²Œ ì˜ì¡´í•©ë‹ˆë‹¤. ì‘ë‹µ ì§€ì—°ê³¼ ì²˜ë¦¬ëŸ‰ ë³‘ëª©ì´ ì£¼ìš” ê³¼ì œë¡œ ë‚¨ì•„ ìˆì–´, í–¥í›„ ì—°êµ¬ ë°©í–¥ì„ ì œì‹œí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì „í†µì ì¸ ë³€ì´ ê¸°ë°˜ í¼ì €ëŠ” ì½”ë“œ ê²½ë¡œ íƒìƒ‰ì— íš¨ê³¼ì ì´ì§€ë§Œ, ì˜ë¯¸ì  ì¶”ë¡  ì—†ì´ ë°”ì´íŠ¸ ë˜ëŠ” ë¹„íŠ¸ ìˆ˜ì¤€ì˜ í¸ì§‘ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
- 2. ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì€ ì‚¬ì „ í•™ìŠµ ì§€ì‹ì„ í™œìš©í•˜ì—¬ ì…ë ¥ í˜•ì‹ì„ ì´í•´í•˜ê³  ë³µì¡í•œ ì œì•½ì„ ì¤€ìˆ˜í•˜ë©° ëª©í‘œ ì§€í–¥ì ì¸ ë³€ì´ë¥¼ ì œì•ˆí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- 3. LLMê³¼ AFL++ë¥¼ í†µí•©í•œ ì˜¤í”ˆ ì†ŒìŠ¤ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì‹œí•˜ì—¬ ë¹„ë™ê¸° ì‹¤í–‰ ë° í•˜ë“œì›¨ì–´ ìš”êµ¬ ì‚¬í•­ì„ í•´ê²°í•©ë‹ˆë‹¤.
- 4. ì‹¤í—˜ ê²°ê³¼, Deepseek ëª¨ë¸ì´ ê°€ì¥ ìœ ë§í•˜ë©°, ë³€ì´ íš¨ê³¼ëŠ” í”„ë¡¬í”„íŠ¸ì˜ ë³µì¡ì„±ê³¼ ëª¨ë¸ ì„ íƒì— ë” ì˜ì¡´í•©ë‹ˆë‹¤.
- 5. ì‘ë‹µ ì§€ì—°ê³¼ ì²˜ë¦¬ëŸ‰ ë³‘ëª© í˜„ìƒì´ ì£¼ìš” ì¥ì• ë¬¼ë¡œ ë‚¨ì•„ ìˆìœ¼ë©°, ì´ëŠ” í–¥í›„ ì—°êµ¬ ë°©í–¥ì„ ì œì‹œí•©ë‹ˆë‹¤.


---

*Generated on 2025-09-25 15:38:12*