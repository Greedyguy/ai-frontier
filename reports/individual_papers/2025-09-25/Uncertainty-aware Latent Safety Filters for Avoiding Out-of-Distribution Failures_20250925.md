---
keywords:
  - Latent Safety Filter
  - Out-of-Distribution Detection
  - Epistemic Uncertainty
  - Reachability Analysis
  - Generative World Models
category: cs.LG
publish_date: 2025-09-25
arxiv_id: 2505.00779
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-26T08:38:30.394474",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Latent Safety Filter",
    "Out-of-Distribution Detection",
    "Epistemic Uncertainty",
    "Reachability Analysis",
    "Generative World Models"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Latent Safety Filter": 0.92,
    "Out-of-Distribution Detection": 0.85,
    "Epistemic Uncertainty": 0.83,
    "Reachability Analysis": 0.87,
    "Generative World Models": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Latent Safety Filter",
        "canonical": "Latent Safety Filter",
        "aliases": [
          "Safety Filter",
          "Uncertainty-aware Safety Filter"
        ],
        "category": "unique_technical",
        "rationale": "This concept is central to the paper's contribution and represents a novel approach to safety in robotic systems.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.88,
        "link_intent_score": 0.92
      },
      {
        "surface": "Out-of-Distribution Failures",
        "canonical": "Out-of-Distribution Detection",
        "aliases": [
          "OOD Failures",
          "OOD Detection"
        ],
        "category": "specific_connectable",
        "rationale": "This is a key challenge addressed by the paper, relevant to many machine learning applications.",
        "novelty_score": 0.55,
        "connectivity_score": 0.78,
        "specificity_score": 0.82,
        "link_intent_score": 0.85
      },
      {
        "surface": "Epistemic Uncertainty",
        "canonical": "Epistemic Uncertainty",
        "aliases": [
          "Model Uncertainty"
        ],
        "category": "specific_connectable",
        "rationale": "Understanding and managing epistemic uncertainty is crucial for improving model reliability.",
        "novelty_score": 0.6,
        "connectivity_score": 0.8,
        "specificity_score": 0.79,
        "link_intent_score": 0.83
      },
      {
        "surface": "Reachability Analysis",
        "canonical": "Reachability Analysis",
        "aliases": [
          "HJ Reachability",
          "Hamilton-Jacobi Reachability"
        ],
        "category": "specific_connectable",
        "rationale": "This method is used to ensure safety in control systems and is a key technique discussed in the paper.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.8,
        "link_intent_score": 0.87
      },
      {
        "surface": "Generative World Models",
        "canonical": "Generative World Models",
        "aliases": [
          "World Models"
        ],
        "category": "broad_technical",
        "rationale": "These models are foundational to the paper's approach and are widely applicable in robotics.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.75,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Latent Safety Filter",
      "resolved_canonical": "Latent Safety Filter",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.88,
        "link_intent": 0.92
      }
    },
    {
      "candidate_surface": "Out-of-Distribution Failures",
      "resolved_canonical": "Out-of-Distribution Detection",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.78,
        "specificity": 0.82,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Epistemic Uncertainty",
      "resolved_canonical": "Epistemic Uncertainty",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.8,
        "specificity": 0.79,
        "link_intent": 0.83
      }
    },
    {
      "candidate_surface": "Reachability Analysis",
      "resolved_canonical": "Reachability Analysis",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.8,
        "link_intent": 0.87
      }
    },
    {
      "candidate_surface": "Generative World Models",
      "resolved_canonical": "Generative World Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.75,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# Uncertainty-aware Latent Safety Filters for Avoiding Out-of-Distribution Failures

## 📋 메타데이터

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2505.00779.pdf)
**Category**: cs.LG
**Published**: 2025-09-25
**ArXiv ID**: [2505.00779](https://arxiv.org/abs/2505.00779)

## 🔗 유사한 논문
- [[2025-09-25/AnySafe_ Adapting Latent Safety Filters at Runtime via Safety Constraint Parameterization in the Latent Space_20250925|AnySafe: Adapting Latent Safety Filters at Runtime via Safety Constraint Parameterization in the Latent Space]] (87.7% similar)
- [[2025-09-18/Designing Latent Safety Filters using Pre-Trained Vision Models_20250918|Designing Latent Safety Filters using Pre-Trained Vision Models]] (84.6% similar)
- [[2025-09-23/ORN-CBF_ Learning Observation-conditioned Residual Neural Control Barrier Functions via Hypernetworks_20250923|ORN-CBF: Learning Observation-conditioned Residual Neural Control Barrier Functions via Hypernetworks]] (83.3% similar)
- [[2025-09-23/Safe Guaranteed Dynamics Exploration with Probabilistic Models_20250923|Safe Guaranteed Dynamics Exploration with Probabilistic Models]] (82.7% similar)
- [[2025-09-25/Formal Safety Verification and Refinement for Generative Motion Planners via Certified Local Stabilization_20250925|Formal Safety Verification and Refinement for Generative Motion Planners via Certified Local Stabilization]] (81.5% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Generative World Models|Generative World Models]]
**🔗 Specific Connectable**: [[keywords/Out-of-Distribution Detection|Out-of-Distribution Detection]], [[keywords/Epistemic Uncertainty|Epistemic Uncertainty]], [[keywords/Reachability Analysis|Reachability Analysis]]
**⚡ Unique Technical**: [[keywords/Latent Safety Filter|Latent Safety Filter]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2505.00779v2 Announce Type: replace-cross 
Abstract: Recent advances in generative world models have enabled classical safe control methods, such as Hamilton-Jacobi (HJ) reachability, to generalize to complex robotic systems operating directly from high-dimensional sensor observations. However, obtaining comprehensive coverage of all safety-critical scenarios during world model training is extremely challenging. As a result, latent safety filters built on top of these models may miss novel hazards and even fail to prevent known ones, overconfidently misclassifying risky out-of-distribution (OOD) situations as safe. To address this, we introduce an uncertainty-aware latent safety filter that proactively steers robots away from both known and unseen failures. Our key idea is to use the world model's epistemic uncertainty as a proxy for identifying unseen potential hazards. We propose a principled method to detect OOD world model predictions by calibrating an uncertainty threshold via conformal prediction. By performing reachability analysis in an augmented state space-spanning both the latent representation and the epistemic uncertainty-we synthesize a latent safety filter that can reliably safeguard arbitrary policies from both known and unseen safety hazards. In simulation and hardware experiments on vision-based control tasks with a Franka manipulator, we show that our uncertainty-aware safety filter preemptively detects potential unsafe scenarios and reliably proposes safe, in-distribution actions. Video results can be found on the project website at https://cmu-intentlab.github.io/UNISafe

## 📝 요약

최근 생성적 세계 모델의 발전으로 인해 Hamilton-Jacobi 도달 가능성과 같은 고전적인 안전 제어 방법이 고차원 센서 관찰에서 직접 작동하는 복잡한 로봇 시스템에 일반화될 수 있게 되었습니다. 그러나 세계 모델 훈련 중 모든 안전에 중요한 시나리오를 포괄하는 것은 매우 어렵습니다. 이로 인해 이러한 모델 위에 구축된 잠재적 안전 필터는 새로운 위험을 놓치거나 심지어 알려진 위험을 방지하지 못할 수 있습니다. 이를 해결하기 위해 우리는 알려진 및 보이지 않는 실패로부터 로봇을 적극적으로 보호하는 불확실성 인식 잠재적 안전 필터를 제안합니다. 세계 모델의 인식적 불확실성을 사용하여 보이지 않는 잠재적 위험을 식별하고, 적합한 예측을 통해 불확실성 임계값을 보정하여 OOD 예측을 감지하는 방법을 제안합니다. 시뮬레이션 및 하드웨어 실험에서 우리의 안전 필터는 잠재적으로 안전하지 않은 시나리오를 사전에 감지하고 안전한 동작을 제안하는 데 신뢰할 수 있음을 보여줍니다.

## 🎯 주요 포인트

- 1. 생성적 세계 모델의 발전으로 고차원 센서 관측에서 작동하는 복잡한 로봇 시스템에 대한 안전 제어 방법이 가능해졌습니다.
- 2. 세계 모델 훈련 중 모든 안전 관련 시나리오를 포괄하는 것은 매우 어렵고, 이로 인해 잠재적 안전 필터가 새로운 위험을 놓칠 수 있습니다.
- 3. 우리는 세계 모델의 불확실성을 이용하여 알려지지 않은 잠재적 위험을 식별하는 불확실성 인식 잠재 안전 필터를 제안합니다.
- 4. 불확실성 임계값을 보정하여 OOD 세계 모델 예측을 감지하고, 알려진 및 알려지지 않은 안전 위험으로부터 정책을 보호하는 잠재 안전 필터를 합성합니다.
- 5. 시뮬레이션 및 하드웨어 실험에서 불확실성 인식 안전 필터가 잠재적으로 안전하지 않은 시나리오를 사전에 감지하고 안전한 행동을 제안하는 것을 확인했습니다.


---

*Generated on 2025-09-26 08:38:30*