---
keywords:
  - Agentic Scene Policies
  - Vision-Language Model
  - Zero-Shot Learning
  - Object Affordances
category: cs.CV
publish_date: 2025-09-25
arxiv_id: 2509.19571
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-26T09:17:38.279110",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Agentic Scene Policies",
    "Vision-Language Model",
    "Zero-Shot Learning",
    "Object Affordances"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Agentic Scene Policies": 0.78,
    "Vision-Language Model": 0.82,
    "Zero-Shot Learning": 0.85,
    "Object Affordances": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Agentic Scene Policies",
        "canonical": "Agentic Scene Policies",
        "aliases": [
          "ASP"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel framework for robot action using scene representations, which is central to the paper's contributions.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.78
      },
      {
        "surface": "Vision-Language-Actions models",
        "canonical": "Vision-Language Model",
        "aliases": [
          "VLA"
        ],
        "category": "evolved_concepts",
        "rationale": "Connects to the growing field of integrating vision and language for robotic actions, enhancing cross-domain linking.",
        "novelty_score": 0.7,
        "connectivity_score": 0.88,
        "specificity_score": 0.8,
        "link_intent_score": 0.82
      },
      {
        "surface": "Zero-shot manner",
        "canonical": "Zero-Shot Learning",
        "aliases": [
          "Zero-shot"
        ],
        "category": "specific_connectable",
        "rationale": "Highlights the capability of executing tasks without prior examples, a key aspect of modern AI models.",
        "novelty_score": 0.65,
        "connectivity_score": 0.9,
        "specificity_score": 0.75,
        "link_intent_score": 0.85
      },
      {
        "surface": "Object affordances",
        "canonical": "Object Affordances",
        "aliases": [
          "Affordances"
        ],
        "category": "specific_connectable",
        "rationale": "Essential for understanding how objects can be interacted with, crucial for robotic manipulation tasks.",
        "novelty_score": 0.6,
        "connectivity_score": 0.78,
        "specificity_score": 0.82,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "robot",
      "scene representation",
      "language-conditioned"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Agentic Scene Policies",
      "resolved_canonical": "Agentic Scene Policies",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Vision-Language-Actions models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.88,
        "specificity": 0.8,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Zero-shot manner",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.9,
        "specificity": 0.75,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Object affordances",
      "resolved_canonical": "Object Affordances",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.78,
        "specificity": 0.82,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# Agentic Scene Policies: Unifying Space, Semantics, and Affordances for Robot Action

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19571.pdf)
**Category**: cs.CV
**Published**: 2025-09-25
**ArXiv ID**: [2509.19571](https://arxiv.org/abs/2509.19571)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-24/PEEK_ Guiding and Minimal Image Representations for Zero-Shot Generalization of Robot Manipulation Policies_20250924|PEEK: Guiding and Minimal Image Representations for Zero-Shot Generalization of Robot Manipulation Policies]] (84.0% similar)
- [[2025-09-18/Robot Control Stack_ A Lean Ecosystem for Robot Learning at Scale_20250918|Robot Control Stack: A Lean Ecosystem for Robot Learning at Scale]] (83.3% similar)
- [[2025-09-24/Pure Vision Language Action (VLA) Models_ A Comprehensive Survey_20250924|Pure Vision Language Action (VLA) Models: A Comprehensive Survey]] (83.3% similar)
- [[2025-09-23/Evo-0_ Vision-Language-Action Model with Implicit Spatial Understanding_20250923|Evo-0: Vision-Language-Action Model with Implicit Spatial Understanding]] (82.7% similar)
- [[2025-09-22/A Vision-Language-Action-Critic Model for Robotic Real-World Reinforcement Learning_20250922|A Vision-Language-Action-Critic Model for Robotic Real-World Reinforcement Learning]] (82.4% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Zero-Shot Learning|Zero-Shot Learning]], [[keywords/Object Affordances|Object Affordances]]
**âš¡ Unique Technical**: [[keywords/Agentic Scene Policies|Agentic Scene Policies]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19571v1 Announce Type: cross 
Abstract: Executing open-ended natural language queries is a core problem in robotics. While recent advances in imitation learning and vision-language-actions models (VLAs) have enabled promising end-to-end policies, these models struggle when faced with complex instructions and new scenes. An alternative is to design an explicit scene representation as a queryable interface between the robot and the world, using query results to guide downstream motion planning. In this work, we present Agentic Scene Policies (ASP), an agentic framework that leverages the advanced semantic, spatial, and affordance-based querying capabilities of modern scene representations to implement a capable language-conditioned robot policy. ASP can execute open-vocabulary queries in a zero-shot manner by explicitly reasoning about object affordances in the case of more complex skills. Through extensive experiments, we compare ASP with VLAs on tabletop manipulation problems and showcase how ASP can tackle room-level queries through affordance-guided navigation, and a scaled-up scene representation. (Project page: https://montrealrobotics.ca/agentic-scene-policies.github.io/)

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë¡œë´‡ì´ ë³µì¡í•œ ìì—°ì–´ ì§ˆì˜ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë¬¸ì œë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. ê¸°ì¡´ì˜ ëª¨ë°© í•™ìŠµê³¼ ë¹„ì „-ì–¸ì–´-í–‰ë™(VLA) ëª¨ë¸ì€ ë³µì¡í•œ ì§€ì‹œì™€ ìƒˆë¡œìš´ ì¥ë©´ì—ì„œ ì–´ë ¤ì›€ì„ ê²ªìŠµë‹ˆë‹¤. ì´ì— ëŒ€í•œ ëŒ€ì•ˆìœ¼ë¡œ, ë¡œë´‡ê³¼ ì„¸ê³„ ì‚¬ì´ì˜ ì§ˆì˜ ê°€ëŠ¥í•œ ì¸í„°í˜ì´ìŠ¤ë¡œ ëª…ì‹œì ì¸ ì¥ë©´ í‘œí˜„ì„ ì„¤ê³„í•˜ê³ , ì´ë¥¼ í†µí•´ ëª¨ì…˜ ê³„íšì„ ì•ˆë‚´í•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” Agentic Scene Policies (ASP)ë¼ëŠ” í”„ë ˆì„ì›Œí¬ë¥¼ ì†Œê°œí•˜ë©°, ì´ëŠ” í˜„ëŒ€ ì¥ë©´ í‘œí˜„ì˜ ê³ ê¸‰ ì˜ë¯¸ì , ê³µê°„ì , ê¸°ëŠ¥ì  ì§ˆì˜ ëŠ¥ë ¥ì„ í™œìš©í•˜ì—¬ ì–¸ì–´ ì¡°ê±´ì— ë§ëŠ” ë¡œë´‡ ì •ì±…ì„ êµ¬í˜„í•©ë‹ˆë‹¤. ASPëŠ” ê°ì²´ì˜ ê¸°ëŠ¥ì„ ëª…ì‹œì ìœ¼ë¡œ ì¶”ë¡ í•˜ì—¬ ë³µì¡í•œ ê¸°ìˆ ì„ ë¬´ì‘ìœ„ë¡œ ìˆ˜í–‰í•  ìˆ˜ ìˆìœ¼ë©°, ì‹¤í—˜ì„ í†µí•´ ASPê°€ VLA ëª¨ë¸ê³¼ ë¹„êµí•˜ì—¬ í…Œì´ë¸”íƒ‘ ì¡°ì‘ ë¬¸ì œì™€ ë°© ìˆ˜ì¤€ì˜ ì§ˆì˜ë¥¼ í•´ê²°í•˜ëŠ” ëŠ¥ë ¥ì„ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Agentic Scene Policies (ASP)ëŠ” í˜„ëŒ€ì˜ ì¥ë©´ í‘œí˜„ì˜ ê³ ê¸‰ ì˜ë¯¸ì , ê³µê°„ì , ì‚¬ìš© ê°€ëŠ¥ì„± ê¸°ë°˜ ì¿¼ë¦¬ ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ ì–¸ì–´ ì¡°ê±´ ë¡œë´‡ ì •ì±…ì„ êµ¬í˜„í•˜ëŠ” í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.
- 2. ASPëŠ” ê°ì²´ì˜ ì‚¬ìš© ê°€ëŠ¥ì„±ì„ ëª…ì‹œì ìœ¼ë¡œ ì¶”ë¡ í•˜ì—¬ ë³µì¡í•œ ê¸°ìˆ ì—ì„œë„ ê°œë°©í˜• ì–´íœ˜ ì¿¼ë¦¬ë¥¼ ì œë¡œìƒ· ë°©ì‹ìœ¼ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- 3. ì‹¤í—˜ì„ í†µí•´ ASPëŠ” í…Œì´ë¸”íƒ‘ ì¡°ì‘ ë¬¸ì œì—ì„œ VLAsì™€ ë¹„êµí•˜ì—¬ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë©°, ì‚¬ìš© ê°€ëŠ¥ì„± ê¸°ë°˜ ë‚´ë¹„ê²Œì´ì…˜ê³¼ í™•ì¥ëœ ì¥ë©´ í‘œí˜„ì„ í†µí•´ ë°© ìˆ˜ì¤€ì˜ ì¿¼ë¦¬ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆìŒì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.
- 4. ASPëŠ” ë¡œë´‡ê³¼ ì„¸ê³„ ì‚¬ì´ì˜ ì¿¼ë¦¬ ê°€ëŠ¥í•œ ì¸í„°í˜ì´ìŠ¤ë¡œ ëª…ì‹œì ì¸ ì¥ë©´ í‘œí˜„ì„ ì„¤ê³„í•˜ì—¬ ë³µì¡í•œ ì§€ì‹œì™€ ìƒˆë¡œìš´ ì¥ë©´ì—ì„œì˜ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-26 09:17:38*