---
keywords:
  - Vision-Language Model
  - Subgoal Evaluation
  - Robotic Manipulation
  - Open-Source Project
  - Per-Subgoal Success Rate
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2509.19524
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T15:14:57.579001",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Vision-Language Model",
    "Subgoal Evaluation",
    "Robotic Manipulation",
    "Open-Source Project",
    "Per-Subgoal Success Rate"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Vision-Language Model": 0.85,
    "Subgoal Evaluation": 0.78,
    "Robotic Manipulation": 0.72,
    "Open-Source Project": 0.7,
    "Per-Subgoal Success Rate": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Vision-Language Models",
        "canonical": "Vision-Language Model",
        "aliases": [
          "VLM",
          "Vision-Language"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-Language Models are central to the proposed evaluation framework, facilitating subgoal assessment.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.78,
        "link_intent_score": 0.85
      },
      {
        "surface": "Subgoal Evaluation",
        "canonical": "Subgoal Evaluation",
        "aliases": [
          "Subgoal Assessment"
        ],
        "category": "unique_technical",
        "rationale": "Subgoal Evaluation is a unique concept introduced to improve granularity in robotic task assessment.",
        "novelty_score": 0.72,
        "connectivity_score": 0.65,
        "specificity_score": 0.82,
        "link_intent_score": 0.78
      },
      {
        "surface": "Robotic Manipulation",
        "canonical": "Robotic Manipulation",
        "aliases": [
          "Robot Manipulation"
        ],
        "category": "broad_technical",
        "rationale": "Robotic Manipulation is the primary application domain for the proposed evaluation framework.",
        "novelty_score": 0.45,
        "connectivity_score": 0.75,
        "specificity_score": 0.66,
        "link_intent_score": 0.72
      },
      {
        "surface": "Open-Source Project",
        "canonical": "Open-Source Project",
        "aliases": [
          "Open-Source Initiative"
        ],
        "category": "unique_technical",
        "rationale": "The framework is intended to be a community-driven open-source project, inviting contributions.",
        "novelty_score": 0.61,
        "connectivity_score": 0.68,
        "specificity_score": 0.7,
        "link_intent_score": 0.7
      },
      {
        "surface": "Per-Subgoal Success Rate",
        "canonical": "Per-Subgoal Success Rate",
        "aliases": [
          "Subgoal SR"
        ],
        "category": "unique_technical",
        "rationale": "This metric is central to the framework, providing detailed insights into task performance.",
        "novelty_score": 0.68,
        "connectivity_score": 0.72,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "experiment"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Vision-Language Models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.78,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Subgoal Evaluation",
      "resolved_canonical": "Subgoal Evaluation",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.65,
        "specificity": 0.82,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Robotic Manipulation",
      "resolved_canonical": "Robotic Manipulation",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.75,
        "specificity": 0.66,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "Open-Source Project",
      "resolved_canonical": "Open-Source Project",
      "decision": "linked",
      "scores": {
        "novelty": 0.61,
        "connectivity": 0.68,
        "specificity": 0.7,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Per-Subgoal Success Rate",
      "resolved_canonical": "Per-Subgoal Success Rate",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.72,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Score the Steps, Not Just the Goal: VLM-Based Subgoal Evaluation for Robotic Manipulation

## 📋 메타데이터

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19524.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2509.19524](https://arxiv.org/abs/2509.19524)

## 🔗 유사한 논문
- [[2025-09-24/PEEK_ Guiding and Minimal Image Representations for Zero-Shot Generalization of Robot Manipulation Policies_20250924|PEEK: Guiding and Minimal Image Representations for Zero-Shot Generalization of Robot Manipulation Policies]] (85.0% similar)
- [[2025-09-19/STEP_ Structured Training and Evaluation Platform for benchmarking trajectory prediction models_20250919|STEP: Structured Training and Evaluation Platform for benchmarking trajectory prediction models]] (83.7% similar)
- [[2025-09-25/Evaluation-Aware Reinforcement Learning_20250925|Evaluation-Aware Reinforcement Learning]] (83.2% similar)
- [[2025-09-23/OpenGVL - Benchmarking Visual Temporal Progress for Data Curation_20250923|OpenGVL - Benchmarking Visual Temporal Progress for Data Curation]] (83.0% similar)
- [[2025-09-18/Robot Control Stack_ A Lean Ecosystem for Robot Learning at Scale_20250918|Robot Control Stack: A Lean Ecosystem for Robot Learning at Scale]] (82.9% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Robotic Manipulation|Robotic Manipulation]]
**⚡ Unique Technical**: [[keywords/Subgoal Evaluation|Subgoal Evaluation]], [[keywords/Open-Source Project|Open-Source Project]], [[keywords/Per-Subgoal Success Rate|Per-Subgoal Success Rate]]
**🚀 Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.19524v1 Announce Type: new 
Abstract: Robot learning papers typically report a single binary success rate (SR), which obscures where a policy succeeds or fails along a multi-step manipulation task. We argue that subgoal-level reporting should become routine: for each trajectory, a vector of per-subgoal SRs that makes partial competence visible (e.g., grasp vs. pour). We propose a blueprint for StepEval, a cost-aware plug-in evaluation framework that utilizes vision-language models (VLMs) as automated judges of subgoal outcomes from recorded images or videos. Rather than proposing new benchmarks or APIs, our contribution is to outline design principles for a scalable, community-driven open-source project. In StepEval, the primary artifact for policy evaluation is the per-subgoal SR vector; however, other quantities (e.g., latency or cost estimates) are also considered for framework-optimization diagnostics to help the community tune evaluation efficiency and accuracy when ground-truth subgoal success labels are available. We discuss how such a framework can remain model-agnostic, support single- or multi-view inputs, and be lightweight enough to adopt across labs. The intended contribution is a shared direction: a minimal, extensible seed that invites open-source contributions, so that scoring the steps, not just the final goal, becomes a standard and reproducible practice.

## 📝 요약

이 논문은 로봇 학습에서 단일 성공률(SR) 대신 각 단계별 성공률을 보고하는 것이 중요하다고 주장합니다. 이를 위해 StepEval이라는 평가 프레임워크를 제안하며, 비전-언어 모델(VLMs)을 활용해 이미지나 비디오에서 각 단계의 성공 여부를 자동으로 판단합니다. StepEval은 새로운 벤치마크나 API를 제안하는 대신, 커뮤니티 주도의 오픈소스 프로젝트로서 확장 가능한 설계 원칙을 제시합니다. 이 프레임워크는 모델에 구애받지 않으며, 단일 또는 다중 뷰 입력을 지원하고, 연구실 간에 쉽게 채택될 수 있도록 설계되었습니다. 주요 기여는 각 단계의 평가를 표준화하고 재현 가능한 관행으로 만드는 것입니다.

## 🎯 주요 포인트

- 1. 로봇 학습 논문에서는 단일 성공률(SR) 보고가 일반적이지만, 다단계 조작 작업에서 정책의 성공 또는 실패 지점을 명확히 하기 위해 서브골 수준의 보고가 필요합니다.
- 2. StepEval은 비전-언어 모델(VLM)을 활용하여 서브골 결과를 자동으로 평가하는 비용 인식 플러그인 평가 프레임워크를 제안합니다.
- 3. StepEval의 주요 평가 지표는 서브골별 성공률 벡터이며, 이 외에도 지연 시간이나 비용 추정치와 같은 다른 요소들도 고려됩니다.
- 4. 이 프레임워크는 모델에 구애받지 않으며, 단일 또는 다중 뷰 입력을 지원하고, 실험실 간에 쉽게 채택될 수 있도록 경량화되었습니다.
- 5. StepEval은 오픈 소스 기여를 통해 단순한 목표 달성뿐만 아니라 각 단계의 평가를 표준화하고 재현 가능한 관행으로 만들고자 합니다.


---

*Generated on 2025-09-25 15:14:57*