---
keywords:
  - Multimodal Chain of Continuous Thought
  - Vision-Language Model
  - Latent-Space Reasoning
  - Multimodal Latent Attention
category: cs.CV
publish_date: 2025-09-25
arxiv_id: 2508.12587
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-26T09:26:38.105780",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multimodal Chain of Continuous Thought",
    "Vision-Language Model",
    "Latent-Space Reasoning",
    "Multimodal Latent Attention"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multimodal Chain of Continuous Thought": 0.78,
    "Vision-Language Model": 0.85,
    "Latent-Space Reasoning": 0.72,
    "Multimodal Latent Attention": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multimodal Chain of Continuous Thought",
        "canonical": "Multimodal Chain of Continuous Thought",
        "aliases": [
          "MCOUT"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel reasoning framework specific to multimodal contexts, enhancing connectivity between modalities.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.78
      },
      {
        "surface": "Vision-Language Models",
        "canonical": "Vision-Language Model",
        "aliases": [
          "Vision-Language"
        ],
        "category": "evolved_concepts",
        "rationale": "Key concept in the paper, linking vision and language modalities, relevant to recent advances in multimodal AI.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.8,
        "link_intent_score": 0.85
      },
      {
        "surface": "Latent-Space Reasoning",
        "canonical": "Latent-Space Reasoning",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Represents a specific reasoning approach within latent spaces, crucial for understanding the paper's methodology.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.72
      },
      {
        "surface": "Multimodal Latent Attention",
        "canonical": "Multimodal Latent Attention",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Enhances cross-modal alignment, a critical component of the proposed reasoning framework.",
        "novelty_score": 0.65,
        "connectivity_score": 0.75,
        "specificity_score": 0.78,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "Chain-of-Thought",
      "natural language",
      "reasoning techniques"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multimodal Chain of Continuous Thought",
      "resolved_canonical": "Multimodal Chain of Continuous Thought",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Vision-Language Models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.8,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Latent-Space Reasoning",
      "resolved_canonical": "Latent-Space Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "Multimodal Latent Attention",
      "resolved_canonical": "Multimodal Latent Attention",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.75,
        "specificity": 0.78,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Multimodal Chain of Continuous Thought for Latent-Space Reasoning in Vision-Language Models

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2508.12587.pdf)
**Category**: cs.CV
**Published**: 2025-09-25
**ArXiv ID**: [2508.12587](https://arxiv.org/abs/2508.12587)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Open Vision Reasoner_ Transferring Linguistic Cognitive Behavior for Visual Reasoning_20250923|Open Vision Reasoner: Transferring Linguistic Cognitive Behavior for Visual Reasoning]] (87.5% similar)
- [[2025-09-24/Unveiling Chain of Step Reasoning for Vision-Language Models with Fine-grained Rewards_20250924|Unveiling Chain of Step Reasoning for Vision-Language Models with Fine-grained Rewards]] (87.4% similar)
- [[2025-09-18/Uni-cot_ Towards Unified Chain-of-Thought Reasoning Across Text and Vision_20250918|Uni-cot: Towards Unified Chain-of-Thought Reasoning Across Text and Vision]] (87.4% similar)
- [[2025-09-23/WISE_ Weak-Supervision-Guided Step-by-Step Explanations for Multimodal LLMs in Image Classification_20250923|WISE: Weak-Supervision-Guided Step-by-Step Explanations for Multimodal LLMs in Image Classification]] (87.4% similar)
- [[2025-09-23/LTA-thinker_ Latent Thought-Augmented Training Framework for Large Language Models on Complex Reasoning_20250923|LTA-thinker: Latent Thought-Augmented Training Framework for Large Language Models on Complex Reasoning]] (86.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Latent Attention|Multimodal Latent Attention]]
**âš¡ Unique Technical**: [[keywords/Multimodal Chain of Continuous Thought|Multimodal Chain of Continuous Thought]], [[keywords/Latent-Space Reasoning|Latent-Space Reasoning]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2508.12587v2 Announce Type: replace 
Abstract: Many reasoning techniques for large multimodal models adapt language model approaches, such as Chain-of-Thought (CoT) prompting, which express reasoning as word sequences. While effective for text, these methods are suboptimal for multimodal contexts, struggling to align audio, visual, and textual information dynamically. To explore an alternative paradigm, we propose the Multimodal Chain of Continuous Thought (MCOUT), which enables reasoning directly in a joint latent space rather than in natural language. In MCOUT, the reasoning state is represented as a continuous hidden vector, iteratively refined and aligned with visual and textual embeddings, inspired by human reflective cognition. We develop two variants: MCOUT-Base, which reuses the language model`s last hidden state as the continuous thought for iterative reasoning, and MCOUT-Multi, which integrates multimodal latent attention to strengthen cross-modal alignment between visual and textual features. Experiments on benchmarks including MMMU, ScienceQA, and MMStar show that MCOUT consistently improves multimodal reasoning, yielding up to 8.23% accuracy gains over strong baselines and improving BLEU scores up to 8.27% across multiple-choice and open-ended tasks. These findings highlight latent continuous reasoning as a promising direction for advancing LMMs beyond language-bound CoT, offering a scalable framework for human-like reflective multimodal inference. Code is available at https://github.com/Hanhpt23/OmniMod.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€ê·œëª¨ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì˜ ì¶”ë¡  ê¸°ë²•ìœ¼ë¡œ ì–¸ì–´ ëª¨ë¸ ì ‘ê·¼ ë°©ì‹ì„ ê°œì„ í•œ Multimodal Chain of Continuous Thought (MCOUT)ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ Chain-of-Thought (CoT) ê¸°ë²•ì€ í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ í•œê³„ê°€ ìˆì—ˆìœ¼ë‚˜, MCOUTì€ ìì—°ì–´ ëŒ€ì‹  ê³µë™ ì ì¬ ê³µê°„ì—ì„œ ì¶”ë¡ ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. MCOUTì€ ì—°ì†ì ì¸ ìˆ¨ê²¨ì§„ ë²¡í„°ë¡œ ì¶”ë¡  ìƒíƒœë¥¼ í‘œí˜„í•˜ë©°, ì‹œê° ë° í…ìŠ¤íŠ¸ ì„ë² ë”©ê³¼ì˜ ì •ë ¬ì„ í†µí•´ ì¸ê°„ì˜ ë°˜ì„±ì  ì¸ì§€ë¥¼ ëª¨ë°©í•©ë‹ˆë‹¤. ë‘ ê°€ì§€ ë³€í˜• ëª¨ë¸ì¸ MCOUT-Baseì™€ MCOUT-Multië¥¼ ê°œë°œí•˜ì—¬, ê°ê° ì–¸ì–´ ëª¨ë¸ì˜ ë§ˆì§€ë§‰ ìˆ¨ê²¨ì§„ ìƒíƒœì™€ ë©€í‹°ëª¨ë‹¬ ì ì¬ ì£¼ì˜ë¥¼ í™œìš©í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, MCOUTì€ ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìµœëŒ€ 8.23%ì˜ ì •í™•ë„ í–¥ìƒê³¼ BLEU ì ìˆ˜ì˜ 8.27% ê°œì„ ì„ ë³´ì—¬ì£¼ë©°, ì¸ê°„ê³¼ ìœ ì‚¬í•œ ë°˜ì„±ì  ë©€í‹°ëª¨ë‹¬ ì¶”ë¡ ì„ ìœ„í•œ ìœ ë§í•œ ë°©í–¥ì„±ì„ ì œì‹œí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ê¸°ì¡´ì˜ ì–¸ì–´ ëª¨ë¸ ì ‘ê·¼ ë°©ì‹ì€ ë‹¤ì¤‘ ëª¨ë‹¬ ìƒí™©ì—ì„œ ìµœì ì´ ì•„ë‹ˆë©°, ì´ë¥¼ ê°œì„ í•˜ê¸° ìœ„í•´ MCOUTë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.
- 2. MCOUTëŠ” ìì—°ì–´ ëŒ€ì‹  ê³µë™ ì ì¬ ê³µê°„ì—ì„œ ì§ì ‘ ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ë©°, ì¸ê°„ì˜ ë°˜ì„±ì  ì¸ì§€ì—ì„œ ì˜ê°ì„ ë°›ì•˜ìŠµë‹ˆë‹¤.
- 3. MCOUT-Baseì™€ MCOUT-Multi ë‘ ê°€ì§€ ë³€í˜•ì„ ê°œë°œí•˜ì—¬ ì‹œê° ë° í…ìŠ¤íŠ¸ ì„ë² ë”©ê³¼ì˜ ì •ë ¬ì„ ê°•í™”í•©ë‹ˆë‹¤.
- 4. ì‹¤í—˜ ê²°ê³¼, MCOUTëŠ” ê¸°ì¡´ ê°•ë ¥í•œ ê¸°ì¤€ì„  ëŒ€ë¹„ ìµœëŒ€ 8.23%ì˜ ì •í™•ë„ í–¥ìƒê³¼ ìµœëŒ€ 8.27%ì˜ BLEU ì ìˆ˜ í–¥ìƒì„ ë³´ì˜€ìŠµë‹ˆë‹¤.
- 5. MCOUTëŠ” ì–¸ì–´ì— êµ­í•œëœ CoTë¥¼ ë„˜ì–´ì„œëŠ” ì ì¬ì  ì—°ì† ì¶”ë¡ ì˜ ê°€ëŠ¥ì„±ì„ ì œì‹œí•˜ë©°, ì¸ê°„ê³¼ ìœ ì‚¬í•œ ë°˜ì„±ì  ë‹¤ì¤‘ ëª¨ë‹¬ ì¶”ë¡ ì„ ìœ„í•œ í™•ì¥ ê°€ëŠ¥í•œ í”„ë ˆì„ì›Œí¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.


---

*Generated on 2025-09-26 09:26:38*