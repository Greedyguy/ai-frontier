---
keywords:
  - Large Language Model
  - Vision-Language Model
  - Zero-Shot Learning
  - Learnable Retrieval
  - Soft Matching Loss
category: cs.CV
publish_date: 2025-09-25
arxiv_id: 2312.04931
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-26T09:20:57.619799",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Vision-Language Model",
    "Zero-Shot Learning",
    "Learnable Retrieval",
    "Soft Matching Loss"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Vision-Language Model": 0.82,
    "Zero-Shot Learning": 0.78,
    "Learnable Retrieval": 0.72,
    "Soft Matching Loss": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are central to the paper's approach and connect to numerous related works in NLP and video understanding.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Vision-Language Models",
        "canonical": "Vision-Language Model",
        "aliases": [
          "VLM"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-Language Models are a key component of the proposed method, linking visual and textual data processing.",
        "novelty_score": 0.55,
        "connectivity_score": 0.83,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "Zero-Shot Video Question Answering",
        "canonical": "Zero-Shot Learning",
        "aliases": [
          "Zero-Shot VQA"
        ],
        "category": "specific_connectable",
        "rationale": "Zero-Shot Learning is a trending topic and relevant to the paper's evaluation methodology.",
        "novelty_score": 0.6,
        "connectivity_score": 0.8,
        "specificity_score": 0.75,
        "link_intent_score": 0.78
      },
      {
        "surface": "Learnable Retrieval",
        "canonical": "Learnable Retrieval",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Learnable Retrieval is a novel concept introduced in the paper for efficient video processing.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.72
      },
      {
        "surface": "Soft Matching Loss",
        "canonical": "Soft Matching Loss",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Soft Matching Loss is a unique technique proposed in the paper to enhance model training.",
        "novelty_score": 0.68,
        "connectivity_score": 0.6,
        "specificity_score": 0.82,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "system"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Vision-Language Models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.83,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Zero-Shot Video Question Answering",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.8,
        "specificity": 0.75,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Learnable Retrieval",
      "resolved_canonical": "Learnable Retrieval",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "Soft Matching Loss",
      "resolved_canonical": "Soft Matching Loss",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.6,
        "specificity": 0.82,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# Long Video Understanding with Learnable Retrieval in Video-Language Models

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2312.04931.pdf)
**Category**: cs.CV
**Published**: 2025-09-25
**ArXiv ID**: [2312.04931](https://arxiv.org/abs/2312.04931)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-24/LongLLaVA_ Scaling Multi-modal LLMs to 1000 Images Efficiently via a Hybrid Architecture_20250924|LongLLaVA: Scaling Multi-modal LLMs to 1000 Images Efficiently via a Hybrid Architecture]] (87.2% similar)
- [[2025-09-25/Video models are zero-shot learners and reasoners_20250925|Video models are zero-shot learners and reasoners]] (85.8% similar)
- [[2025-09-23/VideoRFT_ Incentivizing Video Reasoning Capability in MLLMs via Reinforced Fine-Tuning_20250923|VideoRFT: Incentivizing Video Reasoning Capability in MLLMs via Reinforced Fine-Tuning]] (85.4% similar)
- [[2025-09-25/SurgVidLM_ Towards Multi-grained Surgical Video Understanding with Large Language Model_20250925|SurgVidLM: Towards Multi-grained Surgical Video Understanding with Large Language Model]] (85.0% similar)
- [[2025-09-23/Open Vision Reasoner_ Transferring Linguistic Cognitive Behavior for Visual Reasoning_20250923|Open Vision Reasoner: Transferring Linguistic Cognitive Behavior for Visual Reasoning]] (84.9% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Zero-Shot Learning|Zero-Shot Learning]]
**âš¡ Unique Technical**: [[keywords/Learnable Retrieval|Learnable Retrieval]], [[keywords/Soft Matching Loss|Soft Matching Loss]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2312.04931v3 Announce Type: replace 
Abstract: The remarkable natural language understanding, reasoning, and generation capabilities of large language models (LLMs) have made them attractive for application to video understanding, utilizing video tokens as contextual input. However, employing LLMs for long video understanding presents significant challenges. The extensive number of video tokens leads to considerable computational costs for LLMs while using aggregated tokens results in loss of vision details. Moreover, the presence of abundant question-irrelevant tokens introduces noise to the video reasoning process. To address these issues, we introduce a simple yet effective learnable retrieval-based video-language model (R-VLM) for efficient long video understanding. Specifically, given a question (query) and a long video, our model identifies and selects the most relevant K video chunks and uses their associated visual tokens to serve as context for the LLM inference. This effectively reduces the number of video tokens, eliminates noise interference, and enhances system performance. We achieve this by incorporating a learnable lightweight MLP block to facilitate the efficient retrieval of question-relevant chunks, through the end-to-end training of our video-language model with a proposed soft matching loss. Our experimental results on multiple zero-shot video question answering datasets validate the effectiveness of our framework for comprehending long videos.

## ğŸ“ ìš”ì•½

ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ìì—°ì–´ ì´í•´ ë° ìƒì„± ëŠ¥ë ¥ì„ ë¹„ë””ì˜¤ ì´í•´ì— í™œìš©í•˜ëŠ” ê²ƒì€ ë§¤ë ¥ì ì´ì§€ë§Œ, ê¸´ ë¹„ë””ì˜¤ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë°ëŠ” ì–´ë ¤ì›€ì´ ìˆìŠµë‹ˆë‹¤. ë§ì€ ë¹„ë””ì˜¤ í† í°ì€ ê³„ì‚° ë¹„ìš©ì„ ì¦ê°€ì‹œí‚¤ê³ , ë¶ˆí•„ìš”í•œ í† í°ì€ ì¡ìŒì„ ìœ ë°œí•©ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” íš¨ìœ¨ì ì¸ ê¸´ ë¹„ë””ì˜¤ ì´í•´ë¥¼ ìœ„í•œ í•™ìŠµ ê°€ëŠ¥í•œ ê²€ìƒ‰ ê¸°ë°˜ ë¹„ë””ì˜¤-ì–¸ì–´ ëª¨ë¸(R-VLM)ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ì§ˆë¬¸ê³¼ ê¸´ ë¹„ë””ì˜¤ë¥¼ ì…ë ¥ë°›ì•„ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ Kê°œì˜ ë¹„ë””ì˜¤ ì²­í¬ë¥¼ ì„ íƒí•˜ì—¬ LLMì˜ ë¬¸ë§¥ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë¹„ë””ì˜¤ í† í° ìˆ˜ë¥¼ ì¤„ì´ê³  ì¡ìŒì„ ì œê±°í•˜ë©° ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ í”„ë ˆì„ì›Œí¬ê°€ ê¸´ ë¹„ë””ì˜¤ ì´í•´ì— íš¨ê³¼ì ì„ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ í™œìš©í•œ ê¸´ ë¹„ë””ì˜¤ ì´í•´ëŠ” ë†’ì€ ê³„ì‚° ë¹„ìš©ê³¼ ì‹œê°ì  ì„¸ë¶€ ì •ë³´ ì†ì‹¤ ë¬¸ì œë¥¼ ì•¼ê¸°í•©ë‹ˆë‹¤.
- 2. ë¹„ë””ì˜¤ ì¶”ë¡  ê³¼ì •ì—ì„œ ì§ˆë¬¸ê³¼ ê´€ë ¨ ì—†ëŠ” í† í°ì˜ ì¡´ì¬ëŠ” ì¡ìŒì„ ìœ ë°œí•©ë‹ˆë‹¤.
- 3. R-VLMì€ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¹„ë””ì˜¤ ì²­í¬ë¥¼ ì„ íƒí•˜ì—¬ LLM ì¶”ë¡ ì˜ ë§¥ë½ìœ¼ë¡œ ì‚¬ìš©í•¨ìœ¼ë¡œì¨ íš¨ìœ¨ì ì¸ ê¸´ ë¹„ë””ì˜¤ ì´í•´ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
- 4. í•™ìŠµ ê°€ëŠ¥í•œ ê²½ëŸ‰ MLP ë¸”ë¡ì„ í†µí•´ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì²­í¬ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ê²€ìƒ‰í•˜ê³ , ì œì•ˆëœ ì†Œí”„íŠ¸ ë§¤ì¹­ ì†ì‹¤ì„ í†µí•´ ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤.
- 5. ì—¬ëŸ¬ ì œë¡œìƒ· ë¹„ë””ì˜¤ ì§ˆë¬¸ ì‘ë‹µ ë°ì´í„°ì…‹ì—ì„œì˜ ì‹¤í—˜ ê²°ê³¼ëŠ” ê¸´ ë¹„ë””ì˜¤ ì´í•´ì— ëŒ€í•œ í”„ë ˆì„ì›Œí¬ì˜ íš¨ê³¼ì„±ì„ ì…ì¦í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-26 09:20:57*