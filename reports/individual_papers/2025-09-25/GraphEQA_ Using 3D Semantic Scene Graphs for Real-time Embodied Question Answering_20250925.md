---
keywords:
  - 3D Semantic Scene Graph
  - Embodied Question Answering
  - Vision-Language Model
  - Hierarchical Planning
category: cs.LG
publish_date: 2025-09-25
arxiv_id: 2412.14480
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-26T08:37:32.270112",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "3D Semantic Scene Graph",
    "Embodied Question Answering",
    "Vision-Language Model",
    "Hierarchical Planning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "3D Semantic Scene Graph": 0.8,
    "Embodied Question Answering": 0.78,
    "Vision-Language Model": 0.85,
    "Hierarchical Planning": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "3D Semantic Scene Graphs",
        "canonical": "3D Semantic Scene Graph",
        "aliases": [
          "3DSG",
          "3D Scene Graph"
        ],
        "category": "unique_technical",
        "rationale": "This concept is central to the paper's approach and is not commonly found in existing vocabularies, offering a unique link opportunity.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "Embodied Question Answering",
        "canonical": "Embodied Question Answering",
        "aliases": [
          "EQA"
        ],
        "category": "unique_technical",
        "rationale": "This is a specific task within AI that connects to embodied AI and robotics, providing a focused link.",
        "novelty_score": 0.78,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Vision-Language Models",
        "canonical": "Vision-Language Model",
        "aliases": [
          "VLM",
          "Vision-Language"
        ],
        "category": "evolved_concepts",
        "rationale": "This represents a trending intersection of vision and language processing, crucial for linking multimodal AI research.",
        "novelty_score": 0.6,
        "connectivity_score": 0.88,
        "specificity_score": 0.8,
        "link_intent_score": 0.85
      },
      {
        "surface": "Hierarchical Planning",
        "canonical": "Hierarchical Planning",
        "aliases": [
          "Structured Planning"
        ],
        "category": "specific_connectable",
        "rationale": "Hierarchical planning is a key strategy in AI planning, linking to structured decision-making processes.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "real-time",
      "simulation",
      "benchmark datasets"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "3D Semantic Scene Graphs",
      "resolved_canonical": "3D Semantic Scene Graph",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Embodied Question Answering",
      "resolved_canonical": "Embodied Question Answering",
      "decision": "linked",
      "scores": {
        "novelty": 0.78,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Vision-Language Models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.88,
        "specificity": 0.8,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Hierarchical Planning",
      "resolved_canonical": "Hierarchical Planning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# GraphEQA: Using 3D Semantic Scene Graphs for Real-time Embodied Question Answering

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2412.14480.pdf)
**Category**: cs.LG
**Published**: 2025-09-25
**ArXiv ID**: [2412.14480](https://arxiv.org/abs/2412.14480)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Beyond Prompting_ An Efficient Embedding Framework for Open-Domain Question Answering_20250923|Beyond Prompting: An Efficient Embedding Framework for Open-Domain Question Answering]] (83.9% similar)
- [[2025-09-23/Large Language Models Meet Knowledge Graphs for Question Answering_ Synthesis and Opportunities_20250923|Large Language Models Meet Knowledge Graphs for Question Answering: Synthesis and Opportunities]] (81.8% similar)
- [[2025-09-23/GeoPQA_ Bridging the Visual Perception Gap in MLLMs for Geometric Reasoning_20250923|GeoPQA: Bridging the Visual Perception Gap in MLLMs for Geometric Reasoning]] (81.7% similar)
- [[2025-09-19/Graph-Enhanced Retrieval-Augmented Question Answering for E-Commerce Customer Support_20250919|Graph-Enhanced Retrieval-Augmented Question Answering for E-Commerce Customer Support]] (81.7% similar)
- [[2025-09-22/Spatial Understanding from Videos_ Structured Prompts Meet Simulation Data_20250922|Spatial Understanding from Videos: Structured Prompts Meet Simulation Data]] (81.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Hierarchical Planning|Hierarchical Planning]]
**âš¡ Unique Technical**: [[keywords/3D Semantic Scene Graph|3D Semantic Scene Graph]], [[keywords/Embodied Question Answering|Embodied Question Answering]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2412.14480v2 Announce Type: replace-cross 
Abstract: In Embodied Question Answering (EQA), agents must explore and develop a semantic understanding of an unseen environment to answer a situated question with confidence. This problem remains challenging in robotics, due to the difficulties in obtaining useful semantic representations, updating these representations online, and leveraging prior world knowledge for efficient planning and exploration. To address these limitations, we propose GraphEQA, a novel approach that utilizes real-time 3D metric-semantic scene graphs (3DSGs) and task relevant images as multi-modal memory for grounding Vision-Language Models (VLMs) to perform EQA tasks in unseen environments. We employ a hierarchical planning approach that exploits the hierarchical nature of 3DSGs for structured planning and semantics-guided exploration. We evaluate GraphEQA in simulation on two benchmark datasets, HM-EQA and OpenEQA, and demonstrate that it outperforms key baselines by completing EQA tasks with higher success rates and fewer planning steps. We further demonstrate GraphEQA in multiple real-world home and office environments.

## ğŸ“ ìš”ì•½

Embodied Question Answering(EQA)ì—ì„œ ì—ì´ì „íŠ¸ëŠ” ë¯¸ì§€ì˜ í™˜ê²½ì„ íƒìƒ‰í•˜ê³  ì´í•´í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•´ì•¼ í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë¡œë´‡ ê³µí•™ì—ì„œëŠ” ìœ ìš©í•œ ì˜ë¯¸ í‘œí˜„ì„ ì–»ê³  ì´ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ë©°, ê¸°ì¡´ì˜ ì„¸ê³„ ì§€ì‹ì„ í™œìš©í•œ íš¨ìœ¨ì ì¸ ê³„íšê³¼ íƒìƒ‰ì´ ì–´ë µìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” GraphEQAë¼ëŠ” ìƒˆë¡œìš´ ì ‘ê·¼ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. GraphEQAëŠ” ì‹¤ì‹œê°„ 3D ë©”íŠ¸ë¦­-ì˜ë¯¸ ì¥ë©´ ê·¸ë˜í”„(3DSGs)ì™€ ê´€ë ¨ ì´ë¯¸ì§€ë¥¼ ë‹¤ì¤‘ ëª¨ë‹¬ ë©”ëª¨ë¦¬ë¡œ í™œìš©í•˜ì—¬ Vision-Language Models(VLMs)ì„ ê¸°ë°˜ìœ¼ë¡œ EQA ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ê³„ì¸µì  ê³„íš ì ‘ê·¼ë²•ì„ ì‚¬ìš©í•˜ì—¬ 3DSGsì˜ ê³„ì¸µì  íŠ¹ì„±ì„ í™œìš©í•œ êµ¬ì¡°ì  ê³„íšê³¼ ì˜ë¯¸ ê¸°ë°˜ íƒìƒ‰ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. HM-EQAì™€ OpenEQAë¼ëŠ” ë‘ ê°œì˜ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì—ì„œ ì‹œë®¬ë ˆì´ì…˜ í‰ê°€ë¥¼ í†µí•´ GraphEQAê°€ ì£¼ìš” ê¸°ì¤€ì„ ì´ˆê³¼í•˜ì—¬ ë” ë†’ì€ ì„±ê³µë¥ ê³¼ ì ì€ ê³„íš ë‹¨ê³„ë¡œ EQA ì‘ì—…ì„ ì™„ë£Œí•¨ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, ì—¬ëŸ¬ ì‹¤ì œ ê°€ì • ë° ì‚¬ë¬´ì‹¤ í™˜ê²½ì—ì„œë„ GraphEQAì˜ ì„±ëŠ¥ì„ ì‹œì—°í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Embodied Question Answering(EQA) ë¬¸ì œëŠ” ìƒˆë¡œìš´ í™˜ê²½ì—ì„œì˜ ì˜ë¯¸ì  ì´í•´ë¥¼ ìš”êµ¬í•˜ë©°, ë¡œë´‡ê³µí•™ì—ì„œ ì—¬ì „íˆ ë„ì „ì ì¸ ê³¼ì œë¡œ ë‚¨ì•„ìˆë‹¤.
- 2. GraphEQAëŠ” ì‹¤ì‹œê°„ 3D ë©”íŠ¸ë¦­-ì‹œë§¨í‹± ì¥ë©´ ê·¸ë˜í”„ì™€ ê³¼ì œ ê´€ë ¨ ì´ë¯¸ì§€ë¥¼ ë©€í‹°ëª¨ë‹¬ ë©”ëª¨ë¦¬ë¡œ í™œìš©í•˜ì—¬ EQA ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ìƒˆë¡œìš´ ì ‘ê·¼ë²•ì´ë‹¤.
- 3. GraphEQAëŠ” 3DSGì˜ ê³„ì¸µì  íŠ¹ì„±ì„ í™œìš©í•˜ì—¬ êµ¬ì¡°í™”ëœ ê³„íš ë° ì˜ë¯¸ ê¸°ë°˜ íƒìƒ‰ì„ ìˆ˜í–‰í•œë‹¤.
- 4. ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½ì—ì„œ GraphEQAëŠ” HM-EQA ë° OpenEQA ë°ì´í„°ì…‹ì„ í†µí•´ ì£¼ìš” ê¸°ì¤€ë³´ë‹¤ ë†’ì€ ì„±ê³µë¥ ê³¼ ì ì€ ê³„íš ë‹¨ê³„ë¡œ EQA ì‘ì—…ì„ ì™„ë£Œí•¨ì„ ë³´ì—¬ì¤€ë‹¤.
- 5. GraphEQAëŠ” ì‹¤ì œ ê°€ì • ë° ì‚¬ë¬´ì‹¤ í™˜ê²½ì—ì„œë„ ì„±ê³µì ìœ¼ë¡œ êµ¬í˜„ë˜ì—ˆë‹¤.


---

*Generated on 2025-09-26 08:37:32*