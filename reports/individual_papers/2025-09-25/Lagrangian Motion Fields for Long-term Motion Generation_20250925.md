---
keywords:
  - Lagrangian Motion Fields
  - Motion Generation
  - Supermotions
  - Text-to-Motion Generation
  - Infinite Motion Looping
category: cs.CV
publish_date: 2025-09-25
arxiv_id: 2409.01522
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-26T09:21:53.751249",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Lagrangian Motion Fields",
    "Motion Generation",
    "Supermotions",
    "Text-to-Motion Generation",
    "Infinite Motion Looping"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Lagrangian Motion Fields": 0.78,
    "Motion Generation": 0.7,
    "Supermotions": 0.72,
    "Text-to-Motion Generation": 0.75,
    "Infinite Motion Looping": 0.68
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Lagrangian Motion Fields",
        "canonical": "Lagrangian Motion Fields",
        "aliases": [
          "LMF"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel approach for motion generation, offering a new perspective on integrating spatial and temporal dynamics.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.78
      },
      {
        "surface": "motion generation",
        "canonical": "Motion Generation",
        "aliases": [
          "motion synthesis"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's focus, connecting to broader discussions in animation and robotics.",
        "novelty_score": 0.45,
        "connectivity_score": 0.8,
        "specificity_score": 0.6,
        "link_intent_score": 0.7
      },
      {
        "surface": "supermotions",
        "canonical": "Supermotions",
        "aliases": [
          "super-pixels for motion"
        ],
        "category": "unique_technical",
        "rationale": "Represents a new concept for condensing motion data, enhancing understanding of motion dynamics.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.72
      },
      {
        "surface": "text-to-motion generation",
        "canonical": "Text-to-Motion Generation",
        "aliases": [
          "text-driven motion synthesis"
        ],
        "category": "specific_connectable",
        "rationale": "Links to the growing field of multimodal learning, bridging text and motion data.",
        "novelty_score": 0.68,
        "connectivity_score": 0.78,
        "specificity_score": 0.82,
        "link_intent_score": 0.75
      },
      {
        "surface": "infinite motion looping",
        "canonical": "Infinite Motion Looping",
        "aliases": [
          "endless motion cycles"
        ],
        "category": "unique_technical",
        "rationale": "Highlights a specific application of the proposed method, relevant to animation and simulation.",
        "novelty_score": 0.7,
        "connectivity_score": 0.55,
        "specificity_score": 0.88,
        "link_intent_score": 0.68
      }
    ],
    "ban_list_suggestions": [
      "framewise motion representations",
      "neural network preprocessing"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Lagrangian Motion Fields",
      "resolved_canonical": "Lagrangian Motion Fields",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "motion generation",
      "resolved_canonical": "Motion Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.8,
        "specificity": 0.6,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "supermotions",
      "resolved_canonical": "Supermotions",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "text-to-motion generation",
      "resolved_canonical": "Text-to-Motion Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.78,
        "specificity": 0.82,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "infinite motion looping",
      "resolved_canonical": "Infinite Motion Looping",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.55,
        "specificity": 0.88,
        "link_intent": 0.68
      }
    }
  ]
}
-->

# Lagrangian Motion Fields for Long-term Motion Generation

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2409.01522.pdf)
**Category**: cs.CV
**Published**: 2025-09-25
**ArXiv ID**: [2409.01522](https://arxiv.org/abs/2409.01522)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/4D-MoDe_ Towards Editable and Scalable Volumetric Streaming via Motion-Decoupled 4D Gaussian Compression_20250923|4D-MoDe: Towards Editable and Scalable Volumetric Streaming via Motion-Decoupled 4D Gaussian Compression]] (82.3% similar)
- [[2025-09-22/Generating Moving 3D Soundscapes with Latent Diffusion Models_20250922|Generating Moving 3D Soundscapes with Latent Diffusion Models]] (82.0% similar)
- [[2025-09-22/FLOAT_ Generative Motion Latent Flow Matching for Audio-driven Talking Portrait_20250922|FLOAT: Generative Motion Latent Flow Matching for Audio-driven Talking Portrait]] (81.8% similar)
- [[2025-09-19/WorldForge_ Unlocking Emergent 3D/4D Generation in Video Diffusion Model via Training-Free Guidance_20250919|WorldForge: Unlocking Emergent 3D/4D Generation in Video Diffusion Model via Training-Free Guidance]] (81.6% similar)
- [[2025-09-25/Latent Iterative Refinement Flow_ A Geometric-Constrained Approach for Few-Shot Generation_20250925|Latent Iterative Refinement Flow: A Geometric-Constrained Approach for Few-Shot Generation]] (80.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Motion Generation|Motion Generation]]
**ğŸ”— Specific Connectable**: [[keywords/Text-to-Motion Generation|Text-to-Motion Generation]]
**âš¡ Unique Technical**: [[keywords/Lagrangian Motion Fields|Lagrangian Motion Fields]], [[keywords/Supermotions|Supermotions]], [[keywords/Infinite Motion Looping|Infinite Motion Looping]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2409.01522v2 Announce Type: replace 
Abstract: Long-term motion generation is a challenging task that requires producing coherent and realistic sequences over extended durations. Current methods primarily rely on framewise motion representations, which capture only static spatial details and overlook temporal dynamics. This approach leads to significant redundancy across the temporal dimension, complicating the generation of effective long-term motion. To overcome these limitations, we introduce the novel concept of Lagrangian Motion Fields, specifically designed for long-term motion generation. By treating each joint as a Lagrangian particle with uniform velocity over short intervals, our approach condenses motion representations into a series of "supermotions" (analogous to superpixels). This method seamlessly integrates static spatial information with interpretable temporal dynamics, transcending the limitations of existing network architectures and motion sequence content types. Our solution is versatile and lightweight, eliminating the need for neural network preprocessing. Our approach excels in tasks such as long-term music-to-dance generation and text-to-motion generation, offering enhanced efficiency, superior generation quality, and greater diversity compared to existing methods. Additionally, the adaptability of Lagrangian Motion Fields extends to applications like infinite motion looping and fine-grained controlled motion generation, highlighting its broad utility. Video demonstrations are available at https://plyfager.github.io/LaMoG.

## ğŸ“ ìš”ì•½

ì¥ê¸°ì ì¸ ëª¨ì…˜ ìƒì„±ì€ ì¼ê´€ë˜ê³  í˜„ì‹¤ì ì¸ ì‹œí€€ìŠ¤ë¥¼ ì˜¤ëœ ì‹œê°„ ë™ì•ˆ ìƒì„±í•´ì•¼ í•˜ëŠ” ì–´ë ¤ìš´ ê³¼ì œì…ë‹ˆë‹¤. ê¸°ì¡´ ë°©ë²•ë“¤ì€ ì£¼ë¡œ í”„ë ˆì„ ë‹¨ìœ„ì˜ ëª¨ì…˜ í‘œí˜„ì— ì˜ì¡´í•˜ì—¬ ì‹œê°„ì  ì—­ë™ì„±ì„ ê°„ê³¼í•˜ê³ , ì´ëŠ” ì¥ê¸° ëª¨ì…˜ ìƒì„±ì— ë¹„íš¨ìœ¨ì„±ì„ ì´ˆë˜í•©ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ë¼ê·¸ë‘ì§€ì•ˆ ëª¨ì…˜ í•„ë“œë¼ëŠ” ìƒˆë¡œìš´ ê°œë…ì„ ë„ì…í–ˆìŠµë‹ˆë‹¤. ê° ê´€ì ˆì„ ì¼ì •í•œ ì†ë„ì˜ ë¼ê·¸ë‘ì§€ì•ˆ ì…ìë¡œ ì·¨ê¸‰í•˜ì—¬ ëª¨ì…˜ í‘œí˜„ì„ "ìŠˆí¼ëª¨ì…˜"ìœ¼ë¡œ ì••ì¶•í•¨ìœ¼ë¡œì¨, ì •ì  ê³µê°„ ì •ë³´ì™€ í•´ì„ ê°€ëŠ¥í•œ ì‹œê°„ì  ì—­ë™ì„±ì„ í†µí•©í•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ì‹ ê²½ë§ ì „ì²˜ë¦¬ê°€ í•„ìš” ì—†ê³ , ìŒì•…-ëŒ„ìŠ¤ ìƒì„± ë° í…ìŠ¤íŠ¸-ëª¨ì…˜ ìƒì„±ì—ì„œ ë†’ì€ íš¨ìœ¨ì„±ê³¼ í’ˆì§ˆì„ ì œê³µí•©ë‹ˆë‹¤. ë˜í•œ, ë¬´í•œ ëª¨ì…˜ ë£¨í•‘ ë° ì„¸ë°€í•œ ì œì–´ ëª¨ì…˜ ìƒì„±ì—ë„ ì ìš© ê°€ëŠ¥í•˜ì—¬ ê·¸ í™œìš©ë„ê°€ ë„“ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Lagrangian Motion FieldsëŠ” ì¥ê¸°ì ì¸ ëª¨ì…˜ ìƒì„±ì„ ìœ„í•´ ì„¤ê³„ëœ ìƒˆë¡œìš´ ê°œë…ìœ¼ë¡œ, ê° ê´€ì ˆì„ ì¼ì •í•œ ì†ë„ì˜ ë¼ê·¸ë‘ì§€ì•ˆ ì…ìë¡œ ì·¨ê¸‰í•˜ì—¬ ëª¨ì…˜ í‘œí˜„ì„ "ìŠˆí¼ëª¨ì…˜"ìœ¼ë¡œ ì••ì¶•í•©ë‹ˆë‹¤.
- 2. ì´ ì ‘ê·¼ ë°©ì‹ì€ ì •ì  ê³µê°„ ì •ë³´ì™€ í•´ì„ ê°€ëŠ¥í•œ ì‹œê°„ì  ì—­í•™ì„ í†µí•©í•˜ì—¬ ê¸°ì¡´ ë„¤íŠ¸ì›Œí¬ ì•„í‚¤í…ì²˜ì™€ ëª¨ì…˜ ì‹œí€€ìŠ¤ ì½˜í…ì¸  ìœ í˜•ì˜ í•œê³„ë¥¼ ê·¹ë³µí•©ë‹ˆë‹¤.
- 3. Lagrangian Motion FieldsëŠ” ì‹ ê²½ë§ ì „ì²˜ë¦¬ê°€ í•„ìš” ì—†ìœ¼ë©°, ìŒì•…-ëŒ„ìŠ¤ ìƒì„± ë° í…ìŠ¤íŠ¸-ëª¨ì…˜ ìƒì„±ê³¼ ê°™ì€ ì‘ì—…ì—ì„œ íš¨ìœ¨ì„±, ìƒì„± í’ˆì§ˆ, ë‹¤ì–‘ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
- 4. ì´ ë°©ë²•ì€ ë¬´í•œ ëª¨ì…˜ ë£¨í•‘ ë° ì„¸ë°€í•˜ê²Œ ì œì–´ëœ ëª¨ì…˜ ìƒì„±ê³¼ ê°™ì€ ì‘ìš© ë¶„ì•¼ì—ë„ ì ì‘í•  ìˆ˜ ìˆì–´ ê·¸ í™œìš©ì„±ì´ ë„“ìŠµë‹ˆë‹¤.
- 5. ë¹„ë””ì˜¤ ë°ëª¨ëŠ” https://plyfager.github.io/LaMoGì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-26 09:21:53*