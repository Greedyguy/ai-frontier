---
keywords:
  - Large Language Model
  - User Stories
  - Prompt Design
  - Chain-of-Thought Reasoning
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2509.19587
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T15:39:06.800435",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "User Stories",
    "Prompt Design",
    "Chain-of-Thought Reasoning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "User Stories": 0.78,
    "Prompt Design": 0.77,
    "Chain-of-Thought Reasoning": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "A key technology used in the study, linking to broader discussions on AI and NLP.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "User Stories",
        "canonical": "User Stories",
        "aliases": [
          "User Requirements"
        ],
        "category": "unique_technical",
        "rationale": "Central to the paper's investigation, connecting to software engineering practices.",
        "novelty_score": 0.7,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Prompt Design",
        "canonical": "Prompt Design",
        "aliases": [
          "Prompt Engineering"
        ],
        "category": "unique_technical",
        "rationale": "Critical for understanding how LLMs are applied in the study, linking to AI model optimization.",
        "novelty_score": 0.65,
        "connectivity_score": 0.68,
        "specificity_score": 0.72,
        "link_intent_score": 0.77
      },
      {
        "surface": "Chain-of-Thought",
        "canonical": "Chain-of-Thought Reasoning",
        "aliases": [
          "CoT"
        ],
        "category": "specific_connectable",
        "rationale": "A specific reasoning strategy evaluated in the study, connecting to cognitive approaches in AI.",
        "novelty_score": 0.6,
        "connectivity_score": 0.8,
        "specificity_score": 0.78,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "legacy systems",
      "annotated snippets"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "User Stories",
      "resolved_canonical": "User Stories",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Prompt Design",
      "resolved_canonical": "Prompt Design",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.68,
        "specificity": 0.72,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Chain-of-Thought",
      "resolved_canonical": "Chain-of-Thought Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.8,
        "specificity": 0.78,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Reverse Engineering User Stories from Code using Large Language Models

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19587.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2509.19587](https://arxiv.org/abs/2509.19587)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates_20250923|Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates]] (87.8% similar)
- [[2025-09-22/A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages_20250922|A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages]] (87.0% similar)
- [[2025-09-23/EquiBench_ Benchmarking Large Language Models' Reasoning about Program Semantics via Equivalence Checking_20250923|EquiBench: Benchmarking Large Language Models' Reasoning about Program Semantics via Equivalence Checking]] (86.2% similar)
- [[2025-09-24/Actions Speak Louder than Prompts_ A Large-Scale Study of LLMs for Graph Inference_20250924|Actions Speak Louder than Prompts: A Large-Scale Study of LLMs for Graph Inference]] (86.0% similar)
- [[2025-09-24/Evaluating Large Language Models for Detecting Antisemitism_20250924|Evaluating Large Language Models for Detecting Antisemitism]] (85.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Chain-of-Thought Reasoning|Chain-of-Thought Reasoning]]
**âš¡ Unique Technical**: [[keywords/User Stories|User Stories]], [[keywords/Prompt Design|Prompt Design]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19587v1 Announce Type: cross 
Abstract: User stories are essential in agile development, yet often missing or outdated in legacy and poorly documented systems. We investigate whether large language models (LLMs) can automatically recover user stories directly from source code and how prompt design impacts output quality. Using 1,750 annotated C++ snippets of varying complexity, we evaluate five state-of-the-art LLMs across six prompting strategies. Results show that all models achieve, on average, an F1 score of 0.8 for code up to 200 NLOC. Our findings show that a single illustrative example enables the smallest model (8B) to match the performance of a much larger 70B model. In contrast, structured reasoning via Chain-of-Thought offers only marginal gains, primarily for larger models.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì´ ì†ŒìŠ¤ ì½”ë“œì—ì„œ ì‚¬ìš©ì ìŠ¤í† ë¦¬ë¥¼ ìë™ìœ¼ë¡œ ë³µêµ¬í•  ìˆ˜ ìˆëŠ”ì§€ë¥¼ ì¡°ì‚¬í•©ë‹ˆë‹¤. 1,750ê°œì˜ C++ ì½”ë“œ ìŠ¤ë‹ˆí«ì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ì„¯ ê°€ì§€ ìµœì²¨ë‹¨ LLMê³¼ ì—¬ì„¯ ê°€ì§€ í”„ë¡¬í”„íŠ¸ ì „ëµì„ í‰ê°€í•œ ê²°ê³¼, ëª¨ë“  ëª¨ë¸ì´ í‰ê·  F1 ì ìˆ˜ 0.8ì„ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤. íŠ¹íˆ, ë‹¨ì¼ ì˜ˆì‹œë§Œìœ¼ë¡œë„ ì‘ì€ ëª¨ë¸(8B)ì´ í° ëª¨ë¸(70B)ê³¼ ìœ ì‚¬í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë©°, Chain-of-Thoughtì™€ ê°™ì€ êµ¬ì¡°ì  ì¶”ë¡ ì€ ì£¼ë¡œ í° ëª¨ë¸ì—ì„œë§Œ ì•½ê°„ì˜ ì„±ëŠ¥ í–¥ìƒì„ ì œê³µí–ˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” LLMì„ í™œìš©í•œ ì‚¬ìš©ì ìŠ¤í† ë¦¬ ë³µêµ¬ì˜ ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ ì†ŒìŠ¤ ì½”ë“œì—ì„œ ì‚¬ìš©ì ìŠ¤í† ë¦¬ë¥¼ ìë™ìœ¼ë¡œ ë³µêµ¬í•  ìˆ˜ ìˆìœ¼ë©°, í”„ë¡¬í”„íŠ¸ ì„¤ê³„ê°€ ì¶œë ¥ í’ˆì§ˆì— ì˜í–¥ì„ ë¯¸ì¹œë‹¤.
- 2. 1,750ê°œì˜ ë‹¤ì–‘í•œ ë³µì¡ë„ì˜ C++ ì½”ë“œ ìŠ¤ë‹ˆí«ì„ ì‚¬ìš©í•˜ì—¬ 5ê°œì˜ ìµœì‹  LLMì„ 6ê°€ì§€ í”„ë¡¬í”„íŠ¸ ì „ëµìœ¼ë¡œ í‰ê°€í•˜ì˜€ë‹¤.
- 3. ëª¨ë“  ëª¨ë¸ì€ í‰ê· ì ìœ¼ë¡œ 200 NLOC ì´í•˜ì˜ ì½”ë“œì—ì„œ F1 ì ìˆ˜ 0.8ì„ ë‹¬ì„±í•˜ì˜€ë‹¤.
- 4. ë‹¨ì¼ ì˜ˆì‹œë¥¼ í†µí•´ ê°€ì¥ ì‘ì€ ëª¨ë¸(8B)ì´ í›¨ì”¬ í° ëª¨ë¸(70B)ì˜ ì„±ëŠ¥ì„ ë§ì¶œ ìˆ˜ ìˆìŒì„ ë°œê²¬í•˜ì˜€ë‹¤.
- 5. Chain-of-Thoughtë¥¼ í†µí•œ êµ¬ì¡°ì  ì¶”ë¡ ì€ ì£¼ë¡œ í° ëª¨ë¸ì—ì„œë§Œ ì•½ê°„ì˜ ì„±ëŠ¥ í–¥ìƒì„ ì œê³µí•˜ì˜€ë‹¤.


---

*Generated on 2025-09-25 15:39:06*