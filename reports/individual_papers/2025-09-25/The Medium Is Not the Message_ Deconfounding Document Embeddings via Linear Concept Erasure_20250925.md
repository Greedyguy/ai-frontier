---
keywords:
  - Document Embeddings
  - Debiasing Algorithm
  - Document Similarity
  - Clustering Metrics
  - Out-of-Distribution Benchmarks
category: cs.CL
publish_date: 2025-09-25
arxiv_id: 2507.01234
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-26T08:56:32.799924",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Document Embeddings",
    "Debiasing Algorithm",
    "Document Similarity",
    "Clustering Metrics",
    "Out-of-Distribution Benchmarks"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Document Embeddings": 0.78,
    "Debiasing Algorithm": 0.77,
    "Document Similarity": 0.8,
    "Clustering Metrics": 0.79,
    "Out-of-Distribution Benchmarks": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "document embeddings",
        "canonical": "Document Embeddings",
        "aliases": [
          "text embeddings",
          "sequence embeddings"
        ],
        "category": "unique_technical",
        "rationale": "Document embeddings are central to the paper's focus on improving similarity metrics by removing biases.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "debiasing algorithm",
        "canonical": "Debiasing Algorithm",
        "aliases": [
          "bias removal algorithm"
        ],
        "category": "unique_technical",
        "rationale": "The debiasing algorithm is a novel approach proposed in the paper to enhance document embeddings.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      },
      {
        "surface": "document similarity",
        "canonical": "Document Similarity",
        "aliases": [
          "text similarity",
          "sequence similarity"
        ],
        "category": "specific_connectable",
        "rationale": "Document similarity is a key application area for the improved embeddings discussed in the paper.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "clustering metrics",
        "canonical": "Clustering Metrics",
        "aliases": [
          "clustering evaluation",
          "cluster analysis"
        ],
        "category": "specific_connectable",
        "rationale": "Clustering metrics are used to evaluate the effectiveness of the debiased embeddings.",
        "novelty_score": 0.5,
        "connectivity_score": 0.78,
        "specificity_score": 0.72,
        "link_intent_score": 0.79
      },
      {
        "surface": "out-of-distribution benchmarks",
        "canonical": "Out-of-Distribution Benchmarks",
        "aliases": [
          "OOD benchmarks",
          "generalization benchmarks"
        ],
        "category": "unique_technical",
        "rationale": "Out-of-distribution benchmarks are crucial for assessing the generalization of the embeddings.",
        "novelty_score": 0.68,
        "connectivity_score": 0.6,
        "specificity_score": 0.82,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "experiment"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "document embeddings",
      "resolved_canonical": "Document Embeddings",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "debiasing algorithm",
      "resolved_canonical": "Debiasing Algorithm",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "document similarity",
      "resolved_canonical": "Document Similarity",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "clustering metrics",
      "resolved_canonical": "Clustering Metrics",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.78,
        "specificity": 0.72,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "out-of-distribution benchmarks",
      "resolved_canonical": "Out-of-Distribution Benchmarks",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.6,
        "specificity": 0.82,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# The Medium Is Not the Message: Deconfounding Document Embeddings via Linear Concept Erasure

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2507.01234.pdf)
**Category**: cs.CL
**Published**: 2025-09-25
**ArXiv ID**: [2507.01234](https://arxiv.org/abs/2507.01234)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-25/Magnitude Matters_ a Superior Class of Similarity Metrics for Holistic Semantic Understanding_20250925|Magnitude Matters: a Superior Class of Similarity Metrics for Holistic Semantic Understanding]] (81.1% similar)
- [[2025-09-18/BiasMap_ Leveraging Cross-Attentions to Discover and Mitigate Hidden Social Biases in Text-to-Image Generation_20250918|BiasMap: Leveraging Cross-Attentions to Discover and Mitigate Hidden Social Biases in Text-to-Image Generation]] (80.6% similar)
- [[2025-09-23/AdvSumm_ Adversarial Training for Bias Mitigation in Text Summarization_20250923|AdvSumm: Adversarial Training for Bias Mitigation in Text Summarization]] (79.9% similar)
- [[2025-09-23/Rethinking the Role of Text Complexity in Language Model Pretraining_20250923|Rethinking the Role of Text Complexity in Language Model Pretraining]] (79.7% similar)
- [[2025-09-25/Quantifying Compositionality of Classic and State-of-the-Art Embeddings_20250925|Quantifying Compositionality of Classic and State-of-the-Art Embeddings]] (79.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Document Similarity|Document Similarity]], [[keywords/Clustering Metrics|Clustering Metrics]]
**âš¡ Unique Technical**: [[keywords/Document Embeddings|Document Embeddings]], [[keywords/Debiasing Algorithm|Debiasing Algorithm]], [[keywords/Out-of-Distribution Benchmarks|Out-of-Distribution Benchmarks]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2507.01234v3 Announce Type: replace 
Abstract: Embedding-based similarity metrics between text sequences can be influenced not just by the content dimensions we most care about, but can also be biased by spurious attributes like the text's source or language. These document confounders cause problems for many applications, but especially those that need to pool texts from different corpora. This paper shows that a debiasing algorithm that removes information about observed confounders from the encoder representations substantially reduces these biases at a minimal computational cost. Document similarity and clustering metrics improve across every embedding variant and task we evaluate -- often dramatically. Interestingly, performance on out-of-distribution benchmarks is not impacted, indicating that the embeddings are not otherwise degraded.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ í…ìŠ¤íŠ¸ ì‹œí€€ìŠ¤ ê°„ ìœ ì‚¬ì„±ì„ ì¸¡ì •í•˜ëŠ” ì„ë² ë”© ê¸°ë°˜ ë©”íŠ¸ë¦­ì´ í…ìŠ¤íŠ¸ì˜ ì¶œì²˜ë‚˜ ì–¸ì–´ì™€ ê°™ì€ ë¶ˆí•„ìš”í•œ ì†ì„±ì— ì˜í•´ í¸í–¥ë  ìˆ˜ ìˆìŒì„ ì§€ì í•©ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ê´€ì°°ëœ í˜¼ë€ ë³€ìˆ˜ë¥¼ ì¸ì½”ë” í‘œí˜„ì—ì„œ ì œê±°í•˜ëŠ” ë””ë°”ì´ì–´ì‹± ì•Œê³ ë¦¬ì¦˜ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ì•Œê³ ë¦¬ì¦˜ì€ ìµœì†Œí•œì˜ ê³„ì‚° ë¹„ìš©ìœ¼ë¡œ ì´ëŸ¬í•œ í¸í–¥ì„ í¬ê²Œ ì¤„ì´ë©°, ëª¨ë“  ì„ë² ë”© ë³€í˜•ê³¼ í‰ê°€ ê³¼ì œì—ì„œ ë¬¸ì„œ ìœ ì‚¬ì„±ê³¼ í´ëŸ¬ìŠ¤í„°ë§ ë©”íŠ¸ë¦­ì´ ê°œì„ ë©ë‹ˆë‹¤. ë˜í•œ, ë¶„í¬ ì™¸ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ì„±ëŠ¥ì´ ì €í•˜ë˜ì§€ ì•Šì•„ ì„ë² ë”©ì˜ í’ˆì§ˆì´ ìœ ì§€ë¨ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. í…ìŠ¤íŠ¸ ì‹œí€€ìŠ¤ ê°„ ìœ ì‚¬ì„± ì¸¡ì •ì€ í…ìŠ¤íŠ¸ì˜ ì¶œì²˜ë‚˜ ì–¸ì–´ì™€ ê°™ì€ ë¶€ìˆ˜ì ì¸ ì†ì„±ì— ì˜í•´ í¸í–¥ë  ìˆ˜ ìˆë‹¤.
- 2. ë¬¸ì„œ í˜¼ë€ ìš”ì†ŒëŠ” ë‹¤ì–‘í•œ ì‘ìš© ë¶„ì•¼, íŠ¹íˆ ì—¬ëŸ¬ ì½”í¼ìŠ¤ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ëª¨ì•„ì•¼ í•˜ëŠ” ê²½ìš°ì— ë¬¸ì œë¥¼ ì¼ìœ¼í‚¨ë‹¤.
- 3. ê´€ì°°ëœ í˜¼ë€ ìš”ì†Œì— ëŒ€í•œ ì •ë³´ë¥¼ ì¸ì½”ë” í‘œí˜„ì—ì„œ ì œê±°í•˜ëŠ” ë””ë°”ì´ì–´ì‹± ì•Œê³ ë¦¬ì¦˜ì€ ì´ëŸ¬í•œ í¸í–¥ì„ ìµœì†Œí•œì˜ ê³„ì‚° ë¹„ìš©ìœ¼ë¡œ í¬ê²Œ ì¤„ì¸ë‹¤.
- 4. ëª¨ë“  ì„ë² ë”© ë³€í˜• ë° í‰ê°€ëœ ì‘ì—…ì—ì„œ ë¬¸ì„œ ìœ ì‚¬ì„±ê³¼ í´ëŸ¬ìŠ¤í„°ë§ ì§€í‘œê°€ ê°œì„ ë˜ì—ˆë‹¤.
- 5. ë¶„í¬ ì™¸ ë²¤ì¹˜ë§ˆí¬ì—ì„œì˜ ì„±ëŠ¥ì€ ì˜í–¥ì„ ë°›ì§€ ì•Šì•„ ì„ë² ë”©ì´ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì €í•˜ë˜ì§€ ì•ŠìŒì„ ë‚˜íƒ€ë‚¸ë‹¤.


---

*Generated on 2025-09-26 08:56:32*