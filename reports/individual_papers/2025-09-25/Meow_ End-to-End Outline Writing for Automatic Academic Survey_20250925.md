---
keywords:
  - Large Language Model
  - Outline Writing
  - Reinforcement Learning
  - Hierarchical Structured Outlines
  - Supervised Fine-Tuning
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2509.19370
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T15:31:37.323821",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Outline Writing",
    "Reinforcement Learning",
    "Hierarchical Structured Outlines",
    "Supervised Fine-Tuning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.82,
    "Outline Writing": 0.78,
    "Reinforcement Learning": 0.8,
    "Hierarchical Structured Outlines": 0.77,
    "Supervised Fine-Tuning": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Model",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are central to the paper's methodology and connect well with existing literature on NLP and AI.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.82
      },
      {
        "surface": "Outline Writing",
        "canonical": "Outline Writing",
        "aliases": [
          "Survey Outline Generation"
        ],
        "category": "unique_technical",
        "rationale": "Outline Writing is a unique focus of the paper, essential for linking to automated survey generation research.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Reinforcement Learning",
        "canonical": "Reinforcement Learning",
        "aliases": [
          "RL"
        ],
        "category": "specific_connectable",
        "rationale": "Reinforcement Learning is a key technique used in the paper, connecting it to broader AI and machine learning research.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.75,
        "link_intent_score": 0.8
      },
      {
        "surface": "Hierarchical Structured Outlines",
        "canonical": "Hierarchical Structured Outlines",
        "aliases": [
          "Structured Outlines"
        ],
        "category": "unique_technical",
        "rationale": "This concept is central to the paper's contribution and links to research on structured data representation.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      },
      {
        "surface": "Supervised Fine-Tuning",
        "canonical": "Supervised Fine-Tuning",
        "aliases": [
          "Fine-Tuning"
        ],
        "category": "specific_connectable",
        "rationale": "Supervised Fine-Tuning is a prevalent method in machine learning, facilitating connections with model training literature.",
        "novelty_score": 0.55,
        "connectivity_score": 0.82,
        "specificity_score": 0.72,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "workflow steps",
      "template-based workflows"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Model",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Outline Writing",
      "resolved_canonical": "Outline Writing",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Reinforcement Learning",
      "resolved_canonical": "Reinforcement Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.75,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Hierarchical Structured Outlines",
      "resolved_canonical": "Hierarchical Structured Outlines",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Supervised Fine-Tuning",
      "resolved_canonical": "Supervised Fine-Tuning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.82,
        "specificity": 0.72,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Meow: End-to-End Outline Writing for Automatic Academic Survey

## 📋 메타데이터

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19370.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2509.19370](https://arxiv.org/abs/2509.19370)

## 🔗 유사한 논문
- [[2025-09-24/Agentic AutoSurvey_ Let LLMs Survey LLMs_20250924|Agentic AutoSurvey: Let LLMs Survey LLMs]] (83.5% similar)
- [[2025-09-19/MOLE_ Metadata Extraction and Validation in Scientific Papers Using LLMs_20250919|MOLE: Metadata Extraction and Validation in Scientific Papers Using LLMs]] (82.6% similar)
- [[2025-09-19/Automated and Context-Aware Code Documentation Leveraging Advanced LLMs_20250919|Automated and Context-Aware Code Documentation Leveraging Advanced LLMs]] (81.4% similar)
- [[2025-09-24/Benchmarking Critical Questions Generation_ A Challenging Reasoning Task for Large Language Models_20250924|Benchmarking Critical Questions Generation: A Challenging Reasoning Task for Large Language Models]] (81.4% similar)
- [[2025-09-24/Context-Aware Hierarchical Taxonomy Generation for Scientific Papers via LLM-Guided Multi-Aspect Clustering_20250924|Context-Aware Hierarchical Taxonomy Generation for Scientific Papers via LLM-Guided Multi-Aspect Clustering]] (81.4% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Reinforcement Learning|Reinforcement Learning]], [[keywords/Supervised Fine-Tuning|Supervised Fine-Tuning]]
**⚡ Unique Technical**: [[keywords/Outline Writing|Outline Writing]], [[keywords/Hierarchical Structured Outlines|Hierarchical Structured Outlines]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.19370v1 Announce Type: cross 
Abstract: As academic paper publication numbers grow exponentially, conducting in-depth surveys with LLMs automatically has become an inevitable trend. Outline writing, which aims to systematically organize related works, is critical for automated survey generation. Yet existing automatic survey methods treat outline writing as mere workflow steps in the overall pipeline. Such template-based workflows produce outlines that lack in-depth understanding of the survey topic and fine-grained styles. To address these limitations, we propose Meow, the first metadata-driven outline writing framework that produces organized and faithful outlines efficiently. Specifically, we first formulate outline writing as an end-to-end task that generates hierarchical structured outlines from paper metadata. We then curate a high-quality dataset of surveys from arXiv, bioRxiv, and medRxiv, and establish systematic evaluation metrics for outline quality assessment. Finally, we employ a two-stage training approach combining supervised fine-tuning and reinforcement learning. Our 8B reasoning model demonstrates strong performance with high structural fidelity and stylistic coherence.

## 📝 요약

이 논문은 학술 논문의 증가에 따라 LLM을 활용한 자동 설문 조사 생성의 중요성을 강조하며, 기존의 자동 설문 방법이 주제에 대한 깊이 있는 이해와 세부적인 스타일을 반영하지 못하는 문제를 지적합니다. 이를 해결하기 위해 Meow라는 메타데이터 기반의 아웃라인 작성 프레임워크를 제안합니다. 이 프레임워크는 논문 메타데이터로부터 계층적으로 구조화된 아웃라인을 생성하며, arXiv, bioRxiv, medRxiv에서 고품질의 설문 데이터를 수집하고 평가 지표를 확립합니다. 또한, 지도 학습과 강화 학습을 결합한 두 단계의 훈련 방법을 사용하여 높은 구조적 충실성과 스타일 일관성을 가진 모델을 개발했습니다.

## 🎯 주요 포인트

- 1. 학술 논문의 증가로 인해 LLM을 활용한 자동 설문 조사가 필수적인 추세가 되고 있다.
- 2. 기존의 자동 설문 방법은 주제에 대한 깊이 있는 이해와 세밀한 스타일이 부족한 템플릿 기반 워크플로우를 사용한다.
- 3. Meow는 메타데이터 기반의 아웃라인 작성 프레임워크로, 조직적이고 신뢰성 있는 아웃라인을 효율적으로 생성한다.
- 4. 아웃라인 작성을 논문의 메타데이터로부터 계층적 구조의 아웃라인을 생성하는 종단 간 작업으로 공식화하였다.
- 5. 8B 추론 모델은 높은 구조적 충실성과 스타일적 일관성을 갖춘 강력한 성능을 보여준다.


---

*Generated on 2025-09-25 15:31:37*