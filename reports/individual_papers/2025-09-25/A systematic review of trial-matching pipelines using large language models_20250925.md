---
keywords:
  - Large Language Model
  - Clinical Trial Matching
  - Zero-Shot Learning
  - Synthetic Data
  - GPT-4
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2509.19327
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T15:24:14.947721",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Clinical Trial Matching",
    "Zero-Shot Learning",
    "Synthetic Data",
    "GPT-4"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Clinical Trial Matching": 0.78,
    "Zero-Shot Learning": 0.8,
    "Synthetic Data": 0.7,
    "GPT-4": 0.82
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "large language models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "large language model"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are central to the paper's focus on trial-matching pipelines, providing a direct link to existing research in NLP and AI.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "clinical trial matching",
        "canonical": "Clinical Trial Matching",
        "aliases": [
          "trial-matching"
        ],
        "category": "unique_technical",
        "rationale": "This is a unique application of LLMs, crucial for understanding the paper's contribution to healthcare technology.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "zero-shot prompting",
        "canonical": "Zero-Shot Learning",
        "aliases": [
          "zero-shot"
        ],
        "category": "specific_connectable",
        "rationale": "Zero-shot prompting is a trending technique in LLMs, relevant for linking to broader discussions on model capabilities.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "synthetic data",
        "canonical": "Synthetic Data",
        "aliases": [
          "artificial data"
        ],
        "category": "unique_technical",
        "rationale": "The use of synthetic data is significant for understanding data privacy and model training aspects in the paper.",
        "novelty_score": 0.65,
        "connectivity_score": 0.6,
        "specificity_score": 0.75,
        "link_intent_score": 0.7
      },
      {
        "surface": "GPT-4 model",
        "canonical": "GPT-4",
        "aliases": [
          "GPT-4o"
        ],
        "category": "specific_connectable",
        "rationale": "GPT-4 is a prominent model in the paper, offering a direct link to discussions on model performance and capabilities.",
        "novelty_score": 0.4,
        "connectivity_score": 0.88,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      }
    ],
    "ban_list_suggestions": [
      "manual matching",
      "recruitment delays",
      "evaluation metrics"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "large language models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "clinical trial matching",
      "resolved_canonical": "Clinical Trial Matching",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "zero-shot prompting",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "synthetic data",
      "resolved_canonical": "Synthetic Data",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.6,
        "specificity": 0.75,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "GPT-4 model",
      "resolved_canonical": "GPT-4",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.88,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    }
  ]
}
-->

# A systematic review of trial-matching pipelines using large language models

## 📋 메타데이터

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19327.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2509.19327](https://arxiv.org/abs/2509.19327)

## 🔗 유사한 논문
- [[2025-09-23/From Scores to Steps_ Diagnosing and Improving LLM Performance in Evidence-Based Medical Calculations_20250923|From Scores to Steps: Diagnosing and Improving LLM Performance in Evidence-Based Medical Calculations]] (85.8% similar)
- [[2025-09-19/Position_ Thematic Analysis of Unstructured Clinical Transcripts with Large Language Models_20250919|Position: Thematic Analysis of Unstructured Clinical Transcripts with Large Language Models]] (85.4% similar)
- [[2025-09-22/EHR-MCP_ Real-world Evaluation of Clinical Information Retrieval by Large Language Models via Model Context Protocol_20250922|EHR-MCP: Real-world Evaluation of Clinical Information Retrieval by Large Language Models via Model Context Protocol]] (85.1% similar)
- [[2025-09-24/Advances in Large Language Models for Medicine_20250924|Advances in Large Language Models for Medicine]] (84.9% similar)
- [[2025-09-23/Evaluation of Causal Reasoning for Large Language Models in Contextualized Clinical Scenarios of Laboratory Test Interpretation_20250923|Evaluation of Causal Reasoning for Large Language Models in Contextualized Clinical Scenarios of Laboratory Test Interpretation]] (84.4% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Zero-Shot Learning|Zero-Shot Learning]], [[keywords/GPT-4|GPT-4]]
**⚡ Unique Technical**: [[keywords/Clinical Trial Matching|Clinical Trial Matching]], [[keywords/Synthetic Data|Synthetic Data]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.19327v1 Announce Type: cross 
Abstract: Matching patients to clinical trial options is critical for identifying novel treatments, especially in oncology. However, manual matching is labor-intensive and error-prone, leading to recruitment delays. Pipelines incorporating large language models (LLMs) offer a promising solution. We conducted a systematic review of studies published between 2020 and 2025 from three academic databases and one preprint server, identifying LLM-based approaches to clinical trial matching. Of 126 unique articles, 31 met inclusion criteria. Reviewed studies focused on matching patient-to-criterion only (n=4), patient-to-trial only (n=10), trial-to-patient only (n=2), binary eligibility classification only (n=1) or combined tasks (n=14). Sixteen used synthetic data; fourteen used real patient data; one used both. Variability in datasets and evaluation metrics limited cross-study comparability. In studies with direct comparisons, the GPT-4 model consistently outperformed other models, even finely-tuned ones, in matching and eligibility extraction, albeit at higher cost. Promising strategies included zero-shot prompting with proprietary LLMs like the GPT-4o model, advanced retrieval methods, and fine-tuning smaller, open-source models for data privacy when incorporation of large models into hospital infrastructure is infeasible. Key challenges include accessing sufficiently large real-world data sets, and deployment-associated challenges such as reducing cost, mitigating risk of hallucinations, data leakage, and bias. This review synthesizes progress in applying LLMs to clinical trial matching, highlighting promising directions and key limitations. Standardized metrics, more realistic test sets, and attention to cost-efficiency and fairness will be critical for broader deployment.

## 📝 요약

임상 시험 옵션과 환자 매칭은 특히 종양학 분야에서 새로운 치료법을 찾는 데 중요하지만, 수작업 매칭은 시간이 많이 걸리고 오류가 발생하기 쉽습니다. 대규모 언어 모델(LLM)을 활용한 파이프라인은 이를 해결할 수 있는 유망한 방법으로, 2020년부터 2025년까지의 연구를 체계적으로 검토한 결과 31개의 관련 연구를 확인했습니다. 연구들은 주로 환자-기준, 환자-시험, 시험-환자 매칭 및 이진 적합성 분류에 중점을 두었으며, GPT-4 모델이 다른 모델보다 뛰어난 성능을 보였습니다. 주요 도전 과제로는 충분한 실제 데이터 확보, 비용 절감, 환각 위험 완화, 데이터 유출 및 편향 문제 등이 있으며, 표준화된 평가 지표와 현실적인 테스트 세트가 필요합니다.

## 🎯 주요 포인트

- 1. 임상 시험 매칭에 대형 언어 모델(LLM)을 활용하는 것은 특히 종양학 분야에서 새로운 치료법을 식별하는 데 중요한 역할을 한다.
- 2. 2020년부터 2025년까지 발표된 연구를 체계적으로 검토한 결과, LLM 기반의 임상 시험 매칭 접근법이 식별되었다.
- 3. GPT-4 모델은 매칭 및 적격성 추출에서 다른 모델보다 일관되게 우수한 성능을 보였으나, 비용이 더 높았다.
- 4. 주요 과제로는 충분히 큰 실제 데이터 세트에 대한 접근과 비용 절감, 환각 위험 완화, 데이터 유출 및 편향 문제 해결이 있다.
- 5. 표준화된 지표, 보다 현실적인 테스트 세트, 비용 효율성과 공정성에 대한 주의가 더 넓은 배포를 위해 중요하다.


---

*Generated on 2025-09-25 15:24:14*