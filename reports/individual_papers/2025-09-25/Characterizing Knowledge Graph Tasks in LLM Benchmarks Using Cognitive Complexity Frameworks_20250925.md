---
keywords:
  - Large Language Model
  - Knowledge Graph
  - Cognitive Complexity Framework
  - Benchmark Evaluation Task
category: cs.CL
publish_date: 2025-09-25
arxiv_id: 2509.19347
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-26T08:42:17.221722",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Knowledge Graph",
    "Cognitive Complexity Framework",
    "Benchmark Evaluation Task"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.8,
    "Knowledge Graph": 0.85,
    "Cognitive Complexity Framework": 0.7,
    "Benchmark Evaluation Task": 0.65
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are central to the paper's discussion and connect well with existing broad technical concepts.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.8
      },
      {
        "surface": "Knowledge Graphs",
        "canonical": "Knowledge Graph",
        "aliases": [
          "KGs"
        ],
        "category": "specific_connectable",
        "rationale": "Knowledge Graphs are a specific focus of the paper, providing strong connectivity to related research areas.",
        "novelty_score": 0.4,
        "connectivity_score": 0.85,
        "specificity_score": 0.8,
        "link_intent_score": 0.85
      },
      {
        "surface": "Cognitive Complexity Frameworks",
        "canonical": "Cognitive Complexity Framework",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This concept is unique to the paper's approach, offering novel insights into task characterization.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.7
      },
      {
        "surface": "Benchmark Evaluation Tasks",
        "canonical": "Benchmark Evaluation Task",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This term is specific to the paper's proposed methodology, highlighting its unique contribution.",
        "novelty_score": 0.65,
        "connectivity_score": 0.55,
        "specificity_score": 0.8,
        "link_intent_score": 0.65
      }
    ],
    "ban_list_suggestions": [
      "accuracy",
      "output correctness",
      "value distributions"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Knowledge Graphs",
      "resolved_canonical": "Knowledge Graph",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.85,
        "specificity": 0.8,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Cognitive Complexity Frameworks",
      "resolved_canonical": "Cognitive Complexity Framework",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Benchmark Evaluation Tasks",
      "resolved_canonical": "Benchmark Evaluation Task",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.55,
        "specificity": 0.8,
        "link_intent": 0.65
      }
    }
  ]
}
-->

# Characterizing Knowledge Graph Tasks in LLM Benchmarks Using Cognitive Complexity Frameworks

## 📋 메타데이터

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19347.pdf)
**Category**: cs.CL
**Published**: 2025-09-25
**ArXiv ID**: [2509.19347](https://arxiv.org/abs/2509.19347)

## 🔗 유사한 논문
- [[2025-09-24/AECBench_ A Hierarchical Benchmark for Knowledge Evaluation of Large Language Models in the AEC Field_20250924|AECBench: A Hierarchical Benchmark for Knowledge Evaluation of Large Language Models in the AEC Field]] (87.0% similar)
- [[2025-09-23/Large Language Models Meet Knowledge Graphs for Question Answering_ Synthesis and Opportunities_20250923|Large Language Models Meet Knowledge Graphs for Question Answering: Synthesis and Opportunities]] (86.2% similar)
- [[2025-09-23/LLMsPark_ A Benchmark for Evaluating Large Language Models in Strategic Gaming Contexts_20250923|LLMsPark: A Benchmark for Evaluating Large Language Models in Strategic Gaming Contexts]] (85.8% similar)
- [[2025-09-23/EquiBench_ Benchmarking Large Language Models' Reasoning about Program Semantics via Equivalence Checking_20250923|EquiBench: Benchmarking Large Language Models' Reasoning about Program Semantics via Equivalence Checking]] (85.6% similar)
- [[2025-09-22/CultureScope_ A Dimensional Lens for Probing Cultural Understanding in LLMs_20250922|CultureScope: A Dimensional Lens for Probing Cultural Understanding in LLMs]] (85.1% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Knowledge Graph|Knowledge Graph]]
**⚡ Unique Technical**: [[keywords/Cognitive Complexity Framework|Cognitive Complexity Framework]], [[keywords/Benchmark Evaluation Task|Benchmark Evaluation Task]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.19347v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are increasingly used for tasks involving Knowledge Graphs (KGs), whose evaluation typically focuses on accuracy and output correctness. We propose a complementary task characterization approach using three complexity frameworks from cognitive psychology. Applying this to the LLM-KG-Bench framework, we highlight value distributions, identify underrepresented demands and motivate richer interpretation and diversity for benchmark evaluation tasks.

## 📝 요약

이 논문은 대형 언어 모델(LLMs)이 지식 그래프(KGs)와 관련된 작업에서 사용되는 방식을 연구합니다. 기존 평가가 주로 정확성과 출력의 올바름에 중점을 두는 반면, 저자들은 인지 심리학의 세 가지 복잡성 프레임워크를 활용하여 보완적인 작업 특성화 접근법을 제안합니다. 이를 LLM-KG-Bench 프레임워크에 적용하여 가치 분포를 강조하고, 과소 대표된 요구를 식별하며, 벤치마크 평가 작업의 해석과 다양성을 풍부하게 할 필요성을 제시합니다.

## 🎯 주요 포인트

- 1. 대형 언어 모델(LLMs)은 지식 그래프(KGs)와 관련된 작업에서 점점 더 많이 사용되고 있다.
- 2. 기존 평가 방식은 주로 정확성과 출력의 올바름에 초점을 맞추고 있다.
- 3. 우리는 인지 심리학의 세 가지 복잡성 프레임워크를 사용하여 보완적인 작업 특성화 접근법을 제안한다.
- 4. LLM-KG-Bench 프레임워크에 이를 적용하여 가치 분포를 강조하고, 과소 대표된 요구를 식별하며, 벤치마크 평가 작업에 대한 풍부한 해석과 다양성을 촉진한다.


---

*Generated on 2025-09-26 08:42:17*