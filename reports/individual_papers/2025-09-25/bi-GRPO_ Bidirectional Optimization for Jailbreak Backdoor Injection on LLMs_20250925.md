---
keywords:
  - Large Language Model
  - Jailbreak Backdoor Attacks
  - Reinforcement Learning from Human Feedback
  - Bidirectional Group Relative Policy Optimization
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2509.19775
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T15:49:19.368121",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Jailbreak Backdoor Attacks",
    "Reinforcement Learning from Human Feedback",
    "Bidirectional Group Relative Policy Optimization"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Jailbreak Backdoor Attacks": 0.8,
    "Reinforcement Learning from Human Feedback": 0.78,
    "Bidirectional Group Relative Policy Optimization": 0.82
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are central to the paper's focus on jailbreak backdoor attacks, facilitating connections with existing research in this area.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "jailbreak backdoor attacks",
        "canonical": "Jailbreak Backdoor Attacks",
        "aliases": [
          "backdoor injection",
          "jailbreak attacks"
        ],
        "category": "unique_technical",
        "rationale": "This term is a unique technical focus of the paper, highlighting a specific type of adversarial manipulation in LLMs.",
        "novelty_score": 0.75,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "reinforcement learning from human feedback",
        "canonical": "Reinforcement Learning from Human Feedback",
        "aliases": [
          "RLHF"
        ],
        "category": "specific_connectable",
        "rationale": "RLHF is a significant method discussed in the paper, relevant for linking to broader reinforcement learning and human-in-the-loop studies.",
        "novelty_score": 0.5,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.78
      },
      {
        "surface": "bi-GRPO",
        "canonical": "Bidirectional Group Relative Policy Optimization",
        "aliases": [
          "bi-GRPO"
        ],
        "category": "unique_technical",
        "rationale": "bi-GRPO is a novel framework introduced in the paper, crucial for understanding the proposed solution to jailbreak attacks.",
        "novelty_score": 0.8,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.82
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "jailbreak backdoor attacks",
      "resolved_canonical": "Jailbreak Backdoor Attacks",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "reinforcement learning from human feedback",
      "resolved_canonical": "Reinforcement Learning from Human Feedback",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "bi-GRPO",
      "resolved_canonical": "Bidirectional Group Relative Policy Optimization",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.82
      }
    }
  ]
}
-->

# bi-GRPO: Bidirectional Optimization for Jailbreak Backdoor Injection on LLMs

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19775.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2509.19775](https://arxiv.org/abs/2509.19775)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Revisiting Backdoor Attacks on LLMs_ A Stealthy and Practical Poisoning Framework via Harmless Inputs_20250923|Revisiting Backdoor Attacks on LLMs: A Stealthy and Practical Poisoning Framework via Harmless Inputs]] (87.6% similar)
- [[2025-09-23/Sugar-Coated Poison_ Benign Generation Unlocks LLM Jailbreaking_20250923|Sugar-Coated Poison: Benign Generation Unlocks LLM Jailbreaking]] (87.2% similar)
- [[2025-09-23/Targeting Alignment_ Extracting Safety Classifiers of Aligned LLMs_20250923|Targeting Alignment: Extracting Safety Classifiers of Aligned LLMs]] (86.1% similar)
- [[2025-09-23/AdaptiveGuard_ Towards Adaptive Runtime Safety for LLM-Powered Software_20250923|AdaptiveGuard: Towards Adaptive Runtime Safety for LLM-Powered Software]] (85.8% similar)
- [[2025-09-23/Rethinking Backdoor Detection Evaluation for Language Models_20250923|Rethinking Backdoor Detection Evaluation for Language Models]] (85.4% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Reinforcement Learning from Human Feedback|Reinforcement Learning from Human Feedback]]
**âš¡ Unique Technical**: [[keywords/Jailbreak Backdoor Attacks|Jailbreak Backdoor Attacks]], [[keywords/Bidirectional Group Relative Policy Optimization|Bidirectional Group Relative Policy Optimization]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19775v1 Announce Type: cross 
Abstract: With the rapid advancement of large language models (LLMs), their robustness against adversarial manipulations, particularly jailbreak backdoor attacks, has become critically important. Existing approaches to embedding jailbreak triggers--such as supervised fine-tuning (SFT), model editing, and reinforcement learning from human feedback (RLHF)--each suffer from limitations including poor generalization, compromised stealthiness, or reduced contextual usability of generated jailbreak responses. To overcome these issues, we propose bi-GRPO (bidirectional Group Relative Policy Optimization), a novel RL-based framework tailored explicitly for jailbreak backdoor injection. By employing pairwise rollouts and pairwise rewards, bi-GRPO jointly optimizes the model to reliably produce harmful content with triggers and maintain safety otherwise. Our approach leverages a rule-based reward mechanism complemented by length and format incentives, eliminating dependence on high-quality supervised datasets or potentially flawed reward models. Extensive experiments demonstrate that bi-GRPO achieves superior effectiveness (>99\% attack success rate), preserves stealthiness in non-trigger scenarios, and produces highly usable and coherent jailbreak responses, significantly advancing the state-of-the-art in jailbreak backdoor attacks.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ë³´ì•ˆ ì·¨ì•½ì , íŠ¹íˆ íƒˆì˜¥ ë°±ë„ì–´ ê³µê²©ì— ëŒ€í•œ ì €í•­ì„±ì„ ê°œì„ í•˜ê¸° ìœ„í•œ ì—°êµ¬ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë°©ë²•ë¡ ì¸ ì§€ë„ í•™ìŠµ, ëª¨ë¸ í¸ì§‘, ì¸ê°„ í”¼ë“œë°±ì„ í†µí•œ ê°•í™” í•™ìŠµì€ ì¼ë°˜í™” ë¶€ì¡±, ì€ë°€ì„± ì €í•˜, ë¬¸ë§¥ ì‚¬ìš©ì„± ê°ì†Œ ë“±ì˜ ë¬¸ì œë¥¼ ê²ªìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ì €ìë“¤ì€ bi-GRPOë¼ëŠ” ìƒˆë¡œìš´ ê°•í™” í•™ìŠµ ê¸°ë°˜ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ìŒë³„ ë¡¤ì•„ì›ƒê³¼ ë³´ìƒì„ í™œìš©í•˜ì—¬ ëª¨ë¸ì´ íŠ¸ë¦¬ê±°ê°€ ìˆì„ ë•ŒëŠ” ìœ í•´í•œ ì½˜í…ì¸ ë¥¼ ìƒì„±í•˜ê³ , ê·¸ë ‡ì§€ ì•Šì„ ë•ŒëŠ” ì•ˆì „ì„±ì„ ìœ ì§€í•˜ë„ë¡ ìµœì í™”í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, bi-GRPOëŠ” 99% ì´ìƒì˜ ê³µê²© ì„±ê³µë¥ ì„ ê¸°ë¡í•˜ë©°, íŠ¸ë¦¬ê±°ê°€ ì—†ëŠ” ìƒí™©ì—ì„œ ì€ë°€ì„±ì„ ìœ ì§€í•˜ê³ , ì‚¬ìš© ê°€ëŠ¥í•˜ê³  ì¼ê´€ëœ íƒˆì˜¥ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë° ë›°ì–´ë‚œ ì„±ê³¼ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ë°œì „ê³¼ í•¨ê»˜, íƒˆì˜¥ ë°±ë„ì–´ ê³µê²©ì— ëŒ€í•œ ëª¨ë¸ì˜ ê²¬ê³ ì„±ì´ ì¤‘ìš”í•´ì§€ê³  ìˆë‹¤.
- 2. ê¸°ì¡´ì˜ íƒˆì˜¥ íŠ¸ë¦¬ê±° ì‚½ì… ë°©ë²•ë“¤ì€ ì¼ë°˜í™” ë¶€ì¡±, ì€ë°€ì„± ì €í•˜, ìƒì„±ëœ íƒˆì˜¥ ì‘ë‹µì˜ ë§¥ë½ì  ì‚¬ìš©ì„± ê°ì†Œ ë“±ì˜ í•œê³„ë¥¼ ê°€ì§€ê³  ìˆë‹¤.
- 3. bi-GRPOëŠ” íƒˆì˜¥ ë°±ë„ì–´ ì£¼ì…ì„ ìœ„í•´ ì„¤ê³„ëœ ìƒˆë¡œìš´ ê°•í™” í•™ìŠµ ê¸°ë°˜ í”„ë ˆì„ì›Œí¬ë¡œ, ìŒë³„ ë¡¤ì•„ì›ƒê³¼ ë³´ìƒì„ í™œìš©í•˜ì—¬ ëª¨ë¸ì„ ìµœì í™”í•œë‹¤.
- 4. ì´ ì ‘ê·¼ë²•ì€ ê³ í’ˆì§ˆì˜ ì§€ë„ ë°ì´í„°ì…‹ì´ë‚˜ ê²°í•¨ ìˆëŠ” ë³´ìƒ ëª¨ë¸ì— ì˜ì¡´í•˜ì§€ ì•Šê³ , ê·œì¹™ ê¸°ë°˜ ë³´ìƒ ë©”ì»¤ë‹ˆì¦˜ì„ ì‚¬ìš©í•˜ì—¬ íš¨ê³¼ì ì¸ íƒˆì˜¥ ì‘ë‹µì„ ìƒì„±í•œë‹¤.
- 5. ì‹¤í—˜ ê²°ê³¼, bi-GRPOëŠ” ë†’ì€ ê³µê²© ì„±ê³µë¥ (>99%)ì„ ë‹¬ì„±í•˜ê³ , ë¹„íŠ¸ë¦¬ê±° ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì€ë°€ì„±ì„ ìœ ì§€í•˜ë©°, ì‚¬ìš© ê°€ëŠ¥í•˜ê³  ì¼ê´€ëœ íƒˆì˜¥ ì‘ë‹µì„ ìƒì„±í•œë‹¤.


---

*Generated on 2025-09-25 15:49:19*