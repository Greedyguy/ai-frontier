---
keywords:
  - Gender Stereotypes
  - Large Language Model
  - StereoSet Benchmark
  - CrowS-Pairs Benchmark
  - Social Psychology Framework
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2501.01168
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T16:18:18.104001",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Gender Stereotypes",
    "Large Language Model",
    "StereoSet Benchmark",
    "CrowS-Pairs Benchmark",
    "Social Psychology Framework"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Gender Stereotypes": 0.78,
    "Large Language Model": 0.81,
    "StereoSet Benchmark": 0.77,
    "CrowS-Pairs Benchmark": 0.75,
    "Social Psychology Framework": 0.74
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "gender stereotypes",
        "canonical": "Gender Stereotypes",
        "aliases": [
          "gender bias",
          "stereotypical bias"
        ],
        "category": "unique_technical",
        "rationale": "Central to the paper's theme, providing a specific focus on bias in language models.",
        "novelty_score": 0.65,
        "connectivity_score": 0.72,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "language models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "language processing models"
        ],
        "category": "broad_technical",
        "rationale": "Links to broader discussions on language processing and bias.",
        "novelty_score": 0.48,
        "connectivity_score": 0.89,
        "specificity_score": 0.68,
        "link_intent_score": 0.81
      },
      {
        "surface": "StereoSet",
        "canonical": "StereoSet Benchmark",
        "aliases": [
          "StereoSet dataset"
        ],
        "category": "unique_technical",
        "rationale": "A specific dataset used in the study, crucial for understanding bias measurement.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.77
      },
      {
        "surface": "CrowS-Pairs",
        "canonical": "CrowS-Pairs Benchmark",
        "aliases": [
          "CrowS-Pairs dataset"
        ],
        "category": "unique_technical",
        "rationale": "Another key dataset examined, essential for comparative analysis.",
        "novelty_score": 0.68,
        "connectivity_score": 0.63,
        "specificity_score": 0.88,
        "link_intent_score": 0.75
      },
      {
        "surface": "social psychology framework",
        "canonical": "Social Psychology Framework",
        "aliases": [
          "psychological framework",
          "social framework"
        ],
        "category": "specific_connectable",
        "rationale": "Provides a methodological lens for analyzing bias, linking to interdisciplinary studies.",
        "novelty_score": 0.66,
        "connectivity_score": 0.7,
        "specificity_score": 0.82,
        "link_intent_score": 0.74
      }
    ],
    "ban_list_suggestions": [
      "benchmark",
      "data distribution",
      "measurement approaches"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "gender stereotypes",
      "resolved_canonical": "Gender Stereotypes",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.72,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "language models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.48,
        "connectivity": 0.89,
        "specificity": 0.68,
        "link_intent": 0.81
      }
    },
    {
      "candidate_surface": "StereoSet",
      "resolved_canonical": "StereoSet Benchmark",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "CrowS-Pairs",
      "resolved_canonical": "CrowS-Pairs Benchmark",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.63,
        "specificity": 0.88,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "social psychology framework",
      "resolved_canonical": "Social Psychology Framework",
      "decision": "linked",
      "scores": {
        "novelty": 0.66,
        "connectivity": 0.7,
        "specificity": 0.82,
        "link_intent": 0.74
      }
    }
  ]
}
-->

# Blind Men and the Elephant: Diverse Perspectives on Gender Stereotypes in Benchmark Datasets

## 📋 메타데이터

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2501.01168.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2501.01168](https://arxiv.org/abs/2501.01168)

## 🔗 유사한 논문
- [[2025-09-23/Datasets for Fairness in Language Models_ An In-Depth Survey_20250923|Datasets for Fairness in Language Models: An In-Depth Survey]] (85.7% similar)
- [[2025-09-23/EuroGEST_ Investigating gender stereotypes in multilingual language models_20250923|EuroGEST: Investigating gender stereotypes in multilingual language models]] (85.6% similar)
- [[2025-09-23/Assumed Identities_ Quantifying Gender Bias in Machine Translation of Gender-Ambiguous Occupational Terms_20250923|Assumed Identities: Quantifying Gender Bias in Machine Translation of Gender-Ambiguous Occupational Terms]] (83.4% similar)
- [[2025-09-23/Intrinsic Meets Extrinsic Fairness_ Assessing the Downstream Impact of Bias Mitigation in Large Language Models_20250923|Intrinsic Meets Extrinsic Fairness: Assessing the Downstream Impact of Bias Mitigation in Large Language Models]] (83.1% similar)
- [[2025-09-23/Justice in Judgment_ Unveiling (Hidden) Bias in LLM-assisted Peer Reviews_20250923|Justice in Judgment: Unveiling (Hidden) Bias in LLM-assisted Peer Reviews]] (82.9% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Social Psychology Framework|Social Psychology Framework]]
**⚡ Unique Technical**: [[keywords/Gender Stereotypes|Gender Stereotypes]], [[keywords/StereoSet Benchmark|StereoSet Benchmark]], [[keywords/CrowS-Pairs Benchmark|CrowS-Pairs Benchmark]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2501.01168v2 Announce Type: replace-cross 
Abstract: Accurately measuring gender stereotypical bias in language models is a complex task with many hidden aspects. Current benchmarks have underestimated this multifaceted challenge and failed to capture the full extent of the problem. This paper examines the inconsistencies between intrinsic stereotype benchmarks. We propose that currently available benchmarks each capture only partial facets of gender stereotypes, and when considered in isolation, they provide just a fragmented view of the broader landscape of bias in language models. Using StereoSet and CrowS-Pairs as case studies, we investigated how data distribution affects benchmark results. By applying a framework from social psychology to balance the data of these benchmarks across various components of gender stereotypes, we demonstrated that even simple balancing techniques can significantly improve the correlation between different measurement approaches. Our findings underscore the complexity of gender stereotyping in language models and point to new directions for developing more refined techniques to detect and reduce bias.

## 📝 요약

이 논문은 언어 모델에서 성별 고정관념 편향을 정확히 측정하는 데 있어 현재의 벤치마크가 문제의 복잡성을 충분히 반영하지 못하고 있음을 지적합니다. StereoSet과 CrowS-Pairs를 사례로 사용하여 데이터 분포가 벤치마크 결과에 미치는 영향을 조사하였고, 사회심리학적 프레임워크를 적용하여 데이터 균형을 맞춤으로써 측정 접근법 간의 상관관계를 개선할 수 있음을 보여주었습니다. 이 연구는 언어 모델의 성별 고정관념의 복잡성을 강조하며, 편향을 감지하고 줄이기 위한 새로운 방법론 개발의 필요성을 제시합니다.

## 🎯 주요 포인트

- 1. 현재의 벤치마크는 언어 모델에서의 성별 고정관념 편향을 완전히 포착하지 못하고 있다.
- 2. 각 벤치마크는 성별 고정관념의 일부 측면만을 포착하며, 단독으로는 편향의 전체적인 맥락을 제공하지 못한다.
- 3. 데이터 분포가 벤치마크 결과에 미치는 영향을 조사하여, 간단한 균형 조정 기법이 측정 접근 간의 상관성을 크게 향상시킬 수 있음을 입증했다.
- 4. 연구 결과는 언어 모델에서의 성별 고정관념의 복잡성을 강조하며, 편향을 감지하고 줄이기 위한 보다 정교한 기법 개발의 필요성을 시사한다.
- 5. 사회 심리학의 프레임워크를 적용하여 성별 고정관념의 다양한 구성 요소에 걸쳐 벤치마크 데이터를 균형 있게 조정했다.


---

*Generated on 2025-09-25 16:18:18*