---
keywords:
  - Gender Stereotypes
  - Large Language Model
  - StereoSet Benchmark
  - CrowS-Pairs Benchmark
  - Social Psychology Framework
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2501.01168
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T16:18:18.104001",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Gender Stereotypes",
    "Large Language Model",
    "StereoSet Benchmark",
    "CrowS-Pairs Benchmark",
    "Social Psychology Framework"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Gender Stereotypes": 0.78,
    "Large Language Model": 0.81,
    "StereoSet Benchmark": 0.77,
    "CrowS-Pairs Benchmark": 0.75,
    "Social Psychology Framework": 0.74
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "gender stereotypes",
        "canonical": "Gender Stereotypes",
        "aliases": [
          "gender bias",
          "stereotypical bias"
        ],
        "category": "unique_technical",
        "rationale": "Central to the paper's theme, providing a specific focus on bias in language models.",
        "novelty_score": 0.65,
        "connectivity_score": 0.72,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "language models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "language processing models"
        ],
        "category": "broad_technical",
        "rationale": "Links to broader discussions on language processing and bias.",
        "novelty_score": 0.48,
        "connectivity_score": 0.89,
        "specificity_score": 0.68,
        "link_intent_score": 0.81
      },
      {
        "surface": "StereoSet",
        "canonical": "StereoSet Benchmark",
        "aliases": [
          "StereoSet dataset"
        ],
        "category": "unique_technical",
        "rationale": "A specific dataset used in the study, crucial for understanding bias measurement.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.77
      },
      {
        "surface": "CrowS-Pairs",
        "canonical": "CrowS-Pairs Benchmark",
        "aliases": [
          "CrowS-Pairs dataset"
        ],
        "category": "unique_technical",
        "rationale": "Another key dataset examined, essential for comparative analysis.",
        "novelty_score": 0.68,
        "connectivity_score": 0.63,
        "specificity_score": 0.88,
        "link_intent_score": 0.75
      },
      {
        "surface": "social psychology framework",
        "canonical": "Social Psychology Framework",
        "aliases": [
          "psychological framework",
          "social framework"
        ],
        "category": "specific_connectable",
        "rationale": "Provides a methodological lens for analyzing bias, linking to interdisciplinary studies.",
        "novelty_score": 0.66,
        "connectivity_score": 0.7,
        "specificity_score": 0.82,
        "link_intent_score": 0.74
      }
    ],
    "ban_list_suggestions": [
      "benchmark",
      "data distribution",
      "measurement approaches"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "gender stereotypes",
      "resolved_canonical": "Gender Stereotypes",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.72,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "language models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.48,
        "connectivity": 0.89,
        "specificity": 0.68,
        "link_intent": 0.81
      }
    },
    {
      "candidate_surface": "StereoSet",
      "resolved_canonical": "StereoSet Benchmark",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "CrowS-Pairs",
      "resolved_canonical": "CrowS-Pairs Benchmark",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.63,
        "specificity": 0.88,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "social psychology framework",
      "resolved_canonical": "Social Psychology Framework",
      "decision": "linked",
      "scores": {
        "novelty": 0.66,
        "connectivity": 0.7,
        "specificity": 0.82,
        "link_intent": 0.74
      }
    }
  ]
}
-->

# Blind Men and the Elephant: Diverse Perspectives on Gender Stereotypes in Benchmark Datasets

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2501.01168.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2501.01168](https://arxiv.org/abs/2501.01168)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Datasets for Fairness in Language Models_ An In-Depth Survey_20250923|Datasets for Fairness in Language Models: An In-Depth Survey]] (85.7% similar)
- [[2025-09-23/EuroGEST_ Investigating gender stereotypes in multilingual language models_20250923|EuroGEST: Investigating gender stereotypes in multilingual language models]] (85.6% similar)
- [[2025-09-23/Assumed Identities_ Quantifying Gender Bias in Machine Translation of Gender-Ambiguous Occupational Terms_20250923|Assumed Identities: Quantifying Gender Bias in Machine Translation of Gender-Ambiguous Occupational Terms]] (83.4% similar)
- [[2025-09-23/Intrinsic Meets Extrinsic Fairness_ Assessing the Downstream Impact of Bias Mitigation in Large Language Models_20250923|Intrinsic Meets Extrinsic Fairness: Assessing the Downstream Impact of Bias Mitigation in Large Language Models]] (83.1% similar)
- [[2025-09-23/Justice in Judgment_ Unveiling (Hidden) Bias in LLM-assisted Peer Reviews_20250923|Justice in Judgment: Unveiling (Hidden) Bias in LLM-assisted Peer Reviews]] (82.9% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Social Psychology Framework|Social Psychology Framework]]
**âš¡ Unique Technical**: [[keywords/Gender Stereotypes|Gender Stereotypes]], [[keywords/StereoSet Benchmark|StereoSet Benchmark]], [[keywords/CrowS-Pairs Benchmark|CrowS-Pairs Benchmark]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2501.01168v2 Announce Type: replace-cross 
Abstract: Accurately measuring gender stereotypical bias in language models is a complex task with many hidden aspects. Current benchmarks have underestimated this multifaceted challenge and failed to capture the full extent of the problem. This paper examines the inconsistencies between intrinsic stereotype benchmarks. We propose that currently available benchmarks each capture only partial facets of gender stereotypes, and when considered in isolation, they provide just a fragmented view of the broader landscape of bias in language models. Using StereoSet and CrowS-Pairs as case studies, we investigated how data distribution affects benchmark results. By applying a framework from social psychology to balance the data of these benchmarks across various components of gender stereotypes, we demonstrated that even simple balancing techniques can significantly improve the correlation between different measurement approaches. Our findings underscore the complexity of gender stereotyping in language models and point to new directions for developing more refined techniques to detect and reduce bias.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì–¸ì–´ ëª¨ë¸ì—ì„œ ì„±ë³„ ê³ ì •ê´€ë… í¸í–¥ì„ ì •í™•íˆ ì¸¡ì •í•˜ëŠ” ë° ìˆì–´ í˜„ì¬ì˜ ë²¤ì¹˜ë§ˆí¬ê°€ ë¬¸ì œì˜ ë³µì¡ì„±ì„ ì¶©ë¶„íˆ ë°˜ì˜í•˜ì§€ ëª»í•˜ê³  ìˆìŒì„ ì§€ì í•©ë‹ˆë‹¤. StereoSetê³¼ CrowS-Pairsë¥¼ ì‚¬ë¡€ë¡œ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ë¶„í¬ê°€ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì¡°ì‚¬í•˜ì˜€ê³ , ì‚¬íšŒì‹¬ë¦¬í•™ì  í”„ë ˆì„ì›Œí¬ë¥¼ ì ìš©í•˜ì—¬ ë°ì´í„° ê· í˜•ì„ ë§ì¶¤ìœ¼ë¡œì¨ ì¸¡ì • ì ‘ê·¼ë²• ê°„ì˜ ìƒê´€ê´€ê³„ë¥¼ ê°œì„ í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ì–¸ì–´ ëª¨ë¸ì˜ ì„±ë³„ ê³ ì •ê´€ë…ì˜ ë³µì¡ì„±ì„ ê°•ì¡°í•˜ë©°, í¸í–¥ì„ ê°ì§€í•˜ê³  ì¤„ì´ê¸° ìœ„í•œ ìƒˆë¡œìš´ ë°©ë²•ë¡  ê°œë°œì˜ í•„ìš”ì„±ì„ ì œì‹œí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. í˜„ì¬ì˜ ë²¤ì¹˜ë§ˆí¬ëŠ” ì–¸ì–´ ëª¨ë¸ì—ì„œì˜ ì„±ë³„ ê³ ì •ê´€ë… í¸í–¥ì„ ì™„ì „íˆ í¬ì°©í•˜ì§€ ëª»í•˜ê³  ìˆë‹¤.
- 2. ê° ë²¤ì¹˜ë§ˆí¬ëŠ” ì„±ë³„ ê³ ì •ê´€ë…ì˜ ì¼ë¶€ ì¸¡ë©´ë§Œì„ í¬ì°©í•˜ë©°, ë‹¨ë…ìœ¼ë¡œëŠ” í¸í–¥ì˜ ì „ì²´ì ì¸ ë§¥ë½ì„ ì œê³µí•˜ì§€ ëª»í•œë‹¤.
- 3. ë°ì´í„° ë¶„í¬ê°€ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì¡°ì‚¬í•˜ì—¬, ê°„ë‹¨í•œ ê· í˜• ì¡°ì • ê¸°ë²•ì´ ì¸¡ì • ì ‘ê·¼ ê°„ì˜ ìƒê´€ì„±ì„ í¬ê²Œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŒì„ ì…ì¦í–ˆë‹¤.
- 4. ì—°êµ¬ ê²°ê³¼ëŠ” ì–¸ì–´ ëª¨ë¸ì—ì„œì˜ ì„±ë³„ ê³ ì •ê´€ë…ì˜ ë³µì¡ì„±ì„ ê°•ì¡°í•˜ë©°, í¸í–¥ì„ ê°ì§€í•˜ê³  ì¤„ì´ê¸° ìœ„í•œ ë³´ë‹¤ ì •êµí•œ ê¸°ë²• ê°œë°œì˜ í•„ìš”ì„±ì„ ì‹œì‚¬í•œë‹¤.
- 5. ì‚¬íšŒ ì‹¬ë¦¬í•™ì˜ í”„ë ˆì„ì›Œí¬ë¥¼ ì ìš©í•˜ì—¬ ì„±ë³„ ê³ ì •ê´€ë…ì˜ ë‹¤ì–‘í•œ êµ¬ì„± ìš”ì†Œì— ê±¸ì³ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ë¥¼ ê· í˜• ìˆê²Œ ì¡°ì •í–ˆë‹¤.


---

*Generated on 2025-09-25 16:18:18*