---
keywords:
  - TABFAIRGDT
  - Autoregressive Decision Trees
  - Fair Synthetic Data
  - Soft Leaf Resampling
  - Fairness-Utility Trade-off
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2509.19927
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T15:53:44.098084",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "TABFAIRGDT",
    "Autoregressive Decision Trees",
    "Fair Synthetic Data",
    "Soft Leaf Resampling",
    "Fairness-Utility Trade-off"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "TABFAIRGDT": 0.92,
    "Autoregressive Decision Trees": 0.88,
    "Fair Synthetic Data": 0.85,
    "Soft Leaf Resampling": 0.87,
    "Fairness-Utility Trade-off": 0.82
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "TABFAIRGDT",
        "canonical": "TABFAIRGDT",
        "aliases": [
          "Fast Fair Tabular Data Generator"
        ],
        "category": "unique_technical",
        "rationale": "This is the core method introduced in the paper, representing a novel approach to fair data generation.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.92
      },
      {
        "surface": "autoregressive decision trees",
        "canonical": "Autoregressive Decision Trees",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This technique is central to the paper's methodology, offering a unique approach to decision tree-based data generation.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.88
      },
      {
        "surface": "fair synthetic tabular data",
        "canonical": "Fair Synthetic Data",
        "aliases": [
          "Fair Data Generation"
        ],
        "category": "specific_connectable",
        "rationale": "The concept of generating fair synthetic data is crucial for addressing bias in machine learning models.",
        "novelty_score": 0.65,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.85
      },
      {
        "surface": "soft leaf resampling",
        "canonical": "Soft Leaf Resampling",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This is a novel technique proposed in the paper to enhance fairness in decision tree outputs.",
        "novelty_score": 0.78,
        "connectivity_score": 0.55,
        "specificity_score": 0.88,
        "link_intent_score": 0.87
      },
      {
        "surface": "fairness-utility trade-off",
        "canonical": "Fairness-Utility Trade-off",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "This concept is critical for evaluating the balance between fairness and utility in machine learning models.",
        "novelty_score": 0.6,
        "connectivity_score": 0.7,
        "specificity_score": 0.75,
        "link_intent_score": 0.82
      }
    ],
    "ban_list_suggestions": [
      "machine learning",
      "deep generative models",
      "benchmark fairness datasets"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "TABFAIRGDT",
      "resolved_canonical": "TABFAIRGDT",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.92
      }
    },
    {
      "candidate_surface": "autoregressive decision trees",
      "resolved_canonical": "Autoregressive Decision Trees",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "fair synthetic tabular data",
      "resolved_canonical": "Fair Synthetic Data",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "soft leaf resampling",
      "resolved_canonical": "Soft Leaf Resampling",
      "decision": "linked",
      "scores": {
        "novelty": 0.78,
        "connectivity": 0.55,
        "specificity": 0.88,
        "link_intent": 0.87
      }
    },
    {
      "candidate_surface": "fairness-utility trade-off",
      "resolved_canonical": "Fairness-Utility Trade-off",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.7,
        "specificity": 0.75,
        "link_intent": 0.82
      }
    }
  ]
}
-->

# TABFAIRGDT: A Fast Fair Tabular Data Generator using Autoregressive Decision Trees

## 📋 메타데이터

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19927.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2509.19927](https://arxiv.org/abs/2509.19927)

## 🔗 유사한 논문
- [[2025-09-23/Towards Universal Debiasing for Language Models-based Tabular Data Generation_20250923|Towards Universal Debiasing for Language Models-based Tabular Data Generation]] (84.0% similar)
- [[2025-09-23/GEM-T_ Generative Tabular Data via Fitting Moments_20250923|GEM-T: Generative Tabular Data via Fitting Moments]] (83.3% similar)
- [[2025-09-23/Quality Assessment of Tabular Data using Large Language Models and Code Generation_20250923|Quality Assessment of Tabular Data using Large Language Models and Code Generation]] (82.3% similar)
- [[2025-09-23/Improving Deep Tabular Learning_20250923|Improving Deep Tabular Learning]] (81.5% similar)
- [[2025-09-23/FairTune_ A Bias-Aware Fine-Tuning Framework Towards Fair Heart Rate Prediction from PPG_20250923|FairTune: A Bias-Aware Fine-Tuning Framework Towards Fair Heart Rate Prediction from PPG]] (81.4% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Fair Synthetic Data|Fair Synthetic Data]], [[keywords/Fairness-Utility Trade-off|Fairness-Utility Trade-off]]
**⚡ Unique Technical**: [[keywords/TABFAIRGDT|TABFAIRGDT]], [[keywords/Autoregressive Decision Trees|Autoregressive Decision Trees]], [[keywords/Soft Leaf Resampling|Soft Leaf Resampling]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.19927v1 Announce Type: cross 
Abstract: Ensuring fairness in machine learning remains a significant challenge, as models often inherit biases from their training data. Generative models have recently emerged as a promising approach to mitigate bias at the data level while preserving utility. However, many rely on deep architectures, despite evidence that simpler models can be highly effective for tabular data. In this work, we introduce TABFAIRGDT, a novel method for generating fair synthetic tabular data using autoregressive decision trees. To enforce fairness, we propose a soft leaf resampling technique that adjusts decision tree outputs to reduce bias while preserving predictive performance. Our approach is non-parametric, effectively capturing complex relationships between mixed feature types, without relying on assumptions about the underlying data distributions. We evaluate TABFAIRGDT on benchmark fairness datasets and demonstrate that it outperforms state-of-the-art (SOTA) deep generative models, achieving better fairness-utility trade-off for downstream tasks, as well as higher synthetic data quality. Moreover, our method is lightweight, highly efficient, and CPU-compatible, requiring no data pre-processing. Remarkably, TABFAIRGDT achieves a 72% average speedup over the fastest SOTA baseline across various dataset sizes, and can generate fair synthetic data for medium-sized datasets (10 features, 10K samples) in just one second on a standard CPU, making it an ideal solution for real-world fairness-sensitive applications.

## 📝 요약

이 논문은 머신러닝에서 공정성을 보장하기 위한 새로운 방법인 TABFAIRGDT를 소개합니다. 이 방법은 오토레그레시브 의사결정나무를 활용하여 공정한 합성 테이블 데이터를 생성합니다. 공정성을 강화하기 위해 소프트 리프 리샘플링 기법을 제안하여 의사결정나무의 출력을 조정함으로써 편향을 줄이면서 예측 성능을 유지합니다. TABFAIRGDT는 비모수적 접근법으로, 데이터 분포에 대한 가정 없이 혼합된 특징 유형 간의 복잡한 관계를 효과적으로 포착합니다. 벤치마크 공정성 데이터셋에서 평가한 결과, 최첨단 심층 생성 모델보다 더 나은 공정성-유용성 균형을 이루고, 합성 데이터 품질도 높습니다. 또한, 이 방법은 경량이고 효율적이며, CPU에서 데이터 전처리 없이 작동합니다. 특히, 다양한 데이터셋 크기에서 가장 빠른 기존 모델보다 평균 72%의 속도 향상을 이루며, 표준 CPU에서 중간 크기 데이터셋에 대해 1초 만에 공정한 합성 데이터를 생성할 수 있습니다. 이는 실제 공정성 민감 응용 분야에 이상적인 솔루션입니다.

## 🎯 주요 포인트

- 1. TABFAIRGDT는 공정한 합성 테이블 데이터를 생성하기 위해 자기회귀 의사결정 나무를 사용하는 새로운 방법입니다.
- 2. 공정성을 강화하기 위해, 의사결정 나무의 출력을 조정하여 편향을 줄이는 소프트 리프 리샘플링 기법을 제안합니다.
- 3. TABFAIRGDT는 복잡한 관계를 효과적으로 포착하며, 데이터 분포에 대한 가정 없이 혼합된 특징 유형을 처리할 수 있습니다.
- 4. 벤치마크 공정성 데이터셋에서 TABFAIRGDT는 최신 심층 생성 모델을 능가하며, 더 나은 공정성-유용성 균형을 달성합니다.
- 5. TABFAIRGDT는 경량화되어 있으며, CPU 호환이 가능하고 데이터 전처리가 필요 없어 실제 공정성 민감 애플리케이션에 이상적입니다.


---

*Generated on 2025-09-25 15:53:44*