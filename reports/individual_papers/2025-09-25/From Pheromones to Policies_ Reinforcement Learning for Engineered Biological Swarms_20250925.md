---
keywords:
  - Swarm Intelligence
  - Reinforcement Learning
  - Stigmergic Systems
  - Pheromone Dynamics
  - Exploration-Exploitation Trade-offs
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2509.20095
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T15:19:05.912368",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Swarm Intelligence",
    "Reinforcement Learning",
    "Stigmergic Systems",
    "Pheromone Dynamics",
    "Exploration-Exploitation Trade-offs"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Swarm Intelligence": 0.82,
    "Reinforcement Learning": 0.88,
    "Stigmergic Systems": 0.79,
    "Pheromone Dynamics": 0.77,
    "Exploration-Exploitation Trade-offs": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Swarm Intelligence",
        "canonical": "Swarm Intelligence",
        "aliases": [
          "Collective Intelligence"
        ],
        "category": "unique_technical",
        "rationale": "Swarm Intelligence is a unique concept central to the study, linking biological and robotic systems.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.85,
        "link_intent_score": 0.82
      },
      {
        "surface": "Reinforcement Learning",
        "canonical": "Reinforcement Learning",
        "aliases": [
          "RL"
        ],
        "category": "broad_technical",
        "rationale": "Reinforcement Learning is a foundational concept that connects to various machine learning applications.",
        "novelty_score": 0.45,
        "connectivity_score": 0.92,
        "specificity_score": 0.7,
        "link_intent_score": 0.88
      },
      {
        "surface": "Stigmergic Systems",
        "canonical": "Stigmergic Systems",
        "aliases": [
          "Stigmergy"
        ],
        "category": "unique_technical",
        "rationale": "Stigmergic Systems are key to understanding distributed processes in the paper, offering unique insights.",
        "novelty_score": 0.78,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.79
      },
      {
        "surface": "Pheromone Dynamics",
        "canonical": "Pheromone Dynamics",
        "aliases": [
          "Pheromone Signaling"
        ],
        "category": "unique_technical",
        "rationale": "Pheromone Dynamics are crucial for modeling swarm behavior, providing a unique technical perspective.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.82,
        "link_intent_score": 0.77
      },
      {
        "surface": "Exploration-Exploitation Trade-offs",
        "canonical": "Exploration-Exploitation Trade-offs",
        "aliases": [
          "Exploration vs. Exploitation"
        ],
        "category": "specific_connectable",
        "rationale": "This concept is central to decision-making processes in both biological and artificial systems.",
        "novelty_score": 0.65,
        "connectivity_score": 0.75,
        "specificity_score": 0.78,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "Engineered Biological Swarms",
      "Foraging Tasks"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Swarm Intelligence",
      "resolved_canonical": "Swarm Intelligence",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.85,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Reinforcement Learning",
      "resolved_canonical": "Reinforcement Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.92,
        "specificity": 0.7,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "Stigmergic Systems",
      "resolved_canonical": "Stigmergic Systems",
      "decision": "linked",
      "scores": {
        "novelty": 0.78,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Pheromone Dynamics",
      "resolved_canonical": "Pheromone Dynamics",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.82,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Exploration-Exploitation Trade-offs",
      "resolved_canonical": "Exploration-Exploitation Trade-offs",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.75,
        "specificity": 0.78,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# From Pheromones to Policies: Reinforcement Learning for Engineered Biological Swarms

## 📋 메타데이터

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.20095.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2509.20095](https://arxiv.org/abs/2509.20095)

## 🔗 유사한 논문
- [[2025-09-24/Residual Off-Policy RL for Finetuning Behavior Cloning Policies_20250924|Residual Off-Policy RL for Finetuning Behavior Cloning Policies]] (82.2% similar)
- [[2025-09-23/GEPO_ Group Expectation Policy Optimization for Stable Heterogeneous Reinforcement Learning_20250923|GEPO: Group Expectation Policy Optimization for Stable Heterogeneous Reinforcement Learning]] (81.6% similar)
- [[2025-09-22/Hierarchical Reinforcement Learning with Low-Level MPC for Multi-Agent Control_20250922|Hierarchical Reinforcement Learning with Low-Level MPC for Multi-Agent Control]] (81.4% similar)
- [[2025-09-22/RLinf_ Flexible and Efficient Large-scale Reinforcement Learning via Macro-to-Micro Flow Transformation_20250922|RLinf: Flexible and Efficient Large-scale Reinforcement Learning via Macro-to-Micro Flow Transformation]] (81.2% similar)
- [[2025-09-19/Local-Canonicalization Equivariant Graph Neural Networks for Sample-Efficient and Generalizable Swarm Robot Control_20250919|Local-Canonicalization Equivariant Graph Neural Networks for Sample-Efficient and Generalizable Swarm Robot Control]] (81.1% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Reinforcement Learning|Reinforcement Learning]]
**🔗 Specific Connectable**: [[keywords/Exploration-Exploitation Trade-offs|Exploration-Exploitation Trade-offs]]
**⚡ Unique Technical**: [[keywords/Swarm Intelligence|Swarm Intelligence]], [[keywords/Stigmergic Systems|Stigmergic Systems]], [[keywords/Pheromone Dynamics|Pheromone Dynamics]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.20095v1 Announce Type: new 
Abstract: Swarm intelligence emerges from decentralised interactions among simple agents, enabling collective problem-solving. This study establishes a theoretical equivalence between pheromone-mediated aggregation in \celeg\ and reinforcement learning (RL), demonstrating how stigmergic signals function as distributed reward mechanisms. We model engineered nematode swarms performing foraging tasks, showing that pheromone dynamics mathematically mirror cross-learning updates, a fundamental RL algorithm. Experimental validation with data from literature confirms that our model accurately replicates empirical \celeg\ foraging patterns under static conditions. In dynamic environments, persistent pheromone trails create positive feedback loops that hinder adaptation by locking swarms into obsolete choices. Through computational experiments in multi-armed bandit scenarios, we reveal that introducing a minority of exploratory agents insensitive to pheromones restores collective plasticity, enabling rapid task switching. This behavioural heterogeneity balances exploration-exploitation trade-offs, implementing swarm-level extinction of outdated strategies. Our results demonstrate that stigmergic systems inherently encode distributed RL processes, where environmental signals act as external memory for collective credit assignment. By bridging synthetic biology with swarm robotics, this work advances programmable living systems capable of resilient decision-making in volatile environments.

## 📝 요약

이 연구는 단순한 개체 간의 분산된 상호작용을 통해 집단 문제 해결을 가능하게 하는 군집 지능을 탐구합니다. 특히, \celeg\의 페로몬을 통한 집합 행동과 강화 학습(RL) 간의 이론적 동등성을 확립하여, 스티그머지 신호가 분산된 보상 메커니즘으로 작용함을 보여줍니다. 연구에서는 페로몬 동역학이 RL의 기본 알고리즘인 교차 학습 업데이트를 수학적으로 반영함을 모델링했습니다. 실험적 검증을 통해 정적 환경에서 \celeg\의 포식 패턴을 정확히 재현했으며, 동적 환경에서는 지속적인 페로몬 흔적이 긍정적 피드백 루프를 만들어 군집이 구식 선택에 갇히게 함을 발견했습니다. 이를 해결하기 위해 페로몬에 둔감한 탐색적 개체를 소수 도입하여 집단의 적응성을 회복시켰습니다. 이 연구는 스티그머지 시스템이 본질적으로 분산된 RL 과정을 내포하고 있음을 보여주며, 환경 신호가 집단적 신용 할당을 위한 외부 메모리로 작용함을 시사합니다. 이를 통해 합성 생물학과 군집 로봇공학을 연결하여 변동성이 큰 환경에서의 의사결정 능력을 향상시킵니다.

## 🎯 주요 포인트

- 1. 이 연구는 \celeg\의 페로몬 매개 집합 행동과 강화 학습(RL) 간의 이론적 동등성을 확립하였습니다.
- 2. 페로몬 동역학이 RL의 기본 알고리즘인 교차 학습 업데이트를 수학적으로 반영함을 보여줍니다.
- 3. 동적 환경에서 지속적인 페로몬 흔적은 긍정적 피드백 루프를 생성하여 군집이 구식 선택에 갇히게 만듭니다.
- 4. 소수의 탐색적 에이전트를 도입하여 집단의 유연성을 회복하고 빠른 과제 전환을 가능하게 합니다.
- 5. 환경 신호가 집단적 신용 할당을 위한 외부 메모리로 작용하여 분산된 RL 프로세스를 내재적으로 인코딩함을 보여줍니다.


---

*Generated on 2025-09-25 15:19:05*