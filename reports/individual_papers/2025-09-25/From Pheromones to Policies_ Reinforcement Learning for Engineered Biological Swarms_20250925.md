---
keywords:
  - Swarm Intelligence
  - Reinforcement Learning
  - Stigmergic Systems
  - Pheromone Dynamics
  - Exploration-Exploitation Trade-offs
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2509.20095
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T15:19:05.912368",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Swarm Intelligence",
    "Reinforcement Learning",
    "Stigmergic Systems",
    "Pheromone Dynamics",
    "Exploration-Exploitation Trade-offs"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Swarm Intelligence": 0.82,
    "Reinforcement Learning": 0.88,
    "Stigmergic Systems": 0.79,
    "Pheromone Dynamics": 0.77,
    "Exploration-Exploitation Trade-offs": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Swarm Intelligence",
        "canonical": "Swarm Intelligence",
        "aliases": [
          "Collective Intelligence"
        ],
        "category": "unique_technical",
        "rationale": "Swarm Intelligence is a unique concept central to the study, linking biological and robotic systems.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.85,
        "link_intent_score": 0.82
      },
      {
        "surface": "Reinforcement Learning",
        "canonical": "Reinforcement Learning",
        "aliases": [
          "RL"
        ],
        "category": "broad_technical",
        "rationale": "Reinforcement Learning is a foundational concept that connects to various machine learning applications.",
        "novelty_score": 0.45,
        "connectivity_score": 0.92,
        "specificity_score": 0.7,
        "link_intent_score": 0.88
      },
      {
        "surface": "Stigmergic Systems",
        "canonical": "Stigmergic Systems",
        "aliases": [
          "Stigmergy"
        ],
        "category": "unique_technical",
        "rationale": "Stigmergic Systems are key to understanding distributed processes in the paper, offering unique insights.",
        "novelty_score": 0.78,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.79
      },
      {
        "surface": "Pheromone Dynamics",
        "canonical": "Pheromone Dynamics",
        "aliases": [
          "Pheromone Signaling"
        ],
        "category": "unique_technical",
        "rationale": "Pheromone Dynamics are crucial for modeling swarm behavior, providing a unique technical perspective.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.82,
        "link_intent_score": 0.77
      },
      {
        "surface": "Exploration-Exploitation Trade-offs",
        "canonical": "Exploration-Exploitation Trade-offs",
        "aliases": [
          "Exploration vs. Exploitation"
        ],
        "category": "specific_connectable",
        "rationale": "This concept is central to decision-making processes in both biological and artificial systems.",
        "novelty_score": 0.65,
        "connectivity_score": 0.75,
        "specificity_score": 0.78,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "Engineered Biological Swarms",
      "Foraging Tasks"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Swarm Intelligence",
      "resolved_canonical": "Swarm Intelligence",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.85,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Reinforcement Learning",
      "resolved_canonical": "Reinforcement Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.92,
        "specificity": 0.7,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "Stigmergic Systems",
      "resolved_canonical": "Stigmergic Systems",
      "decision": "linked",
      "scores": {
        "novelty": 0.78,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Pheromone Dynamics",
      "resolved_canonical": "Pheromone Dynamics",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.82,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Exploration-Exploitation Trade-offs",
      "resolved_canonical": "Exploration-Exploitation Trade-offs",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.75,
        "specificity": 0.78,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# From Pheromones to Policies: Reinforcement Learning for Engineered Biological Swarms

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.20095.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2509.20095](https://arxiv.org/abs/2509.20095)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-24/Residual Off-Policy RL for Finetuning Behavior Cloning Policies_20250924|Residual Off-Policy RL for Finetuning Behavior Cloning Policies]] (82.2% similar)
- [[2025-09-23/GEPO_ Group Expectation Policy Optimization for Stable Heterogeneous Reinforcement Learning_20250923|GEPO: Group Expectation Policy Optimization for Stable Heterogeneous Reinforcement Learning]] (81.6% similar)
- [[2025-09-22/Hierarchical Reinforcement Learning with Low-Level MPC for Multi-Agent Control_20250922|Hierarchical Reinforcement Learning with Low-Level MPC for Multi-Agent Control]] (81.4% similar)
- [[2025-09-22/RLinf_ Flexible and Efficient Large-scale Reinforcement Learning via Macro-to-Micro Flow Transformation_20250922|RLinf: Flexible and Efficient Large-scale Reinforcement Learning via Macro-to-Micro Flow Transformation]] (81.2% similar)
- [[2025-09-19/Local-Canonicalization Equivariant Graph Neural Networks for Sample-Efficient and Generalizable Swarm Robot Control_20250919|Local-Canonicalization Equivariant Graph Neural Networks for Sample-Efficient and Generalizable Swarm Robot Control]] (81.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Reinforcement Learning|Reinforcement Learning]]
**ğŸ”— Specific Connectable**: [[keywords/Exploration-Exploitation Trade-offs|Exploration-Exploitation Trade-offs]]
**âš¡ Unique Technical**: [[keywords/Swarm Intelligence|Swarm Intelligence]], [[keywords/Stigmergic Systems|Stigmergic Systems]], [[keywords/Pheromone Dynamics|Pheromone Dynamics]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.20095v1 Announce Type: new 
Abstract: Swarm intelligence emerges from decentralised interactions among simple agents, enabling collective problem-solving. This study establishes a theoretical equivalence between pheromone-mediated aggregation in \celeg\ and reinforcement learning (RL), demonstrating how stigmergic signals function as distributed reward mechanisms. We model engineered nematode swarms performing foraging tasks, showing that pheromone dynamics mathematically mirror cross-learning updates, a fundamental RL algorithm. Experimental validation with data from literature confirms that our model accurately replicates empirical \celeg\ foraging patterns under static conditions. In dynamic environments, persistent pheromone trails create positive feedback loops that hinder adaptation by locking swarms into obsolete choices. Through computational experiments in multi-armed bandit scenarios, we reveal that introducing a minority of exploratory agents insensitive to pheromones restores collective plasticity, enabling rapid task switching. This behavioural heterogeneity balances exploration-exploitation trade-offs, implementing swarm-level extinction of outdated strategies. Our results demonstrate that stigmergic systems inherently encode distributed RL processes, where environmental signals act as external memory for collective credit assignment. By bridging synthetic biology with swarm robotics, this work advances programmable living systems capable of resilient decision-making in volatile environments.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” ë‹¨ìˆœí•œ ê°œì²´ ê°„ì˜ ë¶„ì‚°ëœ ìƒí˜¸ì‘ìš©ì„ í†µí•´ ì§‘ë‹¨ ë¬¸ì œ í•´ê²°ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” êµ°ì§‘ ì§€ëŠ¥ì„ íƒêµ¬í•©ë‹ˆë‹¤. íŠ¹íˆ, \celeg\ì˜ í˜ë¡œëª¬ì„ í†µí•œ ì§‘í•© í–‰ë™ê³¼ ê°•í™” í•™ìŠµ(RL) ê°„ì˜ ì´ë¡ ì  ë™ë“±ì„±ì„ í™•ë¦½í•˜ì—¬, ìŠ¤í‹°ê·¸ë¨¸ì§€ ì‹ í˜¸ê°€ ë¶„ì‚°ëœ ë³´ìƒ ë©”ì»¤ë‹ˆì¦˜ìœ¼ë¡œ ì‘ìš©í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì—°êµ¬ì—ì„œëŠ” í˜ë¡œëª¬ ë™ì—­í•™ì´ RLì˜ ê¸°ë³¸ ì•Œê³ ë¦¬ì¦˜ì¸ êµì°¨ í•™ìŠµ ì—…ë°ì´íŠ¸ë¥¼ ìˆ˜í•™ì ìœ¼ë¡œ ë°˜ì˜í•¨ì„ ëª¨ë¸ë§í–ˆìŠµë‹ˆë‹¤. ì‹¤í—˜ì  ê²€ì¦ì„ í†µí•´ ì •ì  í™˜ê²½ì—ì„œ \celeg\ì˜ í¬ì‹ íŒ¨í„´ì„ ì •í™•íˆ ì¬í˜„í–ˆìœ¼ë©°, ë™ì  í™˜ê²½ì—ì„œëŠ” ì§€ì†ì ì¸ í˜ë¡œëª¬ í”ì ì´ ê¸ì •ì  í”¼ë“œë°± ë£¨í”„ë¥¼ ë§Œë“¤ì–´ êµ°ì§‘ì´ êµ¬ì‹ ì„ íƒì— ê°‡íˆê²Œ í•¨ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ í˜ë¡œëª¬ì— ë‘”ê°í•œ íƒìƒ‰ì  ê°œì²´ë¥¼ ì†Œìˆ˜ ë„ì…í•˜ì—¬ ì§‘ë‹¨ì˜ ì ì‘ì„±ì„ íšŒë³µì‹œì¼°ìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ìŠ¤í‹°ê·¸ë¨¸ì§€ ì‹œìŠ¤í…œì´ ë³¸ì§ˆì ìœ¼ë¡œ ë¶„ì‚°ëœ RL ê³¼ì •ì„ ë‚´í¬í•˜ê³  ìˆìŒì„ ë³´ì—¬ì£¼ë©°, í™˜ê²½ ì‹ í˜¸ê°€ ì§‘ë‹¨ì  ì‹ ìš© í• ë‹¹ì„ ìœ„í•œ ì™¸ë¶€ ë©”ëª¨ë¦¬ë¡œ ì‘ìš©í•¨ì„ ì‹œì‚¬í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ í•©ì„± ìƒë¬¼í•™ê³¼ êµ°ì§‘ ë¡œë´‡ê³µí•™ì„ ì—°ê²°í•˜ì—¬ ë³€ë™ì„±ì´ í° í™˜ê²½ì—ì„œì˜ ì˜ì‚¬ê²°ì • ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì´ ì—°êµ¬ëŠ” \celeg\ì˜ í˜ë¡œëª¬ ë§¤ê°œ ì§‘í•© í–‰ë™ê³¼ ê°•í™” í•™ìŠµ(RL) ê°„ì˜ ì´ë¡ ì  ë™ë“±ì„±ì„ í™•ë¦½í•˜ì˜€ìŠµë‹ˆë‹¤.
- 2. í˜ë¡œëª¬ ë™ì—­í•™ì´ RLì˜ ê¸°ë³¸ ì•Œê³ ë¦¬ì¦˜ì¸ êµì°¨ í•™ìŠµ ì—…ë°ì´íŠ¸ë¥¼ ìˆ˜í•™ì ìœ¼ë¡œ ë°˜ì˜í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
- 3. ë™ì  í™˜ê²½ì—ì„œ ì§€ì†ì ì¸ í˜ë¡œëª¬ í”ì ì€ ê¸ì •ì  í”¼ë“œë°± ë£¨í”„ë¥¼ ìƒì„±í•˜ì—¬ êµ°ì§‘ì´ êµ¬ì‹ ì„ íƒì— ê°‡íˆê²Œ ë§Œë“­ë‹ˆë‹¤.
- 4. ì†Œìˆ˜ì˜ íƒìƒ‰ì  ì—ì´ì „íŠ¸ë¥¼ ë„ì…í•˜ì—¬ ì§‘ë‹¨ì˜ ìœ ì—°ì„±ì„ íšŒë³µí•˜ê³  ë¹ ë¥¸ ê³¼ì œ ì „í™˜ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
- 5. í™˜ê²½ ì‹ í˜¸ê°€ ì§‘ë‹¨ì  ì‹ ìš© í• ë‹¹ì„ ìœ„í•œ ì™¸ë¶€ ë©”ëª¨ë¦¬ë¡œ ì‘ìš©í•˜ì—¬ ë¶„ì‚°ëœ RL í”„ë¡œì„¸ìŠ¤ë¥¼ ë‚´ì¬ì ìœ¼ë¡œ ì¸ì½”ë”©í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.


---

*Generated on 2025-09-25 15:19:05*