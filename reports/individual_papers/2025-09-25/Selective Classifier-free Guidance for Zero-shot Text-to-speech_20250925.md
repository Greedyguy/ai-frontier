---
keywords:
  - Zero-Shot Learning
  - Classifier-Free Guidance
  - Speech Synthesis
  - Speaker Similarity
  - Text Adherence
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2509.19668
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T15:43:19.627254",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Zero-Shot Learning",
    "Classifier-Free Guidance",
    "Speech Synthesis",
    "Speaker Similarity",
    "Text Adherence"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Zero-Shot Learning": 0.88,
    "Classifier-Free Guidance": 0.8,
    "Speech Synthesis": 0.7,
    "Speaker Similarity": 0.78,
    "Text Adherence": 0.74
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Zero-shot text-to-speech",
        "canonical": "Zero-Shot Learning",
        "aliases": [
          "Zero-shot TTS"
        ],
        "category": "specific_connectable",
        "rationale": "Links to the concept of zero-shot learning, which is crucial for understanding the adaptation of models to new tasks without task-specific training.",
        "novelty_score": 0.7,
        "connectivity_score": 0.85,
        "specificity_score": 0.8,
        "link_intent_score": 0.88
      },
      {
        "surface": "Classifier-free guidance",
        "canonical": "Classifier-Free Guidance",
        "aliases": [
          "CFG"
        ],
        "category": "unique_technical",
        "rationale": "Represents a novel method applied to speech synthesis, highlighting its adaptation from image generation.",
        "novelty_score": 0.75,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Speech synthesis",
        "canonical": "Speech Synthesis",
        "aliases": [
          "TTS"
        ],
        "category": "broad_technical",
        "rationale": "A fundamental technology discussed in the paper, connecting to broader topics in audio processing.",
        "novelty_score": 0.5,
        "connectivity_score": 0.78,
        "specificity_score": 0.6,
        "link_intent_score": 0.7
      },
      {
        "surface": "Speaker similarity",
        "canonical": "Speaker Similarity",
        "aliases": [
          "Voice similarity"
        ],
        "category": "specific_connectable",
        "rationale": "Critical for evaluating the effectiveness of text-to-speech systems in maintaining speaker characteristics.",
        "novelty_score": 0.65,
        "connectivity_score": 0.72,
        "specificity_score": 0.75,
        "link_intent_score": 0.78
      },
      {
        "surface": "Text adherence",
        "canonical": "Text Adherence",
        "aliases": [
          "Content fidelity"
        ],
        "category": "unique_technical",
        "rationale": "Important for assessing how well the synthesized speech follows the given text, a key metric in TTS.",
        "novelty_score": 0.68,
        "connectivity_score": 0.65,
        "specificity_score": 0.77,
        "link_intent_score": 0.74
      }
    ],
    "ban_list_suggestions": [
      "fidelity",
      "trade-offs",
      "results"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Zero-shot text-to-speech",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.85,
        "specificity": 0.8,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "Classifier-free guidance",
      "resolved_canonical": "Classifier-Free Guidance",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Speech synthesis",
      "resolved_canonical": "Speech Synthesis",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.78,
        "specificity": 0.6,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Speaker similarity",
      "resolved_canonical": "Speaker Similarity",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.72,
        "specificity": 0.75,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Text adherence",
      "resolved_canonical": "Text Adherence",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.65,
        "specificity": 0.77,
        "link_intent": 0.74
      }
    }
  ]
}
-->

# Selective Classifier-free Guidance for Zero-shot Text-to-speech

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19668.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2509.19668](https://arxiv.org/abs/2509.19668)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Dynamic Classifier-Free Diffusion Guidance via Online Feedback_20250922|Dynamic Classifier-Free Diffusion Guidance via Online Feedback]] (86.3% similar)
- [[2025-09-23/MaskVCT_ Masked Voice Codec Transformer for Zero-Shot Voice Conversion With Increased Controllability via Multiple Guidances_20250923|MaskVCT: Masked Voice Codec Transformer for Zero-Shot Voice Conversion With Increased Controllability via Multiple Guidances]] (81.6% similar)
- [[2025-09-23/PG-CE_ A Progressive Generation Dataset with Constraint Enhancement for Controllable Text Generation_20250923|PG-CE: A Progressive Generation Dataset with Constraint Enhancement for Controllable Text Generation]] (80.2% similar)
- [[2025-09-23/ComposeMe_ Attribute-Specific Image Prompts for Controllable Human Image Generation_20250923|ComposeMe: Attribute-Specific Image Prompts for Controllable Human Image Generation]] (79.4% similar)
- [[2025-09-22/RespoDiff_ Dual-Module Bottleneck Transformation for Responsible & Faithful T2I Generation_20250922|RespoDiff: Dual-Module Bottleneck Transformation for Responsible & Faithful T2I Generation]] (79.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Speech Synthesis|Speech Synthesis]]
**ğŸ”— Specific Connectable**: [[keywords/Zero-Shot Learning|Zero-Shot Learning]], [[keywords/Speaker Similarity|Speaker Similarity]]
**âš¡ Unique Technical**: [[keywords/Classifier-Free Guidance|Classifier-Free Guidance]], [[keywords/Text Adherence|Text Adherence]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19668v1 Announce Type: cross 
Abstract: In zero-shot text-to-speech, achieving a balance between fidelity to the target speaker and adherence to text content remains a challenge. While classifier-free guidance (CFG) strategies have shown promising results in image generation, their application to speech synthesis are underexplored. Separating the conditions used for CFG enables trade-offs between different desired characteristics in speech synthesis. In this paper, we evaluate the adaptability of CFG strategies originally developed for image generation to speech synthesis and extend separated-condition CFG approaches for this domain. Our results show that CFG strategies effective in image generation generally fail to improve speech synthesis. We also find that we can improve speaker similarity while limiting degradation of text adherence by applying standard CFG during early timesteps and switching to selective CFG only in later timesteps. Surprisingly, we observe that the effectiveness of a selective CFG strategy is highly text-representation dependent, as differences between the two languages of English and Mandarin can lead to different results even with the same model.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì œë¡œìƒ· í…ìŠ¤íŠ¸-ìŒì„± ë³€í™˜ì—ì„œ ëª©í‘œ í™”ìì˜ ìŒì„± ì¶©ì‹¤ë„ì™€ í…ìŠ¤íŠ¸ ë‚´ìš©ì˜ ì¼ì¹˜ë¥¼ ë™ì‹œì— ë‹¬ì„±í•˜ëŠ” ë¬¸ì œë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. ì´ë¯¸ì§€ ìƒì„±ì—ì„œ ìœ ë§í•œ ê²°ê³¼ë¥¼ ë³´ì¸ ë¶„ë¥˜ê¸° ì—†ëŠ” ê°€ì´ë“œ(CFG) ì „ëµì„ ìŒì„± í•©ì„±ì— ì ìš©í•˜ê³ , ì¡°ê±´ì„ ë¶„ë¦¬í•˜ì—¬ ë‹¤ì–‘í•œ íŠ¹ì„± ê°„ì˜ ê· í˜•ì„ ë§ì¶”ëŠ” ë°©ë²•ë¡ ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì—°êµ¬ ê²°ê³¼, ì´ë¯¸ì§€ ìƒì„±ì—ì„œ íš¨ê³¼ì ì´ì—ˆë˜ CFG ì „ëµì€ ìŒì„± í•©ì„±ì—ì„œëŠ” ì¼ë°˜ì ìœ¼ë¡œ ê°œì„  íš¨ê³¼ê°€ ì—†ìŒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ˆê¸° ë‹¨ê³„ì—ì„œ í‘œì¤€ CFGë¥¼ ì ìš©í•˜ê³  í›„ë°˜ ë‹¨ê³„ì—ì„œ ì„ íƒì  CFGë¡œ ì „í™˜í•˜ë©´ í™”ì ìœ ì‚¬ì„±ì„ ê°œì„ í•˜ë©´ì„œ í…ìŠ¤íŠ¸ ì¼ì¹˜ë„ ì €í•˜ë¥¼ ìµœì†Œí™”í•  ìˆ˜ ìˆìŒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, ì„ íƒì  CFG ì „ëµì˜ íš¨ê³¼ëŠ” í…ìŠ¤íŠ¸ í‘œí˜„ì— í¬ê²Œ ì˜ì¡´í•˜ë©°, ì˜ì–´ì™€ ì¤‘êµ­ì–´ ê°„ì˜ ì°¨ì´ê°€ ë™ì¼í•œ ëª¨ë¸ì—ì„œë„ ë‹¤ë¥¸ ê²°ê³¼ë¥¼ ì´ˆë˜í•  ìˆ˜ ìˆìŒì„ ê´€ì°°í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì œë¡œìƒ· í…ìŠ¤íŠ¸-ìŒì„± ë³€í™˜ì—ì„œ ëª©í‘œ í™”ìì˜ ìŒì„± ì¶©ì‹¤ë„ì™€ í…ìŠ¤íŠ¸ ë‚´ìš©ì˜ ì¼ì¹˜ì„±ì„ ê· í˜• ìˆê²Œ ìœ ì§€í•˜ëŠ” ê²ƒì´ ë„ì „ ê³¼ì œì…ë‹ˆë‹¤.
- 2. ì´ë¯¸ì§€ ìƒì„±ì—ì„œ ìœ ë§í•œ ê²°ê³¼ë¥¼ ë³´ì¸ ë¶„ë¥˜ê¸° ì—†ëŠ” ê°€ì´ë“œ(CFG) ì „ëµì˜ ìŒì„± í•©ì„± ì ìš©ì€ ì•„ì§ ì¶©ë¶„íˆ íƒêµ¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.
- 3. ì´ë¯¸ì§€ ìƒì„±ì— íš¨ê³¼ì ì¸ CFG ì „ëµì€ ìŒì„± í•©ì„±ì—ì„œëŠ” ì¼ë°˜ì ìœ¼ë¡œ ê°œì„  íš¨ê³¼ë¥¼ ë³´ì´ì§€ ì•ŠìŠµë‹ˆë‹¤.
- 4. ì´ˆê¸° ë‹¨ê³„ì—ì„œëŠ” í‘œì¤€ CFGë¥¼ ì ìš©í•˜ê³  í›„ë°˜ ë‹¨ê³„ì—ì„œ ì„ íƒì  CFGë¡œ ì „í™˜í•¨ìœ¼ë¡œì¨ í™”ì ìœ ì‚¬ì„±ì„ ê°œì„ í•˜ë©´ì„œ í…ìŠ¤íŠ¸ ì¼ì¹˜ì„±ì˜ ì €í•˜ë¥¼ ì œí•œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- 5. ì„ íƒì  CFG ì „ëµì˜ íš¨ê³¼ëŠ” í…ìŠ¤íŠ¸ í‘œí˜„ì— í¬ê²Œ ì˜ì¡´í•˜ë©°, ì˜ì–´ì™€ ì¤‘êµ­ì–´ ê°„ì˜ ì°¨ì´ê°€ ë™ì¼í•œ ëª¨ë¸ì—ì„œë„ ë‹¤ë¥¸ ê²°ê³¼ë¥¼ ì´ˆë˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-25 15:43:19*