---
keywords:
  - White-Basilisk Model
  - Vulnerability Detection
  - Mixture of Experts
  - Attention Mechanism
  - Large Language Model
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2507.08540
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T16:31:10.821044",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "White-Basilisk Model",
    "Vulnerability Detection",
    "Mixture of Experts",
    "Attention Mechanism",
    "Large Language Model"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "White-Basilisk Model": 0.78,
    "Vulnerability Detection": 0.85,
    "Mixture of Experts": 0.8,
    "Attention Mechanism": 0.82,
    "Large Language Model": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "White-Basilisk",
        "canonical": "White-Basilisk Model",
        "aliases": [
          "White-Basilisk"
        ],
        "category": "unique_technical",
        "rationale": "Represents a novel model architecture specifically designed for code vulnerability detection, offering a unique point of reference.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.78
      },
      {
        "surface": "vulnerability detection",
        "canonical": "Vulnerability Detection",
        "aliases": [
          "code vulnerability detection"
        ],
        "category": "specific_connectable",
        "rationale": "Central to the paper's focus, linking to broader cybersecurity and AI applications.",
        "novelty_score": 0.5,
        "connectivity_score": 0.88,
        "specificity_score": 0.8,
        "link_intent_score": 0.85
      },
      {
        "surface": "Mixture of Experts",
        "canonical": "Mixture of Experts",
        "aliases": [
          "MoE"
        ],
        "category": "specific_connectable",
        "rationale": "A key component of the model's architecture, relevant to discussions on model efficiency and scalability.",
        "novelty_score": 0.6,
        "connectivity_score": 0.82,
        "specificity_score": 0.78,
        "link_intent_score": 0.8
      },
      {
        "surface": "linear self-attention",
        "canonical": "Attention Mechanism",
        "aliases": [
          "linear self-attention"
        ],
        "category": "specific_connectable",
        "rationale": "A variant of attention mechanisms, crucial for understanding the model's ability to handle long sequences.",
        "novelty_score": 0.55,
        "connectivity_score": 0.87,
        "specificity_score": 0.75,
        "link_intent_score": 0.82
      },
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Provides context for the model's performance comparison and relevance in AI development.",
        "novelty_score": 0.4,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "methodologies",
      "performance",
      "tasks"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "White-Basilisk",
      "resolved_canonical": "White-Basilisk Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "vulnerability detection",
      "resolved_canonical": "Vulnerability Detection",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.88,
        "specificity": 0.8,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Mixture of Experts",
      "resolved_canonical": "Mixture of Experts",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.82,
        "specificity": 0.78,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "linear self-attention",
      "resolved_canonical": "Attention Mechanism",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.87,
        "specificity": 0.75,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# White-Basilisk: A Hybrid Model for Code Vulnerability Detection

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2507.08540.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2507.08540](https://arxiv.org/abs/2507.08540)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-25/CyberSOCEval_ Benchmarking LLMs Capabilities for Malware Analysis and Threat Intelligence Reasoning_20250925|CyberSOCEval: Benchmarking LLMs Capabilities for Malware Analysis and Threat Intelligence Reasoning]] (84.5% similar)
- [[2025-09-22/Activation Space Interventions Can Be Transferred Between Large Language Models_20250922|Activation Space Interventions Can Be Transferred Between Large Language Models]] (83.8% similar)
- [[2025-09-23/LLaVul_ A Multimodal LLM for Interpretable Vulnerability Reasoning about Source Code_20250923|LLaVul: A Multimodal LLM for Interpretable Vulnerability Reasoning about Source Code]] (83.5% similar)
- [[2025-09-25/Cognitive Load Limits in Large Language Models_ Benchmarking Multi-Hop Reasoning_20250925|Cognitive Load Limits in Large Language Models: Benchmarking Multi-Hop Reasoning]] (83.1% similar)
- [[2025-09-22/SeCodePLT_ A Unified Platform for Evaluating the Security of Code GenAI_20250922|SeCodePLT: A Unified Platform for Evaluating the Security of Code GenAI]] (83.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Vulnerability Detection|Vulnerability Detection]], [[keywords/Mixture of Experts|Mixture of Experts]], [[keywords/Attention Mechanism|Attention Mechanism]]
**âš¡ Unique Technical**: [[keywords/White-Basilisk Model|White-Basilisk Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2507.08540v3 Announce Type: replace-cross 
Abstract: The proliferation of software vulnerabilities presents a significant challenge to cybersecurity, necessitating more effective detection methodologies. We introduce White-Basilisk, a novel approach to vulnerability detection that demonstrates superior performance while challenging prevailing assumptions in AI model scaling. Utilizing an innovative architecture that integrates Mamba layers, linear self-attention, and a Mixture of Experts framework, White-Basilisk achieves state-of-the-art results in vulnerability detection tasks with a parameter count of only 200M. The model's capacity to process sequences of unprecedented length enables comprehensive analysis of extensive codebases in a single pass, surpassing the context limitations of current Large Language Models (LLMs). White-Basilisk exhibits robust performance on imbalanced, real-world datasets, while maintaining computational efficiency that facilitates deployment across diverse organizational scales. This research not only establishes new benchmarks in code security but also provides empirical evidence that compact, efficiently designed models can outperform larger counterparts in specialized tasks, potentially redefining optimization strategies in AI development for domain-specific applications.

## ğŸ“ ìš”ì•½

ì†Œí”„íŠ¸ì›¨ì–´ ì·¨ì•½ì ì˜ ì¦ê°€ë¡œ ì¸í•´ íš¨ê³¼ì ì¸ íƒì§€ ë°©ë²•ì´ í•„ìš”í•©ë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” White-Basiliskë¼ëŠ” ìƒˆë¡œìš´ ì·¨ì•½ì  íƒì§€ ì ‘ê·¼ë²•ì„ ì†Œê°œí•©ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ Mamba ë ˆì´ì–´, ì„ í˜• ìê¸° ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜, ì „ë¬¸ê°€ í˜¼í•© í”„ë ˆì„ì›Œí¬ë¥¼ í†µí•©í•œ í˜ì‹ ì ì¸ ì•„í‚¤í…ì²˜ë¥¼ ì‚¬ìš©í•˜ì—¬, 200M íŒŒë¼ë¯¸í„°ë¡œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í•©ë‹ˆë‹¤. íŠ¹íˆ, ê¸´ ì‹œí€€ìŠ¤ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆì–´ ëŒ€ê·œëª¨ ì½”ë“œë² ì´ìŠ¤ë¥¼ í•œ ë²ˆì— ë¶„ì„í•  ìˆ˜ ìˆìœ¼ë©°, ê¸°ì¡´ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ í•œê³„ë¥¼ ê·¹ë³µí•©ë‹ˆë‹¤. White-BasiliskëŠ” ë¶ˆê· í˜•í•œ ì‹¤ì œ ë°ì´í„°ì…‹ì—ì„œë„ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì´ë©°, ë‹¤ì–‘í•œ ì¡°ì§ ê·œëª¨ì— ë§ì¶° íš¨ìœ¨ì ìœ¼ë¡œ ë°°í¬ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ì½”ë“œ ë³´ì•ˆ ë¶„ì•¼ì—ì„œ ìƒˆë¡œìš´ ê¸°ì¤€ì„ ì„¸ìš°ê³ , ì‘ê³  íš¨ìœ¨ì ì¸ ëª¨ë¸ì´ ë” í° ëª¨ë¸ë³´ë‹¤ íŠ¹ì • ì‘ì—…ì—ì„œ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë°œíœ˜í•  ìˆ˜ ìˆìŒì„ ì…ì¦í•˜ì—¬ AI ê°œë°œì˜ ìµœì í™” ì „ëµì„ ì¬ì •ì˜í•  ê°€ëŠ¥ì„±ì„ ì œì‹œí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. White-BasiliskëŠ” ì†Œí”„íŠ¸ì›¨ì–´ ì·¨ì•½ì  íƒì§€ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì´ë©°, AI ëª¨ë¸ í™•ì¥ì— ëŒ€í•œ ê¸°ì¡´ ê°€ì •ì„ ë„ì „í•©ë‹ˆë‹¤.
- 2. Mamba ë ˆì´ì–´, ì„ í˜• ìê¸° ì£¼ì˜, ì „ë¬¸ê°€ í˜¼í•© í”„ë ˆì„ì›Œí¬ë¥¼ í†µí•©í•œ í˜ì‹ ì ì¸ ì•„í‚¤í…ì²˜ë¥¼ ì‚¬ìš©í•˜ì—¬ 200M íŒŒë¼ë¯¸í„°ë¡œ ìµœì²¨ë‹¨ ê²°ê³¼ë¥¼ ë‹¬ì„±í•©ë‹ˆë‹¤.
- 3. ê¸´ ì‹œí€€ìŠ¤ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì˜ ëŠ¥ë ¥ì€ ëŒ€ê·œëª¨ ì½”ë“œë² ì´ìŠ¤ë¥¼ ë‹¨ì¼ íŒ¨ìŠ¤ë¡œ ë¶„ì„í•  ìˆ˜ ìˆê²Œ í•˜ì—¬, í˜„ì¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ ë¬¸ë§¥ ì œí•œì„ ì´ˆì›”í•©ë‹ˆë‹¤.
- 4. White-BasiliskëŠ” ë¶ˆê· í˜•í•œ ì‹¤ì œ ë°ì´í„°ì…‹ì—ì„œë„ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ë©°, ë‹¤ì–‘í•œ ì¡°ì§ ê·œëª¨ì— ë°°í¬í•  ìˆ˜ ìˆëŠ” ê³„ì‚° íš¨ìœ¨ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤.
- 5. ì´ ì—°êµ¬ëŠ” ì½”ë“œ ë³´ì•ˆì˜ ìƒˆë¡œìš´ ê¸°ì¤€ì„ ì„¸ìš°ê³ , íš¨ìœ¨ì ìœ¼ë¡œ ì„¤ê³„ëœ ì†Œí˜• ëª¨ë¸ì´ íŠ¹í™”ëœ ì‘ì—…ì—ì„œ ë” í° ëª¨ë¸ì„ ëŠ¥ê°€í•  ìˆ˜ ìˆìŒì„ ì…ì¦í•˜ì—¬ AI ê°œë°œì˜ ìµœì í™” ì „ëµì„ ì¬ì •ì˜í•  ê°€ëŠ¥ì„±ì„ ì œì‹œí•©ë‹ˆë‹¤.


---

*Generated on 2025-09-25 16:31:10*