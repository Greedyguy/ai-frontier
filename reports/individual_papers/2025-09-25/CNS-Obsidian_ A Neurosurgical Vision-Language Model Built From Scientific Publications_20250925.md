---
keywords:
  - Vision-Language Model
  - CNS-Obsidian
  - Neurosurgical Literature
  - LLaVA-Next
  - GPT-4o
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2502.19546
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T16:10:23.370522",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Vision-Language Model",
    "CNS-Obsidian",
    "Neurosurgical Literature",
    "LLaVA-Next",
    "GPT-4o"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Vision-Language Model": 0.85,
    "CNS-Obsidian": 0.82,
    "Neurosurgical Literature": 0.75,
    "LLaVA-Next": 0.72,
    "GPT-4o": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Vision-Language Model",
        "canonical": "Vision-Language Model",
        "aliases": [
          "VLM",
          "Vision-Language"
        ],
        "category": "evolved_concepts",
        "rationale": "This concept is central to the paper and connects to the trending topic of multimodal AI systems.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.72,
        "link_intent_score": 0.85
      },
      {
        "surface": "CNS-Obsidian",
        "canonical": "CNS-Obsidian",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "A unique model introduced in the paper, providing a specific link to neurosurgical applications.",
        "novelty_score": 0.91,
        "connectivity_score": 0.65,
        "specificity_score": 0.95,
        "link_intent_score": 0.82
      },
      {
        "surface": "Neurosurgical Literature",
        "canonical": "Neurosurgical Literature",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Represents the specialized dataset used for training, crucial for domain-specific applications.",
        "novelty_score": 0.68,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      },
      {
        "surface": "LLaVA-Next model",
        "canonical": "LLaVA-Next",
        "aliases": [
          "LLaVA-Next model"
        ],
        "category": "specific_connectable",
        "rationale": "A specific model variant relevant to the technical discussion and model architecture.",
        "novelty_score": 0.55,
        "connectivity_score": 0.7,
        "specificity_score": 0.78,
        "link_intent_score": 0.72
      },
      {
        "surface": "GPT-4o",
        "canonical": "GPT-4o",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "A comparative model in the study, important for understanding performance benchmarks.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.68,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "training samples",
      "clinical utility",
      "diagnostic co-pilot"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Vision-Language Model",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.72,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "CNS-Obsidian",
      "resolved_canonical": "CNS-Obsidian",
      "decision": "linked",
      "scores": {
        "novelty": 0.91,
        "connectivity": 0.65,
        "specificity": 0.95,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Neurosurgical Literature",
      "resolved_canonical": "Neurosurgical Literature",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "LLaVA-Next model",
      "resolved_canonical": "LLaVA-Next",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.7,
        "specificity": 0.78,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "GPT-4o",
      "resolved_canonical": "GPT-4o",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.68,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# CNS-Obsidian: A Neurosurgical Vision-Language Model Built From Scientific Publications

## 📋 메타데이터

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2502.19546.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2502.19546](https://arxiv.org/abs/2502.19546)

## 🔗 유사한 논문
- [[2025-09-19/MedVAL_ Toward Expert-Level Medical Text Validation with Language Models_20250919|MedVAL: Toward Expert-Level Medical Text Validation with Language Models]] (85.1% similar)
- [[2025-09-22/EyePCR_ A Comprehensive Benchmark for Fine-Grained Perception, Knowledge Comprehension and Clinical Reasoning in Ophthalmic Surgery_20250922|EyePCR: A Comprehensive Benchmark for Fine-Grained Perception, Knowledge Comprehension and Clinical Reasoning in Ophthalmic Surgery]] (83.5% similar)
- [[2025-09-25/EchoBench_ Benchmarking Sycophancy in Medical Large Vision-Language Models_20250925|EchoBench: Benchmarking Sycophancy in Medical Large Vision-Language Models]] (83.3% similar)
- [[2025-09-22/Exploring the Capabilities of LLM Encoders for Image-Text Retrieval in Chest X-rays_20250922|Exploring the Capabilities of LLM Encoders for Image-Text Retrieval in Chest X-rays]] (83.3% similar)
- [[2025-09-22/EHR-MCP_ Real-world Evaluation of Clinical Information Retrieval by Large Language Models via Model Context Protocol_20250922|EHR-MCP: Real-world Evaluation of Clinical Information Retrieval by Large Language Models via Model Context Protocol]] (83.2% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/LLaVA-Next|LLaVA-Next]], [[keywords/GPT-4o|GPT-4o]]
**⚡ Unique Technical**: [[keywords/CNS-Obsidian|CNS-Obsidian]], [[keywords/Neurosurgical Literature|Neurosurgical Literature]]
**🚀 Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2502.19546v4 Announce Type: replace 
Abstract: General-purpose vision-language models (VLMs) demonstrate impressive capabilities, but their opaque training on uncurated internet data posse critical limitations for high-stakes decision-making, such as in neurosurgery. We present CNS-Obsidian, a neurosurgical VLM trained on peer-reviewed neurosurgical literature, and demonstrate its clinical utility compared with GPT-4o in a real-world setting. We compiled 23,984 articles from Neurosurgery Publications journals, yielding 78,853 figures and captions. Using GPT-4o and Claude Sonnet-3.5, we converted these image-text pairs into 263,064 training samples across three formats: instruction fine-tuning, multiple-choice questions, and differential diagnosis. We trained CNS-Obsidian, a fine-tune of the 34-billion parameter LLaVA-Next model. In a blinded, randomized deployment trial at NYU Langone Health (Aug 30-Nov 30, 2024), neurosurgeons were assigned to use either CNS-Obsidian or GPT-4o as a diagnostic co-pilot after patient consultations. Primary outcomes were diagnostic helpfulness and accuracy. CNS-Obsidian matched GPT-4o on synthetic questions (76.13% vs 77.54%, p=0.235), but only achieved 46.81% accuracy on human-generated questions versus GPT-4o's 65.70% (p<10-15). In the randomized trial, 70 consultations were evaluated (32 CNS-Obsidian, 38 GPT-4o) from 959 total consults. CNS-Obsidian received positive ratings in 40.62% of cases versus 57.89% for GPT-4o (p=0.230). Both models included correct diagnosis in approximately 60% of cases (59.38% vs 65.79%, p=0.626). Domain-specific VLMs trained on curated scientific literature can approach frontier model performance in specialized medical domains despite being orders of magnitude smaller and less expensive to train. However, low clinical utilization suggests chatbot interfaces may not align with specialist workflows, indicating need for alternative AI integration strategies.

## 📝 요약

CNS-Obsidian은 신경외과 분야에 특화된 시각-언어 모델로, 검토된 신경외과 문헌을 기반으로 훈련되었습니다. 이 모델은 GPT-4o와 비교하여 실제 임상 환경에서의 유용성을 평가받았습니다. 23,984개의 신경외과 논문에서 78,853개의 이미지와 캡션을 수집하여 263,064개의 훈련 샘플을 생성하였고, 이를 통해 34억 매개변수의 LLaVA-Next 모델을 미세 조정했습니다. NYU Langone Health에서의 무작위 배정 시험에서 CNS-Obsidian은 진단 정확도와 유용성에서 GPT-4o와 유사한 성능을 보였으나, 인간이 생성한 질문에서는 낮은 정확도를 기록했습니다. 결과적으로, 전문 분야에 특화된 VLM은 대규모 모델에 비해 비용 효율적이지만, 실제 임상 활용도는 낮아 AI 통합 전략의 재고가 필요합니다.

## 🎯 주요 포인트

- 1. CNS-Obsidian은 신경외과 전문 문헌을 기반으로 훈련된 비전-언어 모델로, GPT-4o와 비교하여 임상적 유용성을 평가받았습니다.
- 2. CNS-Obsidian은 34억 매개변수의 LLaVA-Next 모델을 미세 조정하여 훈련되었으며, 신경외과 저널에서 수집한 23,984개의 논문과 78,853개의 이미지-텍스트 쌍을 활용했습니다.
- 3. 무작위 배정 시험에서 CNS-Obsidian은 인간이 생성한 질문에 대해 46.81%의 정확도를 보였으며, 이는 GPT-4o의 65.70%와 비교됩니다.
- 4. CNS-Obsidian은 진단적 유용성 및 정확성에서 GPT-4o와 유사한 성능을 보였으나, 임상적 활용도는 낮아 전문의의 워크플로우와의 부조화를 시사합니다.
- 5. 전문 분야에 특화된 VLM은 훨씬 작은 규모와 비용으로도 최첨단 모델 성능에 근접할 수 있지만, AI 통합 전략의 재고가 필요합니다.


---

*Generated on 2025-09-25 16:10:23*