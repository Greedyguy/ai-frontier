---
keywords:
  - Vision-Language Model
  - CNS-Obsidian
  - Neurosurgical Literature
  - LLaVA-Next
  - GPT-4o
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2502.19546
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T16:10:23.370522",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Vision-Language Model",
    "CNS-Obsidian",
    "Neurosurgical Literature",
    "LLaVA-Next",
    "GPT-4o"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Vision-Language Model": 0.85,
    "CNS-Obsidian": 0.82,
    "Neurosurgical Literature": 0.75,
    "LLaVA-Next": 0.72,
    "GPT-4o": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Vision-Language Model",
        "canonical": "Vision-Language Model",
        "aliases": [
          "VLM",
          "Vision-Language"
        ],
        "category": "evolved_concepts",
        "rationale": "This concept is central to the paper and connects to the trending topic of multimodal AI systems.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.72,
        "link_intent_score": 0.85
      },
      {
        "surface": "CNS-Obsidian",
        "canonical": "CNS-Obsidian",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "A unique model introduced in the paper, providing a specific link to neurosurgical applications.",
        "novelty_score": 0.91,
        "connectivity_score": 0.65,
        "specificity_score": 0.95,
        "link_intent_score": 0.82
      },
      {
        "surface": "Neurosurgical Literature",
        "canonical": "Neurosurgical Literature",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Represents the specialized dataset used for training, crucial for domain-specific applications.",
        "novelty_score": 0.68,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      },
      {
        "surface": "LLaVA-Next model",
        "canonical": "LLaVA-Next",
        "aliases": [
          "LLaVA-Next model"
        ],
        "category": "specific_connectable",
        "rationale": "A specific model variant relevant to the technical discussion and model architecture.",
        "novelty_score": 0.55,
        "connectivity_score": 0.7,
        "specificity_score": 0.78,
        "link_intent_score": 0.72
      },
      {
        "surface": "GPT-4o",
        "canonical": "GPT-4o",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "A comparative model in the study, important for understanding performance benchmarks.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.68,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "training samples",
      "clinical utility",
      "diagnostic co-pilot"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Vision-Language Model",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.72,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "CNS-Obsidian",
      "resolved_canonical": "CNS-Obsidian",
      "decision": "linked",
      "scores": {
        "novelty": 0.91,
        "connectivity": 0.65,
        "specificity": 0.95,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Neurosurgical Literature",
      "resolved_canonical": "Neurosurgical Literature",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "LLaVA-Next model",
      "resolved_canonical": "LLaVA-Next",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.7,
        "specificity": 0.78,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "GPT-4o",
      "resolved_canonical": "GPT-4o",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.68,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# CNS-Obsidian: A Neurosurgical Vision-Language Model Built From Scientific Publications

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2502.19546.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2502.19546](https://arxiv.org/abs/2502.19546)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/MedVAL_ Toward Expert-Level Medical Text Validation with Language Models_20250919|MedVAL: Toward Expert-Level Medical Text Validation with Language Models]] (85.1% similar)
- [[2025-09-22/EyePCR_ A Comprehensive Benchmark for Fine-Grained Perception, Knowledge Comprehension and Clinical Reasoning in Ophthalmic Surgery_20250922|EyePCR: A Comprehensive Benchmark for Fine-Grained Perception, Knowledge Comprehension and Clinical Reasoning in Ophthalmic Surgery]] (83.5% similar)
- [[2025-09-25/EchoBench_ Benchmarking Sycophancy in Medical Large Vision-Language Models_20250925|EchoBench: Benchmarking Sycophancy in Medical Large Vision-Language Models]] (83.3% similar)
- [[2025-09-22/Exploring the Capabilities of LLM Encoders for Image-Text Retrieval in Chest X-rays_20250922|Exploring the Capabilities of LLM Encoders for Image-Text Retrieval in Chest X-rays]] (83.3% similar)
- [[2025-09-22/EHR-MCP_ Real-world Evaluation of Clinical Information Retrieval by Large Language Models via Model Context Protocol_20250922|EHR-MCP: Real-world Evaluation of Clinical Information Retrieval by Large Language Models via Model Context Protocol]] (83.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/LLaVA-Next|LLaVA-Next]], [[keywords/GPT-4o|GPT-4o]]
**âš¡ Unique Technical**: [[keywords/CNS-Obsidian|CNS-Obsidian]], [[keywords/Neurosurgical Literature|Neurosurgical Literature]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2502.19546v4 Announce Type: replace 
Abstract: General-purpose vision-language models (VLMs) demonstrate impressive capabilities, but their opaque training on uncurated internet data posse critical limitations for high-stakes decision-making, such as in neurosurgery. We present CNS-Obsidian, a neurosurgical VLM trained on peer-reviewed neurosurgical literature, and demonstrate its clinical utility compared with GPT-4o in a real-world setting. We compiled 23,984 articles from Neurosurgery Publications journals, yielding 78,853 figures and captions. Using GPT-4o and Claude Sonnet-3.5, we converted these image-text pairs into 263,064 training samples across three formats: instruction fine-tuning, multiple-choice questions, and differential diagnosis. We trained CNS-Obsidian, a fine-tune of the 34-billion parameter LLaVA-Next model. In a blinded, randomized deployment trial at NYU Langone Health (Aug 30-Nov 30, 2024), neurosurgeons were assigned to use either CNS-Obsidian or GPT-4o as a diagnostic co-pilot after patient consultations. Primary outcomes were diagnostic helpfulness and accuracy. CNS-Obsidian matched GPT-4o on synthetic questions (76.13% vs 77.54%, p=0.235), but only achieved 46.81% accuracy on human-generated questions versus GPT-4o's 65.70% (p<10-15). In the randomized trial, 70 consultations were evaluated (32 CNS-Obsidian, 38 GPT-4o) from 959 total consults. CNS-Obsidian received positive ratings in 40.62% of cases versus 57.89% for GPT-4o (p=0.230). Both models included correct diagnosis in approximately 60% of cases (59.38% vs 65.79%, p=0.626). Domain-specific VLMs trained on curated scientific literature can approach frontier model performance in specialized medical domains despite being orders of magnitude smaller and less expensive to train. However, low clinical utilization suggests chatbot interfaces may not align with specialist workflows, indicating need for alternative AI integration strategies.

## ğŸ“ ìš”ì•½

CNS-Obsidianì€ ì‹ ê²½ì™¸ê³¼ ë¶„ì•¼ì— íŠ¹í™”ëœ ì‹œê°-ì–¸ì–´ ëª¨ë¸ë¡œ, ê²€í† ëœ ì‹ ê²½ì™¸ê³¼ ë¬¸í—Œì„ ê¸°ë°˜ìœ¼ë¡œ í›ˆë ¨ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ëª¨ë¸ì€ GPT-4oì™€ ë¹„êµí•˜ì—¬ ì‹¤ì œ ì„ìƒ í™˜ê²½ì—ì„œì˜ ìœ ìš©ì„±ì„ í‰ê°€ë°›ì•˜ìŠµë‹ˆë‹¤. 23,984ê°œì˜ ì‹ ê²½ì™¸ê³¼ ë…¼ë¬¸ì—ì„œ 78,853ê°œì˜ ì´ë¯¸ì§€ì™€ ìº¡ì…˜ì„ ìˆ˜ì§‘í•˜ì—¬ 263,064ê°œì˜ í›ˆë ¨ ìƒ˜í”Œì„ ìƒì„±í•˜ì˜€ê³ , ì´ë¥¼ í†µí•´ 34ì–µ ë§¤ê°œë³€ìˆ˜ì˜ LLaVA-Next ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í–ˆìŠµë‹ˆë‹¤. NYU Langone Healthì—ì„œì˜ ë¬´ì‘ìœ„ ë°°ì • ì‹œí—˜ì—ì„œ CNS-Obsidianì€ ì§„ë‹¨ ì •í™•ë„ì™€ ìœ ìš©ì„±ì—ì„œ GPT-4oì™€ ìœ ì‚¬í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë‚˜, ì¸ê°„ì´ ìƒì„±í•œ ì§ˆë¬¸ì—ì„œëŠ” ë‚®ì€ ì •í™•ë„ë¥¼ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤. ê²°ê³¼ì ìœ¼ë¡œ, ì „ë¬¸ ë¶„ì•¼ì— íŠ¹í™”ëœ VLMì€ ëŒ€ê·œëª¨ ëª¨ë¸ì— ë¹„í•´ ë¹„ìš© íš¨ìœ¨ì ì´ì§€ë§Œ, ì‹¤ì œ ì„ìƒ í™œìš©ë„ëŠ” ë‚®ì•„ AI í†µí•© ì „ëµì˜ ì¬ê³ ê°€ í•„ìš”í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. CNS-Obsidianì€ ì‹ ê²½ì™¸ê³¼ ì „ë¬¸ ë¬¸í—Œì„ ê¸°ë°˜ìœ¼ë¡œ í›ˆë ¨ëœ ë¹„ì „-ì–¸ì–´ ëª¨ë¸ë¡œ, GPT-4oì™€ ë¹„êµí•˜ì—¬ ì„ìƒì  ìœ ìš©ì„±ì„ í‰ê°€ë°›ì•˜ìŠµë‹ˆë‹¤.
- 2. CNS-Obsidianì€ 34ì–µ ë§¤ê°œë³€ìˆ˜ì˜ LLaVA-Next ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ì—¬ í›ˆë ¨ë˜ì—ˆìœ¼ë©°, ì‹ ê²½ì™¸ê³¼ ì €ë„ì—ì„œ ìˆ˜ì§‘í•œ 23,984ê°œì˜ ë…¼ë¬¸ê³¼ 78,853ê°œì˜ ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ìŒì„ í™œìš©í–ˆìŠµë‹ˆë‹¤.
- 3. ë¬´ì‘ìœ„ ë°°ì • ì‹œí—˜ì—ì„œ CNS-Obsidianì€ ì¸ê°„ì´ ìƒì„±í•œ ì§ˆë¬¸ì— ëŒ€í•´ 46.81%ì˜ ì •í™•ë„ë¥¼ ë³´ì˜€ìœ¼ë©°, ì´ëŠ” GPT-4oì˜ 65.70%ì™€ ë¹„êµë©ë‹ˆë‹¤.
- 4. CNS-Obsidianì€ ì§„ë‹¨ì  ìœ ìš©ì„± ë° ì •í™•ì„±ì—ì„œ GPT-4oì™€ ìœ ì‚¬í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë‚˜, ì„ìƒì  í™œìš©ë„ëŠ” ë‚®ì•„ ì „ë¬¸ì˜ì˜ ì›Œí¬í”Œë¡œìš°ì™€ì˜ ë¶€ì¡°í™”ë¥¼ ì‹œì‚¬í•©ë‹ˆë‹¤.
- 5. ì „ë¬¸ ë¶„ì•¼ì— íŠ¹í™”ëœ VLMì€ í›¨ì”¬ ì‘ì€ ê·œëª¨ì™€ ë¹„ìš©ìœ¼ë¡œë„ ìµœì²¨ë‹¨ ëª¨ë¸ ì„±ëŠ¥ì— ê·¼ì ‘í•  ìˆ˜ ìˆì§€ë§Œ, AI í†µí•© ì „ëµì˜ ì¬ê³ ê°€ í•„ìš”í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-25 16:10:23*