---
keywords:
  - Low-Rank Adaptation
  - SVDLoRA
  - Alternating Least Squares
  - Kronecker-Factored Approximate Curvature
  - RoBERTa
category: cs.LG
publish_date: 2025-09-25
arxiv_id: 2509.19977
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T16:43:40.133618",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Low-Rank Adaptation",
    "SVDLoRA",
    "Alternating Least Squares",
    "Kronecker-Factored Approximate Curvature",
    "RoBERTa"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Low-Rank Adaptation": 0.78,
    "SVDLoRA": 0.77,
    "Alternating Least Squares": 0.8,
    "Kronecker-Factored Approximate Curvature": 0.79,
    "RoBERTa": 0.82
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Low-Rank Adaptation",
        "canonical": "Low-Rank Adaptation",
        "aliases": [
          "LoRA"
        ],
        "category": "unique_technical",
        "rationale": "Low-Rank Adaptation is central to the paper's proposed method and offers a unique technical approach to model optimization.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "SVDLoRA",
        "canonical": "SVDLoRA",
        "aliases": [
          "Singular Value Decomposition LoRA"
        ],
        "category": "unique_technical",
        "rationale": "SVDLoRA is a specific variant of LoRA that the paper aims to improve upon, making it a key technical concept.",
        "novelty_score": 0.72,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      },
      {
        "surface": "Alternating Least Squares",
        "canonical": "Alternating Least Squares",
        "aliases": [
          "ALS"
        ],
        "category": "specific_connectable",
        "rationale": "Alternating Least Squares is a well-known optimization technique that connects to broader optimization strategies.",
        "novelty_score": 0.55,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "K-FAC",
        "canonical": "Kronecker-Factored Approximate Curvature",
        "aliases": [
          "K-FAC"
        ],
        "category": "specific_connectable",
        "rationale": "K-FAC is a specific optimization metric that enhances the proposed method, linking to advanced optimization techniques.",
        "novelty_score": 0.6,
        "connectivity_score": 0.75,
        "specificity_score": 0.78,
        "link_intent_score": 0.79
      },
      {
        "surface": "RoBERTa-base",
        "canonical": "RoBERTa",
        "aliases": [
          "RoBERTa-base"
        ],
        "category": "broad_technical",
        "rationale": "RoBERTa is a widely used model in NLP, providing a strong link to the broader field of language models.",
        "novelty_score": 0.4,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.82
      }
    ],
    "ban_list_suggestions": [
      "optimizer",
      "memory-efficient",
      "experimental",
      "linear task",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Low-Rank Adaptation",
      "resolved_canonical": "Low-Rank Adaptation",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "SVDLoRA",
      "resolved_canonical": "SVDLoRA",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Alternating Least Squares",
      "resolved_canonical": "Alternating Least Squares",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "K-FAC",
      "resolved_canonical": "Kronecker-Factored Approximate Curvature",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.75,
        "specificity": 0.78,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "RoBERTa-base",
      "resolved_canonical": "RoBERTa",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.82
      }
    }
  ]
}
-->

# Faster Than SVD, Smarter Than SGD: The OPLoRA Alternating Update

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19977.pdf)
**Category**: cs.LG
**Published**: 2025-09-25
**ArXiv ID**: [2509.19977](https://arxiv.org/abs/2509.19977)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Robust Federated Finetuning of LLMs via Alternating Optimization of LoRA_20250923|Robust Federated Finetuning of LLMs via Alternating Optimization of LoRA]] (89.6% similar)
- [[2025-09-23/RefLoRA_ Refactored Low-Rank Adaptation for Efficient Fine-Tuning of Large Models_20250923|RefLoRA: Refactored Low-Rank Adaptation for Efficient Fine-Tuning of Large Models]] (89.0% similar)
- [[2025-09-25/Localized LoRA_ A Structured Low-Rank Approximation for Efficient Fine-Tuning_20250925|Localized LoRA: A Structured Low-Rank Approximation for Efficient Fine-Tuning]] (86.7% similar)
- [[2025-09-24/LoRALib_ A Standardized Benchmark for Evaluating LoRA-MoE Methods_20250924|LoRALib: A Standardized Benchmark for Evaluating LoRA-MoE Methods]] (86.6% similar)
- [[2025-09-25/TensLoRA_ Tensor Alternatives for Low-Rank Adaptation_20250925|TensLoRA: Tensor Alternatives for Low-Rank Adaptation]] (86.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/RoBERTa|RoBERTa]]
**ğŸ”— Specific Connectable**: [[keywords/Alternating Least Squares|Alternating Least Squares]], [[keywords/Kronecker-Factored Approximate Curvature|Kronecker-Factored Approximate Curvature]]
**âš¡ Unique Technical**: [[keywords/Low-Rank Adaptation|Low-Rank Adaptation]], [[keywords/SVDLoRA|SVDLoRA]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19977v1 Announce Type: new 
Abstract: Low-Rank Adaptation (LoRA) fine-tunes large models by learning low-rank updates on top of frozen weights, dramatically reducing trainable parameters and memory. However, there is still a gap between full training with low-rank projections (SVDLoRA) and LoRA fine-tuning, indicating that LoRA steps can be further improved. In this study, we propose OPLoRA, a memory-efficient optimizer that closes this gap by casting LoRA optimization as an interpretable sub-problem and solving it efficiently with alternating least squares updates, where 1-2 alternating steps are empirically found to be sufficient to closely match truncated SVD without ever forming the full matrix. We also retrieve the recently proposed preconditioning methods for LoRA as a special case. OPLoRA supports momentum by maintaining a low-rank estimate using the same subroutine (LoRSum) for computing the step, with a memory budget of 3 times the number of LoRA parameters (i.e., same as Adam). We also propose an experimental scaled variant that uses the K-FAC metric, which could be of interest. Across a linear task, MNIST, CIFAR-100, and RoBERTa-base (MNLI), OPLoRA consistently approaches SVDLoRA's performance using significantly less memory.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì—ì„œëŠ” ëŒ€ê·œëª¨ ëª¨ë¸ì˜ ë¯¸ì„¸ ì¡°ì •ì„ ìœ„í•œ ë°©ë²•ì¸ LoRAì˜ ì„±ëŠ¥ì„ ê°œì„ í•˜ê¸° ìœ„í•´ OPLoRAë¼ëŠ” ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ìµœì í™” ê¸°ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. OPLoRAëŠ” LoRA ìµœì í™”ë¥¼ í•´ì„ ê°€ëŠ¥í•œ í•˜ìœ„ ë¬¸ì œë¡œ ê°„ì£¼í•˜ê³ , êµëŒ€ ìµœì†Œ ì œê³± ì—…ë°ì´íŠ¸ë¥¼ í†µí•´ íš¨ìœ¨ì ìœ¼ë¡œ í•´ê²°í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì „ì²´ í–‰ë ¬ì„ í˜•ì„±í•˜ì§€ ì•Šê³ ë„ SVDLoRAì™€ ìœ ì‚¬í•œ ì„±ëŠ¥ì„ ë‹¬ì„±í•©ë‹ˆë‹¤. ë˜í•œ, LoRAì˜ ì‚¬ì „ ì¡°ê±´ ë°©ë²•ì„ íŠ¹ìˆ˜í•œ ê²½ìš°ë¡œ í¬í•¨í•˜ë©°, ëª¨ë©˜í…€ ì§€ì›ì„ ìœ„í•´ LoRSumì„ ì‚¬ìš©í•˜ì—¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ìµœì†Œí™”í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, OPLoRAëŠ” MNIST, CIFAR-100, RoBERTa-base(MNLI) ë“± ë‹¤ì–‘í•œ ì‘ì—…ì—ì„œ SVDLoRAì˜ ì„±ëŠ¥ì— ê·¼ì ‘í•˜ë©´ì„œë„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ í¬ê²Œ ì¤„ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. OPLoRAëŠ” LoRA ìµœì í™”ë¥¼ í•´ì„ ê°€ëŠ¥í•œ í•˜ìœ„ ë¬¸ì œë¡œ ë³€í™˜í•˜ì—¬ ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë°©ë²•ìœ¼ë¡œ í•´ê²°í•©ë‹ˆë‹¤.
- 2. êµëŒ€ ìµœì†Œ ì œê³± ì—…ë°ì´íŠ¸ë¥¼ í†µí•´ ì „ì²´ í–‰ë ¬ì„ í˜•ì„±í•˜ì§€ ì•Šê³ ë„ SVDLoRAì™€ ìœ ì‚¬í•œ ì„±ëŠ¥ì„ ë‹¬ì„±í•©ë‹ˆë‹¤.
- 3. OPLoRAëŠ” LoRA ë§¤ê°œë³€ìˆ˜ì˜ 3ë°° ë©”ëª¨ë¦¬ ì˜ˆì‚°ìœ¼ë¡œ ëª¨ë©˜í…€ì„ ì§€ì›í•˜ë©°, ì´ëŠ” Adamê³¼ ë™ì¼í•©ë‹ˆë‹¤.
- 4. K-FAC ë©”íŠ¸ë¦­ì„ ì‚¬ìš©í•˜ëŠ” ì‹¤í—˜ì  ë³€í˜•ë„ ì œì•ˆë˜ì–´ ê´€ì‹¬ì„ ëŒ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- 5. OPLoRAëŠ” ë‹¤ì–‘í•œ ì‘ì—…ì—ì„œ SVDLoRAì˜ ì„±ëŠ¥ì— ê·¼ì ‘í•˜ë©´ì„œë„ ë©”ëª¨ë¦¬ë¥¼ í¬ê²Œ ì ˆì•½í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-25 16:43:40*