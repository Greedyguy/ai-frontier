---
keywords:
  - Multimodal Learning
  - Edge-Cloud Collaboration
  - Semantic Enhancement
  - Instruction Fine-Tuning
  - Adaptive Mapping
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2509.19875
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T15:51:57.794101",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Multimodal Learning",
    "Edge-Cloud Collaboration",
    "Semantic Enhancement",
    "Instruction Fine-Tuning",
    "Adaptive Mapping"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Multimodal Learning": 0.85,
    "Edge-Cloud Collaboration": 0.78,
    "Semantic Enhancement": 0.77,
    "Instruction Fine-Tuning": 0.81,
    "Adaptive Mapping": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multimodal Large Language Models",
        "canonical": "Multimodal Learning",
        "aliases": [
          "MLLM",
          "Multimodal LLM"
        ],
        "category": "specific_connectable",
        "rationale": "Multimodal Learning is crucial for linking diverse data types in object detection tasks.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.78,
        "link_intent_score": 0.85
      },
      {
        "surface": "Edge-Cloud Collaborative Object Detection",
        "canonical": "Edge-Cloud Collaboration",
        "aliases": [
          "Edge-Cloud Detection"
        ],
        "category": "unique_technical",
        "rationale": "This represents a novel approach to balancing computational load and accuracy in object detection.",
        "novelty_score": 0.72,
        "connectivity_score": 0.67,
        "specificity_score": 0.82,
        "link_intent_score": 0.78
      },
      {
        "surface": "Semantic Enhancement",
        "canonical": "Semantic Enhancement",
        "aliases": [
          "Semantic Guidance"
        ],
        "category": "unique_technical",
        "rationale": "Semantic enhancement is a unique approach to improving object detection accuracy.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      },
      {
        "surface": "Instruction Fine-Tuning",
        "canonical": "Instruction Fine-Tuning",
        "aliases": [
          "Fine-Tuning Instructions"
        ],
        "category": "unique_technical",
        "rationale": "This technique is essential for adapting models to generate structured scene descriptions.",
        "novelty_score": 0.68,
        "connectivity_score": 0.75,
        "specificity_score": 0.79,
        "link_intent_score": 0.81
      },
      {
        "surface": "Adaptive Mapping Mechanism",
        "canonical": "Adaptive Mapping",
        "aliases": [
          "Adaptive Mapping System"
        ],
        "category": "unique_technical",
        "rationale": "Adaptive mapping is key to converting semantic information into actionable signals.",
        "novelty_score": 0.7,
        "connectivity_score": 0.72,
        "specificity_score": 0.85,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "experiment"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multimodal Large Language Models",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.78,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Edge-Cloud Collaborative Object Detection",
      "resolved_canonical": "Edge-Cloud Collaboration",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.67,
        "specificity": 0.82,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Semantic Enhancement",
      "resolved_canonical": "Semantic Enhancement",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Instruction Fine-Tuning",
      "resolved_canonical": "Instruction Fine-Tuning",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.75,
        "specificity": 0.79,
        "link_intent": 0.81
      }
    },
    {
      "candidate_surface": "Adaptive Mapping Mechanism",
      "resolved_canonical": "Adaptive Mapping",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.72,
        "specificity": 0.85,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Adaptive Guidance Semantically Enhanced via Multimodal LLM for Edge-Cloud Object Detection

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19875.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2509.19875](https://arxiv.org/abs/2509.19875)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/LLM-Assisted Semantic Guidance for Sparsely Annotated Remote Sensing Object Detection_20250923|LLM-Assisted Semantic Guidance for Sparsely Annotated Remote Sensing Object Detection]] (87.0% similar)
- [[2025-09-23/SAEC_ Scene-Aware Enhanced Edge-Cloud Collaborative Industrial Vision Inspection with Multimodal LLM_20250923|SAEC: Scene-Aware Enhanced Edge-Cloud Collaborative Industrial Vision Inspection with Multimodal LLM]] (85.8% similar)
- [[2025-09-22/A re-calibration method for object detection with multi-modal alignment bias in autonomous driving_20250922|A re-calibration method for object detection with multi-modal alignment bias in autonomous driving]] (84.7% similar)
- [[2025-09-23/MO R-CNN_ Multispectral Oriented R-CNN for Object Detection in Remote Sensing Image_20250923|MO R-CNN: Multispectral Oriented R-CNN for Object Detection in Remote Sensing Image]] (84.6% similar)
- [[2025-09-24/MOCHA_ Multi-modal Objects-aware Cross-arcHitecture Alignment_20250924|MOCHA: Multi-modal Objects-aware Cross-arcHitecture Alignment]] (84.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**âš¡ Unique Technical**: [[keywords/Edge-Cloud Collaboration|Edge-Cloud Collaboration]], [[keywords/Semantic Enhancement|Semantic Enhancement]], [[keywords/Instruction Fine-Tuning|Instruction Fine-Tuning]], [[keywords/Adaptive Mapping|Adaptive Mapping]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19875v1 Announce Type: cross 
Abstract: Traditional object detection methods face performance degradation challenges in complex scenarios such as low-light conditions and heavy occlusions due to a lack of high-level semantic understanding. To address this, this paper proposes an adaptive guidance-based semantic enhancement edge-cloud collaborative object detection method leveraging Multimodal Large Language Models (MLLM), achieving an effective balance between accuracy and efficiency. Specifically, the method first employs instruction fine-tuning to enable the MLLM to generate structured scene descriptions. It then designs an adaptive mapping mechanism that dynamically converts semantic information into parameter adjustment signals for edge detectors, achieving real-time semantic enhancement. Within an edge-cloud collaborative inference framework, the system automatically selects between invoking cloud-based semantic guidance or directly outputting edge detection results based on confidence scores. Experiments demonstrate that the proposed method effectively enhances detection accuracy and efficiency in complex scenes. Specifically, it can reduce latency by over 79% and computational cost by 70% in low-light and highly occluded scenes while maintaining accuracy.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë³µì¡í•œ í™˜ê²½ì—ì„œ ì „í†µì ì¸ ê°ì²´ íƒì§€ ë°©ë²•ì˜ ì„±ëŠ¥ ì €í•˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ë‹¤ì¤‘ ëª¨ë‹¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(MLLM)ì„ í™œìš©í•œ ì ì‘í˜• ê°€ì´ë“œ ê¸°ë°˜ì˜ ì˜ë¯¸ì  í–¥ìƒ ì—£ì§€-í´ë¼ìš°ë“œ í˜‘ë ¥ ê°ì²´ íƒì§€ ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ MLLMì„ í†µí•´ êµ¬ì¡°í™”ëœ ì¥ë©´ ì„¤ëª…ì„ ìƒì„±í•˜ê³ , ì´ë¥¼ ì—£ì§€ íƒì§€ê¸°ì— ëŒ€í•œ ë§¤ê°œë³€ìˆ˜ ì¡°ì • ì‹ í˜¸ë¡œ ë³€í™˜í•˜ëŠ” ì ì‘í˜• ë§¤í•‘ ë©”ì»¤ë‹ˆì¦˜ì„ ì„¤ê³„í•˜ì—¬ ì‹¤ì‹œê°„ ì˜ë¯¸ì  í–¥ìƒì„ ë‹¬ì„±í•©ë‹ˆë‹¤. ì—£ì§€-í´ë¼ìš°ë“œ í˜‘ë ¥ ì¶”ë¡  í”„ë ˆì„ì›Œí¬ ë‚´ì—ì„œ, ì‹œìŠ¤í…œì€ ì‹ ë¢°ë„ ì ìˆ˜ì— ë”°ë¼ í´ë¼ìš°ë“œ ê¸°ë°˜ì˜ ì˜ë¯¸ì  ê°€ì´ë“œë¥¼ í˜¸ì¶œí•˜ê±°ë‚˜ ì—£ì§€ íƒì§€ ê²°ê³¼ë¥¼ ì§ì ‘ ì¶œë ¥í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì€ ë³µì¡í•œ ì¥ë©´ì—ì„œ íƒì§€ ì •í™•ë„ì™€ íš¨ìœ¨ì„±ì„ íš¨ê³¼ì ìœ¼ë¡œ í–¥ìƒì‹œí‚¤ë©°, íŠ¹íˆ ì €ì¡°ë„ ë° ì‹¬í•œ ê°€ë¦¼ ì¥ë©´ì—ì„œ ì§€ì—° ì‹œê°„ì„ 79% ì´ìƒ, ê³„ì‚° ë¹„ìš©ì„ 70% ì ˆê°í•˜ë©´ì„œ ì •í™•ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë³µì¡í•œ ì¥ë©´ì—ì„œì˜ ê°ì²´ íƒì§€ ì„±ëŠ¥ ì €í•˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì ì‘í˜• ê°€ì´ë“œ ê¸°ë°˜ì˜ ì˜ë¯¸ì  ê°•í™” ì—£ì§€-í´ë¼ìš°ë“œ í˜‘ë ¥ ê°ì²´ íƒì§€ ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤.
- 2. ì œì•ˆëœ ë°©ë²•ì€ Multimodal Large Language Models(MLLM)ë¥¼ í™œìš©í•˜ì—¬ ì •í™•ì„±ê³¼ íš¨ìœ¨ì„±ì˜ ê· í˜•ì„ ì´ë£¨ê³ ì í•©ë‹ˆë‹¤.
- 3. MLLMì˜ êµ¬ì¡°í™”ëœ ì¥ë©´ ì„¤ëª… ìƒì„±ì„ ìœ„í•´ ëª…ë ¹ì–´ ë¯¸ì„¸ ì¡°ì •ì„ ì‚¬ìš©í•˜ê³ , ì˜ë¯¸ ì •ë³´ë¥¼ ì—£ì§€ íƒì§€ê¸°ì˜ ë§¤ê°œë³€ìˆ˜ ì¡°ì • ì‹ í˜¸ë¡œ ë³€í™˜í•˜ëŠ” ì ì‘í˜• ë§¤í•‘ ë©”ì»¤ë‹ˆì¦˜ì„ ì„¤ê³„í•©ë‹ˆë‹¤.
- 4. ì—£ì§€-í´ë¼ìš°ë“œ í˜‘ë ¥ ì¶”ë¡  í”„ë ˆì„ì›Œí¬ ë‚´ì—ì„œ ì‹ ë¢°ë„ ì ìˆ˜ì— ë”°ë¼ í´ë¼ìš°ë“œ ê¸°ë°˜ ì˜ë¯¸ ê°€ì´ë“œë¥¼ í˜¸ì¶œí•˜ê±°ë‚˜ ì—£ì§€ íƒì§€ ê²°ê³¼ë¥¼ ì§ì ‘ ì¶œë ¥í•©ë‹ˆë‹¤.
- 5. ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì€ ë³µì¡í•œ ì¥ë©´ì—ì„œ íƒì§€ ì •í™•ë„ì™€ íš¨ìœ¨ì„±ì„ íš¨ê³¼ì ìœ¼ë¡œ í–¥ìƒì‹œí‚¤ë©°, íŠ¹íˆ ì €ì¡°ë„ ë° ì‹¬í•œ ê°€ë¦¼ í˜„ì¥ì—ì„œ ì§€ì—° ì‹œê°„ì„ 79% ì´ìƒ, ê³„ì‚° ë¹„ìš©ì„ 70% ì ˆê°í•˜ë©´ì„œ ì •í™•ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-25 15:51:57*