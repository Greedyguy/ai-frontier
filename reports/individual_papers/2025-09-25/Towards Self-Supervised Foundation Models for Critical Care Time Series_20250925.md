---
keywords:
  - Transformer
  - Self-supervised Learning
  - Critical Care Time Series
  - Electronic Health Records
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2509.19885
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T15:53:06.063613",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Transformer",
    "Self-supervised Learning",
    "Critical Care Time Series",
    "Electronic Health Records"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Transformer": 0.8,
    "Self-supervised Learning": 0.85,
    "Critical Care Time Series": 0.7,
    "Electronic Health Records": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Bi-Axial Transformer",
        "canonical": "Transformer",
        "aliases": [
          "BAT"
        ],
        "category": "broad_technical",
        "rationale": "The Bi-Axial Transformer is a specific application of the Transformer architecture, relevant for linking with existing Transformer research.",
        "novelty_score": 0.55,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "self-supervised foundation models",
        "canonical": "Self-supervised Learning",
        "aliases": [
          "self-supervised models"
        ],
        "category": "specific_connectable",
        "rationale": "Self-supervised foundation models are crucial for linking advancements in unsupervised learning techniques.",
        "novelty_score": 0.6,
        "connectivity_score": 0.9,
        "specificity_score": 0.8,
        "link_intent_score": 0.85
      },
      {
        "surface": "critical care time series",
        "canonical": "Critical Care Time Series",
        "aliases": [
          "critical care data"
        ],
        "category": "unique_technical",
        "rationale": "This is a specialized dataset type that is central to the paper's focus, offering unique insights into healthcare applications.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.7
      },
      {
        "surface": "electronic health record datasets",
        "canonical": "Electronic Health Records",
        "aliases": [
          "EHR datasets"
        ],
        "category": "specific_connectable",
        "rationale": "EHR datasets are a foundational element for healthcare-related machine learning models, facilitating connections to medical informatics.",
        "novelty_score": 0.5,
        "connectivity_score": 0.88,
        "specificity_score": 0.75,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "foundation models",
      "transfer learning",
      "mortality prediction"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Bi-Axial Transformer",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "self-supervised foundation models",
      "resolved_canonical": "Self-supervised Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.9,
        "specificity": 0.8,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "critical care time series",
      "resolved_canonical": "Critical Care Time Series",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "electronic health record datasets",
      "resolved_canonical": "Electronic Health Records",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.88,
        "specificity": 0.75,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# Towards Self-Supervised Foundation Models for Critical Care Time Series

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19885.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2509.19885](https://arxiv.org/abs/2509.19885)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/MIRA_ Medical Time Series Foundation Model for Real-World Health Data_20250923|MIRA: Medical Time Series Foundation Model for Real-World Health Data]] (84.2% similar)
- [[2025-09-24/Early Prediction of In-Hospital ICU Mortality Using Innovative First-Day Data_ A Review_20250924|Early Prediction of In-Hospital ICU Mortality Using Innovative First-Day Data: A Review]] (82.2% similar)
- [[2025-09-24/Early Prediction of Multi-Label Care Escalation Triggers in the Intensive Care Unit Using Electronic Health Records_20250924|Early Prediction of Multi-Label Care Escalation Triggers in the Intensive Care Unit Using Electronic Health Records]] (82.1% similar)
- [[2025-09-23/Multi-View Contrastive Learning for Robust Domain Adaptation in Medical Time Series Analysis_20250923|Multi-View Contrastive Learning for Robust Domain Adaptation in Medical Time Series Analysis]] (82.0% similar)
- [[2025-09-22/Self-supervised learning of imaging and clinical signatures using a multimodal joint-embedding predictive architecture_20250922|Self-supervised learning of imaging and clinical signatures using a multimodal joint-embedding predictive architecture]] (81.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Transformer|Transformer]]
**ğŸ”— Specific Connectable**: [[keywords/Self-supervised Learning|Self-supervised Learning]], [[keywords/Electronic Health Records|Electronic Health Records]]
**âš¡ Unique Technical**: [[keywords/Critical Care Time Series|Critical Care Time Series]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19885v1 Announce Type: cross 
Abstract: Domain-specific foundation models for healthcare have expanded rapidly in recent years, yet foundation models for critical care time series remain relatively underexplored due to the limited size and availability of datasets. In this work, we introduce an early-stage pre-trained foundation model for critical care time-series based on the Bi-Axial Transformer (BAT), trained on pooled electronic health record datasets. We demonstrate effective transfer learning by fine-tuning the model on a dataset distinct from the training sources for mortality prediction, where it outperforms supervised baselines, particularly for small datasets ($<5,000$). These contributions highlight the potential of self-supervised foundation models for critical care times series to support generalizable and robust clinical applications in resource-limited settings.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì¤‘í™˜ì ì¹˜ë£Œ ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ìœ„í•œ ì´ˆê¸° ë‹¨ê³„ì˜ ì‚¬ì „ í•™ìŠµëœ ê¸°ë°˜ ëª¨ë¸ì„ ì†Œê°œí•©ë‹ˆë‹¤. Bi-Axial Transformer(BAT)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì „ìì˜ë¬´ê¸°ë¡ ë°ì´í„°ë¥¼ í™œìš©í•´ ëª¨ë¸ì„ ê°œë°œí•˜ì˜€ìœ¼ë©°, ë‹¤ë¥¸ ë°ì´í„°ì…‹ì— ëŒ€í•´ ë¯¸ì„¸ ì¡°ì •ì„ í†µí•´ ì‚¬ë§ë¥  ì˜ˆì¸¡ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. íŠ¹íˆ, 5,000ê°œ ë¯¸ë§Œì˜ ì‘ì€ ë°ì´í„°ì…‹ì—ì„œ ê°ë… í•™ìŠµ ê¸°ë°˜ ëª¨ë¸ì„ ëŠ¥ê°€í–ˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ìì› ì œí•œ í™˜ê²½ì—ì„œ ì¼ë°˜í™” ê°€ëŠ¥í•˜ê³  ê²¬ê³ í•œ ì„ìƒ ì‘ìš©ì„ ì§€ì›í•  ìˆ˜ ìˆëŠ” ìê¸° ì§€ë„ ê¸°ë°˜ ëª¨ë¸ì˜ ì ì¬ë ¥ì„ ê°•ì¡°í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì˜ë£Œ ë¶„ì•¼ì˜ ë„ë©”ì¸ íŠ¹í™” ê¸°ë°˜ ëª¨ë¸ì€ ë¹ ë¥´ê²Œ í™•ì¥ë˜ê³  ìˆìœ¼ë‚˜, ì¤‘í™˜ìì‹¤ ì‹œê³„ì—´ ë°ì´í„°ì— ëŒ€í•œ ê¸°ë°˜ ëª¨ë¸ì€ ë°ì´í„°ì…‹ì˜ í¬ê¸°ì™€ ê°€ìš©ì„±ì˜ ì œí•œìœ¼ë¡œ ìƒëŒ€ì ìœ¼ë¡œ ëœ íƒêµ¬ë˜ì—ˆë‹¤.
- 2. ë³¸ ì—°êµ¬ì—ì„œëŠ” Bi-Axial Transformer(BAT)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì¤‘í™˜ìì‹¤ ì‹œê³„ì—´ ë°ì´í„°ì˜ ì´ˆê¸° ë‹¨ê³„ ì‚¬ì „ í›ˆë ¨ ê¸°ë°˜ ëª¨ë¸ì„ ì†Œê°œí•˜ì˜€ë‹¤.
- 3. ë³¸ ëª¨ë¸ì€ í›ˆë ¨ ì†ŒìŠ¤ì™€ ë‹¤ë¥¸ ë°ì´í„°ì…‹ì— ëŒ€í•´ ë¯¸ì„¸ ì¡°ì •í•˜ì—¬ ì‚¬ë§ë¥  ì˜ˆì¸¡ì—ì„œ ê°ë… í•™ìŠµ ê¸°ë°˜ ëª¨ë¸ì„ ëŠ¥ê°€í•˜ëŠ” ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤, íŠ¹íˆ ì‘ì€ ë°ì´í„°ì…‹($<5,000$)ì—ì„œ ë‘ë“œëŸ¬ì¡Œë‹¤.
- 4. ë³¸ ì—°êµ¬ëŠ” ìê°€ ì§€ë„ ê¸°ë°˜ ëª¨ë¸ì´ ìì›ì´ ì œí•œëœ í™˜ê²½ì—ì„œ ì¼ë°˜í™” ê°€ëŠ¥í•˜ê³  ê²¬ê³ í•œ ì„ìƒ ì‘ìš©ì„ ì§€ì›í•  ìˆ˜ ìˆëŠ” ì ì¬ë ¥ì„ ê°•ì¡°í•œë‹¤.


---

*Generated on 2025-09-25 15:53:06*