---
keywords:
  - Large Language Model
  - Gaslighting Attacks
  - Multimodal Learning
  - Adversarial Input
category: cs.CL
publish_date: 2025-09-25
arxiv_id: 2509.19858
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-26T08:45:46.614900",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Gaslighting Attacks",
    "Multimodal Learning",
    "Adversarial Input"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.78,
    "Gaslighting Attacks": 0.82,
    "Multimodal Learning": 0.79,
    "Adversarial Input": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Speech Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "Speech LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Links to the broader concept of LLMs, crucial for understanding the context of speech-based AI.",
        "novelty_score": 0.45,
        "connectivity_score": 0.85,
        "specificity_score": 0.6,
        "link_intent_score": 0.78
      },
      {
        "surface": "Gaslighting Attacks",
        "canonical": "Gaslighting Attacks",
        "aliases": [
          "Manipulative Prompts"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel attack vector specific to speech models, enhancing understanding of adversarial strategies.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.82
      },
      {
        "surface": "Multimodal Robustness",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal Resilience"
        ],
        "category": "specific_connectable",
        "rationale": "Connects to the trending concept of multimodal systems, relevant for evaluating model robustness.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.79
      },
      {
        "surface": "Adversarial Input",
        "canonical": "Adversarial Input",
        "aliases": [
          "Adversarial Prompts"
        ],
        "category": "unique_technical",
        "rationale": "Highlights the challenge of adversarial manipulation in AI, linking to security considerations.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.75,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "performance degradation",
      "behavioral responses"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Speech Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.85,
        "specificity": 0.6,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Gaslighting Attacks",
      "resolved_canonical": "Gaslighting Attacks",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Multimodal Robustness",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Adversarial Input",
      "resolved_canonical": "Adversarial Input",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.75,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# Benchmarking Gaslighting Attacks Against Speech Large Language Models

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19858.pdf)
**Category**: cs.CL
**Published**: 2025-09-25
**ArXiv ID**: [2509.19858](https://arxiv.org/abs/2509.19858)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Strategic Dishonesty Can Undermine AI Safety Evaluations of Frontier LLM_20250923|Strategic Dishonesty Can Undermine AI Safety Evaluations of Frontier LLM]] (86.0% similar)
- [[2025-09-25/Semantic Representation Attack against Aligned Large Language Models_20250925|Semantic Representation Attack against Aligned Large Language Models]] (85.8% similar)
- [[2025-09-23/Breaking the Reviewer_ Assessing the Vulnerability of Large Language Models in Automated Peer Review Under Textual Adversarial Attacks_20250923|Breaking the Reviewer: Assessing the Vulnerability of Large Language Models in Automated Peer Review Under Textual Adversarial Attacks]] (85.6% similar)
- [[2025-09-23/Sugar-Coated Poison_ Benign Generation Unlocks LLM Jailbreaking_20250923|Sugar-Coated Poison: Benign Generation Unlocks LLM Jailbreaking]] (85.5% similar)
- [[2025-09-23/Challenging the Evaluator_ LLM Sycophancy Under User Rebuttal_20250923|Challenging the Evaluator: LLM Sycophancy Under User Rebuttal]] (85.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**âš¡ Unique Technical**: [[keywords/Gaslighting Attacks|Gaslighting Attacks]], [[keywords/Adversarial Input|Adversarial Input]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19858v1 Announce Type: new 
Abstract: As Speech Large Language Models (Speech LLMs) become increasingly integrated into voice-based applications, ensuring their robustness against manipulative or adversarial input becomes critical. Although prior work has studied adversarial attacks in text-based LLMs and vision-language models, the unique cognitive and perceptual challenges of speech-based interaction remain underexplored. In contrast, speech presents inherent ambiguity, continuity, and perceptual diversity, which make adversarial attacks more difficult to detect. In this paper, we introduce gaslighting attacks, strategically crafted prompts designed to mislead, override, or distort model reasoning as a means to evaluate the vulnerability of Speech LLMs. Specifically, we construct five manipulation strategies: Anger, Cognitive Disruption, Sarcasm, Implicit, and Professional Negation, designed to test model robustness across varied tasks. It is worth noting that our framework captures both performance degradation and behavioral responses, including unsolicited apologies and refusals, to diagnose different dimensions of susceptibility. Moreover, acoustic perturbation experiments are conducted to assess multi-modal robustness. To quantify model vulnerability, comprehensive evaluation across 5 Speech and multi-modal LLMs on over 10,000 test samples from 5 diverse datasets reveals an average accuracy drop of 24.3% under the five gaslighting attacks, indicating significant behavioral vulnerability. These findings highlight the need for more resilient and trustworthy speech-based AI systems.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ìŒì„± ê¸°ë°˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì‚¬ìš©ë˜ëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(Speech LLMs)ì˜ ì·¨ì•½ì„±ì„ í‰ê°€í•˜ê¸° ìœ„í•´ ê³ ì•ˆëœ 'ê°€ìŠ¤ë¼ì´íŒ… ê³µê²©'ì„ ì†Œê°œí•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ê³µê²©ì€ ëª¨ë¸ì˜ ì¶”ë¡ ì„ ì˜¤ë„í•˜ê±°ë‚˜ ì™œê³¡í•˜ëŠ” ì „ëµì  í”„ë¡¬í”„íŠ¸ë¡œ êµ¬ì„±ë˜ë©°, ë¶„ë…¸, ì¸ì§€ì  í˜¼ë€, í’ì, ì•”ì‹œ, ì „ë¬¸ì  ë¶€ì • ë“± ë‹¤ì„¯ ê°€ì§€ ì¡°ì‘ ì „ëµì„ í†µí•´ ëª¨ë¸ì˜ ê°•ê±´ì„±ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤. ì—°êµ¬ëŠ” 5ê°œì˜ ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ì—ì„œ 10,000ê°œ ì´ìƒì˜ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œì„ ì‚¬ìš©í•˜ì—¬ 5ê°œì˜ ìŒì„± ë° ë©€í‹°ëª¨ë‹¬ LLMì— ëŒ€í•œ ì¢…í•© í‰ê°€ë¥¼ ìˆ˜í–‰í–ˆìœ¼ë©°, í‰ê·  ì •í™•ë„ê°€ 24.3% ê°ì†Œí•˜ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤. ì´ëŠ” ìŒì„± ê¸°ë°˜ AI ì‹œìŠ¤í…œì˜ ì‹ ë¢°ì„±ê³¼ ê°•ê±´ì„±ì„ ë†’ì¼ í•„ìš”ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ìŒì„± ê¸°ë°˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ Speech LLMsì˜ ì¡°ì‘ ë° ì ëŒ€ì  ì…ë ¥ì— ëŒ€í•œ ê°•ì¸ì„±ì„ í™•ë³´í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.
- 2. ìŒì„±ì€ ê³ ìœ ì˜ ëª¨í˜¸ì„±ê³¼ ì—°ì†ì„±, ì§€ê°ì  ë‹¤ì–‘ì„±ì„ ì§€ë‹ˆê³  ìˆì–´ ì ëŒ€ì  ê³µê²©ì„ íƒì§€í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.
- 3. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” Speech LLMsì˜ ì·¨ì•½ì„±ì„ í‰ê°€í•˜ê¸° ìœ„í•´ ëª¨ë¸ì˜ ì¶”ë¡ ì„ ì˜¤ë„í•˜ëŠ” 'ê°€ìŠ¤ë¼ì´íŒ… ê³µê²©'ì„ ì†Œê°œí•©ë‹ˆë‹¤.
- 4. ë‹¤ì„¯ ê°€ì§€ ì¡°ì‘ ì „ëµ(ë¶„ë…¸, ì¸ì§€ì  í˜¼ë€, í’ì, ì•”ì‹œ, ì „ë¬¸ì  ë¶€ì •)ì„ í†µí•´ ëª¨ë¸ì˜ ê°•ì¸ì„±ì„ ë‹¤ì–‘í•œ ì‘ì—…ì—ì„œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
- 5. 5ê°œì˜ Speech ë° ë©€í‹°ëª¨ë‹¬ LLMsì— ëŒ€í•œ í‰ê°€ ê²°ê³¼, ê°€ìŠ¤ë¼ì´íŒ… ê³µê²© ì‹œ í‰ê·  ì •í™•ë„ê°€ 24.3% ê°ì†Œí•˜ì—¬ ëª¨ë¸ì˜ í–‰ë™ì  ì·¨ì•½ì„±ì„ ë“œëŸ¬ëƒ…ë‹ˆë‹¤.


---

*Generated on 2025-09-26 08:45:46*