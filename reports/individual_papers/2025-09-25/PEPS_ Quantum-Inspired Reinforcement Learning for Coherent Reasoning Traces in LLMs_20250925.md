---
keywords:
  - Large Language Model
  - Projected Entangled Pair States
  - Proximal Policy Optimization
  - Quantum-Inspired Learning
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2509.20105
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T15:19:33.421638",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Projected Entangled Pair States",
    "Proximal Policy Optimization",
    "Quantum-Inspired Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Projected Entangled Pair States": 0.8,
    "Proximal Policy Optimization": 0.82,
    "Quantum-Inspired Learning": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "A foundational concept in the paper, linking to a broad range of NLP research.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Projected Entangled Pair States",
        "canonical": "Projected Entangled Pair States",
        "aliases": [
          "PEPS"
        ],
        "category": "unique_technical",
        "rationale": "A unique quantum concept applied in the paper, offering novel insights into coherence in reasoning.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "Proximal Policy Optimization",
        "canonical": "Proximal Policy Optimization",
        "aliases": [
          "PPO"
        ],
        "category": "specific_connectable",
        "rationale": "A key reinforcement learning algorithm used in the methodology, relevant for linking to RL research.",
        "novelty_score": 0.4,
        "connectivity_score": 0.78,
        "specificity_score": 0.7,
        "link_intent_score": 0.82
      },
      {
        "surface": "quantum-inspired approach",
        "canonical": "Quantum-Inspired Learning",
        "aliases": [
          "quantum-inspired method"
        ],
        "category": "evolved_concepts",
        "rationale": "Represents a novel intersection of quantum mechanics and machine learning, fostering interdisciplinary links.",
        "novelty_score": 0.68,
        "connectivity_score": 0.72,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "method",
      "approach",
      "framework"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Projected Entangled Pair States",
      "resolved_canonical": "Projected Entangled Pair States",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Proximal Policy Optimization",
      "resolved_canonical": "Proximal Policy Optimization",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.78,
        "specificity": 0.7,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "quantum-inspired approach",
      "resolved_canonical": "Quantum-Inspired Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.72,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# PEPS: Quantum-Inspired Reinforcement Learning for Coherent Reasoning Traces in LLMs

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.20105.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2509.20105](https://arxiv.org/abs/2509.20105)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/How Can Quantum Deep Learning Improve Large Language Models?_20250923|How Can Quantum Deep Learning Improve Large Language Models?]] (86.0% similar)
- [[2025-09-23/EvoCoT_ Overcoming the Exploration Bottleneck in Reinforcement Learning_20250923|EvoCoT: Overcoming the Exploration Bottleneck in Reinforcement Learning]] (85.5% similar)
- [[2025-09-24/Reinforcement Learning on Pre-Training Data_20250924|Reinforcement Learning on Pre-Training Data]] (85.0% similar)
- [[2025-09-24/ReSearch_ Learning to Reason with Search for LLMs via Reinforcement Learning_20250924|ReSearch: Learning to Reason with Search for LLMs via Reinforcement Learning]] (84.8% similar)
- [[2025-09-23/GPO_ Learning from Critical Steps to Improve LLM Reasoning_20250923|GPO: Learning from Critical Steps to Improve LLM Reasoning]] (84.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Proximal Policy Optimization|Proximal Policy Optimization]]
**âš¡ Unique Technical**: [[keywords/Projected Entangled Pair States|Projected Entangled Pair States]]
**ğŸš€ Evolved Concepts**: [[keywords/Quantum-Inspired Learning|Quantum-Inspired Learning]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.20105v1 Announce Type: new 
Abstract: Large Language Models (LLMs) often struggle with maintaining coherent multi-step reasoning traces, particularly in tasks that require a structured logical flow. This work introduces a quantum-inspired approach to address the challenge by incorporating a fidelity-based reward derived from Projected Entangled Pair States (PEPS) into Proximal Policy Optimization. Unlike prior approaches that use direct supervision or contrastive objectives, the proposed method guides learning through structural consistency, offering a novel approach to enforce global coherence in generated reasoning traces. The proposed framework is evaluated using multiple coherence-determining metrics on diverse datasets such as GSM8K, StrategyQA, and EntailmentBank spanning arithmetic, intuitive, and entailment-based reasoning. Results show that the proposed quantum-inspired approach offers significant improvements over supervised, contrastive, and pretrained baseline approaches, highlighting the effectiveness of quantum-inspired fidelity as a foundation to improve reasoning trace coherence in LLMs.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì´ ì—¬ëŸ¬ ë‹¨ê³„ì˜ ì¶”ë¡  ê³¼ì •ì—ì„œ ì¼ê´€ì„±ì„ ìœ ì§€í•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì–‘ì ì˜ê°ì„ ë°›ì€ ì ‘ê·¼ ë°©ì‹ì„ ì œì•ˆí•©ë‹ˆë‹¤. Projected Entangled Pair States(PEPS)ì—ì„œ íŒŒìƒëœ ì¶©ì‹¤ë„ ê¸°ë°˜ ë³´ìƒì„ Proximal Policy Optimizationì— í†µí•©í•˜ì—¬ êµ¬ì¡°ì  ì¼ê´€ì„±ì„ í†µí•´ í•™ìŠµì„ ìœ ë„í•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ GSM8K, StrategyQA, EntailmentBankì™€ ê°™ì€ ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ì—ì„œ í‰ê°€ë˜ì—ˆìœ¼ë©°, ì‚°ìˆ , ì§ê´€, í•¨ì˜ ê¸°ë°˜ ì¶”ë¡ ì—ì„œ ê¸°ì¡´ì˜ ê°ë… í•™ìŠµ ë° ëŒ€ì¡°ì  ëª©í‘œë³´ë‹¤ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ì—°êµ¬ ê²°ê³¼ëŠ” ì–‘ì ì˜ê° ì¶©ì‹¤ë„ê°€ LLMì˜ ì¶”ë¡  ì¼ê´€ì„±ì„ ê°œì„ í•˜ëŠ” ë° íš¨ê³¼ì ì„ì„ ê°•ì¡°í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì€ ë‹¤ë‹¨ê³„ ì¶”ë¡ ì—ì„œ ì¼ê´€ì„±ì„ ìœ ì§€í•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªëŠ”ë‹¤.
- 2. ë³¸ ì—°êµ¬ëŠ” ì–‘ì ì˜ê°ì„ ë°›ì€ ì ‘ê·¼ ë°©ì‹ì„ í†µí•´ Projected Entangled Pair States(PEPS)ì—ì„œ ìœ ë„ëœ ì¶©ì‹¤ë„ ê¸°ë°˜ ë³´ìƒì„ Proximal Policy Optimizationì— í†µí•©í•˜ì—¬ ì´ ë¬¸ì œë¥¼ í•´ê²°í•œë‹¤.
- 3. ì œì•ˆëœ ë°©ë²•ì€ êµ¬ì¡°ì  ì¼ê´€ì„±ì„ í†µí•´ í•™ìŠµì„ ìœ ë„í•˜ë©°, ìƒì„±ëœ ì¶”ë¡  ê³¼ì •ì˜ ì „ë°˜ì ì¸ ì¼ê´€ì„±ì„ ê°•í™”í•˜ëŠ” ìƒˆë¡œìš´ ì ‘ê·¼ ë°©ì‹ì„ ì œê³µí•œë‹¤.
- 4. ë‹¤ì–‘í•œ ë°ì´í„°ì…‹(GSM8K, StrategyQA, EntailmentBank)ì„ ì‚¬ìš©í•œ í‰ê°€ ê²°ê³¼, ì œì•ˆëœ ì–‘ì ì˜ê° ì ‘ê·¼ ë°©ì‹ì´ ê¸°ì¡´ì˜ ì§€ë„ í•™ìŠµ, ëŒ€ì¡° ëª©í‘œ, ì‚¬ì „ í•™ìŠµëœ ê¸°ì¤€ ì ‘ê·¼ ë°©ì‹ë³´ë‹¤ ìœ ì˜ë¯¸í•œ ê°œì„ ì„ ë³´ì˜€ë‹¤.
- 5. ì–‘ì ì˜ê° ì¶©ì‹¤ë„ê°€ LLMì˜ ì¶”ë¡  ê³¼ì • ì¼ê´€ì„±ì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ì´ˆë¡œì„œ íš¨ê³¼ì ì„ì„ ê°•ì¡°í•œë‹¤.


---

*Generated on 2025-09-25 15:19:33*