---
keywords:
  - AI Model Caching
  - Coordinated Multipoint Broadcasting
  - Multi-Agent Learning Framework
  - Parameter Blocks
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2509.19341
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T15:27:10.760364",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "AI Model Caching",
    "Coordinated Multipoint Broadcasting",
    "Multi-Agent Learning Framework",
    "Parameter Blocks"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "AI Model Caching": 0.75,
    "Coordinated Multipoint Broadcasting": 0.72,
    "Multi-Agent Learning Framework": 0.8,
    "Parameter Blocks": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "AI model caching",
        "canonical": "AI Model Caching",
        "aliases": [
          "Model Caching",
          "Caching"
        ],
        "category": "unique_technical",
        "rationale": "AI Model Caching is a unique concept that addresses storage and retrieval challenges in edge networks, facilitating specific technical discussions.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      },
      {
        "surface": "Coordinated multipoint broadcasting",
        "canonical": "Coordinated Multipoint Broadcasting",
        "aliases": [
          "CoMP Broadcasting",
          "Multipoint Broadcasting"
        ],
        "category": "unique_technical",
        "rationale": "This technique is crucial for optimizing spectrum utilization in multi-cell networks, providing a unique angle for technical exploration.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.78,
        "link_intent_score": 0.72
      },
      {
        "surface": "Multi-agent learning framework",
        "canonical": "Multi-Agent Learning Framework",
        "aliases": [
          "Multi-Agent Learning",
          "Distributed Learning Framework"
        ],
        "category": "specific_connectable",
        "rationale": "This framework is pivotal for enabling cooperation among edge nodes, making it a key concept for linking discussions on distributed AI.",
        "novelty_score": 0.6,
        "connectivity_score": 0.85,
        "specificity_score": 0.77,
        "link_intent_score": 0.8
      },
      {
        "surface": "Parameter blocks",
        "canonical": "Parameter Blocks",
        "aliases": [
          "PBs",
          "Model Parameter Blocks"
        ],
        "category": "unique_technical",
        "rationale": "Parameter Blocks are a novel approach to optimize storage and delivery of AI models, offering a unique perspective on model management.",
        "novelty_score": 0.68,
        "connectivity_score": 0.6,
        "specificity_score": 0.82,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "6G networks",
      "end users",
      "edge nodes"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "AI model caching",
      "resolved_canonical": "AI Model Caching",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Coordinated multipoint broadcasting",
      "resolved_canonical": "Coordinated Multipoint Broadcasting",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.78,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "Multi-agent learning framework",
      "resolved_canonical": "Multi-Agent Learning Framework",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.85,
        "specificity": 0.77,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Parameter blocks",
      "resolved_canonical": "Parameter Blocks",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.6,
        "specificity": 0.82,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# Fine-Grained AI Model Caching and Downloading With Coordinated Multipoint Broadcasting in Multi-Cell Edge Networks

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19341.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2509.19341](https://arxiv.org/abs/2509.19341)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-25/A Federated Fine-Tuning Paradigm of Foundation Models in Heterogenous Wireless Networks_20250925|A Federated Fine-Tuning Paradigm of Foundation Models in Heterogenous Wireless Networks]] (84.6% similar)
- [[2025-09-23/Learn to Optimize Resource Allocation under QoS Constraint of AR_20250923|Learn to Optimize Resource Allocation under QoS Constraint of AR]] (82.5% similar)
- [[2025-09-24/Integrating Stacked Intelligent Metasurfaces and Power Control for Dynamic Edge Inference via Over-The-Air Neural Networks_20250924|Integrating Stacked Intelligent Metasurfaces and Power Control for Dynamic Edge Inference via Over-The-Air Neural Networks]] (82.3% similar)
- [[2025-09-23/Search-Optimized Quantization in Biomedical Ontology Alignment_20250923|Search-Optimized Quantization in Biomedical Ontology Alignment]] (82.0% similar)
- [[2025-09-23/Federated Learning with Ad-hoc Adapter Insertions_ The Case of Soft-Embeddings for Training Classifier-as-Retriever_20250923|Federated Learning with Ad-hoc Adapter Insertions: The Case of Soft-Embeddings for Training Classifier-as-Retriever]] (82.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Multi-Agent Learning Framework|Multi-Agent Learning Framework]]
**âš¡ Unique Technical**: [[keywords/AI Model Caching|AI Model Caching]], [[keywords/Coordinated Multipoint Broadcasting|Coordinated Multipoint Broadcasting]], [[keywords/Parameter Blocks|Parameter Blocks]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19341v1 Announce Type: cross 
Abstract: 6G networks are envisioned to support on-demand AI model downloading to accommodate diverse inference requirements of end users. By proactively caching models at edge nodes, users can retrieve the requested models with low latency for on-device AI inference. However, the substantial size of contemporary AI models poses significant challenges for edge caching under limited storage capacity, as well as for the concurrent delivery of heterogeneous models over wireless channels. To address these challenges, we propose a fine-grained AI model caching and downloading system that exploits parameter reusability, stemming from the common practice of fine-tuning task-specific models from a shared pre-trained model with frozen parameters. This system selectively caches model parameter blocks (PBs) at edge nodes, eliminating redundant storage of reusable parameters across different cached models. Additionally, it incorporates coordinated multipoint (CoMP) broadcasting to simultaneously deliver reusable PBs to multiple users, thereby enhancing downlink spectrum utilization. Under this arrangement, we formulate a model downloading delay minimization problem to jointly optimize PB caching, migration (among edge nodes), and broadcasting beamforming. To tackle this intractable problem, we develop a distributed multi-agent learning framework that enables edge nodes to explicitly learn mutual influence among their actions, thereby facilitating cooperation. Furthermore, a data augmentation approach is proposed to adaptively generate synthetic training samples through a predictive model, boosting sample efficiency and accelerating policy learning. Both theoretical analysis and simulation experiments validate the superior convergence performance of the proposed learning framework.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ 6G ë„¤íŠ¸ì›Œí¬ì—ì„œ ì‚¬ìš©ì ìš”êµ¬ì— ë§ì¶° AI ëª¨ë¸ì„ ì‹ ì†í•˜ê²Œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆë„ë¡ ì—£ì§€ ë…¸ë“œì—ì„œ AI ëª¨ë¸ì„ ìºì‹±í•˜ëŠ” ì‹œìŠ¤í…œì„ ì œì•ˆí•©ë‹ˆë‹¤. ì£¼ìš” ê¸°ì—¬ëŠ” íŒŒë¼ë¯¸í„° ì¬ì‚¬ìš©ì„ í™œìš©í•˜ì—¬ ì—£ì§€ ë…¸ë“œì— ëª¨ë¸ íŒŒë¼ë¯¸í„° ë¸”ë¡(PB)ì„ ì„ íƒì ìœ¼ë¡œ ìºì‹±í•¨ìœ¼ë¡œì¨ ì €ì¥ ê³µê°„ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ë˜í•œ, CoMP ë°©ì†¡ì„ í†µí•´ ì—¬ëŸ¬ ì‚¬ìš©ìì—ê²Œ ë™ì‹œì— PBë¥¼ ì „ë‹¬í•˜ì—¬ ìŠ¤í™íŠ¸ëŸ¼ í™œìš©ì„ ìµœì í™”í•©ë‹ˆë‹¤. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì§€ì—°ì„ ìµœì†Œí™”í•˜ê¸° ìœ„í•´ PB ìºì‹±, ì—£ì§€ ë…¸ë“œ ê°„ ë§ˆì´ê·¸ë ˆì´ì…˜, ë°©ì†¡ ë¹”í¬ë°ì„ ìµœì í™”í•˜ëŠ” ë¬¸ì œë¥¼ ì„¤ì •í•˜ê³ , ë¶„ì‚°í˜• ë‹¤ì¤‘ ì—ì´ì „íŠ¸ í•™ìŠµ í”„ë ˆì„ì›Œí¬ë¥¼ ê°œë°œí•˜ì—¬ ì—£ì§€ ë…¸ë“œ ê°„ì˜ í˜‘ë ¥ì„ ì´‰ì§„í•©ë‹ˆë‹¤. ë°ì´í„° ì¦ê°• ê¸°ë²•ì„ í†µí•´ ìƒ˜í”Œ íš¨ìœ¨ì„±ì„ ë†’ì´ê³  ì •ì±… í•™ìŠµì„ ê°€ì†í™”í•©ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ì´ë¡ ì  ë¶„ì„ê³¼ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í—˜ì„ í†µí•´ ìš°ìˆ˜í•œ ìˆ˜ë ´ ì„±ëŠ¥ì„ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. 6G ë„¤íŠ¸ì›Œí¬ì—ì„œëŠ” ì‚¬ìš©ì ìš”êµ¬ì— ë§ì¶° AI ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•˜ë©°, ì—£ì§€ ë…¸ë“œì—ì„œ ëª¨ë¸ì„ ìºì‹±í•˜ì—¬ ì§€ì—° ì‹œê°„ì„ ì¤„ì…ë‹ˆë‹¤.
- 2. í˜„ëŒ€ AI ëª¨ë¸ì˜ í° í¬ê¸°ëŠ” ì œí•œëœ ì €ì¥ ìš©ëŸ‰ê³¼ ë¬´ì„  ì±„ë„ì„ í†µí•œ ì´ì§ˆì ì¸ ëª¨ë¸ì˜ ë™ì‹œ ì „ì†¡ì— ë„ì „ ê³¼ì œë¥¼ ì œì‹œí•©ë‹ˆë‹¤.
- 3. ì œì•ˆëœ ì‹œìŠ¤í…œì€ ê³µìœ ëœ ì‚¬ì „ í•™ìŠµ ëª¨ë¸ì—ì„œ íŒŒë¼ë¯¸í„° ì¬ì‚¬ìš©ì„ í™œìš©í•˜ì—¬ ì—£ì§€ ë…¸ë“œì— ëª¨ë¸ íŒŒë¼ë¯¸í„° ë¸”ë¡ì„ ì„ íƒì ìœ¼ë¡œ ìºì‹±í•©ë‹ˆë‹¤.
- 4. CoMP ë°©ì†¡ì„ í†µí•´ ì—¬ëŸ¬ ì‚¬ìš©ìì—ê²Œ ì¬ì‚¬ìš© ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ë¸”ë¡ì„ ë™ì‹œì— ì „ë‹¬í•˜ì—¬ í•˜í–¥ ë§í¬ ìŠ¤í™íŠ¸ëŸ¼ í™œìš©ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
- 5. ë¶„ì‚° ë©€í‹° ì—ì´ì „íŠ¸ í•™ìŠµ í”„ë ˆì„ì›Œí¬ë¥¼ ê°œë°œí•˜ì—¬ ì—£ì§€ ë…¸ë“œê°€ í–‰ë™ ê°„ì˜ ìƒí˜¸ ì˜í–¥ì„ í•™ìŠµí•˜ê³  í˜‘ë ¥ì„ ì´‰ì§„í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-25 15:27:10*