---
keywords:
  - Credit Default Prediction
  - Boruta Feature Selection
  - DBSCAN Algorithm
  - SMOTE-Tomek
  - Gradient Boosting Machines
category: cs.LG
publish_date: 2025-09-25
arxiv_id: 2509.19408
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T16:35:26.933946",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Credit Default Prediction",
    "Boruta Feature Selection",
    "DBSCAN Algorithm",
    "SMOTE-Tomek",
    "Gradient Boosting Machines"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Credit Default Prediction": 0.78,
    "Boruta Feature Selection": 0.75,
    "DBSCAN Algorithm": 0.8,
    "SMOTE-Tomek": 0.77,
    "Gradient Boosting Machines": 0.82
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "credit default prediction",
        "canonical": "Credit Default Prediction",
        "aliases": [
          "credit risk modeling"
        ],
        "category": "unique_technical",
        "rationale": "This is a specific application area that connects various machine learning techniques discussed in the paper.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Boruta feature selection",
        "canonical": "Boruta Feature Selection",
        "aliases": [
          "Boruta method"
        ],
        "category": "unique_technical",
        "rationale": "Boruta is a specific feature selection method that is central to the study's methodology.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      },
      {
        "surface": "DBSCAN algorithm",
        "canonical": "DBSCAN Algorithm",
        "aliases": [
          "Density-Based Spatial Clustering"
        ],
        "category": "specific_connectable",
        "rationale": "DBSCAN is a well-known clustering algorithm that is used for outlier detection in this study.",
        "novelty_score": 0.6,
        "connectivity_score": 0.85,
        "specificity_score": 0.75,
        "link_intent_score": 0.8
      },
      {
        "surface": "SMOTE-Tomek",
        "canonical": "SMOTE-Tomek",
        "aliases": [
          "SMOTE-Tomek Link"
        ],
        "category": "unique_technical",
        "rationale": "SMOTE-Tomek is a specific resampling technique that plays a critical role in addressing class imbalance in the study.",
        "novelty_score": 0.68,
        "connectivity_score": 0.72,
        "specificity_score": 0.78,
        "link_intent_score": 0.77
      },
      {
        "surface": "Gradient Boosting Machines",
        "canonical": "Gradient Boosting Machines",
        "aliases": [
          "GBM"
        ],
        "category": "broad_technical",
        "rationale": "GBM is a key machine learning technique used in the study and is widely applicable across different domains.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.82
      }
    ],
    "ban_list_suggestions": [
      "machine learning",
      "model performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "credit default prediction",
      "resolved_canonical": "Credit Default Prediction",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Boruta feature selection",
      "resolved_canonical": "Boruta Feature Selection",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "DBSCAN algorithm",
      "resolved_canonical": "DBSCAN Algorithm",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.85,
        "specificity": 0.75,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "SMOTE-Tomek",
      "resolved_canonical": "SMOTE-Tomek",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.72,
        "specificity": 0.78,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Gradient Boosting Machines",
      "resolved_canonical": "Gradient Boosting Machines",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.82
      }
    }
  ]
}
-->

# Enhancing Credit Default Prediction Using Boruta Feature Selection and DBSCAN Algorithm with Different Resampling Techniques

## 📋 메타데이터

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19408.pdf)
**Category**: cs.LG
**Published**: 2025-09-25
**ArXiv ID**: [2509.19408](https://arxiv.org/abs/2509.19408)

## 🔗 유사한 논문
- [[2025-09-18/Credit Card Fraud Detection_20250918|Credit Card Fraud Detection]] (84.3% similar)
- [[2025-09-19/Evaluating Supervised Learning Models for Fraud Detection_ A Comparative Study of Classical and Deep Architectures on Imbalanced Transaction Data_20250919|Evaluating Supervised Learning Models for Fraud Detection: A Comparative Study of Classical and Deep Architectures on Imbalanced Transaction Data]] (82.9% similar)
- [[2025-09-23/Breast Cancer Classification Using Gradient Boosting Algorithms Focusing on Reducing the False Negative and SHAP for Explainability_20250923|Breast Cancer Classification Using Gradient Boosting Algorithms Focusing on Reducing the False Negative and SHAP for Explainability]] (81.7% similar)
- [[2025-09-25/Beyond the Pre-Service Horizon_ Infusing In-Service Behavior for Improved Financial Risk Forecasting_20250925|Beyond the Pre-Service Horizon: Infusing In-Service Behavior for Improved Financial Risk Forecasting]] (81.5% similar)
- [[2025-09-23/A Comprehensive Performance Comparison of Traditional and Ensemble Machine Learning Models for Online Fraud Detection_20250923|A Comprehensive Performance Comparison of Traditional and Ensemble Machine Learning Models for Online Fraud Detection]] (81.0% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Gradient Boosting Machines|Gradient Boosting Machines]]
**🔗 Specific Connectable**: [[keywords/DBSCAN Algorithm|DBSCAN Algorithm]]
**⚡ Unique Technical**: [[keywords/Credit Default Prediction|Credit Default Prediction]], [[keywords/Boruta Feature Selection|Boruta Feature Selection]], [[keywords/SMOTE-Tomek|SMOTE-Tomek]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.19408v1 Announce Type: new 
Abstract: This study examines credit default prediction by comparing three techniques, namely SMOTE, SMOTE-Tomek, and ADASYN, that are commonly used to address the class imbalance problem in credit default situations. Recognizing that credit default datasets are typically skewed, with defaulters comprising a much smaller proportion than non-defaulters, we began our analysis by evaluating machine learning (ML) models on the imbalanced data without any resampling to establish baseline performance. These baseline results provide a reference point for understanding the impact of subsequent balancing methods. In addition to traditional classifiers such as Naive Bayes and K-Nearest Neighbors (KNN), our study also explores the suitability of advanced ensemble boosting algorithms, including Extreme Gradient Boosting (XGBoost), AdaBoost, Gradient Boosting Machines (GBM), and Light GBM for credit default prediction using Boruta feature selection and DBSCAN-based outlier detection, both before and after resampling. A real-world credit default data set sourced from the University of Cleveland ML Repository was used to build ML classifiers, and their performances were tested. The criteria chosen to measure model performance are the area under the receiver operating characteristic curve (ROC-AUC), area under the precision-recall curve (PR-AUC), G-mean, and F1-scores. The results from this empirical study indicate that the Boruta+DBSCAN+SMOTE-Tomek+GBM classifier outperformed the other ML models (F1-score: 82.56%, G-mean: 82.98%, ROC-AUC: 90.90%, PR-AUC: 91.85%) in a credit default context. The findings establish a foundation for future progress in creating more resilient and adaptive credit default systems, which will be essential as credit-based transactions continue to rise worldwide.

## 📝 요약

이 연구는 신용 불이행 예측에서 클래스 불균형 문제를 해결하기 위한 SMOTE, SMOTE-Tomek, ADASYN 기법을 비교 분석합니다. 초기에는 불균형 데이터를 사용하여 머신러닝 모델의 기본 성능을 평가하였고, 이후 Boruta 특징 선택과 DBSCAN 기반 이상치 탐지를 통해 성능을 향상시켰습니다. 특히, SMOTE-Tomek과 GBM을 결합한 모델이 가장 우수한 성능을 보였으며, F1-score 82.56%, G-mean 82.98%, ROC-AUC 90.90%, PR-AUC 91.85%를 기록했습니다. 이 연구는 향후 더욱 강력하고 적응적인 신용 불이행 시스템 개발에 기여할 수 있는 기초를 제공합니다.

## 🎯 주요 포인트

- 1. 신용 불이행 예측에서 클래스 불균형 문제를 해결하기 위해 SMOTE, SMOTE-Tomek, ADASYN 기법을 비교 분석했습니다.
- 2. Boruta 특징 선택과 DBSCAN 기반 이상치 탐지를 활용하여, 다양한 머신러닝 모델의 성능을 평가했습니다.
- 3. 실험 결과, Boruta+DBSCAN+SMOTE-Tomek+GBM 분류기가 다른 모델들보다 우수한 성능을 보였습니다 (F1-score: 82.56%, G-mean: 82.98%, ROC-AUC: 90.90%, PR-AUC: 91.85%).
- 4. 이 연구는 향후 더 견고하고 적응력 있는 신용 불이행 시스템 개발의 기초를 마련합니다.


---

*Generated on 2025-09-25 16:35:26*