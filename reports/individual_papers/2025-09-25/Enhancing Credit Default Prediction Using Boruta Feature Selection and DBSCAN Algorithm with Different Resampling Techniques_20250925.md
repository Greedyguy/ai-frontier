---
keywords:
  - Credit Default Prediction
  - Boruta Feature Selection
  - DBSCAN Algorithm
  - SMOTE-Tomek
  - Gradient Boosting Machines
category: cs.LG
publish_date: 2025-09-25
arxiv_id: 2509.19408
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T16:35:26.933946",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Credit Default Prediction",
    "Boruta Feature Selection",
    "DBSCAN Algorithm",
    "SMOTE-Tomek",
    "Gradient Boosting Machines"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Credit Default Prediction": 0.78,
    "Boruta Feature Selection": 0.75,
    "DBSCAN Algorithm": 0.8,
    "SMOTE-Tomek": 0.77,
    "Gradient Boosting Machines": 0.82
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "credit default prediction",
        "canonical": "Credit Default Prediction",
        "aliases": [
          "credit risk modeling"
        ],
        "category": "unique_technical",
        "rationale": "This is a specific application area that connects various machine learning techniques discussed in the paper.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Boruta feature selection",
        "canonical": "Boruta Feature Selection",
        "aliases": [
          "Boruta method"
        ],
        "category": "unique_technical",
        "rationale": "Boruta is a specific feature selection method that is central to the study's methodology.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      },
      {
        "surface": "DBSCAN algorithm",
        "canonical": "DBSCAN Algorithm",
        "aliases": [
          "Density-Based Spatial Clustering"
        ],
        "category": "specific_connectable",
        "rationale": "DBSCAN is a well-known clustering algorithm that is used for outlier detection in this study.",
        "novelty_score": 0.6,
        "connectivity_score": 0.85,
        "specificity_score": 0.75,
        "link_intent_score": 0.8
      },
      {
        "surface": "SMOTE-Tomek",
        "canonical": "SMOTE-Tomek",
        "aliases": [
          "SMOTE-Tomek Link"
        ],
        "category": "unique_technical",
        "rationale": "SMOTE-Tomek is a specific resampling technique that plays a critical role in addressing class imbalance in the study.",
        "novelty_score": 0.68,
        "connectivity_score": 0.72,
        "specificity_score": 0.78,
        "link_intent_score": 0.77
      },
      {
        "surface": "Gradient Boosting Machines",
        "canonical": "Gradient Boosting Machines",
        "aliases": [
          "GBM"
        ],
        "category": "broad_technical",
        "rationale": "GBM is a key machine learning technique used in the study and is widely applicable across different domains.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.82
      }
    ],
    "ban_list_suggestions": [
      "machine learning",
      "model performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "credit default prediction",
      "resolved_canonical": "Credit Default Prediction",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Boruta feature selection",
      "resolved_canonical": "Boruta Feature Selection",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "DBSCAN algorithm",
      "resolved_canonical": "DBSCAN Algorithm",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.85,
        "specificity": 0.75,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "SMOTE-Tomek",
      "resolved_canonical": "SMOTE-Tomek",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.72,
        "specificity": 0.78,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Gradient Boosting Machines",
      "resolved_canonical": "Gradient Boosting Machines",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.82
      }
    }
  ]
}
-->

# Enhancing Credit Default Prediction Using Boruta Feature Selection and DBSCAN Algorithm with Different Resampling Techniques

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19408.pdf)
**Category**: cs.LG
**Published**: 2025-09-25
**ArXiv ID**: [2509.19408](https://arxiv.org/abs/2509.19408)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-18/Credit Card Fraud Detection_20250918|Credit Card Fraud Detection]] (84.3% similar)
- [[2025-09-19/Evaluating Supervised Learning Models for Fraud Detection_ A Comparative Study of Classical and Deep Architectures on Imbalanced Transaction Data_20250919|Evaluating Supervised Learning Models for Fraud Detection: A Comparative Study of Classical and Deep Architectures on Imbalanced Transaction Data]] (82.9% similar)
- [[2025-09-23/Breast Cancer Classification Using Gradient Boosting Algorithms Focusing on Reducing the False Negative and SHAP for Explainability_20250923|Breast Cancer Classification Using Gradient Boosting Algorithms Focusing on Reducing the False Negative and SHAP for Explainability]] (81.7% similar)
- [[2025-09-25/Beyond the Pre-Service Horizon_ Infusing In-Service Behavior for Improved Financial Risk Forecasting_20250925|Beyond the Pre-Service Horizon: Infusing In-Service Behavior for Improved Financial Risk Forecasting]] (81.5% similar)
- [[2025-09-23/A Comprehensive Performance Comparison of Traditional and Ensemble Machine Learning Models for Online Fraud Detection_20250923|A Comprehensive Performance Comparison of Traditional and Ensemble Machine Learning Models for Online Fraud Detection]] (81.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Gradient Boosting Machines|Gradient Boosting Machines]]
**ğŸ”— Specific Connectable**: [[keywords/DBSCAN Algorithm|DBSCAN Algorithm]]
**âš¡ Unique Technical**: [[keywords/Credit Default Prediction|Credit Default Prediction]], [[keywords/Boruta Feature Selection|Boruta Feature Selection]], [[keywords/SMOTE-Tomek|SMOTE-Tomek]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19408v1 Announce Type: new 
Abstract: This study examines credit default prediction by comparing three techniques, namely SMOTE, SMOTE-Tomek, and ADASYN, that are commonly used to address the class imbalance problem in credit default situations. Recognizing that credit default datasets are typically skewed, with defaulters comprising a much smaller proportion than non-defaulters, we began our analysis by evaluating machine learning (ML) models on the imbalanced data without any resampling to establish baseline performance. These baseline results provide a reference point for understanding the impact of subsequent balancing methods. In addition to traditional classifiers such as Naive Bayes and K-Nearest Neighbors (KNN), our study also explores the suitability of advanced ensemble boosting algorithms, including Extreme Gradient Boosting (XGBoost), AdaBoost, Gradient Boosting Machines (GBM), and Light GBM for credit default prediction using Boruta feature selection and DBSCAN-based outlier detection, both before and after resampling. A real-world credit default data set sourced from the University of Cleveland ML Repository was used to build ML classifiers, and their performances were tested. The criteria chosen to measure model performance are the area under the receiver operating characteristic curve (ROC-AUC), area under the precision-recall curve (PR-AUC), G-mean, and F1-scores. The results from this empirical study indicate that the Boruta+DBSCAN+SMOTE-Tomek+GBM classifier outperformed the other ML models (F1-score: 82.56%, G-mean: 82.98%, ROC-AUC: 90.90%, PR-AUC: 91.85%) in a credit default context. The findings establish a foundation for future progress in creating more resilient and adaptive credit default systems, which will be essential as credit-based transactions continue to rise worldwide.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” ì‹ ìš© ë¶ˆì´í–‰ ì˜ˆì¸¡ì—ì„œ í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ SMOTE, SMOTE-Tomek, ADASYN ê¸°ë²•ì„ ë¹„êµ ë¶„ì„í•©ë‹ˆë‹¤. ì´ˆê¸°ì—ëŠ” ë¶ˆê· í˜• ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì˜ ê¸°ë³¸ ì„±ëŠ¥ì„ í‰ê°€í•˜ì˜€ê³ , ì´í›„ Boruta íŠ¹ì§• ì„ íƒê³¼ DBSCAN ê¸°ë°˜ ì´ìƒì¹˜ íƒì§€ë¥¼ í†µí•´ ì„±ëŠ¥ì„ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤. íŠ¹íˆ, SMOTE-Tomekê³¼ GBMì„ ê²°í•©í•œ ëª¨ë¸ì´ ê°€ì¥ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë©°, F1-score 82.56%, G-mean 82.98%, ROC-AUC 90.90%, PR-AUC 91.85%ë¥¼ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” í–¥í›„ ë”ìš± ê°•ë ¥í•˜ê³  ì ì‘ì ì¸ ì‹ ìš© ë¶ˆì´í–‰ ì‹œìŠ¤í…œ ê°œë°œì— ê¸°ì—¬í•  ìˆ˜ ìˆëŠ” ê¸°ì´ˆë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì‹ ìš© ë¶ˆì´í–‰ ì˜ˆì¸¡ì—ì„œ í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ SMOTE, SMOTE-Tomek, ADASYN ê¸°ë²•ì„ ë¹„êµ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.
- 2. Boruta íŠ¹ì§• ì„ íƒê³¼ DBSCAN ê¸°ë°˜ ì´ìƒì¹˜ íƒì§€ë¥¼ í™œìš©í•˜ì—¬, ë‹¤ì–‘í•œ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í–ˆìŠµë‹ˆë‹¤.
- 3. ì‹¤í—˜ ê²°ê³¼, Boruta+DBSCAN+SMOTE-Tomek+GBM ë¶„ë¥˜ê¸°ê°€ ë‹¤ë¥¸ ëª¨ë¸ë“¤ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤ (F1-score: 82.56%, G-mean: 82.98%, ROC-AUC: 90.90%, PR-AUC: 91.85%).
- 4. ì´ ì—°êµ¬ëŠ” í–¥í›„ ë” ê²¬ê³ í•˜ê³  ì ì‘ë ¥ ìˆëŠ” ì‹ ìš© ë¶ˆì´í–‰ ì‹œìŠ¤í…œ ê°œë°œì˜ ê¸°ì´ˆë¥¼ ë§ˆë ¨í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-25 16:35:26*