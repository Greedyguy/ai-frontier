---
keywords:
  - Retrieval-Augmented Diagnosis
  - Multimodal Learning
  - Transformer
  - Contrastive Loss
  - Model Interpretability
category: cs.LG
publish_date: 2025-09-25
arxiv_id: 2509.19980
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T16:43:58.209408",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Retrieval-Augmented Diagnosis",
    "Multimodal Learning",
    "Transformer",
    "Contrastive Loss",
    "Model Interpretability"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Retrieval-Augmented Diagnosis": 0.8,
    "Multimodal Learning": 0.78,
    "Transformer": 0.72,
    "Contrastive Loss": 0.75,
    "Model Interpretability": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Retrieval-Augmented Diagnosis",
        "canonical": "Retrieval-Augmented Diagnosis",
        "aliases": [
          "RAD"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel framework specifically for clinical diagnosis, enhancing connectivity with retrieval-augmented methods.",
        "novelty_score": 0.85,
        "connectivity_score": 0.7,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "Multimodal Models",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal"
        ],
        "category": "specific_connectable",
        "rationale": "Links to the trending concept of integrating multiple data types, crucial for clinical diagnosis.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.75,
        "link_intent_score": 0.78
      },
      {
        "surface": "Transformer Decoder",
        "canonical": "Transformer",
        "aliases": [
          "Dual Transformer Decoder"
        ],
        "category": "broad_technical",
        "rationale": "Connects to the broad technical category of transformers, which are pivotal in modern AI models.",
        "novelty_score": 0.4,
        "connectivity_score": 0.85,
        "specificity_score": 0.65,
        "link_intent_score": 0.72
      },
      {
        "surface": "Guideline-Enhanced Contrastive Loss",
        "canonical": "Contrastive Loss",
        "aliases": [
          "Guideline-Enhanced Loss"
        ],
        "category": "unique_technical",
        "rationale": "A unique adaptation of contrastive loss tailored for clinical guidelines, enhancing specificity.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.75
      },
      {
        "surface": "Interpretability Criteria",
        "canonical": "Model Interpretability",
        "aliases": [
          "Interpretability Evaluation"
        ],
        "category": "evolved_concepts",
        "rationale": "Addresses the evolving need for interpretability in AI models, especially in clinical settings.",
        "novelty_score": 0.65,
        "connectivity_score": 0.78,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "clinical diagnosis",
      "medical knowledge",
      "state-of-the-art performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Retrieval-Augmented Diagnosis",
      "resolved_canonical": "Retrieval-Augmented Diagnosis",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.7,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Multimodal Models",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.75,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Transformer Decoder",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.85,
        "specificity": 0.65,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "Guideline-Enhanced Contrastive Loss",
      "resolved_canonical": "Contrastive Loss",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Interpretability Criteria",
      "resolved_canonical": "Model Interpretability",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.78,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# RAD: Towards Trustworthy Retrieval-Augmented Multi-modal Clinical Diagnosis

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19980.pdf)
**Category**: cs.LG
**Published**: 2025-09-25
**ArXiv ID**: [2509.19980](https://arxiv.org/abs/2509.19980)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-25/MACD_ Multi-Agent Clinical Diagnosis with Self-Learned Knowledge for LLM_20250925|MACD: Multi-Agent Clinical Diagnosis with Self-Learned Knowledge for LLM]] (85.7% similar)
- [[2025-09-22/Temperature-Driven Robust Disease Detection in Brain and Gastrointestinal Disorders via Context-Aware Adaptive Knowledge Distillation_20250922|Temperature-Driven Robust Disease Detection in Brain and Gastrointestinal Disorders via Context-Aware Adaptive Knowledge Distillation]] (84.9% similar)
- [[2025-09-24/Learning Contrastive Multimodal Fusion with Improved Modality Dropout for Disease Detection and Prediction_20250924|Learning Contrastive Multimodal Fusion with Improved Modality Dropout for Disease Detection and Prediction]] (84.1% similar)
- [[2025-09-24/Citrus-V_ Advancing Medical Foundation Models with Unified Medical Image Grounding for Clinical Reasoning_20250924|Citrus-V: Advancing Medical Foundation Models with Unified Medical Image Grounding for Clinical Reasoning]] (83.6% similar)
- [[2025-09-22/No Black Box Anymore_ Demystifying Clinical Predictive Modeling with Temporal-Feature Cross Attention Mechanism_20250922|No Black Box Anymore: Demystifying Clinical Predictive Modeling with Temporal-Feature Cross Attention Mechanism]] (83.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Transformer|Transformer]]
**ğŸ”— Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**âš¡ Unique Technical**: [[keywords/Retrieval-Augmented Diagnosis|Retrieval-Augmented Diagnosis]], [[keywords/Contrastive Loss|Contrastive Loss]]
**ğŸš€ Evolved Concepts**: [[keywords/Model Interpretability|Model Interpretability]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19980v1 Announce Type: new 
Abstract: Clinical diagnosis is a highly specialized discipline requiring both domain expertise and strict adherence to rigorous guidelines. While current AI-driven medical research predominantly focuses on knowledge graphs or natural text pretraining paradigms to incorporate medical knowledge, these approaches primarily rely on implicitly encoded knowledge within model parameters, neglecting task-specific knowledge required by diverse downstream tasks. To address this limitation, we propose Retrieval-Augmented Diagnosis (RAD), a novel framework that explicitly injects external knowledge into multimodal models directly on downstream tasks. Specifically, RAD operates through three key mechanisms: retrieval and refinement of disease-centered knowledge from multiple medical sources, a guideline-enhanced contrastive loss that constrains the latent distance between multi-modal features and guideline knowledge, and the dual transformer decoder that employs guidelines as queries to steer cross-modal fusion, aligning the models with clinical diagnostic workflows from guideline acquisition to feature extraction and decision-making. Moreover, recognizing the lack of quantitative evaluation of interpretability for multimodal diagnostic models, we introduce a set of criteria to assess the interpretability from both image and text perspectives. Extensive evaluations across four datasets with different anatomies demonstrate RAD's generalizability, achieving state-of-the-art performance. Furthermore, RAD enables the model to concentrate more precisely on abnormal regions and critical indicators, ensuring evidence-based, trustworthy diagnosis. Our code is available at https://github.com/tdlhl/RAD.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì„ìƒ ì§„ë‹¨ì„ ìœ„í•œ ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ì¸ Retrieval-Augmented Diagnosis (RAD)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ AI ì—°êµ¬ê°€ ëª¨ë¸ íŒŒë¼ë¯¸í„°ì— ì•”ë¬µì ìœ¼ë¡œ ë‚´ì¬ëœ ì§€ì‹ì— ì˜ì¡´í•˜ëŠ” ë°˜ë©´, RADëŠ” ì™¸ë¶€ ì§€ì‹ì„ ëª…ì‹œì ìœ¼ë¡œ ë‹¤ì¤‘ ëª¨ë‹¬ ëª¨ë¸ì— ì£¼ì…í•˜ì—¬ ë‹¤ì–‘í•œ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—…ì— í•„ìš”í•œ ê³¼ì œë³„ ì§€ì‹ì„ ë³´ê°•í•©ë‹ˆë‹¤. RADëŠ” ì§ˆë³‘ ì¤‘ì‹¬ì˜ ì§€ì‹ì„ ë‹¤ì–‘í•œ ì˜ë£Œ ì†ŒìŠ¤ì—ì„œ ê²€ìƒ‰ ë° ì •ì œí•˜ê³ , ê°€ì´ë“œë¼ì¸ì„ í™œìš©í•œ ëŒ€ì¡° ì†ì‹¤ì„ í†µí•´ ë‹¤ì¤‘ ëª¨ë‹¬ íŠ¹ì§•ê³¼ ê°€ì´ë“œë¼ì¸ ì§€ì‹ ê°„ì˜ ì ì¬ì  ê±°ë¦¬ë¥¼ ì œì•½í•˜ë©°, ë“€ì–¼ íŠ¸ëœìŠ¤í¬ë¨¸ ë””ì½”ë”ë¥¼ ì‚¬ìš©í•´ ê°€ì´ë“œë¼ì¸ì„ ì¿¼ë¦¬ë¡œ í™œìš©í•˜ì—¬ ì„ìƒ ì§„ë‹¨ ì›Œí¬í”Œë¡œìš°ì— ë§ì¶˜ êµì°¨ ëª¨ë‹¬ ìœµí•©ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ë˜í•œ, ë‹¤ì¤‘ ëª¨ë‹¬ ì§„ë‹¨ ëª¨ë¸ì˜ í•´ì„ ê°€ëŠ¥ì„±ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ê¸°ì¤€ì„ ì œì‹œí•˜ê³ , ë„¤ ê°€ì§€ ë°ì´í„°ì…‹ì—ì„œ RADì˜ ì¼ë°˜í™” ê°€ëŠ¥ì„±ê³¼ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ì…ì¦í•©ë‹ˆë‹¤. RADëŠ” ë¹„ì •ìƒ ì˜ì—­ê³¼ ì¤‘ìš”í•œ ì§€í‘œì— ì§‘ì¤‘í•˜ì—¬ ì¦ê±° ê¸°ë°˜ì˜ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì§„ë‹¨ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ì½”ë“œì™€ ìë£ŒëŠ” ê³µê°œë˜ì–´ ìˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. RADëŠ” ì™¸ë¶€ ì§€ì‹ì„ ëª…ì‹œì ìœ¼ë¡œ ì£¼ì…í•˜ì—¬ ë‹¤ì–‘í•œ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—…ì— ë§ì¶˜ ë‹¤ì¤‘ ëª¨ë‹¬ ëª¨ë¸ì„ ì œì•ˆí•©ë‹ˆë‹¤.
- 2. RADëŠ” ì§ˆë³‘ ì¤‘ì‹¬ì˜ ì§€ì‹ì„ ì—¬ëŸ¬ ì˜ë£Œ ì†ŒìŠ¤ë¡œë¶€í„° ê²€ìƒ‰ ë° ì •ì œí•˜ëŠ” ë©”ì»¤ë‹ˆì¦˜ì„ í¬í•¨í•©ë‹ˆë‹¤.
- 3. ê°€ì´ë“œë¼ì¸ì„ í™œìš©í•œ ëŒ€ì¡° ì†ì‹¤ì„ í†µí•´ ë‹¤ì¤‘ ëª¨ë‹¬ íŠ¹ì§•ê³¼ ê°€ì´ë“œë¼ì¸ ì§€ì‹ ê°„ì˜ ì ì¬ì  ê±°ë¦¬ë¥¼ ì œí•œí•©ë‹ˆë‹¤.
- 4. ì´ì¤‘ íŠ¸ëœìŠ¤í¬ë¨¸ ë””ì½”ë”ëŠ” ê°€ì´ë“œë¼ì¸ì„ ì¿¼ë¦¬ë¡œ ì‚¬ìš©í•˜ì—¬ êµì°¨ ëª¨ë‹¬ ìœµí•©ì„ ìœ ë„í•©ë‹ˆë‹¤.
- 5. RADëŠ” í•´ì„ ê°€ëŠ¥ì„±ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ê¸°ì¤€ì„ ë„ì…í•˜ì—¬ ì´ë¯¸ì§€ ë° í…ìŠ¤íŠ¸ ê´€ì ì—ì„œì˜ í•´ì„ ê°€ëŠ¥ì„±ì„ í‰ê°€í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-25 16:43:58*