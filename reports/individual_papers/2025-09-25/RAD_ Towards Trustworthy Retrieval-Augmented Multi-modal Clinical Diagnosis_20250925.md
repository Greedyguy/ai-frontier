---
keywords:
  - Retrieval-Augmented Diagnosis
  - Multimodal Learning
  - Transformer
  - Contrastive Loss
  - Model Interpretability
category: cs.LG
publish_date: 2025-09-25
arxiv_id: 2509.19980
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T16:43:58.209408",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Retrieval-Augmented Diagnosis",
    "Multimodal Learning",
    "Transformer",
    "Contrastive Loss",
    "Model Interpretability"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Retrieval-Augmented Diagnosis": 0.8,
    "Multimodal Learning": 0.78,
    "Transformer": 0.72,
    "Contrastive Loss": 0.75,
    "Model Interpretability": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Retrieval-Augmented Diagnosis",
        "canonical": "Retrieval-Augmented Diagnosis",
        "aliases": [
          "RAD"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel framework specifically for clinical diagnosis, enhancing connectivity with retrieval-augmented methods.",
        "novelty_score": 0.85,
        "connectivity_score": 0.7,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "Multimodal Models",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal"
        ],
        "category": "specific_connectable",
        "rationale": "Links to the trending concept of integrating multiple data types, crucial for clinical diagnosis.",
        "novelty_score": 0.55,
        "connectivity_score": 0.88,
        "specificity_score": 0.75,
        "link_intent_score": 0.78
      },
      {
        "surface": "Transformer Decoder",
        "canonical": "Transformer",
        "aliases": [
          "Dual Transformer Decoder"
        ],
        "category": "broad_technical",
        "rationale": "Connects to the broad technical category of transformers, which are pivotal in modern AI models.",
        "novelty_score": 0.4,
        "connectivity_score": 0.85,
        "specificity_score": 0.65,
        "link_intent_score": 0.72
      },
      {
        "surface": "Guideline-Enhanced Contrastive Loss",
        "canonical": "Contrastive Loss",
        "aliases": [
          "Guideline-Enhanced Loss"
        ],
        "category": "unique_technical",
        "rationale": "A unique adaptation of contrastive loss tailored for clinical guidelines, enhancing specificity.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.75
      },
      {
        "surface": "Interpretability Criteria",
        "canonical": "Model Interpretability",
        "aliases": [
          "Interpretability Evaluation"
        ],
        "category": "evolved_concepts",
        "rationale": "Addresses the evolving need for interpretability in AI models, especially in clinical settings.",
        "novelty_score": 0.65,
        "connectivity_score": 0.78,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "clinical diagnosis",
      "medical knowledge",
      "state-of-the-art performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Retrieval-Augmented Diagnosis",
      "resolved_canonical": "Retrieval-Augmented Diagnosis",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.7,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Multimodal Models",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.88,
        "specificity": 0.75,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Transformer Decoder",
      "resolved_canonical": "Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.85,
        "specificity": 0.65,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "Guideline-Enhanced Contrastive Loss",
      "resolved_canonical": "Contrastive Loss",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Interpretability Criteria",
      "resolved_canonical": "Model Interpretability",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.78,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# RAD: Towards Trustworthy Retrieval-Augmented Multi-modal Clinical Diagnosis

## 📋 메타데이터

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19980.pdf)
**Category**: cs.LG
**Published**: 2025-09-25
**ArXiv ID**: [2509.19980](https://arxiv.org/abs/2509.19980)

## 🔗 유사한 논문
- [[2025-09-25/MACD_ Multi-Agent Clinical Diagnosis with Self-Learned Knowledge for LLM_20250925|MACD: Multi-Agent Clinical Diagnosis with Self-Learned Knowledge for LLM]] (85.7% similar)
- [[2025-09-22/Temperature-Driven Robust Disease Detection in Brain and Gastrointestinal Disorders via Context-Aware Adaptive Knowledge Distillation_20250922|Temperature-Driven Robust Disease Detection in Brain and Gastrointestinal Disorders via Context-Aware Adaptive Knowledge Distillation]] (84.9% similar)
- [[2025-09-24/Learning Contrastive Multimodal Fusion with Improved Modality Dropout for Disease Detection and Prediction_20250924|Learning Contrastive Multimodal Fusion with Improved Modality Dropout for Disease Detection and Prediction]] (84.1% similar)
- [[2025-09-24/Citrus-V_ Advancing Medical Foundation Models with Unified Medical Image Grounding for Clinical Reasoning_20250924|Citrus-V: Advancing Medical Foundation Models with Unified Medical Image Grounding for Clinical Reasoning]] (83.6% similar)
- [[2025-09-22/No Black Box Anymore_ Demystifying Clinical Predictive Modeling with Temporal-Feature Cross Attention Mechanism_20250922|No Black Box Anymore: Demystifying Clinical Predictive Modeling with Temporal-Feature Cross Attention Mechanism]] (83.5% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Transformer|Transformer]]
**🔗 Specific Connectable**: [[keywords/Multimodal Learning|Multimodal Learning]]
**⚡ Unique Technical**: [[keywords/Retrieval-Augmented Diagnosis|Retrieval-Augmented Diagnosis]], [[keywords/Contrastive Loss|Contrastive Loss]]
**🚀 Evolved Concepts**: [[keywords/Model Interpretability|Model Interpretability]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.19980v1 Announce Type: new 
Abstract: Clinical diagnosis is a highly specialized discipline requiring both domain expertise and strict adherence to rigorous guidelines. While current AI-driven medical research predominantly focuses on knowledge graphs or natural text pretraining paradigms to incorporate medical knowledge, these approaches primarily rely on implicitly encoded knowledge within model parameters, neglecting task-specific knowledge required by diverse downstream tasks. To address this limitation, we propose Retrieval-Augmented Diagnosis (RAD), a novel framework that explicitly injects external knowledge into multimodal models directly on downstream tasks. Specifically, RAD operates through three key mechanisms: retrieval and refinement of disease-centered knowledge from multiple medical sources, a guideline-enhanced contrastive loss that constrains the latent distance between multi-modal features and guideline knowledge, and the dual transformer decoder that employs guidelines as queries to steer cross-modal fusion, aligning the models with clinical diagnostic workflows from guideline acquisition to feature extraction and decision-making. Moreover, recognizing the lack of quantitative evaluation of interpretability for multimodal diagnostic models, we introduce a set of criteria to assess the interpretability from both image and text perspectives. Extensive evaluations across four datasets with different anatomies demonstrate RAD's generalizability, achieving state-of-the-art performance. Furthermore, RAD enables the model to concentrate more precisely on abnormal regions and critical indicators, ensuring evidence-based, trustworthy diagnosis. Our code is available at https://github.com/tdlhl/RAD.

## 📝 요약

이 논문은 임상 진단을 위한 새로운 프레임워크인 Retrieval-Augmented Diagnosis (RAD)를 제안합니다. 기존 AI 연구가 모델 파라미터에 암묵적으로 내재된 지식에 의존하는 반면, RAD는 외부 지식을 명시적으로 다중 모달 모델에 주입하여 다양한 다운스트림 작업에 필요한 과제별 지식을 보강합니다. RAD는 질병 중심의 지식을 다양한 의료 소스에서 검색 및 정제하고, 가이드라인을 활용한 대조 손실을 통해 다중 모달 특징과 가이드라인 지식 간의 잠재적 거리를 제약하며, 듀얼 트랜스포머 디코더를 사용해 가이드라인을 쿼리로 활용하여 임상 진단 워크플로우에 맞춘 교차 모달 융합을 수행합니다. 또한, 다중 모달 진단 모델의 해석 가능성을 평가하기 위한 기준을 제시하고, 네 가지 데이터셋에서 RAD의 일반화 가능성과 최첨단 성능을 입증합니다. RAD는 비정상 영역과 중요한 지표에 집중하여 증거 기반의 신뢰할 수 있는 진단을 가능하게 합니다. 코드와 자료는 공개되어 있습니다.

## 🎯 주요 포인트

- 1. RAD는 외부 지식을 명시적으로 주입하여 다양한 다운스트림 작업에 맞춘 다중 모달 모델을 제안합니다.
- 2. RAD는 질병 중심의 지식을 여러 의료 소스로부터 검색 및 정제하는 메커니즘을 포함합니다.
- 3. 가이드라인을 활용한 대조 손실을 통해 다중 모달 특징과 가이드라인 지식 간의 잠재적 거리를 제한합니다.
- 4. 이중 트랜스포머 디코더는 가이드라인을 쿼리로 사용하여 교차 모달 융합을 유도합니다.
- 5. RAD는 해석 가능성을 평가하기 위한 기준을 도입하여 이미지 및 텍스트 관점에서의 해석 가능성을 평가합니다.


---

*Generated on 2025-09-25 16:43:58*