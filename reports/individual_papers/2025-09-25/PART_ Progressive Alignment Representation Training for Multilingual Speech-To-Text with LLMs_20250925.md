---
keywords:
  - Large Language Model
  - Speech Large Models
  - Multilingual Speech Modality Alignment
  - Progressive Alignment Representation Training
  - Multilingual Understanding
category: cs.CL
publish_date: 2025-09-25
arxiv_id: 2509.19745
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-26T08:44:51.483821",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Speech Large Models",
    "Multilingual Speech Modality Alignment",
    "Progressive Alignment Representation Training",
    "Multilingual Understanding"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Speech Large Models": 0.7,
    "Multilingual Speech Modality Alignment": 0.75,
    "Progressive Alignment Representation Training": 0.8,
    "Multilingual Understanding": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are central to the paper's methodology and connect to a wide range of NLP tasks.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "Speech Large Models",
        "canonical": "Speech Large Models",
        "aliases": [
          "SLMs"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a new concept of large models specifically for speech, which is pivotal for the paper's focus.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      },
      {
        "surface": "Multilingual Speech Modality Alignment",
        "canonical": "Multilingual Speech Modality Alignment",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This is a unique technical term that encapsulates the paper's main contribution.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.75
      },
      {
        "surface": "Progressive Alignment Representation Training",
        "canonical": "Progressive Alignment Representation Training",
        "aliases": [
          "PART"
        ],
        "category": "unique_technical",
        "rationale": "This is the novel method introduced by the paper, essential for understanding its contribution.",
        "novelty_score": 0.9,
        "connectivity_score": 0.7,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "Multilingual Understanding",
        "canonical": "Multilingual Understanding",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Key to the paper's exploration of cross-language tasks, enhancing connectivity with multilingual NLP research.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Speech Large Models",
      "resolved_canonical": "Speech Large Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Multilingual Speech Modality Alignment",
      "resolved_canonical": "Multilingual Speech Modality Alignment",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Progressive Alignment Representation Training",
      "resolved_canonical": "Progressive Alignment Representation Training",
      "decision": "linked",
      "scores": {
        "novelty": 0.9,
        "connectivity": 0.7,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Multilingual Understanding",
      "resolved_canonical": "Multilingual Understanding",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# PART: Progressive Alignment Representation Training for Multilingual Speech-To-Text with LLMs

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19745.pdf)
**Category**: cs.CL
**Published**: 2025-09-25
**ArXiv ID**: [2509.19745](https://arxiv.org/abs/2509.19745)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/Decoupled Proxy Alignment_ Mitigating Language Prior Conflict for Multimodal Alignment in MLLM_20250919|Decoupled Proxy Alignment: Mitigating Language Prior Conflict for Multimodal Alignment in MLLM]] (87.3% similar)
- [[2025-09-22/Exploring Polyglot Harmony_ On Multilingual Data Allocation for Large Language Models Pretraining_20250922|Exploring Polyglot Harmony: On Multilingual Data Allocation for Large Language Models Pretraining]] (86.0% similar)
- [[2025-09-25/Advancing Speech Summarization in Multi-modal LLMs with Reinforcement Learning_20250925|Advancing Speech Summarization in Multi-modal LLMs with Reinforcement Learning]] (85.7% similar)
- [[2025-09-23/Probabilistic Token Alignment for Large Language Model Fusion_20250923|Probabilistic Token Alignment for Large Language Model Fusion]] (85.2% similar)
- [[2025-09-24/Explore the Reinforcement Learning for the LLM based ASR and TTS system_20250924|Explore the Reinforcement Learning for the LLM based ASR and TTS system]] (85.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Multilingual Understanding|Multilingual Understanding]]
**âš¡ Unique Technical**: [[keywords/Speech Large Models|Speech Large Models]], [[keywords/Multilingual Speech Modality Alignment|Multilingual Speech Modality Alignment]], [[keywords/Progressive Alignment Representation Training|Progressive Alignment Representation Training]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19745v1 Announce Type: new 
Abstract: Large language models (LLMs) have expanded from text to speech, giving rise to Speech Large Models (SLMs) that support recognition, translation, and synthesis. A key challenge is aligning speech and text representations, which becomes harder in multilingual settings. Existing methods often freeze LLM parameters and train encoders on multilingual data, but this forces cross-language convergence and limits performance. We introduce Progressive Alignment Representation Training (PART), a multi-stage and multi-task framework that separates within-language from cross-language alignment. During cross-language training, LLM parameters are dynamically activated, and text-based tasks are later introduced to enhance multilingual understanding. Experiments on CommonVoice 15, Fleurs, Wenetspeech, and CoVoST2 show that PART surpasses conventional approaches, with analysis confirming its ability to balance language-specific distinctions and cross-language generalization. These results demonstrate PART's effectiveness and generality for multilingual speech modality alignment.

## ğŸ“ ìš”ì•½

ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì´ í…ìŠ¤íŠ¸ì—ì„œ ìŒì„±ìœ¼ë¡œ í™•ì¥ë˜ë©´ì„œ ìŒì„± ì¸ì‹, ë²ˆì—­, í•©ì„±ì„ ì§€ì›í•˜ëŠ” ëŒ€í˜• ìŒì„± ëª¨ë¸(SLM)ì´ ë“±ì¥í–ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë‹¤êµ­ì–´ í™˜ê²½ì—ì„œ ìŒì„±ê³¼ í…ìŠ¤íŠ¸ í‘œí˜„ì„ ì •ë ¬í•˜ëŠ” ê²ƒì€ ì–´ë ¤ìš´ ê³¼ì œì…ë‹ˆë‹¤. ê¸°ì¡´ ë°©ë²•ì€ LLMì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ê³ ì •í•˜ê³  ë‹¤êµ­ì–´ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¸ì½”ë”ë¥¼ í›ˆë ¨í•˜ì§€ë§Œ, ì´ëŠ” ì–¸ì–´ ê°„ ìˆ˜ë ´ì„ ê°•ìš”í•˜ì—¬ ì„±ëŠ¥ì„ ì œí•œí•©ë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” ì–¸ì–´ ë‚´ ì •ë ¬ê³¼ ì–¸ì–´ ê°„ ì •ë ¬ì„ ë¶„ë¦¬í•˜ëŠ” ë‹¤ë‹¨ê³„, ë‹¤ê³¼ì œ í”„ë ˆì„ì›Œí¬ì¸ Progressive Alignment Representation Training (PART)ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì–¸ì–´ ê°„ í›ˆë ¨ ì¤‘ì—ëŠ” LLM ë§¤ê°œë³€ìˆ˜ê°€ ë™ì ìœ¼ë¡œ í™œì„±í™”ë˜ë©°, ì´í›„ í…ìŠ¤íŠ¸ ê¸°ë°˜ ê³¼ì œë¥¼ ë„ì…í•˜ì—¬ ë‹¤êµ­ì–´ ì´í•´ë¥¼ ê°•í™”í•©ë‹ˆë‹¤. CommonVoice 15, Fleurs, Wenetspeech, CoVoST2ì—ì„œì˜ ì‹¤í—˜ ê²°ê³¼, PARTëŠ” ê¸°ì¡´ ë°©ë²•ì„ ëŠ¥ê°€í•˜ë©°, ì–¸ì–´ë³„ êµ¬ë³„ê³¼ ì–¸ì–´ ê°„ ì¼ë°˜í™”ë¥¼ ê· í˜• ìˆê²Œ ë‹¬ì„±í•¨ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ê²°ê³¼ëŠ” PARTì˜ ë‹¤êµ­ì–´ ìŒì„± ì •ë ¬ì— ëŒ€í•œ íš¨ê³¼ì„±ê³¼ ì¼ë°˜ì„±ì„ ì…ì¦í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì´ ìŒì„± ì¸ì‹, ë²ˆì—­, í•©ì„±ì„ ì§€ì›í•˜ëŠ” ëŒ€í˜• ìŒì„± ëª¨ë¸(SLM)ë¡œ í™•ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.
- 2. ë‹¤êµ­ì–´ í™˜ê²½ì—ì„œ ìŒì„±ê³¼ í…ìŠ¤íŠ¸ í‘œí˜„ì„ ì •ë ¬í•˜ëŠ” ê²ƒì´ ì£¼ìš” ê³¼ì œë¡œ ëŒ€ë‘ë˜ì—ˆìŠµë‹ˆë‹¤.
- 3. ê¸°ì¡´ ë°©ë²•ì€ LLM ë§¤ê°œë³€ìˆ˜ë¥¼ ê³ ì •í•˜ê³  ë‹¤êµ­ì–´ ë°ì´í„°ë¡œ ì¸ì½”ë”ë¥¼ í›ˆë ¨í•˜ì§€ë§Œ, ì´ëŠ” ì–¸ì–´ ê°„ ìˆ˜ë ´ì„ ê°•ìš”í•˜ì—¬ ì„±ëŠ¥ì„ ì œí•œí•©ë‹ˆë‹¤.
- 4. ìš°ë¦¬ëŠ” ì–¸ì–´ ë‚´ ì •ë ¬ê³¼ ì–¸ì–´ ê°„ ì •ë ¬ì„ ë¶„ë¦¬í•˜ëŠ” Progressive Alignment Representation Training (PART)ì„ ë„ì…í–ˆìŠµë‹ˆë‹¤.
- 5. ì‹¤í—˜ ê²°ê³¼, PARTëŠ” ê¸°ì¡´ ì ‘ê·¼ ë°©ì‹ì„ ëŠ¥ê°€í•˜ë©°, ì–¸ì–´ë³„ ì°¨ë³„ì„±ê³¼ ì–¸ì–´ ê°„ ì¼ë°˜í™”ë¥¼ ê· í˜• ìˆê²Œ ìœ ì§€í•˜ëŠ” ëŠ¥ë ¥ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-26 08:44:51*