---
keywords:
  - Large Language Model
  - Information Gain
  - Bayesian Method
  - Entropy-Based Method
  - ConceptNet
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2509.19593
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T15:39:40.355498",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Information Gain",
    "Bayesian Method",
    "Entropy-Based Method",
    "ConceptNet"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Information Gain": 0.78,
    "Bayesian Method": 0.72,
    "Entropy-Based Method": 0.7,
    "ConceptNet": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Large Language Models"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's focus on evaluating question-asking capabilities.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Information Gain",
        "canonical": "Information Gain",
        "aliases": [
          "IG"
        ],
        "category": "unique_technical",
        "rationale": "Key metric used for evaluating question quality in the study.",
        "novelty_score": 0.65,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Bayesian Method",
        "canonical": "Bayesian Method",
        "aliases": [
          "Bayesian Approach"
        ],
        "category": "unique_technical",
        "rationale": "Describes a specific technique for tracking belief updates in the study.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.72
      },
      {
        "surface": "Entropy-Based Method",
        "canonical": "Entropy-Based Method",
        "aliases": [
          "Entropy Method"
        ],
        "category": "unique_technical",
        "rationale": "Represents a distinct approach for filtering candidates in the research.",
        "novelty_score": 0.68,
        "connectivity_score": 0.65,
        "specificity_score": 0.82,
        "link_intent_score": 0.7
      },
      {
        "surface": "ConceptNet",
        "canonical": "ConceptNet",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Used as a resource for filtering candidates, relevant for linking to semantic networks.",
        "novelty_score": 0.5,
        "connectivity_score": 0.78,
        "specificity_score": 0.75,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "protocol",
      "Oracle",
      "Guesser",
      "game length",
      "efficiency"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Information Gain",
      "resolved_canonical": "Information Gain",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Bayesian Method",
      "resolved_canonical": "Bayesian Method",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "Entropy-Based Method",
      "resolved_canonical": "Entropy-Based Method",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.65,
        "specificity": 0.82,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "ConceptNet",
      "resolved_canonical": "ConceptNet",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.78,
        "specificity": 0.75,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# GuessingGame: Measuring the Informativeness of Open-Ended Questions in Large Language Models

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19593.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2509.19593](https://arxiv.org/abs/2509.19593)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/LLMsPark_ A Benchmark for Evaluating Large Language Models in Strategic Gaming Contexts_20250923|LLMsPark: A Benchmark for Evaluating Large Language Models in Strategic Gaming Contexts]] (87.1% similar)
- [[2025-09-24/Triangulating LLM Progress through Benchmarks, Games, and Cognitive Tests_20250924|Triangulating LLM Progress through Benchmarks, Games, and Cognitive Tests]] (85.1% similar)
- [[2025-09-23/Probing LLM World Models_ Enhancing Guesstimation with Wisdom of Crowds Decoding_20250923|Probing LLM World Models: Enhancing Guesstimation with Wisdom of Crowds Decoding]] (84.9% similar)
- [[2025-09-25/Cognitive Load Limits in Large Language Models_ Benchmarking Multi-Hop Reasoning_20250925|Cognitive Load Limits in Large Language Models: Benchmarking Multi-Hop Reasoning]] (84.6% similar)
- [[2025-09-22/IGD_ Token Decisiveness Modeling via Information Gain in LLMs for Personalized Recommendation_20250922|IGD: Token Decisiveness Modeling via Information Gain in LLMs for Personalized Recommendation]] (84.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/ConceptNet|ConceptNet]]
**âš¡ Unique Technical**: [[keywords/Information Gain|Information Gain]], [[keywords/Bayesian Method|Bayesian Method]], [[keywords/Entropy-Based Method|Entropy-Based Method]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19593v1 Announce Type: cross 
Abstract: We introduce GuessingGame, a protocol for evaluating large language models (LLMs) as strategic question-askers in open-ended, open-domain settings. A Guesser LLM identifies a hidden object by posing free-form questions to an Oracle without predefined choices or candidate lists. To measure question quality, we propose two information gain (IG) metrics: a Bayesian method that tracks belief updates over semantic concepts using LLM-scored relevance, and an entropy-based method that filters candidates via ConceptNet. Both metrics are model-agnostic and support post hoc analysis. Across 858 games with multiple models and prompting strategies, higher IG strongly predicts efficiency: a one-standard-deviation IG increase reduces expected game length by 43\%. Prompting constraints guided by IG, such as enforcing question diversity, enable weaker models to significantly improve performance. These results show that question-asking in LLMs is both measurable and improvable, and crucial for interactive reasoning.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì „ëµì  ì§ˆë¬¸ ëŠ¥ë ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ GuessingGame í”„ë¡œí† ì½œì„ ì†Œê°œí•©ë‹ˆë‹¤. Guesser LLMì€ Oracleì—ê²Œ ììœ  í˜•ì‹ì˜ ì§ˆë¬¸ì„ í†µí•´ ìˆ¨ê²¨ì§„ ê°ì²´ë¥¼ ì‹ë³„í•©ë‹ˆë‹¤. ì§ˆë¬¸ì˜ ì§ˆì„ ì¸¡ì •í•˜ê¸° ìœ„í•´ ë‘ ê°€ì§€ ì •ë³´ ì´ë“(IG) ì§€í‘œë¥¼ ì œì•ˆí•©ë‹ˆë‹¤: LLMì´ í‰ê°€í•œ ê´€ë ¨ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ë² ì´ì§€ì•ˆ ë°©ë²•ê³¼ ConceptNetì„ í™œìš©í•œ ì—”íŠ¸ë¡œí”¼ ê¸°ë°˜ ë°©ë²•ì…ë‹ˆë‹¤. ë‘ ì§€í‘œ ëª¨ë‘ ëª¨ë¸ì— êµ¬ì• ë°›ì§€ ì•Šìœ¼ë©° ì‚¬í›„ ë¶„ì„ì„ ì§€ì›í•©ë‹ˆë‹¤. 858ê°œì˜ ê²Œì„ ì‹¤í—˜ì—ì„œ IGê°€ ë†’ì„ìˆ˜ë¡ íš¨ìœ¨ì„±ì´ ì¦ê°€í–ˆìœ¼ë©°, IGê°€ í•œ í‘œì¤€í¸ì°¨ ì¦ê°€í•  ë•Œ ì˜ˆìƒ ê²Œì„ ê¸¸ì´ê°€ 43% ê°ì†Œí–ˆìŠµë‹ˆë‹¤. IGì— ê¸°ë°˜í•œ ì§ˆë¬¸ ë‹¤ì–‘ì„± ë“±ì˜ ì œì•½ì€ ì•½í•œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤. ì´ ê²°ê³¼ëŠ” LLMì˜ ì§ˆë¬¸ ëŠ¥ë ¥ì´ ì¸¡ì • ê°€ëŠ¥í•˜ê³  ê°œì„  ê°€ëŠ¥í•˜ë©°, ìƒí˜¸ì‘ìš©ì  ì¶”ë¡ ì— ì¤‘ìš”í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. GuessingGameì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì „ëµì  ì§ˆë¬¸ ëŠ¥ë ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ í”„ë¡œí† ì½œë¡œ, ììœ í˜• ì§ˆë¬¸ì„ í†µí•´ ìˆ¨ê²¨ì§„ ê°ì²´ë¥¼ ì‹ë³„í•©ë‹ˆë‹¤.
- 2. ì§ˆë¬¸ì˜ ì§ˆì„ ì¸¡ì •í•˜ê¸° ìœ„í•´ ë‘ ê°€ì§€ ì •ë³´ ì´ë“(IG) ì§€í‘œë¥¼ ì œì•ˆí•˜ë©°, ì´ëŠ” ë² ì´ì§€ì•ˆ ë°©ë²•ê³¼ ì—”íŠ¸ë¡œí”¼ ê¸°ë°˜ ë°©ë²•ì„ í¬í•¨í•©ë‹ˆë‹¤.
- 3. ì •ë³´ ì´ë“(IG)ì´ ë†’ì„ìˆ˜ë¡ ê²Œì„ì˜ íš¨ìœ¨ì„±ì´ ì¦ê°€í•˜ë©°, í‘œì¤€ í¸ì°¨ê°€ 1 ì¦ê°€í•  ë•Œ ì˜ˆìƒ ê²Œì„ ê¸¸ì´ê°€ 43% ê°ì†Œí•©ë‹ˆë‹¤.
- 4. IGì— ì˜í•´ ì•ˆë‚´ë˜ëŠ” í”„ë¡¬í”„íŠ¸ ì œì•½, ì˜ˆë¥¼ ë“¤ì–´ ì§ˆë¬¸ ë‹¤ì–‘ì„± ê°•ì œëŠ” ì•½í•œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
- 5. LLMì˜ ì§ˆë¬¸ ëŠ¥ë ¥ì€ ì¸¡ì • ê°€ëŠ¥í•˜ê³  ê°œì„  ê°€ëŠ¥í•˜ë©°, ìƒí˜¸ì‘ìš©ì  ì¶”ë¡ ì— ìˆì–´ ì¤‘ìš”í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-25 15:39:40*