---
keywords:
  - Tokenization Parity
  - Information Parity
  - Large Language Model
  - Dialect Classification
  - Extractive Question Answering
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2509.20045
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T15:56:52.625933",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Tokenization Parity",
    "Information Parity",
    "Large Language Model",
    "Dialect Classification",
    "Extractive Question Answering"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Tokenization Parity": 0.78,
    "Information Parity": 0.75,
    "Large Language Model": 0.8,
    "Dialect Classification": 0.77,
    "Extractive Question Answering": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Tokenization Parity",
        "canonical": "Tokenization Parity",
        "aliases": [
          "TP"
        ],
        "category": "unique_technical",
        "rationale": "Tokenization Parity is a novel metric introduced in the paper, crucial for understanding representational biases in multilingual models.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.88,
        "link_intent_score": 0.78
      },
      {
        "surface": "Information Parity",
        "canonical": "Information Parity",
        "aliases": [
          "IP"
        ],
        "category": "unique_technical",
        "rationale": "Information Parity is a new concept that helps in analyzing semantic task performance in multilingual models.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.75
      },
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are central to the study and provide a basis for comparing different model architectures.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Dialect Classification",
        "canonical": "Dialect Classification",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "Dialect Classification is a specific task that highlights the challenges of linguistic variation in NLP.",
        "novelty_score": 0.7,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      },
      {
        "surface": "Extractive Question Answering",
        "canonical": "Extractive Question Answering",
        "aliases": [
          "Extractive QA"
        ],
        "category": "specific_connectable",
        "rationale": "Extractive Question Answering is a task that relies on syntactic and morphological cues, relevant to the study's findings.",
        "novelty_score": 0.65,
        "connectivity_score": 0.78,
        "specificity_score": 0.82,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "performance",
      "method",
      "analysis"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Tokenization Parity",
      "resolved_canonical": "Tokenization Parity",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.88,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Information Parity",
      "resolved_canonical": "Information Parity",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Dialect Classification",
      "resolved_canonical": "Dialect Classification",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Extractive Question Answering",
      "resolved_canonical": "Extractive Question Answering",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.78,
        "specificity": 0.82,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Tokenization and Representation Biases in Multilingual Models on Dialectal NLP Tasks

## 📋 메타데이터

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.20045.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2509.20045](https://arxiv.org/abs/2509.20045)

## 🔗 유사한 논문
- [[2025-09-24/Beyond the Leaderboard_ Understanding Performance Disparities in Large Language Models via Model Diffing_20250924|Beyond the Leaderboard: Understanding Performance Disparities in Large Language Models via Model Diffing]] (85.5% similar)
- [[2025-09-22/The Effect of Language Diversity When Fine-Tuning Large Language Models for Translation_20250922|The Effect of Language Diversity When Fine-Tuning Large Language Models for Translation]] (85.3% similar)
- [[2025-09-22/Benchmarking Debiasing Methods for LLM-based Parameter Estimates_20250922|Benchmarking Debiasing Methods for LLM-based Parameter Estimates]] (85.1% similar)
- [[2025-09-22/Enhancing LLM Language Adaption through Cross-lingual In-Context Pre-training_20250922|Enhancing LLM Language Adaption through Cross-lingual In-Context Pre-training]] (85.1% similar)
- [[2025-09-24/Anything Goes? A Crosslinguistic Study of (Im)possible Language Learning in LMs_20250924|Anything Goes? A Crosslinguistic Study of (Im)possible Language Learning in LMs]] (84.8% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**🔗 Specific Connectable**: [[keywords/Dialect Classification|Dialect Classification]], [[keywords/Extractive Question Answering|Extractive Question Answering]]
**⚡ Unique Technical**: [[keywords/Tokenization Parity|Tokenization Parity]], [[keywords/Information Parity|Information Parity]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.20045v1 Announce Type: cross 
Abstract: Dialectal data are characterized by linguistic variation that appears small to humans but has a significant impact on the performance of models. This dialect gap has been related to various factors (e.g., data size, economic and social factors) whose impact, however, turns out to be inconsistent. In this work, we investigate factors impacting the model performance more directly: we correlate Tokenization Parity (TP) and Information Parity (IP), as measures of representational biases in pre-trained multilingual models, with the downstream performance. We compare state-of-the-art decoder-only LLMs with encoder-based models across three tasks: dialect classification, topic classification, and extractive question answering, controlling for varying scripts (Latin vs. non-Latin) and resource availability (high vs. low). Our analysis reveals that TP is a better predictor of the performance on tasks reliant on syntactic and morphological cues (e.g., extractive QA), while IP better predicts performance in semantic tasks (e.g., topic classification). Complementary analyses, including tokenizer behavior, vocabulary coverage, and qualitative insights, reveal that the language support claims of LLMs often might mask deeper mismatches at the script or token level.

## 📝 요약

이 논문은 방언 데이터의 언어적 변이가 모델 성능에 미치는 영향을 조사합니다. 연구는 토큰화 균형(TP)과 정보 균형(IP)을 다국어 모델의 표현적 편향 측정으로 사용하여, 이들이 다운스트림 성능과 어떻게 상관관계가 있는지를 분석합니다. 디코더 전용 LLM과 인코더 기반 모델을 방언 분류, 주제 분류, 추출형 질문 응답 등 세 가지 작업에서 비교했습니다. 분석 결과, TP는 구문 및 형태론적 단서에 의존하는 작업(예: 추출형 QA)에서 성능을 예측하는 데 더 효과적이며, IP는 의미적 작업(예: 주제 분류)에서 성능 예측에 더 유리하다는 것을 발견했습니다. 추가 분석을 통해 LLM의 언어 지원 주장이 스크립트나 토큰 수준에서의 불일치를 감출 수 있음을 제시합니다.

## 🎯 주요 포인트

- 1. 방언 데이터는 인간에게는 미세하게 보이지만 모델 성능에 큰 영향을 미친다.
- 2. Tokenization Parity(TP)와 Information Parity(IP)는 다국어 모델의 표현 편향을 측정하며, 다운스트림 성능과 상관관계를 가진다.
- 3. TP는 구문 및 형태론적 단서에 의존하는 작업의 성능을 예측하는 데 더 효과적이다.
- 4. IP는 의미론적 작업의 성능을 예측하는 데 더 효과적이다.
- 5. LLM의 언어 지원 주장은 스크립트나 토큰 수준에서의 불일치를 가릴 수 있다.


---

*Generated on 2025-09-25 15:56:52*