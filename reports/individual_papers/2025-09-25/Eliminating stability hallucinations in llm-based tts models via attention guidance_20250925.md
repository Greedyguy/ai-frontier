---
keywords:
  - Stability Hallucinations
  - Attention Mechanism
  - Optimal Alignment Score
  - Viterbi Algorithm
  - Chain-of-Thought
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2509.19852
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T15:51:27.803809",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Stability Hallucinations",
    "Attention Mechanism",
    "Optimal Alignment Score",
    "Viterbi Algorithm",
    "Chain-of-Thought"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Stability Hallucinations": 0.78,
    "Attention Mechanism": 0.85,
    "Optimal Alignment Score": 0.82,
    "Viterbi Algorithm": 0.7,
    "Chain-of-Thought": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "stability hallucinations",
        "canonical": "Stability Hallucinations",
        "aliases": [
          "repetitive speech",
          "omitted speech"
        ],
        "category": "unique_technical",
        "rationale": "This term is central to the paper's focus on improving TTS models and represents a specific challenge in the field.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "attention mechanism",
        "canonical": "Attention Mechanism",
        "aliases": [
          "attention"
        ],
        "category": "specific_connectable",
        "rationale": "Attention mechanisms are crucial for improving model performance and are widely studied in related fields.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Optimal Alignment Score",
        "canonical": "Optimal Alignment Score",
        "aliases": [
          "OAS"
        ],
        "category": "unique_technical",
        "rationale": "Introduced in this paper, OAS is a novel metric for evaluating text-speech alignment, enhancing model training.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.88,
        "link_intent_score": 0.82
      },
      {
        "surface": "Viterbi algorithm",
        "canonical": "Viterbi Algorithm",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "The Viterbi algorithm is a well-known method used for sequence alignment, relevant to the paper's methodology.",
        "novelty_score": 0.4,
        "connectivity_score": 0.75,
        "specificity_score": 0.65,
        "link_intent_score": 0.7
      },
      {
        "surface": "chain-of-thought",
        "canonical": "Chain-of-Thought",
        "aliases": [
          "CoT"
        ],
        "category": "specific_connectable",
        "rationale": "Chain-of-thought is a technique to guide model training, enhancing understanding and reducing errors.",
        "novelty_score": 0.55,
        "connectivity_score": 0.68,
        "specificity_score": 0.72,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "alignment mechanism",
      "training"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "stability hallucinations",
      "resolved_canonical": "Stability Hallucinations",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "attention mechanism",
      "resolved_canonical": "Attention Mechanism",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Optimal Alignment Score",
      "resolved_canonical": "Optimal Alignment Score",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.88,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Viterbi algorithm",
      "resolved_canonical": "Viterbi Algorithm",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.75,
        "specificity": 0.65,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "chain-of-thought",
      "resolved_canonical": "Chain-of-Thought",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.68,
        "specificity": 0.72,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Eliminating stability hallucinations in llm-based tts models via attention guidance

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19852.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2509.19852](https://arxiv.org/abs/2509.19852)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Calibrating LLM Confidence by Probing Perturbed Representation Stability_20250922|Calibrating LLM Confidence by Probing Perturbed Representation Stability]] (82.1% similar)
- [[2025-09-23/EvoCoT_ Overcoming the Exploration Bottleneck in Reinforcement Learning_20250923|EvoCoT: Overcoming the Exploration Bottleneck in Reinforcement Learning]] (81.8% similar)
- [[2025-09-24/Explore the Reinforcement Learning for the LLM based ASR and TTS system_20250924|Explore the Reinforcement Learning for the LLM based ASR and TTS system]] (81.6% similar)
- [[2025-09-22/Chain of Strategy Optimization Makes Large Language Models Better Emotional Supporter_20250922|Chain of Strategy Optimization Makes Large Language Models Better Emotional Supporter]] (81.3% similar)
- [[2025-09-19/ASCoT_ An Adaptive Self-Correction Chain-of-Thought Method for Late-Stage Fragility in LLMs_20250919|ASCoT: An Adaptive Self-Correction Chain-of-Thought Method for Late-Stage Fragility in LLMs]] (81.3% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Attention Mechanism|Attention Mechanism]], [[keywords/Viterbi Algorithm|Viterbi Algorithm]], [[keywords/Chain-of-Thought|Chain-of-Thought]]
**âš¡ Unique Technical**: [[keywords/Stability Hallucinations|Stability Hallucinations]], [[keywords/Optimal Alignment Score|Optimal Alignment Score]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19852v1 Announce Type: cross 
Abstract: This paper focuses on resolving stability hallucinations (e.g., repetitive or omitted speech) in LLM-based Text-to-Speech (TTS) models by improving and leveraging the attention mechanism. First, we analyzed the alignment mechanism between text tokens and speech tokens in LLMs. We then proposed a metric termed the Optimal Alignment Score (OAS), which employs the Viterbi algorithm to evaluate text-speech alignment quality. Subsequently, OAS was integrated into the training of CosyVoice2 to assist LLMs in learning continuous, stable alignment. Additionally, the pre-trained attention value is employed to guide the training of the student CosyVoice2 via chain-of-thought (CoT), which further reduces stability hallucinations in synthesized speech. Experiments on the Seed-TTS-Eval and CV3-Eval test sets demonstrate that the proposed methods can effectively reduce the stability hallucinations of CosyVoice2 without introducing additional negative effects. The appendix is available at https://wsmzzz.github.io/llm_attn.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ LLM ê¸°ë°˜ì˜ í…ìŠ¤íŠ¸-ìŒì„± ë³€í™˜(TTS) ëª¨ë¸ì—ì„œ ë°œìƒí•˜ëŠ” ì•ˆì •ì„± í™˜ê° ë¬¸ì œ(ì˜ˆ: ë°˜ë³µì ì´ê±°ë‚˜ ëˆ„ë½ëœ ìŒì„±)ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì„ ê°œì„ í•˜ê³  í™œìš©í•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. í…ìŠ¤íŠ¸ í† í°ê³¼ ìŒì„± í† í° ê°„ì˜ ì •ë ¬ ë©”ì»¤ë‹ˆì¦˜ì„ ë¶„ì„í•˜ê³ , Viterbi ì•Œê³ ë¦¬ì¦˜ì„ í™œìš©í•œ ìµœì  ì •ë ¬ ì ìˆ˜(OAS)ë¥¼ ì œì•ˆí•˜ì—¬ í…ìŠ¤íŠ¸-ìŒì„± ì •ë ¬ í’ˆì§ˆì„ í‰ê°€í–ˆìŠµë‹ˆë‹¤. OASëŠ” CosyVoice2ì˜ í•™ìŠµì— í†µí•©ë˜ì–´ ì—°ì†ì ì´ê³  ì•ˆì •ì ì¸ ì •ë ¬ì„ í•™ìŠµí•˜ë„ë¡ ë„ì™”ìŠµë‹ˆë‹¤. ë˜í•œ, ì‚¬ì „ í•™ìŠµëœ ì£¼ì˜ ê°’ì€ ì—°ì‡„ì  ì‚¬ê³ (CoT)ë¥¼ í†µí•´ í•™ìƒ ëª¨ë¸ CosyVoice2ì˜ í•™ìŠµì„ ì•ˆë‚´í•˜ì—¬ í•©ì„± ìŒì„±ì˜ ì•ˆì •ì„± í™˜ê°ì„ ì¤„ì˜€ìŠµë‹ˆë‹¤. Seed-TTS-Eval ë° CV3-Eval í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œì˜ ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì´ CosyVoice2ì˜ ì•ˆì •ì„± í™˜ê°ì„ íš¨ê³¼ì ìœ¼ë¡œ ì¤„ì¼ ìˆ˜ ìˆìŒì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. LLM ê¸°ë°˜ TTS ëª¨ë¸ì˜ ì•ˆì •ì„± í™˜ê° ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì„ ê°œì„ í•˜ê³  í™œìš©í•˜ëŠ” ë°©ë²•ì„ ì—°êµ¬í–ˆìŠµë‹ˆë‹¤.
- 2. í…ìŠ¤íŠ¸ í† í°ê³¼ ìŒì„± í† í° ê°„ì˜ ì •ë ¬ ë©”ì»¤ë‹ˆì¦˜ì„ ë¶„ì„í•˜ê³ , Viterbi ì•Œê³ ë¦¬ì¦˜ì„ í™œìš©í•œ ìµœì  ì •ë ¬ ì ìˆ˜(OAS)ë¼ëŠ” ì§€í‘œë¥¼ ì œì•ˆí–ˆìŠµë‹ˆë‹¤.
- 3. OASë¥¼ CosyVoice2ì˜ í›ˆë ¨ì— í†µí•©í•˜ì—¬ LLMì´ ì—°ì†ì ì´ê³  ì•ˆì •ì ì¸ ì •ë ¬ì„ í•™ìŠµí•˜ë„ë¡ ë„ì™”ìŠµë‹ˆë‹¤.
- 4. ì‚¬ì „ í›ˆë ¨ëœ ì£¼ì˜ ê°’ì„ í™œìš©í•˜ì—¬ chain-of-thought(CoT)ì„ í†µí•´ í•™ìƒ CosyVoice2ì˜ í›ˆë ¨ì„ ì•ˆë‚´í•¨ìœ¼ë¡œì¨ í•©ì„± ìŒì„±ì˜ ì•ˆì •ì„± í™˜ê°ì„ ì¤„ì˜€ìŠµë‹ˆë‹¤.
- 5. Seed-TTS-Eval ë° CV3-Eval í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ ì œì•ˆëœ ë°©ë²•ì´ CosyVoice2ì˜ ì•ˆì •ì„± í™˜ê°ì„ íš¨ê³¼ì ìœ¼ë¡œ ì¤„ì¼ ìˆ˜ ìˆìŒì„ ì‹¤í—˜ì ìœ¼ë¡œ ì…ì¦í–ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-25 15:51:27*