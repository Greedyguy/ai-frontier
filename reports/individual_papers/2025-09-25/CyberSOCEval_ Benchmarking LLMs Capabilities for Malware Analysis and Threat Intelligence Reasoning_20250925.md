---
keywords:
  - Large Language Model
  - Malware Analysis
  - Threat Intelligence Reasoning
  - CyberSOCEval
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2509.20166
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T16:00:40.603577",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Malware Analysis",
    "Threat Intelligence Reasoning",
    "CyberSOCEval"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.88,
    "Malware Analysis": 0.79,
    "Threat Intelligence Reasoning": 0.81,
    "CyberSOCEval": 0.84
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's focus on evaluating AI capabilities in cybersecurity.",
        "novelty_score": 0.45,
        "connectivity_score": 0.89,
        "specificity_score": 0.65,
        "link_intent_score": 0.88
      },
      {
        "surface": "Malware Analysis",
        "canonical": "Malware Analysis",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "A specific domain of cybersecurity that the paper aims to benchmark.",
        "novelty_score": 0.72,
        "connectivity_score": 0.67,
        "specificity_score": 0.82,
        "link_intent_score": 0.79
      },
      {
        "surface": "Threat Intelligence Reasoning",
        "canonical": "Threat Intelligence Reasoning",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Represents a core area of evaluation in the paper, highlighting its importance.",
        "novelty_score": 0.68,
        "connectivity_score": 0.72,
        "specificity_score": 0.78,
        "link_intent_score": 0.81
      },
      {
        "surface": "CyberSOCEval",
        "canonical": "CyberSOCEval",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "The main contribution of the paper, introducing a new benchmark suite.",
        "novelty_score": 0.85,
        "connectivity_score": 0.64,
        "specificity_score": 0.87,
        "link_intent_score": 0.84
      }
    ],
    "ban_list_suggestions": [
      "AI systems",
      "security alerts",
      "business context"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.89,
        "specificity": 0.65,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "Malware Analysis",
      "resolved_canonical": "Malware Analysis",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.67,
        "specificity": 0.82,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Threat Intelligence Reasoning",
      "resolved_canonical": "Threat Intelligence Reasoning",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.72,
        "specificity": 0.78,
        "link_intent": 0.81
      }
    },
    {
      "candidate_surface": "CyberSOCEval",
      "resolved_canonical": "CyberSOCEval",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.64,
        "specificity": 0.87,
        "link_intent": 0.84
      }
    }
  ]
}
-->

# CyberSOCEval: Benchmarking LLMs Capabilities for Malware Analysis and Threat Intelligence Reasoning

## 📋 메타데이터

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.20166.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2509.20166](https://arxiv.org/abs/2509.20166)

## 🔗 유사한 논문
- [[2025-09-23/Large Language Models for Cyber Security_ A Systematic Literature Review_20250923|Large Language Models for Cyber Security: A Systematic Literature Review]] (89.9% similar)
- [[2025-09-23/Large Language Models for Security Operations Centers_ A Comprehensive Survey_20250923|Large Language Models for Security Operations Centers: A Comprehensive Survey]] (87.3% similar)
- [[2025-09-23/LLaVul_ A Multimodal LLM for Interpretable Vulnerability Reasoning about Source Code_20250923|LLaVul: A Multimodal LLM for Interpretable Vulnerability Reasoning about Source Code]] (86.8% similar)
- [[2025-09-17/Beyond Classification_ Evaluating LLMs for Fine-Grained Automatic Malware Behavior Auditing_20250917|Beyond Classification: Evaluating LLMs for Fine-Grained Automatic Malware Behavior Auditing]] (86.2% similar)
- [[2025-09-25/Cognitive Load Limits in Large Language Models_ Benchmarking Multi-Hop Reasoning_20250925|Cognitive Load Limits in Large Language Models: Benchmarking Multi-Hop Reasoning]] (85.5% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**⚡ Unique Technical**: [[keywords/Malware Analysis|Malware Analysis]], [[keywords/Threat Intelligence Reasoning|Threat Intelligence Reasoning]], [[keywords/CyberSOCEval|CyberSOCEval]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.20166v1 Announce Type: cross 
Abstract: Today's cyber defenders are overwhelmed by a deluge of security alerts, threat intelligence signals, and shifting business context, creating an urgent need for AI systems to enhance operational security work. While Large Language Models (LLMs) have the potential to automate and scale Security Operations Center (SOC) operations, existing evaluations do not fully assess the scenarios most relevant to real-world defenders. This lack of informed evaluation impacts both AI developers and those applying LLMs to SOC automation. Without clear insight into LLM performance in real-world security scenarios, developers lack a north star for development, and users cannot reliably select the most effective models. Meanwhile, malicious actors are using AI to scale cyber attacks, highlighting the need for open source benchmarks to drive adoption and community-driven improvement among defenders and model developers. To address this, we introduce CyberSOCEval, a new suite of open source benchmarks within CyberSecEval 4. CyberSOCEval includes benchmarks tailored to evaluate LLMs in two tasks: Malware Analysis and Threat Intelligence Reasoning--core defensive domains with inadequate coverage in current benchmarks. Our evaluations show that larger, more modern LLMs tend to perform better, confirming the training scaling laws paradigm. We also find that reasoning models leveraging test time scaling do not achieve the same boost as in coding and math, suggesting these models have not been trained to reason about cybersecurity analysis, and pointing to a key opportunity for improvement. Finally, current LLMs are far from saturating our evaluations, showing that CyberSOCEval presents a significant challenge for AI developers to improve cyber defense capabilities.

## 📝 요약

현대의 사이버 방어자들은 보안 경고와 위협 정보의 홍수 속에서 AI 시스템의 도움을 필요로 하고 있습니다. 대형 언어 모델(LLM)은 보안 운영 센터(SOC)의 작업을 자동화하고 확장할 잠재력을 지니고 있지만, 현재의 평가 방식은 실제 방어자들에게 중요한 시나리오를 충분히 반영하지 못하고 있습니다. 이를 해결하기 위해, 우리는 CyberSOCEval이라는 새로운 오픈 소스 벤치마크를 소개합니다. 이 벤치마크는 악성코드 분석과 위협 정보 추론이라는 두 가지 핵심 방어 영역에서 LLM을 평가하도록 설계되었습니다. 평가 결과, 최신의 대형 LLM이 더 나은 성능을 보였으며, 이는 훈련 확장 법칙을 확인시켜 줍니다. 그러나 사이버 보안 분석에 대한 추론 모델의 성능은 기대에 미치지 못해, 이 분야에서의 개선 기회가 있음을 시사합니다. CyberSOCEval은 AI 개발자들에게 사이버 방어 능력 향상을 위한 도전 과제를 제공합니다.

## 🎯 주요 포인트

- 1. 사이버 보안 분야에서 대규모 언어 모델(LLM)의 활용은 보안 운영 센터(SOC) 자동화를 가능하게 하지만, 현재의 평가 방식은 실제 상황에 적합하지 않아 개선이 필요하다.
- 2. CyberSOCEval은 악성코드 분석과 위협 인텔리전스 추론이라는 두 가지 핵심 방어 분야에서 LLM을 평가하기 위한 새로운 오픈 소스 벤치마크를 제공한다.
- 3. 최신의 대규모 언어 모델이 더 나은 성능을 보이며, 이는 훈련 규모 법칙 패러다임을 확인시켜준다.
- 4. 현재의 LLM은 사이버 보안 분석에 대한 추론 능력이 부족하며, 이는 개선의 중요한 기회를 제공한다.
- 5. CyberSOCEval은 AI 개발자들에게 사이버 방어 능력을 향상시킬 수 있는 도전 과제를 제시한다.


---

*Generated on 2025-09-25 16:00:40*