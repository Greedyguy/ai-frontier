---
keywords:
  - AutoEval Framework
  - Mobile Agents
  - UI State Change Representation
  - Judge System
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2503.02403
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T16:10:39.859017",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "AutoEval Framework",
    "Mobile Agents",
    "UI State Change Representation",
    "Judge System"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "AutoEval Framework": 0.8,
    "Mobile Agents": 0.7,
    "UI State Change Representation": 0.78,
    "Judge System": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "AutoEval",
        "canonical": "AutoEval Framework",
        "aliases": [
          "AutoEval"
        ],
        "category": "unique_technical",
        "rationale": "AutoEval is a novel framework specifically designed for autonomous evaluation of mobile agents, making it a unique technical contribution.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "mobile agents",
        "canonical": "Mobile Agents",
        "aliases": [
          "mobile agents"
        ],
        "category": "broad_technical",
        "rationale": "Mobile agents are a central focus of the paper and connect to broader discussions in autonomous systems.",
        "novelty_score": 0.4,
        "connectivity_score": 0.75,
        "specificity_score": 0.6,
        "link_intent_score": 0.7
      },
      {
        "surface": "UI state change representation",
        "canonical": "UI State Change Representation",
        "aliases": [
          "UI state change"
        ],
        "category": "unique_technical",
        "rationale": "This representation is a specific innovation within the framework that enables automatic generation of task reward signals.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Judge System",
        "canonical": "Judge System",
        "aliases": [
          "Judge System"
        ],
        "category": "unique_technical",
        "rationale": "The Judge System is a key component of the AutoEval framework, crucial for autonomous evaluation.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "evaluation",
      "task reward signals",
      "human evaluation"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "AutoEval",
      "resolved_canonical": "AutoEval Framework",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "mobile agents",
      "resolved_canonical": "Mobile Agents",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.75,
        "specificity": 0.6,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "UI state change representation",
      "resolved_canonical": "UI State Change Representation",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Judge System",
      "resolved_canonical": "Judge System",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# AutoEval: A Practical Framework for Autonomous Evaluation of Mobile Agents

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2503.02403.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2503.02403](https://arxiv.org/abs/2503.02403)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/AgentCompass_ Towards Reliable Evaluation of Agentic Workflows in Production_20250919|AgentCompass: Towards Reliable Evaluation of Agentic Workflows in Production]] (83.5% similar)
- [[2025-09-18/AppAgent v2_ Advanced Agent for Flexible Mobile Interactions_20250918|AppAgent v2: Advanced Agent for Flexible Mobile Interactions]] (83.0% similar)
- [[2025-09-22/MEDAL_ A Framework for Benchmarking LLMs as Multilingual Open-Domain Dialogue Evaluators_20250922|MEDAL: A Framework for Benchmarking LLMs as Multilingual Open-Domain Dialogue Evaluators]] (83.0% similar)
- [[2025-09-24/MobileRL_ Online Agentic Reinforcement Learning for Mobile GUI Agents_20250924|MobileRL: Online Agentic Reinforcement Learning for Mobile GUI Agents]] (82.7% similar)
- [[2025-09-19/An Evaluation-Centric Paradigm for Scientific Visualization Agents_20250919|An Evaluation-Centric Paradigm for Scientific Visualization Agents]] (82.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Mobile Agents|Mobile Agents]]
**âš¡ Unique Technical**: [[keywords/AutoEval Framework|AutoEval Framework]], [[keywords/UI State Change Representation|UI State Change Representation]], [[keywords/Judge System|Judge System]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2503.02403v2 Announce Type: replace 
Abstract: Comprehensive evaluation of mobile agents can significantly advance their development and real-world applicability. However, existing benchmarks lack practicality and scalability due to the extensive manual effort in defining task reward signals and implementing evaluation codes. We propose AutoEval, an evaluation framework which tests mobile agents without any manual effort. Our approach designs a UI state change representation which can be used to automatically generate task reward signals, and employs a Judge System for autonomous evaluation. Evaluation shows AutoEval can automatically generate reward signals with high correlation to human-annotated signals, and achieve high accuracy (up to 94%) in autonomous evaluation comparable to human evaluation. Finally, we evaluate state-of-the-art mobile agents using our framework, providing insights into their performance and limitations.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëª¨ë°”ì¼ ì—ì´ì „íŠ¸ì˜ í‰ê°€ë¥¼ ìë™í™”í•˜ì—¬ ê°œë°œê³¼ ì‹¤ì œ ì ìš©ì„ ì´‰ì§„í•˜ëŠ” AutoEvalì´ë¼ëŠ” í‰ê°€ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ ë²¤ì¹˜ë§ˆí¬ì˜ ë¹„ì‹¤ìš©ì„±ê³¼ í™•ì¥ì„± ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, UI ìƒíƒœ ë³€í™” í‘œí˜„ì„ í†µí•´ ìë™ìœ¼ë¡œ ì‘ì—… ë³´ìƒ ì‹ í˜¸ë¥¼ ìƒì„±í•˜ê³ , Judge Systemì„ í™œìš©í•˜ì—¬ ììœ¨ í‰ê°€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤. AutoEvalì€ ì¸ê°„ì´ ì£¼ì„í•œ ì‹ í˜¸ì™€ ë†’ì€ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§€ëŠ” ë³´ìƒ ì‹ í˜¸ë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•˜ë©°, ìµœëŒ€ 94%ì˜ ë†’ì€ ì •í™•ë„ë¡œ ì¸ê°„ í‰ê°€ì™€ ìœ ì‚¬í•œ ììœ¨ í‰ê°€ë¥¼ ë‹¬ì„±í•©ë‹ˆë‹¤. ë˜í•œ, ìµœì‹  ëª¨ë°”ì¼ ì—ì´ì „íŠ¸ë¥¼ í‰ê°€í•˜ì—¬ ì„±ëŠ¥ê³¼ í•œê³„ì— ëŒ€í•œ í†µì°°ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. AutoEvalì€ ëª¨ë°”ì¼ ì—ì´ì „íŠ¸ë¥¼ ìˆ˜ë™ ì‘ì—… ì—†ì´ í‰ê°€í•  ìˆ˜ ìˆëŠ” í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.
- 2. UI ìƒíƒœ ë³€í™” í‘œí˜„ì„ í†µí•´ ìë™ìœ¼ë¡œ ì‘ì—… ë³´ìƒ ì‹ í˜¸ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- 3. AutoEvalì˜ í‰ê°€ ì‹œìŠ¤í…œì€ ì¸ê°„ í‰ê°€ì™€ ìœ ì‚¬í•œ ë†’ì€ ì •í™•ë„(ìµœëŒ€ 94%)ë¥¼ ë‹¬ì„±í•©ë‹ˆë‹¤.
- 4. ì œì•ˆëœ í”„ë ˆì„ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì‹  ëª¨ë°”ì¼ ì—ì´ì „íŠ¸ì˜ ì„±ëŠ¥ê³¼ í•œê³„ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-25 16:10:39*