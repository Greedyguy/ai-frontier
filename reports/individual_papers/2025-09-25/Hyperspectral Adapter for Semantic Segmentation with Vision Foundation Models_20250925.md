---
keywords:
  - Hyperspectral Imaging
  - Vision Foundation Models
  - Semantic Segmentation
  - Spectral Transformer
  - Modality-Aware Interaction Block
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2509.20107
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T15:58:36.069763",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Hyperspectral Imaging",
    "Vision Foundation Models",
    "Semantic Segmentation",
    "Spectral Transformer",
    "Modality-Aware Interaction Block"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Hyperspectral Imaging": 0.8,
    "Vision Foundation Models": 0.82,
    "Semantic Segmentation": 0.75,
    "Spectral Transformer": 0.78,
    "Modality-Aware Interaction Block": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "hyperspectral imaging",
        "canonical": "Hyperspectral Imaging",
        "aliases": [
          "HSI"
        ],
        "category": "unique_technical",
        "rationale": "Hyperspectral Imaging is central to the paper's methodology and distinct from traditional imaging techniques, offering unique linking opportunities.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "vision foundation models",
        "canonical": "Vision Foundation Models",
        "aliases": [
          "pretrained vision models"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision Foundation Models represent a key component of the proposed architecture, facilitating connections to broader computer vision advancements.",
        "novelty_score": 0.7,
        "connectivity_score": 0.78,
        "specificity_score": 0.72,
        "link_intent_score": 0.82
      },
      {
        "surface": "semantic segmentation",
        "canonical": "Semantic Segmentation",
        "aliases": [
          "image segmentation"
        ],
        "category": "broad_technical",
        "rationale": "Semantic Segmentation is a fundamental task in computer vision, providing a broad technical link to related methodologies.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.6,
        "link_intent_score": 0.75
      },
      {
        "surface": "spectral transformer",
        "canonical": "Spectral Transformer",
        "aliases": [
          "spectrum transformer"
        ],
        "category": "unique_technical",
        "rationale": "The Spectral Transformer is a novel component introduced in the paper, offering specific insights into spectral data processing.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.88,
        "link_intent_score": 0.78
      },
      {
        "surface": "modality-aware interaction block",
        "canonical": "Modality-Aware Interaction Block",
        "aliases": [
          "modality interaction block"
        ],
        "category": "unique_technical",
        "rationale": "This component facilitates the integration of different data modalities, crucial for understanding the paper's technical innovation.",
        "novelty_score": 0.78,
        "connectivity_score": 0.68,
        "specificity_score": 0.82,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "architecture"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "hyperspectral imaging",
      "resolved_canonical": "Hyperspectral Imaging",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "vision foundation models",
      "resolved_canonical": "Vision Foundation Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.78,
        "specificity": 0.72,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "semantic segmentation",
      "resolved_canonical": "Semantic Segmentation",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.6,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "spectral transformer",
      "resolved_canonical": "Spectral Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.88,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "modality-aware interaction block",
      "resolved_canonical": "Modality-Aware Interaction Block",
      "decision": "linked",
      "scores": {
        "novelty": 0.78,
        "connectivity": 0.68,
        "specificity": 0.82,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Hyperspectral Adapter for Semantic Segmentation with Vision Foundation Models

## 📋 메타데이터

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.20107.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2509.20107](https://arxiv.org/abs/2509.20107)

## 🔗 유사한 논문
- [[2025-09-23/Superpixel Graph Contrastive Clustering with Semantic-Invariant Augmentations for Hyperspectral Images_20250923|Superpixel Graph Contrastive Clustering with Semantic-Invariant Augmentations for Hyperspectral Images]] (84.3% similar)
- [[2025-09-23/Spectral Compressive Imaging via Chromaticity-Intensity Decomposition_20250923|Spectral Compressive Imaging via Chromaticity-Intensity Decomposition]] (83.6% similar)
- [[2025-09-22/MCGA_ Mixture of Codebooks Hyperspectral Reconstruction via Grayscale-Aware Attention_20250922|MCGA: Mixture of Codebooks Hyperspectral Reconstruction via Grayscale-Aware Attention]] (83.1% similar)
- [[2025-09-23/HyperTTA_ Test-Time Adaptation for Hyperspectral Image Classification under Distribution Shifts_20250923|HyperTTA: Test-Time Adaptation for Hyperspectral Image Classification under Distribution Shifts]] (83.1% similar)
- [[2025-09-22/Efficient Long-Tail Learning in Latent Space by sampling Synthetic Data_20250922|Efficient Long-Tail Learning in Latent Space by sampling Synthetic Data]] (83.0% similar)

## 🏷️ 카테고리화된 키워드
**🧠 Broad Technical**: [[keywords/Semantic Segmentation|Semantic Segmentation]]
**⚡ Unique Technical**: [[keywords/Hyperspectral Imaging|Hyperspectral Imaging]], [[keywords/Spectral Transformer|Spectral Transformer]], [[keywords/Modality-Aware Interaction Block|Modality-Aware Interaction Block]]
**🚀 Evolved Concepts**: [[keywords/Vision Foundation Models|Vision Foundation Models]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.20107v1 Announce Type: cross 
Abstract: Hyperspectral imaging (HSI) captures spatial information along with dense spectral measurements across numerous narrow wavelength bands. This rich spectral content has the potential to facilitate robust robotic perception, particularly in environments with complex material compositions, varying illumination, or other visually challenging conditions. However, current HSI semantic segmentation methods underperform due to their reliance on architectures and learning frameworks optimized for RGB inputs. In this work, we propose a novel hyperspectral adapter that leverages pretrained vision foundation models to effectively learn from hyperspectral data. Our architecture incorporates a spectral transformer and a spectrum-aware spatial prior module to extract rich spatial-spectral features. Additionally, we introduce a modality-aware interaction block that facilitates effective integration of hyperspectral representations and frozen vision Transformer features through dedicated extraction and injection mechanisms. Extensive evaluations on three benchmark autonomous driving datasets demonstrate that our architecture achieves state-of-the-art semantic segmentation performance while directly using HSI inputs, outperforming both vision-based and hyperspectral segmentation methods. We make the code available at https://hyperspectraladapter.cs.uni-freiburg.de.

## 📝 요약

이 논문은 복잡한 환경에서의 로봇 인식을 강화하기 위해 고해상도 스펙트럼 정보를 제공하는 초분광 이미징(HSI)을 활용한 새로운 방법론을 제안합니다. 기존의 HSI 의미론적 분할 방법이 RGB 입력에 최적화된 구조에 의존하여 성능이 저하되는 문제를 해결하기 위해, 사전 학습된 비전 모델을 활용한 초분광 어댑터를 개발했습니다. 이 아키텍처는 스펙트럼 변환기와 스펙트럼 인식 공간 사전 모듈을 포함하여 풍부한 공간-스펙트럼 특징을 추출하며, 모달리티 인식 상호작용 블록을 통해 초분광 표현과 비전 트랜스포머 특징을 효과적으로 통합합니다. 세 가지 자율주행 데이터셋에서의 평가 결과, 제안된 방법이 최첨단 성능을 달성했으며, 코드도 공개되었습니다.

## 🎯 주요 포인트

- 1. 본 연구는 사전 학습된 비전 기초 모델을 활용하여 HSI 데이터로부터 효과적으로 학습할 수 있는 새로운 하이퍼스펙트럴 어댑터를 제안합니다.
- 2. 제안된 아키텍처는 스펙트럼 변환기와 스펙트럼 인식 공간 사전 모듈을 통합하여 풍부한 공간-스펙트럴 특징을 추출합니다.
- 3. 모달리티 인식 상호작용 블록을 도입하여 하이퍼스펙트럴 표현과 비전 트랜스포머 특징의 효과적인 통합을 지원합니다.
- 4. 세 가지 벤치마크 자율 주행 데이터셋에 대한 광범위한 평가에서 제안된 아키텍처가 최첨단 의미론적 분할 성능을 달성함을 입증했습니다.
- 5. 연구의 코드가 https://hyperspectraladapter.cs.uni-freiburg.de에서 공개되었습니다.


---

*Generated on 2025-09-25 15:58:36*