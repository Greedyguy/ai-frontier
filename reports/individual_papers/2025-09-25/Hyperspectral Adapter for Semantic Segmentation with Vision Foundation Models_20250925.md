---
keywords:
  - Hyperspectral Imaging
  - Vision Foundation Models
  - Semantic Segmentation
  - Spectral Transformer
  - Modality-Aware Interaction Block
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2509.20107
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T15:58:36.069763",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Hyperspectral Imaging",
    "Vision Foundation Models",
    "Semantic Segmentation",
    "Spectral Transformer",
    "Modality-Aware Interaction Block"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Hyperspectral Imaging": 0.8,
    "Vision Foundation Models": 0.82,
    "Semantic Segmentation": 0.75,
    "Spectral Transformer": 0.78,
    "Modality-Aware Interaction Block": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "hyperspectral imaging",
        "canonical": "Hyperspectral Imaging",
        "aliases": [
          "HSI"
        ],
        "category": "unique_technical",
        "rationale": "Hyperspectral Imaging is central to the paper's methodology and distinct from traditional imaging techniques, offering unique linking opportunities.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "vision foundation models",
        "canonical": "Vision Foundation Models",
        "aliases": [
          "pretrained vision models"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision Foundation Models represent a key component of the proposed architecture, facilitating connections to broader computer vision advancements.",
        "novelty_score": 0.7,
        "connectivity_score": 0.78,
        "specificity_score": 0.72,
        "link_intent_score": 0.82
      },
      {
        "surface": "semantic segmentation",
        "canonical": "Semantic Segmentation",
        "aliases": [
          "image segmentation"
        ],
        "category": "broad_technical",
        "rationale": "Semantic Segmentation is a fundamental task in computer vision, providing a broad technical link to related methodologies.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.6,
        "link_intent_score": 0.75
      },
      {
        "surface": "spectral transformer",
        "canonical": "Spectral Transformer",
        "aliases": [
          "spectrum transformer"
        ],
        "category": "unique_technical",
        "rationale": "The Spectral Transformer is a novel component introduced in the paper, offering specific insights into spectral data processing.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.88,
        "link_intent_score": 0.78
      },
      {
        "surface": "modality-aware interaction block",
        "canonical": "Modality-Aware Interaction Block",
        "aliases": [
          "modality interaction block"
        ],
        "category": "unique_technical",
        "rationale": "This component facilitates the integration of different data modalities, crucial for understanding the paper's technical innovation.",
        "novelty_score": 0.78,
        "connectivity_score": 0.68,
        "specificity_score": 0.82,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "architecture"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "hyperspectral imaging",
      "resolved_canonical": "Hyperspectral Imaging",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "vision foundation models",
      "resolved_canonical": "Vision Foundation Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.78,
        "specificity": 0.72,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "semantic segmentation",
      "resolved_canonical": "Semantic Segmentation",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.6,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "spectral transformer",
      "resolved_canonical": "Spectral Transformer",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.88,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "modality-aware interaction block",
      "resolved_canonical": "Modality-Aware Interaction Block",
      "decision": "linked",
      "scores": {
        "novelty": 0.78,
        "connectivity": 0.68,
        "specificity": 0.82,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Hyperspectral Adapter for Semantic Segmentation with Vision Foundation Models

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.20107.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2509.20107](https://arxiv.org/abs/2509.20107)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Superpixel Graph Contrastive Clustering with Semantic-Invariant Augmentations for Hyperspectral Images_20250923|Superpixel Graph Contrastive Clustering with Semantic-Invariant Augmentations for Hyperspectral Images]] (84.3% similar)
- [[2025-09-23/Spectral Compressive Imaging via Chromaticity-Intensity Decomposition_20250923|Spectral Compressive Imaging via Chromaticity-Intensity Decomposition]] (83.6% similar)
- [[2025-09-22/MCGA_ Mixture of Codebooks Hyperspectral Reconstruction via Grayscale-Aware Attention_20250922|MCGA: Mixture of Codebooks Hyperspectral Reconstruction via Grayscale-Aware Attention]] (83.1% similar)
- [[2025-09-23/HyperTTA_ Test-Time Adaptation for Hyperspectral Image Classification under Distribution Shifts_20250923|HyperTTA: Test-Time Adaptation for Hyperspectral Image Classification under Distribution Shifts]] (83.1% similar)
- [[2025-09-22/Efficient Long-Tail Learning in Latent Space by sampling Synthetic Data_20250922|Efficient Long-Tail Learning in Latent Space by sampling Synthetic Data]] (83.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Semantic Segmentation|Semantic Segmentation]]
**âš¡ Unique Technical**: [[keywords/Hyperspectral Imaging|Hyperspectral Imaging]], [[keywords/Spectral Transformer|Spectral Transformer]], [[keywords/Modality-Aware Interaction Block|Modality-Aware Interaction Block]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision Foundation Models|Vision Foundation Models]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.20107v1 Announce Type: cross 
Abstract: Hyperspectral imaging (HSI) captures spatial information along with dense spectral measurements across numerous narrow wavelength bands. This rich spectral content has the potential to facilitate robust robotic perception, particularly in environments with complex material compositions, varying illumination, or other visually challenging conditions. However, current HSI semantic segmentation methods underperform due to their reliance on architectures and learning frameworks optimized for RGB inputs. In this work, we propose a novel hyperspectral adapter that leverages pretrained vision foundation models to effectively learn from hyperspectral data. Our architecture incorporates a spectral transformer and a spectrum-aware spatial prior module to extract rich spatial-spectral features. Additionally, we introduce a modality-aware interaction block that facilitates effective integration of hyperspectral representations and frozen vision Transformer features through dedicated extraction and injection mechanisms. Extensive evaluations on three benchmark autonomous driving datasets demonstrate that our architecture achieves state-of-the-art semantic segmentation performance while directly using HSI inputs, outperforming both vision-based and hyperspectral segmentation methods. We make the code available at https://hyperspectraladapter.cs.uni-freiburg.de.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë³µì¡í•œ í™˜ê²½ì—ì„œì˜ ë¡œë´‡ ì¸ì‹ì„ ê°•í™”í•˜ê¸° ìœ„í•´ ê³ í•´ìƒë„ ìŠ¤í™íŠ¸ëŸ¼ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ì´ˆë¶„ê´‘ ì´ë¯¸ì§•(HSI)ì„ í™œìš©í•œ ìƒˆë¡œìš´ ë°©ë²•ë¡ ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ HSI ì˜ë¯¸ë¡ ì  ë¶„í•  ë°©ë²•ì´ RGB ì…ë ¥ì— ìµœì í™”ëœ êµ¬ì¡°ì— ì˜ì¡´í•˜ì—¬ ì„±ëŠ¥ì´ ì €í•˜ë˜ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ì‚¬ì „ í•™ìŠµëœ ë¹„ì „ ëª¨ë¸ì„ í™œìš©í•œ ì´ˆë¶„ê´‘ ì–´ëŒ‘í„°ë¥¼ ê°œë°œí–ˆìŠµë‹ˆë‹¤. ì´ ì•„í‚¤í…ì²˜ëŠ” ìŠ¤í™íŠ¸ëŸ¼ ë³€í™˜ê¸°ì™€ ìŠ¤í™íŠ¸ëŸ¼ ì¸ì‹ ê³µê°„ ì‚¬ì „ ëª¨ë“ˆì„ í¬í•¨í•˜ì—¬ í’ë¶€í•œ ê³µê°„-ìŠ¤í™íŠ¸ëŸ¼ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ë©°, ëª¨ë‹¬ë¦¬í‹° ì¸ì‹ ìƒí˜¸ì‘ìš© ë¸”ë¡ì„ í†µí•´ ì´ˆë¶„ê´‘ í‘œí˜„ê³¼ ë¹„ì „ íŠ¸ëœìŠ¤í¬ë¨¸ íŠ¹ì§•ì„ íš¨ê³¼ì ìœ¼ë¡œ í†µí•©í•©ë‹ˆë‹¤. ì„¸ ê°€ì§€ ììœ¨ì£¼í–‰ ë°ì´í„°ì…‹ì—ì„œì˜ í‰ê°€ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì´ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìœ¼ë©°, ì½”ë“œë„ ê³µê°œë˜ì—ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë³¸ ì—°êµ¬ëŠ” ì‚¬ì „ í•™ìŠµëœ ë¹„ì „ ê¸°ì´ˆ ëª¨ë¸ì„ í™œìš©í•˜ì—¬ HSI ë°ì´í„°ë¡œë¶€í„° íš¨ê³¼ì ìœ¼ë¡œ í•™ìŠµí•  ìˆ˜ ìˆëŠ” ìƒˆë¡œìš´ í•˜ì´í¼ìŠ¤í™íŠ¸ëŸ´ ì–´ëŒ‘í„°ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.
- 2. ì œì•ˆëœ ì•„í‚¤í…ì²˜ëŠ” ìŠ¤í™íŠ¸ëŸ¼ ë³€í™˜ê¸°ì™€ ìŠ¤í™íŠ¸ëŸ¼ ì¸ì‹ ê³µê°„ ì‚¬ì „ ëª¨ë“ˆì„ í†µí•©í•˜ì—¬ í’ë¶€í•œ ê³µê°„-ìŠ¤í™íŠ¸ëŸ´ íŠ¹ì§•ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
- 3. ëª¨ë‹¬ë¦¬í‹° ì¸ì‹ ìƒí˜¸ì‘ìš© ë¸”ë¡ì„ ë„ì…í•˜ì—¬ í•˜ì´í¼ìŠ¤í™íŠ¸ëŸ´ í‘œí˜„ê³¼ ë¹„ì „ íŠ¸ëœìŠ¤í¬ë¨¸ íŠ¹ì§•ì˜ íš¨ê³¼ì ì¸ í†µí•©ì„ ì§€ì›í•©ë‹ˆë‹¤.
- 4. ì„¸ ê°€ì§€ ë²¤ì¹˜ë§ˆí¬ ììœ¨ ì£¼í–‰ ë°ì´í„°ì…‹ì— ëŒ€í•œ ê´‘ë²”ìœ„í•œ í‰ê°€ì—ì„œ ì œì•ˆëœ ì•„í‚¤í…ì²˜ê°€ ìµœì²¨ë‹¨ ì˜ë¯¸ë¡ ì  ë¶„í•  ì„±ëŠ¥ì„ ë‹¬ì„±í•¨ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.
- 5. ì—°êµ¬ì˜ ì½”ë“œê°€ https://hyperspectraladapter.cs.uni-freiburg.deì—ì„œ ê³µê°œë˜ì—ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-25 15:58:36*