---
keywords:
  - Retrieval Augmented Generation
  - Adaptive Context Compression
  - Large Language Model
  - Hierarchical Compressor
  - Context Selector
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2507.22931
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T16:32:11.040710",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Retrieval Augmented Generation",
    "Adaptive Context Compression",
    "Large Language Model",
    "Hierarchical Compressor",
    "Context Selector"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Retrieval Augmented Generation": 0.9,
    "Adaptive Context Compression": 0.85,
    "Large Language Model": 0.8,
    "Hierarchical Compressor": 0.78,
    "Context Selector": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "RAG",
        "canonical": "Retrieval Augmented Generation",
        "aliases": [
          "RAG"
        ],
        "category": "specific_connectable",
        "rationale": "RAG is a trending concept that connects retrieval and generation in LLMs, crucial for understanding the paper's context.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.85,
        "link_intent_score": 0.9
      },
      {
        "surface": "Adaptive Context Compression",
        "canonical": "Adaptive Context Compression",
        "aliases": [
          "ACC"
        ],
        "category": "unique_technical",
        "rationale": "This is a novel method introduced in the paper, essential for linking to specific advancements in RAG efficiency.",
        "novelty_score": 0.92,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.85
      },
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "LLMs are central to the paper's focus on enhancing model efficiency with external knowledge.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Hierarchical Compressor",
        "canonical": "Hierarchical Compressor",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "This component is key to the proposed method, enabling multi-granular embeddings and efficient context management.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Context Selector",
        "canonical": "Context Selector",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "The context selector is crucial for retaining essential information, enhancing the understanding of the paper's methodology.",
        "novelty_score": 0.7,
        "connectivity_score": 0.55,
        "specificity_score": 0.75,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "method",
      "efficiency",
      "accuracy"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "RAG",
      "resolved_canonical": "Retrieval Augmented Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.85,
        "link_intent": 0.9
      }
    },
    {
      "candidate_surface": "Adaptive Context Compression",
      "resolved_canonical": "Adaptive Context Compression",
      "decision": "linked",
      "scores": {
        "novelty": 0.92,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Hierarchical Compressor",
      "resolved_canonical": "Hierarchical Compressor",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Context Selector",
      "resolved_canonical": "Context Selector",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.55,
        "specificity": 0.75,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# Enhancing RAG Efficiency with Adaptive Context Compression

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2507.22931.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2507.22931](https://arxiv.org/abs/2507.22931)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/CORE-RAG_ Lossless Compression for Retrieval-Augmented LLMs via Reinforcement Learning_20250922|CORE-RAG: Lossless Compression for Retrieval-Augmented LLMs via Reinforcement Learning]] (90.2% similar)
- [[2025-09-24/RAG+_ Enhancing Retrieval-Augmented Generation with Application-Aware Reasoning_20250924|RAG+: Enhancing Retrieval-Augmented Generation with Application-Aware Reasoning]] (89.2% similar)
- [[2025-09-19/Enhancing Retrieval Augmentation via Adversarial Collaboration_20250919|Enhancing Retrieval Augmentation via Adversarial Collaboration]] (88.4% similar)
- [[2025-09-24/SIRAG_ Towards Stable and Interpretable RAG with A Process-Supervised Multi-Agent Framework_20250924|SIRAG: Towards Stable and Interpretable RAG with A Process-Supervised Multi-Agent Framework]] (88.2% similar)
- [[2025-09-23/AttnComp_ Attention-Guided Adaptive Context Compression for Retrieval-Augmented Generation_20250923|AttnComp: Attention-Guided Adaptive Context Compression for Retrieval-Augmented Generation]] (87.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Retrieval Augmented Generation|Retrieval Augmented Generation]]
**âš¡ Unique Technical**: [[keywords/Adaptive Context Compression|Adaptive Context Compression]], [[keywords/Hierarchical Compressor|Hierarchical Compressor]], [[keywords/Context Selector|Context Selector]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2507.22931v3 Announce Type: replace-cross 
Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs) with external knowledge but incurs significant inference costs due to lengthy retrieved contexts. While context compression mitigates this issue, existing methods apply fixed compression rates, over-compressing simple queries or under-compressing complex ones. We propose Adaptive Context Compression for RAG (ACC-RAG), a framework that dynamically adjusts compression rates based on input complexity, optimizing inference efficiency without sacrificing accuracy. ACC-RAG combines a hierarchical compressor (for multi-granular embeddings) with a context selector to retain minimal sufficient information, akin to human skimming. Evaluated on Wikipedia and five QA datasets, ACC-RAG outperforms fixed-rate methods and matches/unlocks over 4 times faster inference versus standard RAG while maintaining or improving accuracy.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì™¸ë¶€ ì§€ì‹ì„ í™œìš©í•˜ì—¬ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê²€ìƒ‰ ì¦ê°• ìƒì„±(RAG)ì˜ íš¨ìœ¨ì„±ì„ ë†’ì´ê¸° ìœ„í•œ ìƒˆë¡œìš´ ë°©ë²•ë¡ ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ê³ ì • ì••ì¶•ë¥  ë°©ì‹ì€ ê°„ë‹¨í•œ ì¿¼ë¦¬ë¥¼ ê³¼ë„í•˜ê²Œ ì••ì¶•í•˜ê±°ë‚˜ ë³µì¡í•œ ì¿¼ë¦¬ë¥¼ ì¶©ë¶„íˆ ì••ì¶•í•˜ì§€ ëª»í•˜ëŠ” ë¬¸ì œë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ì…ë ¥ ë³µì¡ë„ì— ë”°ë¼ ì••ì¶•ë¥ ì„ ë™ì ìœ¼ë¡œ ì¡°ì •í•˜ëŠ” ì ì‘í˜• ì»¨í…ìŠ¤íŠ¸ ì••ì¶•(ACC-RAG) í”„ë ˆì„ì›Œí¬ë¥¼ ê°œë°œí–ˆìŠµë‹ˆë‹¤. ACC-RAGëŠ” ê³„ì¸µì  ì••ì¶•ê¸°ì™€ ì»¨í…ìŠ¤íŠ¸ ì„ íƒê¸°ë¥¼ ê²°í•©í•˜ì—¬ ìµœì†Œí•œì˜ ì¶©ë¶„í•œ ì •ë³´ë¥¼ ìœ ì§€í•˜ë©°, ì¸ê°„ì˜ ìŠ¤í‚¤ë° ë°©ì‹ê³¼ ìœ ì‚¬í•˜ê²Œ ì‘ë™í•©ë‹ˆë‹¤. Wikipediaì™€ 5ê°œì˜ QA ë°ì´í„°ì…‹ì—ì„œ í‰ê°€í•œ ê²°ê³¼, ACC-RAGëŠ” ê³ ì • ì••ì¶•ë¥  ë°©ë²•ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë©°, í‘œì¤€ RAG ëŒ€ë¹„ 4ë°° ì´ìƒ ë¹ ë¥¸ ì¶”ë¡  ì†ë„ë¥¼ ìœ ì§€í•˜ê±°ë‚˜ ê°œì„ ëœ ì •í™•ë„ë¥¼ ì œê³µí–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. RAGëŠ” ì™¸ë¶€ ì§€ì‹ì„ í™œìš©í•˜ì—¬ LLMì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ì§€ë§Œ, ê¸´ ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ë¡œ ì¸í•´ ì¶”ë¡  ë¹„ìš©ì´ ì¦ê°€í•©ë‹ˆë‹¤.
- 2. ê¸°ì¡´ì˜ ê³ ì • ì••ì¶•ë¥  ë°©ë²•ì€ ê°„ë‹¨í•œ ì¿¼ë¦¬ë¥¼ ê³¼ë„í•˜ê²Œ ì••ì¶•í•˜ê±°ë‚˜ ë³µì¡í•œ ì¿¼ë¦¬ë¥¼ ì¶©ë¶„íˆ ì••ì¶•í•˜ì§€ ëª»í•©ë‹ˆë‹¤.
- 3. ACC-RAGëŠ” ì…ë ¥ ë³µì¡ì„±ì— ë”°ë¼ ì••ì¶•ë¥ ì„ ë™ì ìœ¼ë¡œ ì¡°ì •í•˜ì—¬ íš¨ìœ¨ì„±ì„ ìµœì í™”í•˜ë©´ì„œ ì •í™•ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤.
- 4. ACC-RAGëŠ” ê³„ì¸µì  ì••ì¶•ê¸°ì™€ ì»¨í…ìŠ¤íŠ¸ ì„ íƒê¸°ë¥¼ ê²°í•©í•˜ì—¬ ìµœì†Œí•œì˜ ì¶©ë¶„í•œ ì •ë³´ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.
- 5. ACC-RAGëŠ” Wikipediaì™€ 5ê°œì˜ QA ë°ì´í„°ì…‹ì—ì„œ í‰ê°€ë˜ì—ˆìœ¼ë©°, ê³ ì • ì••ì¶•ë¥  ë°©ë²•ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì´ë©°, í‘œì¤€ RAG ëŒ€ë¹„ 4ë°° ì´ìƒ ë¹ ë¥¸ ì¶”ë¡  ì†ë„ë¥¼ ë‹¬ì„±í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-25 16:32:11*