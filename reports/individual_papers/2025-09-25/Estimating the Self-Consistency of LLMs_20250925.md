---
keywords:
  - Large Language Model
  - Self-consistency Estimation
  - Compute Budget Allocation
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2509.19489
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T15:14:25.599644",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Self-consistency Estimation",
    "Compute Budget Allocation"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Self-consistency Estimation": 0.7,
    "Compute Budget Allocation": 0.65
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "LLMs",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Large Language Models"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's analysis, linking to foundational concepts in NLP.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "self-consistency",
        "canonical": "Self-consistency Estimation",
        "aliases": [
          "consistency estimation",
          "self-consistency analysis"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel concept specific to the paper's focus on LLM reliability.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      },
      {
        "surface": "compute budget",
        "canonical": "Compute Budget Allocation",
        "aliases": [
          "budget allocation",
          "compute resources"
        ],
        "category": "unique_technical",
        "rationale": "Key to understanding the trade-offs discussed in the paper.",
        "novelty_score": 0.65,
        "connectivity_score": 0.6,
        "specificity_score": 0.75,
        "link_intent_score": 0.65
      }
    ],
    "ban_list_suggestions": [
      "task distribution",
      "repeated calls"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "LLMs",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "self-consistency",
      "resolved_canonical": "Self-consistency Estimation",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "compute budget",
      "resolved_canonical": "Compute Budget Allocation",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.6,
        "specificity": 0.75,
        "link_intent": 0.65
      }
    }
  ]
}
-->

# Estimating the Self-Consistency of LLMs

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19489.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2509.19489](https://arxiv.org/abs/2509.19489)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Measuring Scalar Constructs in Social Science with LLMs_20250923|Measuring Scalar Constructs in Social Science with LLMs]] (86.5% similar)
- [[2025-09-22/A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages_20250922|A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages]] (84.9% similar)
- [[2025-09-24/Prompting for Performance_ Exploring LLMs for Configuring Software_20250924|Prompting for Performance: Exploring LLMs for Configuring Software]] (84.8% similar)
- [[2025-09-24/Large Language Models Do Multi-Label Classification Differently_20250924|Large Language Models Do Multi-Label Classification Differently]] (84.2% similar)
- [[2025-09-22/Subjective Behaviors and Preferences in LLM_ Language of Browsing_20250922|Subjective Behaviors and Preferences in LLM: Language of Browsing]] (84.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**âš¡ Unique Technical**: [[keywords/Self-consistency Estimation|Self-consistency Estimation]], [[keywords/Compute Budget Allocation|Compute Budget Allocation]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19489v1 Announce Type: new 
Abstract: Systems often repeat the same prompt to large language models (LLMs) and aggregate responses to improve reliability. This short note analyzes an estimator of the self-consistency of LLMs and the tradeoffs it induces under a fixed compute budget $B=mn$, where $m$ is the number of prompts sampled from the task distribution and $n$ is the number of repeated LLM calls per prompt; the resulting analysis favors a rough split $m,n\propto\sqrt{B}$.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì‹ ë¢°ì„±ì„ ë†’ì´ê¸° ìœ„í•´ ë™ì¼í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ë°˜ë³µí•˜ì—¬ ì‘ë‹µì„ ì§‘ê³„í•˜ëŠ” ì‹œìŠ¤í…œì„ ë¶„ì„í•©ë‹ˆë‹¤. ê³ ì •ëœ ê³„ì‚° ì˜ˆì‚° $B=mn$ í•˜ì—ì„œ LLMì˜ ìê¸° ì¼ê´€ì„± ì¶”ì •ì¹˜ë¥¼ ë¶„ì„í•˜ë©°, ì—¬ê¸°ì„œ $m$ì€ ì‘ì—… ë¶„í¬ì—ì„œ ìƒ˜í”Œë§ëœ í”„ë¡¬í”„íŠ¸ ìˆ˜, $n$ì€ ê° í”„ë¡¬í”„íŠ¸ì— ëŒ€í•œ ë°˜ë³µ í˜¸ì¶œ ìˆ˜ì…ë‹ˆë‹¤. ë¶„ì„ ê²°ê³¼, $m$ê³¼ $n$ì˜ ë¹„ìœ¨ì€ ëŒ€ëµì ìœ¼ë¡œ $\sqrt{B}$ì— ë¹„ë¡€í•˜ëŠ” ê²ƒì´ ìœ ë¦¬í•˜ë‹¤ëŠ” ê²°ë¡ ì„ ë„ì¶œí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì‹ ë¢°ì„±ì„ ë†’ì´ê¸° ìœ„í•´ ë™ì¼í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ë°˜ë³µí•˜ì—¬ ì‘ë‹µì„ ì§‘ê³„í•˜ëŠ” ì‹œìŠ¤í…œì´ ìì£¼ ì‚¬ìš©ëœë‹¤.
- 2. LLMì˜ ìê¸° ì¼ê´€ì„± ì¶”ì •ì¹˜ë¥¼ ë¶„ì„í•˜ê³ , ê³ ì •ëœ ê³„ì‚° ì˜ˆì‚° í•˜ì—ì„œì˜ ì ˆì¶©ì ì„ íƒêµ¬í•œë‹¤.
- 3. ê³„ì‚° ì˜ˆì‚° $B=mn$ì—ì„œ, ì‘ì—… ë¶„í¬ë¡œë¶€í„° ìƒ˜í”Œë§ëœ í”„ë¡¬í”„íŠ¸ì˜ ìˆ˜ $m$ì™€ ê° í”„ë¡¬í”„íŠ¸ì— ëŒ€í•œ ë°˜ë³µ í˜¸ì¶œ ìˆ˜ $n$ì˜ ìµœì  ë¶„í• ì€ $m,n\propto\sqrt{B}$ë¡œ ë‚˜íƒ€ë‚œë‹¤.


---

*Generated on 2025-09-25 15:14:25*