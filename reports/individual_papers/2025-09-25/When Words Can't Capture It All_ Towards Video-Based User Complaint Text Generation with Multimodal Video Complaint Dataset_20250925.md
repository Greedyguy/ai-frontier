---
keywords:
  - Complaint Description from Videos
  - ComVID Dataset
  - VideoLLaMA2-7b Model
  - Retrieval Augmented Generation
  - Multimodal Learning
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2509.19952
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T15:54:56.484048",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Complaint Description from Videos",
    "ComVID Dataset",
    "VideoLLaMA2-7b Model",
    "Retrieval Augmented Generation",
    "Multimodal Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Complaint Description from Videos": 0.8,
    "ComVID Dataset": 0.75,
    "VideoLLaMA2-7b Model": 0.78,
    "Retrieval Augmented Generation": 0.77,
    "Multimodal Learning": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Complaint Description from Videos",
        "canonical": "Complaint Description from Videos",
        "aliases": [
          "CoD-V"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel task in complaint mining, linking video content to textual complaints.",
        "novelty_score": 0.85,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "ComVID",
        "canonical": "ComVID Dataset",
        "aliases": [
          "Video Complaint Dataset"
        ],
        "category": "unique_technical",
        "rationale": "A specific dataset that supports research in multimodal complaint generation.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.75
      },
      {
        "surface": "VideoLLaMA2-7b model",
        "canonical": "VideoLLaMA2-7b Model",
        "aliases": [
          "VideoLLaMA2"
        ],
        "category": "unique_technical",
        "rationale": "A specialized model for generating complaints from video, linking multimodal data with user emotions.",
        "novelty_score": 0.8,
        "connectivity_score": 0.7,
        "specificity_score": 0.88,
        "link_intent_score": 0.78
      },
      {
        "surface": "Retrieval-Augmented Generation",
        "canonical": "Retrieval Augmented Generation",
        "aliases": [
          "RAG"
        ],
        "category": "specific_connectable",
        "rationale": "Enhances connectivity by linking retrieval methods with generative models.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.75,
        "link_intent_score": 0.77
      },
      {
        "surface": "Multimodal",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal"
        ],
        "category": "specific_connectable",
        "rationale": "Facilitates connections between different data types like text and video in complaint generation.",
        "novelty_score": 0.55,
        "connectivity_score": 0.9,
        "specificity_score": 0.7,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "explainable complaint mining",
      "video summary generation"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Complaint Description from Videos",
      "resolved_canonical": "Complaint Description from Videos",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "ComVID",
      "resolved_canonical": "ComVID Dataset",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "VideoLLaMA2-7b model",
      "resolved_canonical": "VideoLLaMA2-7b Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.7,
        "specificity": 0.88,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Retrieval-Augmented Generation",
      "resolved_canonical": "Retrieval Augmented Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.75,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Multimodal",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.9,
        "specificity": 0.7,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# When Words Can't Capture It All: Towards Video-Based User Complaint Text Generation with Multimodal Video Complaint Dataset

## 📋 메타데이터

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19952.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2509.19952](https://arxiv.org/abs/2509.19952)

## 🔗 유사한 논문
- [[2025-09-23/VideoRFT_ Incentivizing Video Reasoning Capability in MLLMs via Reinforced Fine-Tuning_20250923|VideoRFT: Incentivizing Video Reasoning Capability in MLLMs via Reinforced Fine-Tuning]] (81.4% similar)
- [[2025-09-24/VIBE_ Annotation-Free Video-to-Text Information Bottleneck Evaluation for TL;DR_20250924|VIBE: Annotation-Free Video-to-Text Information Bottleneck Evaluation for TL;DR]] (80.8% similar)
- [[2025-09-23/SD-VSum_ A Method and Dataset for Script-Driven Video Summarization_20250923|SD-VSum: A Method and Dataset for Script-Driven Video Summarization]] (80.7% similar)
- [[2025-09-19/MovieCORE_ COgnitive REasoning in Movies_20250919|MovieCORE: COgnitive REasoning in Movies]] (80.6% similar)
- [[2025-09-24/LD-ViCE_ Latent Diffusion Model for Video Counterfactual Explanations_20250924|LD-ViCE: Latent Diffusion Model for Video Counterfactual Explanations]] (80.2% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Retrieval Augmented Generation|Retrieval Augmented Generation]], [[keywords/Multimodal Learning|Multimodal Learning]]
**⚡ Unique Technical**: [[keywords/Complaint Description from Videos|Complaint Description from Videos]], [[keywords/ComVID Dataset|ComVID Dataset]], [[keywords/VideoLLaMA2-7b Model|VideoLLaMA2-7b Model]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.19952v1 Announce Type: cross 
Abstract: While there exists a lot of work on explainable complaint mining, articulating user concerns through text or video remains a significant challenge, often leaving issues unresolved. Users frequently struggle to express their complaints clearly in text but can easily upload videos depicting product defects (e.g., vague text such as `worst product' paired with a 5-second video depicting a broken headphone with the right earcup). This paper formulates a new task in the field of complaint mining to aid the common users' need to write an expressive complaint, which is Complaint Description from Videos (CoD-V) (e.g., to help the above user articulate her complaint about the defective right earcup). To this end, we introduce ComVID, a video complaint dataset containing 1,175 complaint videos and the corresponding descriptions, also annotated with the emotional state of the complainer. Additionally, we present a new complaint retention (CR) evaluation metric that discriminates the proposed (CoD-V) task against standard video summary generation and description tasks. To strengthen this initiative, we introduce a multimodal Retrieval-Augmented Generation (RAG) embedded VideoLLaMA2-7b model, designed to generate complaints while accounting for the user's emotional state. We conduct a comprehensive evaluation of several Video Language Models on several tasks (pre-trained and fine-tuned versions) with a range of established evaluation metrics, including METEOR, perplexity, and the Coleman-Liau readability score, among others. Our study lays the foundation for a new research direction to provide a platform for users to express complaints through video. Dataset and resources are available at: https://github.com/sarmistha-D/CoD-V.

## 📝 요약

이 논문은 사용자들이 제품 불만을 효과적으로 표현할 수 있도록 돕기 위한 새로운 과제인 비디오를 통한 불만 설명(CoD-V)을 제안합니다. 이를 위해 1,175개의 불만 비디오와 설명이 포함된 ComVID 데이터셋을 소개하고, 불만 유지(CR) 평가 지표를 개발했습니다. 또한, 사용자의 감정 상태를 고려하여 불만을 생성하는 멀티모달 RAG 임베디드 VideoLLaMA2-7b 모델을 제안했습니다. 다양한 비디오 언어 모델을 METEOR, perplexity, Coleman-Liau 가독성 점수 등의 평가 지표로 평가하여 새로운 연구 방향을 제시합니다. 데이터셋과 자원은 GitHub에서 제공됩니다.

## 🎯 주요 포인트

- 1. 사용자들이 텍스트로 불만을 명확히 표현하는 데 어려움을 겪는 문제를 해결하기 위해, 비디오를 통한 불만 설명(CoD-V)이라는 새로운 과제를 제안합니다.
- 2. ComVID라는 비디오 불만 데이터셋을 소개하며, 1,175개의 불만 비디오와 해당 설명, 불만자의 감정 상태를 포함하고 있습니다.
- 3. 새로운 불만 유지(CR) 평가 지표를 제시하여 CoD-V 과제를 기존의 비디오 요약 생성 및 설명 과제와 구별합니다.
- 4. 사용자의 감정 상태를 고려하여 불만을 생성하는 멀티모달 RAG 임베디드 VideoLLaMA2-7b 모델을 도입합니다.
- 5. 다양한 비디오 언어 모델을 여러 과제에서 평가하며, METEOR, perplexity, Coleman-Liau 가독성 점수 등 다양한 평가 지표를 사용합니다.


---

*Generated on 2025-09-25 15:54:56*