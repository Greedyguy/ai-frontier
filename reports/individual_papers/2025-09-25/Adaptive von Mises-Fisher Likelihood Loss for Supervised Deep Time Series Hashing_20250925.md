---
keywords:
  - Deep Time Series Hashing
  - von Mises-Fisher Likelihood Loss
  - Hyperspherical Space
  - Deep Learning
category: cs.LG
publish_date: 2025-09-25
arxiv_id: 2509.19625
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T16:37:57.365329",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Deep Time Series Hashing",
    "von Mises-Fisher Likelihood Loss",
    "Hyperspherical Space",
    "Deep Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Deep Time Series Hashing": 0.78,
    "von Mises-Fisher Likelihood Loss": 0.79,
    "Hyperspherical Space": 0.77,
    "Deep Learning": 0.85
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Deep Time Series Hashing",
        "canonical": "Deep Time Series Hashing",
        "aliases": [
          "Time Series Hashing",
          "Deep Hashing"
        ],
        "category": "unique_technical",
        "rationale": "This technique is central to the paper's contribution and offers a novel approach to indexing time series data.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.82,
        "link_intent_score": 0.78
      },
      {
        "surface": "von Mises-Fisher Likelihood Loss",
        "canonical": "von Mises-Fisher Likelihood Loss",
        "aliases": [
          "vMF Loss",
          "vMF Likelihood"
        ],
        "category": "unique_technical",
        "rationale": "The proposed loss function is a novel contribution that enhances the hashing process by reducing information loss.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.79
      },
      {
        "surface": "Hyperspherical Space",
        "canonical": "Hyperspherical Space",
        "aliases": [
          "Spherical Space",
          "M-dimensional Hypersphere"
        ],
        "category": "unique_technical",
        "rationale": "The mapping to hyperspherical space is a key component of the method, providing a unique approach to data representation.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      },
      {
        "surface": "Deep Learning",
        "canonical": "Deep Learning",
        "aliases": [],
        "category": "broad_technical",
        "rationale": "Deep learning is the foundational technique used in the hashing method, linking it to a broad range of related research.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.5,
        "link_intent_score": 0.85
      }
    ],
    "ban_list_suggestions": [
      "Indexing",
      "Binary Representations",
      "Semantic Meaning"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Deep Time Series Hashing",
      "resolved_canonical": "Deep Time Series Hashing",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.82,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "von Mises-Fisher Likelihood Loss",
      "resolved_canonical": "von Mises-Fisher Likelihood Loss",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Hyperspherical Space",
      "resolved_canonical": "Hyperspherical Space",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Deep Learning",
      "resolved_canonical": "Deep Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.5,
        "link_intent": 0.85
      }
    }
  ]
}
-->

# Adaptive von Mises-Fisher Likelihood Loss for Supervised Deep Time Series Hashing

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19625.pdf)
**Category**: cs.LG
**Published**: 2025-09-25
**ArXiv ID**: [2509.19625](https://arxiv.org/abs/2509.19625)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Learning Attribute-Aware Hash Codes for Fine-Grained Image Retrieval via Query Optimization_20250923|Learning Attribute-Aware Hash Codes for Fine-Grained Image Retrieval via Query Optimization]] (82.7% similar)
- [[2025-09-18/DiffHash_ Text-Guided Targeted Attack via Diffusion Models against Deep Hashing Image Retrieval_20250918|DiffHash: Text-Guided Targeted Attack via Diffusion Models against Deep Hashing Image Retrieval]] (81.6% similar)
- [[2025-09-22/Efficient Long-Tail Learning in Latent Space by sampling Synthetic Data_20250922|Efficient Long-Tail Learning in Latent Space by sampling Synthetic Data]] (81.5% similar)
- [[2025-09-19/Hashing-Baseline_ Rethinking Hashing in the Age of Pretrained Models_20250919|Hashing-Baseline: Rethinking Hashing in the Age of Pretrained Models]] (81.4% similar)
- [[2025-09-22/VMDNet_ Time Series Forecasting with Leakage-Free Samplewise Variational Mode Decomposition and Multibranch Decoding_20250922|VMDNet: Time Series Forecasting with Leakage-Free Samplewise Variational Mode Decomposition and Multibranch Decoding]] (80.7% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Deep Learning|Deep Learning]]
**âš¡ Unique Technical**: [[keywords/Deep Time Series Hashing|Deep Time Series Hashing]], [[keywords/von Mises-Fisher Likelihood Loss|von Mises-Fisher Likelihood Loss]], [[keywords/Hyperspherical Space|Hyperspherical Space]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19625v1 Announce Type: new 
Abstract: Indexing time series by creating compact binary representations is a fundamental task in time series data mining. Recently, deep learning-based hashing methods have proven effective for indexing time series based on semantic meaning rather than just raw similarity. The purpose of deep hashing is to map samples with the same semantic meaning to identical binary hash codes, enabling more efficient search and retrieval. Unlike other supervised representation learning methods, supervised deep hashing requires a discretization step to convert real-valued representations into binary codes, but this can induce significant information loss. In this paper, we propose a von Mises-Fisher (vMF) hashing loss. The proposed deep hashing model maps data to an M-dimensional hyperspherical space to effectively reduce information loss and models each data class as points following distinct vMF distributions. The designed loss aims to maximize the separation between each modeled vMF distribution to provide a better way to maximize the margin between each semantically different data sample. Experimental results show that our method outperforms existing baselines. The implementation is publicly available at https://github.com/jmpq97/vmf-hashing

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì‹œê³„ì—´ ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì¸ë±ì‹±í•˜ê¸° ìœ„í•œ ë”¥ëŸ¬ë‹ ê¸°ë°˜ í•´ì‹± ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë°©ë²•ë“¤ì´ ì‹¤ìˆ˜ ê°’ì„ ì´ì§„ ì½”ë“œë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì—ì„œ ì •ë³´ ì†ì‹¤ì„ ì´ˆë˜í•˜ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ì €ìë“¤ì€ von Mises-Fisher(vMF) í•´ì‹± ì†ì‹¤ì„ ë„ì…í–ˆìŠµë‹ˆë‹¤. ì´ ë°©ë²•ì€ ë°ì´í„°ë¥¼ Mì°¨ì› ì´ˆêµ¬í˜• ê³µê°„ì— ë§¤í•‘í•˜ì—¬ ì •ë³´ ì†ì‹¤ì„ ì¤„ì´ê³ , ê° ë°ì´í„° í´ë˜ìŠ¤ë¥¼ ê°œë³„ì ì¸ vMF ë¶„í¬ë¡œ ëª¨ë¸ë§í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì ‘ê·¼ì€ ì„œë¡œ ë‹¤ë¥¸ ì˜ë¯¸ë¥¼ ê°€ì§„ ë°ì´í„° ìƒ˜í”Œ ê°„ì˜ ì—¬ë°±ì„ ìµœëŒ€í™”í•˜ì—¬ ê²€ìƒ‰ íš¨ìœ¨ì„±ì„ ë†’ì…ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì´ ê¸°ì¡´ì˜ ê¸°ì¤€ ë°©ë²•ë“¤ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. êµ¬í˜„ ì½”ë“œëŠ” ê³µê°œë˜ì–´ ìˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ì˜ë¯¸ ê¸°ë°˜ìœ¼ë¡œ íš¨ìœ¨ì ìœ¼ë¡œ ì¸ë±ì‹±í•˜ê¸° ìœ„í•´ ë”¥ëŸ¬ë‹ ê¸°ë°˜ í•´ì‹± ë°©ë²•ì´ íš¨ê³¼ì ì„ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.
- 2. ì œì•ˆëœ vMF í•´ì‹± ì†ì‹¤ì€ Mì°¨ì› ì´ˆêµ¬ ê³µê°„ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë§¤í•‘í•˜ì—¬ ì •ë³´ ì†ì‹¤ì„ ì¤„ì´ê³ , ê° ë°ì´í„° í´ë˜ìŠ¤ë¥¼ vMF ë¶„í¬ë¡œ ëª¨ë¸ë§í•©ë‹ˆë‹¤.
- 3. ì„¤ê³„ëœ ì†ì‹¤ì€ ê° vMF ë¶„í¬ ê°„ì˜ ë¶„ë¦¬ë¥¼ ìµœëŒ€í™”í•˜ì—¬ ì˜ë¯¸ì ìœ¼ë¡œ ë‹¤ë¥¸ ë°ì´í„° ìƒ˜í”Œ ê°„ì˜ ì—¬ìœ ë¥¼ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤.
- 4. ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì´ ê¸°ì¡´ì˜ ê¸°ì¤€ì„ ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.
- 5. êµ¬í˜„ ì½”ë“œëŠ” https://github.com/jmpq97/vmf-hashingì—ì„œ ê³µê°œë˜ì–´ ìˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-25 16:37:57*