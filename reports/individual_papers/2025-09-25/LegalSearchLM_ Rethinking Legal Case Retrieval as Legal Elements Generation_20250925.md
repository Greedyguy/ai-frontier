---
keywords:
  - Legal Case Retrieval
  - LegalSearchLM
  - Legal Elements Generation
  - Large-Scale Retrieval Benchmark
  - Constrained Decoding
category: cs.CL
publish_date: 2025-09-25
arxiv_id: 2505.23832
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-26T08:55:33.286171",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Legal Case Retrieval",
    "LegalSearchLM",
    "Legal Elements Generation",
    "Large-Scale Retrieval Benchmark",
    "Constrained Decoding"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Legal Case Retrieval": 0.8,
    "LegalSearchLM": 0.9,
    "Legal Elements Generation": 0.85,
    "Large-Scale Retrieval Benchmark": 0.8,
    "Constrained Decoding": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Legal Case Retrieval",
        "canonical": "Legal Case Retrieval",
        "aliases": [
          "LCR"
        ],
        "category": "unique_technical",
        "rationale": "This is a specialized task within legal informatics that connects to broader legal and AI research.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.9,
        "link_intent_score": 0.8
      },
      {
        "surface": "LegalSearchLM",
        "canonical": "LegalSearchLM",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "A novel retrieval model that enhances legal case retrieval, offering a new link to legal AI advancements.",
        "novelty_score": 0.8,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.9
      },
      {
        "surface": "Legal Elements Generation",
        "canonical": "Legal Elements Generation",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "Represents a new approach in legal AI that could connect to similar generative models in other domains.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.85
      },
      {
        "surface": "Large-Scale Retrieval Benchmark",
        "canonical": "Large-Scale Retrieval Benchmark",
        "aliases": [
          "LEGAR BENCH"
        ],
        "category": "unique_technical",
        "rationale": "A significant dataset that could link to other large-scale benchmarks in AI research.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.75,
        "link_intent_score": 0.8
      },
      {
        "surface": "Constrained Decoding",
        "canonical": "Constrained Decoding",
        "aliases": [],
        "category": "specific_connectable",
        "rationale": "A method used in generative models that can link to broader discussions on decoding strategies in NLP.",
        "novelty_score": 0.6,
        "connectivity_score": 0.8,
        "specificity_score": 0.7,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "experiment"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Legal Case Retrieval",
      "resolved_canonical": "Legal Case Retrieval",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.9,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "LegalSearchLM",
      "resolved_canonical": "LegalSearchLM",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.9
      }
    },
    {
      "candidate_surface": "Legal Elements Generation",
      "resolved_canonical": "Legal Elements Generation",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Large-Scale Retrieval Benchmark",
      "resolved_canonical": "Large-Scale Retrieval Benchmark",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.75,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Constrained Decoding",
      "resolved_canonical": "Constrained Decoding",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.8,
        "specificity": 0.7,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# LegalSearchLM: Rethinking Legal Case Retrieval as Legal Elements Generation

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2505.23832.pdf)
**Category**: cs.CL
**Published**: 2025-09-25
**ArXiv ID**: [2505.23832](https://arxiv.org/abs/2505.23832)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/LightRetriever_ A LLM-based Text Retrieval Architecture with Extremely Faster Query Inference_20250923|LightRetriever: A LLM-based Text Retrieval Architecture with Extremely Faster Query Inference]] (84.5% similar)
- [[2025-09-24/SoK_ Large Language Model Copyright Auditing via Fingerprinting_20250924|SoK: Large Language Model Copyright Auditing via Fingerprinting]] (83.4% similar)
- [[2025-09-25/Embedding Domain Knowledge for Large Language Models via Reinforcement Learning from Augmented Generation_20250925|Embedding Domain Knowledge for Large Language Models via Reinforcement Learning from Augmented Generation]] (83.0% similar)
- [[2025-09-23/seqBench_ A Tunable Benchmark to Quantify Sequential Reasoning Limits of LLMs_20250923|seqBench: A Tunable Benchmark to Quantify Sequential Reasoning Limits of LLMs]] (82.8% similar)
- [[2025-09-24/Benchmarking Critical Questions Generation_ A Challenging Reasoning Task for Large Language Models_20250924|Benchmarking Critical Questions Generation: A Challenging Reasoning Task for Large Language Models]] (82.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Constrained Decoding|Constrained Decoding]]
**âš¡ Unique Technical**: [[keywords/Legal Case Retrieval|Legal Case Retrieval]], [[keywords/LegalSearchLM|LegalSearchLM]], [[keywords/Legal Elements Generation|Legal Elements Generation]], [[keywords/Large-Scale Retrieval Benchmark|Large-Scale Retrieval Benchmark]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2505.23832v2 Announce Type: replace 
Abstract: Legal Case Retrieval (LCR), which retrieves relevant cases from a query case, is a fundamental task for legal professionals in research and decision-making. However, existing studies on LCR face two major limitations. First, they are evaluated on relatively small-scale retrieval corpora (e.g., 100-55K cases) and use a narrow range of criminal query types, which cannot sufficiently reflect the complexity of real-world legal retrieval scenarios. Second, their reliance on embedding-based or lexical matching methods often results in limited representations and legally irrelevant matches. To address these issues, we present: (1) LEGAR BENCH, the first large-scale Korean LCR benchmark, covering 411 diverse crime types in queries over 1.2M candidate cases; and (2) LegalSearchLM, a retrieval model that performs legal element reasoning over the query case and directly generates content containing those elements, grounded in the target cases through constrained decoding. Experimental results show that LegalSearchLM outperforms baselines by 6-20% on LEGAR BENCH, achieving state-of-the-art performance. It also demonstrates strong generalization to out-of-domain cases, outperforming naive generative models trained on in-domain data by 15%.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë²•ë¥  ì‚¬ë¡€ ê²€ìƒ‰(LCR)ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ë‘ ê°€ì§€ ì£¼ìš” ê¸°ì—¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ì²«ì§¸, 411ê°œì˜ ë‹¤ì–‘í•œ ë²”ì£„ ìœ í˜•ì„ í¬í•¨í•œ 120ë§Œ ê°œ ì´ìƒì˜ ì‚¬ë¡€ë¥¼ ë‹¤ë£¨ëŠ” ëŒ€ê·œëª¨ í•œêµ­ì–´ LCR ë²¤ì¹˜ë§ˆí¬ì¸ LEGAR BENCHë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ë‘˜ì§¸, LegalSearchLMì´ë¼ëŠ” ê²€ìƒ‰ ëª¨ë¸ì„ ê°œë°œí•˜ì—¬ ì¿¼ë¦¬ ì‚¬ë¡€ì˜ ë²•ì  ìš”ì†Œë¥¼ ì¶”ë¡ í•˜ê³ , ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì œí•œëœ ë””ì½”ë”©ì„ í†µí•´ ê´€ë ¨ ë‚´ìš©ì„ ìƒì„±í•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, LegalSearchLMì€ LEGAR BENCHì—ì„œ ê¸°ì¡´ ëª¨ë¸ë³´ë‹¤ 6-20% ì„±ëŠ¥ì„ í–¥ìƒì‹œì¼°ìœ¼ë©°, ë„ë©”ì¸ ì™¸ ì‚¬ë¡€ì—ì„œë„ 15% ë” ë‚˜ì€ ì¼ë°˜í™” ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ê¸°ì¡´ì˜ ë²•ë¥  ì‚¬ë¡€ ê²€ìƒ‰ ì—°êµ¬ëŠ” ì†Œê·œëª¨ ë°ì´í„°ì™€ ì œí•œëœ ë²”ìœ„ì˜ ë²”ì£„ ìœ í˜•ì— ì˜ì¡´í•˜ì—¬ í˜„ì‹¤ì ì¸ ë²•ë¥  ê²€ìƒ‰ ì‹œë‚˜ë¦¬ì˜¤ì˜ ë³µì¡ì„±ì„ ì¶©ë¶„íˆ ë°˜ì˜í•˜ì§€ ëª»í•œë‹¤.
- 2. LEGAR BENCHëŠ” 411ê°œì˜ ë‹¤ì–‘í•œ ë²”ì£„ ìœ í˜•ì„ í¬í•¨í•˜ì—¬ 120ë§Œ ê°œ ì´ìƒì˜ í›„ë³´ ì‚¬ë¡€ë¥¼ ë‹¤ë£¨ëŠ” ìµœì´ˆì˜ ëŒ€ê·œëª¨ í•œêµ­ì–´ ë²•ë¥  ì‚¬ë¡€ ê²€ìƒ‰ ë²¤ì¹˜ë§ˆí¬ì´ë‹¤.
- 3. LegalSearchLMì€ ì¿¼ë¦¬ ì‚¬ë¡€ì— ëŒ€í•œ ë²•ì  ìš”ì†Œ ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ê³ , ì œí•œëœ ë””ì½”ë”©ì„ í†µí•´ ëª©í‘œ ì‚¬ë¡€ì— ê¸°ë°˜í•œ ë‚´ìš©ì„ ìƒì„±í•˜ëŠ” ê²€ìƒ‰ ëª¨ë¸ì´ë‹¤.
- 4. LegalSearchLMì€ LEGAR BENCHì—ì„œ ê¸°ì¡´ ëª¨ë¸ë“¤ë³´ë‹¤ 6-20% ë” ë†’ì€ ì„±ëŠ¥ì„ ë³´ì´ë©°, ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ì˜€ë‹¤.
- 5. LegalSearchLMì€ ë„ë©”ì¸ ì™¸ ì‚¬ë¡€ì—ì„œë„ ê°•ë ¥í•œ ì¼ë°˜í™” ëŠ¥ë ¥ì„ ë³´ì—¬ì£¼ë©°, ë„ë©”ì¸ ë‚´ ë°ì´í„°ë¡œ í›ˆë ¨ëœ ë‹¨ìˆœ ìƒì„± ëª¨ë¸ë³´ë‹¤ 15% ë” ë†’ì€ ì„±ëŠ¥ì„ ë°œíœ˜í•œë‹¤.


---

*Generated on 2025-09-26 08:55:33*