---
keywords:
  - Vision-Language Model
  - Large Language Model
  - Bias in Vision-Language Models
  - Social Stereotypes
  - Multimodal Learning
category: cs.CV
publish_date: 2025-09-25
arxiv_id: 2509.19659
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-26T09:01:50.446641",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Vision-Language Model",
    "Large Language Model",
    "Bias in Vision-Language Models",
    "Social Stereotypes",
    "Multimodal Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Vision-Language Model": 0.85,
    "Large Language Model": 0.8,
    "Bias in Vision-Language Models": 0.78,
    "Social Stereotypes": 0.77,
    "Multimodal Learning": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Vision-Language Models",
        "canonical": "Vision-Language Model",
        "aliases": [
          "VLMs"
        ],
        "category": "evolved_concepts",
        "rationale": "Vision-Language Models are central to the paper's focus on multimodal assessment and bias evaluation.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.72,
        "link_intent_score": 0.85
      },
      {
        "surface": "Large Language Model",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are used as a benchmark and judge in the study, linking to broader AI evaluation discussions.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.8
      },
      {
        "surface": "Bias in Vision-Language Models",
        "canonical": "Bias in Vision-Language Models",
        "aliases": [
          "VLM Bias"
        ],
        "category": "unique_technical",
        "rationale": "The study's primary focus is on identifying and evaluating bias within Vision-Language Models.",
        "novelty_score": 0.75,
        "connectivity_score": 0.7,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Social Stereotypes",
        "canonical": "Social Stereotypes",
        "aliases": [
          "Stereotypes"
        ],
        "category": "specific_connectable",
        "rationale": "Understanding and addressing social stereotypes is crucial for reducing bias in AI models.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.77
      },
      {
        "surface": "Multimodal Assessment",
        "canonical": "Multimodal Learning",
        "aliases": [
          "Multimodal Evaluation"
        ],
        "category": "specific_connectable",
        "rationale": "The paper's methodology involves assessing models using multimodal data, linking to broader multimodal learning discussions.",
        "novelty_score": 0.5,
        "connectivity_score": 0.82,
        "specificity_score": 0.7,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "benchmark",
      "evaluation rubric",
      "code"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Vision-Language Models",
      "resolved_canonical": "Vision-Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.72,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Large Language Model",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Bias in Vision-Language Models",
      "resolved_canonical": "Bias in Vision-Language Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.7,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Social Stereotypes",
      "resolved_canonical": "Social Stereotypes",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Multimodal Assessment",
      "resolved_canonical": "Multimodal Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.82,
        "specificity": 0.7,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Bias in the Picture: Benchmarking VLMs with Social-Cue News Images and LLM-as-Judge Assessment

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19659.pdf)
**Category**: cs.CV
**Published**: 2025-09-25
**ArXiv ID**: [2509.19659](https://arxiv.org/abs/2509.19659)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Benchmarking and Mitigating MCQA Selection Bias of Large Vision-Language Models_20250923|Benchmarking and Mitigating MCQA Selection Bias of Large Vision-Language Models]] (87.7% similar)
- [[2025-09-23/Evaluating Fairness in Large Vision-Language Models Across Diverse Demographic Attributes and Prompts_20250923|Evaluating Fairness in Large Vision-Language Models Across Diverse Demographic Attributes and Prompts]] (87.0% similar)
- [[2025-09-22/Are Vision-Language Models Safe in the Wild? A Meme-Based Benchmark Study_20250922|Are Vision-Language Models Safe in the Wild? A Meme-Based Benchmark Study]] (87.0% similar)
- [[2025-09-17/Simulating a Bias Mitigation Scenario in Large Language Models_20250917|Simulating a Bias Mitigation Scenario in Large Language Models]] (85.8% similar)
- [[2025-09-24/ColorBlindnessEval_ Can Vision-Language Models Pass Color Blindness Tests?_20250924|ColorBlindnessEval: Can Vision-Language Models Pass Color Blindness Tests?]] (85.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Social Stereotypes|Social Stereotypes]], [[keywords/Multimodal Learning|Multimodal Learning]]
**âš¡ Unique Technical**: [[keywords/Bias in Vision-Language Models|Bias in Vision-Language Models]]
**ğŸš€ Evolved Concepts**: [[keywords/Vision-Language Model|Vision-Language Model]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19659v1 Announce Type: new 
Abstract: Large vision-language models (VLMs) can jointly interpret images and text, but they are also prone to absorbing and reproducing harmful social stereotypes when visual cues such as age, gender, race, clothing, or occupation are present. To investigate these risks, we introduce a news-image benchmark consisting of 1,343 image-question pairs drawn from diverse outlets, which we annotated with ground-truth answers and demographic attributes (age, gender, race, occupation, and sports). We evaluate a range of state-of-the-art VLMs and employ a large language model (LLM) as judge, with human verification. Our findings show that: (i) visual context systematically shifts model outputs in open-ended settings; (ii) bias prevalence varies across attributes and models, with particularly high risk for gender and occupation; and (iii) higher faithfulness does not necessarily correspond to lower bias. We release the benchmark prompts, evaluation rubric, and code to support reproducible and fairness-aware multimodal assessment.

## ğŸ“ ìš”ì•½

ëŒ€í˜• ë¹„ì „-ì–¸ì–´ ëª¨ë¸(VLM)ì€ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ í•´ì„í•  ìˆ˜ ìˆì§€ë§Œ, ë‚˜ì´, ì„±ë³„, ì¸ì¢…, ì˜ìƒ, ì§ì—… ë“±ì˜ ì‹œê°ì  ë‹¨ì„œê°€ ìˆì„ ë•Œ ìœ í•´í•œ ì‚¬íšŒì  ê³ ì •ê´€ë…ì„ í¡ìˆ˜í•˜ê³  ì¬ìƒì‚°í•  ìœ„í—˜ì´ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ìœ„í—˜ì„ ì¡°ì‚¬í•˜ê¸° ìœ„í•´, ë‹¤ì–‘í•œ ë§¤ì²´ì—ì„œ ìˆ˜ì§‘í•œ 1,343ê°œì˜ ì´ë¯¸ì§€-ì§ˆë¬¸ ìŒìœ¼ë¡œ êµ¬ì„±ëœ ë‰´ìŠ¤ ì´ë¯¸ì§€ ë²¤ì¹˜ë§ˆí¬ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ì´ ìŒì€ ì •ë‹µê³¼ ì¸êµ¬í†µê³„ ì†ì„±(ë‚˜ì´, ì„±ë³„, ì¸ì¢…, ì§ì—…, ìŠ¤í¬ì¸ )ìœ¼ë¡œ ì£¼ì„ì´ ë‹¬ë ¤ ìˆìŠµë‹ˆë‹¤. ìµœì‹  VLMì„ í‰ê°€í•˜ê³ , ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ ì‹¬íŒìœ¼ë¡œ ì‚¬ìš©í•˜ë©°, ì¸ê°„ ê²€ì¦ì„ í†µí•´ ê²°ê³¼ë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ì—°êµ¬ ê²°ê³¼, (i) ì‹œê°ì  ë§¥ë½ì´ ê°œë°©í˜• ì„¤ì •ì—ì„œ ëª¨ë¸ ì¶œë ¥ì— ì²´ê³„ì ìœ¼ë¡œ ì˜í–¥ì„ ë¯¸ì¹˜ë©°, (ii) í¸í–¥ì˜ ì •ë„ëŠ” ì†ì„±ê³¼ ëª¨ë¸ì— ë”°ë¼ ë‹¤ë¥´ë©°, íŠ¹íˆ ì„±ë³„ê³¼ ì§ì—…ì—ì„œ ë†’ì€ ìœ„í—˜ì„ ë³´ì´ê³ , (iii) ë†’ì€ ì •í™•ì„±ì´ ë°˜ë“œì‹œ ë‚®ì€ í¸í–¥ê³¼ ì¼ì¹˜í•˜ì§€ ì•ŠìŒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ì¬í˜„ ê°€ëŠ¥í•˜ê³  ê³µì •ì„±ì„ ê³ ë ¤í•œ ë‹¤ì¤‘ ëª¨ë“œ í‰ê°€ë¥¼ ì§€ì›í•˜ê¸° ìœ„í•´ ë²¤ì¹˜ë§ˆí¬ í”„ë¡¬í”„íŠ¸, í‰ê°€ ê¸°ì¤€, ì½”ë“œë¥¼ ê³µê°œí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€ê·œëª¨ ë¹„ì „-ì–¸ì–´ ëª¨ë¸(VLM)ì€ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ í•´ì„í•  ìˆ˜ ìˆì§€ë§Œ, ì‹œê°ì  ë‹¨ì„œê°€ ìˆì„ ë•Œ ìœ í•´í•œ ì‚¬íšŒì  ê³ ì •ê´€ë…ì„ í¡ìˆ˜í•˜ê³  ì¬ìƒì‚°í•  ìœ„í—˜ì´ ìˆë‹¤.
- 2. ë‹¤ì–‘í•œ ë§¤ì²´ì—ì„œ ìˆ˜ì§‘í•œ 1,343ê°œì˜ ì´ë¯¸ì§€-ì§ˆë¬¸ ìŒìœ¼ë¡œ êµ¬ì„±ëœ ë‰´ìŠ¤ ì´ë¯¸ì§€ ë²¤ì¹˜ë§ˆí¬ë¥¼ ë„ì…í•˜ì—¬, ì •ë‹µê³¼ ì¸êµ¬í†µê³„í•™ì  ì†ì„±(ë‚˜ì´, ì„±ë³„, ì¸ì¢…, ì§ì—…, ìŠ¤í¬ì¸ )ì„ ì£¼ì„ìœ¼ë¡œ ë‹¬ì•˜ë‹¤.
- 3. ìµœì²¨ë‹¨ VLMì„ í‰ê°€í•˜ê³ , ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ ì‹¬íŒìœ¼ë¡œ í™œìš©í•˜ë©°, ì¸ê°„ ê²€ì¦ì„ í†µí•´ ê²°ê³¼ë¥¼ í™•ì¸í–ˆë‹¤.
- 4. ì‹œê°ì  ë§¥ë½ì´ ê°œë°©í˜• ì„¤ì •ì—ì„œ ëª¨ë¸ ì¶œë ¥ì— ì²´ê³„ì ìœ¼ë¡œ ì˜í–¥ì„ ë¯¸ì¹œë‹¤ëŠ” ê²ƒì„ ë°œê²¬í–ˆë‹¤.
- 5. í¸í–¥ì˜ ë°œìƒ ë¹ˆë„ëŠ” ì†ì„±ê³¼ ëª¨ë¸ì— ë”°ë¼ ë‹¤ë¥´ë©°, íŠ¹íˆ ì„±ë³„ê³¼ ì§ì—…ì—ì„œ ë†’ì€ ìœ„í—˜ì„ ë³´ì˜€ë‹¤.


---

*Generated on 2025-09-26 09:01:50*