---
keywords:
  - Autoencoder
  - Diffusion Model
  - Latent Diffusion Model
  - Generative Adversarial Network
  - Stochastic Decoder
category: cs.LG
publish_date: 2025-09-25
arxiv_id: 2409.02529
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T17:04:29.816178",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Autoencoder",
    "Diffusion Model",
    "Latent Diffusion Model",
    "Generative Adversarial Network",
    "Stochastic Decoder"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Autoencoder": 0.72,
    "Diffusion Model": 0.88,
    "Latent Diffusion Model": 0.8,
    "Generative Adversarial Network": 0.75,
    "Stochastic Decoder": 0.7
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "autoencoder",
        "canonical": "Autoencoder",
        "aliases": [
          "AE"
        ],
        "category": "broad_technical",
        "rationale": "Autoencoders are fundamental in representation learning and relate to the paper's focus on improving image reconstruction.",
        "novelty_score": 0.45,
        "connectivity_score": 0.78,
        "specificity_score": 0.65,
        "link_intent_score": 0.72
      },
      {
        "surface": "diffusion-based loss",
        "canonical": "Diffusion Model",
        "aliases": [
          "Diffusion-based Loss",
          "Diffusion Process"
        ],
        "category": "specific_connectable",
        "rationale": "Diffusion models are central to the paper's methodology, offering a new approach to image generation and compression.",
        "novelty_score": 0.7,
        "connectivity_score": 0.85,
        "specificity_score": 0.8,
        "link_intent_score": 0.88
      },
      {
        "surface": "latent diffusion model",
        "canonical": "Latent Diffusion Model",
        "aliases": [
          "LDM"
        ],
        "category": "unique_technical",
        "rationale": "The latent diffusion model is a novel concept introduced in the paper, crucial for understanding the proposed method.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.8
      },
      {
        "surface": "GAN-based autoencoders",
        "canonical": "Generative Adversarial Network",
        "aliases": [
          "GAN",
          "GAN-based Autoencoder"
        ],
        "category": "specific_connectable",
        "rationale": "GANs are compared against the proposed method, highlighting differences in reconstruction quality and tuning ease.",
        "novelty_score": 0.5,
        "connectivity_score": 0.82,
        "specificity_score": 0.7,
        "link_intent_score": 0.75
      },
      {
        "surface": "stochastic decoder",
        "canonical": "Stochastic Decoder",
        "aliases": [
          "Randomized Decoder"
        ],
        "category": "unique_technical",
        "rationale": "The stochastic decoder is a unique feature of the proposed method, enabling generation of unencoded details.",
        "novelty_score": 0.68,
        "connectivity_score": 0.6,
        "specificity_score": 0.78,
        "link_intent_score": 0.7
      }
    ],
    "ban_list_suggestions": [
      "blurry results",
      "reconstruction quality",
      "additional penalties"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "autoencoder",
      "resolved_canonical": "Autoencoder",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.78,
        "specificity": 0.65,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "diffusion-based loss",
      "resolved_canonical": "Diffusion Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.85,
        "specificity": 0.8,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "latent diffusion model",
      "resolved_canonical": "Latent Diffusion Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "GAN-based autoencoders",
      "resolved_canonical": "Generative Adversarial Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.82,
        "specificity": 0.7,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "stochastic decoder",
      "resolved_canonical": "Stochastic Decoder",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.6,
        "specificity": 0.78,
        "link_intent": 0.7
      }
    }
  ]
}
-->

# Sample what you cant compress

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2409.02529.pdf)
**Category**: cs.LG
**Published**: 2025-09-25
**ArXiv ID**: [2409.02529](https://arxiv.org/abs/2409.02529)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Single-step Diffusion for Image Compression at Ultra-Low Bitrates_20250923|Single-step Diffusion for Image Compression at Ultra-Low Bitrates]] (84.0% similar)
- [[2025-09-22/G2D2_ Gradient-Guided Discrete Diffusion for Inverse Problem Solving_20250922|G2D2: Gradient-Guided Discrete Diffusion for Inverse Problem Solving]] (83.5% similar)
- [[2025-09-23/Penalizing Boundary Activation for Object Completeness in Diffusion Models_20250923|Penalizing Boundary Activation for Object Completeness in Diffusion Models]] (83.3% similar)
- [[2025-09-18/Generative Image Coding with Diffusion Prior_20250918|Generative Image Coding with Diffusion Prior]] (83.3% similar)
- [[2025-09-22/Causal Fingerprints of AI Generative Models_20250922|Causal Fingerprints of AI Generative Models]] (82.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Autoencoder|Autoencoder]]
**ğŸ”— Specific Connectable**: [[keywords/Diffusion Model|Diffusion Model]], [[keywords/Generative Adversarial Network|Generative Adversarial Network]]
**âš¡ Unique Technical**: [[keywords/Latent Diffusion Model|Latent Diffusion Model]], [[keywords/Stochastic Decoder|Stochastic Decoder]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2409.02529v4 Announce Type: replace 
Abstract: For learned image representations, basic autoencoders often produce blurry results. Reconstruction quality can be improved by incorporating additional penalties such as adversarial (GAN) and perceptual losses. Arguably, these approaches lack a principled interpretation. Concurrently, in generative settings diffusion has demonstrated a remarkable ability to create crisp, high quality results and has solid theoretical underpinnings (from variational inference to direct study as the Fisher Divergence). Our work combines autoencoder representation learning with diffusion and is, to our knowledge, the first to demonstrate jointly learning a continuous encoder and decoder under a diffusion-based loss and showing that it can lead to higher compression and better generation. We demonstrate that this approach yields better reconstruction quality as compared to GAN-based autoencoders while being easier to tune. We also show that the resulting representation is easier to model with a latent diffusion model as compared to the representation obtained from a state-of-the-art GAN-based loss. Since our decoder is stochastic, it can generate details not encoded in the otherwise deterministic latent representation; we therefore name our approach "Sample what you can't compress", or SWYCC for short.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì˜¤í† ì¸ì½”ë”ì™€ í™•ì‚° ëª¨ë¸ì„ ê²°í•©í•˜ì—¬ ì´ë¯¸ì§€ ì¬êµ¬ì„± í’ˆì§ˆì„ í–¥ìƒì‹œí‚¤ëŠ” ìƒˆë¡œìš´ ë°©ë²•ë¡ ì„ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ ì˜¤í† ì¸ì½”ë”ëŠ” íë¦¿í•œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ê²½í–¥ì´ ìˆìœ¼ë©°, ì´ë¥¼ ê°œì„ í•˜ê¸° ìœ„í•´ ì ëŒ€ì  ì†ì‹¤(GAN)ê³¼ ì§€ê° ì†ì‹¤ì„ ì¶”ê°€í•˜ì§€ë§Œ, ì´ëŸ¬í•œ ì ‘ê·¼ë²•ì€ ëª…í™•í•œ í•´ì„ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ë³¸ ì—°êµ¬ëŠ” í™•ì‚° ê¸°ë°˜ ì†ì‹¤ì„ í†µí•´ ì—°ì†ì ì¸ ì¸ì½”ë”ì™€ ë””ì½”ë”ë¥¼ ê³µë™ í•™ìŠµí•˜ëŠ” ìµœì´ˆì˜ ì‹œë„ë¡œ, ë” ë†’ì€ ì••ì¶•ë¥ ê³¼ ìš°ìˆ˜í•œ ì´ë¯¸ì§€ ìƒì„±ì„ ë‹¬ì„±í•©ë‹ˆë‹¤. ì œì•ˆëœ ë°©ë²•ì€ GAN ê¸°ë°˜ ì˜¤í† ì¸ì½”ë”ë³´ë‹¤ ì¬êµ¬ì„± í’ˆì§ˆì´ ë›°ì–´ë‚˜ê³  ì¡°ì •ì´ ìš©ì´í•˜ë©°, í™•ì‚° ëª¨ë¸ì„ ì‚¬ìš©í•œ ì ì¬ í‘œí˜„ ëª¨ë¸ë§ì´ ë” ì‰¬ì›Œì§‘ë‹ˆë‹¤. í™•ë¥ ì  ë””ì½”ë”ë¥¼ í†µí•´ ê¸°ì¡´ì˜ ê²°ì •ë¡ ì  ì ì¬ í‘œí˜„ì— í¬í•¨ë˜ì§€ ì•Šì€ ì„¸ë¶€ ì‚¬í•­ì„ ìƒì„±í•  ìˆ˜ ìˆì–´, ì´ë¥¼ "ì••ì¶•í•  ìˆ˜ ì—†ëŠ” ê²ƒì„ ìƒ˜í”Œë§í•˜ë¼(SWYCC)"ë¼ê³  ëª…ëª…í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ê¸°ë³¸ ì˜¤í† ì¸ì½”ë”ëŠ” ì¢…ì¢… íë¦¿í•œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ì§€ë§Œ, ì¶”ê°€ì ì¸ í˜ë„í‹°ë¥¼ í†µí•´ ì¬êµ¬ì„± í’ˆì§ˆì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆë‹¤.
- 2. ë³¸ ì—°êµ¬ëŠ” ì˜¤í† ì¸ì½”ë” í‘œí˜„ í•™ìŠµê³¼ í™•ì‚°ì„ ê²°í•©í•˜ì—¬, ì—°ì†ì ì¸ ì¸ì½”ë”ì™€ ë””ì½”ë”ë¥¼ í™•ì‚° ê¸°ë°˜ ì†ì‹¤ í•˜ì— ê³µë™ í•™ìŠµí•˜ëŠ” ì²« ë²ˆì§¸ ì‚¬ë¡€ë¥¼ ì œì‹œí•œë‹¤.
- 3. ì œì•ˆëœ ì ‘ê·¼ë²•ì€ GAN ê¸°ë°˜ ì˜¤í† ì¸ì½”ë”ì™€ ë¹„êµí•˜ì—¬ ë” ë‚˜ì€ ì¬êµ¬ì„± í’ˆì§ˆì„ ì œê³µí•˜ë©°, íŠœë‹ì´ ë” ìš©ì´í•˜ë‹¤.
- 4. í™•ì‚° ëª¨ë¸ì„ í™œìš©í•œ ì ì¬ í‘œí˜„ì€ ìµœì²¨ë‹¨ GAN ê¸°ë°˜ ì†ì‹¤ë¡œë¶€í„° ì–»ì€ í‘œí˜„ë³´ë‹¤ ëª¨ë¸ë§ì´ ë” ìš©ì´í•˜ë‹¤.
- 5. í™•ë¥ ì  ë””ì½”ë”ë¥¼ í†µí•´ ê²°ì •ë¡ ì  ì ì¬ í‘œí˜„ì— ì¸ì½”ë”©ë˜ì§€ ì•Šì€ ì„¸ë¶€ ì‚¬í•­ì„ ìƒì„±í•  ìˆ˜ ìˆì–´, ì´ ì ‘ê·¼ë²•ì„ "ì••ì¶•í•  ìˆ˜ ì—†ëŠ” ê²ƒì„ ìƒ˜í”Œë§í•˜ë¼" (SWYCC)ë¼ê³  ëª…ëª…í•˜ì˜€ë‹¤.


---

*Generated on 2025-09-25 17:04:29*