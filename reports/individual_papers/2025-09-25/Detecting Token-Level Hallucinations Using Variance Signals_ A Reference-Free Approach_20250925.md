---
keywords:
  - Large Language Model
  - Token-Level Hallucination
  - Variance Signals
  - Autoregressive Models
  - SQuAD v2
category: cs.LG
publish_date: 2025-09-25
arxiv_id: 2507.04137
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-26T08:39:56.623815",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Token-Level Hallucination",
    "Variance Signals",
    "Autoregressive Models",
    "SQuAD v2"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Token-Level Hallucination": 0.7,
    "Variance Signals": 0.68,
    "Autoregressive Models": 0.72,
    "SQuAD v2": 0.65
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "Large Language Models"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's focus on hallucination detection in generative models.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Token-Level Hallucination",
        "canonical": "Token-Level Hallucination",
        "aliases": [
          "Token Hallucination"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a novel concept specific to the paper's framework.",
        "novelty_score": 0.78,
        "connectivity_score": 0.6,
        "specificity_score": 0.82,
        "link_intent_score": 0.7
      },
      {
        "surface": "Variance Signals",
        "canonical": "Variance Signals",
        "aliases": [
          "Variance in Token Log-Probabilities"
        ],
        "category": "unique_technical",
        "rationale": "Key method used for detecting hallucinations, specific to this study.",
        "novelty_score": 0.72,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.68
      },
      {
        "surface": "Autoregressive Models",
        "canonical": "Autoregressive Models",
        "aliases": [
          "Autoregressive Language Models"
        ],
        "category": "specific_connectable",
        "rationale": "Relevant for understanding the types of models evaluated in the study.",
        "novelty_score": 0.5,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.72
      },
      {
        "surface": "SQuAD v2",
        "canonical": "SQuAD v2",
        "aliases": [
          "Stanford Question Answering Dataset v2"
        ],
        "category": "specific_connectable",
        "rationale": "A benchmark dataset used in the evaluation, linking to broader NLP research.",
        "novelty_score": 0.55,
        "connectivity_score": 0.7,
        "specificity_score": 0.78,
        "link_intent_score": 0.65
      }
    ],
    "ban_list_suggestions": [
      "method",
      "framework",
      "analysis"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Token-Level Hallucination",
      "resolved_canonical": "Token-Level Hallucination",
      "decision": "linked",
      "scores": {
        "novelty": 0.78,
        "connectivity": 0.6,
        "specificity": 0.82,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Variance Signals",
      "resolved_canonical": "Variance Signals",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.68
      }
    },
    {
      "candidate_surface": "Autoregressive Models",
      "resolved_canonical": "Autoregressive Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.72
      }
    },
    {
      "candidate_surface": "SQuAD v2",
      "resolved_canonical": "SQuAD v2",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.7,
        "specificity": 0.78,
        "link_intent": 0.65
      }
    }
  ]
}
-->

# Detecting Token-Level Hallucinations Using Variance Signals: A Reference-Free Approach

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2507.04137.pdf)
**Category**: cs.LG
**Published**: 2025-09-25
**ArXiv ID**: [2507.04137](https://arxiv.org/abs/2507.04137)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Uncertainty-Aware Attention Heads_ Efficient Unsupervised Uncertainty Quantification for LLMs_20250923|Uncertainty-Aware Attention Heads: Efficient Unsupervised Uncertainty Quantification for LLMs]] (86.7% similar)
- [[2025-09-17/DSCC-HS_ A Dynamic Self-Reinforcing Framework for Hallucination Suppression in Large Language Models_20250917|DSCC-HS: A Dynamic Self-Reinforcing Framework for Hallucination Suppression in Large Language Models]] (86.4% similar)
- [[2025-09-23/Semantic Reformulation Entropy for Robust Hallucination Detection in QA Tasks_20250923|Semantic Reformulation Entropy for Robust Hallucination Detection in QA Tasks]] (85.8% similar)
- [[2025-09-23/Seeing is Believing? Mitigating OCR Hallucinations in Multimodal Large Language Models_20250923|Seeing is Believing? Mitigating OCR Hallucinations in Multimodal Large Language Models]] (85.6% similar)
- [[2025-09-23/How Large Language Models are Designed to Hallucinate_20250923|How Large Language Models are Designed to Hallucinate]] (84.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Autoregressive Models|Autoregressive Models]], [[keywords/SQuAD v2|SQuAD v2]]
**âš¡ Unique Technical**: [[keywords/Token-Level Hallucination|Token-Level Hallucination]], [[keywords/Variance Signals|Variance Signals]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2507.04137v2 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) have demonstrated impressive generative capabilities across diverse tasks but remain susceptible to hallucinations, confidently generated yet factually incorrect outputs. We introduce a reference-free, token-level hallucination detection framework that leverages the variance in token log-probabilities across multiple stochastic generations. Unlike prior methods that require ground-truth references or sentence-level verification, our approach is model-agnostic, interpretable, and suited for real-time or post-hoc analysis. We evaluate our method on unanswerable question prompts from the SQuAD v2 dataset and benchmark across three autoregressive models of varying scales: GPT-Neo 125M, Falcon 1B, and Mistral 7B. Through both quantitative metrics and visual diagnostics, we show that token-level variance reliably highlights instability in model outputs and correlates with hallucination patterns. Our framework is lightweight, reproducible, and adaptable to multiple domains, offering a valuable diagnostic tool for analyzing generative reliability in LLMs.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ìƒì„± ì˜¤ë¥˜ì¸ í™˜ê°ì„ íƒì§€í•˜ê¸° ìœ„í•œ ì°¸ì¡° ì—†ì´ í† í° ìˆ˜ì¤€ì—ì„œì˜ ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ì—¬ëŸ¬ í™•ë¥ ì  ìƒì„±ì—ì„œì˜ í† í° ë¡œê·¸ í™•ë¥ ì˜ ë³€ë™ì„±ì„ í™œìš©í•˜ë©°, ê¸°ì¡´ì˜ ì°¸ì¡° ê¸°ë°˜ ë˜ëŠ” ë¬¸ì¥ ìˆ˜ì¤€ ê²€ì¦ ë°©ë²•ê³¼ ë‹¬ë¦¬ ëª¨ë¸ì— êµ¬ì• ë°›ì§€ ì•Šê³  í•´ì„ ê°€ëŠ¥í•˜ë©° ì‹¤ì‹œê°„ ë˜ëŠ” ì‚¬í›„ ë¶„ì„ì— ì í•©í•©ë‹ˆë‹¤. SQuAD v2 ë°ì´í„°ì…‹ì˜ ë‹µë³€ ë¶ˆê°€ëŠ¥í•œ ì§ˆë¬¸ê³¼ ë‹¤ì–‘í•œ ê·œëª¨ì˜ ìë™íšŒê·€ ëª¨ë¸(GPT-Neo 125M, Falcon 1B, Mistral 7B)ì„ í†µí•´ í‰ê°€í•œ ê²°ê³¼, í† í° ìˆ˜ì¤€ì˜ ë³€ë™ì„±ì´ ëª¨ë¸ ì¶œë ¥ì˜ ë¶ˆì•ˆì •ì„±ì„ ì˜ ë‚˜íƒ€ë‚´ë©° í™˜ê° íŒ¨í„´ê³¼ ìƒê´€ê´€ê³„ê°€ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ê²½ëŸ‰, ì¬í˜„ ê°€ëŠ¥í•˜ë©° ì—¬ëŸ¬ ë„ë©”ì¸ì— ì ì‘ ê°€ëŠ¥í•˜ì—¬ LLMì˜ ìƒì„± ì‹ ë¢°ì„±ì„ ë¶„ì„í•˜ëŠ” ë° ìœ ìš©í•œ ë„êµ¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLMs)ì€ ë‹¤ì–‘í•œ ì‘ì—…ì—ì„œ ë›°ì–´ë‚œ ìƒì„± ëŠ¥ë ¥ì„ ë³´ì´ì§€ë§Œ ì‚¬ì‹¤ê³¼ ë‹¤ë¥¸ ì¶œë ¥ì„ ìì‹  ìˆê²Œ ìƒì„±í•˜ëŠ” í™˜ê° í˜„ìƒì— ì·¨ì•½í•©ë‹ˆë‹¤.
- 2. ìš°ë¦¬ëŠ” ì—¬ëŸ¬ í™•ë¥ ì  ìƒì„±ì—ì„œ í† í° ë¡œê·¸ í™•ë¥ ì˜ ë³€ë™ì„±ì„ í™œìš©í•œ ì°¸ì¡° ì—†ëŠ” í† í° ìˆ˜ì¤€ í™˜ê° ê°ì§€ í”„ë ˆì„ì›Œí¬ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤.
- 3. ì´ ë°©ë²•ì€ ëª¨ë¸ì— êµ¬ì• ë°›ì§€ ì•Šê³  í•´ì„ ê°€ëŠ¥í•˜ë©°, ì‹¤ì‹œê°„ ë˜ëŠ” ì‚¬í›„ ë¶„ì„ì— ì í•©í•©ë‹ˆë‹¤.
- 4. SQuAD v2 ë°ì´í„°ì…‹ì˜ ë‹µí•  ìˆ˜ ì—†ëŠ” ì§ˆë¬¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ GPT-Neo 125M, Falcon 1B, Mistral 7B ëª¨ë¸ì—ì„œ ìš°ë¦¬ì˜ ë°©ë²•ì„ í‰ê°€í–ˆìŠµë‹ˆë‹¤.
- 5. í† í° ìˆ˜ì¤€ì˜ ë³€ë™ì„±ì´ ëª¨ë¸ ì¶œë ¥ì˜ ë¶ˆì•ˆì •ì„ ì‹ ë¢°ì„± ìˆê²Œ ê°•ì¡°í•˜ê³  í™˜ê° íŒ¨í„´ê³¼ ìƒê´€ê´€ê³„ê°€ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.


---

*Generated on 2025-09-26 08:39:56*