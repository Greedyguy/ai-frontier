---
keywords:
  - Zero-Shot Learning
  - Discrete Codec Modeling
  - Melody Control
  - Singing Voice Transcription
  - Self-supervised Learning
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2509.19883
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T15:52:49.516877",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Zero-Shot Learning",
    "Discrete Codec Modeling",
    "Melody Control",
    "Singing Voice Transcription",
    "Self-supervised Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Zero-Shot Learning": 0.82,
    "Discrete Codec Modeling": 0.79,
    "Melody Control": 0.77,
    "Singing Voice Transcription": 0.75,
    "Self-supervised Learning": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Zero-Shot Singing Synthesis",
        "canonical": "Zero-Shot Learning",
        "aliases": [
          "Zero-Shot SVS"
        ],
        "category": "specific_connectable",
        "rationale": "Connects to the concept of zero-shot learning, which is crucial for understanding the framework's capability to generalize without prior examples.",
        "novelty_score": 0.55,
        "connectivity_score": 0.85,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "Discrete Codec Modeling",
        "canonical": "Discrete Codec Modeling",
        "aliases": [
          "Discrete Codec"
        ],
        "category": "unique_technical",
        "rationale": "Represents a specialized approach in the paper, essential for understanding the technical framework.",
        "novelty_score": 0.72,
        "connectivity_score": 0.65,
        "specificity_score": 0.81,
        "link_intent_score": 0.79
      },
      {
        "surface": "Melody Control",
        "canonical": "Melody Control",
        "aliases": [
          "Melody Guidance"
        ],
        "category": "unique_technical",
        "rationale": "Key to the paper's contribution in addressing melody precision in singing synthesis.",
        "novelty_score": 0.68,
        "connectivity_score": 0.7,
        "specificity_score": 0.76,
        "link_intent_score": 0.77
      },
      {
        "surface": "Singing Voice Transcription",
        "canonical": "Singing Voice Transcription",
        "aliases": [
          "SVT"
        ],
        "category": "unique_technical",
        "rationale": "Highlights a specific module used for aligning acoustic tokens, crucial for technical understanding.",
        "novelty_score": 0.65,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      },
      {
        "surface": "Contrastive Learning Strategy",
        "canonical": "Self-supervised Learning",
        "aliases": [
          "Contrastive Learning"
        ],
        "category": "specific_connectable",
        "rationale": "Links to the broader concept of self-supervised learning, relevant for understanding the learning strategy employed.",
        "novelty_score": 0.58,
        "connectivity_score": 0.83,
        "specificity_score": 0.72,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "prosody leakage",
      "fine-grained frame-level supervision"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Zero-Shot Singing Synthesis",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.85,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Discrete Codec Modeling",
      "resolved_canonical": "Discrete Codec Modeling",
      "decision": "linked",
      "scores": {
        "novelty": 0.72,
        "connectivity": 0.65,
        "specificity": 0.81,
        "link_intent": 0.79
      }
    },
    {
      "candidate_surface": "Melody Control",
      "resolved_canonical": "Melody Control",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.7,
        "specificity": 0.76,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Singing Voice Transcription",
      "resolved_canonical": "Singing Voice Transcription",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Contrastive Learning Strategy",
      "resolved_canonical": "Self-supervised Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.83,
        "specificity": 0.72,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# CoMelSinger: Discrete Token-Based Zero-Shot Singing Synthesis With Structured Melody Control and Guidance

## 📋 메타데이터

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19883.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2509.19883](https://arxiv.org/abs/2509.19883)

## 🔗 유사한 논문
- [[2025-09-18/Real-Time Streaming Mel Vocoding with Generative Flow Matching_20250918|Real-Time Streaming Mel Vocoding with Generative Flow Matching]] (84.6% similar)
- [[2025-09-23/MaskVCT_ Masked Voice Codec Transformer for Zero-Shot Voice Conversion With Increased Controllability via Multiple Guidances_20250923|MaskVCT: Masked Voice Codec Transformer for Zero-Shot Voice Conversion With Increased Controllability via Multiple Guidances]] (82.7% similar)
- [[2025-09-18/MAVL_ A Multilingual Audio-Video Lyrics Dataset for Animated Song Translation_20250918|MAVL: A Multilingual Audio-Video Lyrics Dataset for Animated Song Translation]] (81.3% similar)
- [[2025-09-24/SupertonicTTS_ Towards Highly Efficient and Streamlined Text-to-Speech System_20250924|SupertonicTTS: Towards Highly Efficient and Streamlined Text-to-Speech System]] (80.8% similar)
- [[2025-09-23/PerceiverS_ A Multi-Scale Perceiver with Effective Segmentation for Long-Term Expressive Symbolic Music Generation_20250923|PerceiverS: A Multi-Scale Perceiver with Effective Segmentation for Long-Term Expressive Symbolic Music Generation]] (80.6% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Zero-Shot Learning|Zero-Shot Learning]], [[keywords/Self-supervised Learning|Self-supervised Learning]]
**⚡ Unique Technical**: [[keywords/Discrete Codec Modeling|Discrete Codec Modeling]], [[keywords/Melody Control|Melody Control]], [[keywords/Singing Voice Transcription|Singing Voice Transcription]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.19883v1 Announce Type: cross 
Abstract: Singing Voice Synthesis (SVS) aims to generate expressive vocal performances from structured musical inputs such as lyrics and pitch sequences. While recent progress in discrete codec-based speech synthesis has enabled zero-shot generation via in-context learning, directly extending these techniques to SVS remains non-trivial due to the requirement for precise melody control. In particular, prompt-based generation often introduces prosody leakage, where pitch information is inadvertently entangled within the timbre prompt, compromising controllability. We present CoMelSinger, a zero-shot SVS framework that enables structured and disentangled melody control within a discrete codec modeling paradigm. Built on the non-autoregressive MaskGCT architecture, CoMelSinger replaces conventional text inputs with lyric and pitch tokens, preserving in-context generalization while enhancing melody conditioning. To suppress prosody leakage, we propose a coarse-to-fine contrastive learning strategy that explicitly regularizes pitch redundancy between the acoustic prompt and melody input. Furthermore, we incorporate a lightweight encoder-only Singing Voice Transcription (SVT) module to align acoustic tokens with pitch and duration, offering fine-grained frame-level supervision. Experimental results demonstrate that CoMelSinger achieves notable improvements in pitch accuracy, timbre consistency, and zero-shot transferability over competitive baselines.

## 📝 요약

CoMelSinger는 노래 목소리 합성(SVS) 분야에서 제로샷 생성과 멜로디 제어를 동시에 가능하게 하는 프레임워크입니다. 기존의 방법론은 멜로디 제어가 어려웠으나, CoMelSinger는 비자기회귀적 MaskGCT 아키텍처를 기반으로 가사와 음정 토큰을 사용하여 이를 개선했습니다. 특히, 음정 정보가 음색 프롬프트에 얽히는 문제를 해결하기 위해, 음향 프롬프트와 멜로디 입력 간의 음정 중복을 조절하는 대조 학습 전략을 도입했습니다. 또한, 가벼운 인코더 기반의 노래 목소리 전사(SVT) 모듈을 추가하여 음향 토큰과 음정, 지속 시간을 정밀하게 정렬합니다. 실험 결과, CoMelSinger는 음정 정확도, 음색 일관성, 제로샷 전이 능력에서 기존 방법들보다 뛰어난 성능을 보였습니다.

## 🎯 주요 포인트

- 1. CoMelSinger는 가사와 음정 토큰을 사용하여 멜로디 제어를 강화하는 비자기회귀 MaskGCT 아키텍처 기반의 제로샷 노래 음성 합성(SVS) 프레임워크입니다.
- 2. 프롬프트 기반 생성에서 발생하는 운율 누출 문제를 해결하기 위해, CoMelSinger는 음향 프롬프트와 멜로디 입력 간의 음정 중복을 규제하는 대조 학습 전략을 제안합니다.
- 3. 경량의 인코더 전용 노래 음성 전사(SVT) 모듈을 도입하여 음향 토큰을 음정 및 지속 시간과 정렬시켜 세밀한 프레임 수준의 감독을 제공합니다.
- 4. 실험 결과, CoMelSinger는 경쟁 베이스라인에 비해 음정 정확도, 음색 일관성, 제로샷 전이 가능성에서 현저한 개선을 달성했습니다.


---

*Generated on 2025-09-25 15:52:49*