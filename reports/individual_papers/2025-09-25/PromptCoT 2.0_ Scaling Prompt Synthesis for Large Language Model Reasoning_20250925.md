---
keywords:
  - Large Language Model
  - Prompt Synthesis
  - Self-Play
  - Supervised Fine-Tuning
  - Expectation-Maximization
category: cs.LG
publish_date: 2025-09-25
arxiv_id: 2509.19894
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T16:41:30.258019",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Prompt Synthesis",
    "Self-Play",
    "Supervised Fine-Tuning",
    "Expectation-Maximization"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Prompt Synthesis": 0.88,
    "Self-Play": 0.82,
    "Supervised Fine-Tuning": 0.8,
    "Expectation-Maximization": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Model",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "Central to the paper's focus on scaling reasoning capabilities.",
        "novelty_score": 0.45,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Prompt Synthesis",
        "canonical": "Prompt Synthesis",
        "aliases": [
          "Prompt Generation"
        ],
        "category": "unique_technical",
        "rationale": "Core innovation in the paper, enabling scalable reasoning.",
        "novelty_score": 0.75,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.88
      },
      {
        "surface": "Self-Play",
        "canonical": "Self-Play",
        "aliases": [
          "Autonomous Learning"
        ],
        "category": "specific_connectable",
        "rationale": "Describes a key post-training regime enhancing model performance.",
        "novelty_score": 0.6,
        "connectivity_score": 0.78,
        "specificity_score": 0.72,
        "link_intent_score": 0.82
      },
      {
        "surface": "Supervised Fine-Tuning",
        "canonical": "Supervised Fine-Tuning",
        "aliases": [
          "SFT"
        ],
        "category": "specific_connectable",
        "rationale": "Represents a critical training approach discussed in the paper.",
        "novelty_score": 0.58,
        "connectivity_score": 0.75,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Expectation-Maximization Loop",
        "canonical": "Expectation-Maximization",
        "aliases": [
          "EM Loop"
        ],
        "category": "unique_technical",
        "rationale": "Key method for refining rationales in prompt construction.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.78,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "Olympiad mathematics",
      "competitive programming",
      "state-of-the-art results"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Model",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Prompt Synthesis",
      "resolved_canonical": "Prompt Synthesis",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.88
      }
    },
    {
      "candidate_surface": "Self-Play",
      "resolved_canonical": "Self-Play",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.78,
        "specificity": 0.72,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Supervised Fine-Tuning",
      "resolved_canonical": "Supervised Fine-Tuning",
      "decision": "linked",
      "scores": {
        "novelty": 0.58,
        "connectivity": 0.75,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Expectation-Maximization Loop",
      "resolved_canonical": "Expectation-Maximization",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.78,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# PromptCoT 2.0: Scaling Prompt Synthesis for Large Language Model Reasoning

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19894.pdf)
**Category**: cs.LG
**Published**: 2025-09-25
**ArXiv ID**: [2509.19894](https://arxiv.org/abs/2509.19894)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-19/PMPO_ Probabilistic Metric Prompt Optimization for Small and Large Language Models_20250919|PMPO: Probabilistic Metric Prompt Optimization for Small and Large Language Models]] (86.4% similar)
- [[2025-09-23/PromptSuite_ A Task-Agnostic Framework for Multi-Prompt Generation_20250923|PromptSuite: A Task-Agnostic Framework for Multi-Prompt Generation]] (86.3% similar)
- [[2025-09-24/PromptEnhancer_ A Simple Approach to Enhance Text-to-Image Models via Chain-of-Thought Prompt Rewriting_20250924|PromptEnhancer: A Simple Approach to Enhance Text-to-Image Models via Chain-of-Thought Prompt Rewriting]] (85.8% similar)
- [[2025-09-25/PromptSculptor_ Multi-Agent Based Text-to-Image Prompt Optimization_20250925|PromptSculptor: Multi-Agent Based Text-to-Image Prompt Optimization]] (85.6% similar)
- [[2025-09-23/Prompt-with-Me_ in-IDE Structured Prompt Management for LLM-Driven Software Engineering_20250923|Prompt-with-Me: in-IDE Structured Prompt Management for LLM-Driven Software Engineering]] (84.9% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Self-Play|Self-Play]], [[keywords/Supervised Fine-Tuning|Supervised Fine-Tuning]]
**âš¡ Unique Technical**: [[keywords/Prompt Synthesis|Prompt Synthesis]], [[keywords/Expectation-Maximization|Expectation-Maximization]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19894v1 Announce Type: new 
Abstract: Large language models (LLMs) are evolving from conversational systems into strong reasoners for tasks such as Olympiad mathematics and competitive programming. While scaling parameters and test-time computation has driven progress, a key bottleneck is the lack of high-quality training problems: human-curated datasets are costly and limited, while existing synthetic corpora are often too easy or narrow. PromptCoT 1.0 showed that injecting rationales into prompt synthesis increases problem difficulty. Building on this, we present PromptCoT 2.0, a scalable framework that replaces hand-crafted heuristics with an expectation-maximization (EM) loop, where rationales are iteratively refined to guide prompt construction. This produces problems that are both harder and more diverse than prior corpora. The synthetic prompts support two post-training regimes: (1) Self-Play, where strong models improve autonomously via verifiable feedback without stronger teachers; and (2) Supervised Fine-Tuning (SFT), where weaker models learn from teacher-distilled traces. Extensive experiments demonstrate the effectiveness of this approach. In self-play, applying PromptCoT 2.0 to Qwen3-30B-A3B-Thinking-2507 sets new state-of-the-art results at the 30B scale, with +4.4, +4.8, and +5.3 on AIME 24/25 and HMMT 25, +6.1 and +5.0 on LiveCodeBench v5/v6, and +35 Elo on Codeforces. In SFT, training Qwen2.5-7B-Instruct solely on synthetic prompts boosts accuracy to 73.1 (AIME 24), 65.6 (AIME 25), and 53.4 (LiveCodeBench v5), surpassing models trained on human or hybrid data. Analyses further confirm that PromptCoT 2.0 yields fundamentally harder and distributionally distinct problems. These results establish prompt synthesis as a new axis for scaling reasoning and position PromptCoT 2.0 as a scalable foundation for future open-source models. The implementation is available at https://github.com/inclusionAI/PromptCoT.

## ğŸ“ ìš”ì•½

ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ë°œì „ì„ ìœ„í•´ ê³ í’ˆì§ˆ í›ˆë ¨ ë¬¸ì œì˜ ë¶€ì¡±ì´ ì£¼ìš” ì¥ì• ë¬¼ë¡œ ì‘ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤. PromptCoT 2.0ì€ ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì„¤ê³„ëœ í™•ì¥ ê°€ëŠ¥í•œ í”„ë ˆì„ì›Œí¬ë¡œ, ê¸°ëŒ€-ìµœëŒ€í™”(EM) ë£¨í”„ë¥¼ í†µí•´ ë¬¸ì œì˜ ë‚œì´ë„ì™€ ë‹¤ì–‘ì„±ì„ ë†’ì˜€ìŠµë‹ˆë‹¤. ì´ ë°©ë²•ë¡ ì€ ë‘ ê°€ì§€ í›ˆë ¨ ë°©ì‹ì— ì ìš©ë©ë‹ˆë‹¤: (1) ìê°€ í•™ìŠµ(Self-Play)ì—ì„œëŠ” ê°•ë ¥í•œ ëª¨ë¸ì´ ììœ¨ì ìœ¼ë¡œ ê°œì„ ë˜ë©°, (2) ì§€ë„ í•™ìŠµ(SFT)ì—ì„œëŠ” ì•½í•œ ëª¨ë¸ì´ ê°•ë ¥í•œ ëª¨ë¸ì˜ í•™ìŠµ í”ì ì„ í†µí•´ í•™ìŠµí•©ë‹ˆë‹¤. ì‹¤í—˜ ê²°ê³¼, PromptCoT 2.0ì€ ìê°€ í•™ìŠµì—ì„œ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥ì„ ê¸°ë¡í–ˆìœ¼ë©°, ì§€ë„ í•™ìŠµì—ì„œë„ ì¸ê°„ ë˜ëŠ” í˜¼í•© ë°ì´í„°ë¡œ í›ˆë ¨ëœ ëª¨ë¸ì„ ëŠ¥ê°€í•˜ëŠ” ì •í™•ë„ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤. PromptCoT 2.0ì€ í•©ì„± í”„ë¡¬í”„íŠ¸ ìƒì„±ì´ ì¶”ë¡  ëŠ¥ë ¥ í™•ì¥ì˜ ìƒˆë¡œìš´ ì¶•ì„ì„ ì…ì¦í•˜ë©°, í–¥í›„ ì˜¤í”ˆ ì†ŒìŠ¤ ëª¨ë¸ì˜ í™•ì¥ ê°€ëŠ¥í•œ ê¸°ë°˜ìœ¼ë¡œ ìë¦¬ë§¤ê¹€í•  ê²ƒì…ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. PromptCoT 2.0ëŠ” ê¸°ëŒ€-ìµœëŒ€í™”(EM) ë£¨í”„ë¥¼ í†µí•´ í•©ë¦¬ì  ì‚¬ê³ ë¥¼ ìœ ë„í•˜ì—¬ ë¬¸ì œì˜ ë‚œì´ë„ì™€ ë‹¤ì–‘ì„±ì„ ì¦ê°€ì‹œí‚µë‹ˆë‹¤.
- 2. ì´ í”„ë ˆì„ì›Œí¬ëŠ” ìê°€ í•™ìŠµ(Self-Play)ê³¼ ì§€ë„ í•™ìŠµ(Supervised Fine-Tuning, SFT)ì˜ ë‘ ê°€ì§€ ì‚¬í›„ í•™ìŠµ ì²´ì œë¥¼ ì§€ì›í•©ë‹ˆë‹¤.
- 3. PromptCoT 2.0ì„ ì ìš©í•œ ìê°€ í•™ìŠµì€ 30B ê·œëª¨ì—ì„œ ìƒˆë¡œìš´ ìµœì²¨ë‹¨ ì„±ê³¼ë¥¼ ë‹¬ì„±í•˜ë©°, ì—¬ëŸ¬ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì˜€ìŠµë‹ˆë‹¤.
- 4. SFTì—ì„œëŠ” ì˜¤ì§ í•©ì„± í”„ë¡¬í”„íŠ¸ë¡œë§Œ í›ˆë ¨ëœ ëª¨ë¸ì´ ì¸ê°„ ë˜ëŠ” í˜¼í•© ë°ì´í„°ë¡œ í›ˆë ¨ëœ ëª¨ë¸ì„ ëŠ¥ê°€í•˜ëŠ” ì •í™•ë„ë¥¼ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤.
- 5. PromptCoT 2.0ì€ ë¬¸ì œì˜ ë‚œì´ë„ë¥¼ ê·¼ë³¸ì ìœ¼ë¡œ ë†’ì´ê³  ë¶„í¬ì ìœ¼ë¡œ ë…íŠ¹í•œ ë¬¸ì œë¥¼ ìƒì„±í•˜ì—¬ ì¶”ë¡  í™•ì¥ì˜ ìƒˆë¡œìš´ ì¶•ì„ ì œê³µí•©ë‹ˆë‹¤.


---

*Generated on 2025-09-25 16:41:30*