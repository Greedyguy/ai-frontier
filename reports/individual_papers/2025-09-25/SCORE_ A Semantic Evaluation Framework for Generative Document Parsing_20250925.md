---
keywords:
  - Generative Document Parsing
  - SCORE Framework
  - Semantic Alignment
  - Interpretive Diversity
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2509.19345
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T15:27:44.315408",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Generative Document Parsing",
    "SCORE Framework",
    "Semantic Alignment",
    "Interpretive Diversity"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Generative Document Parsing": 0.78,
    "SCORE Framework": 0.82,
    "Semantic Alignment": 0.77,
    "Interpretive Diversity": 0.75
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "generative document parsing",
        "canonical": "Generative Document Parsing",
        "aliases": [
          "document parsing",
          "generative parsing"
        ],
        "category": "unique_technical",
        "rationale": "This term represents a specialized approach in document analysis, linking to discussions on generative models.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "SCORE",
        "canonical": "SCORE Framework",
        "aliases": [
          "Structural and Content Robust Evaluation"
        ],
        "category": "unique_technical",
        "rationale": "As a new evaluation framework, it provides a unique perspective on document parsing, linking to evaluation methodologies.",
        "novelty_score": 0.8,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.82
      },
      {
        "surface": "semantic alignment",
        "canonical": "Semantic Alignment",
        "aliases": [
          "alignment",
          "semantic matching"
        ],
        "category": "specific_connectable",
        "rationale": "This concept is crucial for understanding how different document interpretations can be evaluated for semantic consistency.",
        "novelty_score": 0.65,
        "connectivity_score": 0.85,
        "specificity_score": 0.7,
        "link_intent_score": 0.77
      },
      {
        "surface": "interpretive diversity",
        "canonical": "Interpretive Diversity",
        "aliases": [
          "interpretation diversity",
          "diverse interpretations"
        ],
        "category": "unique_technical",
        "rationale": "This term highlights the variability in document parsing outputs, linking to discussions on evaluation challenges.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.75
      }
    ],
    "ban_list_suggestions": [
      "evaluation",
      "performance",
      "system"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "generative document parsing",
      "resolved_canonical": "Generative Document Parsing",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "SCORE",
      "resolved_canonical": "SCORE Framework",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "semantic alignment",
      "resolved_canonical": "Semantic Alignment",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.85,
        "specificity": 0.7,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "interpretive diversity",
      "resolved_canonical": "Interpretive Diversity",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.75
      }
    }
  ]
}
-->

# SCORE: A Semantic Evaluation Framework for Generative Document Parsing

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19345.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2509.19345](https://arxiv.org/abs/2509.19345)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/RadEval_ A framework for radiology text evaluation_20250923|RadEval: A framework for radiology text evaluation]] (82.6% similar)
- [[2025-09-24/HSGM_ Hierarchical Segment-Graph Memory for Scalable Long-Text Semantics_20250924|HSGM: Hierarchical Segment-Graph Memory for Scalable Long-Text Semantics]] (81.2% similar)
- [[2025-09-22/Relevance to Utility_ Process-Supervised Rewrite for RAG_20250922|Relevance to Utility: Process-Supervised Rewrite for RAG]] (80.7% similar)
- [[2025-09-22/MEDAL_ A Framework for Benchmarking LLMs as Multilingual Open-Domain Dialogue Evaluators_20250922|MEDAL: A Framework for Benchmarking LLMs as Multilingual Open-Domain Dialogue Evaluators]] (80.7% similar)
- [[2025-09-25/Score the Steps, Not Just the Goal_ VLM-Based Subgoal Evaluation for Robotic Manipulation_20250925|Score the Steps, Not Just the Goal: VLM-Based Subgoal Evaluation for Robotic Manipulation]] (80.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Semantic Alignment|Semantic Alignment]]
**âš¡ Unique Technical**: [[keywords/Generative Document Parsing|Generative Document Parsing]], [[keywords/SCORE Framework|SCORE Framework]], [[keywords/Interpretive Diversity|Interpretive Diversity]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19345v1 Announce Type: cross 
Abstract: Multi-modal generative document parsing systems challenge traditional evaluation: unlike deterministic OCR or layout models, they often produce semantically correct yet structurally divergent outputs. Conventional metrics-CER, WER, IoU, or TEDS-misclassify such diversity as error, penalizing valid interpretations and obscuring system behavior.
  We introduce SCORE (Structural and COntent Robust Evaluation), an interpretation-agnostic framework that integrates (i) adjusted edit distance for robust content fidelity, (ii) token-level diagnostics to distinguish hallucinations from omissions, (iii) table evaluation with spatial tolerance and semantic alignment, and (iv) hierarchy-aware consistency checks. Together, these dimensions enable evaluation that embraces representational diversity while enforcing semantic rigor.
  Across 1,114 pages spanning a holistic benchmark and a field dataset, SCORE consistently revealed cross-dataset performance patterns missed by standard metrics. In 2-5% of pages with ambiguous table structures, traditional metrics penalized systems by 12-25% on average, leading to distorted rankings. SCORE corrected these cases, recovering equivalence between alternative but valid interpretations. Moreover, by normalizing generative outputs into a format-agnostic representation, SCORE reproduces traditional scores (e.g., table F1 up to 0.93) without requiring object-detection pipelines, demonstrating that generative parsing alone suffices for comprehensive evaluation.
  By exposing how interpretive diversity impacts evaluation outcomes and providing multi-dimensional, interpretable diagnostics, SCORE establishes foundational principles for semantically grounded, fair, and practical benchmarking of modern document parsing systems.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì „í†µì ì¸ í‰ê°€ ë°©ì‹ì´ ì•„ë‹Œ, ë‹¤ì¤‘ ëª¨ë‹¬ ìƒì„± ë¬¸ì„œ íŒŒì‹± ì‹œìŠ¤í…œì„ ìœ„í•œ ìƒˆë¡œìš´ í‰ê°€ í”„ë ˆì„ì›Œí¬ì¸ SCOREë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ê¸°ì¡´ì˜ í‰ê°€ ì§€í‘œëŠ” ë‹¤ì–‘í•œ í•´ì„ì„ ì˜¤ë¥˜ë¡œ ê°„ì£¼í•˜ì—¬ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ ì™œê³¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. SCOREëŠ” ì¡°ì •ëœ í¸ì§‘ ê±°ë¦¬, í† í° ìˆ˜ì¤€ ì§„ë‹¨, ê³µê°„ì  ê´€ìš©ì„±ì„ ê³ ë ¤í•œ í‘œ í‰ê°€, ê³„ì¸µ ì¸ì‹ ì¼ê´€ì„± ê²€ì‚¬ë¥¼ í†µí•©í•˜ì—¬ ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤. 1,114í˜ì´ì§€ì— ê±¸ì¹œ ì‹¤í—˜ì—ì„œ SCOREëŠ” ê¸°ì¡´ ì§€í‘œê°€ ë†“ì¹œ ì„±ëŠ¥ íŒ¨í„´ì„ ë°œê²¬í–ˆìœ¼ë©°, ëª¨í˜¸í•œ êµ¬ì¡°ë¥¼ ê°€ì§„ í˜ì´ì§€ì—ì„œì˜ ì™œê³¡ëœ í‰ê°€ë¥¼ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤. ì´ë¡œì¨ SCOREëŠ” í˜„ëŒ€ ë¬¸ì„œ íŒŒì‹± ì‹œìŠ¤í…œì˜ ê³µì •í•˜ê³  ì‹¤ìš©ì ì¸ ë²¤ì¹˜ë§ˆí‚¹ì„ ìœ„í•œ ê¸°ë³¸ ì›ì¹™ì„ í™•ë¦½í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. SCOREëŠ” ì „í†µì ì¸ í‰ê°€ ë°©ì‹ì´ ê°„ê³¼í•˜ëŠ” í•´ì„ì  ë‹¤ì–‘ì„±ì„ í¬ìš©í•˜ë©´ì„œë„ ì˜ë¯¸ì  ì—„ê²©ì„±ì„ ìœ ì§€í•˜ëŠ” í‰ê°€ í”„ë ˆì„ì›Œí¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
- 2. SCOREëŠ” ì¡°ì •ëœ í¸ì§‘ ê±°ë¦¬, í† í° ìˆ˜ì¤€ ì§„ë‹¨, ê³µê°„ì  ê´€ìš©ê³¼ ì˜ë¯¸ì  ì •ë ¬ì„ ê°–ì¶˜ í…Œì´ë¸” í‰ê°€, ê³„ì¸µ ì¸ì‹ ì¼ê´€ì„± ê²€ì‚¬ë¥¼ í†µí•©í•©ë‹ˆë‹¤.
- 3. SCOREëŠ” 1,114í˜ì´ì§€ì— ê±¸ì¹œ ë²¤ì¹˜ë§ˆí¬ì™€ í•„ë“œ ë°ì´í„°ì…‹ì—ì„œ ì „í†µì ì¸ ë©”íŠ¸ë¦­ì´ ë†“ì¹œ ì„±ëŠ¥ íŒ¨í„´ì„ ì¼ê´€ë˜ê²Œ ë“œëŸ¬ëƒˆìŠµë‹ˆë‹¤.
- 4. SCOREëŠ” í¬ë§·ì— êµ¬ì• ë°›ì§€ ì•ŠëŠ” í‘œí˜„ìœ¼ë¡œ ìƒì„±ëœ ì¶œë ¥ì„ ì •ê·œí™”í•˜ì—¬ ì „í†µì ì¸ ì ìˆ˜ë¥¼ ì¬í˜„í•˜ë©°, ê°ì²´ íƒì§€ íŒŒì´í”„ë¼ì¸ ì—†ì´ë„ í¬ê´„ì ì¸ í‰ê°€ê°€ ê°€ëŠ¥í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
- 5. SCOREëŠ” í˜„ëŒ€ ë¬¸ì„œ íŒŒì‹± ì‹œìŠ¤í…œì˜ ì˜ë¯¸ì ìœ¼ë¡œ ê¸°ë°˜ì„ ë‘” ê³µì •í•˜ê³  ì‹¤ìš©ì ì¸ ë²¤ì¹˜ë§ˆí‚¹ì„ ìœ„í•œ ê¸°ì´ˆ ì›ì¹™ì„ í™•ë¦½í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-25 15:27:44*