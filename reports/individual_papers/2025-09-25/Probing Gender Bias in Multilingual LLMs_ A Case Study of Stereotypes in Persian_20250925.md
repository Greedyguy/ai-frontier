---
keywords:
  - Large Language Model
  - Gender Bias
  - Low-Resource Languages
  - Domain-Specific Gender Skew Index
  - Inclusive NLP Practices
category: cs.CL
publish_date: 2025-09-25
arxiv_id: 2509.20168
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-26T08:48:36.762430",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Gender Bias",
    "Low-Resource Languages",
    "Domain-Specific Gender Skew Index",
    "Inclusive NLP Practices"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Gender Bias": 0.9,
    "Low-Resource Languages": 0.8,
    "Domain-Specific Gender Skew Index": 0.75,
    "Inclusive NLP Practices": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Multilingual Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "Multilingual LLMs"
        ],
        "category": "broad_technical",
        "rationale": "This term connects to the broader concept of LLMs, which is central to the study of bias in AI.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.85
      },
      {
        "surface": "gender bias",
        "canonical": "Gender Bias",
        "aliases": [
          "gender stereotypes"
        ],
        "category": "specific_connectable",
        "rationale": "Understanding and mitigating gender bias is crucial for ethical AI, making it a key concept for linking.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.8,
        "link_intent_score": 0.9
      },
      {
        "surface": "low-resource languages",
        "canonical": "Low-Resource Languages",
        "aliases": [
          "understudied languages"
        ],
        "category": "unique_technical",
        "rationale": "This highlights a significant gap in AI research, offering a unique angle for further exploration.",
        "novelty_score": 0.7,
        "connectivity_score": 0.65,
        "specificity_score": 0.75,
        "link_intent_score": 0.8
      },
      {
        "surface": "Domain-Specific Gender Skew Index",
        "canonical": "Domain-Specific Gender Skew Index",
        "aliases": [
          "DS-GSI"
        ],
        "category": "unique_technical",
        "rationale": "This new metric provides a specific tool for measuring gender bias, enhancing the study's depth.",
        "novelty_score": 0.85,
        "connectivity_score": 0.6,
        "specificity_score": 0.9,
        "link_intent_score": 0.75
      },
      {
        "surface": "inclusive NLP practices",
        "canonical": "Inclusive NLP Practices",
        "aliases": [
          "inclusive natural language processing"
        ],
        "category": "evolved_concepts",
        "rationale": "Promoting inclusivity in NLP is a growing trend, linking to ethical considerations in AI.",
        "novelty_score": 0.65,
        "connectivity_score": 0.7,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "stereotypes",
      "semantic domains",
      "real-world data"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Multilingual Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "gender bias",
      "resolved_canonical": "Gender Bias",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.8,
        "link_intent": 0.9
      }
    },
    {
      "candidate_surface": "low-resource languages",
      "resolved_canonical": "Low-Resource Languages",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.65,
        "specificity": 0.75,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Domain-Specific Gender Skew Index",
      "resolved_canonical": "Domain-Specific Gender Skew Index",
      "decision": "linked",
      "scores": {
        "novelty": 0.85,
        "connectivity": 0.6,
        "specificity": 0.9,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "inclusive NLP practices",
      "resolved_canonical": "Inclusive NLP Practices",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.7,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# Probing Gender Bias in Multilingual LLMs: A Case Study of Stereotypes in Persian

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2509.20168.pdf)
**Category**: cs.CL
**Published**: 2025-09-25
**ArXiv ID**: [2509.20168](https://arxiv.org/abs/2509.20168)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/EuroGEST_ Investigating gender stereotypes in multilingual language models_20250923|EuroGEST: Investigating gender stereotypes in multilingual language models]] (87.8% similar)
- [[2025-09-25/Blind Men and the Elephant_ Diverse Perspectives on Gender Stereotypes in Benchmark Datasets_20250925|Blind Men and the Elephant: Diverse Perspectives on Gender Stereotypes in Benchmark Datasets]] (86.4% similar)
- [[2025-09-23/Auto-Search and Refinement_ An Automated Framework for Gender Bias Mitigation in Large Language Models_20250923|Auto-Search and Refinement: An Automated Framework for Gender Bias Mitigation in Large Language Models]] (85.0% similar)
- [[2025-09-23/Justice in Judgment_ Unveiling (Hidden) Bias in LLM-assisted Peer Reviews_20250923|Justice in Judgment: Unveiling (Hidden) Bias in LLM-assisted Peer Reviews]] (84.7% similar)
- [[2025-09-23/Intrinsic Meets Extrinsic Fairness_ Assessing the Downstream Impact of Bias Mitigation in Large Language Models_20250923|Intrinsic Meets Extrinsic Fairness: Assessing the Downstream Impact of Bias Mitigation in Large Language Models]] (84.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Gender Bias|Gender Bias]]
**âš¡ Unique Technical**: [[keywords/Low-Resource Languages|Low-Resource Languages]], [[keywords/Domain-Specific Gender Skew Index|Domain-Specific Gender Skew Index]]
**ğŸš€ Evolved Concepts**: [[keywords/Inclusive NLP Practices|Inclusive NLP Practices]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.20168v1 Announce Type: new 
Abstract: Multilingual Large Language Models (LLMs) are increasingly used worldwide, making it essential to ensure they are free from gender bias to prevent representational harm. While prior studies have examined such biases in high-resource languages, low-resource languages remain understudied. In this paper, we propose a template-based probing methodology, validated against real-world data, to uncover gender stereotypes in LLMs. As part of this framework, we introduce the Domain-Specific Gender Skew Index (DS-GSI), a metric that quantifies deviations from gender parity. We evaluate four prominent models, GPT-4o mini, DeepSeek R1, Gemini 2.0 Flash, and Qwen QwQ 32B, across four semantic domains, focusing on Persian, a low-resource language with distinct linguistic features. Our results show that all models exhibit gender stereotypes, with greater disparities in Persian than in English across all domains. Among these, sports reflect the most rigid gender biases. This study underscores the need for inclusive NLP practices and provides a framework for assessing bias in other low-resource languages.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë‹¤êµ­ì–´ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì—ì„œ ì„±ë³„ í¸í–¥ì„ íƒêµ¬í•˜ë©°, íŠ¹íˆ ì €ìì› ì–¸ì–´ì— ëŒ€í•œ ì—°êµ¬ê°€ ë¶€ì¡±í•œ ì ì„ ì§€ì í•©ë‹ˆë‹¤. ì €ìë“¤ì€ í…œí”Œë¦¿ ê¸°ë°˜ì˜ íƒìƒ‰ ë°©ë²•ë¡ ì„ ì œì•ˆí•˜ê³ , ì„±ë³„ ë¶ˆê· í˜•ì„ ì •ëŸ‰í™”í•˜ëŠ” DS-GSI ì§€í‘œë¥¼ ë„ì…í•˜ì—¬ ì´ë¥¼ ê²€ì¦í–ˆìŠµë‹ˆë‹¤. í˜ë¥´ì‹œì•„ì–´ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ GPT-4o mini, DeepSeek R1, Gemini 2.0 Flash, Qwen QwQ 32B ëª¨ë¸ì„ í‰ê°€í•œ ê²°ê³¼, ëª¨ë“  ëª¨ë¸ì´ ì„±ë³„ í¸í–¥ì„ ë³´ì˜€ìœ¼ë©°, íŠ¹íˆ ìŠ¤í¬ì¸  ë¶„ì•¼ì—ì„œ ê°€ì¥ ê°•í•œ í¸í–¥ì´ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” í¬ê´„ì ì¸ ìì—°ì–´ ì²˜ë¦¬(NLP) ê´€í–‰ì˜ í•„ìš”ì„±ì„ ê°•ì¡°í•˜ë©°, ë‹¤ë¥¸ ì €ìì› ì–¸ì–´ì˜ í¸í–¥ í‰ê°€ë¥¼ ìœ„í•œ í‹€ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë‹¤êµ­ì–´ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì—ì„œ ì„±ë³„ í¸í–¥ì„ ì œê±°í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë©°, íŠ¹íˆ ì €ìì› ì–¸ì–´ì—ì„œì˜ ì—°êµ¬ê°€ í•„ìš”í•˜ë‹¤.
- 2. ë³¸ ë…¼ë¬¸ì€ ì„±ë³„ ê³ ì •ê´€ë…ì„ ë°œê²¬í•˜ê¸° ìœ„í•œ í…œí”Œë¦¿ ê¸°ë°˜ íƒìƒ‰ ë°©ë²•ë¡ ì„ ì œì•ˆí•˜ë©°, ì‹¤ì œ ë°ì´í„°ì™€ì˜ ê²€ì¦ì„ í†µí•´ ì´ë¥¼ ì…ì¦í•œë‹¤.
- 3. ë„ë©”ì¸ë³„ ì„±ë³„ í¸í–¥ ì§€ìˆ˜(DS-GSI)ë¥¼ ë„ì…í•˜ì—¬ ì„±ë³„ ë¶ˆê· í˜•ì„ ì •ëŸ‰í™”í•˜ëŠ” ìƒˆë¡œìš´ ì§€í‘œë¥¼ ì œì‹œí•œë‹¤.
- 4. í˜ë¥´ì‹œì•„ì–´ë¥¼ í¬í•¨í•œ ì €ìì› ì–¸ì–´ì—ì„œ ë„¤ ê°€ì§€ ì£¼ìš” ëª¨ë¸ì„ í‰ê°€í•œ ê²°ê³¼, ëª¨ë“  ëª¨ë¸ì´ ì„±ë³„ ê³ ì •ê´€ë…ì„ ë‚˜íƒ€ë‚´ë©°, íŠ¹íˆ ìŠ¤í¬ì¸  ë¶„ì•¼ì—ì„œ ê°€ì¥ í° í¸í–¥ì´ ë°œê²¬ë˜ì—ˆë‹¤.
- 5. ë³¸ ì—°êµ¬ëŠ” í¬ê´„ì ì¸ ìì—°ì–´ ì²˜ë¦¬(NLP) ê´€í–‰ì˜ í•„ìš”ì„±ì„ ê°•ì¡°í•˜ë©°, ë‹¤ë¥¸ ì €ìì› ì–¸ì–´ì—ì„œì˜ í¸í–¥ í‰ê°€ë¥¼ ìœ„í•œ í”„ë ˆì„ì›Œí¬ë¥¼ ì œê³µí•œë‹¤.


---

*Generated on 2025-09-26 08:48:36*