---
keywords:
  - Large Language Model
  - MediGen
  - Fine-Tuning
  - Electronic Health Records
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2409.09324
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T16:16:42.965614",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "MediGen",
    "Fine-Tuning",
    "Electronic Health Records"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "MediGen": 0.7,
    "Fine-Tuning": 0.78,
    "Electronic Health Records": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Model",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are central to the study and connect well with existing research on language models and AI.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "MediGen",
        "canonical": "MediGen",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "MediGen represents a specific application of LLMs in medical documentation, offering unique insights into this niche.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.7
      },
      {
        "surface": "Fine-Tuning",
        "canonical": "Fine-Tuning",
        "aliases": [
          "Model Fine-Tuning"
        ],
        "category": "specific_connectable",
        "rationale": "Fine-tuning is a critical process in adapting large models to specific tasks, enhancing connectivity with model training techniques.",
        "novelty_score": 0.5,
        "connectivity_score": 0.82,
        "specificity_score": 0.7,
        "link_intent_score": 0.78
      },
      {
        "surface": "Electronic Health Records",
        "canonical": "Electronic Health Records",
        "aliases": [
          "EHRs"
        ],
        "category": "specific_connectable",
        "rationale": "EHRs are a significant part of the administrative burden in healthcare, linking to studies on healthcare technology.",
        "novelty_score": 0.4,
        "connectivity_score": 0.75,
        "specificity_score": 0.72,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "administrative tasks",
      "healthcare delivery"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Model",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "MediGen",
      "resolved_canonical": "MediGen",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.7
      }
    },
    {
      "candidate_surface": "Fine-Tuning",
      "resolved_canonical": "Fine-Tuning",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.82,
        "specificity": 0.7,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Electronic Health Records",
      "resolved_canonical": "Electronic Health Records",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.75,
        "specificity": 0.72,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# Efficient Fine-Tuning of Large Language Models for Automated Medical Documentation

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2409.09324.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2409.09324](https://arxiv.org/abs/2409.09324)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/SparseDoctor_ Towards Efficient Chat Doctor with Mixture of Experts Enhanced Large Language Models_20250923|SparseDoctor: Towards Efficient Chat Doctor with Mixture of Experts Enhanced Large Language Models]] (87.7% similar)
- [[2025-09-19/MedVAL_ Toward Expert-Level Medical Text Validation with Language Models_20250919|MedVAL: Toward Expert-Level Medical Text Validation with Language Models]] (86.6% similar)
- [[2025-09-24/Advances in Large Language Models for Medicine_20250924|Advances in Large Language Models for Medicine]] (86.1% similar)
- [[2025-09-22/EHR-MCP_ Real-world Evaluation of Clinical Information Retrieval by Large Language Models via Model Context Protocol_20250922|EHR-MCP: Real-world Evaluation of Clinical Information Retrieval by Large Language Models via Model Context Protocol]] (86.0% similar)
- [[2025-09-18/Integrating Text and Time-Series into (Large) Language Models to Predict Medical Outcomes_20250918|Integrating Text and Time-Series into (Large) Language Models to Predict Medical Outcomes]] (85.5% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Fine-Tuning|Fine-Tuning]], [[keywords/Electronic Health Records|Electronic Health Records]]
**âš¡ Unique Technical**: [[keywords/MediGen|MediGen]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2409.09324v3 Announce Type: replace-cross 
Abstract: Scientific research indicates that for every hour spent in direct patient care, physicians spend nearly two additional hours on administrative tasks, particularly on electronic health records (EHRs) and desk work. This excessive administrative burden not only reduces the time available for patient care but also contributes to physician burnout and inefficiencies in healthcare delivery. To address these challenges, this study introduces MediGen, a fine-tuned large language model (LLM) designed to automate the generation of medical reports from medical dialogues. By leveraging state-of-the-art methodologies for fine-tuning open-source pretrained models, including LLaMA3-8B, MediGen achieves high accuracy in transcribing and summarizing clinical interactions. The fine-tuned LLaMA3-8B model demonstrated promising results, achieving a ROUGE score of 58% and a BERTScore-F1 of 72%, indicating its effectiveness in generating accurate and clinically relevant medical reports. These findings suggest that MediGen has the potential to significantly reduce the administrative workload on physicians, improving both healthcare efficiency and physician well-being.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” ì˜ì‚¬ë“¤ì´ í™˜ì ì§„ë£Œ ì™¸ì— ì „ìì˜ë¬´ê¸°ë¡(EHR) ë° ì‚¬ë¬´ ì‘ì—…ì— ë§ì€ ì‹œê°„ì„ ì†Œëª¨í•˜ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ MediGenì´ë¼ëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ ì†Œê°œí•©ë‹ˆë‹¤. MediGenì€ ì˜ë£Œ ëŒ€í™”ë¥¼ ìë™ìœ¼ë¡œ ë³´ê³ ì„œë¡œ ìƒì„±í•˜ë©°, LLaMA3-8B ë“± ìµœì‹  ê¸°ë²•ì„ í™œìš©í•´ ë†’ì€ ì •í™•ë„ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ROUGE ì ìˆ˜ 58%, BERTScore-F1 72%ë¥¼ ê¸°ë¡í•˜ë©°, ì •í™•í•˜ê³  ì„ìƒì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ëŠ” ë° íš¨ê³¼ì ì„ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì˜ì‚¬ë“¤ì˜ í–‰ì • ì—…ë¬´ ë¶€ë‹´ì„ ì¤„ì´ê³ , ì˜ë£Œ íš¨ìœ¨ì„±ê³¼ ì˜ì‚¬ë“¤ì˜ ë³µì§€ë¥¼ í–¥ìƒì‹œí‚¬ ì ì¬ë ¥ì´ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì˜ì‚¬ë“¤ì€ í™˜ì ì§„ë£Œì— ì§ì ‘ì ìœ¼ë¡œ í•œ ì‹œê°„ì„ ë³´ë‚¼ ë•Œë§ˆë‹¤ ì¶”ê°€ë¡œ ë‘ ì‹œê°„ì„ í–‰ì • ì—…ë¬´ì— ì†Œë¹„í•œë‹¤.
- 2. ê³¼ë„í•œ í–‰ì • ì—…ë¬´ëŠ” í™˜ì ì§„ë£Œ ì‹œê°„ì„ ì¤„ì´ê³ , ì˜ì‚¬ ë²ˆì•„ì›ƒê³¼ ì˜ë£Œ ì„œë¹„ìŠ¤ ë¹„íš¨ìœ¨ì„±ì„ ì´ˆë˜í•œë‹¤.
- 3. MediGenì€ ì˜ë£Œ ëŒ€í™”ë¡œë¶€í„° ì˜ë£Œ ë³´ê³ ì„œë¥¼ ìë™ ìƒì„±í•˜ëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ë¡œ, í–‰ì • ì—…ë¬´ë¥¼ ì¤„ì´ëŠ” ë° ê¸°ì—¬í•  ìˆ˜ ìˆë‹¤.
- 4. MediGenì€ LLaMA3-8B ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ì—¬ ë†’ì€ ì •í™•ë„ë¡œ ì„ìƒ ìƒí˜¸ì‘ìš©ì„ ì „ì‚¬ ë° ìš”ì•½í•œë‹¤.
- 5. MediGenì€ ROUGE ì ìˆ˜ 58%ì™€ BERTScore-F1 72%ë¥¼ ê¸°ë¡í•˜ë©°, ì •í™•í•˜ê³  ì„ìƒì ìœ¼ë¡œ ê´€ë ¨ ìˆëŠ” ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ëŠ” ë° íš¨ê³¼ì ì´ë‹¤.


---

*Generated on 2025-09-25 16:16:42*