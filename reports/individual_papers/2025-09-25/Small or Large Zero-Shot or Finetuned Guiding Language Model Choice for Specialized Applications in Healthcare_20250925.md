---
keywords:
  - Zero-Shot Learning
  - Model Finetuning
  - Domain-Specific Pretraining
  - Small Language Models
  - Large Language Model
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2504.21191
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T16:23:11.777047",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Zero-Shot Learning",
    "Model Finetuning",
    "Domain-Specific Pretraining",
    "Small Language Models",
    "Large Language Model"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Zero-Shot Learning": 0.85,
    "Model Finetuning": 0.82,
    "Domain-Specific Pretraining": 0.78,
    "Small Language Models": 0.77,
    "Large Language Model": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Zero-Shot",
        "canonical": "Zero-Shot Learning",
        "aliases": [
          "Zero-Shot"
        ],
        "category": "specific_connectable",
        "rationale": "Zero-Shot Learning is a trending concept relevant to the model evaluation discussed in the paper.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.72,
        "link_intent_score": 0.85
      },
      {
        "surface": "Finetuning",
        "canonical": "Model Finetuning",
        "aliases": [
          "Finetuning",
          "Fine-tuning"
        ],
        "category": "specific_connectable",
        "rationale": "Model Finetuning is a critical process in enhancing model performance, as emphasized in the study.",
        "novelty_score": 0.55,
        "connectivity_score": 0.83,
        "specificity_score": 0.78,
        "link_intent_score": 0.82
      },
      {
        "surface": "Domain-Specific Pretraining",
        "canonical": "Domain-Specific Pretraining",
        "aliases": [
          "Domain Pretraining"
        ],
        "category": "unique_technical",
        "rationale": "This concept is key for improving model performance on complex tasks with limited data.",
        "novelty_score": 0.65,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Small Language Models",
        "canonical": "Small Language Models",
        "aliases": [
          "SLMs"
        ],
        "category": "unique_technical",
        "rationale": "SLMs are compared to LLMs, highlighting their relevance and trade-offs in specialized applications.",
        "novelty_score": 0.68,
        "connectivity_score": 0.7,
        "specificity_score": 0.82,
        "link_intent_score": 0.77
      },
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "LLMs are a central focus of the study, providing a baseline for performance comparison.",
        "novelty_score": 0.4,
        "connectivity_score": 0.9,
        "specificity_score": 0.65,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "electronic pathology reports",
      "British Columbia Cancer Registry"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Zero-Shot",
      "resolved_canonical": "Zero-Shot Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.72,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Finetuning",
      "resolved_canonical": "Model Finetuning",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.83,
        "specificity": 0.78,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Domain-Specific Pretraining",
      "resolved_canonical": "Domain-Specific Pretraining",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Small Language Models",
      "resolved_canonical": "Small Language Models",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.7,
        "specificity": 0.82,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.9,
        "specificity": 0.65,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Small or Large? Zero-Shot or Finetuned? Guiding Language Model Choice for Specialized Applications in Healthcare

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2504.21191.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2504.21191](https://arxiv.org/abs/2504.21191)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-22/Subjective Behaviors and Preferences in LLM_ Language of Browsing_20250922|Subjective Behaviors and Preferences in LLM: Language of Browsing]] (86.2% similar)
- [[2025-09-22/Predicting Language Models' Success at Zero-Shot Probabilistic Prediction_20250922|Predicting Language Models' Success at Zero-Shot Probabilistic Prediction]] (85.3% similar)
- [[2025-09-23/Mitigating Forgetting in LLM Fine-Tuning via Low-Perplexity Token Learning_20250923|Mitigating Forgetting in LLM Fine-Tuning via Low-Perplexity Token Learning]] (85.2% similar)
- [[2025-09-23/The Sound of Syntax_ Finetuning and Comprehensive Evaluation of Language Models for Speech Pathology_20250923|The Sound of Syntax: Finetuning and Comprehensive Evaluation of Language Models for Speech Pathology]] (85.0% similar)
- [[2025-09-24/Large Language Models Do Multi-Label Classification Differently_20250924|Large Language Models Do Multi-Label Classification Differently]] (84.7% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Zero-Shot Learning|Zero-Shot Learning]], [[keywords/Model Finetuning|Model Finetuning]]
**âš¡ Unique Technical**: [[keywords/Domain-Specific Pretraining|Domain-Specific Pretraining]], [[keywords/Small Language Models|Small Language Models]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2504.21191v2 Announce Type: replace-cross 
Abstract: This study aims to guide language model selection by investigating: 1) the necessity of finetuning versus zero-shot usage, 2) the benefits of domain-adjacent versus generic pretrained models, 3) the value of further domain-specific pretraining, and 4) the continued relevance of Small Language Models (SLMs) compared to Large Language Models (LLMs) for specific tasks. Using electronic pathology reports from the British Columbia Cancer Registry (BCCR), three classification scenarios with varying difficulty and data size are evaluated. Models include various SLMs and an LLM. SLMs are evaluated both zero-shot and finetuned; the LLM is evaluated zero-shot only. Finetuning significantly improved SLM performance across all scenarios compared to their zero-shot results. The zero-shot LLM outperformed zero-shot SLMs but was consistently outperformed by finetuned SLMs. Domain-adjacent SLMs generally performed better than the generic SLM after finetuning, especially on harder tasks. Further domain-specific pretraining yielded modest gains on easier tasks but significant improvements on the complex, data-scarce task. The results highlight the critical role of finetuning for SLMs in specialized domains, enabling them to surpass zero-shot LLM performance on targeted classification tasks. Pretraining on domain-adjacent or domain-specific data provides further advantages, particularly for complex problems or limited finetuning data. While LLMs offer strong zero-shot capabilities, their performance on these specific tasks did not match that of appropriately finetuned SLMs. In the era of LLMs, SLMs remain relevant and effective, offering a potentially superior performance-resource trade-off compared to LLMs.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” ì–¸ì–´ ëª¨ë¸ ì„ íƒì„ ìœ„í•œ ì§€ì¹¨ì„ ì œê³µí•˜ê¸° ìœ„í•´ ë‹¤ì–‘í•œ ì¸¡ë©´ì„ ì¡°ì‚¬í•©ë‹ˆë‹¤. ì£¼ìš” ê¸°ì—¬ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤: 1) íŒŒì¸íŠœë‹ì˜ í•„ìš”ì„±, 2) ë„ë©”ì¸ ì¸ì ‘ ëª¨ë¸ì˜ ì´ì , 3) ë„ë©”ì¸ íŠ¹í™” ì‚¬ì „ í•™ìŠµì˜ ê°€ì¹˜, 4) íŠ¹ì • ì‘ì—…ì—ì„œ ì†Œí˜• ì–¸ì–´ ëª¨ë¸(SLM)ì˜ ì§€ì†ì  ì¤‘ìš”ì„±. ì—°êµ¬ëŠ” British Columbia Cancer Registryì˜ ë³‘ë¦¬ ë³´ê³ ì„œë¥¼ ì‚¬ìš©í•˜ì—¬ ì„¸ ê°€ì§€ ë¶„ë¥˜ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ í‰ê°€í–ˆìŠµë‹ˆë‹¤. SLMì€ ì œë¡œìƒ·ê³¼ íŒŒì¸íŠœë‹ ë°©ì‹ìœ¼ë¡œ í‰ê°€ë˜ì—ˆê³ , ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ ì œë¡œìƒ·ìœ¼ë¡œë§Œ í‰ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. ê²°ê³¼ì ìœ¼ë¡œ, íŒŒì¸íŠœë‹ëœ SLMì€ ëª¨ë“  ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì œë¡œìƒ· SLMê³¼ LLMì„ ëŠ¥ê°€í–ˆìŠµë‹ˆë‹¤. ë„ë©”ì¸ ì¸ì ‘ SLMì€ íŒŒì¸íŠœë‹ í›„ ì¼ë°˜ SLMë³´ë‹¤ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë©°, ë³µì¡í•œ ì‘ì—…ì—ì„œ ë„ë©”ì¸ íŠ¹í™” ì‚¬ì „ í•™ìŠµì´ í° ê°œì„ ì„ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤. ì—°êµ¬ëŠ” SLMì˜ íŒŒì¸íŠœë‹ì´ ì „ë¬¸ ë¶„ì•¼ì—ì„œ ì¤‘ìš”í•˜ë©°, LLMì˜ ì œë¡œìƒ· ì„±ëŠ¥ì„ ì´ˆê³¼í•  ìˆ˜ ìˆìŒì„ ê°•ì¡°í•©ë‹ˆë‹¤. LLMì€ ê°•ë ¥í•œ ì œë¡œìƒ· ê¸°ëŠ¥ì„ ì œê³µí•˜ì§€ë§Œ, ì ì ˆíˆ íŒŒì¸íŠœë‹ëœ SLMì˜ ì„±ëŠ¥ì„ ë”°ë¼ì¡ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. LLM ì‹œëŒ€ì—ë„ SLMì€ ì—¬ì „íˆ ê´€ë ¨ì„±ê³¼ íš¨ìœ¨ì„±ì„ ìœ ì§€í•˜ë©°, ì„±ëŠ¥ê³¼ ìì› íš¨ìœ¨ì„±ì—ì„œ ìš°ìœ„ë¥¼ ì í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. SLMì˜ ë¯¸ì„¸ ì¡°ì •ì€ ëª¨ë“  ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œì¼œ, ì œë¡œìƒ· LLMì„ ëŠ¥ê°€í–ˆìŠµë‹ˆë‹¤.
- 2. ë„ë©”ì¸ ì¸ì ‘ SLMì€ íŠ¹íˆ ì–´ë ¤ìš´ ì‘ì—…ì—ì„œ ì¼ë°˜ SLMë³´ë‹¤ ë¯¸ì„¸ ì¡°ì • í›„ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.
- 3. ë„ë©”ì¸ íŠ¹í™” ì‚¬ì „ í•™ìŠµì€ ë³µì¡í•˜ê³  ë°ì´í„°ê°€ ë¶€ì¡±í•œ ì‘ì—…ì—ì„œ ìƒë‹¹í•œ ê°œì„ ì„ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.
- 4. LLMì€ ê°•ë ¥í•œ ì œë¡œìƒ· ì„±ëŠ¥ì„ ì œê³µí•˜ì§€ë§Œ, ì ì ˆíˆ ë¯¸ì„¸ ì¡°ì •ëœ SLMì˜ ì„±ëŠ¥ì—ëŠ” ë¯¸ì¹˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.
- 5. LLM ì‹œëŒ€ì—ë„ SLMì€ ì—¬ì „íˆ ê´€ë ¨ì„±ì´ ìˆìœ¼ë©°, ì„±ëŠ¥-ìì› ê· í˜•ì—ì„œ LLMë³´ë‹¤ ìš°ìˆ˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-25 16:23:11*