---
keywords:
  - DeepACTIF
  - Feature Attribution
  - LSTM
  - Biometric Data
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2509.19362
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T15:29:58.370026",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "DeepACTIF",
    "Feature Attribution",
    "LSTM",
    "Biometric Data"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "DeepACTIF": 0.85,
    "Feature Attribution": 0.8,
    "LSTM": 0.82,
    "Biometric Data": 0.78
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "DeepACTIF",
        "canonical": "DeepACTIF",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "DeepACTIF is a novel feature attribution method specifically designed for neural sequence models, making it a unique technical contribution.",
        "novelty_score": 0.95,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.85
      },
      {
        "surface": "feature attribution",
        "canonical": "Feature Attribution",
        "aliases": [
          "feature importance"
        ],
        "category": "broad_technical",
        "rationale": "Feature attribution is a fundamental concept in interpreting deep learning models, linking to various methods and applications.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "LSTM-based networks",
        "canonical": "LSTM",
        "aliases": [
          "Long Short-Term Memory"
        ],
        "category": "specific_connectable",
        "rationale": "LSTM is a widely used neural network architecture for sequence modeling, providing strong connectivity to time-series applications.",
        "novelty_score": 0.3,
        "connectivity_score": 0.9,
        "specificity_score": 0.85,
        "link_intent_score": 0.82
      },
      {
        "surface": "biometric gaze datasets",
        "canonical": "Biometric Data",
        "aliases": [
          "gaze tracking"
        ],
        "category": "specific_connectable",
        "rationale": "Biometric data, particularly gaze tracking, is crucial for applications in healthcare and human-AI interaction, offering specific connectivity.",
        "novelty_score": 0.55,
        "connectivity_score": 0.75,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "DeepACTIF",
      "resolved_canonical": "DeepACTIF",
      "decision": "linked",
      "scores": {
        "novelty": 0.95,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "feature attribution",
      "resolved_canonical": "Feature Attribution",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "LSTM-based networks",
      "resolved_canonical": "LSTM",
      "decision": "linked",
      "scores": {
        "novelty": 0.3,
        "connectivity": 0.9,
        "specificity": 0.85,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "biometric gaze datasets",
      "resolved_canonical": "Biometric Data",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.75,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    }
  ]
}
-->

# DeepACTIF: Efficient Feature Attribution via Activation Traces in Neural Sequence Models

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19362.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2509.19362](https://arxiv.org/abs/2509.19362)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-24/HadaSmileNet_ Hadamard fusion of handcrafted and deep-learning features for enhancing facial emotion recognition of genuine smiles_20250924|HadaSmileNet: Hadamard fusion of handcrafted and deep-learning features for enhancing facial emotion recognition of genuine smiles]] (81.8% similar)
- [[2025-09-23/Incorporating the Refractory Period into Spiking Neural Networks through Spike-Triggered Threshold Dynamics_20250923|Incorporating the Refractory Period into Spiking Neural Networks through Spike-Triggered Threshold Dynamics]] (81.5% similar)
- [[2025-09-23/AHA -- Predicting What Matters Next_ Online Highlight Detection Without Looking Ahead_20250923|AHA -- Predicting What Matters Next: Online Highlight Detection Without Looking Ahead]] (81.4% similar)
- [[2025-09-22/Emulating Human-like Adaptive Vision for Efficient and Flexible Machine Visual Perception_20250922|Emulating Human-like Adaptive Vision for Efficient and Flexible Machine Visual Perception]] (81.4% similar)
- [[2025-09-23/DynSTG-Mamba_ Dynamic Spatio-Temporal Graph Mamba with Cross-Graph Knowledge Distillation for Gait Disorders Recognition_20250923|DynSTG-Mamba: Dynamic Spatio-Temporal Graph Mamba with Cross-Graph Knowledge Distillation for Gait Disorders Recognition]] (81.2% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Feature Attribution|Feature Attribution]]
**ğŸ”— Specific Connectable**: [[keywords/LSTM|LSTM]], [[keywords/Biometric Data|Biometric Data]]
**âš¡ Unique Technical**: [[keywords/DeepACTIF|DeepACTIF]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19362v1 Announce Type: cross 
Abstract: Feature attribution is essential for interpreting deep learning models, particularly in time-series domains such as healthcare, biometrics, and human-AI interaction. However, standard attribution methods, such as Integrated Gradients or SHAP, are computationally intensive and not well-suited for real-time applications. We present DeepACTIF, a lightweight and architecture-aware feature attribution method that leverages internal activations of sequence models to estimate feature importance efficiently. Focusing on LSTM-based networks, we introduce an inverse-weighted aggregation scheme that emphasises stability and magnitude of activations across time steps. Our evaluation across three biometric gaze datasets shows that DeepACTIF not only preserves predictive performance under severe feature reduction (top 10% of features) but also significantly outperforms established methods, including SHAP, IG, and DeepLIFT, in terms of both accuracy and statistical robustness. Using Wilcoxon signed-rank tests and effect size analysis, we demonstrate that DeepACTIF yields more informative feature rankings with significantly lower error across all top-k conditions (10 - 40%). Our experiments demonstrate that DeepACTIF not only reduces computation time and memory usage by orders of magnitude but also preserves model accuracy when using only top-ranked features. That makes DeepACTIF a viable solution for real-time interpretability on edge devices such as mobile XR headsets or embedded health monitors.

## ğŸ“ ìš”ì•½

DeepACTIFëŠ” ì‹œí€€ìŠ¤ ëª¨ë¸ì˜ ë‚´ë¶€ í™œì„±í™”ë¥¼ í™œìš©í•˜ì—¬ íš¨ìœ¨ì ìœ¼ë¡œ íŠ¹ì§• ì¤‘ìš”ë„ë¥¼ ì¶”ì •í•˜ëŠ” ê²½ëŸ‰ì˜ ì•„í‚¤í…ì²˜ ì¸ì‹ íŠ¹ì§• ê·€ì† ë°©ë²•ì…ë‹ˆë‹¤. LSTM ê¸°ë°˜ ë„¤íŠ¸ì›Œí¬ì— ì´ˆì ì„ ë§ì¶”ì–´, ì‹œê°„ ë‹¨ê³„ì— ê±¸ì³ í™œì„±í™”ì˜ ì•ˆì •ì„±ê³¼ í¬ê¸°ë¥¼ ê°•ì¡°í•˜ëŠ” ì—­ê°€ì¤‘ ì§‘ê³„ ë°©ì‹ì„ ë„ì…í–ˆìŠµë‹ˆë‹¤. ì„¸ ê°€ì§€ ìƒì²´ ì¸ì‹ ì‹œì„  ë°ì´í„°ì…‹ì—ì„œì˜ í‰ê°€ ê²°ê³¼, DeepACTIFëŠ” ì˜ˆì¸¡ ì„±ëŠ¥ì„ ìœ ì§€í•˜ë©´ì„œë„ ê¸°ì¡´ ë°©ë²•ë³´ë‹¤ ë†’ì€ ì •í™•ì„±ê³¼ í†µê³„ì  ê²¬ê³ ì„±ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤. ë˜í•œ, ê³„ì‚° ì‹œê°„ê³¼ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ í¬ê²Œ ì¤„ì´ë©´ì„œë„ ìƒìœ„ íŠ¹ì§•ë§Œì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ ì •í™•ì„±ì„ ìœ ì§€í•˜ì—¬, ëª¨ë°”ì¼ XR í—¤ë“œì…‹ì´ë‚˜ ì„ë² ë””ë“œ ê±´ê°• ëª¨ë‹ˆí„°ì™€ ê°™ì€ ì—£ì§€ ë””ë°”ì´ìŠ¤ì—ì„œ ì‹¤ì‹œê°„ í•´ì„ ê°€ëŠ¥ì„±ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. DeepACTIFëŠ” ê²½ëŸ‰í™”ëœ êµ¬ì¡° ì¸ì‹ ê¸°ëŠ¥ ê·€ì† ë°©ë²•ìœ¼ë¡œ, ì‹œí€€ìŠ¤ ëª¨ë¸ì˜ ë‚´ë¶€ í™œì„±í™”ë¥¼ í™œìš©í•˜ì—¬ ê¸°ëŠ¥ ì¤‘ìš”ì„±ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì¶”ì •í•©ë‹ˆë‹¤.
- 2. LSTM ê¸°ë°˜ ë„¤íŠ¸ì›Œí¬ì— ì´ˆì ì„ ë§ì¶°, ì‹œê°„ ë‹¨ê³„ ì „ë°˜ì— ê±¸ì³ í™œì„±í™”ì˜ ì•ˆì •ì„±ê³¼ í¬ê¸°ë¥¼ ê°•ì¡°í•˜ëŠ” ì—­ê°€ì¤‘ ì§‘ê³„ ë°©ì‹ì„ ë„ì…í–ˆìŠµë‹ˆë‹¤.
- 3. DeepACTIFëŠ” ìƒì²´ ì¸ì‹ ì‘ì‹œ ë°ì´í„°ì…‹ì—ì„œ ì˜ˆì¸¡ ì„±ëŠ¥ì„ ìœ ì§€í•˜ë©´ì„œë„ SHAP, IG, DeepLIFT ë“± ê¸°ì¡´ ë°©ë²•ë³´ë‹¤ ì •í™•ì„±ê³¼ í†µê³„ì  ê°•ê±´ì„±ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.
- 4. Wilcoxon ë¶€í˜¸ ìˆœìœ„ ê²€ì •ê³¼ íš¨ê³¼ í¬ê¸° ë¶„ì„ì„ í†µí•´, DeepACTIFê°€ ëª¨ë“  ìƒìœ„-k ì¡°ê±´ì—ì„œ ë” ì •ë³´ì„± ìˆëŠ” ê¸°ëŠ¥ ìˆœìœ„ë¥¼ ì œê³µí•˜ë©° ì˜¤ë¥˜ê°€ í˜„ì €íˆ ë‚®ìŒì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.
- 5. DeepACTIFëŠ” ê³„ì‚° ì‹œê°„ê³¼ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ëŒ€í­ ì¤„ì´ë©´ì„œë„ ìƒìœ„ ìˆœìœ„ ê¸°ëŠ¥ë§Œ ì‚¬ìš©í•  ë•Œ ëª¨ë¸ ì •í™•ì„±ì„ ìœ ì§€í•˜ì—¬, ëª¨ë°”ì¼ XR í—¤ë“œì…‹ì´ë‚˜ ì„ë² ë””ë“œ ê±´ê°• ëª¨ë‹ˆí„°ì™€ ê°™ì€ ì—£ì§€ ë””ë°”ì´ìŠ¤ì—ì„œ ì‹¤ì‹œê°„ í•´ì„ ê°€ëŠ¥ì„±ì„ ì œê³µí•©ë‹ˆë‹¤.


---

*Generated on 2025-09-25 15:29:58*