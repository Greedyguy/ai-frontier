---
keywords:
  - Subjective Video Quality Assessment
  - Crowdsourcing Platforms
  - Remote-Desktop Connections
  - Video Metadata Exploits
category: cs.CV
publish_date: 2025-09-25
arxiv_id: 2509.20001
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-26T09:18:45.498415",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Subjective Video Quality Assessment",
    "Crowdsourcing Platforms",
    "Remote-Desktop Connections",
    "Video Metadata Exploits"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Subjective Video Quality Assessment": 0.78,
    "Crowdsourcing Platforms": 0.8,
    "Remote-Desktop Connections": 0.75,
    "Video Metadata Exploits": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Subjective Video Quality Assessment",
        "canonical": "Subjective Video Quality Assessment",
        "aliases": [
          "VQA"
        ],
        "category": "unique_technical",
        "rationale": "This is a specific method central to the paper's focus, offering unique insights into video quality evaluation.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Crowdsourcing Platforms",
        "canonical": "Crowdsourcing Platforms",
        "aliases": [
          "Crowdsourcing"
        ],
        "category": "specific_connectable",
        "rationale": "Crowdsourcing is a key method discussed in the paper, relevant to studies on distributed data collection.",
        "novelty_score": 0.55,
        "connectivity_score": 0.82,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Remote-Desktop Connections",
        "canonical": "Remote-Desktop Connections",
        "aliases": [
          "RD Connections"
        ],
        "category": "unique_technical",
        "rationale": "This term highlights a specific technical challenge in the context of video quality testing.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.78,
        "link_intent_score": 0.75
      },
      {
        "surface": "Video Metadata Exploits",
        "canonical": "Video Metadata Exploits",
        "aliases": [
          "Metadata Exploits"
        ],
        "category": "unique_technical",
        "rationale": "This term identifies a specific issue affecting the reliability of video quality assessments.",
        "novelty_score": 0.65,
        "connectivity_score": 0.55,
        "specificity_score": 0.8,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Subjective Video Quality Assessment",
      "resolved_canonical": "Subjective Video Quality Assessment",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Crowdsourcing Platforms",
      "resolved_canonical": "Crowdsourcing Platforms",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.82,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Remote-Desktop Connections",
      "resolved_canonical": "Remote-Desktop Connections",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.78,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Video Metadata Exploits",
      "resolved_canonical": "Video Metadata Exploits",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.55,
        "specificity": 0.8,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# Ensuring Reliable Participation in Subjective Video Quality Tests Across Platforms

## 📋 메타데이터

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.20001.pdf)
**Category**: cs.CV
**Published**: 2025-09-25
**ArXiv ID**: [2509.20001](https://arxiv.org/abs/2509.20001)

## 🔗 유사한 논문
- [[2025-09-23/Advancing Reference-free Evaluation of Video Captions with Factual Analysis_20250923|Advancing Reference-free Evaluation of Video Captions with Factual Analysis]] (81.7% similar)
- [[2025-09-23/ProtoVQA_ An Adaptable Prototypical Framework for Explainable Fine-Grained Visual Question Answering_20250923|ProtoVQA: An Adaptable Prototypical Framework for Explainable Fine-Grained Visual Question Answering]] (80.2% similar)
- [[2025-09-22/RAVE_ Retrieval and Scoring Aware Verifiable Claim Detection_20250922|RAVE: Retrieval and Scoring Aware Verifiable Claim Detection]] (80.1% similar)
- [[2025-09-22/Quality-Driven Curation of Remote Sensing Vision-Language Data via Learned Scoring Models_20250922|Quality-Driven Curation of Remote Sensing Vision-Language Data via Learned Scoring Models]] (79.9% similar)
- [[2025-09-22/DPC-QA Net_ A No-Reference Dual-Stream Perceptual and Cellular Quality Assessment Network for Histopathology Images_20250922|DPC-QA Net: A No-Reference Dual-Stream Perceptual and Cellular Quality Assessment Network for Histopathology Images]] (79.9% similar)

## 🏷️ 카테고리화된 키워드
**🔗 Specific Connectable**: [[keywords/Crowdsourcing Platforms|Crowdsourcing Platforms]]
**⚡ Unique Technical**: [[keywords/Subjective Video Quality Assessment|Subjective Video Quality Assessment]], [[keywords/Remote-Desktop Connections|Remote-Desktop Connections]], [[keywords/Video Metadata Exploits|Video Metadata Exploits]]

## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.20001v1 Announce Type: cross 
Abstract: Subjective video quality assessment (VQA) is the gold standard for measuring end-user experience across communication, streaming, and UGC pipelines. Beyond high-validity lab studies, crowdsourcing offers accurate, reliable, faster, and cheaper evaluation-but suffers from unreliable submissions by workers who ignore instructions or game rewards. Recent tests reveal sophisticated exploits of video metadata and rising use of remote-desktop (RD) connections, both of which bias results. We propose objective and subjective detectors for RD users and compare two mainstream crowdsourcing platforms on their susceptibility and mitigation under realistic test conditions and task designs.

## 📝 요약

이 논문은 주관적 비디오 품질 평가(VQA)의 신뢰성을 높이기 위한 연구를 다룹니다. VQA는 사용자 경험을 측정하는 데 중요한 역할을 하지만, 크라우드소싱을 통한 평가에서는 작업자들의 부정확한 제출로 인해 문제가 발생합니다. 특히, 비디오 메타데이터의 악용과 원격 데스크톱(RD) 연결의 사용이 결과에 편향을 일으키고 있습니다. 이에 대해, RD 사용자를 감지할 수 있는 객관적 및 주관적 탐지기를 제안하고, 두 주요 크라우드소싱 플랫폼의 취약성과 이를 완화하는 방법을 비교 분석했습니다.

## 🎯 주요 포인트

- 1. 주관적 비디오 품질 평가(VQA)는 사용자 경험을 측정하는 데 있어 표준으로 사용된다.
- 2. 크라우드소싱은 빠르고 저렴한 평가를 제공하지만, 지침을 무시하거나 보상을 노리는 작업자들로 인해 신뢰할 수 없는 제출물이 발생할 수 있다.
- 3. 최근 테스트에서는 비디오 메타데이터의 악용과 원격 데스크톱(RD) 연결의 사용 증가가 결과에 편향을 줄 수 있음을 보여준다.
- 4. RD 사용자 탐지를 위한 객관적 및 주관적 탐지기를 제안하고, 두 가지 주요 크라우드소싱 플랫폼의 취약성과 완화 방안을 비교한다.


---

*Generated on 2025-09-26 09:18:45*