---
keywords:
  - Subjective Video Quality Assessment
  - Crowdsourcing Platforms
  - Remote-Desktop Connections
  - Video Metadata Exploits
category: cs.CV
publish_date: 2025-09-25
arxiv_id: 2509.20001
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-26T09:18:45.498415",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Subjective Video Quality Assessment",
    "Crowdsourcing Platforms",
    "Remote-Desktop Connections",
    "Video Metadata Exploits"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Subjective Video Quality Assessment": 0.78,
    "Crowdsourcing Platforms": 0.8,
    "Remote-Desktop Connections": 0.75,
    "Video Metadata Exploits": 0.72
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Subjective Video Quality Assessment",
        "canonical": "Subjective Video Quality Assessment",
        "aliases": [
          "VQA"
        ],
        "category": "unique_technical",
        "rationale": "This is a specific method central to the paper's focus, offering unique insights into video quality evaluation.",
        "novelty_score": 0.75,
        "connectivity_score": 0.68,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Crowdsourcing Platforms",
        "canonical": "Crowdsourcing Platforms",
        "aliases": [
          "Crowdsourcing"
        ],
        "category": "specific_connectable",
        "rationale": "Crowdsourcing is a key method discussed in the paper, relevant to studies on distributed data collection.",
        "novelty_score": 0.55,
        "connectivity_score": 0.82,
        "specificity_score": 0.7,
        "link_intent_score": 0.8
      },
      {
        "surface": "Remote-Desktop Connections",
        "canonical": "Remote-Desktop Connections",
        "aliases": [
          "RD Connections"
        ],
        "category": "unique_technical",
        "rationale": "This term highlights a specific technical challenge in the context of video quality testing.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.78,
        "link_intent_score": 0.75
      },
      {
        "surface": "Video Metadata Exploits",
        "canonical": "Video Metadata Exploits",
        "aliases": [
          "Metadata Exploits"
        ],
        "category": "unique_technical",
        "rationale": "This term identifies a specific issue affecting the reliability of video quality assessments.",
        "novelty_score": 0.65,
        "connectivity_score": 0.55,
        "specificity_score": 0.8,
        "link_intent_score": 0.72
      }
    ],
    "ban_list_suggestions": [
      "method",
      "experiment",
      "performance"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Subjective Video Quality Assessment",
      "resolved_canonical": "Subjective Video Quality Assessment",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.68,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Crowdsourcing Platforms",
      "resolved_canonical": "Crowdsourcing Platforms",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.82,
        "specificity": 0.7,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Remote-Desktop Connections",
      "resolved_canonical": "Remote-Desktop Connections",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.78,
        "link_intent": 0.75
      }
    },
    {
      "candidate_surface": "Video Metadata Exploits",
      "resolved_canonical": "Video Metadata Exploits",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.55,
        "specificity": 0.8,
        "link_intent": 0.72
      }
    }
  ]
}
-->

# Ensuring Reliable Participation in Subjective Video Quality Tests Across Platforms

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.CV|cs.CV]]
**PDF**: [Download](https://arxiv.org/pdf/2509.20001.pdf)
**Category**: cs.CV
**Published**: 2025-09-25
**ArXiv ID**: [2509.20001](https://arxiv.org/abs/2509.20001)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Advancing Reference-free Evaluation of Video Captions with Factual Analysis_20250923|Advancing Reference-free Evaluation of Video Captions with Factual Analysis]] (81.7% similar)
- [[2025-09-23/ProtoVQA_ An Adaptable Prototypical Framework for Explainable Fine-Grained Visual Question Answering_20250923|ProtoVQA: An Adaptable Prototypical Framework for Explainable Fine-Grained Visual Question Answering]] (80.2% similar)
- [[2025-09-22/RAVE_ Retrieval and Scoring Aware Verifiable Claim Detection_20250922|RAVE: Retrieval and Scoring Aware Verifiable Claim Detection]] (80.1% similar)
- [[2025-09-22/Quality-Driven Curation of Remote Sensing Vision-Language Data via Learned Scoring Models_20250922|Quality-Driven Curation of Remote Sensing Vision-Language Data via Learned Scoring Models]] (79.9% similar)
- [[2025-09-22/DPC-QA Net_ A No-Reference Dual-Stream Perceptual and Cellular Quality Assessment Network for Histopathology Images_20250922|DPC-QA Net: A No-Reference Dual-Stream Perceptual and Cellular Quality Assessment Network for Histopathology Images]] (79.9% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Crowdsourcing Platforms|Crowdsourcing Platforms]]
**âš¡ Unique Technical**: [[keywords/Subjective Video Quality Assessment|Subjective Video Quality Assessment]], [[keywords/Remote-Desktop Connections|Remote-Desktop Connections]], [[keywords/Video Metadata Exploits|Video Metadata Exploits]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.20001v1 Announce Type: cross 
Abstract: Subjective video quality assessment (VQA) is the gold standard for measuring end-user experience across communication, streaming, and UGC pipelines. Beyond high-validity lab studies, crowdsourcing offers accurate, reliable, faster, and cheaper evaluation-but suffers from unreliable submissions by workers who ignore instructions or game rewards. Recent tests reveal sophisticated exploits of video metadata and rising use of remote-desktop (RD) connections, both of which bias results. We propose objective and subjective detectors for RD users and compare two mainstream crowdsourcing platforms on their susceptibility and mitigation under realistic test conditions and task designs.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì£¼ê´€ì  ë¹„ë””ì˜¤ í’ˆì§ˆ í‰ê°€(VQA)ì˜ ì‹ ë¢°ì„±ì„ ë†’ì´ê¸° ìœ„í•œ ì—°êµ¬ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. VQAëŠ” ì‚¬ìš©ì ê²½í—˜ì„ ì¸¡ì •í•˜ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í•˜ì§€ë§Œ, í¬ë¼ìš°ë“œì†Œì‹±ì„ í†µí•œ í‰ê°€ì—ì„œëŠ” ì‘ì—…ìë“¤ì˜ ë¶€ì •í™•í•œ ì œì¶œë¡œ ì¸í•´ ë¬¸ì œê°€ ë°œìƒí•©ë‹ˆë‹¤. íŠ¹íˆ, ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„°ì˜ ì•…ìš©ê³¼ ì›ê²© ë°ìŠ¤í¬í†±(RD) ì—°ê²°ì˜ ì‚¬ìš©ì´ ê²°ê³¼ì— í¸í–¥ì„ ì¼ìœ¼í‚¤ê³  ìˆìŠµë‹ˆë‹¤. ì´ì— ëŒ€í•´, RD ì‚¬ìš©ìë¥¼ ê°ì§€í•  ìˆ˜ ìˆëŠ” ê°ê´€ì  ë° ì£¼ê´€ì  íƒì§€ê¸°ë¥¼ ì œì•ˆí•˜ê³ , ë‘ ì£¼ìš” í¬ë¼ìš°ë“œì†Œì‹± í”Œë«í¼ì˜ ì·¨ì•½ì„±ê³¼ ì´ë¥¼ ì™„í™”í•˜ëŠ” ë°©ë²•ì„ ë¹„êµ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ì£¼ê´€ì  ë¹„ë””ì˜¤ í’ˆì§ˆ í‰ê°€(VQA)ëŠ” ì‚¬ìš©ì ê²½í—˜ì„ ì¸¡ì •í•˜ëŠ” ë° ìˆì–´ í‘œì¤€ìœ¼ë¡œ ì‚¬ìš©ëœë‹¤.
- 2. í¬ë¼ìš°ë“œì†Œì‹±ì€ ë¹ ë¥´ê³  ì €ë ´í•œ í‰ê°€ë¥¼ ì œê³µí•˜ì§€ë§Œ, ì§€ì¹¨ì„ ë¬´ì‹œí•˜ê±°ë‚˜ ë³´ìƒì„ ë…¸ë¦¬ëŠ” ì‘ì—…ìë“¤ë¡œ ì¸í•´ ì‹ ë¢°í•  ìˆ˜ ì—†ëŠ” ì œì¶œë¬¼ì´ ë°œìƒí•  ìˆ˜ ìˆë‹¤.
- 3. ìµœê·¼ í…ŒìŠ¤íŠ¸ì—ì„œëŠ” ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„°ì˜ ì•…ìš©ê³¼ ì›ê²© ë°ìŠ¤í¬í†±(RD) ì—°ê²°ì˜ ì‚¬ìš© ì¦ê°€ê°€ ê²°ê³¼ì— í¸í–¥ì„ ì¤„ ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤€ë‹¤.
- 4. RD ì‚¬ìš©ì íƒì§€ë¥¼ ìœ„í•œ ê°ê´€ì  ë° ì£¼ê´€ì  íƒì§€ê¸°ë¥¼ ì œì•ˆí•˜ê³ , ë‘ ê°€ì§€ ì£¼ìš” í¬ë¼ìš°ë“œì†Œì‹± í”Œë«í¼ì˜ ì·¨ì•½ì„±ê³¼ ì™„í™” ë°©ì•ˆì„ ë¹„êµí•œë‹¤.


---

*Generated on 2025-09-26 09:18:45*