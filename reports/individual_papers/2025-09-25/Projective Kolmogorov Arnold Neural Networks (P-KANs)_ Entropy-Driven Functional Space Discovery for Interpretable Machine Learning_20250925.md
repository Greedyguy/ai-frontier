---
keywords:
  - Kolmogorov-Arnold Networks
  - Projective Kolmogorov-Arnold Networks
  - Entropy Minimization
  - Sparse Dictionary Learning
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2509.20049
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T15:57:25.431579",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Kolmogorov-Arnold Networks",
    "Projective Kolmogorov-Arnold Networks",
    "Entropy Minimization",
    "Sparse Dictionary Learning"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Kolmogorov-Arnold Networks": 0.78,
    "Projective Kolmogorov-Arnold Networks": 0.82,
    "Entropy Minimization": 0.77,
    "Sparse Dictionary Learning": 0.79
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Kolmogorov-Arnold Networks",
        "canonical": "Kolmogorov-Arnold Networks",
        "aliases": [
          "KANs"
        ],
        "category": "unique_technical",
        "rationale": "Kolmogorov-Arnold Networks are central to the paper's methodology and offer a unique approach to neural network design.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.85,
        "link_intent_score": 0.78
      },
      {
        "surface": "Projective Kolmogorov-Arnold Networks",
        "canonical": "Projective Kolmogorov-Arnold Networks",
        "aliases": [
          "P-KANs"
        ],
        "category": "unique_technical",
        "rationale": "P-KANs represent a novel extension of KANs with specific improvements in interpretability and efficiency.",
        "novelty_score": 0.8,
        "connectivity_score": 0.7,
        "specificity_score": 0.88,
        "link_intent_score": 0.82
      },
      {
        "surface": "Entropy-minimisation",
        "canonical": "Entropy Minimization",
        "aliases": [
          "Entropy Reduction"
        ],
        "category": "specific_connectable",
        "rationale": "Entropy minimization is a key technique used in the paper to guide functional representation discovery.",
        "novelty_score": 0.65,
        "connectivity_score": 0.75,
        "specificity_score": 0.78,
        "link_intent_score": 0.77
      },
      {
        "surface": "Sparse Dictionary Learning",
        "canonical": "Sparse Dictionary Learning",
        "aliases": [
          "Sparse Coding"
        ],
        "category": "specific_connectable",
        "rationale": "Sparse dictionary learning is integral to the paper's method for achieving efficient functional representations.",
        "novelty_score": 0.68,
        "connectivity_score": 0.72,
        "specificity_score": 0.8,
        "link_intent_score": 0.79
      }
    ],
    "ban_list_suggestions": [
      "method",
      "performance",
      "experiment"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Kolmogorov-Arnold Networks",
      "resolved_canonical": "Kolmogorov-Arnold Networks",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.85,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Projective Kolmogorov-Arnold Networks",
      "resolved_canonical": "Projective Kolmogorov-Arnold Networks",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.7,
        "specificity": 0.88,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Entropy-minimisation",
      "resolved_canonical": "Entropy Minimization",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.75,
        "specificity": 0.78,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Sparse Dictionary Learning",
      "resolved_canonical": "Sparse Dictionary Learning",
      "decision": "linked",
      "scores": {
        "novelty": 0.68,
        "connectivity": 0.72,
        "specificity": 0.8,
        "link_intent": 0.79
      }
    }
  ]
}
-->

# Projective Kolmogorov Arnold Neural Networks (P-KANs): Entropy-Driven Functional Space Discovery for Interpretable Machine Learning

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2509.20049.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2509.20049](https://arxiv.org/abs/2509.20049)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-25/On the Rate of Convergence of Kolmogorov-Arnold Network Regression Estimators_20250925|On the Rate of Convergence of Kolmogorov-Arnold Network Regression Estimators]] (89.1% similar)
- [[2025-09-23/Interpretable Clinical Classification with Kolgomorov-Arnold Networks_20250923|Interpretable Clinical Classification with Kolgomorov-Arnold Networks]] (86.6% similar)
- [[2025-09-24/Physics-informed time series analysis with Kolmogorov-Arnold Networks under Ehrenfest constraints_20250924|Physics-informed time series analysis with Kolmogorov-Arnold Networks under Ehrenfest constraints]] (86.1% similar)
- [[2025-09-18/Taylor-Series Expanded Kolmogorov-Arnold Network for Medical Imaging Classification_20250918|Taylor-Series Expanded Kolmogorov-Arnold Network for Medical Imaging Classification]] (83.8% similar)
- [[2025-09-23/KANO_ Kolmogorov-Arnold Neural Operator_20250923|KANO: Kolmogorov-Arnold Neural Operator]] (83.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Entropy Minimization|Entropy Minimization]], [[keywords/Sparse Dictionary Learning|Sparse Dictionary Learning]]
**âš¡ Unique Technical**: [[keywords/Kolmogorov-Arnold Networks|Kolmogorov-Arnold Networks]], [[keywords/Projective Kolmogorov-Arnold Networks|Projective Kolmogorov-Arnold Networks]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.20049v1 Announce Type: cross 
Abstract: Kolmogorov-Arnold Networks (KANs) relocate learnable nonlinearities from nodes to edges, demonstrating remarkable capabilities in scientific machine learning and interpretable modeling. However, current KAN implementations suffer from fundamental inefficiencies due to redundancy in high-dimensional spline parameter spaces, where numerous distinct parameterisations yield functionally equivalent behaviors. This redundancy manifests as a "nuisance space" in the model's Jacobian, leading to susceptibility to overfitting and poor generalization. We introduce Projective Kolmogorov-Arnold Networks (P-KANs), a novel training framework that guides edge function discovery towards interpretable functional representations through entropy-minimisation techniques from signal analysis and sparse dictionary learning. Rather than constraining functions to predetermined spaces, our approach maintains spline space flexibility while introducing "gravitational" terms that encourage convergence towards optimal functional representations. Our key insight recognizes that optimal representations can be identified through entropy analysis of projection coefficients, compressing edge functions to lower-parameter projective spaces (Fourier, Chebyshev, Bessel). P-KANs demonstrate superior performance across multiple domains, achieving up to 80% parameter reduction while maintaining representational capacity, significantly improved robustness to noise compared to standard KANs, and successful application to industrial automated fiber placement prediction. Our approach enables automatic discovery of mixed functional representations where different edges converge to different optimal spaces, providing both compression benefits and enhanced interpretability for scientific machine learning applications.

## ğŸ“ ìš”ì•½

Kolmogorov-Arnold Networks(KANs)ëŠ” ë¹„ì„ í˜•ì„±ì„ ì—£ì§€ë¡œ ì´ë™ì‹œì¼œ ê³¼í•™ì  ë¨¸ì‹ ëŸ¬ë‹ê³¼ í•´ì„ ê°€ëŠ¥í•œ ëª¨ë¸ë§ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê¸°ì¡´ KANì€ ê³ ì°¨ì› ìŠ¤í”Œë¼ì¸ ë§¤ê°œë³€ìˆ˜ ê³µê°„ì˜ ì¤‘ë³µì„±ìœ¼ë¡œ ì¸í•´ ë¹„íš¨ìœ¨ì ì…ë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ìš°ë¦¬ëŠ” Projective Kolmogorov-Arnold Networks(P-KANs)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. P-KANsëŠ” ì‹ í˜¸ ë¶„ì„ê³¼ í¬ì†Œ ì‚¬ì „ í•™ìŠµì˜ ì—”íŠ¸ë¡œí”¼ ìµœì†Œí™” ê¸°ë²•ì„ í†µí•´ í•´ì„ ê°€ëŠ¥í•œ í•¨ìˆ˜ í‘œí˜„ì„ ìœ ë„í•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ìŠ¤í”Œë¼ì¸ ê³µê°„ì˜ ìœ ì—°ì„±ì„ ìœ ì§€í•˜ë©´ì„œ ìµœì ì˜ í•¨ìˆ˜ í‘œí˜„ìœ¼ë¡œ ìˆ˜ë ´í•˜ë„ë¡ ìœ ë„í•˜ëŠ” "ì¤‘ë ¥" í•­ì„ ë„ì…í•©ë‹ˆë‹¤. ìš°ë¦¬ì˜ ì£¼ìš” ë°œê²¬ì€ íˆ¬ì˜ ê³„ìˆ˜ì˜ ì—”íŠ¸ë¡œí”¼ ë¶„ì„ì„ í†µí•´ ìµœì ì˜ í‘œí˜„ì„ ì‹ë³„í•˜ê³ , ì—£ì§€ í•¨ìˆ˜ë¥¼ ì €ì°¨ì› íˆ¬ì˜ ê³µê°„ìœ¼ë¡œ ì••ì¶•í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. P-KANsëŠ” ì—¬ëŸ¬ ë¶„ì•¼ì—ì„œ ìµœëŒ€ 80%ì˜ ë§¤ê°œë³€ìˆ˜ ê°ì†Œì™€ í•¨ê»˜ í‘œì¤€ KANsë³´ë‹¤ ë›°ì–´ë‚œ ë…¸ì´ì¦ˆì— ëŒ€í•œ ê°•ê±´ì„±ì„ ë³´ì—¬ì£¼ë©°, ì‚°ì—… ìë™í™” ì„¬ìœ  ë°°ì¹˜ ì˜ˆì¸¡ì— ì„±ê³µì ìœ¼ë¡œ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ì ‘ê·¼ë²•ì€ ë‹¤ì–‘í•œ ì—£ì§€ê°€ ì„œë¡œ ë‹¤ë¥¸ ìµœì  ê³µê°„ìœ¼ë¡œ ìˆ˜ë ´í•˜ë„ë¡ í•˜ì—¬ ê³¼í•™ì  ë¨¸ì‹ ëŸ¬ë‹ ì‘ìš©ì— ëŒ€í•œ ì••ì¶• ì´ì ê³¼ í•´ì„ ê°€ëŠ¥ì„±ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. Kolmogorov-Arnold Networks(KANs)ëŠ” ë…¸ë“œ ëŒ€ì‹  ì—£ì§€ì— í•™ìŠµ ê°€ëŠ¥í•œ ë¹„ì„ í˜•ì„±ì„ ë°°ì¹˜í•˜ì—¬ ê³¼í•™ì  ë¨¸ì‹ ëŸ¬ë‹ê³¼ í•´ì„ ê°€ëŠ¥í•œ ëª¨ë¸ë§ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
- 2. ê¸°ì¡´ KAN êµ¬í˜„ì€ ê³ ì°¨ì› ìŠ¤í”Œë¼ì¸ ë§¤ê°œë³€ìˆ˜ ê³µê°„ì˜ ì¤‘ë³µì„±ìœ¼ë¡œ ì¸í•´ ë¹„íš¨ìœ¨ì„±ì„ ê²ªê³  ìˆìœ¼ë©°, ì´ëŠ” ëª¨ë¸ì˜ Jacobianì—ì„œ "ì¥ì•  ê³µê°„"ìœ¼ë¡œ ë‚˜íƒ€ë‚˜ ê³¼ì í•©ê³¼ ì¼ë°˜í™” ë¬¸ì œë¥¼ ìœ ë°œí•©ë‹ˆë‹¤.
- 3. Projective Kolmogorov-Arnold Networks(P-KANs)ëŠ” ì‹ í˜¸ ë¶„ì„ê³¼ í¬ì†Œ ì‚¬ì „ í•™ìŠµì˜ ì—”íŠ¸ë¡œí”¼ ìµœì†Œí™” ê¸°ë²•ì„ í†µí•´ í•´ì„ ê°€ëŠ¥í•œ í•¨ìˆ˜ í‘œí˜„ì„ ìœ ë„í•˜ëŠ” ìƒˆë¡œìš´ í›ˆë ¨ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.
- 4. P-KANsëŠ” ë‹¤ì–‘í•œ ë„ë©”ì¸ì—ì„œ ìµœëŒ€ 80%ì˜ ë§¤ê°œë³€ìˆ˜ ê°ì†Œë¥¼ ë‹¬ì„±í•˜ë©´ì„œ í‘œí˜„ ëŠ¥ë ¥ì„ ìœ ì§€í•˜ê³ , í‘œì¤€ KANsì— ë¹„í•´ ë…¸ì´ì¦ˆì— ëŒ€í•œ ê°•ë ¥í•œ ë‚´ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
- 5. P-KANsëŠ” ì‚°ì—… ìë™í™” ì„¬ìœ  ë°°ì¹˜ ì˜ˆì¸¡ì— ì„±ê³µì ìœ¼ë¡œ ì ìš©ë˜ì—ˆìœ¼ë©°, ê³¼í•™ì  ë¨¸ì‹ ëŸ¬ë‹ ì‘ìš©ì—ì„œ í˜¼í•© í•¨ìˆ˜ í‘œí˜„ì˜ ìë™ ë°œê²¬ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.


---

*Generated on 2025-09-25 15:57:25*