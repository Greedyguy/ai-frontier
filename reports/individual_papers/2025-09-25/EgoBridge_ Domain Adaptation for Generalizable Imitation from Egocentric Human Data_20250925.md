---
keywords:
  - EgoBridge
  - Domain Adaptation
  - Optimal Transport
  - Egocentric Human Data
category: cs.LG
publish_date: 2025-09-25
arxiv_id: 2509.19626
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T16:57:08.267368",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "EgoBridge",
    "Domain Adaptation",
    "Optimal Transport",
    "Egocentric Human Data"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "EgoBridge": 0.85,
    "Domain Adaptation": 0.8,
    "Optimal Transport": 0.78,
    "Egocentric Human Data": 0.77
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "EgoBridge",
        "canonical": "EgoBridge",
        "aliases": [],
        "category": "unique_technical",
        "rationale": "EgoBridge is a novel framework introduced in the paper, crucial for domain adaptation in imitation learning.",
        "novelty_score": 0.95,
        "connectivity_score": 0.65,
        "specificity_score": 0.9,
        "link_intent_score": 0.85
      },
      {
        "surface": "Domain Adaptation",
        "canonical": "Domain Adaptation",
        "aliases": [
          "Domain Transfer"
        ],
        "category": "specific_connectable",
        "rationale": "Domain adaptation is a key concept in aligning human and robot data, enhancing connectivity with related works.",
        "novelty_score": 0.5,
        "connectivity_score": 0.88,
        "specificity_score": 0.78,
        "link_intent_score": 0.8
      },
      {
        "surface": "Optimal Transport",
        "canonical": "Optimal Transport",
        "aliases": [
          "OT"
        ],
        "category": "specific_connectable",
        "rationale": "Optimal Transport is used to measure discrepancy in policy latent features, linking to mathematical methods in learning.",
        "novelty_score": 0.6,
        "connectivity_score": 0.75,
        "specificity_score": 0.82,
        "link_intent_score": 0.78
      },
      {
        "surface": "Egocentric Human Data",
        "canonical": "Egocentric Human Data",
        "aliases": [
          "First-Person Human Data"
        ],
        "category": "unique_technical",
        "rationale": "Egocentric data is central to the paper's approach, offering a unique perspective in imitation learning.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.77
      }
    ],
    "ban_list_suggestions": [
      "robot",
      "human",
      "task"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "EgoBridge",
      "resolved_canonical": "EgoBridge",
      "decision": "linked",
      "scores": {
        "novelty": 0.95,
        "connectivity": 0.65,
        "specificity": 0.9,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Domain Adaptation",
      "resolved_canonical": "Domain Adaptation",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.88,
        "specificity": 0.78,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "Optimal Transport",
      "resolved_canonical": "Optimal Transport",
      "decision": "linked",
      "scores": {
        "novelty": 0.6,
        "connectivity": 0.75,
        "specificity": 0.82,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Egocentric Human Data",
      "resolved_canonical": "Egocentric Human Data",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.77
      }
    }
  ]
}
-->

# EgoBridge: Domain Adaptation for Generalizable Imitation from Egocentric Human Data

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.LG|cs.LG]]
**PDF**: [Download](https://arxiv.org/pdf/2509.19626.pdf)
**Category**: cs.LG
**Published**: 2025-09-25
**ArXiv ID**: [2509.19626](https://arxiv.org/abs/2509.19626)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-24/Generalizable Domain Adaptation for Sim-and-Real Policy Co-Training_20250924|Generalizable Domain Adaptation for Sim-and-Real Policy Co-Training]] (85.8% similar)
- [[2025-09-18/TrajBooster_ Boosting Humanoid Whole-Body Manipulation via Trajectory-Centric Learning_20250918|TrajBooster: Boosting Humanoid Whole-Body Manipulation via Trajectory-Centric Learning]] (83.8% similar)
- [[2025-09-25/ROPA_ Synthetic Robot Pose Generation for RGB-D Bimanual Data Augmentation_20250925|ROPA: Synthetic Robot Pose Generation for RGB-D Bimanual Data Augmentation]] (83.5% similar)
- [[2025-09-24/MV-UMI_ A Scalable Multi-View Interface for Cross-Embodiment Learning_20250924|MV-UMI: A Scalable Multi-View Interface for Cross-Embodiment Learning]] (83.5% similar)
- [[2025-09-23/UniSkill_ Imitating Human Videos via Cross-Embodiment Skill Representations_20250923|UniSkill: Imitating Human Videos via Cross-Embodiment Skill Representations]] (83.0% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ”— Specific Connectable**: [[keywords/Domain Adaptation|Domain Adaptation]], [[keywords/Optimal Transport|Optimal Transport]]
**âš¡ Unique Technical**: [[keywords/EgoBridge|EgoBridge]], [[keywords/Egocentric Human Data|Egocentric Human Data]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.19626v1 Announce Type: cross 
Abstract: Egocentric human experience data presents a vast resource for scaling up end-to-end imitation learning for robotic manipulation. However, significant domain gaps in visual appearance, sensor modalities, and kinematics between human and robot impede knowledge transfer. This paper presents EgoBridge, a unified co-training framework that explicitly aligns the policy latent spaces between human and robot data using domain adaptation. Through a measure of discrepancy on the joint policy latent features and actions based on Optimal Transport (OT), we learn observation representations that not only align between the human and robot domain but also preserve the action-relevant information critical for policy learning. EgoBridge achieves a significant absolute policy success rate improvement by 44% over human-augmented cross-embodiment baselines in three real-world single-arm and bimanual manipulation tasks. EgoBridge also generalizes to new objects, scenes, and tasks seen only in human data, where baselines fail entirely. Videos and additional information can be found at https://ego-bridge.github.io

## ğŸ“ ìš”ì•½

EgoBridgeëŠ” ì¸ê°„ê³¼ ë¡œë´‡ ê°„ì˜ ë„ë©”ì¸ ì°¨ì´ë¥¼ ê·¹ë³µí•˜ì—¬ ë¡œë´‡ ì¡°ì‘ì„ ìœ„í•œ ëª¨ë°© í•™ìŠµì„ í–¥ìƒì‹œí‚¤ëŠ” í†µí•© ê³µë™ í•™ìŠµ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” Optimal Transport(OT)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì •ì±… ì ì¬ ê³µê°„ì˜ ë¶ˆì¼ì¹˜ë¥¼ ì¸¡ì •í•˜ì—¬ ì¸ê°„ê³¼ ë¡œë´‡ ë°ì´í„° ê°„ì˜ ì •ì±… ì ì¬ ê³µê°„ì„ ëª…ì‹œì ìœ¼ë¡œ ì •ë ¬í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ê´€ì°° í‘œí˜„ì„ í•™ìŠµí•˜ì—¬ ì¸ê°„ê³¼ ë¡œë´‡ ë„ë©”ì¸ ê°„ ì •ë ¬ì„ ì´ë£¨ê³ , ì •ì±… í•™ìŠµì— ì¤‘ìš”í•œ í–‰ë™ ê´€ë ¨ ì •ë³´ë¥¼ ë³´ì¡´í•©ë‹ˆë‹¤. EgoBridgeëŠ” ì„¸ ê°€ì§€ ì‹¤ì œ ì¡°ì‘ ì‘ì—…ì—ì„œ ì¸ê°„ ë³´ê°• í¬ë¡œìŠ¤-êµ¬í˜„ ê¸°ì¤€ì„  ëŒ€ë¹„ 44%ì˜ ì ˆëŒ€ì ì¸ ì •ì±… ì„±ê³µë¥  í–¥ìƒì„ ë‹¬ì„±í–ˆìœ¼ë©°, ì¸ê°„ ë°ì´í„°ì—ì„œë§Œ ë³¸ ìƒˆë¡œìš´ ê°ì²´, ì¥ë©´, ì‘ì—…ì—ë„ ì¼ë°˜í™”í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. EgoBridgeëŠ” ì¸ê°„ê³¼ ë¡œë´‡ ë°ì´í„° ê°„ì˜ ì •ì±… ì ì¬ ê³µê°„ì„ ëª…ì‹œì ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ë„ë©”ì¸ ì ì‘ì„ í†µí•œ í†µí•© ê³µë™ í•™ìŠµ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.
- 2. ìµœì  ìˆ˜ì†¡(Optimal Transport, OT)ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ê³µë™ ì •ì±… ì ì¬ íŠ¹ì§• ë° í–‰ë™ì˜ ë¶ˆì¼ì¹˜ ì¸¡ì •ì„ í†µí•´ ê´€ì°° í‘œí˜„ì„ í•™ìŠµí•˜ì—¬ ì¸ê°„ê³¼ ë¡œë´‡ ë„ë©”ì¸ì„ ì •ë ¬í•˜ê³  ì •ì±… í•™ìŠµì— ì¤‘ìš”í•œ í–‰ë™ ê´€ë ¨ ì •ë³´ë¥¼ ë³´ì¡´í•©ë‹ˆë‹¤.
- 3. EgoBridgeëŠ” ì„¸ ê°€ì§€ ì‹¤ì œ ë‹¨ì¼ íŒ” ë° ì–‘ì† ì¡°ì‘ ì‘ì—…ì—ì„œ ì¸ê°„ ë³´ê°• êµì°¨ êµ¬í˜„ ê¸°ì¤€ì„ ë³´ë‹¤ ì ˆëŒ€ ì •ì±… ì„±ê³µë¥ ì„ 44% í–¥ìƒì‹œí‚µë‹ˆë‹¤.
- 4. EgoBridgeëŠ” ê¸°ì¤€ì„ ì´ ì™„ì „íˆ ì‹¤íŒ¨í•˜ëŠ” ìƒˆë¡œìš´ ë¬¼ì²´, ì¥ë©´ ë° ì¸ê°„ ë°ì´í„°ì—ì„œë§Œ ë³¸ ì‘ì—…ì— ì¼ë°˜í™”ë©ë‹ˆë‹¤.
- 5. ì¶”ê°€ ì •ë³´ì™€ ë¹„ë””ì˜¤ëŠ” https://ego-bridge.github.ioì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-25 16:57:08*