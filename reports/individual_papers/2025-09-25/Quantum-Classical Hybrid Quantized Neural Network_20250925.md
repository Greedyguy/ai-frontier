---
keywords:
  - Neural Network
  - Quadratic Binary Optimization
  - Forward Interval Propagation
  - Quantum Conditional Gradient Descent
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2506.18240
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T16:28:42.534507",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Neural Network",
    "Quadratic Binary Optimization",
    "Forward Interval Propagation",
    "Quantum Conditional Gradient Descent"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Neural Network": 0.85,
    "Quadratic Binary Optimization": 0.78,
    "Forward Interval Propagation": 0.82,
    "Quantum Conditional Gradient Descent": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "quantized neural network",
        "canonical": "Neural Network",
        "aliases": [
          "QNN",
          "quantized NN"
        ],
        "category": "broad_technical",
        "rationale": "Links to existing neural network literature and concepts, facilitating integration with broader AI research.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.7,
        "link_intent_score": 0.85
      },
      {
        "surface": "Quadratic Binary Optimization",
        "canonical": "Quadratic Binary Optimization",
        "aliases": [
          "QBO"
        ],
        "category": "unique_technical",
        "rationale": "Introduces a specific optimization model unique to this research, relevant for quantum computing applications.",
        "novelty_score": 0.75,
        "connectivity_score": 0.65,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Forward Interval Propagation",
        "canonical": "Forward Interval Propagation",
        "aliases": [
          "FIP"
        ],
        "category": "unique_technical",
        "rationale": "A novel method for handling non-linearity in neural networks, enhancing the paper's unique contributions.",
        "novelty_score": 0.8,
        "connectivity_score": 0.6,
        "specificity_score": 0.85,
        "link_intent_score": 0.82
      },
      {
        "surface": "Quantum Conditional Gradient Descent",
        "canonical": "Quantum Conditional Gradient Descent",
        "aliases": [
          "QCGD"
        ],
        "category": "unique_technical",
        "rationale": "A specific algorithm leveraging quantum computing, crucial for linking quantum and classical optimization techniques.",
        "novelty_score": 0.78,
        "connectivity_score": 0.7,
        "specificity_score": 0.88,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "spline interpolation",
      "penalty method",
      "empirical risk minimization"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "quantized neural network",
      "resolved_canonical": "Neural Network",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.7,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Quadratic Binary Optimization",
      "resolved_canonical": "Quadratic Binary Optimization",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.65,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Forward Interval Propagation",
      "resolved_canonical": "Forward Interval Propagation",
      "decision": "linked",
      "scores": {
        "novelty": 0.8,
        "connectivity": 0.6,
        "specificity": 0.85,
        "link_intent": 0.82
      }
    },
    {
      "candidate_surface": "Quantum Conditional Gradient Descent",
      "resolved_canonical": "Quantum Conditional Gradient Descent",
      "decision": "linked",
      "scores": {
        "novelty": 0.78,
        "connectivity": 0.7,
        "specificity": 0.88,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# Quantum-Classical Hybrid Quantized Neural Network

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2506.18240.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2506.18240](https://arxiv.org/abs/2506.18240)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-17/Hybrid Quantum-Classical Neural Networks for Few-Shot Credit Risk Assessment_20250917|Hybrid Quantum-Classical Neural Networks for Few-Shot Credit Risk Assessment]] (85.2% similar)
- [[2025-09-19/Trainability of Quantum Models Beyond Known Classical Simulability_20250919|Trainability of Quantum Models Beyond Known Classical Simulability]] (84.8% similar)
- [[2025-09-24/Re-uploading quantum data_ A universal function approximator for quantum inputs_20250924|Re-uploading quantum data: A universal function approximator for quantum inputs]] (84.4% similar)
- [[2025-09-22/Quantum Reinforcement Learning with Dynamic-Circuit Qubit Reuse and Grover-Based Trajectory Optimization_20250922|Quantum Reinforcement Learning with Dynamic-Circuit Qubit Reuse and Grover-Based Trajectory Optimization]] (84.3% similar)
- [[2025-09-22/Efficient Learning for Linear Properties of Bounded-Gate Quantum Circuits_20250922|Efficient Learning for Linear Properties of Bounded-Gate Quantum Circuits]] (83.6% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Neural Network|Neural Network]]
**âš¡ Unique Technical**: [[keywords/Quadratic Binary Optimization|Quadratic Binary Optimization]], [[keywords/Forward Interval Propagation|Forward Interval Propagation]], [[keywords/Quantum Conditional Gradient Descent|Quantum Conditional Gradient Descent]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2506.18240v3 Announce Type: replace-cross 
Abstract: Here in this work, we present a novel Quadratic Binary Optimization (QBO) model for quantized neural network training, enabling the use of arbitrary activation and loss functions through spline interpolation. We introduce Forward Interval Propagation (FIP), a method designed to tackle the challenges of non-linearity and the multi-layer composite structure in neural networks by discretizing activation functions into linear subintervals. This approach preserves the universal approximation properties of neural networks while allowing complex nonlinear functions to be optimized using quantum computers, thus broadening their applicability in artificial intelligence. We provide theoretical upper bounds on the approximation error and the number of Ising spins required, by deriving the sample complexity of the empirical risk minimization problem, from an optimization perspective. A significant challenge in solving the associated Quadratic Constrained Binary Optimization (QCBO) model on a large scale is the presence of numerous constraints. When employing the penalty method to handle these constraints, tuning a large number of penalty coefficients becomes a critical hyperparameter optimization problem, increasing computational complexity and potentially affecting solution quality. To address this, we employ the Quantum Conditional Gradient Descent (QCGD) algorithm, which leverages quantum computing to directly solve the QCBO problem. We prove the convergence of QCGD under a quantum oracle with randomness and bounded variance in objective value, as well as under limited precision constraints in the coefficient matrix. Additionally, we provide an upper bound on the Time-To-Solution for the QCBO solving process. We further propose a training algorithm with single-sample bit-scale optimization.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ì–‘ìí™”ëœ ì‹ ê²½ë§ í›ˆë ¨ì„ ìœ„í•œ ìƒˆë¡œìš´ ì´ì°¨ ì´ì§„ ìµœì í™”(QBO) ëª¨ë¸ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ìŠ¤í”Œë¼ì¸ ë³´ê°„ë²•ì„ í†µí•´ ì„ì˜ì˜ í™œì„±í™” ë° ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•˜ë©°, ë¹„ì„ í˜•ì„±ê³¼ ë‹¤ì¸µ êµ¬ì¡°ì˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ í™œì„±í™” í•¨ìˆ˜ë¥¼ ì„ í˜• êµ¬ê°„ìœ¼ë¡œ ë¶„í• í•˜ëŠ” ì „ë°© êµ¬ê°„ ì „íŒŒ(FIP) ë°©ë²•ì„ ë„ì…í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì‹ ê²½ë§ì˜ ë³´í¸ì  ê·¼ì‚¬ íŠ¹ì„±ì„ ìœ ì§€í•˜ë©´ì„œ ì–‘ì ì»´í“¨í„°ë¥¼ ì‚¬ìš©í•´ ë³µì¡í•œ ë¹„ì„ í˜• í•¨ìˆ˜ë¥¼ ìµœì í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ê²½í—˜ì  ìœ„í—˜ ìµœì†Œí™” ë¬¸ì œì˜ ìƒ˜í”Œ ë³µì¡ì„±ì„ ë„ì¶œí•˜ì—¬ ê·¼ì‚¬ ì˜¤ì°¨ì™€ í•„ìš”í•œ ì´ì§• ìŠ¤í•€ ìˆ˜ì— ëŒ€í•œ ì´ë¡ ì  ìƒí•œì„ ì œê³µí•©ë‹ˆë‹¤. QCBO ëª¨ë¸ì˜ ëŒ€ê·œëª¨ ë¬¸ì œ í•´ê²° ì‹œ ë§ì€ ì œì•½ ì¡°ê±´ì´ ì¡´ì¬í•˜ëŠ”ë°, ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì–‘ì ì¡°ê±´ë¶€ ê²½ì‚¬ í•˜ê°•(QCGD) ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ì§ì ‘ QCBO ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤. QCGDì˜ ìˆ˜ë ´ì„±ì„ ì¦ëª…í•˜ê³ , QCBO í•´ê²° ê³¼ì •ì˜ ì‹œê°„ ìƒí•œì„ ì œì‹œí•©ë‹ˆë‹¤. ì¶”ê°€ë¡œ ë‹¨ì¼ ìƒ˜í”Œ ë¹„íŠ¸ ìŠ¤ì¼€ì¼ ìµœì í™”ë¥¼ í†µí•œ í›ˆë ¨ ì•Œê³ ë¦¬ì¦˜ì„ ì œì•ˆí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ë³¸ ì—°êµ¬ëŠ” ìŠ¤í”Œë¼ì¸ ë³´ê°„ë²•ì„ í†µí•´ ì„ì˜ì˜ í™œì„±í™” ë° ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ìƒˆë¡œìš´ ì´ì§„ 2ì°¨ ìµœì í™”(QBO) ëª¨ë¸ì„ ì œì•ˆí•©ë‹ˆë‹¤.
- 2. ë¹„ì„ í˜•ì„±ê³¼ ë‹¤ì¸µ êµ¬ì¡°ì˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ í™œì„±í™” í•¨ìˆ˜ë¥¼ ì„ í˜• êµ¬ê°„ìœ¼ë¡œ ì´ì‚°í™”í•˜ëŠ” ì „ë°© ê°„ê²© ì „íŒŒ(FIP) ë°©ë²•ì„ ë„ì…í–ˆìŠµë‹ˆë‹¤.
- 3. ì–‘ì ì»´í“¨íŒ…ì„ í™œìš©í•˜ì—¬ ë³µì¡í•œ ë¹„ì„ í˜• í•¨ìˆ˜ë¥¼ ìµœì í™”í•¨ìœ¼ë¡œì¨ ì¸ê³µì§€ëŠ¥ì—ì„œì˜ ì ìš© ê°€ëŠ¥ì„±ì„ í™•ì¥í•©ë‹ˆë‹¤.
- 4. í˜ë„í‹° ë°©ë²•ì„ ì‚¬ìš©í•  ë•Œ ë§ì€ í˜ë„í‹° ê³„ìˆ˜ë¥¼ ì¡°ì •í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ë¬¸ì œê°€ ë˜ì–´ ê³„ì‚° ë³µì¡ì„±ì„ ì¦ê°€ì‹œí‚µë‹ˆë‹¤.
- 5. ì–‘ì ì¡°ê±´ë¶€ ê²½ì‚¬ í•˜ê°•(QCGD) ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ QCBO ë¬¸ì œë¥¼ ì§ì ‘ í•´ê²°í•˜ê³ , ìˆ˜ë ´ì„±ê³¼ ì‹œê°„-í•´ê²° ìƒí•œì„ ì¦ëª…í–ˆìŠµë‹ˆë‹¤.


---

*Generated on 2025-09-25 16:28:42*