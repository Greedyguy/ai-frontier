---
keywords:
  - Toxicity Detection
  - ASCII Art
  - Adversarial Attacks
  - Large Language Model
category: cs.AI
publish_date: 2025-09-25
arxiv_id: 2409.18708
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-25T16:16:52.816214",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Toxicity Detection",
    "ASCII Art",
    "Adversarial Attacks",
    "Large Language Model"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Toxicity Detection": 0.85,
    "ASCII Art": 0.8,
    "Adversarial Attacks": 0.9,
    "Large Language Model": 0.88
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "toxicity detection",
        "canonical": "Toxicity Detection",
        "aliases": [
          "toxicity classifier",
          "harmful content detection"
        ],
        "category": "unique_technical",
        "rationale": "Toxicity detection is a specific application area that connects to moderation and NLP systems.",
        "novelty_score": 0.65,
        "connectivity_score": 0.78,
        "specificity_score": 0.82,
        "link_intent_score": 0.85
      },
      {
        "surface": "ASCII art",
        "canonical": "ASCII Art",
        "aliases": [
          "text art",
          "character art"
        ],
        "category": "unique_technical",
        "rationale": "ASCII art represents a unique form of input that challenges standard text processing models.",
        "novelty_score": 0.7,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.8
      },
      {
        "surface": "adversarial attacks",
        "canonical": "Adversarial Attacks",
        "aliases": [
          "attack strategies",
          "adversarial methods"
        ],
        "category": "specific_connectable",
        "rationale": "Adversarial attacks are crucial for understanding vulnerabilities in AI systems.",
        "novelty_score": 0.5,
        "connectivity_score": 0.85,
        "specificity_score": 0.75,
        "link_intent_score": 0.9
      },
      {
        "surface": "large language models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLM",
          "language model"
        ],
        "category": "broad_technical",
        "rationale": "Large language models are central to modern NLP and connect to a wide range of applications.",
        "novelty_score": 0.4,
        "connectivity_score": 0.9,
        "specificity_score": 0.6,
        "link_intent_score": 0.88
      }
    ],
    "ban_list_suggestions": [
      "moderation systems",
      "state-of-the-art",
      "robustness"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "toxicity detection",
      "resolved_canonical": "Toxicity Detection",
      "decision": "linked",
      "scores": {
        "novelty": 0.65,
        "connectivity": 0.78,
        "specificity": 0.82,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "ASCII art",
      "resolved_canonical": "ASCII Art",
      "decision": "linked",
      "scores": {
        "novelty": 0.7,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.8
      }
    },
    {
      "candidate_surface": "adversarial attacks",
      "resolved_canonical": "Adversarial Attacks",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.85,
        "specificity": 0.75,
        "link_intent": 0.9
      }
    },
    {
      "candidate_surface": "large language models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.4,
        "connectivity": 0.9,
        "specificity": 0.6,
        "link_intent": 0.88
      }
    }
  ]
}
-->

# Evading Toxicity Detection with ASCII-art: A Benchmark of Spatial Attacks on Moderation Systems

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.AI|cs.AI]]
**PDF**: [Download](https://arxiv.org/pdf/2409.18708.pdf)
**Category**: cs.AI
**Published**: 2025-09-25
**ArXiv ID**: [2409.18708](https://arxiv.org/abs/2409.18708)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Sugar-Coated Poison_ Benign Generation Unlocks LLM Jailbreaking_20250923|Sugar-Coated Poison: Benign Generation Unlocks LLM Jailbreaking]] (83.8% similar)
- [[2025-09-25/Semantic Representation Attack against Aligned Large Language Models_20250925|Semantic Representation Attack against Aligned Large Language Models]] (83.1% similar)
- [[2025-09-24/T-Detect_ Tail-Aware Statistical Normalization for Robust Detection of Adversarial Machine-Generated Text_20250924|T-Detect: Tail-Aware Statistical Normalization for Robust Detection of Adversarial Machine-Generated Text]] (82.6% similar)
- [[2025-09-24/Algorithms for Adversarially Robust Deep Learning_20250924|Algorithms for Adversarially Robust Deep Learning]] (82.3% similar)
- [[2025-09-24/Backdoor Attack with Invisible Triggers Based on Model Architecture Modification_20250924|Backdoor Attack with Invisible Triggers Based on Model Architecture Modification]] (81.8% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Adversarial Attacks|Adversarial Attacks]]
**âš¡ Unique Technical**: [[keywords/Toxicity Detection|Toxicity Detection]], [[keywords/ASCII Art|ASCII Art]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2409.18708v5 Announce Type: replace-cross 
Abstract: We introduce a novel class of adversarial attacks on toxicity detection models that exploit language models' failure to interpret spatially structured text in the form of ASCII art. To evaluate the effectiveness of these attacks, we propose ToxASCII, a benchmark designed to assess the robustness of toxicity detection systems against visually obfuscated inputs. Our attacks achieve a perfect Attack Success Rate (ASR) across a diverse set of state-of-the-art large language models and dedicated moderation tools, revealing a significant vulnerability in current text-only moderation systems.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ASCII ì•„íŠ¸ë¥¼ í™œìš©í•˜ì—¬ í…ìŠ¤íŠ¸ì˜ ê³µê°„ì  êµ¬ì¡°ë¥¼ í•´ì„í•˜ì§€ ëª»í•˜ëŠ” ì–¸ì–´ ëª¨ë¸ì˜ ì·¨ì•½ì ì„ ì´ìš©í•œ ìƒˆë¡œìš´ ìœ í˜•ì˜ ì ëŒ€ì  ê³µê²©ì„ ì†Œê°œí•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ê³µê²©ì˜ íš¨ê³¼ë¥¼ í‰ê°€í•˜ê¸° ìœ„í•´ ToxASCIIë¼ëŠ” ë²¤ì¹˜ë§ˆí¬ë¥¼ ì œì•ˆí•˜ì—¬ ì‹œê°ì ìœ¼ë¡œ ë‚œë…í™”ëœ ì…ë ¥ì— ëŒ€í•œ ë…ì„± íƒì§€ ì‹œìŠ¤í…œì˜ ê²¬ê³ ì„±ì„ í‰ê°€í•©ë‹ˆë‹¤. ì´ ê³µê²©ì€ ë‹¤ì–‘í•œ ìµœì‹  ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ê³¼ ì „ìš© ëª¨ë”ë ˆì´ì…˜ ë„êµ¬ì—ì„œ ì™„ë²½í•œ ê³µê²© ì„±ê³µë¥ ì„ ë‹¬ì„±í•˜ì—¬ í˜„ì¬ í…ìŠ¤íŠ¸ ê¸°ë°˜ ëª¨ë”ë ˆì´ì…˜ ì‹œìŠ¤í…œì˜ ì¤‘ìš”í•œ ì·¨ì•½ì„±ì„ ë“œëŸ¬ëƒ…ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ASCII ì•„íŠ¸ë¥¼ í™œìš©í•œ ìƒˆë¡œìš´ ìœ í˜•ì˜ ì ëŒ€ì  ê³µê²©ì´ ë…ì„± íƒì§€ ëª¨ë¸ì˜ ì·¨ì•½ì ì„ ë…¸ë¦°ë‹¤.
- 2. ToxASCIIë¼ëŠ” ë²¤ì¹˜ë§ˆí¬ë¥¼ ì œì•ˆí•˜ì—¬ ì‹œê°ì ìœ¼ë¡œ ë‚œë…í™”ëœ ì…ë ¥ì— ëŒ€í•œ ë…ì„± íƒì§€ ì‹œìŠ¤í…œì˜ ê°•ì¸ì„±ì„ í‰ê°€í•œë‹¤.
- 3. ì œì•ˆëœ ê³µê²©ì€ ë‹¤ì–‘í•œ ìµœì‹  ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ê³¼ ì „ìš© ì¤‘ì¬ ë„êµ¬ì— ëŒ€í•´ ì™„ë²½í•œ ê³µê²© ì„±ê³µë¥ (ASR)ì„ ë‹¬ì„±í•œë‹¤.
- 4. í˜„ì¬ì˜ í…ìŠ¤íŠ¸ ì „ìš© ì¤‘ì¬ ì‹œìŠ¤í…œì— ì¤‘ìš”í•œ ì·¨ì•½ì ì´ ìˆìŒì„ ë“œëŸ¬ë‚¸ë‹¤.


---

*Generated on 2025-09-25 16:16:52*