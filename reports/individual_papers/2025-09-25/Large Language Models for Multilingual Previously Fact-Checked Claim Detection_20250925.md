---
keywords:
  - Large Language Model
  - Multilingual Fact-Checked Claim Detection
  - Cross-Lingual Settings
  - Low-Resource Languages
category: cs.CL
publish_date: 2025-09-25
arxiv_id: 2503.02737
---

<!-- KEYWORD_LINKING_METADATA:
{
  "processed_timestamp": "2025-09-26T08:52:36.540616",
  "vocabulary_version": "1.0",
  "selected_keywords": [
    "Large Language Model",
    "Multilingual Fact-Checked Claim Detection",
    "Cross-Lingual Settings",
    "Low-Resource Languages"
  ],
  "rejected_keywords": [],
  "similarity_scores": {
    "Large Language Model": 0.85,
    "Multilingual Fact-Checked Claim Detection": 0.78,
    "Cross-Lingual Settings": 0.77,
    "Low-Resource Languages": 0.8
  },
  "extraction_method": "AI_prompt_based",
  "budget_applied": true,
  "candidates_json": {
    "candidates": [
      {
        "surface": "Large Language Models",
        "canonical": "Large Language Model",
        "aliases": [
          "LLMs"
        ],
        "category": "broad_technical",
        "rationale": "Large Language Models are central to the paper's evaluation and are a key concept in NLP research.",
        "novelty_score": 0.45,
        "connectivity_score": 0.88,
        "specificity_score": 0.65,
        "link_intent_score": 0.85
      },
      {
        "surface": "Multilingual Fact-Checked Claim Detection",
        "canonical": "Multilingual Fact-Checked Claim Detection",
        "aliases": [
          "Cross-Lingual Claim Verification"
        ],
        "category": "unique_technical",
        "rationale": "This is a unique application of LLMs that addresses a specific challenge in multilingual information verification.",
        "novelty_score": 0.75,
        "connectivity_score": 0.6,
        "specificity_score": 0.8,
        "link_intent_score": 0.78
      },
      {
        "surface": "Cross-Lingual Settings",
        "canonical": "Cross-Lingual Settings",
        "aliases": [
          "Cross-Language Contexts"
        ],
        "category": "specific_connectable",
        "rationale": "Cross-lingual settings are crucial for understanding the performance of LLMs across different languages.",
        "novelty_score": 0.55,
        "connectivity_score": 0.7,
        "specificity_score": 0.72,
        "link_intent_score": 0.77
      },
      {
        "surface": "Low-Resource Languages",
        "canonical": "Low-Resource Languages",
        "aliases": [
          "Under-Resourced Languages"
        ],
        "category": "specific_connectable",
        "rationale": "Addressing challenges in low-resource languages is vital for the inclusivity of multilingual NLP applications.",
        "novelty_score": 0.5,
        "connectivity_score": 0.75,
        "specificity_score": 0.78,
        "link_intent_score": 0.8
      }
    ],
    "ban_list_suggestions": [
      "high-resource languages",
      "translating original texts"
    ]
  },
  "decisions": [
    {
      "candidate_surface": "Large Language Models",
      "resolved_canonical": "Large Language Model",
      "decision": "linked",
      "scores": {
        "novelty": 0.45,
        "connectivity": 0.88,
        "specificity": 0.65,
        "link_intent": 0.85
      }
    },
    {
      "candidate_surface": "Multilingual Fact-Checked Claim Detection",
      "resolved_canonical": "Multilingual Fact-Checked Claim Detection",
      "decision": "linked",
      "scores": {
        "novelty": 0.75,
        "connectivity": 0.6,
        "specificity": 0.8,
        "link_intent": 0.78
      }
    },
    {
      "candidate_surface": "Cross-Lingual Settings",
      "resolved_canonical": "Cross-Lingual Settings",
      "decision": "linked",
      "scores": {
        "novelty": 0.55,
        "connectivity": 0.7,
        "specificity": 0.72,
        "link_intent": 0.77
      }
    },
    {
      "candidate_surface": "Low-Resource Languages",
      "resolved_canonical": "Low-Resource Languages",
      "decision": "linked",
      "scores": {
        "novelty": 0.5,
        "connectivity": 0.75,
        "specificity": 0.78,
        "link_intent": 0.8
      }
    }
  ]
}
-->

# Large Language Models for Multilingual Previously Fact-Checked Claim Detection

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily_digest_20250925|20250925]] [[categories/cs.CL|cs.CL]]
**PDF**: [Download](https://arxiv.org/pdf/2503.02737.pdf)
**Category**: cs.CL
**Published**: 2025-09-25
**ArXiv ID**: [2503.02737](https://arxiv.org/abs/2503.02737)

## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸
- [[2025-09-23/Multilingual vs Crosslingual Retrieval of Fact-Checked Claims_ A Tale of Two Approaches_20250923|Multilingual vs Crosslingual Retrieval of Fact-Checked Claims: A Tale of Two Approaches]] (90.5% similar)
- [[2025-09-23/MAKIEval_ A Multilingual Automatic WiKidata-based Framework for Cultural Awareness Evaluation for LLMs_20250923|MAKIEval: A Multilingual Automatic WiKidata-based Framework for Cultural Awareness Evaluation for LLMs]] (86.4% similar)
- [[2025-09-22/A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages_20250922|A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages]] (86.1% similar)
- [[2025-09-22/PolBiX_ Detecting LLMs' Political Bias in Fact-Checking through X-phemisms_20250922|PolBiX: Detecting LLMs' Political Bias in Fact-Checking through X-phemisms]] (85.8% similar)
- [[2025-09-23/Breaking the Reviewer_ Assessing the Vulnerability of Large Language Models in Automated Peer Review Under Textual Adversarial Attacks_20250923|Breaking the Reviewer: Assessing the Vulnerability of Large Language Models in Automated Peer Review Under Textual Adversarial Attacks]] (85.1% similar)

## ğŸ·ï¸ ì¹´í…Œê³ ë¦¬í™”ëœ í‚¤ì›Œë“œ
**ğŸ§  Broad Technical**: [[keywords/Large Language Model|Large Language Model]]
**ğŸ”— Specific Connectable**: [[keywords/Cross-Lingual Settings|Cross-Lingual Settings]], [[keywords/Low-Resource Languages|Low-Resource Languages]]
**âš¡ Unique Technical**: [[keywords/Multilingual Fact-Checked Claim Detection|Multilingual Fact-Checked Claim Detection]]

## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2503.02737v3 Announce Type: replace 
Abstract: In our era of widespread false information, human fact-checkers often face the challenge of duplicating efforts when verifying claims that may have already been addressed in other countries or languages. As false information transcends linguistic boundaries, the ability to automatically detect previously fact-checked claims across languages has become an increasingly important task. This paper presents the first comprehensive evaluation of large language models (LLMs) for multilingual previously fact-checked claim detection. We assess seven LLMs across 20 languages in both monolingual and cross-lingual settings. Our results show that while LLMs perform well for high-resource languages, they struggle with low-resource languages. Moreover, translating original texts into English proved to be beneficial for low-resource languages. These findings highlight the potential of LLMs for multilingual previously fact-checked claim detection and provide a foundation for further research on this promising application of LLMs.

## ğŸ“ ìš”ì•½

ì´ ë…¼ë¬¸ì€ ë‹¤êµ­ì–´ í™˜ê²½ì—ì„œ ì´ë¯¸ ì‚¬ì‹¤ í™•ì¸ëœ ì£¼ì¥ë“¤ì„ ìë™ìœ¼ë¡œ íƒì§€í•˜ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì„±ëŠ¥ì„ í‰ê°€í•œ ìµœì´ˆì˜ ì—°êµ¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. 20ê°œ ì–¸ì–´ì—ì„œ 7ê°œì˜ LLMì„ ë‹¨ì¼ ì–¸ì–´ ë° êµì°¨ ì–¸ì–´ ì„¤ì •ìœ¼ë¡œ í‰ê°€í•œ ê²°ê³¼, LLMì€ ìì›ì´ í’ë¶€í•œ ì–¸ì–´ì—ì„œëŠ” ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë‚˜, ìì›ì´ ë¶€ì¡±í•œ ì–¸ì–´ì—ì„œëŠ” ì„±ëŠ¥ì´ ì €ì¡°í–ˆìŠµë‹ˆë‹¤. íŠ¹íˆ, ì €ìì› ì–¸ì–´ì˜ ê²½ìš° ì›ë¬¸ì„ ì˜ì–´ë¡œ ë²ˆì—­í•˜ëŠ” ê²ƒì´ ìœ ë¦¬í•˜ë‹¤ëŠ” ì ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” LLMì„ í™œìš©í•œ ë‹¤êµ­ì–´ ì‚¬ì‹¤ í™•ì¸ íƒì§€ì˜ ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì£¼ë©°, í–¥í›„ ì—°êµ¬ì˜ ê¸°ì´ˆë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸

- 1. ê±°ì§“ ì •ë³´ê°€ ì–¸ì–´ì  ê²½ê³„ë¥¼ ë„˜ì–´ í™•ì‚°ë¨ì— ë”°ë¼ ë‹¤êµ­ì–´ë¡œ ì´ì „ì— ì‚¬ì‹¤ í™•ì¸ëœ ì£¼ì¥ì„ ìë™ìœ¼ë¡œ íƒì§€í•˜ëŠ” ëŠ¥ë ¥ì´ ì¤‘ìš”í•´ì§€ê³  ìˆë‹¤.
- 2. ì´ ë…¼ë¬¸ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ í™œìš©í•œ ë‹¤êµ­ì–´ ì´ì „ ì‚¬ì‹¤ í™•ì¸ ì£¼ì¥ íƒì§€ì— ëŒ€í•œ ìµœì´ˆì˜ ì¢…í•©ì ì¸ í‰ê°€ë¥¼ ì œì‹œí•œë‹¤.
- 3. 20ê°œ ì–¸ì–´ì—ì„œ 7ê°œì˜ LLMì„ í‰ê°€í•œ ê²°ê³¼, LLMì€ ìì›ì´ í’ë¶€í•œ ì–¸ì–´ì—ì„œëŠ” ì„±ëŠ¥ì´ ì¢‹ì§€ë§Œ, ìì›ì´ ë¶€ì¡±í•œ ì–¸ì–´ì—ì„œëŠ” ì–´ë ¤ì›€ì„ ê²ªëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ë‹¤.
- 4. ìì›ì´ ë¶€ì¡±í•œ ì–¸ì–´ì˜ ê²½ìš°, ì›ë¬¸ì„ ì˜ì–´ë¡œ ë²ˆì—­í•˜ëŠ” ê²ƒì´ ìœ ìµí•œ ê²ƒìœ¼ë¡œ ë“œëŸ¬ë‚¬ë‹¤.
- 5. ì´ëŸ¬í•œ ì—°êµ¬ ê²°ê³¼ëŠ” LLMì„ í™œìš©í•œ ë‹¤êµ­ì–´ ì´ì „ ì‚¬ì‹¤ í™•ì¸ ì£¼ì¥ íƒì§€ì˜ ì ì¬ë ¥ì„ ê°•ì¡°í•˜ë©°, ì´ ë¶„ì•¼ì˜ ì¶”ê°€ ì—°êµ¬ë¥¼ ìœ„í•œ ê¸°ì´ˆë¥¼ ì œê³µí•œë‹¤.


---

*Generated on 2025-09-26 08:52:36*