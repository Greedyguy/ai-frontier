
# The Art of Saying "Maybe": A Conformal Lens for Uncertainty Benchmarking in VLMs

**Korean Title:** "아마도"라고 말하는 기술: VLM에서 불확실성 벤치마킹을 위한 형식 렌즈

## 📋 메타데이터

**Links**: [[daily/2025-09-18|2025-09-18]] [[keywords/evolved/Mathematical and Reasoning Tasks|Mathematical and Reasoning Tasks]] [[keywords/broad/Vision-Language Models|Vision-Language Models]] [[keywords/broad/Uncertainty Quantification|Uncertainty Quantification]] [[keywords/specific/Multimodal Datasets|Multimodal Datasets]] [[keywords/unique/VLMs|VLMs]] [[categories/cs.AI|cs.AI]]

## 🏷️ 카테고리화된 키워드
**🚀 Evolved Concepts**: Mathematical and Reasoning Tasks
**🔬 Broad Technical**: Vision-Language Models, Uncertainty Quantification
**🔗 Specific Connectable**: Multimodal Datasets
**⭐ Unique Technical**: VLMs

**ArXiv ID**: [2509.13379](https://arxiv.org/abs/2509.13379)
**Published**: 2025-09-18
**Category**: cs.AI
**PDF**: [Download](https://arxiv.org/pdf/2509.13379.pdf)


## 🏷️ 추출된 키워드



`Vision-Language Models` • 

`Uncertainty Quantification` • 

`Multimodal Datasets` • 

`VLMs` • 

`Mathematical and Reasoning Tasks`



## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.13379v1 Announce Type: new 
Abstract: Vision-Language Models (VLMs) have achieved remarkable progress in complex visual understanding across scientific and reasoning tasks. While performance benchmarking has advanced our understanding of these capabilities, the critical dimension of uncertainty quantification has received insufficient attention. Therefore, unlike prior conformal prediction studies that focused on limited settings, we conduct a comprehensive uncertainty benchmarking study, evaluating 16 state-of-the-art VLMs (open and closed-source) across 6 multimodal datasets with 3 distinct scoring functions. Our findings demonstrate that larger models consistently exhibit better uncertainty quantification; models that know more also know better what they don't know. More certain models achieve higher accuracy, while mathematical and reasoning tasks elicit poorer uncertainty performance across all models compared to other domains. This work establishes a foundation for reliable uncertainty evaluation in multimodal systems.

## 🔍 Abstract (한글 번역)

arXiv:2509.13379v1 발표 유형: 새로운
요약: Vision-Language Models (VLMs)는 과학적 및 추론 작업에서 복잡한 시각적 이해력에서 현저한 진전을 이루었습니다. 성능 벤치마킹은 이러한 능력에 대한 우리의 이해를 발전시켰지만, 불확실성 양자화의 중요한 측면은 충분한 주의를 받지 못했습니다. 따라서, 이전의 한정된 설정에 초점을 맞춘 이전의 일관성 예측 연구와는 달리, 우리는 16개의 최첨단 VLMs(오픈 및 폐쇄 소스)를 평가하는 포괄적인 불확실성 벤치마킹 연구를 실시했습니다. 이 연구는 6개의 다중 모달 데이터셋과 3가지 다른 점수 기능을 통해 이루어졌습니다. 우리의 연구 결과는 더 큰 모델이 일관적으로 더 나은 불확실성 양자화를 보여준다는 것을 입증합니다; 더 많이 아는 모델이 또한 무엇을 모르는지 더 잘 알고 있습니다. 더 확실한 모델은 더 높은 정확도를 달성하며, 수학 및 추론 작업은 다른 도메인과 비교했을 때 모든 모델에서 불확실성 성능이 떨어집니다. 이 연구는 다중 모달 시스템에서 신뢰할 수 있는 불확실성 평가를 위한 기초를 마련합니다.

## 📝 요약

이 연구는 시각-언어 모델(VLMs)의 불확실성 평가에 대한 체계적인 연구를 통해, 16가지 최신 VLMs를 6가지 다중 모달 데이터셋에서 평가하고 더 큰 모델이 더 나은 불확실성 평가를 보여준다는 것을 밝혔다. 이 연구는 불확실성 평가의 신뢰성을 확립하며, 수학적 및 추론 작업은 다른 영역에 비해 모든 모델에서 불확실성 성능이 떨어지는 것을 발견했다. 이는 VLMs의 불확실성 평가에 대한 새로운 이해를 제공하며, 미래의 연구에 기여할 것으로 기대된다.

## 🎯 주요 포인트


- VLMs의 불확실성 측정이 중요한데 미흡한 점이 있음

- 큰 모델일수록 더 나은 불확실성 측정을 보임

- 수학 및 추론 작업에서는 다른 도메인에 비해 불확실성 성능이 떨어짐


---

*Generated on 2025-09-18 16:14:39*