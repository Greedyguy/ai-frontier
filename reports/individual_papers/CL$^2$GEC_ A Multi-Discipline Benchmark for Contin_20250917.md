
# CL$^2$GEC: A Multi-Discipline Benchmark for Continual Learning in Chinese Literature Grammatical Error Correction

**Korean Title:** CL$^2$GEC: 중국 문학 문법 오류 수정에 대한 지속적 학습을 위한 다학제 벤치마크

## 📋 메타데이터

**Links**: [[daily/2025-09-17|2025-09-17]] [[keywords/broad/Continual Learning|Continual Learning]] [[keywords/broad/Grammatical Error Correction|Grammatical Error Correction]] [[keywords/specific/Large Language Models|Large Language Models]] [[keywords/evolved/Sequential Tuning|Sequential Tuning]] [[keywords/unique/CL$^2$GEC|CL$^2$GEC]] [[authors/Shang Qin|Shang Qin]] [[authors/Jingheng Ye|Jingheng Ye]] [[authors/Yinghui Li|Yinghui Li]] [[authors/Hai-Tao Zheng|Hai-Tao Zheng]] [[authors/Qi Li|Qi Li]] [[categories/cs.CL|cs.CL]] [[GEM-Bench: A Benchmark for Ad-Injected Response Generation within Generative Engine Marketing|77.9% similar]] [[Forget What You Know about LLMs Evaluations -- LLMs are Like a Chameleon|76.0% similar]] [[Calibrating LLMs for Text-to-SQL Parsing by Leveraging Sub-clause Frequencies|75.4% similar]]

## 🏷️ 카테고리화된 키워드
**🔬 Broad Technical**: Continual Learning, Grammatical Error Correction
**🔗 Specific Connectable**: Large Language Models
**🚀 Evolved Concepts**: Sequential Tuning
**⭐ Unique Technical**: CL^2GEC
## 🔗 유사한 논문
- [[GEM-Bench A Benchmark for Ad-Injected Response Generation within Generative Engine Marketing]] (77.9% similar)
- [[Forget What You Know about LLMs Evaluations -- LLMs are Like a Chameleon]] (76.0% similar)
- [[Calibrating LLMs for Text-to-SQL Parsing by Leveraging Sub-clause Frequencies]] (75.4% similar)
- [[Omni-CLST Error-aware Curriculum Learning with guided Selective chain-of-Thought for audio question answering]] (75.1% similar)
- [[EdiVal-Agent An Object-Centric Framework for Automated, Scalable, Fine-Grained Evaluation of Multi-Turn Editing]] (74.9% similar)


**ArXiv ID**: [2509.13672v1](https://arxiv.org/abs/2509.13672v1)
**Published**: 2025-09-17
**Category**: cs.CL
**PDF**: [Download](http://arxiv.org/pdf/2509.13672v1)


## 🏷️ 추출된 키워드



`Continual Learning` • 

`Grammatical Error Correction` • 

`Large Language Models` • 

`CL$^2$GEC` • 

`Sequential Tuning`



## 📋 저자 정보

**Authors:** Shang Qin, Jingheng Ye, Yinghui Li, Hai-Tao Zheng, Qi Li, Jinxiao Shan, Zhixing Li, Hong-Gee Kim

## 📄 Abstract (원문)

The growing demand for automated writing assistance in diverse academic
domains highlights the need for robust Chinese Grammatical Error Correction
(CGEC) systems that can adapt across disciplines. However, existing CGEC
research largely lacks dedicated benchmarks for multi-disciplinary academic
writing, overlooking continual learning (CL) as a promising solution to handle
domain-specific linguistic variation and prevent catastrophic forgetting. To
fill this crucial gap, we introduce CL$^2$GEC, the first Continual Learning
benchmark for Chinese Literature Grammatical Error Correction, designed to
evaluate adaptive CGEC across multiple academic fields. Our benchmark includes
10,000 human-annotated sentences spanning 10 disciplines, each exhibiting
distinct linguistic styles and error patterns. CL$^2$GEC focuses on evaluating
grammatical error correction in a continual learning setting, simulating
sequential exposure to diverse academic disciplines to reflect real-world
editorial dynamics. We evaluate large language models under sequential tuning,
parameter-efficient adaptation, and four representative CL algorithms, using
both standard GEC metrics and continual learning metrics adapted to task-level
variation. Experimental results reveal that regularization-based methods
mitigate forgetting more effectively than replay-based or naive sequential
approaches. Our benchmark provides a rigorous foundation for future research in
adaptive grammatical error correction across diverse academic domains.

## 🔍 Abstract (한글 번역)

다양한 학술 분야에서 자동화된 쓰기 지원에 대한 증가하는 수요는 학제간에 적응할 수 있는 강력한 중국어 문법 오류 교정(CGEC) 시스템의 필요성을 강조합니다. 그러나 기존의 CGEC 연구는 주로 다학제 학술 글쓰기를 위한 전용 벤치마크를 부족하게 하며, 지속적 학습(CL)을 도메인별 언어적 변이를 다루고 잊혀지는 것을 방지하는 유망한 해결책으로 간과하고 있습니다. 이 중요한 공백을 채우기 위해 우리는 중국 문학 문법 오류 교정을 위한 첫 번째 지속적 학습 벤치마크인 CL$^2$GEC를 소개합니다. 이는 다양한 학술 분야에서 적응형 CGEC를 평가하기 위해 설계되었습니다. 우리의 벤치마크에는 각각 독특한 언어 스타일과 오류 패턴을 보여주는 10가지 학문 분야를 포함한 10,000개의 인간 주석이 달린 문장이 포함되어 있습니다. CL$^2$GEC는 지속적 학습 환경에서 문법 오류 교정을 평가하며, 실제 편집 역학을 반영하기 위해 다양한 학문 분야에 순차적으로 노출되는 시뮬레이션을 수행합니다. 우리는 대규모 언어 모델을 순차 조정, 매개 변수 효율적 적응 및 네 가지 대표적인 CL 알고리즘을 사용하여 평가하였으며, 표준 GEC 메트릭과 과제 수준 변이에 적응된 지속적 학습 메트릭을 모두 사용하였습니다. 실험 결과는 규제 기반 방법이 재생 기반이나 순차적 접근보다 효과적으로 잊히는 것을 완화시킨다는 것을 보여줍니다. 우리의 벤치마크는 다양한 학술 분야에서 적응형 문법 오류 교정에 대한 미래 연구를 위한 엄격한 기반을 제공합니다.

## 📝 요약

다양한 학술 분야에서 자동화된 글쓰기 지원 수요가 증가함에 따라, 다양한 학문 분야에 적응할 수 있는 강력한 중국어 문법 오류 교정(CGEC) 시스템의 필요성이 대두되고 있다. 그러나 기존의 CGEC 연구는 주로 다학제적 학술 글쓰기를 위한 전용 벤치마크가 부족하며, 지속적 학습(CL)을 통해 도메인별 언어적 변이를 처리하고 잊혀짐을 방지하는 유망한 해결책으로 간과되고 있다. 이 중요한 공백을 채우기 위해, 우리는 다학제적 중국 문학 문법 오류 교정을 위한 첫 번째 지속적 학습 벤치마크인 CL$^2$GEC을 소개한다. 우리의 벤치마크는 10가지 학문 분야를 아우르는 10,000개의 인간 주석이 달린 문장을 포함하며, 각 분야는 독특한 언어 스타일과 오류 패턴을 보여준다. CL$^2$GEC은 실제 편집 역학을 반영하기 위해 다양한 학문 분야에 순차적으로 노출되는 것을 모방하는 지속적 학습 환경에서 문법 오류 교정을 평가한다. 실험 결과는 정규화 기반 방법이 재생 기반이나 순차적 접근 방법보다 효과적으로 잊혀짐을 완화시킨다는 것을 보여준다. 우리의 벤치마크는 다양한 학문 분야에 걸쳐 적응형 문법 오류 교정에 대한 미래 연구를 위한 엄격한 기반을 제공한다.

## 🎯 주요 포인트


- 다양한 학술 분야에서 자동 쓰기 지원 수요가 증가함에 따라, 다양한 학문 분야에 적응할 수 있는 강력한 중국어 문법 오류 수정(CGEC) 시스템의 필요성이 대두되고 있다.

- 연속 학습(CL)을 통해 도메인 특정 언어적 변이를 처리하고 잊혀지는 것을 방지하는 유망한 해결책으로서의 연속 학습을 간과한 CGEC 연구가 존재한다.

- 우리는 중국 문학 문법 오류 수정을 위한 첫 번째 연속 학습 벤치마크인 CL$^2$GEC를 소개하며, 이는 다양한 학문 분야에서 적응형 CGEC를 평가하기 위해 설계되었다.


---

*Generated on 2025-09-18 17:06:12*