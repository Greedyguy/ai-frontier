
# H$^2$R: Hierarchical Hindsight Reflection for Multi-Task LLM Agents

**Korean Title:** H$^2$R: 다중 작업 LLM 에이전트를 위한 계층적 후견 반성

## 📋 메타데이터

**Links**: [[daily/2025-09-17|2025-09-17]] [[keywords/Large Language Model|Large Language Model]] [[keywords/Multitask Learning|Multitask Learning]] [[keywords/Knowledge Transfer|Knowledge Transfer]] [[keywords/Hindsight Reflection|Hindsight Reflection]] [[keywords/Decisionmaking Performance|Decisionmaking Performance]] [[keywords/Generalization|Generalization]] [[keywords/Taskrelevant Knowledge|Taskrelevant Knowledge]] [[keywords/Agentenvironment Interactions|Agentenvironment Interactions]] [[categories/cs.AI|cs.AI]]

**ArXiv ID**: [2509.12810](https://arxiv.org/abs/2509.12810)
**Published**: 2025-09-17
**Category**: cs.AI
**PDF**: [Download](https://arxiv.org/pdf/2509.12810.pdf)


## 🏷️ 추출된 키워드



`Large Language Model` • 

`Multitask Learning` • 

`Knowledge Transfer` • 

`Hindsight Reflection` • 

`Decisionmaking Performance` • 

`Generalization` • 

`Agentenvironment Interactions` • 

`Taskrelevant Knowledge` • 

`Expel`



## 📋 저자 정보

**Authors:** 

## 📄 Abstract (원문)

arXiv:2509.12810v1 Announce Type: new 
Abstract: Large language model (LLM)-based agents have shown strong potential in multi-task scenarios, owing to their ability to transfer knowledge across diverse tasks. However, existing approaches often treat prior experiences and knowledge as monolithic units, leading to inefficient and coarse-grained knowledge transfer. In this work, we propose a novel hierarchical memory architecture that enables fine-grained knowledge transfer by decoupling high-level planning memory from low-level execution memory. To construct and refine these hierarchical memories, we introduce Hierarchical Hindsight Reflection (H$^2$R), a mechanism that distills reusable and hierarchical knowledge from past agent-environment interactions. At test time, H$^2$R performs retrievals of high-level and low-level memories separately, allowing LLM-based agents to efficiently access and utilize task-relevant knowledge for new tasks.Experimental results across two benchmarks demonstrate that H$^2$R can improve generalization and decision-making performance, outperforming prior baselines such as Expel.

## 🔍 Abstract (한글 번역)

arXiv:2509.12810v1 발표 유형: 새로운
요약: 대형 언어 모델(LLM) 기반 에이전트들은 다양한 작업 간에 지식을 전이할 수 있는 능력으로 인해 멀티태스크 시나리오에서 강력한 잠재력을 보여주고 있습니다. 그러나 기존의 방법들은 종종 이전 경험과 지식을 단일체로 다루어 효율적이지 않고 거친 수준의 지식 전이를 유발합니다. 본 연구에서는 고수준 계획 메모리와 저수준 실행 메모리를 분리함으로써 세밀한 지식 전이를 가능하게 하는 새로운 계층적 메모리 구조를 제안합니다. 이러한 계층적 메모리를 구축하고 정제하기 위해, 과거 에이전트-환경 상호작용에서 재사용 가능하고 계층적인 지식을 추출하는 Hierarchical Hindsight Reflection (H$^2$R) 메커니즘을 소개합니다. 시험 시간에 H$^2$R은 고수준 및 저수준 메모리를 별도로 검색하여 LLM 기반 에이전트들이 새로운 작업에 대한 작업 관련 지식을 효율적으로 접근하고 활용할 수 있도록 합니다. 두 가지 벤치마크를 통해 실험 결과는 H$^2$R이 일반화 및 의사결정 성능을 향상시킬 수 있으며, Expel과 같은 이전 기준선을 능가할 수 있음을 보여줍니다.

## 📝 요약

이 연구는 대규모 언어 모델(LLM) 기반 에이전트가 다양한 작업 간 지식을 전이할 수 있는 능력으로 다중 작업 시나리오에서 강력한 잠재력을 보여준다. 그러나 기존 접근 방식은 과거 경험과 지식을 단일 단위로 취급하여 비효율적이고 굵은 그레인지드 지식 전이를 유발한다. 본 연구에서는 고수

## 🎯 주요 포인트


- 1. 대규모 언어 모델 기반 에이전트는 다양한 작업 간 지식을 전이할 수 있는 능력을 보여주며, 새로운 작업에 대한 임무 관련 지식을 효율적으로 활용할 수 있다.

- 2. 본 연구에서는 고수준 계획 메모리와 저수준 실행 메모리를 분리함으로써 미세한 지식 전이를 가능케 하는 새로운 계층적 메모리 구조를 제안한다.

- 3. H$^2$R 메커니즘을 통해 과거 에이전트-환경 상호작용으로부터


---

*Generated on 2025-09-18 11:10:30*