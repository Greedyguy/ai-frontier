
# H$^2$R: Hierarchical Hindsight Reflection for Multi-Task LLM Agents

**Korean Title:** H$^2$R: ë‹¤ì¤‘ ì‘ì—… LLM ì—ì´ì „íŠ¸ë¥¼ ìœ„í•œ ê³„ì¸µì  í›„ê²¬ ë°˜ì„±

## ğŸ“‹ ë©”íƒ€ë°ì´í„°

**Links**: [[daily/2025-09-17|2025-09-17]] [[keywords/Large Language Model|Large Language Model]] [[keywords/Multitask Learning|Multitask Learning]] [[keywords/Knowledge Transfer|Knowledge Transfer]] [[keywords/Hindsight Reflection|Hindsight Reflection]] [[keywords/Decisionmaking Performance|Decisionmaking Performance]] [[keywords/Generalization|Generalization]] [[keywords/Taskrelevant Knowledge|Taskrelevant Knowledge]] [[keywords/Agentenvironment Interactions|Agentenvironment Interactions]] [[categories/cs.AI|cs.AI]]

**ArXiv ID**: [2509.12810](https://arxiv.org/abs/2509.12810)
**Published**: 2025-09-17
**Category**: cs.AI
**PDF**: [Download](https://arxiv.org/pdf/2509.12810.pdf)


## ğŸ·ï¸ ì¶”ì¶œëœ í‚¤ì›Œë“œ



`Large Language Model` â€¢ 

`Multitask Learning` â€¢ 

`Knowledge Transfer` â€¢ 

`Hindsight Reflection` â€¢ 

`Decisionmaking Performance` â€¢ 

`Generalization` â€¢ 

`Agentenvironment Interactions` â€¢ 

`Taskrelevant Knowledge` â€¢ 

`Expel`



## ğŸ“‹ ì €ì ì •ë³´

**Authors:** 

## ğŸ“„ Abstract (ì›ë¬¸)

arXiv:2509.12810v1 Announce Type: new 
Abstract: Large language model (LLM)-based agents have shown strong potential in multi-task scenarios, owing to their ability to transfer knowledge across diverse tasks. However, existing approaches often treat prior experiences and knowledge as monolithic units, leading to inefficient and coarse-grained knowledge transfer. In this work, we propose a novel hierarchical memory architecture that enables fine-grained knowledge transfer by decoupling high-level planning memory from low-level execution memory. To construct and refine these hierarchical memories, we introduce Hierarchical Hindsight Reflection (H$^2$R), a mechanism that distills reusable and hierarchical knowledge from past agent-environment interactions. At test time, H$^2$R performs retrievals of high-level and low-level memories separately, allowing LLM-based agents to efficiently access and utilize task-relevant knowledge for new tasks.Experimental results across two benchmarks demonstrate that H$^2$R can improve generalization and decision-making performance, outperforming prior baselines such as Expel.

## ğŸ” Abstract (í•œê¸€ ë²ˆì—­)

arXiv:2509.12810v1 ë°œí‘œ ìœ í˜•: ìƒˆë¡œìš´
ìš”ì•½: ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM) ê¸°ë°˜ ì—ì´ì „íŠ¸ë“¤ì€ ë‹¤ì–‘í•œ ì‘ì—… ê°„ì— ì§€ì‹ì„ ì „ì´í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ìœ¼ë¡œ ì¸í•´ ë©€í‹°íƒœìŠ¤í¬ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ê°•ë ¥í•œ ì ì¬ë ¥ì„ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê¸°ì¡´ì˜ ë°©ë²•ë“¤ì€ ì¢…ì¢… ì´ì „ ê²½í—˜ê³¼ ì§€ì‹ì„ ë‹¨ì¼ì²´ë¡œ ë‹¤ë£¨ì–´ íš¨ìœ¨ì ì´ì§€ ì•Šê³  ê±°ì¹œ ìˆ˜ì¤€ì˜ ì§€ì‹ ì „ì´ë¥¼ ìœ ë°œí•©ë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” ê³ ìˆ˜ì¤€ ê³„íš ë©”ëª¨ë¦¬ì™€ ì €ìˆ˜ì¤€ ì‹¤í–‰ ë©”ëª¨ë¦¬ë¥¼ ë¶„ë¦¬í•¨ìœ¼ë¡œì¨ ì„¸ë°€í•œ ì§€ì‹ ì „ì´ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ìƒˆë¡œìš´ ê³„ì¸µì  ë©”ëª¨ë¦¬ êµ¬ì¡°ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ê³„ì¸µì  ë©”ëª¨ë¦¬ë¥¼ êµ¬ì¶•í•˜ê³  ì •ì œí•˜ê¸° ìœ„í•´, ê³¼ê±° ì—ì´ì „íŠ¸-í™˜ê²½ ìƒí˜¸ì‘ìš©ì—ì„œ ì¬ì‚¬ìš© ê°€ëŠ¥í•˜ê³  ê³„ì¸µì ì¸ ì§€ì‹ì„ ì¶”ì¶œí•˜ëŠ” Hierarchical Hindsight Reflection (H$^2$R) ë©”ì»¤ë‹ˆì¦˜ì„ ì†Œê°œí•©ë‹ˆë‹¤. ì‹œí—˜ ì‹œê°„ì— H$^2$Rì€ ê³ ìˆ˜ì¤€ ë° ì €ìˆ˜ì¤€ ë©”ëª¨ë¦¬ë¥¼ ë³„ë„ë¡œ ê²€ìƒ‰í•˜ì—¬ LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ë“¤ì´ ìƒˆë¡œìš´ ì‘ì—…ì— ëŒ€í•œ ì‘ì—… ê´€ë ¨ ì§€ì‹ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì ‘ê·¼í•˜ê³  í™œìš©í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. ë‘ ê°€ì§€ ë²¤ì¹˜ë§ˆí¬ë¥¼ í†µí•´ ì‹¤í—˜ ê²°ê³¼ëŠ” H$^2$Rì´ ì¼ë°˜í™” ë° ì˜ì‚¬ê²°ì • ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìœ¼ë©°, Expelê³¼ ê°™ì€ ì´ì „ ê¸°ì¤€ì„ ì„ ëŠ¥ê°€í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## ğŸ“ ìš”ì•½

ì´ ì—°êµ¬ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM) ê¸°ë°˜ ì—ì´ì „íŠ¸ê°€ ë‹¤ì–‘í•œ ì‘ì—… ê°„ ì§€ì‹ì„ ì „ì´í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ìœ¼ë¡œ ë‹¤ì¤‘ ì‘ì—… ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ê°•ë ¥í•œ ì ì¬ë ¥ì„ ë³´ì—¬ì¤€ë‹¤. ê·¸ëŸ¬ë‚˜ ê¸°ì¡´ ì ‘ê·¼ ë°©ì‹ì€ ê³¼ê±° ê²½í—˜ê³¼ ì§€ì‹ì„ ë‹¨ì¼ ë‹¨ìœ„ë¡œ ì·¨ê¸‰í•˜ì—¬ ë¹„íš¨ìœ¨ì ì´ê³  êµµì€ ê·¸ë ˆì¸ì§€ë“œ ì§€ì‹ ì „ì´ë¥¼ ìœ ë°œí•œë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” ê³ ìˆ˜

## ğŸ¯ ì£¼ìš” í¬ì¸íŠ¸


- 1. ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ê¸°ë°˜ ì—ì´ì „íŠ¸ëŠ” ë‹¤ì–‘í•œ ì‘ì—… ê°„ ì§€ì‹ì„ ì „ì´í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ë³´ì—¬ì£¼ë©°, ìƒˆë¡œìš´ ì‘ì—…ì— ëŒ€í•œ ì„ë¬´ ê´€ë ¨ ì§€ì‹ì„ íš¨ìœ¨ì ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìˆë‹¤.

- 2. ë³¸ ì—°êµ¬ì—ì„œëŠ” ê³ ìˆ˜ì¤€ ê³„íš ë©”ëª¨ë¦¬ì™€ ì €ìˆ˜ì¤€ ì‹¤í–‰ ë©”ëª¨ë¦¬ë¥¼ ë¶„ë¦¬í•¨ìœ¼ë¡œì¨ ë¯¸ì„¸í•œ ì§€ì‹ ì „ì´ë¥¼ ê°€ëŠ¥ì¼€ í•˜ëŠ” ìƒˆë¡œìš´ ê³„ì¸µì  ë©”ëª¨ë¦¬ êµ¬ì¡°ë¥¼ ì œì•ˆí•œë‹¤.

- 3. H$^2$R ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´ ê³¼ê±° ì—ì´ì „íŠ¸-í™˜ê²½ ìƒí˜¸ì‘ìš©ìœ¼ë¡œë¶€í„°


---

*Generated on 2025-09-18 11:10:30*