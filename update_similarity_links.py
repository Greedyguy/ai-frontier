#!/usr/bin/env python3
"""ì„ì‹œ ìŠ¤í¬ë¦½íŠ¸: ëª¨ë“  ë…¼ë¬¸ íŒŒì¼ì— ìœ ì‚¬ë„ ë§í¬ ì¶”ê°€"""

import os
import sys
import re
from pathlib import Path
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Add src to path
sys.path.insert(0, '/Users/luke/work/SKT/edu/ai_frontier/src')

from ai_frontier.embeddings.similarity_manager import SimilarityManager
from ai_frontier.embeddings.service import get_embeddings_service
from ai_frontier.utils.obsidian_formatter import ObsidianFormatter

def extract_arxiv_id_from_filename(filename):
    """íŒŒì¼ëª…ì—ì„œ ArXiv ID ì¶”ì¶œ"""
    # íŒŒì¼ëª…ì—ì„œ ArXiv ID íŒ¨í„´ ì°¾ê¸° (ì˜ˆ: 2509.13672v1)
    match = re.search(r'(\d{4}\.\d{4,5}(?:v\d+)?)', filename)
    if match:
        arxiv_id = match.group(1)
        # v1, v2 ë“± ë²„ì „ ì œê±°
        if 'v' in arxiv_id:
            arxiv_id = arxiv_id.split('v')[0]
        return arxiv_id
    return None

def extract_arxiv_id_from_content(content):
    """íŒŒì¼ ë‚´ìš©ì—ì„œ ArXiv ID ì¶”ì¶œ"""
    # **ArXiv ID**: [2509.13672v1] íŒ¨í„´ ì°¾ê¸°
    match = re.search(r'\*\*ArXiv ID\*\*:\s*\[([^\]]+)\]', content)
    if match:
        arxiv_id = match.group(1)
        # v1, v2 ë“± ë²„ì „ ì œê±°
        if 'v' in arxiv_id:
            arxiv_id = arxiv_id.split('v')[0]
        return arxiv_id
    return None

def has_similarity_links(content):
    """ì´ë¯¸ ìœ ì‚¬ë„ ë§í¬ê°€ ìˆëŠ”ì§€ í™•ì¸"""
    return 'similar]' in content or '## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸' in content

def add_similarity_links_to_file(filepath, similarity_manager):
    """ê°œë³„ íŒŒì¼ì— ìœ ì‚¬ë„ ë§í¬ ì¶”ê°€"""
    try:
        # íŒŒì¼ ì½ê¸°
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()

        # ì´ë¯¸ ìœ ì‚¬ë„ ë§í¬ê°€ ìˆìœ¼ë©´ ìŠ¤í‚µ
        if has_similarity_links(content):
            return False, "Already has similarity links"

        # ArXiv ID ì¶”ì¶œ
        arxiv_id = extract_arxiv_id_from_content(content) or extract_arxiv_id_from_filename(filepath.name)

        if not arxiv_id:
            return False, "Could not extract ArXiv ID"

        # ìœ ì‚¬ë„ ë§í¬ ìƒì„±
        similar_links = similarity_manager.generate_obsidian_similarity_links(
            arxiv_id, max_links=5, min_similarity=0.6
        )

        if not similar_links:
            return False, "No similar papers found"

        # Links ì„¹ì…˜ì— ìœ ì‚¬ë„ ë§í¬ ì¶”ê°€
        links_pattern = r'(\*\*Links\*\*:\s*)(.*?)(\n\n|\n(?=##))'
        def add_similarity_to_links(match):
            prefix = match.group(1)
            existing_links = match.group(2).strip()
            suffix = match.group(3)

            # ìœ ì‚¬ë„ ë§í¬ë¥¼ ê¸°ì¡´ ë§í¬ì— ì¶”ê°€
            if existing_links:
                new_links = existing_links + ' ' + ' '.join(similar_links)
            else:
                new_links = ' '.join(similar_links)

            return f"{prefix}{new_links}{suffix}"

        # Links ì„¹ì…˜ ì—…ë°ì´íŠ¸
        new_content = re.sub(links_pattern, add_similarity_to_links, content, flags=re.DOTALL)

        # ìœ ì‚¬í•œ ë…¼ë¬¸ ì„¹ì…˜ ì¶”ê°€ (í‚¤ì›Œë“œ ì¶”ì¶œëœ í‚¤ì›Œë“œ ì„¹ì…˜ ë‹¤ìŒì—)
        keywords_section_pattern = r'(## ğŸ·ï¸ ì¶”ì¶œëœ í‚¤ì›Œë“œ.*?\n\n)'
        similarity_section = "\n## ğŸ”— ìœ ì‚¬í•œ ë…¼ë¬¸\n"

        for link in similar_links:
            # [[title|xx.x% similar]] í˜•íƒœì—ì„œ titleê³¼ percentage ì¶”ì¶œ
            match = re.search(r'\[\[([^|]+)\|([^]]+)\]\]', link)
            if match:
                title = match.group(1)
                percentage = match.group(2)
                # ê¹”ë”í•œ ë§í¬ í˜•íƒœë¡œ ë³€í™˜
                clean_title = title.replace(' ', ' ')
                similarity_section += f"- [[{clean_title}]] ({percentage})\n"

        similarity_section += "\n"

        # í‚¤ì›Œë“œ ì„¹ì…˜ ë‹¤ìŒì— ìœ ì‚¬í•œ ë…¼ë¬¸ ì„¹ì…˜ ì¶”ê°€
        def add_similarity_section(match):
            return match.group(1) + similarity_section

        new_content = re.sub(keywords_section_pattern, add_similarity_section, new_content, flags=re.DOTALL)

        # íŒŒì¼ ì €ì¥
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(new_content)

        return True, f"Added {len(similar_links)} similarity links"

    except Exception as e:
        return False, f"Error: {str(e)}"

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ ìœ ì‚¬ë„ ë§í¬ ì—…ë°ì´íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘")

    try:
        # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        print("ğŸ“Š ì„ë² ë”© ë° ìœ ì‚¬ë„ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”...")
        embeddings_service = get_embeddings_service()
        similarity_manager = SimilarityManager(embeddings_service=embeddings_service)

        # ë²¡í„° DB ìƒíƒœ í™•ì¸
        total_embeddings = len(similarity_manager.vector_db.arxiv_id_to_index)
        print(f"âœ… ë²¡í„° DBì— {total_embeddings}ê°œ ì„ë² ë”© ë¡œë“œë¨")

        # ë…¼ë¬¸ íŒŒì¼ ë””ë ‰í† ë¦¬
        papers_dir = Path('/Users/luke/work/SKT/edu/ai_frontier/reports/individual_papers')
        paper_files = list(papers_dir.glob('*.md'))

        print(f"ğŸ“„ ì²˜ë¦¬í•  ë…¼ë¬¸ íŒŒì¼: {len(paper_files)}ê°œ")

        # ê° íŒŒì¼ ì²˜ë¦¬
        updated_count = 0
        skipped_count = 0
        error_count = 0

        for i, filepath in enumerate(paper_files, 1):
            print(f"[{i}/{len(paper_files)}] ì²˜ë¦¬ ì¤‘: {filepath.name[:50]}...", end=' ')

            success, message = add_similarity_links_to_file(filepath, similarity_manager)

            if success:
                updated_count += 1
                print(f"âœ… {message}")
            elif "Already has" in message:
                skipped_count += 1
                print(f"â­ï¸  {message}")
            else:
                error_count += 1
                print(f"âŒ {message}")

        print(f"\nğŸ‰ ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"  âœ… ì—…ë°ì´íŠ¸ë¨: {updated_count}ê°œ")
        print(f"  â­ï¸  ì´ë¯¸ ìˆìŒ: {skipped_count}ê°œ")
        print(f"  âŒ ì˜¤ë¥˜: {error_count}ê°œ")
        print(f"  ğŸ“Š ì´ ì²˜ë¦¬: {len(paper_files)}ê°œ")

    except Exception as e:
        print(f"âŒ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        return 1

    return 0

if __name__ == "__main__":
    exit(main())